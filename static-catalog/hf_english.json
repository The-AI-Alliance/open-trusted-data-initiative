{"name":"NMT_Rwandan-Gazette_parallel_data_en_kin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a curated parallel dataset from the Official Gazette of the Republic of Rwanda. It has been curated to extract corresponding English and Kinyarwanda text and in the future we shall add French to the mix\\n\\nCurated by: Digital Umuganda\\nLanguage(s) (NLP): Kinyarwanda and English\\nLicense: cc-by-4.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\nThe dataset original content was retrieved from the Rwandan ministry of Justiceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DigitalUmuganda/NMT_Rwandan-Gazette_parallel_data_en_kin.","license":"https://choosealicense.com/licenses/cc/","url":"https://huggingface.co/datasets/DigitalUmuganda/NMT_Rwandan-Gazette_parallel_data_en_kin","creator_name":"Digital Umuganda","creator_url":"https://huggingface.co/DigitalUmuganda","keywords":["translation","Kinyarwanda","English","cc","100K - 1M","csv","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","kinyarwanda","english","machine-translation","low-ressourced languages"]}
{"name":"baby-python","description":"\\n  \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBaby Python\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnglish + Python pretraining dataset.\\n\\t\\n\\nThis dataset contains the dataset from the BabyLM 100M dataset, evenly matched by a truncated subset of the small-python-stack.\\nEnglish / all of BabyLM 100M\\n\\nCHILDES (child-directed speech)\\nSubtitles (speech)\\nBNC (speech)\\nTED talks (speech)\\nchildren's books (simple written language)\\n\\nPython\\n\\nPython code (from small-python-stack) corresponding to 100M words of English.\\n\\n","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/nilq/baby-python","creator_name":"Niels Horn","creator_url":"https://huggingface.co/nilq","keywords":["text-generation","English","mit","10M - 100M","parquet","Text","Datasets","Dask","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","python","english"]}
{"name":"CCNet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCCNet Reproduced Split (4M rows, 3.7B Tokens (Mistral tokenizer))\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is a reproduced subset of the larger CCNet dataset, tailored specifically to facilitate easier access and processing for researchers needing high-quality, web-crawled text data for natural language processing tasks. The CCNet dataset leverages data from the Common Crawl, a non-profit organization that crawls the web and freely provides its archives to the public. This subsetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JorgeeGF/CCNet.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/JorgeeGF/CCNet","creator_name":"Jorge Gallego Feliciano","creator_url":"https://huggingface.co/JorgeeGF","keywords":["English","mit","1M - 10M","json","Tabular","Text","Datasets","Dask","Croissant","ðŸ‡ºðŸ‡¸ Region: US","ccnet","english","common crawl","pretraining","internet","massive","text corpora","general text"]}
{"name":"HINMIX_hi-en","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Hindi English Codemix Dataset - HINMIX\\n\\t\\n\\nHINMIX is a massive parallel codemixed dataset for Hindi-English code switching.\\nSee the ðŸ“š paper on arxiv to dive deep into this synthetic codemix data generation pipeline. \\nDataset contains 4.2M fully parallel sentences in 6 Hindi-English forms.\\nFurther, we release gold standard codemix dev and test set manually translated by proficient bilingual annotators.\\n\\nDev Set consists of 280 examples\\nTest set consists of 2507 examplesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kartikagg98/HINMIX_hi-en.","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/kartikagg98/HINMIX_hi-en","creator_name":"kartik","creator_url":"https://huggingface.co/kartikagg98","keywords":["translation","Hindi","English","apache-2.0","10M - 100M","parquet","Text","Datasets","Dask","Croissant","Polars","arxiv:2403.16771","doi:10.57967/hf/4520","ðŸ‡ºðŸ‡¸ Region: US","codemix","indicnlp","hindi","english","multilingual"]}
{"name":"ACE_Australian_Corpus_of_English","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAustralian Corpus of English (ACE)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nKeywords: Australian English, Corpus linguistics.\\nThe Australian Corpus of English (ACE) corpus was compiled to match Australian data from 1986 to the standard American and British corpora (Brown and LOB) from the 1960s. It includes 1 million words of published text in 500 samples from 15 categories of nonfiction and fiction.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Source\\n\\t\\n\\nThe original dataset is from Macquarie University Research Data -â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SouthernCrossAI/ACE_Australian_Corpus_of_English.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/SouthernCrossAI/ACE_Australian_Corpus_of_English","creator_name":"Southern Cross AI","creator_url":"https://huggingface.co/SouthernCrossAI","keywords":["English","mit","10K - 100K","csv","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","australia","corpus","english"]}
{"name":"CoANZSE_Corpus_of_Australian_and_New_Zealand_Spoken_English","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpus of Australian and New Zealand Spoken English (CoANZSE)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAnnouncement\\n\\t\\n\\nThe dataset has limited access and requires access/download permission from Harvard Dataverse - Corpus of Australian and New Zealand Spoken English.\\nPlease acknowledge that the dataset owners are Steven Coats and Jeremy Yuenger. This repository is only used for study and research purposes for Southern Cross AI.\\nAny commercial use is not permitted by the dataset owner. Any distribution ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SouthernCrossAI/CoANZSE_Corpus_of_Australian_and_New_Zealand_Spoken_English.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/SouthernCrossAI/CoANZSE_Corpus_of_Australian_and_New_Zealand_Spoken_English","creator_name":"Southern Cross AI","creator_url":"https://huggingface.co/SouthernCrossAI","keywords":["English","mit","10K - 100K","csv","Text","Datasets","Dask","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","australia","new-zealand","corpus","english"]}
{"name":"COOEE_The_Corpus_of_Oz_Early_English","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tA COrpus of Oz Early English (COOEE)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nMaterial to be included had to meet a regional and a temporal criterion. The latter required texts to have been produced between 1788 and 1900 in order to become eligible for COOEE. It was mandatory for a text to have been written in Australia, New Zealand or Norfolk Island. But in a few cases, other localities were allowed. For example, if a person who was a native Australian or who had lived in Australia for aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SouthernCrossAI/COOEE_The_Corpus_of_Oz_Early_English.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/SouthernCrossAI/COOEE_The_Corpus_of_Oz_Early_English","creator_name":"Southern Cross AI","creator_url":"https://huggingface.co/SouthernCrossAI","keywords":["English","mit","10K - 100K","csv","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","australia","corpus","english"]}
{"name":"ART_Australian_Radio_Talkback_Corpus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAustralian Radio Talkback Corpus (ART)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nAustralian Radio Talkback (ART) is a set of transcribed recordings of samples of national, regional and commercial Australian talkback radio from 2004 to 2006. It consists of transcriptions of 27 audio recordingsof talkback from ABC National Radio (NAT), ABC Radio broadcasts to eastern Australian (ABCE), ABC Radio broadcasts to southern and western Australia (ABCNE), as well as commercial stations broadcasting toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SouthernCrossAI/ART_Australian_Radio_Talkback_Corpus.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/SouthernCrossAI/ART_Australian_Radio_Talkback_Corpus","creator_name":"Southern Cross AI","creator_url":"https://huggingface.co/SouthernCrossAI","keywords":["English","mit","1K - 10K","csv","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","australia","corpus","english"]}
{"name":"wikipedia_knowledge_base_en","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Wikipedia Knowledge Base\\n\\t\\n\\nThe dataset contains 117_364_716 extracted facts from a subset of selected wikipedia articles.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\nThe dataset was created using LLM processing a subset of the English Wikipedia 20231101.en dataset.\\n{\\n    \\\"language\\\": null,\\n    \\\"title\\\": \\\"Artificial intelligence\\\",\\n    \\\"url\\\": \\\"https://en.wikipedia.org/wiki/Artificial%20intelligence\\\",\\n    \\\"id\\\": \\\"1164\\\",\\n    \\\"facts\\\": [\\n        {\\n            \\\"text\\\": \\\"Two most widelyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jotschi/wikipedia_knowledge_base_en.","license":"https://choosealicense.com/licenses/cc-by-sa-3.0/","url":"https://huggingface.co/datasets/Jotschi/wikipedia_knowledge_base_en","creator_name":"Johannes SchÃ¼th","creator_url":"https://huggingface.co/Jotschi","keywords":["text-generation","text2text-generation","text-retrieval","machine-generated","English","cc-by-sa-3.0","ðŸ‡ºðŸ‡¸ Region: US","english","Synthetic"]}
{"name":"my-en-transliteration","description":"This dataset is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License. You can find the full license text [here](https://creativecommons.org/licenses/by-nc-sa/4.0/).\\n","license":"https://choosealicense.com/licenses/cc-by-nc-sa-4.0/","url":"https://huggingface.co/datasets/PhuePwint/my-en-transliteration","creator_name":"Phue Pwint Thwe","creator_url":"https://huggingface.co/PhuePwint","keywords":["cc-by-nc-sa-4.0","10K - 100K","csv","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","translation","transliteration","myanmar","english"]}
{"name":"english-telugu-translation","description":"\\n\\t\\n\\t\\t\\n\\t\\tEnglish-Telugu Translation Dataset\\n\\t\\n\\nThis dataset contains English-Telugu parallel sentences for translation tasks.  \\n\\n\\t\\n\\t\\t\\n\\t\\tðŸ“‚ Files Included:\\n\\t\\n\\n\\ntrain.csv â†’ Training data\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tðŸ“œ License\\n\\t\\n\\nThis dataset is licensed under cc-by-4.0.\\n","license":"https://choosealicense.com/licenses/cc-by-4.0/","url":"https://huggingface.co/datasets/hima06varshini/english-telugu-translation","creator_name":"Yaleru Himavarshini","creator_url":"https://huggingface.co/hima06varshini","keywords":["English","Telugu","cc-by-4.0","< 1K","csv","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","translation","english","telugu"]}
{"name":"en_to_kn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTranslation Dataset - English to Kannada\\n\\t\\n\\nThis dataset provides translation pairs from English to Kannada across a wide variety of common conversational contexts.\\nIt includes basic phrases and sentences covering a broad range of subjects, such as:\\n\\nBasic Greetings\\nSmall Talk\\nTravel and Directions\\nWeather and Environment\\nWork and Professional\\nEducation and Learning\\nHealth and Well-being\\nTechnology and Internet\\nShopping and Requests\\nFamily and Relationships\\nDining and Food\\nPublicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pavan-naik/en_to_kn.","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/pavan-naik/en_to_kn","creator_name":"Pavan Naik","creator_url":"https://huggingface.co/pavan-naik","keywords":["translation","English","Kannada","apache-2.0","< 1K","csv","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","kannada","translation","english_to_kannada","english"]}
{"name":"wikipedia-paragraph-summaries","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikipedia Paragraph Summaries Dataset\\n\\t\\n\\nThe Wikipedia Paragraph Summaries Dataset is designed for the task of text summarization, specifically generating concise summaries from paragraphs extracted from English Wikipedia articles. Each entry in the dataset consists of an input paragraph and its corresponding summary, facilitating research in natural language processing (NLP) and machine learning.\\nData Format:\\nThe dataset is provided in JSON Lines format (.jsonl), where each lineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/wikipedia-paragraph-summaries.","license":"https://choosealicense.com/licenses/cc-by-sa-3.0/","url":"https://huggingface.co/datasets/agentlans/wikipedia-paragraph-summaries","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","keywords":["summarization","text-classification","text-generation","language-modeling","English","cc-by-sa-3.0","10K - 100K","json","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","wikipedia","paragraphs","english"]}
{"name":"phonetic-tibetan-to-english-translation-pairs","description":"This dataset consists of a single csv with 10,000,000 rows which are pairs of sentences or phrases. The first member of each pair is a sentence or phrase in Classical Tibetan. The second member is the English translation of the first.\\nThe pairs are pulled from texts sourced from Lotsawa House and are offered under the same license as the original texts from which they are sourced.\\nThis data was scraped, cleaned, and formatted programmatically. Because of the difficulty in assembling data inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/billingsmoore/phonetic-tibetan-to-english-translation-pairs.","license":"https://choosealicense.com/licenses/cc-by-nc-4.0/","url":"https://huggingface.co/datasets/billingsmoore/phonetic-tibetan-to-english-translation-pairs","creator_name":"Jacob Moore","creator_url":"https://huggingface.co/billingsmoore","keywords":["translation","Tibetan","English","cc-by-nc-4.0","10M - 100M","csv","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","tibetan","english","translation","nlp","natural language processing","buddhism","dharma"]}
{"name":"high-quality-nli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHigh-Quality NLI Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is designed for Natural Language Inference (NLI) tasks, containing high-quality sentence pairs. It improves upon commonly used NLI datasets by offering more complex and nuanced examples, making it suitable for advanced language understanding models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\nTrain set size: 550â€‰970\\nTest set size: 137â€‰743\\nTotal size: 688â€‰713\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tClass Distributionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-nli.","license":"https://choosealicense.com/licenses/cc-by-sa-4.0/","url":"https://huggingface.co/datasets/agentlans/high-quality-nli","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","keywords":["text-classification","natural-language-inference","English","cc-by-sa-4.0","100K - 1M","json","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","nli","text-classification","english"]}
{"name":"Devnagari-Romanized-Pair","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThe dataset devanagari romanized pair contains, 959 rows, where each row has one English sentence and its corresponding Nepali translations both in the devanagari script and in romanized format, the size of the data set is less than 1,000 elements and it's designed for use in Translation, text generation and text to text generation tasks.\\n","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/nirajandhakal/Devnagari-Romanized-Pair","creator_name":"Nirajan Dhakal","creator_url":"https://huggingface.co/nirajandhakal","keywords":["translation","text-generation","text2text-generation","English","Nepali","apache-2.0","< 1K","csv","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","nepali","english","translation","nepali-english-bilingual"]}
{"name":"Quran_English_Myanmar_Parrelel_Corpus","description":"\\n\\t\\n\\t\\t\\n\\t\\tQuran English-Myanmar Parallel Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset is a parallel corpus of the Quran, containing translations in English and Myanmar. It includes 6,237 verses (ayahs) from all chapters (surahs), aligned by their respective Surah and Ayah numbers.\\n\\nEnglish Translation: Provided by Dr. Muhsin Khan and Dr. Hilali.\\nMyanmar Translation: Translated by the Myanmar Quran Translation Committee, comprising religious and non-religious scholars, and later published byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kingkaung/Quran_English_Myanmar_Parrelel_Corpus.","license":"https://choosealicense.com/licenses/cc0-1.0/","url":"https://huggingface.co/datasets/kingkaung/Quran_English_Myanmar_Parrelel_Corpus","creator_name":"King Kaung","creator_url":"https://huggingface.co/kingkaung","keywords":["translation","text-generation","Burmese","English","cc0-1.0","1K - 10K","csv","Tabular","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","myanmar","english","nlp","parrelel","corpus","Quran"]}
{"name":"LatinSummarizerDataset","description":"\\n\\t\\n\\t\\t\\n\\t\\tLatinSummarizer Dataset\\n\\t\\n\\n    \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe LatinSummarizerDataset is a structured dataset used in the GitHub Repository for Latin summarization and translation tasks. This dataset provides aligned English-Latin texts, extractive summaries, and pre-training prompts for fine-tuning models like mT5 for low-resource NLP applications.\\n\\n\\t\\n\\t\\t\\n\\t\\tStructure\\n\\t\\n\\nThe dataset is divided into two main phases: \\n\\nPre-training Data: Includes aligned bilingual corpora, syntheticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset.","license":"https://choosealicense.com/licenses/cc-by-4.0/","url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","keywords":["translation","text-generation","summarization","news-articles-summarization","document-retrieval","English","Latin","cc-by-4.0","Text","ðŸ‡ºðŸ‡¸ Region: US","text","translation","latin","english","parallel-corpus","dataset","mt5","nlp","multilingual","summarization"]}
{"name":"wikipedia_knowledge_graph_en","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Wikipedia Knowledge Graph\\n\\t\\n\\nThe dataset contains 16_958_654 extracted ontologies from a subset of selected wikipedia articles.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\nThe dataset was created via LLM processing a subset of the English Wikipedia 20231101.en dataset.\\nThe initial knowledge base dataset was used as a basis to extract the ontologies from. \\nPipeline: Wikipedia article â†’ Chunking â†’ Fact extraction (Knowledge base dataset) â†’ Ontology extraction from facts â†’â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jotschi/wikipedia_knowledge_graph_en.","license":"https://choosealicense.com/licenses/cc-by-sa-3.0/","url":"https://huggingface.co/datasets/Jotschi/wikipedia_knowledge_graph_en","creator_name":"Johannes SchÃ¼th","creator_url":"https://huggingface.co/Jotschi","keywords":["text-generation","text2text-generation","text-retrieval","machine-generated","English","cc-by-sa-3.0","ðŸ‡ºðŸ‡¸ Region: US","english","Synthetic"]}
{"name":"G15","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tG15 - v0.1\\n\\t\\n\\nG15-v0.1 is a part of G-series datasets which are pre-formatted in ChatML template.\\nThese datasets are useful for quickly finetuning LLMs for better responses.\\n\\n\\nThe G15-v0.1 is a combination of the following datasets:\\n\\nOpenHermes-2.5\\nMetaMathQA (100k entries)\\nA section of our in-house dataset used to finetune Cerberus-v0.1\\n\\nThis dataset is to be used on smaller LLMs (1B - 7B) to increase their response quality.\\n\\nFor queries please reach out to us at hello@brahmai.in\\n","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/brahmairesearch/G15","creator_name":"BRAHMAI Research","creator_url":"https://huggingface.co/brahmairesearch","keywords":["text2text-generation","text-generation","Hindi","English","apache-2.0","1M - 10M","parquet","Text","Datasets","Dask","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","hindi","maths","english","general"]}
{"name":"ElapticAI-1024","description":"The ElapticAI-1024 dataset consists of many datasets from different sources, all in plain text, english. unannotated and raw.\\n","license":"https://choosealicense.com/licenses/wtfpl/","url":"https://huggingface.co/datasets/elapt1c/ElapticAI-1024","creator_name":"elapt1c","creator_url":"https://huggingface.co/elapt1c","keywords":["English","wtfpl","1M - 10M","text","Text","Datasets","Croissant","ðŸ‡ºðŸ‡¸ Region: US","text","english","raw","unannotated","diverse"]}
{"name":"english_ner_dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnglish NER dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgement\\n\\t\\n\\nThis dataset had been created as part of joint research of HUMADEX research group (https://www.linkedin.com/company/101563689/) and has received funding by the European Union Horizon Europe Research and Innovation Program project SMILE (grant number 101080923) and Marie SkÅ‚odowska-Curie Actions (MSCA) Doctoral Networks, project BosomShield ((rant number 101073222). Responsibility for the information and views expressed hereinâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HUMADEX/english_ner_dataset.","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/HUMADEX/english_ner_dataset","creator_name":"HUMADEX Research Group","creator_url":"https://huggingface.co/HUMADEX","keywords":["token-classification","English","apache-2.0","100K - 1M","parquet","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","english","ner","medical","symptoms"]}
{"name":"dark_thoughts_casestudies_en_cn","description":"\\n\\t\\n\\t\\t\\n\\t\\tDark Thoughts Case Studies Dataset (English-Chinese)\\n\\t\\n\\nThis dataset contains a bilingual collection of case studies with detailed stakeholder analyses in English and Chinese. Each case study includes structured information about stakeholders and their motivations, along with comprehensive case analysis and solutions.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe dataset consists of 344,580 paired case studies in English and Chinese, with detailed stakeholder analyses andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DataTonic/dark_thoughts_casestudies_en_cn.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/DataTonic/dark_thoughts_casestudies_en_cn","creator_name":"Data Tonic (Alignment Lab)","creator_url":"https://huggingface.co/DataTonic","keywords":["text-generation","English","Chinese","mit","100K - 1M","parquet","Text","Datasets","Dask","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","business","case","business case","Synthetic","synthetic data","enterprise","chineese","english","multilingual"]}
{"name":"urdu-idioms-with-english-translation","description":"Ehtisham1328/urdu-idioms-with-english-translation dataset hosted on Hugging Face and contributed by the HF Datasets community","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/Ehtisham1328/urdu-idioms-with-english-translation","creator_name":"Ehtisham ul Hassan","creator_url":"https://huggingface.co/Ehtisham1328","keywords":["translation","text-generation","text2text-generation","Urdu","English","apache-2.0","1K - 10K","csv","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","urdu","idioms","nlp","english"]}
{"name":"korean_parallel_sentences_v1.1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Korean Parallel Sentences Ver 1.1\\n\\t\\n\\nThis dataset card provides information about the Korean Parallel Sentences Ver 1.1 dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Korean Parallel Sentences Ver 1.1 dataset is a collection of parallel sentences in Korean and English.\\nAlthough the factual accuracy of the data is not guaranteed, it has been designed to ensure accurate and consistent translation style between English and Korean.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lemon-mint/korean_parallel_sentences_v1.1.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/lemon-mint/korean_parallel_sentences_v1.1","creator_name":"Lemon Mint","creator_url":"https://huggingface.co/lemon-mint","keywords":["translation","text2text-generation","Korean","English","mit","100K - 1M","parquet","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","sentence-transformers","translation","korean","english","parallel","embedding","distill","distillation"]}
{"name":"korean_english_parallel_wiki_augmented_v1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKorean-English Parallel Wiki Augmented v1\\n\\t\\n\\nThis dataset contains a large number of Korean-English parallel sentences extracted from Wikipedia. It was created by augmenting the original English Wikipedia dataset with machine-translated Korean sentences. The dataset is designed for training and evaluating machine translation models, especially those focusing on English-to-Korean and Korean-to-English translation.\\nDataset Features:\\n\\nenglish: English sentence.\\nkorean:  Koreanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lemon-mint/korean_english_parallel_wiki_augmented_v1.","license":"https://choosealicense.com/licenses/cc-by-sa-3.0/","url":"https://huggingface.co/datasets/lemon-mint/korean_english_parallel_wiki_augmented_v1","creator_name":"Lemon Mint","creator_url":"https://huggingface.co/lemon-mint","keywords":["translation","text2text-generation","Korean","English","cc-by-sa-3.0","100K - 1M","parquet","Text","Datasets","Dask","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","sentence-transformers","translation","korean","english","parallel","embedding","distill","distillation"]}
{"name":"wikipedia-paragraphs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikipedia Paragraph Samples\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains paragraphs extracted from randomly selected English Wikipedia articles. It provides a diverse sample of Wikipedia content across various topics.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nName: Wikipedia Paragraph Samples\\nVersion: 1.0\\nDate Created: 2024-08-20\\nLanguage: English\\nFormat: JSONLines\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContents\\n\\t\\n\\nEach line in the dataset represents a single paragraph and contains two fields:\\n\\nTitleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/wikipedia-paragraphs.","license":"https://choosealicense.com/licenses/cc-by-sa-3.0/","url":"https://huggingface.co/datasets/agentlans/wikipedia-paragraphs","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","keywords":["text-classification","summarization","text-generation","multi-class-classification","topic-classification","language-modeling","English","cc-by-sa-3.0","10K - 100K","json","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","wikipedia","paragraphs","english"]}
{"name":"dark_thoughts_stakeholders_en_cn","description":"\\n\\t\\n\\t\\t\\n\\t\\tDark Thoughts Case Studies Dataset (English-Chinese)\\n\\t\\n\\nThis dataset contains a bilingual collection of case studies with detailed stakeholder analyses in English and Chinese. Each case study includes structured information about stakeholders and their motivations, along with comprehensive case analysis and solutions.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe dataset consists of 344,580 case studies in English and in Chinese, with detailed stakeholder analyses andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DataTonic/dark_thoughts_stakeholders_en_cn.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/DataTonic/dark_thoughts_stakeholders_en_cn","creator_name":"Data Tonic (Alignment Lab)","creator_url":"https://huggingface.co/DataTonic","keywords":["text-generation","English","Chinese","mit","100K - 1M","parquet","Text","Datasets","Dask","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","business","case","business case","Synthetic","synthetic data","enterprise","chineese","english","multilingual"]}
{"name":"english_tamil_slang","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BLESSENA30/english_tamil_slang.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/BLESSENA30/english_tamil_slang","creator_name":"VinukondaBlessena","creator_url":"https://huggingface.co/BLESSENA30","keywords":["translation","question-answering","English","Tamil","mit","< 1K","csv","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","english","tamil","language","multilinguial"]}
{"name":"inglish","description":"This dataset is built as a playground for beginner to make a translation model for Indonesian and English.","license":"https://choosealicense.com/licenses/cc-by-4.0/","url":"https://huggingface.co/datasets/jakartaresearch/inglish","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","keywords":["translation","machine-generated","machine-generated","translation","original","Indonesian","English","cc-by-4.0","10K - 100K","Text","Datasets","Croissant","ðŸ‡ºðŸ‡¸ Region: US","indonesian","english","translation"]}
{"name":"ugalang_0","description":"The ugalang_0 dataset contains Bible texts translated into East African languages, including English. It can be used for various translation tasks and language-related research in the context of East African languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nLanguages: Daasanach, Masaaba, Rendille, Ganda, Aringa, Kakwa, Lugbara, Talinga-Bwisi, Samburu, Lango, Rundi, Swahili, Ateso, Somali, English, Chidigo, Kinyarwanda, Gwere, Acholi, Kumam, Jopadhola, Keliko, Suba, Gungu, Soga, Nyankore, Kipfokomoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/oumo-os/ugalang_0.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/oumo-os/ugalang_0","creator_name":"O. Samuel Oumo","creator_url":"https://huggingface.co/oumo-os","keywords":["English","mit","1K - 10K","csv","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","translation","east-african-languages","english","bible-texts"]}
{"name":"fake_news_en_opensources","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Fake News Opensources\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nHomepage: https://github.com/AndyTheFactory/FakeNewsDataset\\nRepository: https://github.com/AndyTheFactory/FakeNewsDataset\\nPoint of Contact: Andrei Paraschiv\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\na consolidated and cleaned up version of the opensources Fake News dataset\\nFake News Corpus comprises 8,529,090 individual articles, classified into 12 classes: reliable, unreliable, political, bias, fakeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/andyP/fake_news_en_opensources.","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/andyP/fake_news_en_opensources","creator_name":"Andrei Paraschiv","creator_url":"https://huggingface.co/andyP","keywords":["text-classification","topic-classification","fact-checking","expert-generated","found","monolingual","Opensources https://github.com/BigMcLargeHuge/opensources","FakeNews Corpus https://github.com/several27/FakeNewsCorpus","English","apache-2.0","1M - 10M","csv","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","fake-news-detection","fake news","english","nlp"]}
{"name":"medical","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Medical\\\" Healthcare QnA Datasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe \\\"Medical\\\" dataset is a specialized subset curated from the larger MedDialog collection, featuring healthcare dialogues between doctors and patients. This dataset focuses on conversations from Icliniq, HealthcareMagic, and HealthTap. Written primarily in English, it is designed to serve a broad range of applications such as NLP research, healthcare chatbotâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kabatubare/medical.","license":"https://choosealicense.com/licenses/other/","url":"https://huggingface.co/datasets/Kabatubare/medical","creator_name":"Kabatubare","creator_url":"https://huggingface.co/Kabatubare","keywords":["English","other","10K - 100K","csv","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","healthcare","qna","nlp","english"]}
{"name":"english_to_igbo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnglish-Igbo Parallel Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset is a comprehensive collection of parallel sentences in English and Igbo. It has been compiled from multiple sources to create a rich resource for machine translation, language research, and natural language processing tasks. The dataset is particularly valuable for those focusing on Igbo, a language spoken primarily in Nigeria, which is underrepresented in the field of computational linguistics.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ccibeekeoc42/english_to_igbo.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/ccibeekeoc42/english_to_igbo","creator_name":"Chinemerem Christopher Ibe-Ekeocha","creator_url":"https://huggingface.co/ccibeekeoc42","keywords":["English","Igbo","mit","100K - 1M","json","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","machine-translation","igbo","english","nlp"]}
{"name":"tatoeba-tr-en","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTatoeba Turkish-English 2024\\n\\t\\n\\ntatoeba.org Turkish-English pairs. \\nLast Update: 01.01.2024\\n","license":"https://choosealicense.com/licenses/cc-by-2.0/","url":"https://huggingface.co/datasets/beratcmn/tatoeba-tr-en","creator_name":"Berat Ã‡imen","creator_url":"https://huggingface.co/beratcmn","keywords":["translation","Turkish","English","cc-by-2.0","100K - 1M","json","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","translation","turkish","english","tatoeba"]}
{"name":"English-Urdu-Dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\tEnglish Transliteration (Roman Urdu) of Urdu Poetry Dataset\\n\\t\\n\\nWelcome to the English Transliteration (Roman Urdu) of Urdu Poetry Dataset! This dataset provides a collection of Urdu poetry transliterated into Roman script, making the rich literary heritage of Urdu accessible to a broader audience. Each entry in the dataset includes two columns:\\n\\nTitle: The transliterated title of the poem in Roman Urdu.\\nPoem: The full text of the poem in Roman Urdu.\\n\\nThis dataset is ideal forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ReySajju742/English-Urdu-Dataset.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/ReySajju742/English-Urdu-Dataset","creator_name":"Muhammad Sajjad Rasool","creator_url":"https://huggingface.co/ReySajju742","keywords":["text-classification","English","Urdu","mit","1K - 10K","csv","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","urdu","english","urdu poetry"]}
{"name":"synthetic-urdu-poetry-dataset","description":"Urdu-English Poetic Translation Dataset\\nDescription\\nThis dataset provides a unique collection of English sentences paired with their Urdu translations, specifically crafted in a poetic style. It's designed for researchers, developers, and enthusiasts interested in exploring the intersection of natural language processing, machine translation, and Urdu poetry.\\nFeatures\\n\\nEnglish sentences paired with Urdu poetic translations\\nDesigned for NLP, machine translation, and Urdu poetry researchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ReySajju742/synthetic-urdu-poetry-dataset.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/ReySajju742/synthetic-urdu-poetry-dataset","creator_name":"Muhammad Sajjad Rasool","creator_url":"https://huggingface.co/ReySajju742","keywords":["text-classification","Urdu","English","mit","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US","urdu","english","urdu english"]}
{"name":"scaleway_r1_dark_thoughts_casestudies","description":"Tonic/scaleway_r1_dark_thoughts_casestudies dataset hosted on Hugging Face and contributed by the HF Datasets community","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/Tonic/scaleway_r1_dark_thoughts_casestudies","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","keywords":["text-classification","English","Chinese","mit","1M - 10M","arrow","Text","Datasets","Croissant","ðŸ‡ºðŸ‡¸ Region: US","casestudies","business","enterprise","qwen","r1","benign","chinese","english"]}
{"name":"LatinSummarizer","description":"\\n\\t\\n\\t\\t\\n\\t\\tLatinSummarizer Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tStructure\\n\\t\\n\\n\\naligned_en_la_data_raw.csv\\naligned_en_la_data_cleaned.csv\\naligned_en_la_data_cleaned_with_stanza.csv\\nconcat_aligned_data.csv\\nconcat_cleaned.csv\\nlatin_wikipedia_cleaned.csv\\nlatin_wikipedia_raw.csv\\nlatin-literature-dataset-170M_raw_cleaned.csv\\nlatin-literature-dataset-170M_raw_cleaned_chunked.csv\\nElsa_aligned/\\nREADME.md\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDetails\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\taligned_en_la_data_raw.csv\\n\\t\\n\\nThis dataset contains aligned Latin (la) - English (en)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizer.","license":"https://choosealicense.com/licenses/cc-by-4.0/","url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizer","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","keywords":["translation","text-generation","summarization","news-articles-summarization","document-retrieval","English","Latin","cc-by-4.0","1M - 10M","csv","Text","Datasets","Dask","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","text","translation","latin","english","parallel-corpus","dataset","mt5","nlp","multilingual","summarization"]}
