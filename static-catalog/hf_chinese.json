{"name":"GLM-4-Instruct-4K-zh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n❤️欢迎使用rqq/GLM-4-Instruct-4K-zh数据集，本数据集包含了4000条高质量的glm4回复。\\n该数据集的提问数据源自高质量的Sao10K/Claude-3-Opus-Instruct-5K数据集，我们把它的问题翻译成了中文，使用glm-4进行了重新回答。\\n该数据集使用alpaca格式，可以直接用在llama-factory项目中进行训练！\\n文件如下：\\nGLM-4-Instruct-4K-zh.json 问答数据集，alpaca格式\\nGLM-4-question-translate-5K-zh 翻译-对话数据集，记录了把Sao10K/Claude-3-Opus-Instruct-5K问题翻译成中文的数据\\nWelcome to the rqq/GLM-4-Instruct-4K-zh dataset! This dataset includes 4,000 high-quality responses from the GLM-4 model.\\nThe question… See the full description on the dataset page: https://huggingface.co/datasets/rqq/GLM-4-Instruct-4K-zh.","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/rqq/GLM-4-Instruct-4K-zh","creator_name":"hikariming","creator_url":"https://huggingface.co/rqq","keywords":["translation","question-answering","Chinese","apache-2.0","1K - 10K","json","Text","Datasets","Dask","Croissant","🇺🇸 Region: US","GLM4","chinese","chat"]}
{"name":"confucius","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tconfucius\\n\\t\\n\\nConfucius for real. See all analects.\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"AWeirdDev/confucius\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFormat\\n\\t\\n\\n{\\n  \\\"chapter\\\": \\\"學而\\\", # Chapter name\\n  \\\"content\\\": \\\"子曰：「學而時習之，不亦說乎？…\\\",  # Content\\n  \\\"translation\\\": \\\"孔子說：「經常學習，不也喜悅嗎？…\\\"  # Translated (zh-TW)\\n}\\n\\n\\n  \\n    \\n    Confucius, confused.\\n  \\n","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/AWeirdDev/confucius","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","keywords":["translation","text-generation","Chinese","mit","< 1K","parquet","Text","Datasets","pandas","Croissant","Polars","🇺🇸 Region: US","chinese","analect","confucius","language"]}
{"name":"Chinese-Braille-Dataset-No-Tone","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Braille Dataset (No Tone)\\n\\t\\n\\n\\n  📃 [Paper] • 💻 [Github] • 🤗 [Dataset] • ⚙️ [Model] • 🎬 [Demo]\\n\\n\\nThis dataset is the Chinese-Braille-Dataset-No-Tone dataset described in https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\n# Sample\\nBraille Len. (Mean/Median) String\\nBraille Len. (Mean/Median) Token\\nChinese Len. (Mean/Median) String\\nChinese Len. (Mean/Median) Token\\n\\n\\n\\t\\t\\nTraining\\n525072\\n140/108\\n144/112\\n74/64… See the full description on the dataset page: https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-No-Tone.","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-No-Tone","creator_name":"ALanWu","creator_url":"https://huggingface.co/Violet-yo","keywords":["Chinese","apache-2.0","100K - 1M","parquet","Text","Datasets","pandas","Croissant","Polars","arxiv:2407.06048","🇺🇸 Region: US","chinese","braille"]}
{"name":"Chinese-Braille-Dataset-10per-Tone","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Braille Dataset\\n\\t\\n\\n\\n  📃 [Paper] • 💻 [Github] • 🤗 [Dataset] • ⚙️ [Model] • 🎬 [Demo]\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Chinese-Braille-10per-Tone dataset addresses the scarcity of publicly available Chinese Braille datasets. The original Chinese text data was sourced from the publicly available Leipzig Corpora Collection. This dataset consists of one million discrete sentences collected from news media between 2007 and 2009.\\nThe Chinese characters from the Leipzig… See the full description on the dataset page: https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone.","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone","creator_name":"ALanWu","creator_url":"https://huggingface.co/Violet-yo","keywords":["Chinese","apache-2.0","100K - 1M","parquet","Text","Datasets","pandas","Croissant","Polars","arxiv:2407.06048","🇺🇸 Region: US","chinese","braille"]}
{"name":"CHUBS","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCHUBS: A Large-Scale Dataset of Chu Bamboo Slip Script\\n\\t\\n\\n\\n  Code | Paper (upcoming)\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is a large-scale dataset of Chu bamboo slip (CBS, Chinese: 楚简, chujian) script, an ancient Chinese script used during the Spring and Autumn period over 2,000 years ago. This dataset consists of two parts: \\n\\nThe main dataset where each example is an image and the corresponding text label. This part is contained in the glyphs.zip ZIP file.\\nA character detection… See the full description on the dataset page: https://huggingface.co/datasets/chen-yingfa/CHUBS.","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/chen-yingfa/CHUBS","creator_name":"Yingfa Chen","creator_url":"https://huggingface.co/chen-yingfa","keywords":["image-classification","text-to-image","token-classification","Chinese","apache-2.0","1K - 10K","json","Image","Text","Datasets","Dask","Croissant","🇺🇸 Region: US","chinese","ancient-script"]}
{"name":"TWRMCD","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tyuhuanstudio/TWRMCD\\n\\t\\n\\n(此項目數據及處理方式參考並改良自 ytchen175/master_thesis 感謝開源處理流程！)\\n一個收錄了正體中文（繁體中文）字典的資料集，用於大模型微調\\n(追求進步但不應該捨去歷史，中華文化不該因政治而被抹去並消亡)\\nA data set containing Traditional Chines dictionaries for fine-tuning LLM\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n「台灣教育部重編國語辭典修訂本」 （Taiwan's Ministry of Education Revised Mandarin Chinese Dictionary，TWRMCD），\\n資料取自於台灣教育部的《重編國語辭典修訂本》\\n為了讓LLM從多方面增加對繁體中文的認識，我們利用從中提取並設計六大指令任務「詞語解釋、讀音問答、簡繁轉換、單句釋義、近似詞與反義詞」（約51萬筆指令）\\nThis dataset is sourced from Taiwan’s Ministry of… See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/TWRMCD.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/yuhuanstudio/TWRMCD","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","keywords":["text-generation","Chinese","mit","100K - 1M","json","Text","Datasets","pandas","Croissant","Polars","🇺🇸 Region: US","chinese","RMCD"]}
{"name":"JUREX-4E","description":"\\n\\t\\n\\t\\t\\n\\t\\tJUREX\\n\\t\\n\\nSource code and data for JUREX-4E: Juridical Expert-Annotated Four-Element Knowledge Base for Legal Reasoning\\nCode: https://github.com/THUlawtech/JUREX\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\n\\nDataset Structure\\nAnnotation\\nExperiment\\nSimilar Charge Distinction\\nLegal Case Retrieval\\n\\n\\nRequirements\\nLicense\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nJUREX-4E is the first part of our curated expert knowledge base(mind map structure), \\nfocusing on the four elements of criminal charges.\\ndata\\n- law  # legal texts… See the full description on the dataset page: https://huggingface.co/datasets/zotown/JUREX-4E.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/zotown/JUREX-4E","creator_name":"zotown","creator_url":"https://huggingface.co/zotown","keywords":["question-answering","Chinese","mit","< 1K","json","Text","Datasets","pandas","Croissant","Polars","arxiv:2502.17166","🇺🇸 Region: US","legal","chinese"]}
{"name":"piaozhu","description":"\\n\\t\\n\\t\\t\\n\\t\\t数据集名称：嘴臭搭子微调数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1. 数据集简介\\n\\t\\n\\n这个数据集为微调对话生成模型提供了一个特殊的训练样本，基于一个虚拟的角色“沈蓬竹”进行交互。这个角色（外号“朴竹”）具有冷嘲热讽、毒舌、简洁而有攻击性的特点，适合训练模型产生具有讽刺、冷嘲热讽语气的回答。数据集的内容主要是角色扮演对话场景，适用于生成具有特定风格的对话模型，特别是在带有讽刺和幽默的情境下进行互动时。\\n\\n\\t\\n\\t\\t\\n\\t\\t2. 数据集结构\\n\\t\\n\\n数据集为一个包含若干对话轮次的 JSON 格式文件。每个对话轮次由角色和用户的对话组成，每个对话包含以下字段：\\n\\nrole：角色的身份，可能是 \\\"system\\\" 或 \\\"user\\\"。\\n\\\"system\\\" 表示是模型设定角色的输入（如定义角色背景、行为模式等）。\\n\\\"user\\\" 表示对话中的用户输入（如提问、请求或交互）。\\n\\n\\ncontent：对话内容，表示角色或者用户的具体发言。\\nloss_weight（可选）：每个数据条目对应的损失权重，当前可为空或为 null。可以在模型训练中加权不同对话内容。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t3. 数据样例… See the full description on the dataset page: https://huggingface.co/datasets/Retr01234/piaozhu.","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/Retr01234/piaozhu","creator_name":"Chen","creator_url":"https://huggingface.co/Retr01234","keywords":["text-generation","Chamorro","Chinese","apache-2.0","< 1K","json","Text","Datasets","pandas","Croissant","Polars","🇺🇸 Region: US","dialogue","sarcasm","humor","chinese","toxic","NLP"]}
{"name":"cmmlu","description":"CMMLU is a comprehensive Chinese assessment suite specifically designed to evaluate the advanced knowledge and reasoning abilities of LLMs within the Chinese language and cultural context.","license":"https://choosealicense.com/licenses/cc-by-nc-4.0/","url":"https://huggingface.co/datasets/haonan-li/cmmlu","creator_name":"Haonan Li","creator_url":"https://huggingface.co/haonan-li","keywords":["multiple-choice","question-answering","Chinese","cc-by-nc-4.0","10K - 100K","Text","Datasets","Croissant","arxiv:2306.09212","🇺🇸 Region: US","chinese","llm","evaluation"]}
{"name":"Chinese-Roleplay-SingleTurn","description":"请注意，个人模型经过characterEval的reward model进行DPO训练，因此使用本数据集进行SFT的模型在该榜单上会存在bias，导致分数异常偏高，请勿直接使用该榜单进行测试\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t简介\\n\\t\\n\\n因已找到更优数据合成方案，为填充中文角色扮演数据集的空白，现开源部分中文角色扮演单轮对话数据集。\\n使用Refined-Anime-Text作为system prompt，使用小黄鸡随机query作为输入，调用个人角色扮演模型作为输出。\\n已处理为alpaca数据格式，方便大家处理和训练。经过验证，仅使用该数据集进行Lora微调即可获取一个效果还不错的模型~\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tchatGPT对比\\n\\t\\n\\n\\n\\t\\n\\t\\t\\ncharacter\\nquestion\\nanswer_us\\nanswer_chatGPT… See the full description on the dataset page: https://huggingface.co/datasets/LooksJuicy/Chinese-Roleplay-SingleTurn.","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/LooksJuicy/Chinese-Roleplay-SingleTurn","creator_name":"LooksJuicy","creator_url":"https://huggingface.co/LooksJuicy","keywords":["text-generation","Chinese","apache-2.0","1K - 10K","json","Text","Datasets","pandas","Croissant","Polars","🇺🇸 Region: US","rp","character","roleplay","chinese","alpaca"]}
{"name":"Chinese-Braille-Dataset-Full-Tone","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Braille Dataset (Full Tone)\\n\\t\\n\\n\\n  📃 [Paper] • 💻 [Github] • 🤗 [Dataset] • ⚙️ [Model] • 🎬 [Demo]\\n\\n\\nThis dataset is the Chinese-Braille-Dataset-Full-Tone dataset described in https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\n# Sample\\nBraille Len. (Mean/Median) String\\nBraille Len. (Mean/Median) Token\\nChinese Len. (Mean/Median) String\\nChinese Len. (Mean/Median) Token\\n\\n\\n\\t\\t\\nTraining\\n525072\\n186/144\\n190/147… See the full description on the dataset page: https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-Full-Tone.","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-Full-Tone","creator_name":"ALanWu","creator_url":"https://huggingface.co/Violet-yo","keywords":["Chinese","apache-2.0","100K - 1M","parquet","Text","Datasets","pandas","Croissant","Polars","arxiv:2407.06048","🇺🇸 Region: US","chinese","braille"]}
{"name":"Chinese-Tag-Extraction","description":"Johnson8187/Chinese-Tag-Extraction dataset hosted on Hugging Face and contributed by the HF Datasets community","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/Johnson8187/Chinese-Tag-Extraction","creator_name":"Johnson","creator_url":"https://huggingface.co/Johnson8187","keywords":["text2text-generation","text-classification","zero-shot-classification","feature-extraction","Chinese","mit","1K - 10K","json","Text","Datasets","pandas","Croissant","Polars","🇺🇸 Region: US","tag","keyword","chinese"]}
{"name":"CaseGen","description":"\\n\\t\\n\\t\\t\\n\\t\\tCaseGen: A Benchmark for Multi-Stage Legal Case Documents Generation\\n\\t\\n\\n\\n\\n\\n\\nCaseGen is a benchmark designed to evaluate large language models (LLMs) in the generation of legal case documents in the Chinese legal domain. The dataset includes 500 real-world legal case instances, each structured into seven sections: Prosecution, Defense, Evidence, Events, Facts, Reasoning, and Judgment. It supports four key tasks: drafting defense statements, writing trial facts, composing legal reasoning… See the full description on the dataset page: https://huggingface.co/datasets/CSHaitao/CaseGen.","license":"https://choosealicense.com/licenses/cc-by-sa-4.0/","url":"https://huggingface.co/datasets/CSHaitao/CaseGen","creator_name":"Haitao Li","creator_url":"https://huggingface.co/CSHaitao","keywords":["text-generation","Chinese","cc-by-sa-4.0","🇺🇸 Region: US","legal","chinese","multi-stage-generation"]}
{"name":"chinese_text_recognition","description":"Source of data: https://github.com/FudanVI/benchmarking-chinese-text-recognition\\n","license":"https://choosealicense.com/licenses/undefined/","url":"https://huggingface.co/datasets/priyank-m/chinese_text_recognition","creator_name":"priyank","creator_url":"https://huggingface.co/priyank-m","keywords":["image-to-text","image-captioning","monolingual","Chinese","100K - 1M","parquet","Image","Text","Datasets","pandas","Croissant","Polars","🇺🇸 Region: US","ocr","text-recognition","chinese"]}
{"name":"spanish-chinese","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"spanish-chinese\\\"\\n\\t\\n\\nAll sensences extracted from the United Nations Parallel Corpus v1.0.\\nThe parallel corpus consists of manually translated United Nations documents for the six\\nofficial UN languages, Arabic, Chinese, English, French, Russian, and Spanish.\\nThe corpus is freely available for download at https://conferences.unite.un.org/UNCorpus\\nunder the terms of use outlined in the attached DISCLAIMER.\\nThe original individual documents are available at the United… See the full description on the dataset page: https://huggingface.co/datasets/Deysi/spanish-chinese.","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/Deysi/spanish-chinese","creator_name":"Caraballo","creator_url":"https://huggingface.co/Deysi","keywords":["translation","Spanish","Chinese","apache-2.0","10M - 100M","parquet","Text","Datasets","Dask","Croissant","Polars","🇺🇸 Region: US","language","translation","traducción","idiomas","chino","chinese","español","spanish","Universidad de La Rioja"]}
{"name":"TWDOCI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tyuhuanstudio/TWDOCI\\n\\t\\n\\n一個收錄了正體中文（繁體中文）成語典的資料集，用於大模型微調\\n(追求進步但不應該捨去歷史，中華文化不該因政治而被抹去並消亡)\\nA data set containing dictionary of traditional chinese idioms for fine-tuning LLM\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n「台灣教育部成語典」 （Taiwan's Ministry of Education Dictionary Of Chinese Idioms，TWDOCI），\\n資料取自於台灣教育部的《成語典》\\n為了讓LLM從多方面增加對繁體中文的認識，我們利用從中提取並設計六大指令任務「成語典故、讀音問答、成語解釋、使用時機、近似詞與反義詞、使用方法」（約2.2萬筆指令）\\nThis dataset is sourced from Taiwan’s Ministry of Education’s Revised Mandarin Chinese Dictionary.\\nTo… See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/TWDOCI.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/yuhuanstudio/TWDOCI","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","keywords":["text-generation","Chinese","mit","10K - 100K","json","Text","Datasets","pandas","Croissant","Polars","🇺🇸 Region: US","chinese","DOCI","TWDOCI"]}
{"name":"scaleway_r1_dark_thoughts_casestudies","description":"Tonic/scaleway_r1_dark_thoughts_casestudies dataset hosted on Hugging Face and contributed by the HF Datasets community","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/Tonic/scaleway_r1_dark_thoughts_casestudies","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","keywords":["text-classification","English","Chinese","mit","1M - 10M","arrow","Text","Datasets","Croissant","🇺🇸 Region: US","casestudies","business","enterprise","qwen","r1","benign","chinese","english"]}
