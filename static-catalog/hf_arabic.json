{"name":"kmZQBkk558WWAGV","description":"israel/kmZQBkk558WWAGV dataset hosted on Hugging Face and contributed by the HF Datasets community","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/israel/kmZQBkk558WWAGV","creator_name":"Israel Abebe Azime","creator_url":"https://huggingface.co/israel","keywords":["multiple-choice","multiple-choice-qa","Amharic","English","Spanish","Somali","Tigrinya","Oriya","Arabic","mit","10K - 100K","csv","Tabular","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","ethiopia","amharic","emotion","oromo","tigregya","spanish","arabic"]}
{"name":"KHATT_v1.0_dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKHATT_v1.0 - line level\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKHATT (KFUPM Handwritten Arabic TexT) database is a database of unconstrained handwritten Arabic Text written by 1000 different writers. This research databaseâ€™s development was undertaken by a research group from KFUPM, Dhahran, S audi Arabia headed by Professor Sabri Mahmoud in collaboration with Professor Fink from TU-Dortmund, Germany and Dr. MÃ¤rgner from TU-Braunschweig, Germany.\\nThe database includes 2000 similar-textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/johnlockejrr/KHATT_v1.0_dataset.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/johnlockejrr/KHATT_v1.0_dataset","creator_name":"John Locke","creator_url":"https://huggingface.co/johnlockejrr","keywords":["image-to-text","Arabic","mit","Image","ðŸ‡ºðŸ‡¸ Region: US","atr","htr","ocr","historical","handwritten","arabic"]}
{"name":"AURA-Sentiment","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAURA-Sentiment\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe AURA Sentiment Dataset is a collection of 29,700 app reviews in Arabic from iOS and Android platforms. Each review is labeled with a sentiment class, enabling researchers and practitioners to develop and evaluate sentiment analysis models tailored to the Arabic language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\nThe dataset includes the following columns:\\n\\nreview: The text of the app review in Arabic.\\nappName: The name of the applicationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/irfan-ahmad/AURA-Sentiment.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/irfan-ahmad/AURA-Sentiment","creator_name":"Irfan Ahmad","creator_url":"https://huggingface.co/irfan-ahmad","keywords":["Arabic","mit","10K - 100K","parquet","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","sentiment-classification","arabic","app-reviews","text-classification","nlp"]}
{"name":"TuniziBigBench","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTuniziBigBench: The Largest Open-Source Tunizi (Darija) Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset was created by scraping over 14,000 Tunisian YouTube videos, providing a rich repository of Tunisian language data. It covers a wide range of topics and text types, including politics, news, football, and more. The dataset is particularly valuable for training and fine-tuning natural language processing models specific to Tunisian Arabic and other local dialects.\\nWe are workingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nehdi/TuniziBigBench.","license":"https://choosealicense.com/licenses/creativeml-openrail-m/","url":"https://huggingface.co/datasets/Nehdi/TuniziBigBench","creator_name":"Taha","creator_url":"https://huggingface.co/Nehdi","keywords":["text-classification","Arabic","creativeml-openrail-m","1M - 10M","csv","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","Tunizi","arabic"]}
{"name":"FineWeb2-North-Levantine-Arabic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFineWeb2 North Levantine Arabic\\n\\t\\n\\n\\nðŸ‡±ðŸ‡§ This is the  North Levantine Arabic Portion of The FineWeb2 Dataset.\\nðŸ‡¸ðŸ‡© The North Levantine Arabic, represented by the ISO 639-3 code apc, is a member of the Afro-Asiatic language family and utilizes the Arabic script. \\nðŸ‡¯ðŸ‡´ Known within subsets as apc_Arab, this language boasts an extensive corpus of over ** 221K rows**.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose of This Repository\\n\\t\\n\\nThis repository provides easy access to the Arabic portion -  North Levantineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-North-Levantine-Arabic.","license":"https://choosealicense.com/licenses/odc-by/","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-North-Levantine-Arabic","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","keywords":["Arabic","odc-by","100K - 1M","parquet","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","datasets","fineweb2","arabic","North Levantine"]}
{"name":"Tamazight-Speech-to-Arabic-Text","description":"\\n\\t\\n\\t\\t\\n\\t\\tTamazight-Arabic Speech Recognition Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis is the EMINES organization-hosted version of the Tamazight-Arabic Speech Recognition Dataset, synchronized with the original dataset. It contains ~15.5 hours of Tamazight speech (Tachelhit dialect) paired with Arabic transcriptions, designed for developing ASR and translation systems.\\n\\n\\t\\n\\t\\t\\n\\t\\tQuick Start\\n\\t\\n\\nfrom datasets import load_dataset\\n\\n# Load the dataset\\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text.","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","keywords":["automatic-speech-recognition","Arabic","Standard Moroccan Tamazight","apache-2.0","10K - 100K","parquet","Audio","Text","Datasets","Dask","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","speech","tamazight","arabic","speech-to-text","low-resource","north-africa"]}
{"name":"ILMAAM-Arabic-Culturally-Aligned-MMLU","description":"\\n\\t\\n\\t\\t\\n\\t\\tILMAAM Arabic Culturally Aligned MMLU Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe ILMAAM (Index for Language Models for Arabic Assessment on Multitasks) benchmark provides a culturally enriched, linguistically refined, and contextually relevant evaluation framework for Arabic Large Language Models (LLMs). It is based on the Arabic Massive Multitask Language Understanding (MMLU) dataset but extends it with culturally aligned topics and annotations for fluency, adequacy, culturalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/ILMAAM-Arabic-Culturally-Aligned-MMLU.","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/ILMAAM-Arabic-Culturally-Aligned-MMLU","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","keywords":["Arabic","apache-2.0","10K - 100K","csv","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","datasets","arabic","mmlu","evalution"]}
{"name":"AURA-Classification","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAURA-Classification\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe AURA (App User Review in Arabic) Classification dataset is a collection of 2,900 Arabic-language app reviews collected from various mobile applications. This dataset is primarily designed for text classification tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\nThe dataset includes the following fields:\\n\\nreview: The text of the review in Arabic.\\n\\nappName: The name of the application being reviewed.\\n\\nplatform: The platform (iOS or Android)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/irfan-ahmad/AURA-Classification.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/irfan-ahmad/AURA-Classification","creator_name":"Irfan Ahmad","creator_url":"https://huggingface.co/irfan-ahmad","keywords":["Arabic","mit","1K - 10K","parquet","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","text-classification","arabic","app-reviews","nlp"]}
{"name":"summarized-darija-msa-wiki-data","description":"\\n\\t\\n\\t\\t\\n\\t\\tMSA-Darija Summarization Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis is the EMINES organization-hosted version of the MSA-Darija Summarization Dataset, synchronized with the original dataset. It contains 4800 rows of Moroccan and Arabic texts with Arabic summarization, designed for developing summarization models.\\n\\n\\t\\n\\t\\t\\n\\t\\tQuick Start\\n\\t\\n\\nfrom datasets import load_dataset\\n\\n# Load the dataset\\ndataset = load_dataset(\\\"EMINES/summarized-darija-msa-wiki-data\\\")\\n\\n# Example usage\\nfor example inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EMINES/summarized-darija-msa-wiki-data.","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/EMINES/summarized-darija-msa-wiki-data","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","keywords":["summarization","Arabic","apache-2.0","1K - 10K","parquet","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","text","Moroccan Darija","arabic","summarization","low-resource","north-africa"]}
{"name":"arabic-books","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Books\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe arabic-books dataset contains 8,500 rows of text, each representing the full text of a single Arabic book. These texts were extracted using the arabic-large-nougat model, showcasing the modelâ€™s capabilities in Arabic OCR and text extraction. The dataset spans a total of 1.1 billion tokens, calculated using the GPT-4 tokenizer.\\nThis dataset is a testimony to the quality of the Arabic Nougat models and their effectiveness inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/arabic-books.","license":"https://choosealicense.com/licenses/gpl-3.0/","url":"https://huggingface.co/datasets/MohamedRashad/arabic-books","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","keywords":["text-generation","Arabic","gpl-3.0","1K - 10K","arrow","Text","Datasets","Croissant","arxiv:2411.17835","ðŸ‡ºðŸ‡¸ Region: US","arabic","ocr","books","text-extraction","language-modeling","vision-transformers"]}
{"name":"quran-question-answer-context","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"quran-question-answer-context\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTranslated the original dataset from Arabic to English and added the Surah ayahs to the context column.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"nazimali/quran-question-answer-context\\\")\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['q_id', 'question', 'answer', 'q_word', 'q_topic', 'fine_class', 'class', 'ontology_concept', 'ontology_concept2', 'source'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nazimali/quran-question-answer-context.","license":"https://choosealicense.com/licenses/cc-by-4.0/","url":"https://huggingface.co/datasets/nazimali/quran-question-answer-context","creator_name":"Nazim Ali","creator_url":"https://huggingface.co/nazimali","keywords":["question-answering","Arabic","English","cc-by-4.0","1K - 10K","parquet","Tabular","Text","Datasets","Dask","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","islam","quran","arabic"]}
{"name":"Casablanca","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCasablanca: Data and Models for Multidialectal Arabic Speech Recognition\\n\\t\\n\\n\\n\\nIn spite of the recent progress in speech processing, the majority of world languages and dialects remain uncovered. This situation only furthers an already wide technological divide, thereby hindering technological and socioeconomic inclusion. This challenge is largely due to the absence of datasets that can empower diverse speech systems. In this paper, we seek to mitigate this obstacle for a number ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/UBC-NLP/Casablanca.","license":"https://choosealicense.com/licenses/cc-by-nc-nd-4.0/","url":"https://huggingface.co/datasets/UBC-NLP/Casablanca","creator_name":"UBC Deep Learning & NLP Lab","creator_url":"https://huggingface.co/UBC-NLP","keywords":["Arabic","cc-by-nc-nd-4.0","10K - 100K","parquet","Audio","Text","Datasets","Dask","Croissant","Polars","arxiv:2410.04527","ðŸ‡ºðŸ‡¸ Region: US","speech","arabic","asr","speech_recognition","speech_processing","dialects","algeria","egypt","jordan","mauritania","morocco","palestine","uae","yemen"]}
{"name":"alquran","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Terjemahan dan Tafsir Al-Quran\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDeskripsi Dataset\\n\\t\\n\\nDataset ini berisi terjemahan Al-Quran dalam bahasa Indonesia beserta tafsirnya. Dataset ini dapat digunakan untuk berbagai tugas NLP seperti machine translation, text generation, dan text summarization.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFitur Utama\\n\\t\\n\\n\\nTerjemahan Al-Quran: Teks Al-Quran dalam bahasa Arab beserta terjemahannya dalam bahasa Indonesia.\\nTafsir Al-Quran: Penjelasan atau interpretasi dari ayat-ayat Al-Quran dalamâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ronnieaban/alquran.","license":"https://choosealicense.com/licenses/cc-by-4.0/","url":"https://huggingface.co/datasets/ronnieaban/alquran","creator_name":"Ronnie Aban","creator_url":"https://huggingface.co/ronnieaban","keywords":["text-generation","translation","text-classification","Arabic","Indonesian","cc-by-4.0","1K - 10K","csv","Tabular","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","quran","translation","tafsir","religious-text","islamic-studies","arabic","indonesian","on, tafsir, religious-text, islamic-studies, arabic, indonesian, text-generation","machine-translation","text-classification","natural-language-understanding"]}
{"name":"Arabic_fake_news_dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic_fake_news_dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPlease note that this dataset needs more preprocessing.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repository contains the Arabic_fake_news_dataset, a collection of news articles scraped from the Egyptian platform Ù…ØªØµØ¯Ù‚Ø´ (Matsda2sh). The dataset is intended for studying and addressing the spread of fake news within the Egyptian community. It includes news articles classified as either fake or true, along with their corresponding titles.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HeshamHaroon/Arabic_fake_news_dataset.","license":"https://choosealicense.com/licenses/apache-2.0/","url":"https://huggingface.co/datasets/HeshamHaroon/Arabic_fake_news_dataset","creator_name":"Hesham Haroon","creator_url":"https://huggingface.co/HeshamHaroon","keywords":["text-classification","Arabic","apache-2.0","1K - 10K","json","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","fake-news","arabic","web-scraping"]}
{"name":"arabic_dialects_question_and_answer","description":"Data Content\\nThe file provided: Q/A Reasoning dataset\\ncontains the following columns:\\n\\n\\nID # : Denotes the reference ID for:\\na. Question\\nb. Answer to the question\\nc. Hint\\nd. Reasoning\\ne. Word count for items a to d above\\nDialects: Contains the following dialects in separate columns:\\na. English\\nb. MSA\\nc. Emirati\\nd. Egyptian\\ne. Levantine Syria\\nf. Levantine Jordan\\ng. Levantine Palestine\\nh. Levantine Lebanon\\nData Generation Process\\nThe following are the steps that were followed to curate the data:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CNTXTAI0/arabic_dialects_question_and_answer.","license":"https://choosealicense.com/licenses/mit/","url":"https://huggingface.co/datasets/CNTXTAI0/arabic_dialects_question_and_answer","creator_name":"CNTXT AI","creator_url":"https://huggingface.co/CNTXTAI0","keywords":["question-answering","text-generation","text2text-generation","Arabic","English","mit","< 1K","csv","Tabular","Text","Datasets","pandas","Croissant","Polars","ðŸ‡ºðŸ‡¸ Region: US","arabic","arabicdialicts","msa","Q&A","STEM","math"]}
