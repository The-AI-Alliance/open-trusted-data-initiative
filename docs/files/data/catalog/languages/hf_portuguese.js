var data_for_portuguese = [

  {"name":"instruct-aira-dataset-v2","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v2","creator_name":"Nicholas Kluge Corr√™a","creator_url":"https://huggingface.co/nicholasKluge","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInstruct-Aira Dataset version 2.0\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains a collection of single-turn conversations between an assistant and a user. Conversations were generated by user interactions with already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc). The dataset is available in Portuguese and English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be utilized for various natural language processing tasks, including but not limited‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v2."},
  {"name":"toxic-text","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nicholasKluge/toxic-text","creator_name":"Nicholas Kluge Corr√™a","creator_url":"https://huggingface.co/nicholasKluge","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tToxic-Text\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains a collection of examples of toxic and non-toxic language. The dataset is available in both Portuguese and English.\\nSamples were collected from the following datasets:\\n\\nAnthropic/hh-rlhf.\\nallenai/prosocial-dialog.\\nallenai/real-toxicity-prompts.\\ndirtycomputer/Toxic_Comment_Classification_Challenge.\\nPaul/hatecheck-portuguese.\\ntold-br.\\nskg/toxigen-data.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/toxic-text."},
  {"name":"mittens","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/google/mittens","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMiTTenS: A Dataset for Evaluating Misgendering in Translation\\n\\t\\n\\nMisgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scripts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/mittens."},
  {"name":"google-play-apps-review-pt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AiresPucrs/google-play-apps-review-pt","creator_name":"AI Robotics Ethics Society (PUCRS)","creator_url":"https://huggingface.co/AiresPucrs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGoogle Play Apps Review PT (Teeny-Tiny Castle)\\n\\t\\n\\nThis dataset is part of a tutorial tied to the Teeny-Tiny Castle, an open-source repository containing¬†educational tools for AI Ethics and Safety research. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"AiresPucrs/google-play-apps-review-pt\\\", split = 'train')\\n\\n"},
  {"name":"aya_dataset_pt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/botbot-ai/aya_dataset_pt","creator_name":"BotBot","creator_url":"https://huggingface.co/botbot-ai","description":"CohereForAI Aya Dataset filtrado para portugu√™s (PT).\\nAya Dataset Summary\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\nCurated by: Contributors of Aya Open Science Intiative.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/botbot-ai/aya_dataset_pt."},
  {"name":"aya_dataset_pt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/botbot-ai/aya_dataset_pt","creator_name":"BotBot","creator_url":"https://huggingface.co/botbot-ai","description":"CohereForAI Aya Dataset filtrado para portugu√™s (PT).\\nAya Dataset Summary\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\nCurated by: Contributors of Aya Open Science Intiative.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/botbot-ai/aya_dataset_pt."},
  {"name":"testedata","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Nuno-Tome/testedata","creator_name":"Nuno Tome","creator_url":"https://huggingface.co/Nuno-Tome","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset aims to be a base template for new datasets and for testing code.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n2 image files in jpg format\\n"},
  {"name":"SQuAD-pt_BR-V1.1_","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/vsvasconcelos/SQuAD-pt_BR-V1.1_","creator_name":"Vagner Sanches Vasconcelos","creator_url":"https://huggingface.co/vsvasconcelos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card para o SQuAD 1.1 em Portugu√™s Brasil\\n\\t\\n\\nO conjunto de dados \\\"Stanford Question Answering Dataset\\\" (SQuAD),\\npara tarefa de perguntas e respostas extrativas, foi desenvolvido em 2016. Ele utiliza perguntas geradas a partir de\\n536 artigos da Wikipedia* com mais de 100.000 linhas de dados. √â constru√≠do na forma de uma pergunta e um contexto dos artigos da\\nWikipedia contendo a resposta √† pergunta. [1]Originalmente este dataset foi constru√≠do no idioma ingl√™s, contudo, o‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vsvasconcelos/SQuAD-pt_BR-V1.1_."},
  {"name":"questions_answers_geo_nord","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rhaymison/questions_answers_geo_nord","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","description":"rhaymison/questions_answers_geo_nord dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Cabra3k","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/botbot-ai/Cabra3k","creator_name":"BotBot","creator_url":"https://huggingface.co/botbot-ai","description":"O conjunto de dados Cabra √© uma cole√ß√£o ampla e diversificada de 3.000 entradas ou conjuntos de perguntas e respostas (QA) sobre o Brasil. Inclui t√≥picos variados como hist√≥ria, pol√≠tica, geografia, cultura, cinema, esportes, ci√™ncia e tecnologia, governo e muito mais. Este conjunto foi cuidadosamente elaborado e selecionado pela nossa equipe, garantindo alta qualidade e relev√¢ncia para estudos e aplica√ß√µes relacionadas ao Brasil.\\nDetalhes do Conjunto de Dados:\\nTamanho: 3.000 conjuntos de QA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/botbot-ai/Cabra3k."},
  {"name":"Publico","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hugosousa/Publico","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tP√∫blico\\n\\t\\n\\nThis dataset was build by translating a set of 34,157 news from P√∫blico, an European Portuguese news paper. The news have been translated using Google Translator.\\nTo now more about the data visit the Github repos used to scrape and translate the news.\\n"},
  {"name":"mewsli-x","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\\nand converted into different parts (see process.py):\\n\\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\\n\\nRaw data files are in raw.tar.gz, which contains:\\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\\n[...] 9.8M Feb 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x."},
  {"name":"medicine-information-pt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rhaymison/medicine-information-pt","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","description":"rhaymison/medicine-information-pt dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Puntuguese","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Superar/Puntuguese","creator_name":"Marcio Lima In√°cio","creator_url":"https://huggingface.co/Superar","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPuntuguese - A Corpus of Puns in Portuguese with Micro-editions\\n\\t\\n\\nPuntuguese is a corpus of Portuguese punning texts, including Brazilian and European Portuguese jokes. The data has been manually gathered and curated according to our guidelines. It also contains some layers of annotation:\\n\\nEvery pun is classified as homophonic, homographic, both, or none according to their specific punning signs;\\nThe punning and alternative signs were made explicit for every joke;\\nWe also mark‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Superar/Puntuguese."},
  {"name":"stopwords-pt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AiresPucrs/stopwords-pt","creator_name":"AI Robotics Ethics Society (PUCRS)","creator_url":"https://huggingface.co/AiresPucrs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStopwords PT (Teeny-Tiny Castle)\\n\\t\\n\\nThis dataset is part of a tutorial tied to the Teeny-Tiny Castle, an open-source repository containing¬†educational tools for AI Ethics and Safety research. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"AiresPucrs/stopwords-pt\\\", split = 'train')\\n\\n"},
  {"name":"multi-hatecheck","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/multi-hatecheck","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nCombines multilingual HateCheck datasets (10 languages, including English), by Paul Roettger and colleagues (2021, 2022).\\nThe original English dataset can be found under https://github.com/Paul/hatecheck.\\nDatasets for other languages are found at:\\n\\nhttps://github.com/Paul/hatecheck-arabic\\nhttps://github.com/Paul/hatecheck-mandarin\\nhttps://github.com/Paul/hatecheck-german\\nhttps://github.com/Paul/hatecheck-french\\nhttps://github.com/Paul/hatecheck-hindi‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/multi-hatecheck."},
  {"name":"aya_african_alpaca","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/vutuka/aya_african_alpaca","creator_name":"vutuka","creator_url":"https://huggingface.co/vutuka","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAya African Alpaca Style Dataset\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vutuka/aya_african_alpaca."},
  {"name":"ptbr-deita-8k","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/botbot-ai/ptbr-deita-8k","creator_name":"BotBot","creator_url":"https://huggingface.co/botbot-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\tPTBR Deita 8k\\n\\t\\n\\nPortuguese translation of the Deita 8k dataset. \\n"},
  {"name":"oab_gemini","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/celsowm/oab_gemini","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","description":"celsowm/oab_gemini dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"InvoicesReceiptsPT","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Francisco-Cruz/InvoicesReceiptsPT","creator_name":"Francisco Cruz","creator_url":"https://huggingface.co/Francisco-Cruz","description":"This is a dataset comprising 1003 images of invoices and receipts, as well as the transcription of relevant fields for each document ‚Äì seller name, seller address, seller tax identification, buyer tax identification, invoice date, invoice total amount, invoice tax amount, and document reference. \\nIt is organized as:\\n\\nfolder 1_Images: files with pictures od the invoices/receipts \\nfolder 2_Annotations_Json: text files with the annotations on a json format\\n\\nAlso available at:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Francisco-Cruz/InvoicesReceiptsPT."},
  {"name":"enem-essay-correction-2018-2024","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fonsecovizk/enem-essay-correction-2018-2024","creator_name":"Gabriel Fonseca","creator_url":"https://huggingface.co/fonsecovizk","description":"fonsecovizk/enem-essay-correction-2018-2024 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fake_voices","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/unfake/fake_voices","creator_name":"Unfake","creator_url":"https://huggingface.co/unfake","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Fake Voices\\n\\t\\n\\nThis dataset contains deepfakes in Brazilian Portuguese created with XTTS model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe dataset was created using the XTTS model, which is a Text-to-Speech model pre-trained in several languages including Portuguese. \\nIn order to generate the mentioned deepfakes, the model was fed with recordings from the CETUC Corpus, \\nmade available by Fala Brasil Group. It contains speeches from 101 speakers, totaling 140 hours of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unfake/fake_voices."},
  {"name":"dataset-portuguese-aira-v2-Gemma-format","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/EddyGiusepe/dataset-portuguese-aira-v2-Gemma-format","creator_name":"EDDY GIUSEPE CHIRINOS ISIDRO, PhD","creator_url":"https://huggingface.co/EddyGiusepe","description":"Dataset Aira para o formato do Modelo Gemma \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tResumo do Dataset\\n\\t\\n\\nEste conjunto de dados cont√©m uma cole√ß√£o de conversas individuais entre um assistente e um usu√°rio.\\nAs conversas foram geradas pelas intera√ß√µes do usu√°rio com modelos j√° ajustados (ChatGPT, LLama 2, Open-Assistant, etc).\\nO conjunto de dados est√° dispon√≠vel em portugu√™s (tem a vers√£o em Ingl√™s que ainda n√£o tratei). Mas voc√™ pode baixar do \\nreposit√≥rio de Nicholas Kluge Corr√™a tanto a vers√£o em Portugu√™s e \\na vers√£o‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EddyGiusepe/dataset-portuguese-aira-v2-Gemma-format."},
  {"name":"cetacean-ptbr","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lucianosb/cetacean-ptbr","creator_name":"Luciano Santa Br√≠gida","creator_url":"https://huggingface.co/lucianosb","description":"This dataset is a merge of Open-Orca and Dolphin translated to portuguese.\\n"},
  {"name":"gemini_orpo_dpo_ptbr","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/celsowm/gemini_orpo_dpo_ptbr","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","description":"celsowm/gemini_orpo_dpo_ptbr dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"xm3600","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\nIt also includes the image features as PIL Image and has a uniform and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600."},
  {"name":"xm3600_1k","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600 - 1K Split\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a 1K split of XM3600!\\n\\t\\n\\nFor this, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k."},
  {"name":"xgqa","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/xgqa","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\txGQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a clone of the few_shot-test split of the xGQA dataset\\n\\t\\n\\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{pfeiffer-etal-2021-xGQA,\\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\\\'{c}} and Iryna Gurevych}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa."},
  {"name":"cpc_2015_brasil","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/0rakul0/cpc_2015_brasil","creator_name":"Jefferson Silva dos Anjos","creator_url":"https://huggingface.co/0rakul0","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSALVAMENTO do Dataset\\n\\t\\n\\nfrom datasets import load_dataset\\nfrom datasets import Dataset\\nimport pandas as pd\\n\\n# Carregar os dados do arquivo de texto\\ndf = pd.read_parquet('../data/cpc_2015_cleaned.parquet')\\n\\ndata = {\\n    \\\"livro\\\": df[\\\"Livro\\\"],\\n    \\\"capitulo\\\": df[\\\"Capitulo\\\"],\\n    \\\"titulo\\\": df[\\\"Titulo\\\"],\\n    \\\"secao\\\": df[\\\"Secao\\\"],\\n    \\\"subsecao\\\": df[\\\"Subsecao\\\"],\\n    \\\"artigo\\\": df[\\\"Artigo\\\"]\\n}\\n\\n# Dividir o texto em se√ß√µes\\ndataset = Dataset.from_pandas(pd.DataFrame(data))‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/0rakul0/cpc_2015_brasil."},
  {"name":"x-fact","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"x-fact\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact."},
  {"name":"xgqa_1k","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/xgqa_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\txGQA 1K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a 1K subset of the few_shot-test split of the xGQA dataset\\n\\t\\n\\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{pfeiffer-etal-2021-xGQA,\\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\\\'{c}} and Iryna Gurevych}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa_1k."},
  {"name":"from-one-to-many-toxicity-mitigation","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation","creator_name":"Luiza Pozzobon","creator_url":"https://huggingface.co/luizapzbn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFrom One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\\n\\t\\n\\n[arxiv][code][data]\\nData accompanying the paper \\\"From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\\\" accepted to ACL Findings 2024.\\nAbstract: To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, it‚Äôs crucial our safety measures keep pace. Recognizing this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation."},
  {"name":"anacreontea","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ronunes/anacreontea","creator_name":"Rafael Oleques Nunes","creator_url":"https://huggingface.co/ronunes","description":"This repository contains the dataset for the paper Ancient Greek's New Technological Muse: Extracting Topoi in the Anacreontea with LLMs, accepted at the 51st SEMISH (51¬∫ Semin√°rio Integrado de Software e Hardware).\\nAbstract:\\n\\nNatural Language Processing (NLP), along with Large Language Models (LLMs), holds significant potential in the domain of literature, leveraging its computational capabilities to analyze and comprehend human language. These techniques prove to be particularly useful in a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ronunes/anacreontea."},
  {"name":"europa-random-split","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/NCube/europa-random-split","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EUROPA\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\\nKey Features:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa-random-split."},
  {"name":"MultiPICo","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo","creator_name":"MultilingualPerspectivistNLU","creator_url":"https://huggingface.co/Multilingual-Perspectivist-NLU","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultiPICo (Multilingual Perspectivist Irony Corpus) is a disaggregated multilingual corpus for irony detection, containing 18,778 pairs of short conversations (post-reply) from Twitter (8,956) and Reddit (9,822), along with the demographic information of each annotator (age, nationality, gender, and so on). \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nIrony classification task using soft labels (i.e., distribution of annotations) or hard labels (i.e.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo."},
  {"name":"Chatgpt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt."},
  {"name":"synthetic_multilingual_llm_prompts","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","description":"\\n  \\n  Image generated by DALL-E. See prompt for more details\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìùüåê Synthetic Multilingual LLM Prompts\\n\\t\\n\\nWelcome to the \\\"Synthetic Multilingual LLM Prompts\\\" dataset! This comprehensive collection features 1,250 synthetic LLM prompts generated using Gretel Navigator, available in seven different languages. To ensure accuracy and diversity in prompts, and translation quality and consistency across the different languages, we employed Gretel Navigator both as a generation tool and as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts."},
  {"name":"FairytaleQA-translated-ptBR","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/benjleite/FairytaleQA-translated-ptBR","creator_name":"Bernardo Leite","creator_url":"https://huggingface.co/benjleite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for FairytaleQA-translated-ptBR\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis repository contains the Brazilian Portuguese (pt-BR) machine-translated version of the original English FairytaleQA dataset (https://huggingface.co/datasets/WorkInTheDark/FairytaleQA). FairytaleQA is an open-source dataset designed to enhance comprehension of narratives, aimed at students from kindergarten to eighth grade. The dataset is meticulously annotated by education experts following an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjleite/FairytaleQA-translated-ptBR."},
  {"name":"portuguese-blogs","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fabiovilao/portuguese-blogs","creator_name":"fabio vila","creator_url":"https://huggingface.co/fabiovilao","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nBlog-1 may include other languages in an unstructured text format without markdown. The latest one, Blog-6, is formatted in markdown and may contain less other languages text.\\nTexts are separated by the string <|endoftext|>.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\nTraining language models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nA simple text file with articles separated by <|endoftext|> between each text.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\nFirst semester of 2024.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBias, Risks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fabiovilao/portuguese-blogs."},
  {"name":"portuguese-blogs","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fabiovilao/portuguese-blogs","creator_name":"fabio vila","creator_url":"https://huggingface.co/fabiovilao","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nBlog-1 may include other languages in an unstructured text format without markdown. The latest one, Blog-6, is formatted in markdown and may contain less other languages text.\\nTexts are separated by the string <|endoftext|>.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\nTraining language models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nA simple text file with articles separated by <|endoftext|> between each text.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\nFirst semester of 2024.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBias, Risks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fabiovilao/portuguese-blogs."},
  {"name":"speakerVerification_PTBR","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nnenufar/speakerVerification_PTBR","creator_name":"Jo√£o Gabriel Lima","creator_url":"https://huggingface.co/nnenufar","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card\\n\\t\\n\\n\\n\\nThis dataset includes ~80k samples of speech audio in Brazilian Portuguese. Samples have variable length ranging from 1 to 4 seconds, with a sampling rate of 16kHz. The metadata file includes speaker tags and corresponding labels for each sample, making it appropriate for speaker identification and speaker verification tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nAudio samples are taken from three bigger corpora: C-ORAL Brasil, NURC Recife and NURC SP. Please take‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nnenufar/speakerVerification_PTBR."},
  {"name":"meudata","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/EronSamez/meudata","creator_name":"Samez","creator_url":"https://huggingface.co/EronSamez","description":"EronSamez/meudata dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"multiple-choice-questions","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mateus-hamade/multiple-choice-questions","creator_name":"Mateus Hamade","creator_url":"https://huggingface.co/mateus-hamade","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuest√µes de M√∫ltipla Escolha - Base de dados (PT-BR)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContextualiza√ß√£o\\n\\t\\n\\nEste reposit√≥rio cont√©m uma base de dados (data.json) com quest√µes de m√∫ltipla escolha, a qual foi utilizada principalmente no desenvolvimento de modelos de recupera√ß√£o de informa√ß√£o.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescri√ß√£o do conjunto de dados\\n\\t\\n\\nO conjunto de dados √© composto por quest√µes de m√∫ltipla escolha, abrangendo uma variedade de temas dentro da √°rea da Ci√™ncia da Computa√ß√£o. Cada quest√£o √© estruturada‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mateus-hamade/multiple-choice-questions."},
  {"name":"Multilingual-Benchmark","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \\nBibTex\\n@misc{lu2024languagecountslearnunlearn,\\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \\n      author={Taiming Lu and Philipp Koehn},\\n      year={2024},\\n      eprint={2406.13748},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2406.13748}, \\n}\\n\\n"},
  {"name":"lambada-pt","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/TucanoBR/lambada-pt","creator_name":"Tucano","creator_url":"https://huggingface.co/TucanoBR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLAMBADA-PT\\n\\t\\n\\n\\nRepository: TucanoBR/lambada-pt\\nPaper: Radford et al. Language Models are Unsupervised Multitask Learners\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a translated version (Portuguese) of the LAMBADA test split as pre-processed by OpenAI.\\nLAMBADA is used to evaluate the capabilities of computational models for text understanding by means of a word prediction task. LAMBADA is a collection of narrative texts sharing the characteristic that human subjects are able to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TucanoBR/lambada-pt."},
  {"name":"Descriptors_STJ","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MartimZanatti/Descriptors_STJ","creator_name":"Martim Zanatti dos Santos Gomes da Silva","creator_url":"https://huggingface.co/MartimZanatti","description":"\\nWork developed as part of [IRIS] (https://www.inesc-id.pt/projects/PR07005/)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExtreme Multi-Label Classification of Descriptors\\n\\t\\n\\nThe goal of this dataset is to train an Extreme Multi-Label classifier that, given a judgment from the Supreme Court of Justice of Portugal (STJ), can associate relevant descriptors to the judgment.\\nDataset Contents:\\n\\nJudgment ID: Unique identifier for each judgment.\\nSTJ Section: The section of the STJ to which the judgment belongs.\\nJudgment Text: Full‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MartimZanatti/Descriptors_STJ."},
  {"name":"Emakhuwa-Portuguese-News-MT","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LIACC/Emakhuwa-Portuguese-News-MT","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNews Parallel Dataset for Emakhuwa of Mozambique\\n\\t\\n\\n\\n\\nThis repository contains releases of parallel data for machine translation in Mozambican languages. \\nCurrently, it supports one language pair, Portuguese-Emakhuwa, Emakhuwa being the widely spoken language in Mozambique.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\nFunded by: This dataset was created with support from Lacuna Fund, the world‚Äôs first collaborative effort to provide data scientists‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LIACC/Emakhuwa-Portuguese-News-MT."},
  {"name":"Emakhuwa-FLORES","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/LIACC/Emakhuwa-FLORES","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\n\\nFLORES+ dev and devtest set in Emakhuwa\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\n\\nCC-BY-SA-4.0\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAttribution\\n\\t\\n\\n\\n\\n@inproceedings{ali-etal-2024-expanding,\\n    title = \\\"Expanding {FLORES}+ Benchmark for More Low-Resource Settings: {P}ortuguese-Emakhuwa Machine Translation Evaluation\\\",\\n    author = \\\"Ali, Felermino Dario Mario  and\\n      Lopes Cardoso, Henrique  and\\n      Sousa-Silva, Rui\\\",\\n    editor = \\\"Haddow, Barry  and\\n      Kocmi, Tom  and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LIACC/Emakhuwa-FLORES."},
  {"name":"fact-check-bureau","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau","creator_name":"Younes","creator_url":"https://huggingface.co/NaughtyConstrictor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFact-Check Retrieval Dataset\\n\\t\\n\\nThis dataset is designed to support the development and evaluation of fact-check retrieval pipelines. It is structured to work with FactCheckBureau, a tool for designing and evaluating fact-check retrieval pipelines. The dataset comprises a list of claims, fact-check articles, and precomputed embeddings for English and French fact-checks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset consists of the following files and directories:\\n\\narticles.csv:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau."},
  {"name":"Emakhuwa-News-Topic-Classification","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LIACC/Emakhuwa-News-Topic-Classification","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","description":"BibTeX:\\nThe dataset paper was published in EMNLP 2024.\\nPlease cite as:\\n@inproceedings{ali-etal-2024-building,\\n    title = \\\"Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks\\\",\\n    author = \\\"Ali, Felermino D. M. A.  and\\n      Lopes Cardoso, Henrique  and\\n      Sousa-Silva, Rui\\\",\\n    editor = \\\"Al-Onaizan, Yaser  and\\n      Bansal, Mohit  and\\n      Chen, Yun-Nung\\\",\\n    booktitle = \\\"Proceedings of the 2024 Conference on Empirical Methods in Natural Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LIACC/Emakhuwa-News-Topic-Classification."},
  {"name":"Emakhuwa-loanwords-detection","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/LIACC/Emakhuwa-loanwords-detection","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDetecting Loanwords in Emakhuwa\\n\\t\\n\\nPaper: Detecting Loanwords in Emakhuwa: An Extremely Low-Resource {B}antu Language Exhibiting Significant Borrowing from Portuguese\\n\\n@inproceedings{ali-etal-2024-detecting,\\n    title = \\\"Detecting Loanwords in Emakhuwa: An Extremely Low-Resource {B}antu Language Exhibiting Significant Borrowing from {P}ortuguese\\\",\\n    author = \\\"Ali, Felermino Dario Mario  and\\n      Lopes Cardoso, Henrique  and\\n      Sousa-Silva, Rui\\\",\\n    booktitle = \\\"Proceedings‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LIACC/Emakhuwa-loanwords-detection."},
  {"name":"medical-translation-test-set","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ai-amplified/medical-translation-test-set","creator_name":"admin","creator_url":"https://huggingface.co/ai-amplified","description":"ai-amplified/medical-translation-test-set dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"zenless_zone_zero_interknots_v1.0","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZZZ Interknots\\n\\t\\n\\nThis datasets contains extracted Interknot posts and comments (Áª≥ÁΩëÁöÑÂçöÂÆ¢‰∏éËØÑËÆ∫) in multi-language.\\nUp to game version: 1.0\\n\\nInterknot posts and comments examples\\n\\n{\\n  \\\"id\\\": \\\"1021\\\",\\n  \\\"poster\\\": \\\"Sorrowful Intern\\\",\\n  \\\"title\\\": \\\"[Commission] Missing Bangboo merchants\\\",\\n  \\\"text\\\": \\\"Hello, pros... Some of the senior Bangboo of our merchant association have gone missing! We urgently need an expert to help find them!!\\\\nLet me explain, I recently joined a very prestigious‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0."},
  {"name":"XL-HeadTags","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/faisaltareque/XL-HeadTags","creator_name":"Faisal Tareque Shohan","creator_url":"https://huggingface.co/faisaltareque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for XL-HeadTags Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Source\\n\\t\\n\\nWe have used M3LS and XL-Sum as source for this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n We provide XL-HeadTags, a large-scale news headline and tags generation dataset. The dataset consists of 20 languages across six diverse language families. It contains 415K news headline-article pairs with auxiliary information such as image captions, topic words (read more).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/faisaltareque/XL-HeadTags."},
  {"name":"treino","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/colab-tjap/treino","creator_name":"Trainee TJAP","creator_url":"https://huggingface.co/colab-tjap","description":"Primeiro teste\\n"},
  {"name":"olist_customers_review","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/verissimomanoel/olist_customers_review","creator_name":"Manoel Ver√≠ssimo dos Santos Neto","creator_url":"https://huggingface.co/verissimomanoel","description":"verissimomanoel/olist_customers_review dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"text-to-icpc2","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/diogocarapito/text-to-icpc2","creator_name":"Diogo Carapito","creator_url":"https://huggingface.co/diogocarapito","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nThis dataset to train a text classification model for  ICPC2 codes in portuguese\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): pt\\nLicense: apache-2.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: https://github.com/diogocarapito/text-to-icpc2\\nPaper [optional]:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/diogocarapito/text-to-icpc2."},
  {"name":"mmarco-hard-negatives-reranker-score","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score","creator_name":"Yuichi Tateno","creator_url":"https://huggingface.co/hotchpotch","description":"\\nhotchpotch/mmarco-hard-negatives-reranker-score\\n\\nThis repository contains data from mMARCO scored using the reranker BAAI/bge-reranker-v2-m3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Covered\\n\\t\\n\\ntarget_languages = [\\n    \\\"english\\\",\\n    \\\"chinese\\\", \\n    \\\"french\\\",\\n    \\\"german\\\",\\n    \\\"indonesian\\\",\\n    \\\"italian\\\",\\n    \\\"portuguese\\\",\\n    \\\"russian\\\",\\n    \\\"spanish\\\",\\n    \\\"arabic\\\",\\n    \\\"dutch\\\",\\n    \\\"hindi\\\",\\n    \\\"japanese\\\",\\n    \\\"vietnamese\\\"\\n]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHard Negative Data\\n\\t\\n\\nThe hard negative data is derived from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score."},
  {"name":"Multi-Opthalingua","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AAAIBenchmark/Multi-Opthalingua","creator_name":"AAAIBenchmark","creator_url":"https://huggingface.co/AAAIBenchmark","description":"AAAIBenchmark/Multi-Opthalingua dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"nothing_is_real","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Monteiroo/nothing_is_real","creator_name":"Igor Gabriel Monteiro","creator_url":"https://huggingface.co/Monteiroo","description":"Monteiroo/nothing_is_real dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"mls-annotated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PHBJT/mls-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotations of non English MLS\\n\\t\\n\\nThis dataset consists in annotations of a the Non English subset of the Multilingual LibriSpeech (MLS) dataset. \\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/mls-annotated."},
  {"name":"PangeaBench-xm100","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM100\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n"},
  {"name":"ApolloMoEDataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüåà Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset."},
  {"name":"ApolloMoEBench","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüåà Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench."},
  {"name":"portufake","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/unfake/portufake","creator_name":"Unfake","creator_url":"https://huggingface.co/unfake","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Portufake\\n\\t\\n\\n\\n\\nThis dataset contains spectrograms of audio deepfakes and real speaker recordings in Portuguese, originating from Fake Voices Dataset \\nand CETUC Corpus, respectively.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nThe dataset contains 183,878 512px x 256px colored constant-Q transform (CQT) spectrograms created from audios categorized in two labels: \\\"real\\\" or \\\"fake\\\". \\nThey correspond, respectively, to Brazilian Portuguese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unfake/portufake."},
  {"name":"PangeaBench-xgqa","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/neulab/PangeaBench-xgqa","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\txGQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a clone of the few_shot-test split of the xGQA dataset\\n\\t\\n\\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{pfeiffer-etal-2021-xGQA,\\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\\\'{c}} and Iryna Gurevych}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-xgqa."},
  {"name":"MegaWika","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/conceptofmind/MegaWika","creator_name":"Enrico Shippole","creator_url":"https://huggingface.co/conceptofmind","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. Furthermore, nearly 130 million English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/conceptofmind/MegaWika."},
  {"name":"WiNNL","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/peemil/WiNNL","creator_name":"Emile Peetermans","creator_url":"https://huggingface.co/peemil","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWiNNL\\n\\t\\n\\nWikiNews Named entity recognition and Linking (WiNNL) is a multilingual news NER & NEL benchmark based on Wikinews articles.\\nThe dataset was created by automatically scraping and tagging news articles, and manually corrected by native speakers to ensure accuracy.\\nYou can find more information in the paper:\\nhttps://aclanthology.org/2024.dlnld-1.3.pdf\\nThe dataset includes the following NER classes in IOB format (labels):\\n\\nPER (Person): person names \\nLOC (Location):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/peemil/WiNNL."},
  {"name":"panlex","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex."},
  {"name":"Ceu","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/nerfadox/Ceu","creator_name":"Fabr√≠cio Mendes","creator_url":"https://huggingface.co/nerfadox","description":"nerfadox/Ceu dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"stata","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/adenhaus/stata","creator_name":"Aden Haussmann","creator_url":"https://huggingface.co/adenhaus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBackground\\n\\t\\n\\nThis dataset contains human evaluations of whether outputs on the TaTA dataset are a) understandable and b) attributable to the source tables. See TaTA: A Multilingual Table-to-Text Dataset for African Languages for more details. \\nIt can be used to train a learned metric, called StATA, to evaluate model performance on the TaTA dataset.\\nThe original can be found here.\\n"},
  {"name":"pt_to_an","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/matjs/pt_to_an","creator_name":"Matheus J. G. Silva","creator_url":"https://huggingface.co/matjs","description":"A collection of translations from Portuguese do Angrarosskesh, my fictional language.\\n"},
  {"name":"my_cool_dataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ricardo-lsantos/my_cool_dataset","creator_name":"Ricardo Lisboa Santos","creator_url":"https://huggingface.co/ricardo-lsantos","description":"ricardo-lsantos/my_cool_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"ChatML-aya_dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = [\\n        {\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": columns[\\\"inputs\\\"].strip(),\\n        },\\n        {‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset."},
  {"name":"Agricultura_regenerativa_Portugues_Portuguese","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Solshine/Agricultura_regenerativa_Portugues_Portuguese","creator_name":"Caleb DeLeeuw","creator_url":"https://huggingface.co/Solshine","description":"Dados semissint√©ticos gerados por meio da biblioteca RAG contendo conhecimento de agricultura regenerativa de especialistas do dom√≠nio, conectados √† API ChatGPT4.\\nUm conjunto de dados que detalha solu√ß√µes agr√≠colas regenerativas para problemas agr√≠colas comuns, em portugu√™s, com consci√™ncia cultural em rela√ß√£o √† Floresta Amaz√¥nica e √†s comunidades agr√≠colas brasileiras marginalizadas.\\nSemi-synthetic data generated via RAG library containing regenerative farming knowledge from domain experts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Solshine/Agricultura_regenerativa_Portugues_Portuguese."},
  {"name":"MultiQ","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiQ\\n\\t\\n\\nThis is the dataset corresponding to the paper \\\"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\\\". \\nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \\ntranslated into 137 typologically diverse languages. \\n\\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ."},
  {"name":"medicine-medical_meadow_wikidoc_pt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rhaymison/medicine-medical_meadow_wikidoc_pt","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","description":"rhaymison/medicine-medical_meadow_wikidoc_pt dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"mental-health-pt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rhaymison/mental-health-pt","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","description":"rhaymison/mental-health-pt dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"medicine-medical-eval-pt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rhaymison/medicine-medical-eval-pt","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","description":"rhaymison/medicine-medical-eval-pt dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"SQuAD-pt_BR-V1.1","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/vsvasconcelos/SQuAD-pt_BR-V1.1","creator_name":"Vagner Sanches Vasconcelos","creator_url":"https://huggingface.co/vsvasconcelos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nO conjunto de dados \\\"Stanford Question Answering Dataset\\\" (SQuAD), para tarefa de perguntas e respostas extrativas, foi desenvolvido em 2016. Ele utiliza perguntas geradas \\na partir de 536 artigos da Wikipedia com mais de 100.000 linhas de dados. √â constru√≠do na forma de uma pergunta e um contexto dos artigos da Wikipedia contendo a resposta \\n√† pergunta.\\nOriginalmente este dataset foi constru√≠do no idioma ingl√™s, contudo, o grupo Deep Learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vsvasconcelos/SQuAD-pt_BR-V1.1."},
  {"name":"bhojpuri","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri."},
  {"name":"panlex-meanings","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings."},
  {"name":"NTREX","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX."},
  {"name":"caramelo-emotions-v2","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Adilmar/caramelo-emotions-v2","creator_name":"Adilmar Coelho Dantas","creator_url":"https://huggingface.co/Adilmar","description":"Adilmar/caramelo-emotions-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"eurlex-multilingual","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/eurlex-multilingual","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"eurlex-multilingual\\\"\\n\\t\\n\\nMore Information needed\\n"},
  {"name":"biblenlp-corpus-mmteb","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb."},
  {"name":"nurc-sp_pseudo_labelled","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/RodrigoLimaRFL/nurc-sp_pseudo_labelled","creator_name":"Rodrigo de Freitas Lima","creator_url":"https://huggingface.co/RodrigoLimaRFL","description":"RodrigoLimaRFL/nurc-sp_pseudo_labelled dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"orca-math-portuguese-64k","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rhaymison/orca-math-portuguese-64k","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","description":"translated for:\\n\\n\\nRepository: microsoft/orca-math-word-problems-200k\\nPaper: Orca-Math: Unlocking the potential of\\nSLMs in Grade School Math\\n\\n"},
  {"name":"Date_jese","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Raivatv24/Date_jese","creator_name":"Fernando Roldao","creator_url":"https://huggingface.co/Raivatv24","description":"Raivatv24/Date_jese dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Buscape","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/liaad/Buscape","creator_name":"LIAAD, INESCTEC","creator_url":"https://huggingface.co/liaad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuscap√© Sample annotated for Semantic Role Labelling\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPropbank-Br Corpora Buscap√© Sample\\n\\t\\n\\nThe Propbank-Br is a project that aims to annotate corpora with semantic role labels for the purpose of creating training datasets for automated semantic role classifiers. The annotation scheme is quite similar to that of the English Propbank (Palmer et al., 2005), with language-specific differences taken into account. The set of semantic roles was designed to facilitate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/liaad/Buscape."},
  {"name":"xsimplusplus","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n"},
  {"name":"biblenlp-corpus-mmteb","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb."},
  {"name":"sib200","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200."},
  {"name":"sigarra","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/neuralshift/sigarra","creator_name":"NeuralShift","creator_url":"https://huggingface.co/neuralshift","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"sigarra\\\"\\n\\t\\n\\nThe \\\"sigarra\\\" dataset available on Hugging Face is not a property of NeuralShift. We are uploading it to the platform to increase its accessibility and foster further research.\\nHere's some additional information about the original SIGARRA News Corpus:\\nSource: University of Porto (UP) SIGARRA information system\\nContent: A collection of academic news articles with manual annotations for named entity recognition.\\nSize: Approximately 4.22 MB\\nFormat:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neuralshift/sigarra."},
  {"name":"nurc-sp_pseudo_labelled-dev","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/RodrigoLimaRFL/nurc-sp_pseudo_labelled-dev","creator_name":"Rodrigo de Freitas Lima","creator_url":"https://huggingface.co/RodrigoLimaRFL","description":"RodrigoLimaRFL/nurc-sp_pseudo_labelled-dev dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"NTREX","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX."},
  {"name":"ParaNames","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames."},
  {"name":"europa","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/NCube/europa","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EUROPA\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\\nKey Features:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa."},
  {"name":"FairytaleQA-translated-ptPT","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/benjleite/FairytaleQA-translated-ptPT","creator_name":"Bernardo Leite","creator_url":"https://huggingface.co/benjleite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for FairytaleQA-translated-ptPT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis repository contains the European Portuguese (pt-PT) machine-translated version of the original English FairytaleQA dataset (https://huggingface.co/datasets/WorkInTheDark/FairytaleQA). FairytaleQA is an open-source dataset designed to enhance comprehension of narratives, aimed at students from kindergarten to eighth grade. The dataset is meticulously annotated by education experts following an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjleite/FairytaleQA-translated-ptPT."},
  {"name":"M3GIA","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Songweii/M3GIA","creator_name":"Wei Song","creator_url":"https://huggingface.co/Songweii","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tM3GIA: A Cognition Inspired Multilingual and Multimodal General Intelligence Ability\\n\\t\\n\\n[üåê Homepage] | ü§ó Dataset | ü§ó Paper | üìñ arXiv | üíª GitHub\\nThe evaluation code can be found in üíª GitHub.\\n[Abstract]\\nAs recent multi-modality large language models (MLLMs) have shown formidable proficiency on various complex tasks, there has been increasing attention on debating whether these models could eventually mirror human intelligence. However, existing benchmarks mainly focus on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Songweii/M3GIA."},
  {"name":"bitext_sib200_miners","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fleurs_clean","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean."},
  {"name":"learnlangai-general","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/falleco/learnlangai-general","creator_name":"Israel Crisanto","creator_url":"https://huggingface.co/falleco","description":"falleco/learnlangai-general dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"sql-create-context-pt","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/emdemor/sql-create-context-pt","creator_name":"Eduardo Morais","creator_url":"https://huggingface.co/emdemor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEste dataset  √© uma vers√£o traduzida para o portugu√™s do dataset b-mc2/sql-create-context,\\nque foi constru√≠do a partir dos datasets WikiSQL e Spider. Ele cont√©m exemplos de perguntas\\nem portugu√™s, instru√ß√µes SQL CREATE TABLE e consultas SQL que respondem √†s perguntas\\nutilizando a instru√ß√£o CREATE TABLE como contexto.\\nO principal objetivo deste dataset √© ajudar modelos de linguagem natural  em portugu√™s a gerar consultas\\nSQL precisas e contextualizadas, prevenindo a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/emdemor/sql-create-context-pt."},
  {"name":"social_i_qa_pt","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/fabiogr/social_i_qa_pt","creator_name":"Fabio Grassiotto","creator_url":"https://huggingface.co/fabiogr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSocialIQa dataset v1.4 (PT)\\n\\t\\n\\nThis is translation to the portuguese language of the dataset allenai/social_i_qa.Translations were done using three independent models:  \\n\\nHelsinki-NLP/opus-mt-tc-big-en-pt\\nunicamp-dl/translation-en-pt-t5  \\nfacebook/nllb-200-distilled-1.3B\\n\\nTranslations were evaluated using the evaluation metric GEMBA - GPT Estimation Metric Based Assessment\\n(from the article Large Language Models Are State-of-the-Art Evaluators of Translation Quality) using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fabiogr/social_i_qa_pt."},
  {"name":"xP3x-Kongo","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo."},
  {"name":"testedados","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/MatheusFr/testedados","creator_name":"Matheus Francisco","creator_url":"https://huggingface.co/MatheusFr","description":"MatheusFr/testedados dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"medicine-evaluation-pt-tokenized-2048","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/mmoreirast/medicine-evaluation-pt-tokenized-2048","creator_name":"Mariana Moreira","creator_url":"https://huggingface.co/mmoreirast","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEvaluation Dataset for Doctor Llama\\n\\t\\n\\nThis repository contains a tokenized version of medicine-evaluation-pt.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAuthor\\n\\t\\n\\nMariana Moreira dos Santos (LinkedIn)\\n"},
  {"name":"librivox-tracks","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\\nChanges:\\n\\nUsed archive.org metadata API to annotate rows with \\\"duration\\\" column\\n\\n"},
  {"name":"testeliminha","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Ciscomuna/testeliminha","creator_name":"Jo√£o Gabriel da Silva dos Santos","creator_url":"https://huggingface.co/Ciscomuna","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ciscomuna/testeliminha."},
  {"name":"muri-it-language-split","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split."},
  {"name":"wiki-talks","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lflage/wiki-talks","creator_name":"Lucas Fonseca Lage","creator_url":"https://huggingface.co/lflage","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWiki-Talks\\n\\t\\n\\nThe Wiki-Talks dataset is a collection of conversational threads extracted from the talk pages on Wikipedia.\\nThis dataset captures collaborative dialogue, discussion patterns, and consensus-building among Wikipedia contributors.\\nIt is useful for NLP research focused on dialogue, sentiment analysis, and community dynamics.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDetails\\n\\t\\n\\nCurrently due to PyArrow incompatibility to the long recursive structures in the dataset there is an intrinsic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lflage/wiki-talks."},
  {"name":"qa-portuguese-small","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Jpzinn654/qa-portuguese-small","creator_name":"Juan Pablo","creator_url":"https://huggingface.co/Jpzinn654","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQA-PORTUGUESE-SMALL\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe qa-portuguese-small dataset is a collection of 500,000 question-answer pairs in Portuguese designed for Question Answering (QA) tasks. The dataset includes questions based on a wide variety of domains, such as news, general knowledge, and everyday facts, and provides corresponding answers in natural language.\\nThe dataset is intended for training and evaluating machine learning models that can answer questions in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jpzinn654/qa-portuguese-small."},
  {"name":"tabela-taco","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/julianamarques/tabela-taco","creator_name":"Juliana Marques","creator_url":"https://huggingface.co/julianamarques","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset: TACO - Tabela Brasileira de Composi√ß√£o de Alimentos\\n\\t\\n\\nThe TACO Table is the reference nutritional table for foods consumed in Brazil. The information contained in this dataset was taken from the excel file made available by NEPA - Center for Studies and Research in Food at UNICAMP, through the link: \\nhttps://nepa.unicamp.br/publicacoes/tabela-taco-excel/\\n"},
  {"name":"FactNews","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/franciellevargas/FactNews","creator_name":"Francielle Vargas","creator_url":"https://huggingface.co/franciellevargas","description":"\\n\\t\\n\\t\\t\\n\\t\\tEvaluation Benchmark for Sentence-Level Factuality Prediciton in Portuguese\\n\\t\\n\\nThe FactNews consits of the first large sentence-level annotated corpus for factuality prediciton in Portuguese. \\nIt is composed of 6,191 sentences annotated according to factuality and media bias definitions proposed by AllSides. We use FactNews to assess the overall reliability of news sources by formulating \\ntwo text classification problems for predicting sentence-level factuality of news reporting and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/franciellevargas/FactNews."},
  {"name":"GammaCorpus-Polylingo-50k","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","description":"\\n\\t\\n\\t\\t\\n\\t\\tGammaCorpus Polylingo 50k\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is it?\\n\\t\\n\\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\\n\\nInput: A user prompt or question.\\nOutput: A response generated by an AI assistant.\\nLanguage: The language used in the interaction.\\n\\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k."},
  {"name":"parallel_corpus_game_2024","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bot-yaya/parallel_corpus_game_2024","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","description":"https://github.com/mnbvc-parallel-corpus-team/parallel_corpus_mnbvc\\nMNBVCÂπ≥Ë°åËØ≠ÊñôÂ∞èÁªÑÔºöÊ∏∏ÊàèËØ≠Êñô\\n‰∏çÂÆöÊúüÊõ¥Êñ∞ÔºåÁõÆÂâçÂ∑≤Êî∂ÂΩïÁöÑÊ∏∏ÊàèËØ≠ÊñôÊñá‰ª∂ÔºåÂÖ±29‰ªΩÔºö\\n\\nÂçöÂæ∑‰πãÈó®3\\nËµõÂçöÊúãÂÖã2077\\nÈªëÊöó‰πãÈ≠Ç3\\nÂ∫ïÁâπÂæãÔºöÂåñË∫´‰∏∫‰∫∫\\nÈ••Ëçí\\nËâæÂ∞îÁôªÊ≥ïÁéØ\\nÂéüÁ•û\\nÈªëÂ∏ùÊñØ\\nÈúçÊ†ºÊ≤ÉÂÖπ‰πãÈÅó\\nIb\\nÂ¶ÇÈæô8\\nÂ¶ÇÈæô7Â§ñ‰º†\\nËçíÈáéÂ§ßÈïñÂÆ¢2\\nÂè™ÁãºÔºöÂΩ±ÈÄù‰∫åÂ∫¶\\nÊñáÊòé6\\nÊùÄÊàÆÂ∞ñÂ°î\\nÂ¥©ÂùèÊòüÁ©πÈìÅÈÅì\\nÁæ§Êòü\\nÊ≥∞ÊãâÁëû‰∫ö\\nÂ∑´Â∏à3\\nÈ≠îÂ•≥‰πãÊ≥â3\\nÈ≠îÂ•≥‰πãÊ≥âR\\nÈ∏£ÊΩÆ\\nÂ¶ÇÈæô3\\nÂ¶ÇÈæô4\\nÂ¶ÇÈæô5\\nÂ¶ÇÈæô6\\nÂ¶ÇÈæôÊûÅ2\\nÂ¶ÇÈæô7\\n\\n"},
  {"name":"cml-tts-filtered-annotated","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Filtred and annotated CML TTS\\n\\t\\n\\nThis dataset is an annotated and filtred version of a CML-TTS [1]. \\nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated."},
  {"name":"X-ALMA-Preference","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\\nsource: the source sentence.\\nchosen: the preferred translation.\\nreject: the dis-preferred translation.\\ndirections: the translation direction.\\n@misc{xu2024xalmaplugplay,\\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \\n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\\n      year={2024},\\n      eprint={2410.03115}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference."},
  {"name":"rest-products","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/victorvarela/rest-products","creator_name":"Victor Varela","creator_url":"https://huggingface.co/victorvarela","description":"victorvarela/rest-products dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"CPTransExercise","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/edmond5995/CPTransExercise","creator_name":"Hoi","creator_url":"https://huggingface.co/edmond5995","description":"Chinese-Portuguese Translation Exercise Corpus (CPTEC)\\nThis dataset aims to provide translators to practice Chinese-Portuguese translation with different levels from basic to proficient.\\nThis is a sample dataset from CPTEC, please contact us for more information.\\nlmhoi@mpu.edu.mo\\n"},
  {"name":"alagoasideb","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/giseldo/alagoasideb","creator_name":"Giseldo Neo","creator_url":"https://huggingface.co/giseldo","description":"A pr√≥xima vers√£o desse modelo ter√° um pequeno tratamento dos dados, em rela√ß√£o ao tipo das colunas.\\n"},
  {"name":"BRIGHTER-emotion-intensities","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\tBRIGHTER Emotion Intensities Dataset\\n\\t\\n\\nThis dataset contains the emotion intensities data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe BRIGHTER Emotion Intensities dataset is a comprehensive multi-language emotion intensity dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple languages, providing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities."},
  {"name":"semeval-2025-task11-track-a","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track A Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track A, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 26 standard ISO codes\\nTotal examples: 115159\\nSplits: train, dev, test\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguage Configurations\\n\\t\\n\\nEach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a."},
  {"name":"semeval-2025-task11-track-c","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track C Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track C, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 30 standard ISO codes\\nTotal examples: 57254\\nSplits: dev, test (Track C has no train split)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTrack‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c."},
  {"name":"cgu__notas_fiscais","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/fredguth/cgu__notas_fiscais","creator_name":"Fred Guth","creator_url":"https://huggingface.co/fredguth","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card: cgu_notas_fiscais\\n\\t\\n\\nData from electronic invoices for federal government purchases made available by\\nComptroller General of the Union (Controladoria-Geral da Uni√£o), which is a\\nBrazilian federal government agency responsible for oversight and transparency.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\nCurated by: Fred Guth (@fredguth)\\nFunded by: World Bank\\nLanguage(s) (NLP): pt-br\\nLicense: CC-BY 4.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\nThe source of this datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fredguth/cgu__notas_fiscais."},
  {"name":"juciData","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/ResidenciaTJAP-IA/juciData","creator_name":"Equipe de IA da Resid√™ncia Tecnol√≥gica","creator_url":"https://huggingface.co/ResidenciaTJAP-IA","description":"Primeiro teste\\n"},
  {"name":"Emakhuwa-Portuguese-OCR-post-correction","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LIACC/Emakhuwa-Portuguese-OCR-post-correction","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","description":"BibTeX:\\nThe dataset paper was published in EMNLP 2024.\\nPlease cite as:\\n@inproceedings{ali-etal-2024-building,\\n    title = \\\"Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks\\\",\\n    author = \\\"Ali, Felermino D. M. A.  and\\n      Lopes Cardoso, Henrique  and\\n      Sousa-Silva, Rui\\\",\\n    editor = \\\"Al-Onaizan, Yaser  and\\n      Bansal, Mohit  and\\n      Chen, Yun-Nung\\\",\\n    booktitle = \\\"Proceedings of the 2024 Conference on Empirical Methods in Natural Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LIACC/Emakhuwa-Portuguese-OCR-post-correction."},
  {"name":"Emakhuwa-Monolingual","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LIACC/Emakhuwa-Monolingual","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","description":"BibTeX:\\nThe dataset paper was published in EMNLP 2024.\\nPlease cite as:\\n@inproceedings{ali-etal-2024-building,\\n    title = \\\"Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks\\\",\\n    author = \\\"Ali, Felermino D. M. A.  and\\n      Lopes Cardoso, Henrique  and\\n      Sousa-Silva, Rui\\\",\\n    editor = \\\"Al-Onaizan, Yaser  and\\n      Bansal, Mohit  and\\n      Chen, Yun-Nung\\\",\\n    booktitle = \\\"Proceedings of the 2024 Conference on Empirical Methods in Natural Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LIACC/Emakhuwa-Monolingual."},
  {"name":"mc-translation","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/efederici/mc-translation","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","description":"This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy This Dataset?\\n\\t\\n\\nTranslation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specialized‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation."},
  {"name":"TCCHandInformation","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/GuilhermeGomes/TCCHandInformation","creator_name":"Guilherme Gomes Luccas Rodrigues","creator_url":"https://huggingface.co/GuilhermeGomes","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nDataset created with MediaPipe with the aim of doing fine tuning consisting of:\\n\\nuser prompt containing the information\\nsystem prompt explaining what will be received\\nexpected response\\n\\n"},
  {"name":"enunciados_pge_rj","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/celsowm/enunciados_pge_rj","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","description":"celsowm/enunciados_pge_rj dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"LEI40","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/abelrh/LEI40","creator_name":"Abel Melo Borges","creator_url":"https://huggingface.co/abelrh","description":"abelrh/LEI40 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"LegiSubject-Br-Summaries","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ronunes/LegiSubject-Br-Summaries","creator_name":"Rafael Oleques Nunes","creator_url":"https://huggingface.co/ronunes","description":"ronunes/LegiSubject-Br-Summaries dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"xtreme-up-semantic-parsing","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrixnli\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSee XTREME-UP GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 20 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import load_dataset\\ndata = load_dataset('Davlan/xtreme-up-semantic-parsing', 'yor') \\n# Please, specify the language code\\n# A data point example is below:\\n{\\n\\\"id\\\": \\\"3231323330393336\\\",\\n\\\"split\\\": \\\"test\\\",\\n\\\"intent\\\": \\\"IN:GET_REMINDER\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing."},
  {"name":"figuras_de_linguagem","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/marioluciofjr/figuras_de_linguagem","creator_name":"M√°rio L√∫cio","creator_url":"https://huggingface.co/marioluciofjr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescri√ß√£o\\n\\t\\n\\nDataset com 100 frases diferentes sobre processo seletivo de emprego. As frases correspondem √†s figuras de linguagem: analogia, met√°fora, sarcasmo e ironia.\\n"},
  {"name":"cml-tts-filtered","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Filtred and CML-TTS\\n\\t\\n\\nThis dataset is a filtred version of a CML-TTS [1]. \\nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered."},
  {"name":"reviews_linkedin","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/marioluciofjr/reviews_linkedin","creator_name":"M√°rio L√∫cio","creator_url":"https://huggingface.co/marioluciofjr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescri√ß√£o\\n\\t\\n\\nDataset que traz os coment√°rios dos usus√°rios do Google Play sobre o app do LinkedIn\\n"},
  {"name":"GUI-Ban","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/wendellast/GUI-Ban","creator_name":"wendel alves","creator_url":"https://huggingface.co/wendellast","description":"wendellast/GUI-Ban dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"testdata","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/leoloko/testdata","creator_name":"Leonardo","creator_url":"https://huggingface.co/leoloko","description":"leoloko/testdata dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"mmmlu_lite","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMLU-Lite\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is about‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite."},
  {"name":"portugese_ner_dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HUMADEX/portugese_ner_dataset","creator_name":"HUMADEX Research Group","creator_url":"https://huggingface.co/HUMADEX","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortugese NER dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgement\\n\\t\\n\\nThis dataset had been created as part of joint research of HUMADEX research group (https://www.linkedin.com/company/101563689/) and has received funding by the European Union Horizon Europe Research and Innovation Program project SMILE (grant number 101080923) and Marie Sk≈Çodowska-Curie Actions (MSCA) Doctoral Networks, project BosomShield ((rant number 101073222). Responsibility for the information and views expressed herein‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HUMADEX/portugese_ner_dataset."},
  {"name":"Multilingal-sakalt-data","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"„Éû„É´„ÉÅ„É™„É≥„Ç¨„É´„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇmit„É©„Ç§„Çª„É≥„Çπ„Åß„Åô„ÄÇ\\n"},
  {"name":"bidCorpus","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/tcepi/bidCorpus","creator_name":"Tribunal de Contas do Estado do Piau√≠","creator_url":"https://huggingface.co/tcepi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"BidCorpus\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to load the datasets\\n\\t\\n\\nTo load one of the datasets, simply provide the tcepi/bidCorpus argument as the first parameter, followed by the name of the desired dataset, such as bid_corpus_raw.\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"tcepi/bidCorpus\\\", \\\"bidCorpus_raw\\\")\\n\\nThe csv format version of the datasets is available in the \\\\bidCorpus_csvs folder.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe BidCorpus dataset consists of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tcepi/bidCorpus."},
  {"name":"AyaVisionBench","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/AyaVisionBench","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Aya Vision Benchmark\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \\nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/AyaVisionBench."},
  {"name":"oasst1","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1."},
  {"name":"Everything_Instruct_Multilingual","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEverything Instruct (Multilingual Edition)\\n\\t\\n\\nEverything you need... all in one place üíò\\n\\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\\nNote2: This version of the dataset supports the following languages:\\n\\nEnglish\\nRussian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual."},
  {"name":"oasst2","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen Assistant Conversations Dataset Release 2 (OASST2)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \\nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \\nAll messages have a role property: this can either be \\\"assistant\\\" or \\\"prompter\\\". The roles in \\nconversation threads from prompt to leaf node strictly alternate between \\\"prompter\\\" and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2."},
  {"name":"Global-MMLU","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU üåç is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) üóΩ or Culturally Agnostic (CA) ‚öñÔ∏è. These annotations were collected as part of an open‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU."},
  {"name":"reasoning-multilingual-R1-Llama-70B-train","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\tlightblue/reasoning-multilingual-R1-Llama-70B-train\\n\\t\\n\\nThis is a multilingual reasoning dataset covering more than 30 languages.\\nThis dataset was made by:\\n\\nSampling prompts from English datasets and translating them to various languages\\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\\n\\nThis dataset was then used to train a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train."},
  {"name":"wmt24pp","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tWMT24++\\n\\t\\n\\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\\nthe publication\\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\\nIf you are interested in the images of the source URLs for each document, please see here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema\\n\\t\\n\\nEach language pair is stored in its own jsonl file.\\nEach row is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp."},
  {"name":"thinking-multilingual-30-23-small-690","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \\nOr use the \\\"big\\\" version: big 10k rows version\\n"},
  {"name":"spider-test-portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Boakpe/spider-test-portuguese","creator_name":"Breno","creator_url":"https://huggingface.co/Boakpe","description":"\\n\\t\\n\\t\\t\\n\\t\\tSpider Dataset - Vers√£o em Portugu√™s\\n\\t\\n\\nEste reposit√≥rio cont√©m a tradu√ß√£o para portugu√™s da parti√ß√£o de teste do dataset Spider, um benchmark para a tarefa de Text-to-SQL.\\n\\n\\t\\n\\t\\t\\n\\t\\tSobre esta tradu√ß√£o\\n\\t\\n\\nA tradu√ß√£o da parti√ß√£o \\\"test\\\" do Spider (contendo 2.147 inst√¢ncias) foi realizada seguindo um processo rigoroso:\\n\\nTradu√ß√£o inicial: Utilizando a API do GPT-4o mini da OpenAI\\nRevis√£o manual: Todas as 2.147 quest√µes foram revisadas e validadas manualmente\\nCrit√©rios de tradu√ß√£o:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Boakpe/spider-test-portuguese."},
  {"name":"spider-test-portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Boakpe/spider-test-portuguese","creator_name":"Breno","creator_url":"https://huggingface.co/Boakpe","description":"\\n\\t\\n\\t\\t\\n\\t\\tSpider Dataset - Vers√£o em Portugu√™s\\n\\t\\n\\nEste reposit√≥rio cont√©m a tradu√ß√£o para portugu√™s da parti√ß√£o de teste do dataset Spider, um benchmark para a tarefa de Text-to-SQL.\\n\\n\\t\\n\\t\\t\\n\\t\\tSobre esta tradu√ß√£o\\n\\t\\n\\nA tradu√ß√£o da parti√ß√£o \\\"test\\\" do Spider (contendo 2.147 inst√¢ncias) foi realizada seguindo um processo rigoroso:\\n\\nTradu√ß√£o inicial: Utilizando a API do GPT-4o mini da OpenAI\\nRevis√£o manual: Todas as 2.147 quest√µes foram revisadas e validadas manualmente\\nCrit√©rios de tradu√ß√£o:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Boakpe/spider-test-portuguese."},
  {"name":"conceptnet5","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/conceptnet5/conceptnet5","creator_name":"conceptnet5","creator_url":"https://huggingface.co/conceptnet5","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Conceptnet5\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nConceptNet is a multilingual knowledge base, representing words and\\nphrases that people use and the common-sense relationships between\\nthem. The knowledge in ConceptNet is collected from a variety of\\nresources, including crowd-sourced resources (such as Wiktionary and\\nOpen Mind Common Sense), games with a purpose (such as Verbosity and\\nnadya.jp), and expert-created resources (such as WordNet and JMDict).\\nYou can browse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/conceptnet5/conceptnet5."},
  {"name":"exams","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mhardalov/exams","creator_name":"Momchil Hardalov","creator_url":"https://huggingface.co/mhardalov","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nEXAMS is a benchmark dataset for multilingual and cross-lingual question answering from high school examinations. It consists of more than 24,000 high-quality high school exam questions in 16 languages, covering 8 language families and 24 school subjects from Natural Sciences and Social Sciences, among others.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mhardalov/exams."},
  {"name":"mfaq","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/clips/mfaq","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"We present the first multilingual FAQ dataset publicly available. We collected around 6M FAQ pairs from the web, in 21 different languages."},
  {"name":"mqa","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages."},
  {"name":"multilingual_librispeech","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/facebook/multilingual_librispeech","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiLingual LibriSpeech\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \\nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/multilingual_librispeech."},
  {"name":"hatecheck-portuguese","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Paul/hatecheck-portuguese","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-portuguese."},
  {"name":"xwinograd","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Muennighoff/xwinograd","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities."},
  {"name":"multilingual-sentiments","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/tyqiangz/multilingual-sentiments","creator_name":"Tay Yong Qiang","creator_url":"https://huggingface.co/tyqiangz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Sentiments Dataset\\n\\t\\n\\nA collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.\\nMost multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments."},
  {"name":"qa-pt","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/ju-resplande/qa-pt","creator_name":"Juliana Resplande","creator_url":"https://huggingface.co/ju-resplande","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for QA-Portuguese\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPortuguese preprocessed split from MQA dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is Portuguese.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ju-resplande/qa-pt."},
  {"name":"legal-mc4","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/legal-mc4","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"Legal-MC4: A Corpus Covering the Legal Part of MC4 for European Languages"},
  {"name":"multiconer_v2","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/MultiCoNER/multiconer_v2","creator_name":"MultiCoNER","creator_url":"https://huggingface.co/MultiCoNER","description":"Complex named entities (NE), like the titles of creative works, are not simple nouns and pose challenges for NER systems (Ashwini and Choi, 2014). They can take the form of any linguistic constituent, like an imperative clause (‚ÄúDial M for Murder‚Äù), and do not look like traditional NEs (Persons, Locations, etc.). This syntactic ambiguity makes it challenging to recognize them based on context. We organized the MultiCoNER task (Malmasi et al., 2022) at SemEval-2022 to address these challenges in 11 languages, receiving a very positive community response with 34 system papers. Results confirmed the challenges of processing complex and long-tail NEs: even the largest pre-trained Transformers did not achieve top performance without external knowledge. The top systems infused transformers with knowledge bases and gazetteers. However, such solutions are brittle against out of knowledge-base entities and noisy scenarios like the presence of spelling mistakes and typos. We propose MultiCoNER II which represents novel challenges through new tasks that emphasize the shortcomings of the current top models.\\n\\nMultiCoNER II features complex NER in these languages:\\n\\n1. English\\n2. Spanish\\n3. Hindi\\n4. Bangla\\n5. Chinese\\n6. Swedish\\n7. Farsi\\n8. French\\n9. Italian\\n10. Portugese\\n11. Ukranian\\n12. German\\n\\nFor more details see https://multiconer.github.io/\\n\\n## References\\n* Sandeep Ashwini and Jinho D. Choi. 2014. Targetable named entity recognition in social media. CoRR, abs/1408.0782.\\n* Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta Kar, Oleg Rokhlenko. 2022. SemEval-2022 Task 11: Multilingual Complex Named Entity Recognition (MultiCoNER)."},
  {"name":"massive_translation_dataset","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Amani27/massive_translation_dataset","creator_name":"Amani N","creator_url":"https://huggingface.co/Amani27","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Massive Dataset for Translation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is derived from AmazonScience/MASSIVE dataset for translation task purpose.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nTranslation\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nEnglish (en_US)\\nGerman (de_DE)\\nHindi (hi_IN)\\nSpanish (es_ES)\\nFrench (fr_FR)\\nItalian (it_IT)\\nArabic (ar_SA)\\nDutch (nl_NL)\\nJapanese (ja_JP)\\nPortugese (pt_PT)\\n\\n"},
  {"name":"bbc_news_ptbr_summary","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/celsowm/bbc_news_ptbr_summary","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"bbc_news_ptbr_summary\\\"\\n\\t\\n\\nMore Information needed\\n"},
  {"name":"Open_Assistant_Conversation_Chains","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\n\\n\\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\\n\\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\\n\\nIt was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains."},
  {"name":"cml-tts","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ylacombe/cml-tts","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for CML-TTS\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG).\\nCML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in Dutch, German, French, Italian, Polish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/cml-tts."},
  {"name":"enem","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/maritaca-ai/enem","creator_name":"Maritaca AI","creator_url":"https://huggingface.co/maritaca-ai","description":"The ENEM 2022, 2023 and 2024 datasets encompass all multiple-choice questions from the last two editions of the Exame Nacional do Ensino M√©dio (ENEM), the main standardized entrance examination adopted by Brazilian universities. The datasets have been created to allow the evaluation of both textual-only and textual-visual language models. To evaluate textual-only models, we incorporated into the datasets the textual descriptions of the images that appear in the questions' statements from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maritaca-ai/enem."},
  {"name":"multilingual-tts","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/MohamedRashad/multilingual-tts","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBefore Anything and Everything ‚ö±\\n\\t\\n\\nIn the time of writing this Dataset Card, 17,490 18,412 civilian has been killed in Palestine (7,870 8,000 are children and 6,121 6,200 are women).\\nSeek any non-profit organization to help them with what you can (For myself, I use Mersal) üáµüá∏\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Multilingual TTS dataset is an exceptional compilation of text-to-speech (TTS) samples, meticulously crafted to showcase the richness and diversity of human languages.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/multilingual-tts."},
  {"name":"UltrachatBR","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/recogna-nlp/UltrachatBR","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUltrachatBR: Um Dataset em Portugu√™s baseado no Ultrachat\\n\\t\\n\\nO UltrachatBR √© uma vers√£o em portugu√™s do conhecido dataset Ultrachat, originalmente desenvolvido para o idioma ingl√™s. Este projeto visa disponibilizar uma vasta cole√ß√£o de di√°logos traduzidos para o portugu√™s, ampliando assim o acesso a recursos de processamento de linguagem natural para a comunidade de l√≠ngua portuguesa.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProcesso de Tradu√ß√£o\\n\\t\\n\\nO processo de tradu√ß√£o foi realizado utilizando a API do‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/UltrachatBR."},
  {"name":"UltrachatBR","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/recogna-nlp/UltrachatBR","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUltrachatBR: Um Dataset em Portugu√™s baseado no Ultrachat\\n\\t\\n\\nO UltrachatBR √© uma vers√£o em portugu√™s do conhecido dataset Ultrachat, originalmente desenvolvido para o idioma ingl√™s. Este projeto visa disponibilizar uma vasta cole√ß√£o de di√°logos traduzidos para o portugu√™s, ampliando assim o acesso a recursos de processamento de linguagem natural para a comunidade de l√≠ngua portuguesa.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProcesso de Tradu√ß√£o\\n\\t\\n\\nO processo de tradu√ß√£o foi realizado utilizando a API do‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/UltrachatBR."},
  {"name":"canarim","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/dominguesm/canarim","creator_name":"Maicon Domingues","creator_url":"https://huggingface.co/dominguesm","description":"\\n  \\n\\n\\n\\n  [üê± GitHub]\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCanarim: A Large-Scale Dataset of Web Pages in the Portuguese Language\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nCanarim is a database encompassing over 342 million Portuguese language documents, sourced from multiple iterations of CommonCrawl. This nearly 1 terabyte database stands as one of the most extensive Portuguese language data collections available. It underwent initial deduplication using URLs, with plans for further text-based deduplication and filtering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dominguesm/canarim."},
  {"name":"recognasumm","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/recogna-nlp/recognasumm","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRecognaSumm Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nRecognaSumm is a novel and comprehensive database specifically designed for the task of automatic text summarization in Portuguese. RecognaSumm stands out due to its diverse origin, composed of news collected from a variety of information sources, including agencies and online news portals. The database was constructed using web scraping techniques and careful curation, re sulting in a rich and representative collection of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/recognasumm."},
  {"name":"FAQ_BACEN","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Itau-Unibanco/FAQ_BACEN","creator_name":"Ita√∫-Unibanco","creator_url":"https://huggingface.co/Itau-Unibanco","description":"This dataset was used in the article: https://arxiv.org/abs/2311.11331\\n"},
  {"name":"openassistant-deepseek-coder","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using:\\nB_INST = '\\\\n### Instruction:\\\\n'\\nE_INST = '\\\\n### Response:\\\\n'\\nBOS = '<ÔΩúbegin‚ñÅof‚ñÅsentenceÔΩú>'\\nEOS = '\\\\n<|EOT|>\\\\n'\\n\\nSample Preparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder."},
  {"name":"sharegpt_dialogue_base","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base","creator_name":"Hieu Lam","creator_url":"https://huggingface.co/lamhieu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe dataset is from unknown, formatted as dialogues for speed and ease of use. Many thanks to author for releasing it.\\nImportantly, this format is easy to use via the default chat template of transformers, meaning you can use huggingface/alignment-handbook immediately, unsloth.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\nView online through viewer.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\nWe advise you to reconsider before use, thank you. If you find it useful, please like and follow this account.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base."},
  {"name":"QuestionClassification","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/cnmoro/QuestionClassification","creator_name":"Carlo Moro","creator_url":"https://huggingface.co/cnmoro","description":"cnmoro/QuestionClassification dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"extraglue","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/PORTULAN/extraglue","creator_name":"PORTULAN","creator_url":"https://huggingface.co/PORTULAN","description":"\\n\\n\\n¬†¬†¬†¬†This is the dataset card for extraGLUE. \\n  You may be interested in some of the other datasets for Portuguese and in the models trained with them, \\n  namely Albertina (encoders) and Gerv√°sio (decoders) families.\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExtraGLUE\\n\\t\\n\\n\\n\\n\\nExtraGLUE is a Portuguese dataset obtained by the automatic translation of some of the tasks in the GLUE and SuperGLUE benchmarks.\\nTwo variants of Portuguese are considered, namely European Portuguese and American Portuguese.\\nThe dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PORTULAN/extraglue."},
  {"name":"bio-mqm-dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zouharvi/bio-mqm-dataset","creator_name":"Vil√©m Zouhar","creator_url":"https://huggingface.co/zouharvi","description":"This dataset is compiled from the official Amazon repository (all respective licensing applies).\\nIt contains system translations, multiple references, and their quality evaluation on the MQM scale. It accompanies the ACL 2024 paper Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains.\\nWatch a brief 4 minutes-long video.\\n\\nAbstract: We introduce a new, extensive multidimensional quality metrics (MQM) annotated dataset covering 11 language pairs in the biomedical domain. We use this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/bio-mqm-dataset."},
  {"name":"tokenizer-wiki-bench","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Tokenizer Benchmark\\n\\t\\n\\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \\nfrom transformers import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench."},
  {"name":"bbrc_brazilian_banking_regulation_corpora","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bancodobrasil/bbrc_brazilian_banking_regulation_corpora","creator_name":"Banco do Brasil S.A.","creator_url":"https://huggingface.co/bancodobrasil","description":"We present BBRC, a collection of 25 corpus of banking regulatory risk from different departments of Banco do Brasil (BB). These are individual corpus about investments, insurance, human resources, security, technology, treasury, loans, accounting, fraud, credit cards, payment methods, agribusiness, risks, etc. They were annotated in binary form by experts indicating whether each regulatory document contains regulatory risk that may require changes to products, processes, services, and channels‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bancodobrasil/bbrc_brazilian_banking_regulation_corpora."},
  {"name":"GPT4-500k-Augmented-PTBR-Clean","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/cnmoro/GPT4-500k-Augmented-PTBR-Clean","creator_name":"Carlo Moro","creator_url":"https://huggingface.co/cnmoro","description":"A translated version of Open-Orca/1million-gpt-4 to portuguese.\\nInstructions and responses with non-latin characters have been removed, as well as coding-related tasks.\\n"},
  {"name":"webui-dom-snapshots","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WebUI DOM snapshots\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: Gary Benson\\nLanguages: Mostly English (87%);\\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\\nLicense: CC0 1.0 Universal\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots."},
  {"name":"GigaVerbo-Text-Filter","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/TucanoBR/GigaVerbo-Text-Filter","creator_name":"Tucano","creator_url":"https://huggingface.co/TucanoBR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGigaVerbo Text-Filter\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGigaVerbo Text-Filter is a dataset with 110,000 randomly selected samples from 9 subsets of GigaVerbo (i.e., specifically those that were not synthetic). This dataset was used to train the text-quality filters described in \\\"Tucano: Advancing Neural Text Generation for Portuguese\\\". To create the text embeddings, we used sentence-transformers/LaBSE. All scores were generated by GPT-4o.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TucanoBR/GigaVerbo-Text-Filter."},
  {"name":"GigaVerbo-Text-Filter","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/TucanoBR/GigaVerbo-Text-Filter","creator_name":"Tucano","creator_url":"https://huggingface.co/TucanoBR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGigaVerbo Text-Filter\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGigaVerbo Text-Filter is a dataset with 110,000 randomly selected samples from 9 subsets of GigaVerbo (i.e., specifically those that were not synthetic). This dataset was used to train the text-quality filters described in \\\"Tucano: Advancing Neural Text Generation for Portuguese\\\". To create the text embeddings, we used sentence-transformers/LaBSE. All scores were generated by GPT-4o.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TucanoBR/GigaVerbo-Text-Filter."},
  {"name":"wikipedia-2024-06-bge-m3","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3","creator_name":"Upstash","creator_url":"https://huggingface.co/Upstash","description":"\\n\\t\\n\\t\\t\\n\\t\\tWikipedia Embeddings with BGE-M3\\n\\t\\n\\nThis dataset contains embeddings from the\\nJune 2024 Wikipedia dump\\nfor the 11 most popular languages.\\nThe embeddings are generated with the multilingual\\nBGE-M3 model.\\nThe dataset consists of Wikipedia articles split into paragraphs,\\nand embedded with the aforementioned model.\\nTo enhance search quality, the paragraphs are prefixed with their\\nrespective article titles before embedding.\\nAdditionally, paragraphs containing fewer than 100 characters‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3."},
  {"name":"text_ratings","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"Todo - Write dataset card\\n"},
  {"name":"MMMLU","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLU‚Äôs test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU."},
  {"name":"MultiSimV2","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MichaelR207/MultiSimV2","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiSim Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe MultiSim benchmark is a growing collection of text simplification datasets targeted at sentence simplification in several languages.  Currently, the benchmark spans 12 languages.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nSentence Simplification\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"MichaelR207/MultiSimV2\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you use this benchmark, please cite our‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MichaelR207/MultiSimV2."},
  {"name":"m-ArenaHard","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/m-ArenaHard","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-ArenaHard\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-ArenaHard."},
  {"name":"ToxicCommons","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/PleIAs/ToxicCommons","creator_name":"PleIAs","creator_url":"https://huggingface.co/PleIAs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tToxic Commons\\n\\t\\n\\nToxic Commons is a release of 2 million samples of annotated, public domain, multilingual text that was used to train Celadon. \\nIt is being released alongside Celadon, in order to better understand multilingual and multicultural toxicity. \\nEach sample was classified across 5 axes of toxicity:\\n\\nRace and origin-based bias: includes racism as well as bias against someone‚Äôs country or region of origin or immigration status, especially immigrant or refugee status.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PleIAs/ToxicCommons."},
  {"name":"PangeaBench-xmmmu","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/neulab/PangeaBench-xmmmu","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"neulab/PangeaBench-xmmmu dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"VoxCommunis","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis."},
  {"name":"P-MMEval","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Qwen/P-MMEval","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tP-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce a multilingual benchmark, P-MMEval, covering effective fundamental and capability-specialized datasets. We extend the existing benchmarks, ensuring consistent language coverage across all datasets and providing parallel samples among multiple languages, supporting up to 10 languages from 8 language families (i.e., en, zh, ar, es, ja, ko, th, fr, pt‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Qwen/P-MMEval."},
  {"name":"include-base-44","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/include-base-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-base (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-base-44."},
  {"name":"unlabelled-sti-corpus","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SIRIS-Lab/unlabelled-sti-corpus","creator_name":"SIRIS Lab, Research Division of SIRIS Academic","creator_url":"https://huggingface.co/SIRIS-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe unlabelled-sti-corpus is a diverse dataset designed for developing information extraction datasets (i.e. text classification or NER) for Science, Technology, and Innovation (STI) records. The corpus contains approximately 35,000 records sourced from four major repositories:\\n\\n22,500 publications from OpenAlex\\n10,000 European research projects from CORDIS\\n5,000 regional projects from Interreg and Kohesio\\n7,000 patents from Lens.org\\n\\nThe dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SIRIS-Lab/unlabelled-sti-corpus."},
  {"name":"include-lite-44","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/include-lite-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-lite (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-lite-44."},
  {"name":"crime_tweets_in_portuguese","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/miguelribeirokk/crime_tweets_in_portuguese","creator_name":"Miguel Ant√¥nio Ribeiro e Silva","creator_url":"https://huggingface.co/miguelribeirokk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTweets190: A Comprehensive Dataset of Crime-Related Tweets in Portuguese with Sentiment, Toxicity, and Location Information\\n\\t\\n\\nThis dataset contains 61.715 tweets related to possible crime reports, labeled with categories such as \\\"Assalto\\\", \\\"Roubo\\\", \\\"Furto\\\", \\\"Ass√©dio\\\", \\\"Seguran√ßa P√∫blica\\\", \\\"Homic√≠dio, and \\\"Outros\\\", along with sentiment analysis, toxicity analysis, and location identification.\\nA particular feature in the Portuguese language is that many words potentially related to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miguelribeirokk/crime_tweets_in_portuguese."},
  {"name":"leis_ordinarias_1988_2024","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/celsowm/leis_ordinarias_1988_2024","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","description":"celsowm/leis_ordinarias_1988_2024 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Global-MMLU-Lite","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 15 languages, including English. It is \\\"lite\\\" version of the original Global-MMLU dataset üåç.\\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \\n\\nCurated by: Professional annotators and contributors of Cohere For‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite."},
  {"name":"MultiLingualSentiment","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/clapAI/MultiLingualSentiment","creator_name":"clapAI","creator_url":"https://huggingface.co/clapAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nMultilingualSentiment is a sentiment classification dataset that encompasses three sentiment labels: Positive, Neutral, Negative\\nThe dataset spans multiple languages and covers a wide range of domains, making it ideal for multilingual sentiment analysis tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\nThe dataset was meticulously collected and aggregated from various sources, including Hugging Face and Kaggle. These sources provide diverse languages and domains to ensure a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clapAI/MultiLingualSentiment."},
  {"name":"BoundingDocs","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/letxbe/BoundingDocs","creator_name":"Letxbe","creator_url":"https://huggingface.co/letxbe","description":"\\n\\nBoundingDocs\\n\\nüîç The largest spatially-annotated dataset for Document Question Answering\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBoundingDocs is a unified dataset for Document Question Answering (QA) that includes spatial annotations. It consolidates multiple public datasets from Document AI and Visually Rich Document Understanding (VRDU) domains. The dataset reformulates Information Extraction (IE) tasks into QA tasks, making it a valuable resource for training and evaluating Large Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/letxbe/BoundingDocs."},
  {"name":"LegalSumm","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MartimZanatti/LegalSumm","creator_name":"Martim Zanatti dos Santos Gomes da Silva","creator_url":"https://huggingface.co/MartimZanatti","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAnotated Dataset of Summaries of the Supreme Court of Justice of Portugal\\n\\t\\n\\nThis dataset contains 68 summaries of 12 judgments STJ annotated in several dimensions by legal experts. \\n\\n10 summaries are the summaries written by the judges themselves.\\n29 summaries are extractive summaries generated by LexRank technique.\\n30 summaries are abstractive summaries generated by Llamma LLM.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Content:\\n\\t\\n\\nCase information\\n\\nJudgment Name\\n\\nId of judgment\\n\\n\\nReport Section‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MartimZanatti/LegalSumm."},
  {"name":"AllTripletsMsMarco-PTBR","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/cnmoro/AllTripletsMsMarco-PTBR","creator_name":"Carlo Moro","creator_url":"https://huggingface.co/cnmoro","description":"Need a huge dataset translated? Connect with me!\\n"},
  {"name":"imatrix-calibration","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/eaddario/imatrix-calibration","creator_name":"Ed Addario","creator_url":"https://huggingface.co/eaddario","description":"\\n\\t\\n\\t\\t\\n\\t\\tImportance Matrix (imatrix) calibration datasets\\n\\t\\n\\nThis dataset consists of over 10M tokens of cleaned and de-duplicated text files for 13 different languages. Each language file is available in five sizes, ranging from large (~ 26,000 lines equivalent to approx. 750K tokens), to micro (~ 1,625 lines and 125K tokens avg).\\nOriginal data sourced from HuggingFaceFW/fineweb and HuggingFaceFW/fineweb-2\\n\\n\\t\\n\\t\\t\\nFile\\nLanguage\\nLines\\nSize\\n\\n\\n\\t\\t\\ncalibration_ar_large\\nArabic\\n26,000\\n3.1M‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eaddario/imatrix-calibration."},
  {"name":"open_government","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AgentPublic/open_government","creator_name":"AgentPublic","creator_url":"https://huggingface.co/AgentPublic","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Government Dataset\\n\\t\\n\\nOpen Government is the largest agregation of governement text and data made available as part of open data programs. \\nIn total, the dataset contains approximately 380B tokens. While Open Government aims to become a global resource, in its current state it mostly features open datasets from the US, France, European and international organizations.\\nThe dataset comprises 16 collections curated through two different initiaties: Finance commons and Legal commons.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AgentPublic/open_government."},
  {"name":"news-of-the-brazilian-newspaper","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/emdemor/news-of-the-brazilian-newspaper","creator_name":"Eduardo Morais","creator_url":"https://huggingface.co/emdemor","description":"\\n\\t\\n\\t\\t\\n\\t\\tNews of the Brazilian Newspaper\\n\\t\\n\\nThis repository contains a comprehensive dataset of news articles from a Brazilian newspaper, Folha de S√£o Paulo (http://www.folha.uol.com.br/). The dataset includes 167,053 examples of news articles, comprising headlines, URLs of articles, complete articles, and their respective categories. \\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Creation\\n\\t\\n\\nThe headlines were initially gathered from Inshorts and were then used to scrape the complete news articles from Folha de S√£o Paulo.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/emdemor/news-of-the-brazilian-newspaper."},
  {"name":"LivingNER","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Praise2112/LivingNER","creator_name":"Praise","creator_url":"https://huggingface.co/Praise2112","description":"\\n\\t\\n\\t\\t\\n\\t\\tLivingNER: Named entity recognition, normalization & classification of species, pathogens and food\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe LivingNER Gold Standard corpus is a collection of 2000 clinical case reports covering a broad range of medical specialities, i.e. infectious diseases (including Covid-19 cases), cardiology, neurology, oncology, dentistry, pediatrics, endocrinology, primary care, allergology, radiology, psychiatry, ophthalmology, urology, internal medicine, emergency and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Praise2112/LivingNER."},
  {"name":"DATA-AI_Chat","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","description":"\\n\\t\\n\\t\\t\\n\\t\\tDATA-AI: Il Modello di IA di M.INC.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tüìå Introduzione\\n\\t\\n\\nDATA-AI √® un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello √® basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \\nDATA-AI √® stato addestrato su un‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat."},
  {"name":"u-sticker","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/metchee/u-sticker","creator_name":"Metilda Chee","creator_url":"https://huggingface.co/metchee","description":"\\n\\t\\n\\t\\t\\n\\t\\tU-Sticker\\n\\t\\n\\nUser-Sticker is a stickers dataset with multi-domain conversations.\\nFeatures of U-Sticker:\\n\\nMulti-domain interactions ‚úÖ\\nTemporal ‚úÖ\\nUser information ‚úÖ\\n370.2k stickers ‚úÖ (104k unique)\\n22.6k users ‚úÖ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nU-Sticker contains three files:\\n\\nConversation files: 1 to 67.json\\nDomain mapping files idx_to_domain.txt.\\nSticker files.\\n\\n\\nSticker files are available here and Baidu Cloud.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tConversation file\\n\\t\\n\\n\\nEmpty lines are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/metchee/u-sticker."},
  {"name":"wikis","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/nyuuzyou/wikis","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Public MediaWiki Collection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 1,662,448 articles harvested from 930 random public MediaWiki instances found across the Internet. The collection was created by extracting current page content from these wikis, preserving article text, metadata, and structural information. The dataset represents a diverse cross-section of public wiki content spanning multiple domains, topics, and languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wikis."},
  {"name":"Thinking-multilingual-big-10k-sft","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\\nenjoy üëç\\n"},
  {"name":"m-WildVision","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/m-WildVision","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-WildVision\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \\nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \\nThe authors demonstrated that these prompts enable automatic LLM judge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-WildVision."},
  {"name":"OpenHumanreasoning-multilingual-2.2k","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\\nnote: translations are not human generated.\\n"},
  {"name":"BRIGHTER-emotion-categories","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\tBRIGHTER Emotion Categories Dataset\\n\\t\\n\\nThis dataset contains the emotion categories data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe BRIGHTER Emotion Categories dataset is a comprehensive multi-language, multi-label emotion classification dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories."},
  {"name":"bnl_newspapers","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/bnl-data/bnl_newspapers","creator_name":"BnL Open Data","creator_url":"https://huggingface.co/bnl-data","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BnL Historical Newspapers\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe BnL has digitised over 800.000 pages of Luxembourg newspapers. This dataset currently has one configuration covering a subset of these newspapers, which sit under the \\\"Processed Datasets\\\" collection. The BNL:\\n\\nprocessed all newspapers and monographs that are in the public domain and extracted the full text and associated meta data of every single article, section, advertisement‚Ä¶ The result is a large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bnl-data/bnl_newspapers."},
  {"name":"europa_eac_tm","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/community-datasets/europa_eac_tm","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Europa Education and Culture Translation Memory (EAC-TM)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a corpus of manually produced translations from english to up to 25 languages, released in 2012 by the European Union's Directorate General for Education and Culture (EAC).\\nTo load a language pair that is not part of the config, just specify the language code as language pair. For example, if you want to translate Czech to Greek:\\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/europa_eac_tm."},
  {"name":"europa_ecdc_tm","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/community-datasets/europa_ecdc_tm","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn October 2012, the European Union (EU) agency 'European Centre for Disease Prevention and Control' (ECDC) released a translation memory (TM), i.e. a collection of sentences and their professionally produced translations, in twenty-five languages.\\nECDC-TM covers 25 languages: the 23 official languages of the EU plus Norwegian (Norsk) and Icelandic. ECDC-TM was created by translating from English into the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/europa_ecdc_tm."},
  {"name":"opus_paracrawl","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for OpusParaCrawl\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nParallel corpora from Web Crawls collected in the ParaCrawl project.\\nTha dataset contains:\\n\\n42 languages, 43 bitexts\\ntotal number of files: 59,996\\ntotal number of tokens: 56.11G\\ntotal number of sentence fragments: 3.13G\\n\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs,\\ne.g.\\ndataset = load_dataset(\\\"opus_paracrawl\\\", lang1=\\\"en\\\", lang2=\\\"so\\\")\\n\\nYou can find‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl."},
  {"name":"squad_v1_pt","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nunorc/squad_v1_pt","creator_name":"Nuno Ramos Carvalho","creator_url":"https://huggingface.co/nunorc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"squad_v1_pt\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPortuguese translation of the SQuAD dataset. The translation was performed automatically using the Google Cloud API.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdefault\\n\\t\\n\\n\\nSize of downloaded dataset files: 39.53 MB\\nSize of the generated dataset: 96.72 MB\\nTotal amount‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nunorc/squad_v1_pt."},
  {"name":"xcsr","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/INK-USC/xcsr","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for X-CSR\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTo evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr."},
  {"name":"xlel_wd_dictionary","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles."},
  {"name":"xlel_wd","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles."},
  {"name":"askD","license":"GNU Lesser General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/ju-resplande/askD","creator_name":"Juliana Resplande","creator_url":"https://huggingface.co/ju-resplande","description":"\\\\\\r\\n#TODO: description"},
  {"name":"translation-en-pt","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/VanessaSchenkel/translation-en-pt","creator_name":"Vanessa Schramm Schenkel Da Silva","creator_url":"https://huggingface.co/VanessaSchenkel","description":"How to use it: \\nfrom datasets import load_dataset\\n\\nremote_dataset = load_dataset(\\\"VanessaSchenkel/translation-en-pt\\\", field=\\\"data\\\")\\n\\nremote_dataset\\n\\nOutput:\\nDatasetDict({\\n    train: Dataset({\\n        features: ['id', 'translation'],\\n        num_rows: 260482\\n    })\\n})\\n\\nExemple: \\nremote_dataset[\\\"train\\\"][5]\\n\\nOutput:\\n{'id': '5',\\n 'translation': {'english': 'I have to go to sleep.',\\n  'portuguese': 'Tenho de dormir.'}}\\n\\n"},
  {"name":"mapa","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/mapa","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset consists of 12 documents (9 for Spanish due to parsing errors) taken from EUR-Lex, a multilingual corpus of court\\ndecisions and legal dispositions in the 24 official languages of the European Union. The documents have been annotated\\nfor named entities following the guidelines of the MAPA project which foresees two\\nannotation level, a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mapa."},
  {"name":"NERDE","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Gpaiva/NERDE","creator_name":"Guilherme Pereira Paiva","creator_url":"https://huggingface.co/Gpaiva","description":"(pt) NERDE √© um dataset para NER a partir de documentos jur√≠dicos da defesa econ√¥mica em portugu√™s do Brasil, foi criado em colabora√ß√£o com o Cade e o laborat√≥rio LATITUDE/UnB.\\n(en) NERDE is a NER dataset from economic defense legal documents in Brazilian Portuguese, created in collaboration with Cade and the LATITUDE/UnB laboratory."},
  {"name":"xP3all","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot."},
  {"name":"lextreme","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/lextreme","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"The LEXTREME Benchmark is a collection of multilingual datasets for evaluating model performance \\nacross a diverse set of legal NLU tasks."},
  {"name":"handmade-dataset","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/VanessaSchenkel/handmade-dataset","creator_name":"Vanessa Schramm Schenkel Da Silva","creator_url":"https://huggingface.co/VanessaSchenkel","description":"Dataset with sentences regarding professions, half of the translations are to feminine and half for masculine sentences.\\nHow to use it: \\nfrom datasets import load_dataset\\nremote_dataset = load_dataset(\\\"VanessaSchenkel/handmade-dataset\\\", field=\\\"data\\\")\\nremote_dataset\\n\\nOutput:\\nDatasetDict({\\n    train: Dataset({\\n        features: ['id', 'translation'],\\n        num_rows: 388\\n    })\\n})\\n\\nExemple: \\nremote_dataset[\\\"train\\\"][5]\\n\\nOutput:\\n{'id': '5',\\n 'translation': {'english': 'the postman finished her‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VanessaSchenkel/handmade-dataset."},
  {"name":"opus_books_en_pt","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/VanessaSchenkel/opus_books_en_pt","creator_name":"Vanessa Schramm Schenkel Da Silva","creator_url":"https://huggingface.co/VanessaSchenkel","description":"How to use it: \\nfrom datasets import load_dataset\\nremote_dataset = load_dataset(\\\"VanessaSchenkel/opus_books_en_pt\\\", field=\\\"data\\\")\\nremote_dataset\\n\\nOutput:\\nDatasetDict({\\n    train: Dataset({\\n        features: ['id', 'translation'],\\n        num_rows: 1404\\n    })\\n})\\n\\nExemple: \\nremote_dataset[\\\"train\\\"][5]\\n\\nOutput:\\n{'id': '5',\\n 'translation': {'en': \\\"There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself, 'Oh dear!\\\",\\n  'pt':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VanessaSchenkel/opus_books_en_pt."},
  {"name":"xP3mt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot."},
  {"name":"mc4_legal","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/mc4_legal","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MC4_Legal: A Corpus Covering the Legal Part of MC4 for European Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains large text resources (~133GB in total) from mc4 filtered for legal data that can be used for pretraining language models.\\nUse the dataset like this:\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"joelito/mc4_legal\\\", \\\"de\\\", split='train', streaming=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset supports the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mc4_legal."},
  {"name":"olid-br","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/dougtrajano/olid-br","creator_name":"Douglas Trajano","creator_url":"https://huggingface.co/dougtrajano","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOLID-BR\\n\\t\\n\\nOffensive Language Identification Dataset for Brazilian Portuguese (OLID-BR) is a dataset with multi-task annotations for the detection of offensive language.\\nThe current version (v1.0) contains 7,943 (extendable to 13,538) comments from different sources, including social media (YouTube and Twitter) and related datasets.\\nOLID-BR contains a collection of annotated sentences in Brazilian Portuguese using an annotation model that encompasses the following levels:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dougtrajano/olid-br."},
  {"name":"brwac_tiny","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/thegoodfellas/brwac_tiny","creator_name":"The Good Fellas","creator_url":"https://huggingface.co/thegoodfellas","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BrWac\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe BrWaC (Brazilian Portuguese Web as Corpus) is a large corpus constructed following the Wacky framework, \\nwhich was made public for research purposes. The current corpus version, released in January 2017, is composed by \\n3.53 million documents, 2.68 billion tokens and 5.79 million types. Please note that this resource is available \\nsolely for academic research purposes, and you agreed not to use it for any commercial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thegoodfellas/brwac_tiny."},
  {"name":"PortugueseLegalSentences-v1","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v1","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Legal Sentences\\n\\t\\n\\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\\nThe goal of this dataset was to be used for MLM and TSDAE\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContributions\\n\\t\\n\\n@rufimelo99\\n"},
  {"name":"PortugueseLegalSentences-v0","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v0","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Legal Sentences\\n\\t\\n\\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\\nThe goal of this dataset was to be used for MLM and TSDAE\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContributions\\n\\t\\n\\n@rufimelo99\\n"},
  {"name":"PortugueseLegalSentences-v2","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v2","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Legal Sentences\\n\\t\\n\\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\\nThe goal of this dataset was to be used for MLM and TSDAE\\nExtended version of rufimelo/PortugueseLegalSentences-v1\\n200000/200000/100000\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContributions\\n\\t\\n\\n@rufimelo99\\n"},
  {"name":"PortugueseLegalSentences-v3","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v3","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Legal Sentences\\n\\t\\n\\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\\nThe goal of this dataset was to be used for MLM and TSDAE\\nExtended version of rufimelo/PortugueseLegalSentences-v1\\n400000/50000/50000\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContributions\\n\\t\\n\\n@rufimelo99\\n"},
  {"name":"TaTA","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/GEM/TaTA","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","description":"Dataset loader for TaTA: A Multilingual Table-to-Text Dataset for African Languages"},
  {"name":"portuguese-legal-sentences-v0","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/stjiris/portuguese-legal-sentences-v0","creator_name":"Sumariza√ß√£o e Informa√ß√£o de decis√µes: Aplica√ß√£o de T√©cnicas de Intelig√™ncia Artificial no Supremo Tribunal de Justi√ßa (IRIS)","creator_url":"https://huggingface.co/stjiris","description":"\\n\\nWork developed as part of Project IRIS.\\nThesis: A Semantic Search System for Supremo Tribunal de Justi√ßa\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Legal Sentences\\n\\t\\n\\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\\nThe goal of this dataset was to be used for MLM and TSDAE\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContributions\\n\\t\\n\\n@rufimelo99\\nIf you use this work, please cite:\\n@InProceedings{MeloSemantic,\\n  author=\\\"Melo, Rui\\n  and Santos, Pedro A.\\n  and Dias, Jo{\\\\~a}o\\\",\\n  editor=\\\"Moniz, Nuno\\n  and Vale, Zita\\n  and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stjiris/portuguese-legal-sentences-v0."},
  {"name":"MultiLegalPile_Wikipedia_Filtered","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPile_Wikipedia_Filtered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles."},
  {"name":"EU_Wikipedias","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/EU_Wikipedias","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"Wikipedia dataset containing cleaned articles of all languages.\\nThe datasets are built from the Wikipedia dump\\n(https://dumps.wikimedia.org/) with one split per language. Each example\\ncontains the content of one full Wikipedia article with cleaning to strip\\nmarkdown and unwanted sections (references, etc.)."},
  {"name":"b2w-reviews01","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ruanchaves/b2w-reviews01","creator_name":"Ruan Chaves Rodrigues","creator_url":"https://huggingface.co/ruanchaves","description":"B2W-Reviews01 is an open corpus of product reviews. It contains more than 130k e-commerce customer reviews, collected from the Americanas.com website between January and May, 2018. B2W-Reviews01 offers rich information about the reviewer profile, such as gender, age, and geographical location. The corpus also has two different review rates"},
  {"name":"MultiLegalPileWikipediaFiltered","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPileWikipediaFiltered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles."},
  {"name":"blogset-br","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/thegoodfellas/blogset-br","creator_name":"The Good Fellas","creator_url":"https://huggingface.co/thegoodfellas","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nEste Dataset foi criado a partir dos dados disponibilizados pelo Grupo de Processamento de Linguagem Natural da PUC-RS. O site oficial pode ser encontrado aqui: https://www.inf.pucrs.br/linatural/wordpress/recursos-e-ferramentas/blogset-br/\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nIndicado para treinamento de modelos de linguagem.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nPortugu√™s do Brasil\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInitial Data Collection‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thegoodfellas/blogset-br."},
  {"name":"gutenberg_multilang","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/sedthh/gutenberg_multilang","creator_name":"Richard Nagyfi","creator_url":"https://huggingface.co/sedthh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Project Gutenber - Multilanguage eBooks\\n\\t\\n\\nA collection of non-english language eBooks (7907, about 75-80% of all the ES, DE, FR, NL, IT, PT, HU books available on the site) from the Project Gutenberg site with metadata removed. \\nOriginally colected for https://github.com/LAION-AI/Open-Assistant\\n\\n\\t\\n\\t\\t\\nLANG\\nEBOOKS\\n\\n\\n\\t\\t\\nES\\n717\\n\\n\\nDE\\n1735\\n\\n\\nFR\\n2863\\n\\n\\nNL\\n904\\n\\n\\nIT\\n692\\n\\n\\nPT\\n501\\n\\n\\nHU\\n495\\n\\n\\n\\t\\n\\nThe METADATA column contains catalogue meta information on each book as a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sedthh/gutenberg_multilang."},
  {"name":"faquad-nli","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ruanchaves/faquad-nli","creator_name":"Ruan Chaves Rodrigues","creator_url":"https://huggingface.co/ruanchaves","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for FaQuAD-NLI\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFaQuAD is a Portuguese reading comprehension dataset that follows the format of the Stanford Question Answering Dataset (SQuAD). It is a pioneer Portuguese reading comprehension dataset using the challenging format of SQuAD. The dataset aims to address the problem of abundant questions sent by academics whose answers are found in available institutional documents in the Brazilian higher education system. It consists of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ruanchaves/faquad-nli."},
  {"name":"mc4-pt-cleaned","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/thegoodfellas/mc4-pt-cleaned","creator_name":"The Good Fellas","creator_url":"https://huggingface.co/thegoodfellas","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis is a clenned version of AllenAI mC4 PtBR section. The original dataset can be found here https://huggingface.co/datasets/allenai/c4\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tClean procedure\\n\\t\\n\\nWe applied the same clenning procedure as explained here: https://gitlab.com/yhavinga/c4nlpreproc.git \\nThe repository offers two strategies. The first one, found in the main.py file, uses pyspark to create a dataframe that can both clean the text and create a \\npseudo mix on the entire dataset. We found‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thegoodfellas/mc4-pt-cleaned."},
  {"name":"Fact-Completion","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion","creator_name":"Polyglot-or-Not","creator_url":"https://huggingface.co/Polyglot-or-Not","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\nHomepage: https://bit.ly/ischool-berkeley-capstone\\nRepository: https://github.com/daniel-furman/Capstone\\nPoint of Contact: daniel_furman@berkeley.edu\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the dataset for Polyglot or Not?: Measuring Multilingual Encyclopedic Knowledge Retrieval from Foundation Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTest Description\\n\\t\\n\\n Given a factual association such as The capital of France is Paris, we determine whether a model adequately \\\"knows\\\" this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion."},
  {"name":"lingnli-multi-mt","license":"BSD 2-Clause \"Simplified\" License","language":"en","url":"https://huggingface.co/datasets/maximoss/lingnli-multi-mt","creator_name":"Maximos Skandalis","creator_url":"https://huggingface.co/maximoss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis repository contains a collection of machine translations of LingNLI dataset \\ninto 9 different languages (Bulgarian, Finnish, French, Greek, Italian, Korean, Lithuanian, Portuguese, Spanish). The goal is to predict textual entailment (does sentence A \\nimply/contradict/neither sentence B), which is a classification task (given two sentences, \\npredict one of three labels). It is here formatted in the same manner as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maximoss/lingnli-multi-mt."},
  {"name":"portuguese-parliament-interventions","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/luist18/portuguese-parliament-interventions","creator_name":"Lu√≠s Tavares","creator_url":"https://huggingface.co/luist18","description":"luist18/portuguese-parliament-interventions dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"pt-parliament-interventions","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/luist18/pt-parliament-interventions","creator_name":"Lu√≠s Tavares","creator_url":"https://huggingface.co/luist18","description":"luist18/pt-parliament-interventions dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"ptparl","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/luist18/ptparl","creator_name":"Lu√≠s Tavares","creator_url":"https://huggingface.co/luist18","description":"The PTPARL dataset is a dataset containing 5713 interventions in the Portuguese parliament."},
  {"name":"instruct-aira-dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset","creator_name":"Nicholas Kluge Corr√™a","creator_url":"https://huggingface.co/nicholasKluge","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInstruct-Aira Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains a collection of prompts and responses to those prompts. All completions were generated by querying already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc.). The dataset is available in Portuguese, English, and Spanish.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:\\n\\nLanguage modeling.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset."},
  {"name":"reward-aira-dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nicholasKluge/reward-aira-dataset","creator_name":"Nicholas Kluge Corr√™a","creator_url":"https://huggingface.co/nicholasKluge","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReward-Aira Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains a collection of prompt + completion examples of LLM following instructions in a conversational manner. All prompts come with two possible completions (one better than the other). The dataset is available in both Portuguese and English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be utilized to train a reward/preference model or DPO fine-tuning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/reward-aira-dataset."},
  {"name":"toxic-aira-dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nicholasKluge/toxic-aira-dataset","creator_name":"Nicholas Kluge Corr√™a","creator_url":"https://huggingface.co/nicholasKluge","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tToxic-Aira Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains a collection of prompt + completion examples of LLM following instructions in a conversational manner. All prompts come with two possible completions (one deemed appropriate and the other toxic). The dataset is available in both Portuguese and English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be utilized to train a reward/preference model, toxicity detection, or DPO fine-tuning.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/toxic-aira-dataset."},
  {"name":"SREDFM","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Babelscape/SREDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\\\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\\nFirst, we present SRED\\\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \\nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \\nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\\\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}."},
  {"name":"all-scam-spam","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\\n1040 rows of balanced data, consisting of casual conversations and scam emails in ‚âà10 languages, were manually collected and annotated by me, with some help from ChatGPT.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSome preprcoessing algorithms\\n\\t\\n\\n\\nspam_assassin.js, followed by spam_assassin.py\\nenron_spam.py\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData composition\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam."},
  {"name":"malicious-website-features-2.4M","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"Important Notice:\\n\\nA subset of the URL dataset is from Kaggle, and the Kaggle datasets contained 10%-15% mislabelled data. See this dicussion I opened for some false positives. I have contacted Kaggle regarding their erroneous \\\"Usability\\\" score calculation for these unreliable datasets.\\nThe feature extraction methods shown here are not robust at all in 2023, and there're even silly mistakes in 3 functions: not_indexed_by_google, domain_registration_length, and age_of_domain.\\n\\n\\n\\nThe features‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M."},
  {"name":"professor_heideltime_en","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hugosousa/professor_heideltime_en","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProfessor HeidelTime\\n\\t\\n\\n\\n\\nProfessor HeidelTime is a project to create a multilingual corpus weakly labeled with HeidelTime, a temporal tagger.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpus Details\\n\\t\\n\\nThe weak labeling was performed in six languages. Here are the specifics of the corpus for each language:\\n\\n\\t\\n\\t\\t\\nDataset\\nLanguage\\nDocuments\\nFrom\\nTo\\nTokens\\nTimexs\\n\\n\\n\\t\\t\\nAll the News 2.0\\nEN\\n24,642\\n2016-01-01\\n2020-04-02\\n18,755,616\\n254,803\\n\\n\\nItalian Crime News\\nIT\\n9,619\\n2011-01-01\\n2021-12-31\\n3,296,898\\n58,823\\n\\n\\nGerman‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hugosousa/professor_heideltime_en."},
  {"name":"ggml-vicuna-v0-quantized","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","description":"These are quantized ggml binary files for vicuna 7B and 13B models. The version of vicuna for these models are v0.\\nThese files can be used in conjunction with minigpt4 ggml models 7B and 13B in minigpt4.cpp\\nRecommended are the Q5_K and Q6_K implementations. If there are any issues, use Q4_1 or Q4_0.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVicuna Model Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel details\\n\\t\\n\\nModel type:\\nVicuna is an open-source chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT.\\nIt is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized."},
  {"name":"MMLU_Portuguese","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/MMLU_Portuguese","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"Portuguese version of MMLU dataset tranlasted by gpt-3.5-turbo.The dataset is used in the research related to MultilingualSIFT. \\n"},
  {"name":"text-template-to-summarize","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Anderson-Andre-P/text-template-to-summarize","creator_name":"Anderson Andr√© Pereira Eleut√©rio","creator_url":"https://huggingface.co/Anderson-Andre-P","description":"Anderson-Andre-P/text-template-to-summarize dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"central_de_fatos","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/fake-news-UFG/central_de_fatos","creator_name":"fake-news-UFG","creator_url":"https://huggingface.co/fake-news-UFG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCentral de Fatos\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn recent times, the interest for research dissecting the dissemination and prevention of misinformation in the online environment has spiked dramatically.\\nGiven that scenario, a recurring obstacle is the unavailability of public datasets containing fact-checked instances.\\nIn this work, we performed an extensive data collection of such instances from the better part of all major internationally recognized Brazilian fact-checking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fake-news-UFG/central_de_fatos."},
  {"name":"bible-ptbr-gun-gub-aligned","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/tiagoblima/bible-ptbr-gun-gub-aligned","creator_name":"Tiago Barbosa de Lima","creator_url":"https://huggingface.co/tiagoblima","description":"tiagoblima/bible-ptbr-gun-gub-aligned dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"text_coordinates_regions","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Regions\\\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\\nKey Features:\\n\\nTextual Data: The dataset contains 500,000 text samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions."},
  {"name":"CC-MAIN-2023-23","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/dominguesm/CC-MAIN-2023-23","creator_name":"Maicon Domingues","creator_url":"https://huggingface.co/dominguesm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"CC-MAIN-2023-23\\\"\\n\\t\\n\\nMore Information needed\\n"},
  {"name":"pira","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/paulopirozelli/pira","creator_name":"Paulo Pirozelli","creator_url":"https://huggingface.co/paulopirozelli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPir√°: A Bilingual Portuguese-English Dataset for Question-Answering about the Ocean, the Brazilian coast, and climate change\\n\\t\\n\\nPir√° is a crowdsourced reading comprehension dataset on the ocean, the Brazilian coast, and climate change. \\nQA sets are presented in both Portuguese and English, together with their corresponding textual context.\\nThe dataset also contains human and automatic paraphrases for questions and answers, as well as a number of qualitative assessments. \\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/paulopirozelli/pira."},
  {"name":"openassistant-guanaco-EOS","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Guanaco Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using \\\"### Human:\\\" AND \\\"### Assistant\\\" as the beginning and end of sequence tokens.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then slightly adjusted to:\\n\\n\\nif a row of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS."},
  {"name":"openassistant-llama-style","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Llama 2 Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then filtered to:\\n\\n\\nreplace instances of '### Human:' with '[INST]'\\nreplace‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style."},
  {"name":"calame-pt","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/NOVA-vision-language/calame-pt","creator_name":"NOVA Vision & Language","creator_url":"https://huggingface.co/NOVA-vision-language","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCALAME-PT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContext-Aware LAnguage Modeling Evaluation for Portuguese\\n\\t\\n\\nCALAME-PT is a PT benchmark composed of small texts (contexts) and their respective last words. \\nThese contexts should, in theory, contain enough information so that a human or a model is capable of guessing its last word - without being too specific and/or too ambiguous.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tComposition\\n\\t\\n\\nCALAME-PT is composed of 2 \\\"sets\\\" of data - handwritten and generated. \\n\\nHandwritten Set: contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NOVA-vision-language/calame-pt."},
  {"name":"calame-pt","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/NOVA-vision-language/calame-pt","creator_name":"NOVA Vision & Language","creator_url":"https://huggingface.co/NOVA-vision-language","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCALAME-PT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContext-Aware LAnguage Modeling Evaluation for Portuguese\\n\\t\\n\\nCALAME-PT is a PT benchmark composed of small texts (contexts) and their respective last words. \\nThese contexts should, in theory, contain enough information so that a human or a model is capable of guessing its last word - without being too specific and/or too ambiguous.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tComposition\\n\\t\\n\\nCALAME-PT is composed of 2 \\\"sets\\\" of data - handwritten and generated. \\n\\nHandwritten Set: contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NOVA-vision-language/calame-pt."},
  {"name":"gender-by-name","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/erickrribeiro/gender-by-name","creator_name":"Erick R. Ribeiro","creator_url":"https://huggingface.co/erickrribeiro","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Gender-by-Name\\\"\\n\\t\\n\\nThis dataset attributes first names to genders, giving counts and probabilities. It combines open-source government data from the US, UK, Canada, and Australia. The dataset is taken from UCI Machine Learning Repository\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\nThis dataset combines raw counts for first/given names of male and female babies in those time periods, and then calculates a probability for a name given the aggregate count.  Source datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/erickrribeiro/gender-by-name."},
  {"name":"FakeRecogna","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/recogna-nlp/FakeRecogna","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFakeRecogna\\n\\t\\n\\nFakeRecogna is a dataset comprised of real and fake news. The real news is not directly linked to fake news and vice-versa, which could lead to a biased classification. The news collection was performed by crawlers developed for mining pages of well-known and of great national importance agency news. The web crawlers were developed based on each analyzed webpage, where the extracted information is first separated into categories and then grouped by dates. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/FakeRecogna."},
  {"name":"FakeRecogna","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/recogna-nlp/FakeRecogna","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFakeRecogna\\n\\t\\n\\nFakeRecogna is a dataset comprised of real and fake news. The real news is not directly linked to fake news and vice-versa, which could lead to a biased classification. The news collection was performed by crawlers developed for mining pages of well-known and of great national importance agency news. The web crawlers were developed based on each analyzed webpage, where the extracted information is first separated into categories and then grouped by dates. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/FakeRecogna."},
  {"name":"mqnli","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SachinPatel248/mqnli","creator_name":"Patel","creator_url":"https://huggingface.co/SachinPatel248","description":"SachinPatel248/mqnli dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"bfc-test","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AugustoSavi/bfc-test","creator_name":"Augusto Savi","creator_url":"https://huggingface.co/AugustoSavi","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset de Exemplos para BFC-Script\\n\\t\\n\\nEste dataset cont√©m exemplos pr√°ticos de uso da linguagem bfc-script, organizados em pares de prompt e completion. Ele foi criado para ajudar desenvolvedores a entender e utilizar a linguagem em diversos cen√°rios, desde opera√ß√µes b√°sicas at√© funcionalidades mais avan√ßadas.\\n\\n\\t\\n\\t\\t\\n\\t\\tEstrutura do Dataset\\n\\t\\n\\nO dataset est√° no formato JSONL (JSON Lines), onde cada linha √© um objeto JSON com dois campos:\\n\\nprompt: Uma pergunta ou descri√ß√£o de um cen√°rio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AugustoSavi/bfc-test."},
  {"name":"AIME2025-Multilingual","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/fedric95/AIME2025-Multilingual","creator_name":"Federico Ricciuti","creator_url":"https://huggingface.co/fedric95","description":"\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nThis repository contains a multi language version of the AIME2025 dataset. \\nAs the english reference version, we haved used the one created by the authors of MathArena.\\nFor completness, we have included the english version also in this repository, please, refer to the one contained in the MathArena github repository for the original one (https://github.com/eth-sri/matharena/tree/main/data/aime). Many thanks to Jasper Dekoninck for the help in understanding the structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fedric95/AIME2025-Multilingual."},
  {"name":"Squad_PT","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/vitorandrade/Squad_PT","creator_name":"Vitor Pereira Andrade","creator_url":"https://huggingface.co/vitorandrade","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card para o SQuAD 1.1 em Portugu√™s Brasil\\n\\t\\n\\nO conjunto de dados \\\"Stanford Question Answering Dataset\\\" (SQuAD),\\npara tarefa de perguntas e respostas extrativas, foi desenvolvido em 2016. Ele utiliza perguntas geradas a partir de\\n536 artigos da Wikipedia* com mais de 100.000 linhas de dados. √â constru√≠do na forma de uma pergunta e um contexto dos artigos da\\nWikipedia contendo a resposta √† pergunta. [1]Originalmente este dataset foi constru√≠do no idioma ingl√™s, contudo, o‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vitorandrade/Squad_PT."},
  {"name":"inteligenciamultipla","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/giseldo/inteligenciamultipla","creator_name":"Giseldo Neo","creator_url":"https://huggingface.co/giseldo","description":"Resposta de estudante ao question√°rio que levanta o perfil de intelig√™ncia m√∫ltiplas.\\n"},
  {"name":"mosel","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description, Collection, and Source\\n\\t\\n\\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel."},
  {"name":"ementas_camarabr_1934_2024","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/belisards/ementas_camarabr_1934_2024","creator_name":"adriano","creator_url":"https://huggingface.co/belisards","description":"Collected at 26 Sept 2024\\n"},
  {"name":"librispeech_pt","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/murilo-as/librispeech_pt","creator_name":"Murilo Alvares Silva","creator_url":"https://huggingface.co/murilo-as","description":"murilo-as/librispeech_pt dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"estatuto","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/abelrh/estatuto","creator_name":"Abel Melo Borges","creator_url":"https://huggingface.co/abelrh","description":"abelrh/estatuto dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"product-database","license":"GNU Affero General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Food Facts Database\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is üçä Open Food Facts?\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tA food products database\\n\\t\\n\\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\\n\\n\\t\\n\\t\\t\\n\\t\\tMade by everyone\\n\\t\\n\\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database."},
  {"name":"test_4","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4."},
  {"name":"enunciados_pge_rj_orpo","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/celsowm/enunciados_pge_rj_orpo","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","description":"celsowm/enunciados_pge_rj_orpo dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"prompt-injection-multilingual","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/rikka-snow/prompt-injection-multilingual","creator_name":"Le Xuan Hoang","creator_url":"https://huggingface.co/rikka-snow","description":"rikka-snow/prompt-injection-multilingual dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"quinquilharia","license":"The Unlicense","language":"en","url":"https://huggingface.co/datasets/tallesl/quinquilharia","creator_name":"Talles L","creator_url":"https://huggingface.co/tallesl","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tQuinquilharia\\n\\t\\n\\nTextos variados em portugu√™s do Brasil.\\n\\n\\t\\n\\t\\t\\n\\t\\tF√≥runs\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nTema\\nLink do f√≥rum\\nDataset com scrap realizado\\n\\n\\n\\t\\t\\nAgility (esporte)\\nagilityrj.forumeiros.com\\nagilityrj.csv (~10 mil linhas)\\n\\n\\nArtes marciais\\nforum.bjjforum.com.br\\nbjjforum.csv (~318 mil linhas)\\n\\n\\nArtes marciais\\nufconfantasy.forumeiros.com\\nufconfantasy.csv (~120 mil linhas)\\nArtesanato\\natelierdasartes.forumeiros.com\\natelierdasartes.csv (~30 mil linhas)\\n\\n\\nArtesanato\\ndsmemories.forumeiros.com\\ndsmemories.csv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tallesl/quinquilharia."},
  {"name":"semeval-2025-task11-track-b","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track B Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track B, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 11 standard ISO codes\\nTotal examples: 47111\\nSplits: train, dev, test\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTrack Information\\n\\t\\n\\nTrack B has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b."},
  {"name":"multiCHILDES","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/IParraMartin/multiCHILDES","creator_name":"I√±igo Parra","creator_url":"https://huggingface.co/IParraMartin","description":"\\n\\t\\n\\t\\t\\n\\t\\tmultiCHILDES: Multilingual Child-Directed Speech Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains child-directed speech from 19 languages, extracted from the CHILDES corpus. The text has been cleaned and is designed for text generation tasks, particularly in studying early language acquisition.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nSource: CHILDES corpus\\nLanguages: 19 languages\\nText Type: Child-directed speech\\nTask: Text Generation, Language Modeling\\nData Processing: The dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IParraMartin/multiCHILDES."},
  {"name":"UFLA-FORMS","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Victorgonl/UFLA-FORMS","creator_name":"Victor Gon√ßalves Lima","creator_url":"https://huggingface.co/Victorgonl","description":"\\n\\t\\n\\t\\t\\n\\t\\tUFLA-FORMS: an Academic Forms Dataset for Information Extraction in the Portuguese Language\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tAbout\\n\\t\\n\\nUFLA-FORMS is a manually labeled dataset of document forms in Brazilian Portuguese extracted from the domains of the Federal University of Lavras (UFLA). The dataset emphasizes the hierarchical structure between the entities of a document through their relationships, in addition to the extraction of key-value pairs. Samples were labeled using ToolRI.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Victorgonl/UFLA-FORMS."},
  {"name":"wikipedia-pt-embeddings","license":"European Union Public License 1.1","language":"en","url":"https://huggingface.co/datasets/marquesafonso/wikipedia-pt-embeddings","creator_name":"Afonso Marques","creator_url":"https://huggingface.co/marquesafonso","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nA Wikipedia dataset using only the portuguese subset. An embeddings column is added to enable vector search. \\nThe dataset has been chunked using chonkie and sentence transformers (model: static-similarity-mrl-multilingual-v1)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: marquesafonso\\nLanguage(s) (NLP): Portuguese\\nLicense: eupl-1.1\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: wikimedia/wikipedia‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marquesafonso/wikipedia-pt-embeddings."},
  {"name":"oab_bench","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/felipeoes/oab_bench","creator_name":"Felipe Oliveira","creator_url":"https://huggingface.co/felipeoes","description":"\\n\\t\\n\\t\\t\\n\\t\\tOABench: Brazilian Bar Exams Benchmark Dataset\\n\\t\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nOABench is a benchmark dataset designed to evaluate the performance of Large Language Models (LLMs) on Brazilian legal exams. It is based on the Unified Bar Exam of the Brazilian Bar Association (OAB), a comprehensive and challenging exam required for law graduates to practice law in Brazil. This dataset provides a rigorous and realistic testbed for LLMs in the legal domain, covering a wide range of legal topics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/felipeoes/oab_bench."},
  {"name":"oab_bench","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/felipeoes/oab_bench","creator_name":"Felipe Oliveira","creator_url":"https://huggingface.co/felipeoes","description":"\\n\\t\\n\\t\\t\\n\\t\\tOABench: Brazilian Bar Exams Benchmark Dataset\\n\\t\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nOABench is a benchmark dataset designed to evaluate the performance of Large Language Models (LLMs) on Brazilian legal exams. It is based on the Unified Bar Exam of the Brazilian Bar Association (OAB), a comprehensive and challenging exam required for law graduates to practice law in Brazil. This dataset provides a rigorous and realistic testbed for LLMs in the legal domain, covering a wide range of legal topics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/felipeoes/oab_bench."},
  {"name":"M-ABSA","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tM-ABSA\\n\\t\\n\\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Description:\\n\\t\\n\\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\\nAll datasets are stored in the data/ folder:\\n\\nAll dataset contains 7 domains.\\n\\ndomains = [\\\"coursera\\\", \\\"hotel\\\", \\\"laptop\\\", \\\"restaurant\\\", \\\"phone\\\", \\\"sight\\\", \\\"food\\\"]\\n\\n\\nEach dataset contains 21 languages.\\n\\nlangs = [\\\"ar\\\", \\\"da\\\", \\\"de\\\", \\\"en\\\", \\\"es\\\", \\\"fr\\\", \\\"hi\\\", \\\"hr\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA."},
  {"name":"E-FAQ","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/GoBotsAI/E-FAQ","creator_name":"GoBots","creator_url":"https://huggingface.co/GoBotsAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tE-FAQ\\n\\t\\n\\nWe present the E-FAQ, a weakly-supervised dataset consisting of a collection of e-commerce frequently asked questions (FAQs). Each entry i of the\\ndataset is the pair (q_{i}, Q_{i}), in which q_{i} is an anchor question sentence and Q_{i} is a set of questions similar to the\\nanchor. All sentences are uttered in brazilian portuguese or spanish.\\n"},
  {"name":"TinyMarkdown-Instruct-PT","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/VAMJ-0042/TinyMarkdown-Instruct-PT","creator_name":"Vitor Augusto Machado Jorge","creator_url":"https://huggingface.co/VAMJ-0042","description":"\\n\\t\\n\\t\\t\\n\\t\\tMarkdown Fine-Tuning Datasets (English & PT-BR)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThese datasets are designed to fine-tune Large Language Models (LLMs) like Gemma to generate structured Markdown-formatted responses. The datasets contain instruction-response pairs, ensuring the model learns how to output Markdown elements correctly.\\n\\n\\t\\n\\t\\t\\n\\t\\tDatasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1. English Markdown Dataset\\n\\t\\n\\n\\nAvailable on Hugging Face: TinyMarkdown-Instruct-EN\\nSize: Large-scale dataset with structured Markdown‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VAMJ-0042/TinyMarkdown-Instruct-PT."},
  {"name":"dou-brazil-dataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/gerson-vfs/dou-brazil-dataset","creator_name":"Gerson Victor Vieira Fontenele da Silva","creator_url":"https://huggingface.co/gerson-vfs","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Di√°rio Oficial da Uni√£o (DOU)\\n\\t\\n\\n\\n\\nThe Di√°rio Oficial da Uni√£o (DOU) is the official government gazette of Brazil, published by the National Press. It serves as the primary means of communication for federal government acts, including laws, decrees, ordinances, public notices, and other official decisions. The DOU ensures transparency and legal validity for government actions and is divided into three sections:  \\n\\nSection 1: Publishes laws, decrees, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gerson-vfs/dou-brazil-dataset."},
  {"name":"blogsetbr","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/tallesl/blogsetbr","creator_name":"Talles L","creator_url":"https://huggingface.co/tallesl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBlogSet-BR\\n\\t\\n\\nReprodu√ß√£o do dataset BlogSet-BR criado pela universidade PUCRS.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Original\\n\\t\\n\\nO dataset original (sem modifica√ß√µes) encontra-se em blogsetbr-original.csv (7.477.853\\nregistros).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Modificado\\n\\t\\n\\nUma c√≥pia modificada do dataset pode ser encontrada em blogsetbr-modificado.csv (7.468.541\\nregistros). Foi modificado:\\n\\nRemo√ß√£o de registros duplicados e com problemas de escape (9.312 registros removidos).\\nAdicionado um cabe√ßalho ao arquivo.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tallesl/blogsetbr."},
  {"name":"Wikipedia-Abstract","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/laion/Wikipedia-Abstract","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"Wikipedia Abstract\\n\\n\\n  \\n\\n\\n\\nIntroducing Wikipedia Abstract, a comprehensive dataset encompassing abstracts, complete articles, and a popularity score index for both widely spoken and lesser-known Wikipedia subsets. Our dedication to Wikipedia-X ensures a centralized Wikipedia dataset that undergoes regular updates and adheres to the highest standards.\\nA central focus of our efforts was to include exotic languages that often lack up-to-date Wikipedia dumps or may not have any dumps at all.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laion/Wikipedia-Abstract."},
  {"name":"ordem_paranormal_QA","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/thnbi/ordem_paranormal_QA","creator_name":"Renato Freitas","creator_url":"https://huggingface.co/thnbi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Ordem Paranormal: Enigma do Medo\\n\\t\\n\\nDataset para o modelo thnbi/magistrada\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescri√ß√£o\\n\\t\\n\\nEste dataset cont√©m pares de instru√ß√£o-resposta baseados no universo do jogo \\\"Enigma do Medo\\\", parte do sistema de RPG Ordem Paranormal. Os dados foram extra√≠dos e curados a partir da Wiki oficial do Ordem Paranormal.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tConte√∫do\\n\\t\\n\\n\\nPerguntas e respostas sobre localiza√ß√µes do jogo\\nInforma√ß√µes sobre mec√¢nicas e sistemas\\nDetalhes sobre a narrativa e lore\\nOrienta√ß√µes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thnbi/ordem_paranormal_QA."},
  {"name":"Saudades_da_terra","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Verotic/Saudades_da_terra","creator_name":"Adriano","creator_url":"https://huggingface.co/Verotic","description":"Verotic/Saudades_da_terra dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"webfaq","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\\n\\n   \\n       Overview |\\n       Details  |\\n       Structure  |\\n       Examples |\\n       Considerations |\\n       License |\\n       Citation |\\n       Contact |\\n       Acknowledgement\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq."},
  {"name":"xtreme","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xtreme\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme."},
  {"name":"toxi-text-3M","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\\n\\n\\t\\n\\t\\t\\n\\nToxic\\nNeutral\\nTotal\\n\\n\\n\\t\\t\\nmultilingual-train-deduplicated.csv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M."},
  {"name":"belebele","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\\n\\t\\n\\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele."},
  {"name":"librivox-tracks","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\n"},
  {"name":"multilingual-pl-bert","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\\n"},
  {"name":"sib200","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200."},
  {"name":"aya_dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_dataset","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\n\\nCurated by: Contributors of Aya Open Science Intiative.\\n\\nLanguage(s): 65 languages (71 including dialects &‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_dataset."},
  {"name":"aya_collection","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_collection","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection."},
  {"name":"aya_evaluation_suite","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\\n\\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\\nmachine-translations of handpicked examples into 101 languages ‚Üí‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite."},
  {"name":"CulturaY","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \\nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \\nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY."},
  {"name":"aya_collection_language_split","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_collection_language_split","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection_language_split."},
  {"name":"GlotCC-V1","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
  {"name":"GlotCC-V1","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
  {"name":"muri-it","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it."},
  {"name":"HPLT2.0_cleaned","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned."},
  {"name":"belebele-fleurs","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBelebele-Fleurs\\n\\t\\n\\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\\n\\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs."},
  {"name":"sib-fleurs","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs."},
  {"name":"2M-Belebele","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2M-Belebele\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\\n\\t\\n\\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \\nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele."},
  {"name":"reranker_continuous_filt_max7_train","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReranker training data\\n\\t\\n\\nThis data was generated using 4 steps:\\n\\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \\\"1\\\", \\\"2\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train."},
  {"name":"degeneration-html-multilingual","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe Degeneration of the Nation Multilingual Dataset\\n\\t\\n\\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual."},
  {"name":"Synthdog-Multilingual-100","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthdog Multilingual\\n\\t\\n\\n\\n\\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100."},
  {"name":"smol","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tSMOL\\n\\t\\n\\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\\ntranslations into 221 Low-Resource Languages, for the purpose of training\\ntranslation models, and otherwise increasing the representations of said\\nlanguages in NLP and technology.\\nPlease read the SMOL Paper and the\\nGATITOS Paper for a much more\\nthorough description!\\nThere are four resources in this directory:\\n\\nSmolDoc: document-level translations into 100 languages\\nSmolSent: sentence-level translations into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/smol."},
  {"name":"high-quality-multilingual-sentences","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tHigh Quality Multilingual Sentences\\n\\t\\n\\n\\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\\n\\nExample row (from the all config):\\n{\\n    \\\"text\\\": \\\"ÿßŸÖÿßŸÖ ÿ¨ŸÖÿπŸá ÿßÿµŸÅŸáÿßŸÜ ⁄ØŸÅÿ™: ŸÖ€åÿ≤ÿßŸÜ ŸÜ€åÿßÿ≤ ÿ¢ÿ® ÿ¥ÿ±ÿ® ÿßÿµŸÅŸáÿßŸÜ €±€±.€µ ŸÖÿ™ÿ± ŸÖ⁄©ÿπÿ® ÿßÿ≥ÿ™ ⁄©Ÿá ÿ™ŸÖÿßŸÖ ÿßÿ≥ÿ™ÿßŸÜ ÿßÿµŸÅŸáÿßŸÜ ÿ±ÿß ŸæŸàÿ¥ÿ¥ ŸÖ€åÿØŸáÿØ Ÿà ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸÇÿ®ŸÑ ÿßÿ≤ ÿßŸÜŸÇŸÑÿßÿ® €å⁄©€å ÿßÿ≤ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿáÿß ÿØÿ± ÿ≠Ÿàÿ≤Ÿá ÿ¢ÿ® ÿ®ŸàÿØŸá ÿßÿ≥ÿ™.\\\",\\n    \\\"fasttext\\\": \\\"fa\\\",\\n    \\\"gcld3\\\": \\\"fa\\\"\\n}\\n\\nFields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences."},
  {"name":"wikipedia_quality_wikirank","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy It‚Äôs Important\\n\\t\\n\\n\\nEnhances Trust: For readers and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank."},
  {"name":"multilingual_translation_sft","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"opus_ubuntu","license":"BSD 3-Clause \"New\" or \"Revised\" License","language":"en","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu."},
  {"name":"flores_101","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
  {"name":"wit_base","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base."},
  {"name":"HashtagPrediction","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\\n\\t\\n\\n  \\nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \\n[arXiv]\\n[HuggingFace Models]\\n[Github repo]\\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDownload\\n\\t\\n\\nUse the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction."},
  {"name":"IRIS_sts","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/stjiris/IRIS_sts","creator_name":"Sumariza√ß√£o e Informa√ß√£o de decis√µes: Aplica√ß√£o de T√©cnicas de Intelig√™ncia Artificial no Supremo Tribunal de Justi√ßa (IRIS)","creator_url":"https://huggingface.co/stjiris","description":"\\n\\nWork developed as part of Project IRIS.\\nThesis: A Semantic Search System for Supremo Tribunal de Justi√ßa\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Legal Sentences\\n\\t\\n\\nCollection of Legal Sentences pairs from the Portuguese Supreme Court of Justice\\nThe goal of this dataset was to be used for Semantic Textual Similarity\\n\\nValues from 0-1: random sentences across documents\\nValues from 2-4: sentences from the same summary (implying some level of entailment)\\nValues from 4-5: sentences pairs generated through OpenAi'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stjiris/IRIS_sts."},
  {"name":"told_br_binary_sm","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/inctdd/told_br_binary_sm","creator_name":"Instituto Nacional de Ci√™ncia e Tecnologia em Democracia Digital","creator_url":"https://huggingface.co/inctdd","description":"This dataset is a random 1/3 slice of the original told-br\\n"},
  {"name":"flores_101","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
  {"name":"xP3x-sample","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities."},
  {"name":"wikianc","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc."},
  {"name":"entity_cs","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EntityCS\\n\\t\\n\\n\\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \\nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \\nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \\nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs."},
  {"name":"gpt4all-j-prompt-generations-pt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/pablo-moreira/gpt4all-j-prompt-generations-pt","creator_name":"Pablo Filetti Moreira","creator_url":"https://huggingface.co/pablo-moreira","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"gpt4all-j-prompt-generations-pt\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCopy translated into Portuguese of the dataset gpt4all_prompt_generations using the googletrans library.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTranslate\\n\\t\\n\\ntranslate_dataset.ipynb\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\ndataset_usage.ipynb\\n"},
  {"name":"udhr-lid","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUDHR-LID\\n\\t\\n\\nWhy UDHR-LID?\\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \\\"missing\\\" or \\\"?\\\". Also, about 1/3 of the sentences consist only of \\\"articles 1-30\\\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid."},
  {"name":"Multi-EuP","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/unimelb-nlp/Multi-EuP","creator_name":"The University of Melbourne","creator_url":"https://huggingface.co/unimelb-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNOTES FOR DOWNLOAD!\\n\\t\\n\\n\\nHighly recommend downloading it via the API:\\n\\ncurl -X GET \\\\\\n     \\\"https://datasets-server.huggingface.co/first-rows?dataset=unimelb-nlp%2FMulti-EuP&config=default&split=full\\\"\\n\\n\\nIf you are using the HuggingFace library, please follow these steps:\\n\\npip install datasets\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"unimelb-nlp/Multi-EuP\\\", keep_default_na=False)\\n\\nNote: It's crucial to use keep_default_na=False because some datasets contain 'null'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unimelb-nlp/Multi-EuP."},
  {"name":"rebel_portuguese","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/grsilva/rebel_portuguese","creator_name":"Gabriel Silva","creator_url":"https://huggingface.co/grsilva","description":"This is a dataset that was created to re-train REBEL to work better for the Portuguese language.\\nThis dataset was generated using CROCODILE, which was adapted to use a Portuguese specific model (pt_core_news_sm) instead of their default multi-language model (xx_ent_wiki_sm).\\nThe dataset comes with a train, test, dev and train_dev splits. The train_dev split accounts for 80% of the dataset with the remaining 20% being the training data. The train and dev split was generated from the 80%‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/grsilva/rebel_portuguese."},
  {"name":"seamless-align","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to use the data\\n\\t\\n\\nThere are two ways to access the data:\\n\\nVia the Hugging Face Python datasets library\\n\\nScripts coming soon‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align."},
  {"name":"isaaa","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lz0kzs/isaaa","creator_name":"luiz","creator_url":"https://huggingface.co/lz0kzs","description":"lz0kzs/isaaa dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"openassistant-falcon","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant Falcon\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using '\\\\Human:' AND '\\\\nAssistant:' to wrap user messages.\\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\\nSample \\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon."},
  {"name":"qa_hotel_dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nova-sqoin/qa_hotel_dataset","creator_name":"nova","creator_url":"https://huggingface.co/nova-sqoin","description":"nova-sqoin/qa_hotel_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"cnn_news_ptbr","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/celsowm/cnn_news_ptbr","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"cnn_news_ptbr\\\"\\n\\t\\n\\nMore Information needed\\n"},
  {"name":"adoro_cinema_filmes","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/celsowm/adoro_cinema_filmes","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"adoro_cinema_filmes\\\"\\n\\t\\n\\nMore Information needed\\n"},
  {"name":"hotel_dataset_llama2","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nova-sqoin/hotel_dataset_llama2","creator_name":"nova","creator_url":"https://huggingface.co/nova-sqoin","description":"nova-sqoin/hotel_dataset_llama2 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"mapa-eur-lex","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/dglover1/mapa-eur-lex","creator_name":"D Glover","creator_url":"https://huggingface.co/dglover1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a completed version of the MAPA EUR-LEX dataset, originally converted to Huggingface format by joelniklaus. See the dataset card for more information about MAPA.\\n3 of the (Spanish) EUR-LEX WebAnno TSV files in the source MAPA repository are malformed, so they were omitted from the original conversion, causing under-representation of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dglover1/mapa-eur-lex."},
  {"name":"lr-sum","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LR-Sum\\n\\t\\n\\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \\nThe data is based on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum."},
  {"name":"hotel_dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nova-sqoin/hotel_dataset","creator_name":"nova","creator_url":"https://huggingface.co/nova-sqoin","description":"nova-sqoin/hotel_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"cabrita-guanaco-dataset-52k","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/f7lipe/cabrita-guanaco-dataset-52k","creator_name":"FIlipe Correia","creator_url":"https://huggingface.co/f7lipe","description":"f7lipe/cabrita-guanaco-dataset-52k dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"re_dial_ptbr","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/matheusrdgsf/re_dial_ptbr","creator_name":"Matheus Rodrigues de Souza F√©lix","creator_url":"https://huggingface.co/matheusrdgsf","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ReDial - PTBR\\n\\t\\n\\n\\nOriginal dataset: Redial Huggingface\\nHomepage: ReDial Dataset\\nRepository: ReDialData\\nPaper: Towards Deep Conversational Recommendations\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe ReDial (Recommendation Dialogues) PTBR dataset is an annotated collection of dialogues where users recommend movies to each other translated to brazilian portuguese.\\nThe adapted version of this dataset in Brazilian Portuguese was translated by the Maritalk. This translated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/matheusrdgsf/re_dial_ptbr."},
  {"name":"ProfessorHeidelTime","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hugosousa/ProfessorHeidelTime","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProfessor HeidelTime\\n\\t\\n\\nPaper    GitHub\\nProfessor HeidelTime is a project to create a multilingual corpus weakly labeled with HeidelTime, a temporal tagger.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpus Details\\n\\t\\n\\nThe weak labeling was performed in six languages. Here are the specifics of the corpus for each language:\\n\\n\\t\\n\\t\\t\\nDataset\\nLanguage\\nDocuments\\nFrom\\nTo\\nTokens\\nTimexs\\n\\n\\n\\t\\t\\nAll the News 2.0\\nEN\\n24,642\\n2016-01-01\\n2020-04-02\\n18,755,616\\n254,803\\n\\n\\nItalian Crime News\\nIT\\n9,619\\n2011-01-01\\n2021-12-31\\n3,296,898\\n58‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hugosousa/ProfessorHeidelTime."},
  {"name":"cosmos_qa_ptbr","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/heloisy/cosmos_qa_ptbr","creator_name":"Heloisy Rodrigues","creator_url":"https://huggingface.co/heloisy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCosmos QA Portugu√™s\\n\\t\\n\\nEste dataset √© uma tradu√ß√£o para portugu√™s do Cosmos QA, que originalmente √© na l√≠ngua inglesa. \\nA tradu√ß√£o foi feita automaticamente usando o GPT-3.5-turbo, logo pode ter erros que n√£o foram notados numa an√°lise superficial. \\nSe atente ao uso.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for cosmos_qa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC BY 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation INformation\\n\\t\\n\\n@inproceedings{huang-etal-2019-cosmos‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/heloisy/cosmos_qa_ptbr."},
  {"name":"Propbank-BR","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/liaad/Propbank-BR","creator_name":"LIAAD, INESCTEC","creator_url":"https://huggingface.co/liaad","description":"Problem in line 20727 with \\\\t missing\\n"},
  {"name":"Bosque_PT-PT","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/liaad/Bosque_PT-PT","creator_name":"LIAAD, INESCTEC","creator_url":"https://huggingface.co/liaad","description":"liaad/Bosque_PT-PT dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"uner_llm_instructions","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/universalner/uner_llm_instructions","creator_name":"Universal NER","creator_url":"https://huggingface.co/universalner","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Universal NER v1 in the Aya format\\n\\t\\n\\nThis dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the same CC-BY-SA 4.0 license and conditions.\\nIt contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.\\nThe dataset contains different subsets and their dev/test/train splits, depending on language. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you utilize this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/universalner/uner_llm_instructions."},
  {"name":"uner_llm_inst_portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/universalner/uner_llm_inst_portuguese","creator_name":"Universal NER","creator_url":"https://huggingface.co/universalner","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Universal NER v1 in the Aya format - Portuguese subset\\n\\t\\n\\nThis dataset is a format conversion for the Portuguese data in the original Universal NER v1 into the Aya instruction format and it's released here under the same CC-BY-SA 4.0 license and conditions.\\nThe dataset contains different subsets and their dev/test/train splits, depending on language. For more details, please refer to:\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nFor the original Universal NER dataset v1 and more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/universalner/uner_llm_inst_portuguese."},
  {"name":"ntx_llm_instructions","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format\\n\\t\\n\\nThis dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license and conditions.\\nIt contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you utilize this dataset version, feel free to cite/footnote this huggingface dataset repo, but please also cite the original dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions."},
  {"name":"ntx_llm_inst_portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_portuguese","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format - Portuguese subset\\n\\t\\n\\nThis dataset is a format conversion for the Portuguese data from the original NTX into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nFor the original NTX dataset, the conversion to the Aya instructions format, or more details, please refer to the full dataset in instruction form (https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions) or to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_portuguese."},
  {"name":"TuPY_dataset_multilabel","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/victoriadreis/TuPY_dataset_multilabel","creator_name":"Victoria Reis","creator_url":"https://huggingface.co/victoriadreis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Hate Speech Dataset (TuPy)\\n\\t\\n\\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) and natural language processing (NLP) techniques. TuPy is formed by 10000 thousand unpublished annotated tweets collected in 2023.\\nThis repository is organized as follows:\\nroot.\\n    ‚îú‚îÄ‚îÄ annotations   : classification given by annotators\\n    ‚îú‚îÄ‚îÄ raw corpus    : dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/victoriadreis/TuPY_dataset_multilabel."},
  {"name":"TuPY_dataset_binary","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/victoriadreis/TuPY_dataset_binary","creator_name":"Victoria Reis","creator_url":"https://huggingface.co/victoriadreis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Hate Speech Dataset (TuPy)\\n\\t\\n\\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) and natural language processing (NLP) techniques. TuPy is formed by 10000 thousand unpublished annotated tweets collected in 2023.\\nThis repository is organized as follows:\\nroot.\\n    ‚îú‚îÄ‚îÄ annotations   : classification given by annotators\\n    ‚îú‚îÄ‚îÄ raw corpus    : dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/victoriadreis/TuPY_dataset_binary."},
  {"name":"TuPy-Dataset","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Hate Speech Dataset (TuPy)\\n\\t\\n\\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) \\nand natural language processing (NLP) techniques. TuPy is comprised of 10,000 (ten thousand) unpublished, annotated, and anonymized documents collected \\non Twitter (currently known as X) in 2023. \\nThis repository is organized as follows:\\nroot.\\n    ‚îú‚îÄ‚îÄ binary     : binary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset."},
  {"name":"FAQ_BACEN","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/paulofinardi/FAQ_BACEN","creator_name":"paulo","creator_url":"https://huggingface.co/paulofinardi","description":"This dataset was the used in the paper https://arxiv.org/abs/2311.11331\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlicense: apache-2.0\\n\\t\\n\\n"},
  {"name":"TuPyE-Dataset","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Hate Speech Expanded Dataset (TuPyE)\\n\\t\\n\\nTuPyE, an enhanced iteration of TuPy, encompasses a compilation of 43,668 meticulously annotated documents specifically \\nselected for the purpose of hate speech detection within diverse social network contexts. \\nThis augmented dataset integrates supplementary annotations and amalgamates with datasets sourced from \\nFortuna et al. (2019), \\nLeite et al. (2020), \\nand Vargas et al. (2022),\\ncomplemented by an infusion of 10,000 original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset."},
  {"name":"prompt_injections","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/yanismiraoui/prompt_injections","creator_name":"Yanis Miraoui","creator_url":"https://huggingface.co/yanismiraoui","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Prompt Injections by  Yanis Miraoui  üëã\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset of prompt injections enriches Large Language Models (LLMs) by providing task-specific examples and prompts, helping improve LLMs' performance and control their behavior.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains over 1000 rows of prompt injections in multiple languages. It contains examples of prompt injections using different techniques such as: prompt leaking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yanismiraoui/prompt_injections."},
  {"name":"oasst2_top1_chat_format","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\\n\\t\\n\\nExport of oasst2 only top 1 threads in huggingface chat format\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScript\\n\\t\\n\\nThe convert script can be find here\\n"},
  {"name":"harem","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/arubenruben/harem","creator_name":"R√∫ben Almeida","creator_url":"https://huggingface.co/arubenruben","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for HAREM\\n\\t\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): pt\\nLicense: cc-by-4.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More Information Needed]\\nDemo [optional]: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arubenruben/harem."},
  {"name":"aes_enem_dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kamel-usp/aes_enem_dataset","creator_name":"KAMeL USP","creator_url":"https://huggingface.co/kamel-usp","description":"\\n\\t\\n\\t\\t\\n\\t\\tAutomated Essay Score (AES) ENEM Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tUse Case and Creators\\n\\t\\n\\n\\nIntended Use: Estimate Essay Score\\nCreators: Igor Cataneo Silveira, Andr√© Barbosa and Denis Deratani Mau√°\\nContact Information:  igorcs@ime.usp.br; andre.barbosa@ime.usp.br\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLicensing Information\\n\\t\\n\\n\\nLicense: MIT License\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation Details\\n\\t\\n\\n\\nPreferred Citation:\\n\\n@proceedings{DBLP:conf/propor/2024,\\n  editor       = {Igor Cataneo Silveira, Andr√© Barbosa and Denis Deratani Mau√°},\\n  title        =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kamel-usp/aes_enem_dataset."},
  {"name":"TCC","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/Kashmir96/TCC","creator_name":"Thierry Braga","creator_url":"https://huggingface.co/Kashmir96","description":"Kashmir96/TCC dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"instruct-aira-dataset-v3","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v3","creator_name":"Nicholas Kluge Corr√™a","creator_url":"https://huggingface.co/nicholasKluge","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInstruct-Aira Dataset version 3.0\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains a collection of multi-turn conversations between an assistant and a user. Conversations were generated by user interactions with already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc). The dataset is available in Portuguese and English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v3."},
  {"name":"oaast_rm_full_jieba","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"Â∞ùËØïËß£ÂÜ≥\\\"llm repetition problem\\\"Ôºå‰ΩøÁî®ÂàÜËØçÊ®°ÂûãÂØπoaastËØ≠ÊñôËøõË°å‚ÄúÁªìÂ∑¥Âåñ‚ÄùÊï∞ÊçÆÂ¢ûÂº∫ÔºåÊèê‰æõÊõ¥Âº∫ÁöÑÈáçÂ§çÂÜÖÂÆπÊãíÁªùÊïàÊûú„ÄÇ\\nAttempts to solve the \\\"llm repetition problem\\\" by using a segmentation model to enhance the oaast corpus with \\\"stuttering\\\" data to provide stronger rejection of duplicate content.\\nÂÖ∂Ê¨°ÔºåËøòËøáÊª§Êéâ‰∫ÜÊâÄÊúâËá™ÊàëËÆ§Áü•ÁöÑÂæÆË∞ÉÊ†∑Êú¨„ÄÇ\\nSecond, it also filters out all the fine-tuned samples of self-cognition.\\nfiles:\\n\\noaast_rm_full_jieba.jsonl : word level repeat\\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\\n\\n"},
  {"name":"sentiment-analysis-pt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AiresPucrs/sentiment-analysis-pt","creator_name":"AI Robotics Ethics Society (PUCRS)","creator_url":"https://huggingface.co/AiresPucrs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentiment Analysis PT (Teeny-Tiny Castle)\\n\\t\\n\\nThis dataset is part of a tutorial tied to the Teeny-Tiny Castle, an open-source repository containing¬†educational tools for AI Ethics and Safety research. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"AiresPucrs/sentiment-analysis-pt\\\", split = 'train')\\n\\n"},
  {"name":"language-dataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","description":"\\n"},
  {"name":"InferBR","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hapaxlegomenon/InferBR","creator_name":"Matheus Westhelle","creator_url":"https://huggingface.co/hapaxlegomenon","description":"\\n\\t\\n\\t\\t\\n\\t\\tInferBR\\n\\t\\n\\nThis is the InferBR dataset for Natural Language Inference in Portuguese. This version removes the flagged low-quality samples from the original dataset,\\nkeeping 10.528 samples. The Github repo with the raw data can be found at: https://github.com/lbencke/InferBR.\\n\\n\\t\\n\\t\\t\\n\\t\\tColumns\\n\\t\\n\\nsentence_pair_id: Identifier for premise-hypothesis sentence pairs.\\npremise: The premise sentence.\\nhypothesis: The hypothesis sentence.\\nlabel: The generated label for the hypothesis considering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hapaxlegomenon/InferBR."},
  {"name":"brwac","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bfunicheli/brwac","creator_name":"Funicheli","creator_url":"https://huggingface.co/bfunicheli","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BrWaC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe BrWaC (Brazilian Portuguese Web as Corpus) is a large corpus constructed following the Wacky framework, \\nwhich was made public for research purposes. The current corpus version, released in January 2017, is composed by \\n3.53 million documents, 2.68 billion tokens and 5.79 million types. Please note that this resource is available \\nsolely for academic research purposes, and you agreed not to use it for any commercial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bfunicheli/brwac."},
  {"name":"megawika-report-generation","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika for Report Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. \\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation."},
  {"name":"Rhulk_pt-br","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/satierf/Rhulk_pt-br","creator_name":"thiago freitas pimenta","creator_url":"https://huggingface.co/satierf","description":"satierf/Rhulk_pt-br dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Portuguese-English-Vocab-PartiallyTransformed","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Solshine/Portuguese-English-Vocab-PartiallyTransformed","creator_name":"Caleb DeLeeuw","creator_url":"https://huggingface.co/Solshine","description":"Notes on use:\\nPortuguese and English Translations of readme are available here.\\nPartially cleaned and reorganized. Minimal secondhand verification after generation through Google Bard on November 28th 2023. Mistakes are minimal but present, such as tagging of words in supplemental information sometimes using the whole word (ie Noun) and sometimes only a letter or abreviation (ie N) for the same part of speech.\\nReccomended for finetuning of smaller models only, such as 12, 7, or 3 B models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Solshine/Portuguese-English-Vocab-PartiallyTransformed."},
  {"name":"Pontoon-Translations","license":"Mozilla Public License 2.0","language":"en","url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations."},
  {"name":"mswc_fscil_subset","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset","creator_name":"NeuroBench","creator_url":"https://huggingface.co/NeuroBench","description":"This is a subset of the Multilingual Spoken Word Corpus dataset, which is built specifically for the Few-shot Class-incremental Learning (FSCIL) task. \\nA total of 15 languages are chosen, split into 5 base languages (English, German, Catalan, French, Kinyarwanda) and 10 incrementally learned languages (Persian, Spanish, Russian, Welsh, Italian, Basque, Polish, Esparanto, Portuguese, Dutch).\\nThe FSCIL task entails first training a model using abundant training data on words from the 5 base‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset."},
  {"name":"HisaSoft","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Hisasartori/HisaSoft","creator_name":"Hisa Sartori ","creator_url":"https://huggingface.co/Hisasartori","description":"Hisasartori/HisaSoft dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"language_tags","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"Fran√ßais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog convention‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags."},
  {"name":"Deltacorpus_1.1","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, Portoro≈æ, Slovenia).\\nChanges in version 1.1: \\n\\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \\n\\nSVM classifier trained on Universal Dependencies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1."},
  {"name":"linkedin-industry-list","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/fantastic-jobs/linkedin-industry-list","creator_name":"Fantastic.jobs","creator_url":"https://huggingface.co/fantastic-jobs","description":"fantastic-jobs/linkedin-industry-list dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"MMMLU","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLU‚Äôs test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU."},
  {"name":"English-PTBR","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Dexavator/English-PTBR","creator_name":"VICTOR DE ALENCAR DELGADO","creator_url":"https://huggingface.co/Dexavator","description":"Dexavator/English-PTBR dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"zenith_ai_305","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/alvemoans/zenith_ai_305","creator_name":"moans alvs","creator_url":"https://huggingface.co/alvemoans","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLegal Data Analysis Dataset\\n\\t\\n\\nThis dataset contains legal statements, analyses, and judgments primarily related to labor law and contract law, drawn from various cases and legal interpretations. It includes text entries with factual descriptions, legal arguments, and conclusions based on judicial decisions, as well as instructions related to interpreting those facts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThe dataset is structured as a series of legal paragraphs and corresponding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alvemoans/zenith_ai_305."},
  {"name":"multicultural-wvs-alignment","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ryzzlestrizzle/multicultural-wvs-alignment","creator_name":"Jonathan Rystr√∏m","creator_url":"https://huggingface.co/ryzzlestrizzle","description":"ryzzlestrizzle/multicultural-wvs-alignment dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"V1Q","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q."},
  {"name":"PleIAs-ToxicCommons","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tPleIAs/ToxicCommons\\n\\t\\n\\nThis dataset is a refined version of the PleIAs/ToxicCommons collection, focusing on historical texts labeled for content that may be considered objectionable by modern standards (what the authors of the dataset deem \\\"toxic\\\"). \\nThe cleaned dataset contains 1‚Äâ051‚Äâ027 rows, each representing a text sample with associated toxicity scores across five dimensions:\\n\\nRace and origin-based bias\\nGender and sexuality-based bias\\nReligious bias\\nAbility bias\\nViolence and abuse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons."},
  {"name":"chatgptex","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AstatonnCorp/chatgptex","creator_name":"Astatonn Corp","creator_url":"https://huggingface.co/AstatonnCorp","description":"\\n\\t\\n\\t\\t\\n\\t\\tImportant\\n\\t\\n\\nPlease, remember to cite the author.\\nName: Lucas Lima (Astatonn)\\nSocial: https://astatonn.com\\n"},
  {"name":"RePro-categories-multilabel","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/higopires/RePro-categories-multilabel","creator_name":"Higo Felipe Silva Pires","creator_url":"https://huggingface.co/higopires","description":"\\n\\t\\n\\t\\t\\n\\t\\tRePro: A Benchmark Dataset for Opinion Mining in Brazilian Portuguese\\n\\t\\n\\nRePro, which stands for \\\"REview of PROducts,\\\" is a benchmark dataset for opinion mining in Brazilian Portuguese. It consists of 10,000 humanly annotated e-commerce product reviews, each labeled with sentiment and topic information. The dataset was created based on data from one of the largest Brazilian e-commerce platforms, which produced the B2W-Reviews01 dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/higopires/RePro-categories-multilabel."},
  {"name":"HateBR","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/franciellevargas/HateBR","creator_name":"Francielle Vargas","creator_url":"https://huggingface.co/franciellevargas","description":"\\n\\t\\n\\t\\t\\n\\t\\tHateBR: The Evaluation Benchmark for Brazilian Portuguese Hate Speech Detection\\n\\t\\n\\nHateBR is the first large-scale, expert-annotated dataset of Brazilian Instagram comments specifically designed for hate speech detection on the web and social media. The dataset was collected from Brazilian Instagram comments made by politicians and manually annotated by specialists.\\nIt contains 7,000 documents, annotated across three distinct layers:\\nBinary classification (offensive vs. non-offensive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/franciellevargas/HateBR."},
  {"name":"MOL","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/franciellevargas/MOL","creator_name":"Francielle Vargas","creator_url":"https://huggingface.co/franciellevargas","description":"\\n\\t\\n\\t\\t\\n\\t\\tMOL - Context-Aware Multilingual Offensive Lexicon\\n\\t\\n\\nThe MOL is the first specialized lexicon for hate speech detection, annotated with contextual information.\\nIt consists of 1,000 explicit and implicit (clue-based) human-annotated rationales used with pejorative connotations, manually identified by a linguist and annotated by three experts regarding their contextual dependency (context-dependent or context-independent).\\nFor example, the term \\\"stupid\\\" is classified as a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/franciellevargas/MOL."},
  {"name":"multilingual_translation_gen_binarized","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"brazilian-news-articles","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/maikerdr/brazilian-news-articles","creator_name":"reis","creator_url":"https://huggingface.co/maikerdr","description":"maikerdr/brazilian-news-articles dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"HPLT2.0_cleaned","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned."}
];
