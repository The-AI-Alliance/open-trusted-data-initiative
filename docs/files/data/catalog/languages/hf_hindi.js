var data_for_hindi = [

  {"name":"mittens","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/google/mittens","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMiTTenS: A Dataset for Evaluating Misgendering in Translation\\n\\t\\n\\nMisgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scripts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/mittens."},
  {"name":"mC4-Hindi-Cleaned","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zicsx/mC4-Hindi-Cleaned","creator_name":"Satish Kumar Mishra","creator_url":"https://huggingface.co/zicsx","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"mC4-Hindi-Cleaned\\\"\\n\\t\\n\\nMore Information needed\\n"},
  {"name":"Indic-subtitler-audio_evals","license":"GNU General Public License v2.0","language":"en","url":"https://huggingface.co/datasets/kurianbenoy/Indic-subtitler-audio_evals","creator_name":"Kurian Benoy","creator_url":"https://huggingface.co/kurianbenoy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIndic_audio_evals\\n\\t\\n\\nAs part of this project. We are evaluating our performance of various ASR models as well\\nin a benchmarking dataset, we have created in various languages. This benchmarking dataset\\nis more alligned to real-world use-cases rather than having any academic datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout Dataset\\n\\t\\n\\n\\nDataset Link in HuggingFace: kurianbenoy/Indic-subtitler-audio_evals\\n\\nThis dataset contains audio file in .wav format and video file in .mp4. The respective groundtruth‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kurianbenoy/Indic-subtitler-audio_evals."},
  {"name":"hind-promo","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/thinkedgeAI/hind-promo","creator_name":"ThinkEdge AI lAB","creator_url":"https://huggingface.co/thinkedgeAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card: Hindi Narrative Prompt Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of over 45,000 rows of Hindi language data, serving as a valuable resource for training and evaluating natural language generation models, particularly in the Hindi language domain. Each row contains the following fields:\\n\\nsystem_prompt: A detailed prompt provided in Hindi, intended to guide the generation of narratives or explanations.\\nqas_id: Unique identifier for each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thinkedgeAI/hind-promo."},
  {"name":"Hindi-Instruct-Gemma-Prompt-formate","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CognitiveLab/Hindi-Instruct-Gemma-Prompt-formate","creator_name":"CL","creator_url":"https://huggingface.co/CognitiveLab","description":"CognitiveLab/Hindi-Instruct-Gemma-Prompt-formate dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Hindi-Instruct-Gemma-Prompt-formate","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CognitiveLab/Hindi-Instruct-Gemma-Prompt-formate","creator_name":"CL","creator_url":"https://huggingface.co/CognitiveLab","description":"CognitiveLab/Hindi-Instruct-Gemma-Prompt-formate dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"truthfulqa_indic","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/vakyansh/truthfulqa_indic","creator_name":"Vakyansh","creator_url":"https://huggingface.co/vakyansh","description":"Original Repository\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTasks (from original repository)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneration (main task):\\n\\t\\n\\nTask: Given a question, generate a 1-2 sentence answer.\\nObjective: The primary objective is overall truthfulness, expressed as the percentage of the model's answers that are true. Since this can be gamed with a model that responds \\\"I have no comment\\\" to every question, the secondary objective is the percentage of the model's answers that are informative.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFuture Work:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vakyansh/truthfulqa_indic."},
  {"name":"mC4-Hindi-Cleaned-2.0","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zicsx/mC4-Hindi-Cleaned-2.0","creator_name":"Satish Kumar Mishra","creator_url":"https://huggingface.co/zicsx","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"test\\\"\\n\\t\\n\\nMore Information needed\\n"},
  {"name":"OSCAR-2301-Hindi-Cleaned-2.0","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zicsx/OSCAR-2301-Hindi-Cleaned-2.0","creator_name":"Satish Kumar Mishra","creator_url":"https://huggingface.co/zicsx","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"OSCAR-2301-Hindi-Cleaned\\\"\\n\\t\\n\\nMore Information needed\\n"},
  {"name":"OSCAR-2301-Hindi-Cleaned","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zicsx/OSCAR-2301-Hindi-Cleaned","creator_name":"Satish Kumar Mishra","creator_url":"https://huggingface.co/zicsx","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"OSCAR-2301-Hindi-Cleaned-2.0\\\"\\n\\t\\n\\nMore Information needed\\n"},
  {"name":"MMCQSD","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ArkaAcharya/MMCQSD","creator_name":"Arkadeep Acharya","creator_url":"https://huggingface.co/ArkaAcharya","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MMCQS Dataset\\n\\t\\n\\nThis is the MMCQS Dataset that have been used in the paper \\\"MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries\\\" accepted in ECIR 2024.\\n\\nGithub: https://github.com/ArkadeepAcharya/MedSumm-ECIR2024\\n\\nPaper: https://arxiv.org/abs/2401.01596\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\n\\nDownload and unzip the Multimodal_images.zip file, that can be found the in the 'Files and Version' section, to access the images that have been used in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArkaAcharya/MMCQSD."},
  {"name":"Bhandara","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Tensoic/Bhandara","creator_name":"Tensoic AI","creator_url":"https://huggingface.co/Tensoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tA Pretraining Hindi Dataset for Diverse Indian NLP Tasks\\n\\t\\n\\nThis dataset contains over 12,000 rows and 7 million words of text specifically generated for pretraining NLP models on Hindi language tasks. It was created using the Bard API, ensuring high-quality and diverse content.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKey Feature: Rich India-Specific Data\\n\\t\\n\\nA distinguishing characteristic of this dataset is its inclusion of a substantial amount of content related to India. This makes it valuable for training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tensoic/Bhandara."},
  {"name":"ai4bharat-hi-subset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zicsx/ai4bharat-hi-subset","creator_name":"Satish Kumar Mishra","creator_url":"https://huggingface.co/zicsx","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"ai4bharat-hi-subset\\\"\\n\\t\\n\\nMore Information needed\\n"},
  {"name":"gooftagoo","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Tensoic/gooftagoo","creator_name":"Tensoic AI","creator_url":"https://huggingface.co/Tensoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHindi/Hinglish Conversation Dataset\\n\\t\\n\\nThis repository contains a dataset of conversational text in conversational hindi and hinglish(a mix of Hindi and English languages).\\nThe Conversation Dataset contains multi-turn conversations on multiple topics usually revolving around daily real-life experiences. \\nA small amount of reasoning tasks have also been added (specifically COT style reasoning and coding) with about 1k samples from Openhermes 2.5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCaution\\n\\t\\n\\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tensoic/gooftagoo."},
  {"name":"gooftagoo","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Tensoic/gooftagoo","creator_name":"Tensoic AI","creator_url":"https://huggingface.co/Tensoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHindi/Hinglish Conversation Dataset\\n\\t\\n\\nThis repository contains a dataset of conversational text in conversational hindi and hinglish(a mix of Hindi and English languages).\\nThe Conversation Dataset contains multi-turn conversations on multiple topics usually revolving around daily real-life experiences. \\nA small amount of reasoning tasks have also been added (specifically COT style reasoning and coding) with about 1k samples from Openhermes 2.5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCaution\\n\\t\\n\\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tensoic/gooftagoo."},
  {"name":"indic-align","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ai4bharat/indic-align","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIndicAlign\\n\\t\\n\\nA diverse collection of Instruction and Toxic alignment datasets for 14 Indic Languages. The collection comprises of:\\n\\nIndicAlign - Instruct\\nIndic-ShareLlama\\nDolly-T\\nOpenAssistant-T\\nWikiHow\\nIndoWordNet\\nAnudesh\\nWiki-Conv\\nWiki-Chat\\n\\n\\nIndicAlign - Toxic\\nHHRLHF-T\\nToxic-Matrix\\n\\n\\n\\nWe use IndicTrans2 (Gala et al., 2023) for the translation of the datasets. \\nWe recommend the readers to check out our paper on Arxiv for detailed information on the curation process of these‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/indic-align."},
  {"name":"Nadi_Indic466k_Instruct","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct","creator_name":"Convai Innovations","creator_url":"https://huggingface.co/convaiinnovations","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNadi_Indic466K_Instruct Dataset\\n\\t\\n\\nThe Nadi_Indic466K_Instruct dataset is the world's first coding dataset with 18 Indian language support, 466k rows and 142 Million total tokens. This dataset can be used by developers to build Indian coding language models (LLMs) for various programming languages.\\nQ-LoRA based SFT/PPO/DPO fine-tuning can be done on the dataset in LLAMA-2 or Mistral or any opens-soure LLM for text generation.\\nThe dataset was carefully curated such that the coding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct."},
  {"name":"indian-history-hindi-QA-3.4k","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kaifahmad/indian-history-hindi-QA-3.4k","creator_name":"Mohd Kaif","creator_url":"https://huggingface.co/kaifahmad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains 3.47k top-notch question-answer pairs about Indian History in Hindi.\\n\\nCurated by: Mohd Kaif\\nLanguage(s) (NLP): Hindi\\nLicense: apache-2.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t\\n\\t\\n\\n"},
  {"name":"indian-history-hindi-QA-3.4k","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kaifahmad/indian-history-hindi-QA-3.4k","creator_name":"Mohd Kaif","creator_url":"https://huggingface.co/kaifahmad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains 3.47k top-notch question-answer pairs about Indian History in Hindi.\\n\\nCurated by: Mohd Kaif\\nLanguage(s) (NLP): Hindi\\nLicense: apache-2.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t\\n\\t\\n\\n"},
  {"name":"samvaad-hi-v1","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rishiraj/samvaad-hi-v1","creator_name":"Rishiraj Acharya","creator_url":"https://huggingface.co/rishiraj","description":"100k high-quality conversations in English, Hindi, and Hinglish curated exclusively with an Indic context.\\n"},
  {"name":"mewsli-x","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\\nand converted into different parts (see process.py):\\n\\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\\n\\nRaw data files are in raw.tar.gz, which contains:\\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\\n[...] 9.8M Feb 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x."},
  {"name":"bhasha-sft","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/soketlabs/bhasha-sft","creator_name":"Soket Labs","creator_url":"https://huggingface.co/soketlabs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBhasha SFT\\n\\t\\n\\n\\nBhasha SFT is a massive collection of multiple open sourced Supervised Fine-Tuning datasets for training Multilingual \\nLarge Language Models. The dataset contains collation of over 13 million instances of\\ninstruction-response data for 3 Indian languages (Hindi, Gujarati, Bengali) and English having both human annotated and synthetic data.\\n\\nCurated by: Soket AI Labs\\nLanguage(s) (NLP): [English, Hindi, Bengali, Gujarati]\\nLicense: [cc-by-4.0, apache-2.0, mit]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/soketlabs/bhasha-sft."},
  {"name":"HinglishCognitiveReframing","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nirbhaysinghnarang/HinglishCognitiveReframing","creator_name":"Nirbhay Singh Narang","creator_url":"https://huggingface.co/nirbhaysinghnarang","description":"nirbhaysinghnarang/HinglishCognitiveReframing dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"limmits-2024","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/iAkashPaul/limmits-2024","creator_name":"Akash","creator_url":"https://huggingface.co/iAkashPaul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIndic TTS dataset\\n\\t\\n\\n7 languages from IISC's LIMMITS Challenge 2024\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRoadmap\\n\\t\\n\\nTo use this for training VALLE-X & VoiceBox based TTS models\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFetch the tars directly\\n\\t\\n\\nwget -O 'Bengali_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Bengali_F.tar.gz'\\nwget -O 'Chhattisgarhi_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Chhattisgarhi_F.tar.gz'\\nwget -O 'English_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/English_F.tar.gz'\\nwget -O‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iAkashPaul/limmits-2024."},
  {"name":"hindidataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kvrma/hindidataset","creator_name":"kvRma","creator_url":"https://huggingface.co/kvrma","description":"kvrma/hindidataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"cross-rag-enhi","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/BhabhaAI/cross-rag-enhi","creator_name":"Bhabha AI","creator_url":"https://huggingface.co/BhabhaAI","description":"BhabhaAI/cross-rag-enhi dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"hindi-RAG-20k","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/BhabhaAI/hindi-RAG-20k","creator_name":"Bhabha AI","creator_url":"https://huggingface.co/BhabhaAI","description":"BhabhaAI/hindi-RAG-20k dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"multi-hatecheck","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/multi-hatecheck","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nCombines multilingual HateCheck datasets (10 languages, including English), by Paul Roettger and colleagues (2021, 2022).\\nThe original English dataset can be found under https://github.com/Paul/hatecheck.\\nDatasets for other languages are found at:\\n\\nhttps://github.com/Paul/hatecheck-arabic\\nhttps://github.com/Paul/hatecheck-mandarin\\nhttps://github.com/Paul/hatecheck-german\\nhttps://github.com/Paul/hatecheck-french\\nhttps://github.com/Paul/hatecheck-hindi‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/multi-hatecheck."},
  {"name":"bhasha-wiki-translated","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/soketlabs/bhasha-wiki-translated","creator_name":"Soket Labs","creator_url":"https://huggingface.co/soketlabs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBhasha Wikipedia Translated\\n\\t\\n\\n\\nTranslated wikipedia articles\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nDataset is being updated\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nWe have translated 6.185 million English wikipedia articles into 6 Indic languages. The translations were done using IndicTrans2 model.\\n\\nCurated by: Soket AI labs\\nLanguage(s) (NLP): Hindi, Bengali, Gujarati, Tamil, Kannada, Urdu\\nLicense: cc-by-sa-4.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\n\\nFor pretraining or Fine tuning for Indic language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/soketlabs/bhasha-wiki-translated."},
  {"name":"HINMIX_hi-en","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kartikagg98/HINMIX_hi-en","creator_name":"kartik","creator_url":"https://huggingface.co/kartikagg98","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Hindi English Codemix Dataset - HINMIX\\n\\t\\n\\nHINMIX is a massive parallel codemixed dataset for Hindi-English code switching.\\nSee the üìö paper on arxiv to dive deep into this synthetic codemix data generation pipeline. \\nDataset contains 4.2M fully parallel sentences in 6 Hindi-English forms.\\nFurther, we release gold standard codemix dev and test set manually translated by proficient bilingual annotators.\\n\\nDev Set consists of 280 examples\\nTest set consists of 2507 examples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kartikagg98/HINMIX_hi-en."},
  {"name":"HINMIX_hi-en","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kartikagg98/HINMIX_hi-en","creator_name":"kartik","creator_url":"https://huggingface.co/kartikagg98","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Hindi English Codemix Dataset - HINMIX\\n\\t\\n\\nHINMIX is a massive parallel codemixed dataset for Hindi-English code switching.\\nSee the üìö paper on arxiv to dive deep into this synthetic codemix data generation pipeline. \\nDataset contains 4.2M fully parallel sentences in 6 Hindi-English forms.\\nFurther, we release gold standard codemix dev and test set manually translated by proficient bilingual annotators.\\n\\nDev Set consists of 280 examples\\nTest set consists of 2507 examples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kartikagg98/HINMIX_hi-en."},
  {"name":"orca-math-word-problems-200k-hindi-filtered","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/BhabhaAI/orca-math-word-problems-200k-hindi-filtered","creator_name":"Bhabha AI","creator_url":"https://huggingface.co/BhabhaAI","description":"BhabhaAI/orca-math-word-problems-200k-hindi-filtered dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"aditi-syn-v2","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/manishiitg/aditi-syn-v2","creator_name":"Manish Prakash","creator_url":"https://huggingface.co/manishiitg","description":"This repo contains synthentic dataset in hindi/hinglish language using to fine tune aditi OOS LLM.\\nThis has different type of data formats\\n\\nTOOLS: teaching hindi/hinglish based function calling\\nRAG/RAG-Complex: teching context based rag for hindi/hinglish\\nCODE: writing code\\nORCA: reasoning/math questions\\nCOT: chain of thought reasoning\\nPrompts: Hindi/Hinglish answers on highly quality curated prompts\\nInstruct: general Q/A on indian context questions\\nWriting: general writing instructions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/manishiitg/aditi-syn-v2."},
  {"name":"THAR-Dataset","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Aakash941/THAR-Dataset","creator_name":"Aakash Singh","creator_url":"https://huggingface.co/Aakash941","description":"The dataset consists 11,549 YouTube comments in Hindi-English code-mixed language for targeted hate speech detection against religion. Binary and multi-class tagging of YouTube comments is used. \\nThe classification of YouTube comments addresses two subtasks: Subtask-1 (Binary classification): comments are labeled as antireligion or non-antireligion. Subtask-2 (Multi-class classification): comments are labeled on the major targeted religions such as Islam, Hinduism, and Christianity, with a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aakash941/THAR-Dataset."},
  {"name":"Hindi_XSUM","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/pkumark/Hindi_XSUM","creator_name":"Praveenkumar Katwe","creator_url":"https://huggingface.co/pkumark","description":"pkumark/Hindi_XSUM dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"long_context_hindi","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/damerajee/long_context_hindi","creator_name":"dame rajee","creator_url":"https://huggingface.co/damerajee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\nThis dataset was filtered from AI4BHarat dataset sangraha,which is the largest high-quality, cleaned Indic language pretraining data containing 251B tokens summed up over 22 languages, extracted from curated sources, existing multilingual corpora and large scale translations.\\nThis dataset contains only  Hindi as of now \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInformation\\n\\t\\n\\n\\nFirst this dataset is mainly for long context training \\nThe minimum len is 6000 and maximum len is 3754718‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/damerajee/long_context_hindi."},
  {"name":"shrutilipi","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/amithm3/shrutilipi","creator_name":"Amith M","creator_url":"https://huggingface.co/amithm3","description":"amithm3/shrutilipi dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"NeuripsHS","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ProgComp/NeuripsHS","creator_name":"Programming Competitions","creator_url":"https://huggingface.co/ProgComp","description":"Dataset comes In 3 parts:\\n\\nbase data: CulturaX/webscrapes\\nInstruct: AlpacaGPT4 hindi\\nFT: multiple for tone and dialect\\n\\n"},
  {"name":"IN22-Conv","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/IN22-Conv","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIN22-Conv\\n\\t\\n\\nIN-22 is a newly created comprehensive benchmark for evaluating machine translation performance in multi-domain, n-way parallel contexts across 22 Indic languages. IN22-Conv is the conversation domain subset of IN22. It is designed to assess translation quality in typical day-to-day conversational-style applications. The evaluation subset consists of 1503 sentences translated across 22 Indic languages enabling evaluation of MT systems across 506 directions.\\nCurrently‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Conv."},
  {"name":"IN22-Gen","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/IN22-Gen","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIN22-Gen\\n\\t\\n\\nIN22 is a newly created comprehensive benchmark for evaluating machine translation performance in multi-domain, n-way parallel contexts across 22 Indic languages. IN22-Gen is a general-purpose multi-domain evaluation subset of IN22. It has been created from two sources: Wikipedia and Web Sources offering diverse content spanning news, entertainment, culture, legal, and India-centric topics. The evaluation subset consists of 1024 sentences translated across 22 Indic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Gen."},
  {"name":"multilingual-llava-bench-in-the-wild","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual LLaVA Bench in the Wild\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote that this is a copy from https://huggingface.co/datasets/MBZUAI/multilingual-llava-bench-in-the-wild\\n\\t\\n\\nIt was created due to issues in the original repo. It also includes the image features and has a uniform and joined structure.\\nIf you use this dataset, please cite the original authors:\\n@article{PALO2024,\\n  title={Palo: A Large Multilingual Multimodal Language Model},\\n  author={Maaz, Muhammad and Rasheed, Hanoona and Shaker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild."},
  {"name":"xm3600","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\nIt also includes the image features as PIL Image and has a uniform and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600."},
  {"name":"xm3600_1k","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600 - 1K Split\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a 1K split of XM3600!\\n\\t\\n\\nFor this, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k."},
  {"name":"x-fact","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"x-fact\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact."},
  {"name":"from-one-to-many-toxicity-mitigation","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation","creator_name":"Luiza Pozzobon","creator_url":"https://huggingface.co/luizapzbn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFrom One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\\n\\t\\n\\n[arxiv][code][data]\\nData accompanying the paper \\\"From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\\\" accepted to ACL Findings 2024.\\nAbstract: To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, it‚Äôs crucial our safety measures keep pace. Recognizing this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation."},
  {"name":"News_Hinglish_English","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/suyash2739/News_Hinglish_English","creator_name":"suyash agarwal","creator_url":"https://huggingface.co/suyash2739","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a collection of text conversations in Hinglish (code mixing between Hindi-English) and their corresponding English versions. Can be used for Translating between the two.\\nThis dataset was generated by translating the first 5000 news content from the Inshorts Dataset - English News [https://www.kaggle.com/datasets/shivamtaneja2304/inshorts-dataset-english]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nHinglish\\nEnglish\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nAn example from the json‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suyash2739/News_Hinglish_English."},
  {"name":"rendered_xnli","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/baidu/rendered_xnli","creator_name":"ERNIE","creator_url":"https://huggingface.co/baidu","description":"   \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for rendered XNLI\\n\\t\\n\\n\\nThis repository contains the rendered XNLI dataset evaluated in the paper Autoregressive Pre-Training on Pixels and Texts (EMNLP 2024). For detailed instructions on how to use the model, please visit our GitHub page.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{chai2024autoregressivepretrainingpixelstexts,\\n  title = {Autoregressive Pre-Training on Pixels and Texts},\\n  author = {Chai, Yekun and Liu, Qingyi and Xiao, Jingwu and Wang, Shuohuan and Sun, Yu and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/baidu/rendered_xnli."},
  {"name":"MultiPICo","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo","creator_name":"MultilingualPerspectivistNLU","creator_url":"https://huggingface.co/Multilingual-Perspectivist-NLU","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultiPICo (Multilingual Perspectivist Irony Corpus) is a disaggregated multilingual corpus for irony detection, containing 18,778 pairs of short conversations (post-reply) from Twitter (8,956) and Reddit (9,822), along with the demographic information of each annotator (age, nationality, gender, and so on). \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nIrony classification task using soft labels (i.e., distribution of annotations) or hard labels (i.e.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo."},
  {"name":"Hindi-Captions","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/damerajee/Hindi-Captions","creator_name":"dame rajee","creator_url":"https://huggingface.co/damerajee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset information\\n\\t\\n\\nThis dataset is primarily for training a image captioning model ,this model was filtered from damerajee/Hindi-LLaVA-CC3M-Pretrain-595K-3 to only include hindi captions \\n\\nThe first column Images contains images which are  224 pixels wide and 224 pixels tall\\nThe second column Captions contains captions corresponding to the text\\n\\nThe Average Length of the captions\\n\\n"},
  {"name":"CaLMQA","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/shanearora/CaLMQA","creator_name":"Shane Arora","creator_url":"https://huggingface.co/shanearora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\n\\nCaLMQA is a long-form question answering (LFQA) dataset spanning 23 high- to low-resource languages. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCaLMQA is an LFQA dataset with 2K questions from 23 languages, 11 high- to mid-resource and 12 low-resource.\\nQuestions are either culturally specific ‚Äì uniquely or more likely to be asked by people of a specific\\nculture ‚Äì or culturally agnostic (not culturally specific). These questions were‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shanearora/CaLMQA."},
  {"name":"Benchmark-Testing","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/shounakpaul95/Benchmark-Testing","creator_name":"Shounak Paul","creator_url":"https://huggingface.co/shounakpaul95","description":"shounakpaul95/Benchmark-Testing dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Uncensored-Alpaca-v01","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ShubhVenom/Uncensored-Alpaca-v01","creator_name":"Shubh Rajput","creator_url":"https://huggingface.co/ShubhVenom","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUncensored Alpaca Dataset: A New Frontier in Language Models\\n\\t\\n\\nThis dataset is a collection of uncensored prompts and responses in the Alpaca format. It aims to provide a diverse and unfiltered source of data for training language models, pushing the boundaries of what these models can understand and generate. \\nWhat Makes This Dataset Different?\\n\\nUncensored: This dataset includes prompts and responses that touch upon topics that are often censored or avoided in traditional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ShubhVenom/Uncensored-Alpaca-v01."},
  {"name":"Uncensored-Alpaca","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/V3N0M/Uncensored-Alpaca","creator_name":"Shubh Rajput","creator_url":"https://huggingface.co/V3N0M","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUncensored Alpaca Dataset: A New Frontier in Language Models\\n\\t\\n\\nThis dataset is a collection of uncensored prompts and responses in the Alpaca format. It aims to provide a diverse and unfiltered source of data for training language models, pushing the boundaries of what these models can understand and generate. \\nWhat Makes This Dataset Different?\\n\\nUncensored: This dataset includes prompts and responses that touch upon topics that are often censored or avoided in traditional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/V3N0M/Uncensored-Alpaca."},
  {"name":"Hindi_Fever","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/AIhnIndicRag/Hindi_Fever","creator_name":"AIHN Indic Rag Community","creator_url":"https://huggingface.co/AIhnIndicRag","description":"AIhnIndicRag/Hindi_Fever dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"AyaRedTeaming","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/walledai/AyaRedTeaming","creator_name":"Walled AI","creator_url":"https://huggingface.co/walledai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Aya Red-teaming\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe Aya Red-teaming dataset is a human-annotated multilingual red-teaming dataset consisting of harmful prompts in 8 languages across 9 different categories of harm with explicit labels for \\\"global\\\" and \\\"local\\\" harm.\\n\\n\\n\\n\\n\\n\\nCurated by: Professional compensated annotators\\nLanguages: Arabic, English, Filipino, French, Hindi, Russian, Serbian and Spanish\\nLicense: Apache 2.0\\nPaper: arxiv link\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHarm‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/walledai/AyaRedTeaming."},
  {"name":"Multilingual-Benchmark","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \\nBibTex\\n@misc{lu2024languagecountslearnunlearn,\\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \\n      author={Taiming Lu and Philipp Koehn},\\n      year={2024},\\n      eprint={2406.13748},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2406.13748}, \\n}\\n\\n"},
  {"name":"mv-ner-v0.1","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ditpoo/mv-ner-v0.1","creator_name":"ditpoo","creator_url":"https://huggingface.co/ditpoo","description":"ditpoo/mv-ner-v0.1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fact-check-bureau","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau","creator_name":"Younes","creator_url":"https://huggingface.co/NaughtyConstrictor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFact-Check Retrieval Dataset\\n\\t\\n\\nThis dataset is designed to support the development and evaluation of fact-check retrieval pipelines. It is structured to work with FactCheckBureau, a tool for designing and evaluating fact-check retrieval pipelines. The dataset comprises a list of claims, fact-check articles, and precomputed embeddings for English and French fact-checks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset consists of the following files and directories:\\n\\narticles.csv:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau."},
  {"name":"XL-HeadTags","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/faisaltareque/XL-HeadTags","creator_name":"Faisal Tareque Shohan","creator_url":"https://huggingface.co/faisaltareque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for XL-HeadTags Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Source\\n\\t\\n\\nWe have used M3LS and XL-Sum as source for this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n We provide XL-HeadTags, a large-scale news headline and tags generation dataset. The dataset consists of 20 languages across six diverse language families. It contains 415K news headline-article pairs with auxiliary information such as image captions, topic words (read more).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/faisaltareque/XL-HeadTags."},
  {"name":"ILSUM-2.0","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ILSUM/ILSUM-2.0","creator_name":"Indian Language Summarization","creator_url":"https://huggingface.co/ILSUM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"ILSUM-2.0\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nILSUM-2.0 contains additional ~10K articles along with ILSUM-1.0 dataset. Along with Hindi, English, and Gujarati, which were part of ILSUM-1.0, Bengali is also introduced as part of ILSUM-20. dataset.\\nThe dataset for this task is built using articles and headline pairs from several leading newspapers of the country. We provide >=10,000 news articles for each language. The task is to generate a meaningful fixed length‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ILSUM/ILSUM-2.0."},
  {"name":"Indic_south_langs","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Logii33/Indic_south_langs","creator_name":"Logesh","creator_url":"https://huggingface.co/Logii33","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Logii33/Indic_south_langs."},
  {"name":"mmarco-hard-negatives-reranker-score","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score","creator_name":"Yuichi Tateno","creator_url":"https://huggingface.co/hotchpotch","description":"\\nhotchpotch/mmarco-hard-negatives-reranker-score\\n\\nThis repository contains data from mMARCO scored using the reranker BAAI/bge-reranker-v2-m3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Covered\\n\\t\\n\\ntarget_languages = [\\n    \\\"english\\\",\\n    \\\"chinese\\\", \\n    \\\"french\\\",\\n    \\\"german\\\",\\n    \\\"indonesian\\\",\\n    \\\"italian\\\",\\n    \\\"portuguese\\\",\\n    \\\"russian\\\",\\n    \\\"spanish\\\",\\n    \\\"arabic\\\",\\n    \\\"dutch\\\",\\n    \\\"hindi\\\",\\n    \\\"japanese\\\",\\n    \\\"vietnamese\\\"\\n]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHard Negative Data\\n\\t\\n\\nThe hard negative data is derived from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score."},
  {"name":"Multi-Opthalingua","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AAAIBenchmark/Multi-Opthalingua","creator_name":"AAAIBenchmark","creator_url":"https://huggingface.co/AAAIBenchmark","description":"AAAIBenchmark/Multi-Opthalingua dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"hindi-english-code-mixed","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ar5entum/hindi-english-code-mixed","creator_name":"Astitva Jaiswal","creator_url":"https://huggingface.co/ar5entum","description":"This dataset was compiled from various open sources online including some asr datasets and some percenteage of data generated using prompt engineering on generative llms. Some sources used are listed down below:\\n\\nhttps://github.com/l3cube-pune/code-mixed-nlp?tab=readme-ov-file\\nhttps://github.com/piyushmakhija5/hinglishNorm\\nhttps://github.com/ishan00/translation-for-code-switching-acl/tree/master\\n\\n"},
  {"name":"shiksha","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/SPRINGLab/shiksha","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShiksha Dataset\\n\\t\\n\\nThis is a Technical Domain focused Translation Dataset for 8 Indian Languages. It consists of more than 2.5 million rows of translation pairs between all 8 languages and English.\\nThis data has been derived from raw NPTEL documents. More information on this can be found in our paper: https://arxiv.org/abs/2412.09025\\nIf you use this data in your work, please cite us:\\n@misc{joglekar2024shikshatechnicaldomainfocused,\\n      title={Shiksha: A Technical Domain focused‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/shiksha."},
  {"name":"PangeaBench-xm100","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM100\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n"},
  {"name":"ApolloMoEDataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüåà Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset."},
  {"name":"ApolloMoEBench","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüåà Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench."},
  {"name":"aya_redteaming_consitutional","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/pbevan11/aya_redteaming_consitutional","creator_name":"Peter J. Bevan","creator_url":"https://huggingface.co/pbevan11","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Aya Red-teaming-constiutional\\n\\t\\n\\nThis dataset is an extended version of CohereForAI/aya_redteaming, with added targeted constitutional principles, aiming to allow multilingual constitional AI using the Aya Red team prompts.\\nWe take the Anthropic constitutional principles and manually cut out the existing harms so that we can dynamically insert harms specific to our red team prompts.\\nThere are 16 critiques and 16 revisions for each red-team prompt, each targeting the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pbevan11/aya_redteaming_consitutional."},
  {"name":"Roleplay-Hindi","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Hindi","creator_name":"Min Si Thu","creator_url":"https://huggingface.co/jojo-ai-mst","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRolePlay-Hindi\\n\\t\\n\\nRoleplay-Hindi Dataset is a dataset for roleplaying in the Hindi language for Large Language Model.\\nThe base dataset is GPTeacher role play dataset by teknium 1, which can be found under this link, released under MIT License. The dataset is then translated into respective languages. The translation process is powered by Google Translate, using cloud translation API. \\nFor more information and other language datasets for roleplay, it can be found at this github‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Hindi."},
  {"name":"indicvoices_hi_tagged_transcripts","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for indicvoices_hi_tagged_transcripts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Hindi.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Collection\\n\\t\\n\\nThe dataset was collected through automated processes and manual transcription.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains:\\n\\nAudio files (.wav format)\\nTranscriptions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts."},
  {"name":"MegaWika","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/conceptofmind/MegaWika","creator_name":"Enrico Shippole","creator_url":"https://huggingface.co/conceptofmind","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. Furthermore, nearly 130 million English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/conceptofmind/MegaWika."},
  {"name":"panlex","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex."},
  {"name":"human-eval","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ai4bharat/human-eval","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAiravata HumanEval Prompts\\n\\t\\n\\nThis benchmark contains a set of prompts written by real-users to evaluate LLMs on real-world tasks and test it for different abilities. We collect prompts for 5 abilities listed below:\\n\\nLong: Ability to generate long-form text like writing essays, speeches, reports, etc.\\nFact-Ops: Ability to give factual opinions and explanations like seeking recommendations, seeking advice, opinions, explanations, etc.\\nContent: Ability to make content accessible like‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/human-eval."},
  {"name":"ChatML-aya_dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = [\\n        {\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": columns[\\\"inputs\\\"].strip(),\\n        },\\n        {‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset."},
  {"name":"Hindi-Niband","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/thinkedgeAI/Hindi-Niband","creator_name":"ThinkEdge AI lAB","creator_url":"https://huggingface.co/thinkedgeAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Name: Hindi- Niband (Massive Hindi language Text Dataset)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThis dataset is a comprehensive collection of text data consisting of more than 10 billion tokens. It encompasses a wide range of sources, including Wikipedia articles, news articles, email transcripts, and generated prompt text. Specific Hindi language data columns have been extracted from the CulturaX dataset, which is a large, cleaned, and multilingual dataset for large language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thinkedgeAI/Hindi-Niband."},
  {"name":"tts-rj-hi-karya","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/1rsh/tts-rj-hi-karya","creator_name":"Irsh Vijay","creator_url":"https://huggingface.co/1rsh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRajasthani Hindi Speech Dataset\\n\\t\\n\\n\\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. They had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426872 recordings in this dataset. They had roughly 58 male participants and 40 female participants.\\n\\nPoint to Note:\\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/1rsh/tts-rj-hi-karya."},
  {"name":"speech-rj-hi","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/severo/speech-rj-hi","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRajasthani Hindi Speech Dataset\\n\\t\\n\\n\\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. We had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426873 recordings in this dataset. We had roughly 58 male participants and 40 female participants.\\n\\nPoint to Note:\\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the sentences‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/severo/speech-rj-hi."},
  {"name":"MultiQ","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiQ\\n\\t\\n\\nThis is the dataset corresponding to the paper \\\"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\\\". \\nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \\ntranslated into 137 typologically diverse languages. \\n\\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ."},
  {"name":"bhojpuri","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri."},
  {"name":"panlex-meanings","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings."},
  {"name":"NTREX","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX."},
  {"name":"indic_sts","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jaygala24/indic_sts","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Indic STS\\n\\t\\n\\nThis dataset is STS benchmark between English and 12 high-resource Indic languages. This was released as a part of Samanantar paper. Please refer to the paper for more details.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nAvailable languages are: en-as, en-bn, en-gu, en-hi, en-kn, en-ml, en-mr, en-or, en-pa, en-ta, en-te, en-ur\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Fields\\n\\t\\n\\n\\nlang_code: 2-digit ISO language code\\nsource: The source from which the candidate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jaygala24/indic_sts."},
  {"name":"biblenlp-corpus-mmteb","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb."},
  {"name":"Solar-Panel-Thermal-Drone-UAV-Images","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Manishsahu53/Solar-Panel-Thermal-Drone-UAV-Images","creator_name":"Sahu","creator_url":"https://huggingface.co/Manishsahu53","description":"Git\\nThis is Thermal Images of solar power plant captured using DJI drone in India.\\nHow to read thermal values from Image:\\n\\nhttps://github.com/ManishSahu53/read_thermal_temperature\\n\\nHow to do automated hotspot detection:\\n\\nhttps://github.com/ManishSahu53/solarHotspotAnalysis\\n\\n"},
  {"name":"MIMIC-Meme-Dataset","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Aakash941/MIMIC-Meme-Dataset","creator_name":"Aakash Singh","creator_url":"https://huggingface.co/Aakash941","description":"This dataset endeavors to fill the research void by presenting a meticulously curated collection of misogynistic memes in a code-mixed language of Hindi and English. It introduces two sub-tasks: the first entails a binary classification to determine the presence of misogyny in a meme, while the second task involves categorizing the misogynistic memes into multiple labels, including Objectification, Prejudice, and Humiliation.\\nFor more Information and Citation: Singh, A., Sharma, D., & Singh‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aakash941/MIMIC-Meme-Dataset."},
  {"name":"xsimplusplus","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n"},
  {"name":"indic-swim-ir-cross-lingual","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/nthakur/indic-swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Indic SWIM-IR (Cross-lingual)\\n\\t\\n\\n\\n\\n\\nThis is the cross-lingual Indic subset of the SWIM-IR dataset, where the query generated is in the Indo-European language and the passage is in English.\\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/indic-swim-ir-cross-lingual."},
  {"name":"swim-ir-cross-lingual","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SWIM-IR (Cross-lingual)\\n\\t\\n\\n\\n\\n\\nThis is the cross-lingual subset of the SWIM-IR dataset, where the query generated is in the target language and the passage is in English.\\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is a synthetic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual."},
  {"name":"Suvach","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Vaishak11a/Suvach","creator_name":"N","creator_url":"https://huggingface.co/Vaishak11a","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Description\\n\\t\\n\\nThis dataset consists of over 100k question answers in Hindi, with 1200 tokens per question on average. Questions are generated from Wikipedia pages (Page title and Chunks). The generated part of data contain Secret Context, Question, Choices, Answer, and Description.\\nThe question will be accompanied with 4 Choices and one and only one of them would be the correct answer. For improving generation quality, a retrieval step is added to extract a chunk of text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vaishak11a/Suvach."},
  {"name":"biblenlp-corpus-mmteb","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb."},
  {"name":"indic_sts","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/mteb/indic_sts","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Indic STS\\n\\t\\n\\nThis dataset is STS benchmark between English and 12 high-resource Indic languages. This was released as a part of Samanantar paper. Please refer to the paper for more details.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nAvailable languages are: en-as, en-bn, en-gu, en-hi, en-kn, en-ml, en-mr, en-or, en-pa, en-ta, en-te, en-ur\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Fields\\n\\t\\n\\n\\nlang_code: 2-digit ISO language code\\nsource: The source from which the candidate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/indic_sts."},
  {"name":"English-Hindi-Translation","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Ketan3101/English-Hindi-Translation","creator_name":"Ketan Kumar","creator_url":"https://huggingface.co/Ketan3101","description":"This dataset is for translation or similar task.\\nCredit: DanteAl97/hindi-english-translation\\n"},
  {"name":"sib200","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200."},
  {"name":"NTREX","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX."},
  {"name":"ParaNames","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames."},
  {"name":"bitext_sib200_miners","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fleurs_clean","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean."},
  {"name":"bitext_phinc_miners","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/gentaiscool/bitext_phinc_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_phinc_miners dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"xP3x-Kongo","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo."},
  {"name":"librivox-tracks","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\\nChanges:\\n\\nUsed archive.org metadata API to annotate rows with \\\"duration\\\" column\\n\\n"},
  {"name":"parsed_hindi_dictionary","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/utkarsh2299/parsed_hindi_dictionary","creator_name":"Utkarsh Pathak","creator_url":"https://huggingface.co/utkarsh2299","description":"Parsed Hindi Dictionary\\n"},
  {"name":"muri-it-language-split","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split."},
  {"name":"gita_translations_and_commentaries","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jhaabhi/gita_translations_and_commentaries","creator_name":"Abhishek Jha","creator_url":"https://huggingface.co/jhaabhi","description":"jhaabhi/gita_translations_and_commentaries dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"audio-data","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/SachinTelecmi/audio-data","creator_name":"Sachin Mohanty","creator_url":"https://huggingface.co/SachinTelecmi","description":"SachinTelecmi/audio-data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"LAION-art-EN-improved-captions-translate","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/jaeyong2/LAION-art-EN-improved-captions-translate","creator_name":"jeongjaeyong","creator_url":"https://huggingface.co/jaeyong2","description":"\\n\\t\\n\\t\\t\\n\\t\\tDevelopment Process\\n\\t\\n\\n\\nsource dataset from recastai/LAION-art-EN-improved-captions\\nWe used Qwen/Qwen2-72B-Instruct model to translate.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLicense\\n\\t\\n\\n\\nQwen/Qwen2.5-72B-Instruct : https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/LICENSE\\nrecastai/LAION-art-EN-improved-captions : https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/cc-by-4.0.md\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgement\\n\\t\\n\\nThis research is supported by TPU Research Cloud program.\\n"},
  {"name":"Bharat_NanoDBPedia_hi","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoDBPedia dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hi."},
  {"name":"Bharat_NanoHotpotQA_hi","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hi."},
  {"name":"Bharat_NanoMSMARCO_hi","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoMSMARCO dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hi."},
  {"name":"Bharat_NanoNQ_hi","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hi."},
  {"name":"Bharat_NanoSCIDOCS_hi","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoSCIDOCS dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hi."},
  {"name":"IN22-Conv-Doc-Level","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/VarunGumma/IN22-Conv-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"This dataset was constructed by merging individual conversations from the IN22-Conv dataset to create a long-context, document-level parallel benchmark. For further information on domains and statistics, please refer to the original paper and dataset.\\n"},
  {"name":"Flores-Indic-Doc-Level","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/VarunGumma/Flores-Indic-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"This dataset was constructed by merging individual sentences from the Flores dataset based on matching domain, topic, and URL attributes. The result is a long-context, document-level parallel benchmark. For more details on the domains and dataset statistics, please refer to the original paper and the dataset.\\n"},
  {"name":"dhpileIN","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/aloobun/dhpileIN","creator_name":"aloobun","creator_url":"https://huggingface.co/aloobun","description":"@misc{aralikatte2023varta,\\n      title={V\\\\=arta: A Large-Scale Headline-Generation Dataset for Indic Languages}, \\n      author={Rahul Aralikatte and Ziling Cheng and Sumanth Doddapaneni and Jackie Chi Kit Cheung},\\n      year={2023},\\n      eprint={2305.05858},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n\\n"},
  {"name":"X-ALMA-Preference","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\\nsource: the source sentence.\\nchosen: the preferred translation.\\nreject: the dis-preferred translation.\\ndirections: the translation direction.\\n@misc{xu2024xalmaplugplay,\\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \\n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\\n      year={2024},\\n      eprint={2410.03115}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference."},
  {"name":"semeval-2025-task11-track-a","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track A Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track A, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 26 standard ISO codes\\nTotal examples: 115159\\nSplits: train, dev, test\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguage Configurations\\n\\t\\n\\nEach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a."},
  {"name":"semeval-2025-task11-track-c","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track C Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track C, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 30 standard ISO codes\\nTotal examples: 57254\\nSplits: dev, test (Track C has no train split)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTrack‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c."},
  {"name":"kurage_training_data","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lightblue/kurage_training_data","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"lightblue/kurage_training_data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"PangeaBench-xchat","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/neulab/PangeaBench-xchat","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"neulab/PangeaBench-xchat dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"hi-rag-cot","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jaeyong2/hi-rag-cot","creator_name":"jeongjaeyong","creator_url":"https://huggingface.co/jaeyong2","description":">>> from datasets import load_dataset\\n\\n>>> ds = load_dataset(\\\"jaeyong2/hi-rag-cot\\\", split=\\\"train\\\")\\n>>> ds\\nDataset({\\n    features: ['context', 'Question', 'RAW Ground Truth', 'Thinking', 'Final Answer'],\\n    num_rows: 19083\\n})\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDevelopment Process\\n\\t\\n\\n\\nsource dataset from Cohere/wikipedia-22-12-hi-embeddings\\nWe used Qwen/Qwen2-72B-Instruct model to generate answer with COT.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\n\\nQwen/Qwen2.5-72B-Instruct :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jaeyong2/hi-rag-cot."},
  {"name":"sangraha-hin-100000","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/alex-joseph/sangraha-hin-100000","creator_name":"Alex Joseph","creator_url":"https://huggingface.co/alex-joseph","description":"This is a portion of AI4Bharat's Sangraha Hindi Corpus.\\nIt contains the first 10,00,000 lines of the corpus.\\n"},
  {"name":"indicvoices_pa_tagged_transcripts","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for indicvoices_pa_tagged_transcripts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Hindi.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Collection\\n\\t\\n\\nThe dataset was collected through automated processes and manual transcription.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains:\\n\\nAudio files (.wav format)\\nTranscriptions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts."},
  {"name":"mc-translation","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/efederici/mc-translation","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","description":"This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy This Dataset?\\n\\t\\n\\nTranslation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specialized‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation."},
  {"name":"indicvoices_mr_tagged_transcripts","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for indicvoices_mr_tagged_transcripts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Hindi.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Collection\\n\\t\\n\\nThe dataset was collected through automated processes and manual transcription.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains:\\n\\nAudio files (.wav format)\\nTranscriptions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts."},
  {"name":"indicvoices_bn_tagged_transcripts","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for indicvoices_bn_tagged_transcripts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Hindi.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Collection\\n\\t\\n\\nThe dataset was collected through automated processes and manual transcription.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains:\\n\\nAudio files (.wav format)\\nTranscriptions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts."},
  {"name":"hindi_tweet_sampled_dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sumanpaudel1997/hindi_tweet_sampled_dataset","creator_name":"Suman Paudel","creator_url":"https://huggingface.co/sumanpaudel1997","description":"sumanpaudel1997/hindi_tweet_sampled_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"global-festivals-translated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/azminetoushikwasi/global-festivals-translated","creator_name":"Azmine Toushik Wasi","creator_url":"https://huggingface.co/azminetoushikwasi","description":"azminetoushikwasi/global-festivals-translated dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"mmlu-indic","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/sarvamai/mmlu-indic","creator_name":"Sarvam AI","creator_url":"https://huggingface.co/sarvamai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIndic MMLU Dataset\\n\\t\\n\\nA multilingual version of the Massive Multitask Language Understanding (MMLU) benchmark, translated from English into 10 Indian languages.\\nThis version contains the translations of the development and test sets only. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Covered\\n\\t\\n\\nThe dataset includes translations in the following languages:\\n\\nBengali (bn)\\nGujarati (gu)\\nHindi (hi)\\nKannada (kn)\\nMarathi (mr)\\nMalayalam (ml)\\nOriya (or)\\nPunjabi (pa)\\nTamil (ta)\\nTelugu (te)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTask Format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sarvamai/mmlu-indic."},
  {"name":"xtreme-up-semantic-parsing","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrixnli\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSee XTREME-UP GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 20 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import load_dataset\\ndata = load_dataset('Davlan/xtreme-up-semantic-parsing', 'yor') \\n# Please, specify the language code\\n# A data point example is below:\\n{\\n\\\"id\\\": \\\"3231323330393336\\\",\\n\\\"split\\\": \\\"test\\\",\\n\\\"intent\\\": \\\"IN:GET_REMINDER\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing."},
  {"name":"Hierarchical_Text_Classification_Intent_Classification","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AkashPrasadMishra/Hierarchical_Text_Classification_Intent_Classification","creator_name":"Akash Prasad Mishra","creator_url":"https://huggingface.co/AkashPrasadMishra","description":"AkashPrasadMishra/Hierarchical_Text_Classification_Intent_Classification dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"indic-parallel-sentences-talks","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/aloobun/indic-parallel-sentences-talks","creator_name":"aloobun","creator_url":"https://huggingface.co/aloobun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Parallel Sentences - Indic Talks\\n\\t\\n\\nThis dataset contains parallel sentences (i.e. English sentence + the same sentences in another language) for numerous other languages.\\n"},
  {"name":"eng_hi_idioms_csv","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/aimagic/eng_hi_idioms_csv","creator_name":"Shubham Aditya","creator_url":"https://huggingface.co/aimagic","description":"aimagic/eng_hi_idioms_csv dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Hindi-Sign-Language-Dataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Vedant3907/Hindi-Sign-Language-Dataset","creator_name":"Vedant Rajpurohit","creator_url":"https://huggingface.co/Vedant3907","description":"Vedant3907/Hindi-Sign-Language-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Hindi-Sign-Language-Dataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Vedant3907/Hindi-Sign-Language-Dataset","creator_name":"Vedant Rajpurohit","creator_url":"https://huggingface.co/Vedant3907","description":"Vedant3907/Hindi-Sign-Language-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"G15","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/brahmairesearch/G15","creator_name":"BRAHMAI Research","creator_url":"https://huggingface.co/brahmairesearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tG15 - v0.1\\n\\t\\n\\nG15-v0.1 is a part of G-series datasets which are pre-formatted in ChatML template.\\nThese datasets are useful for quickly finetuning LLMs for better responses.\\n\\n\\nThe G15-v0.1 is a combination of the following datasets:\\n\\nOpenHermes-2.5\\nMetaMathQA (100k entries)\\nA section of our in-house dataset used to finetune Cerberus-v0.1\\n\\nThis dataset is to be used on smaller LLMs (1B - 7B) to increase their response quality.\\n\\nFor queries please reach out to us at hello@brahmai.in\\n"},
  {"name":"G15","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/brahmairesearch/G15","creator_name":"BRAHMAI Research","creator_url":"https://huggingface.co/brahmairesearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tG15 - v0.1\\n\\t\\n\\nG15-v0.1 is a part of G-series datasets which are pre-formatted in ChatML template.\\nThese datasets are useful for quickly finetuning LLMs for better responses.\\n\\n\\nThe G15-v0.1 is a combination of the following datasets:\\n\\nOpenHermes-2.5\\nMetaMathQA (100k entries)\\nA section of our in-house dataset used to finetune Cerberus-v0.1\\n\\nThis dataset is to be used on smaller LLMs (1B - 7B) to increase their response quality.\\n\\nFor queries please reach out to us at hello@brahmai.in\\n"},
  {"name":"dhhLyrics-ReversePrompt","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/pranavinani/dhhLyrics-ReversePrompt","creator_name":"Pranav Inani","creator_url":"https://huggingface.co/pranavinani","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLyrics Datasets for Creative and Linguistic Applications\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis repository contains two datasets of song lyrics, meticulously curated and organized for diverse applications in natural language processing, machine learning, and creative AI. These datasets include song verses, descriptive prompts, and romanized lyrics, providing rich resources for tasks such as text generation, sentiment analysis, transliteration, and more. All the songs are from Hip Hop‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pranavinani/dhhLyrics-ReversePrompt."},
  {"name":"mmmlu_lite","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMLU-Lite\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is about‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite."},
  {"name":"Multilingal-sakalt-data","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"„Éû„É´„ÉÅ„É™„É≥„Ç¨„É´„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇmit„É©„Ç§„Çª„É≥„Çπ„Åß„Åô„ÄÇ\\n"},
  {"name":"arc-challenge-indic","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/sarvamai/arc-challenge-indic","creator_name":"Sarvam AI","creator_url":"https://huggingface.co/sarvamai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIndic ARC Dataset\\n\\t\\n\\nA multilingual version of the ARC Challenge Set Challenge Set, translated from English into 10 Indian languages. ARC is a collection of grade-school science questions that require complex reasoning to solve.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Covered\\n\\t\\n\\nThe dataset includes translations in the following languages:\\n\\nBengali (bn)\\nGujarati (gu)\\nHindi (hi)\\nKannada (kn)\\nMarathi (mr)\\nMalayalam (ml)\\nOriya (or)\\nPunjabi (pa)\\nTamil (ta)\\nTelugu (te)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Format\\n\\t\\n\\nEach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sarvamai/arc-challenge-indic."},
  {"name":"AyaVisionBench","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/AyaVisionBench","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Aya Vision Benchmark\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \\nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/AyaVisionBench."},
  {"name":"Everything_Instruct_Multilingual","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEverything Instruct (Multilingual Edition)\\n\\t\\n\\nEverything you need... all in one place üíò\\n\\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\\nNote2: This version of the dataset supports the following languages:\\n\\nEnglish\\nRussian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual."},
  {"name":"Global-MMLU","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU üåç is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) üóΩ or Culturally Agnostic (CA) ‚öñÔ∏è. These annotations were collected as part of an open‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU."},
  {"name":"reasoning-multilingual-R1-Llama-70B-train","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\tlightblue/reasoning-multilingual-R1-Llama-70B-train\\n\\t\\n\\nThis is a multilingual reasoning dataset covering more than 30 languages.\\nThis dataset was made by:\\n\\nSampling prompts from English datasets and translating them to various languages\\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\\n\\nThis dataset was then used to train a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train."},
  {"name":"wmt24pp","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tWMT24++\\n\\t\\n\\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\\nthe publication\\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\\nIf you are interested in the images of the source URLs for each document, please see here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema\\n\\t\\n\\nEach language pair is stored in its own jsonl file.\\nEach row is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp."},
  {"name":"xquad","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/google/xquad","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xquad\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nXQuAD (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering\\nperformance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set\\nof SQuAD v1.1 (Rajpurkar et al., 2016) together with their professional translations into ten languages: Spanish, German,\\nGreek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/xquad."},
  {"name":"mqa","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages."},
  {"name":"multilingual-sentiments","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/tyqiangz/multilingual-sentiments","creator_name":"Tay Yong Qiang","creator_url":"https://huggingface.co/tyqiangz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Sentiments Dataset\\n\\t\\n\\nA collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.\\nMost multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments."},
  {"name":"wmt-da-human-evaluation","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation","creator_name":"Ricardo Costa Dias Rei","creator_url":"https://huggingface.co/RicardoRei","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains all DA human annotations from previous WMT News Translation shared tasks.\\nThe data is organised into 8 columns:\\n\\nlp: language pair\\nsrc: input text\\nmt: translation\\nref: reference translation\\nscore: z score\\nraw: direct assessment\\nannotators: number of annotators\\ndomain: domain of the input text (e.g. news)\\nyear: collection year\\n\\nYou can also find the original data for each year in the results section‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation."},
  {"name":"multiconer_v2","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/MultiCoNER/multiconer_v2","creator_name":"MultiCoNER","creator_url":"https://huggingface.co/MultiCoNER","description":"Complex named entities (NE), like the titles of creative works, are not simple nouns and pose challenges for NER systems (Ashwini and Choi, 2014). They can take the form of any linguistic constituent, like an imperative clause (‚ÄúDial M for Murder‚Äù), and do not look like traditional NEs (Persons, Locations, etc.). This syntactic ambiguity makes it challenging to recognize them based on context. We organized the MultiCoNER task (Malmasi et al., 2022) at SemEval-2022 to address these challenges in 11 languages, receiving a very positive community response with 34 system papers. Results confirmed the challenges of processing complex and long-tail NEs: even the largest pre-trained Transformers did not achieve top performance without external knowledge. The top systems infused transformers with knowledge bases and gazetteers. However, such solutions are brittle against out of knowledge-base entities and noisy scenarios like the presence of spelling mistakes and typos. We propose MultiCoNER II which represents novel challenges through new tasks that emphasize the shortcomings of the current top models.\\n\\nMultiCoNER II features complex NER in these languages:\\n\\n1. English\\n2. Spanish\\n3. Hindi\\n4. Bangla\\n5. Chinese\\n6. Swedish\\n7. Farsi\\n8. French\\n9. Italian\\n10. Portugese\\n11. Ukranian\\n12. German\\n\\nFor more details see https://multiconer.github.io/\\n\\n## References\\n* Sandeep Ashwini and Jinho D. Choi. 2014. Targetable named entity recognition in social media. CoRR, abs/1408.0782.\\n* Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta Kar, Oleg Rokhlenko. 2022. SemEval-2022 Task 11: Multilingual Complex Named Entity Recognition (MultiCoNER)."},
  {"name":"massive_translation_dataset","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Amani27/massive_translation_dataset","creator_name":"Amani N","creator_url":"https://huggingface.co/Amani27","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Massive Dataset for Translation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is derived from AmazonScience/MASSIVE dataset for translation task purpose.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nTranslation\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nEnglish (en_US)\\nGerman (de_DE)\\nHindi (hi_IN)\\nSpanish (es_ES)\\nFrench (fr_FR)\\nItalian (it_IT)\\nArabic (ar_SA)\\nDutch (nl_NL)\\nJapanese (ja_JP)\\nPortugese (pt_PT)\\n\\n"},
  {"name":"hindi-headline-article-generation","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ganeshjcs/hindi-headline-article-generation","creator_name":"Ganesh Jagadeesan","creator_url":"https://huggingface.co/ganeshjcs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nhindi-headline-article-generation is an open source dataset of instruct-style records generated from the Hindi Text Short and Large Summarization dataset. This was created as part of Aya Open Science Initiative from Cohere For AI.\\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the CC BY-SA 4.0 License.\\nSupported Tasks:\\n\\nTraining LLMs\\nSynthetic Data Generation\\nData Augmentation\\n\\nLanguages: Hindi Version: 1.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ganeshjcs/hindi-headline-article-generation."},
  {"name":"PMIndiaSum","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PMIndiaData/PMIndiaSum","creator_name":"PMIndiaData","creator_url":"https://huggingface.co/PMIndiaData","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"PMIndiaSum\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nPMIndiaSum is a new multilingual and massively parallel headline summarization corpus focused on languages in India. Our corpus covers four language families, 14 languages, and the largest to date, 196 language pairs. It provides a testing ground for all cross-lingual pairs.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported tasks\\n\\t\\n\\nMonolingual, multilingual and cross-lingual summarization for languages in India.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PMIndiaData/PMIndiaSum."},
  {"name":"multilingual-tts","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/MohamedRashad/multilingual-tts","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBefore Anything and Everything ‚ö±\\n\\t\\n\\nIn the time of writing this Dataset Card, 17,490 18,412 civilian has been killed in Palestine (7,870 8,000 are children and 6,121 6,200 are women).\\nSeek any non-profit organization to help them with what you can (For myself, I use Mersal) üáµüá∏\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Multilingual TTS dataset is an exceptional compilation of text-to-speech (TTS) samples, meticulously crafted to showcase the richness and diversity of human languages.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/multilingual-tts."},
  {"name":"samvaad-hi-v1","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sarvamai/samvaad-hi-v1","creator_name":"Sarvam AI","creator_url":"https://huggingface.co/sarvamai","description":"100k high-quality conversations in English, Hindi, and Hinglish curated exclusively with an Indic context.\\n"},
  {"name":"sangraha","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ai4bharat/sangraha","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\\n\\t\\n\\t\\t\\n\\t\\tSangraha\\n\\t\\n\\n\\n  \\n\\n\\nSangraha is the largest high-quality, cleaned Indic language pretraining data containing 251B tokens summed up over 22 languages, extracted from curated sources, existing multilingual corpora and large scale translations.\\nMore information:\\n\\nFor detailed information on the curation and cleaning process of Sangraha, please checkout our paper on Arxiv;\\nCheck out the scraping and cleaning pipelines used to curate Sangraha on GitHub;\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tGetting Started\\n\\t\\n\\nFor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/sangraha."},
  {"name":"XMedbench","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/XMedbench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Medicine: Model, Dataset, Benchmark, Code\\n\\t\\n\\nCovering English, Chinese, French, Hindi, Spanish, Hindi, Arabic So far\\n\\n   üë®üèª‚ÄçüíªGithub ‚Ä¢üìÉ Paper ‚Ä¢ ü§ó ApolloCorpus ‚Ä¢ ü§ó XMedBench \\n      ‰∏≠Êñá  |  English\\n\\n\\n\\n\\n\\n\\t\\t\\n\\t\\tüåà Update\\n\\t\\n\\n\\n[2024.03.07] Paper released.\\n[2024.02.12] ApolloCorpus and  XMedBench  is publishedÔºÅüéâ\\n[2024.01.23] Apollo repo is publishedÔºÅüéâ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tResults\\n\\t\\n\\n   \\n\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\n\\nZip File\\nData category\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData:\\n\\t\\n\\n\\nEN:\\n\\nMedQA-USMLE \\nMedMCQA\\nPubMedQA:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/XMedbench."},
  {"name":"tokenizer-wiki-bench","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Tokenizer Benchmark\\n\\t\\n\\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \\nfrom transformers import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench."},
  {"name":"aditi-syn-v1","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/manishiitg/aditi-syn-v1","creator_name":"Manish Prakash","creator_url":"https://huggingface.co/manishiitg","description":"v1 for synthetic dataset generate for aditi model.\\nGeneration scripts are located here https://github.com/manishiitg/aditi_dataset/tree/main/gen\\n"},
  {"name":"gooftagoo","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/adi-kmt/gooftagoo","creator_name":"Adithya Kamath","creator_url":"https://huggingface.co/adi-kmt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHindi/Hinglish Conversation Dataset\\n\\t\\n\\nThis repository contains a dataset of conversational text in conversational hindi and hinglish(a mix of Hindi and English languages).\\nThe Conversation Dataset contains multi-turn conversations on multiple topics usually revolving around daily real-life experiences. \\nA small amount of reasoning tasks have also been added (specifically COT style reasoning and coding) with about 1k samples from Openhermes 2.5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCaution\\n\\t\\n\\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/adi-kmt/gooftagoo."},
  {"name":"gooftagoo","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/adi-kmt/gooftagoo","creator_name":"Adithya Kamath","creator_url":"https://huggingface.co/adi-kmt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHindi/Hinglish Conversation Dataset\\n\\t\\n\\nThis repository contains a dataset of conversational text in conversational hindi and hinglish(a mix of Hindi and English languages).\\nThe Conversation Dataset contains multi-turn conversations on multiple topics usually revolving around daily real-life experiences. \\nA small amount of reasoning tasks have also been added (specifically COT style reasoning and coding) with about 1k samples from Openhermes 2.5.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCaution\\n\\t\\n\\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/adi-kmt/gooftagoo."},
  {"name":"swim-ir-monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/nthakur/swim-ir-monolingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SWIM-IR (Monolingual)\\n\\t\\n\\n\\n\\n\\nThis is the monolingual subset of the SWIM-IR dataset, where the query generated and the passage are both in the same language.\\nA few remaining languages will be added in the upcoming v2 version of SWIM-IR. The dataset is available as CC-BY-SA 4.0.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is a synthetic multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-monolingual."},
  {"name":"webui-dom-snapshots","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WebUI DOM snapshots\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: Gary Benson\\nLanguages: Mostly English (87%);\\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\\nLicense: CC0 1.0 Universal\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots."},
  {"name":"IndicVarna-100k","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/dynopii/IndicVarna-100k","creator_name":"Dynopii Inc","creator_url":"https://huggingface.co/dynopii","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIndicVarna for Callchimp.ai (a Dynopii product)\\n\\t\\n\\nWe introduce IndiVarna which was prepared by using Google Translate on the dair-ai/emotion dataset to get the samples there translated to the top 10 most commonly used Indian languages.\\nThis dataset contains 10000 samples of each of the 10 languages supported.\\nThe dataset further translated the labels in the dataset to 3 label sentiments - 0: Negative, 1: Neutral and 2: Positive. Each language has 3334 samples of each category of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dynopii/IndicVarna-100k."},
  {"name":"hindi_VQA","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/damerajee/hindi_VQA","creator_name":"dame rajee","creator_url":"https://huggingface.co/damerajee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\nThis dataset was filterd to be more  balanced and this dataset was processed to create sentence embeddings . The embeddings were generated using a pre-trained sentence transformer model. Then, KMeans clustering was performed on the embeddings to group similar answers together. Finally, t-SNE was applied to reduce the dimensionality of the embeddings for visualization purposes. The resulting plot shows the clusters of sentence embeddings, which can be used for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/damerajee/hindi_VQA."},
  {"name":"TinyJenna-Uncensored-v01","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/V3N0M/TinyJenna-Uncensored-v01","creator_name":"Shubh Rajput","creator_url":"https://huggingface.co/V3N0M","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUncensored Alpaca Dataset: A New Frontier in Language Models\\n\\t\\n\\nThis dataset is a collection of uncensored prompts and responses in the Alpaca format. It aims to provide a diverse and unfiltered source of data for training language models, pushing the boundaries of what these models can understand and generate. \\nWhat Makes This Dataset Different?\\n\\nUncensored: This dataset includes prompts and responses that touch upon topics that are often censored or avoided in traditional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/V3N0M/TinyJenna-Uncensored-v01."},
  {"name":"nomiracl-instruct","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/miracl/nomiracl-instruct","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NoMIRACL (EMNLP 2024 Findings Track)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Overview\\n\\t\\n\\nThis repository contains the fine-tuning (training & development split) of the NoMIRACL instruct dataset for fine-tuning LLMs on multilingual relevance assessment.\\nThe training dataset is a binary classification task; they need to explicitly output either Yes, answer is present or I don't know. \\nThe dataset contains training pairs from all 18 languages for both splits: relevant & non-relevant.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miracl/nomiracl-instruct."},
  {"name":"text_ratings","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"Todo - Write dataset card\\n"},
  {"name":"MMMLU","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLU‚Äôs test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU."},
  {"name":"vqa","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/worldcuisines/vqa","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\\n\\t\\n\\n\\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 October‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa."},
  {"name":"ssi-speech-emotion-recognition","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/stapesai/ssi-speech-emotion-recognition","creator_name":"Stapes AI","creator_url":"https://huggingface.co/stapesai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SSI: Speech Emotion Recognition - Stapes AI\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Format for Audio Files\\n\\t\\n\\nThis is the format for the audio files in the dataset. We'll open-source the dataset soon.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGender\\n\\t\\n\\n\\nM - Male\\nF - Female\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAge Group\\n\\t\\n\\n\\nCH - Child (0-12)\\nTE - Teenager (13-19)\\nAD - Adult (20-60)\\nSE - Senior (60+)\\nUNK - Unknown\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUtterance Type\\n\\t\\n\\n\\nSEN: Sentence\\nWOR: Word\\nPHR: Phrase\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentence‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stapesai/ssi-speech-emotion-recognition."},
  {"name":"m-ArenaHard","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/m-ArenaHard","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-ArenaHard\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-ArenaHard."},
  {"name":"PangeaBench-xmmmu","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/neulab/PangeaBench-xmmmu","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"neulab/PangeaBench-xmmmu dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"VoxCommunis","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis."},
  {"name":"include-base-44","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/include-base-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-base (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-base-44."},
  {"name":"include-lite-44","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/include-lite-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-lite (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-lite-44."},
  {"name":"Global-MMLU-Lite","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 15 languages, including English. It is \\\"lite\\\" version of the original Global-MMLU dataset üåç.\\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \\n\\nCurated by: Professional annotators and contributors of Cohere For‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite."},
  {"name":"MultiLingualSentiment","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/clapAI/MultiLingualSentiment","creator_name":"clapAI","creator_url":"https://huggingface.co/clapAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nMultilingualSentiment is a sentiment classification dataset that encompasses three sentiment labels: Positive, Neutral, Negative\\nThe dataset spans multiple languages and covers a wide range of domains, making it ideal for multilingual sentiment analysis tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\nThe dataset was meticulously collected and aggregated from various sources, including Hugging Face and Kaggle. These sources provide diverse languages and domains to ensure a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clapAI/MultiLingualSentiment."},
  {"name":"hindi_instruct","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/maharnab/hindi_instruct","creator_name":"Maharnab Saikia","creator_url":"https://huggingface.co/maharnab","description":"This dataset was created for the \\\"Unlock Global Communication with Gemma\\\" competition on Kaggle. It combines multiple datasets to capture a diverse range of topics and use cases:\\n\\nOdiaGenAI/instruction_set_hindi_1035: Includes instructions and responses related to art, culture, history, cooking, environment, music, and sports.\\nSherryT997/HelpSteer-hindi: Focuses on general question-answering conversations.\\nkaifahmad/indian-history-hindi-QA-3.4k: Contains questions and answers specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maharnab/hindi_instruct."},
  {"name":"SMPQA","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/WueNLP/SMPQA","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSMPQA (Synthetic Multilingual Plot QA)\\n\\t\\n\\n\\n\\nThe SMPQA evaluation dataset proposed in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nSMPQA is composed of synthetic bar plots and pie charts (generated using word lists of different languages) together with questions about those plots.\\nThe datasets aims at providing an initial way of evaluating multilingual OCR capabilities of models in arbritrary languages.\\nThere are two sub-tasks: \\n\\nGrounding text labels‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/SMPQA."},
  {"name":"wmt-da-human-evaluation-long-context","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLong-context / document-level dataset for Quality Estimation of Machine Translation.\\nIt is an augmented variant of the sentence-level WMT DA Human Evaluation dataset.\\nIn addition to individual sentences, it contains augmentations of 2, 4, 8, 16, and 32 sentences, among each language pair lp and domain.\\nThe raw column represents a weighted average of scores of augmented sentences using character lengths of src and mt as weights.\\nThe code used to apply the augmentation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context."},
  {"name":"imatrix-calibration","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/eaddario/imatrix-calibration","creator_name":"Ed Addario","creator_url":"https://huggingface.co/eaddario","description":"\\n\\t\\n\\t\\t\\n\\t\\tImportance Matrix (imatrix) calibration datasets\\n\\t\\n\\nThis dataset consists of over 10M tokens of cleaned and de-duplicated text files for 13 different languages. Each language file is available in five sizes, ranging from large (~ 26,000 lines equivalent to approx. 750K tokens), to micro (~ 1,625 lines and 125K tokens avg).\\nOriginal data sourced from HuggingFaceFW/fineweb and HuggingFaceFW/fineweb-2\\n\\n\\t\\n\\t\\t\\nFile\\nLanguage\\nLines\\nSize\\n\\n\\n\\t\\t\\ncalibration_ar_large\\nArabic\\n26,000\\n3.1M‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eaddario/imatrix-calibration."},
  {"name":"audio_public","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SayantanJoker/audio_public","creator_name":"Sayantan Ray","creator_url":"https://huggingface.co/SayantanJoker","description":"SayantanJoker/audio_public dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"indiantranslator","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nashrah18/indiantranslator","creator_name":"Nashrah Shaikh","creator_url":"https://huggingface.co/nashrah18","description":"nashrah18/indiantranslator dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"english-hindi-colloquial-dataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bajpaideeksha/english-hindi-colloquial-dataset","creator_name":"deeksha bajpai","creator_url":"https://huggingface.co/bajpaideeksha","description":"A curated dataset of colloquial English phrases and their corresponding Hindi translations. This dataset focuses on informal language, including slang, idioms, and everyday expressions, making it ideal for training models that handle casual conversations.\\nDataset Details:\\nSize:e.g., 500+ phrase pairs]\\nSource: Collected from publicly available conversational datasets, social media, and crowdsourced contributions.\\nLanguage Pair: English ‚Üí Hindi\\nAnnotations: Each phrase pair is manually verified‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bajpaideeksha/english-hindi-colloquial-dataset."},
  {"name":"u-sticker","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/metchee/u-sticker","creator_name":"Metilda Chee","creator_url":"https://huggingface.co/metchee","description":"\\n\\t\\n\\t\\t\\n\\t\\tU-Sticker\\n\\t\\n\\nUser-Sticker is a stickers dataset with multi-domain conversations.\\nFeatures of U-Sticker:\\n\\nMulti-domain interactions ‚úÖ\\nTemporal ‚úÖ\\nUser information ‚úÖ\\n370.2k stickers ‚úÖ (104k unique)\\n22.6k users ‚úÖ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nU-Sticker contains three files:\\n\\nConversation files: 1 to 67.json\\nDomain mapping files idx_to_domain.txt.\\nSticker files.\\n\\n\\nSticker files are available here and Baidu Cloud.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tConversation file\\n\\t\\n\\n\\nEmpty lines are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/metchee/u-sticker."},
  {"name":"english_telugu_slang","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/BLESSENA30/english_telugu_slang","creator_name":"VinukondaBlessena","creator_url":"https://huggingface.co/BLESSENA30","description":"BLESSENA30/english_telugu_slang dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"shrimad-bhagavad-gita-dataset-alpaca","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/SatyaSanatan/shrimad-bhagavad-gita-dataset-alpaca","creator_name":"Sanatan Dharma","creator_url":"https://huggingface.co/SatyaSanatan","description":"SatyaSanatan/shrimad-bhagavad-gita-dataset-alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Hinglish-Preference-Humanized-DPO","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/fhai50032/Hinglish-Preference-Humanized-DPO","creator_name":"Low IQ Gen AI","creator_url":"https://huggingface.co/fhai50032","description":"\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset was created using Mistral-large-2411 and Mistral-large-2407 models. It is a preference dataset similar to DPO datasets and includes four fields: english_input, hinglish_input, chosen, and rejected.\\n\\n\\t\\n\\t\\t\\n\\t\\tPurpose\\n\\t\\n\\nWe advise users to utilize this dataset for emulating human-like behavior, specifically through the Hinglish language. The dataset is designed to enhance conversational AI models, making them more natural and engaging in their interactions.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fhai50032/Hinglish-Preference-Humanized-DPO."},
  {"name":"wikis","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/nyuuzyou/wikis","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Public MediaWiki Collection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 1,662,448 articles harvested from 930 random public MediaWiki instances found across the Internet. The collection was created by extracting current page content from these wikis, preserving article text, metadata, and structural information. The dataset represents a diverse cross-section of public wiki content spanning multiple domains, topics, and languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wikis."},
  {"name":"m-WildVision","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/m-WildVision","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-WildVision\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \\nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \\nThe authors demonstrated that these prompts enable automatic LLM judge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-WildVision."},
  {"name":"BRIGHTER-emotion-categories","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\tBRIGHTER Emotion Categories Dataset\\n\\t\\n\\nThis dataset contains the emotion categories data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe BRIGHTER Emotion Categories dataset is a comprehensive multi-language, multi-label emotion classification dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories."},
  {"name":"aya_redteaming","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_redteaming","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Aya Red-teaming\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe Aya Red-teaming dataset is a human-annotated multilingual red-teaming dataset consisting of harmful prompts in 8 languages across 9 different categories of harm with explicit labels for \\\"global\\\" and \\\"local\\\" harm.\\n\\n\\n\\n\\n\\n\\nCurated by: Professional compensated annotators\\nLanguages: Arabic, English, Filipino, French, Hindi, Russian, Serbian and Spanish\\nLicense: Apache 2.0\\nPaper: arxiv link\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHarm Categories:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_redteaming."},
  {"name":"alt","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mutiyama/alt","creator_name":"Masao Utiyama","creator_url":"https://huggingface.co/mutiyama","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Asian Language Treebank (ALT)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe ALT project aims to advance the state-of-the-art Asian natural language processing (NLP) techniques through the open collaboration for developing and using ALT. It was first conducted by NICT and UCSY as described in Ye Kyaw Thu, Win Pa Pa, Masao Utiyama, Andrew Finch and Eiichiro Sumita (2016). Then, it was developed under ASEAN IVO as described in this Web page. \\nThe process of building ALT began‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mutiyama/alt."},
  {"name":"bbc_hindi_nli","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/midas/bbc_hindi_nli","creator_name":"MIDAS Research Laboratory, IIIT-Delhi","creator_url":"https://huggingface.co/midas","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BBC Hindi NLI Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nDataset for Natural Language Inference in Hindi Language. BBC Hindi Dataset consists of textual-entailment pairs.\\nEach row of the Datasets if made up of 4 columns - Premise, Hypothesis, Label and Topic.\\nContext and Hypothesis is written in Hindi while Entailment_Label is in English.\\nEntailment_label is of 2 types - entailed and not-entailed.\\nDataset can be used to train models for Natural Language Inference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/midas/bbc_hindi_nli."},
  {"name":"ilist","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/kmi-linguistics/ilist","creator_name":"kmi-linguistics","creator_url":"https://huggingface.co/kmi-linguistics","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ilist\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is introduced in a task which aimed at identifying 5 closely-related languages of Indo-Aryan language family: Hindi (also known as Khari Boli), Braj Bhasha, Awadhi, Bhojpuri and Magahi. These languages form part of a continuum starting from Western Uttar Pradesh (Hindi and Braj Bhasha) to Eastern Uttar Pradesh (Awadhi and Bhojpuri) and the neighbouring Eastern state of Bihar (Bhojpuri and Magahi).\\nFor this task‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kmi-linguistics/ilist."},
  {"name":"xcsr","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/INK-USC/xcsr","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for X-CSR\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTo evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr."},
  {"name":"xquad_r","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/google-research-datasets/xquad_r","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nXQuAD-R is a retrieval version of the XQuAD dataset (a cross-lingual extractive\\nQA dataset). Like XQuAD, XQUAD-R is an 11-way parallel dataset,  where each\\nquestion appears in 11 different languages and has 11 parallel correct answers\\nacross the languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset can be found with the following languages:\\n\\nArabic:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/xquad_r."},
  {"name":"indicxnli","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Divyanshu/indicxnli","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","description":"IndicXNLI is a translated version of XNLI to 11 Indic Languages. As with XNLI, the goal is\\nto predict textual entailment (does sentence A imply/contradict/neither sentence\\nB) and is a classification task (given two sentences, predict one of three\\nlabels)."},
  {"name":"xlel_wd_dictionary","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles."},
  {"name":"xlel_wd","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles."},
  {"name":"shades_nationality","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/bigscience-catalogue-data/shades_nationality","creator_name":"BigScience Catalogue Data","creator_url":"https://huggingface.co/bigscience-catalogue-data","description":"Possibly a placeholder dataset for the original here: https://huggingface.co/datasets/bigscience-catalogue-data/bias-shades\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Statement for SHADES\\n\\t\\n\\n\\nHow to use this document:\\nFill in each section according to the instructions. Give as much detail as you can, but there's no need to extrapolate. The goal is to help people understand your data when they approach it. This could be someone looking at it in ten years, or it could be you yourself looking back at the data in two‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bigscience-catalogue-data/shades_nationality."},
  {"name":"hatecheck-hindi","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Paul/hatecheck-hindi","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-hindi."},
  {"name":"xP3all","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot."},
  {"name":"xP3mt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot."},
  {"name":"miracl-corpus","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/miracl/miracl-corpus","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MIRACL Corpus\\n\\t\\n\\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\\nThis dataset contains the collection data of the 16 \\\"known languages\\\". The remaining 2 \\\"surprise languages\\\" will not be released until later.\\nThe corpus for each language is prepared from a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus."},
  {"name":"IE_SemParse","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Divyanshu/IE_SemParse","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","description":"    IE-SemParse is an Inter-bilingual Seq2seq Semantic parsing dataset for 11 distinct Indian languages"},
  {"name":"TyDiP","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Genius1237/TyDiP","creator_name":"Genius1237","creator_url":"https://huggingface.co/Genius1237","description":"The TyDiP dataset is a dataset of requests in conversations between wikipedia editors\\nthat have been annotated for politeness. The splits available below consists of only\\nrequests from the top 25 percentile (polite) and bottom 25 percentile (impolite) of\\npoliteness scores. The English train set and English test set that are\\nadapted from the Stanford Politeness Corpus, and test data in 9 more languages\\n(Hindi, Korean, Spanish, Tamil, French, Vietnamese, Russian, Afrikaans, Hungarian) \\nwas annotated by us."},
  {"name":"wikipedia-22-12-hi-embeddings","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-hi-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikipedia (hi) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded Wikipedia (hi) using the cohere.ai multilingual-22-12 embedding model.\\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEmbeddings\\n\\t\\n\\nWe compute for title+\\\" \\\"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-hi-embeddings."},
  {"name":"naamapadam","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/ai4bharat/naamapadam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":""},
  {"name":"xstory_cloze","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/juletxara/xstory_cloze","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","description":"XStoryCloze consists of the professionally translated version of the [English StoryCloze dataset](https://cs.rochester.edu/nlp/rocstories/) (Spring 2016 version) to 10 non-English languages. This dataset is released by Meta AI."},
  {"name":"miracl-hi-corpus-22-12","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Cohere/miracl-hi-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (hi) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-hi-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-hi-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-hi-corpus-22-12."},
  {"name":"miracl-hi-queries-22-12","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Cohere/miracl-hi-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (hi) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-hi-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-hi-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-hi-queries-22-12."},
  {"name":"xOA22","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sambanovasystems/xOA22","creator_name":"SambaNova Systems","creator_url":"https://huggingface.co/sambanovasystems","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xOA22 - Multilingual Prompts from OpenAssistant\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nxOA22 consists of 22 prompts originally shown in Appendix E, page 25 of the OpenAssistant Conversations paper. These 22 prompts were then manually translated by volunteers into 5 languages: Arabic, Simplified Chinese, French, Hindi and Spanish. \\nThese prompts were originally created for human evaluations of the multilingual abilities of BLOOMChat. Since not all prompts could be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sambanovasystems/xOA22."},
  {"name":"x-self-instruct-seed-32","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sambanovasystems/x-self-instruct-seed-32","creator_name":"SambaNova Systems","creator_url":"https://huggingface.co/sambanovasystems","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xOA22 - Multilingual Prompts from OpenAssistant\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nx-self-instruct-seed-32 consists of 32 prompts chosen out of the 252 prompts in the self-instruct-seed dataset from the Self-Instruct paper. These 32 prompts were filtered out according to the following criteria:\\n\\nShould be natural in a chat setting\\nTherefore, we filter out any prompts with \\\"few-shot examples\\\", as these are all instruction prompts that we consider unnatural in a chat‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sambanovasystems/x-self-instruct-seed-32."},
  {"name":"Bhasha-Abhijnaanam","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Aksharantar\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBhasha-Abhijnaanam is a language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\nAssamese (asm)\\nHindi (hin)\\nMaithili (mai)\\nNepali (nep)\\nSanskrit (san)\\nTamil (tam)\\n\\n\\nBengali (ben)\\nKannada (kan)\\nMalayalam (mal)\\nOriya (ori)\\nSantali (sat)\\nTelugu (tel)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam."},
  {"name":"multi-figqa","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/cmu-lti/multi-figqa","creator_name":"CMU-LTI","creator_url":"https://huggingface.co/cmu-lti","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for multi-figqa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA multilingual dataset of human-written creative figurative expressions in many languages (mostly metaphors and similes). The English version (with the same format) can be found here\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nLanguages included are Hindi, Indonesian, Javanese, Kannada, Sundanese, Swahili, and Yoruba. The language codes are respectively hi, id, kn, su, sw, and yo.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmu-lti/multi-figqa."},
  {"name":"hindi-summarization","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Someman/hindi-summarization","creator_name":"Samman","creator_url":"https://huggingface.co/Someman","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nHindi Text Short and Large Summarization Corpus is a collection of ~180k articles with their headlines and summary collected from Hindi News Websites.\\nThis is a first of its kind Dataset in Hindi which can be used to benchmark models for Text summarization in Hindi. This does not contain articles contained in Hindi Text Short Summarization Corpus which is being released parallely with this Dataset.\\nThe dataset retains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Someman/hindi-summarization."},
  {"name":"SREDFM","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Babelscape/SREDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\\\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\\nFirst, we present SRED\\\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \\nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \\nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\\\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}."},
  {"name":"english-to-hinglish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/findnitai/english-to-hinglish","creator_name":"Nitai Agarwal","creator_url":"https://huggingface.co/findnitai","description":"English to Hinglish Dataset aggregated from publicly available datasources.\\nSources:\\n\\nHinglish TOP Dataset\\nCMU English Dog\\nHinGE\\nPHINC\\n\\nsource : 1 - Human Annotated , \\nsource : 0 -  Synthetically Generated\\n"},
  {"name":"all-scam-spam","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\\n1040 rows of balanced data, consisting of casual conversations and scam emails in ‚âà10 languages, were manually collected and annotated by me, with some help from ChatGPT.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSome preprcoessing algorithms\\n\\t\\n\\n\\nspam_assassin.js, followed by spam_assassin.py\\nenron_spam.py\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData composition\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam."},
  {"name":"open-lid-dataset","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/hac541309/open-lid-dataset","creator_name":"Chris Ha","creator_url":"https://huggingface.co/hac541309","description":"This dataset is built from the open source data accompanying \\\"An Open Dataset and Model for Language Identification\\\" (Burchell et al., 2023)\\nThe repository containing the actual data can be found here : https://github.com/laurieburchell/open-lid-dataset.\\nThe license for this recreation itself follows the original upstream dataset as GPLv3+. \\nHowever, individual datasets within it follow each of their own licenses.\\nThe \\\"src\\\" column lists the sources. \\\"lang\\\" column lists the language code in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hac541309/open-lid-dataset."},
  {"name":"hindi-article-summarization","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ganeshjcs/hindi-article-summarization","creator_name":"Ganesh Jagadeesan","creator_url":"https://huggingface.co/ganeshjcs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nhindi-article-summarization is an open source dataset of instruct-style records generated from the Hindi Text Short and Large Summarization dataset. This was created as part of Aya Open Science Initiative from Cohere For AI.\\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the CC BY-SA 4.0 License.\\nSupported Tasks:\\n\\nTraining LLMs\\nSynthetic Data Generation\\nData Augmentation\\n\\nLanguages: Hindi Version: 1.0\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ganeshjcs/hindi-article-summarization."},
  {"name":"text_coordinates_regions","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Regions\\\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\\nKey Features:\\n\\nTextual Data: The dataset contains 500,000 text samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions."},
  {"name":"phinc","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/veezbo/phinc","creator_name":"Vibhor Kumar","creator_url":"https://huggingface.co/veezbo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nPHINC is a parallel corpus for machine translation pairing code-mixed Hinglish (a fusion of Hindi and English commonly used in modern India) with human-generated English translations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCredit\\n\\t\\n\\nAll credit goes to:\\nPHINC: A Parallel Hinglish Social Media Code-Mixed Corpus for Machine Translation (Srivastava & Singh, WNUT 2020)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOriginal Abstract\\n\\t\\n\\nCode-mixing is the phenomenon of using more than one language in a sentence. It is a very‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/veezbo/phinc."},
  {"name":"mqnli","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SachinPatel248/mqnli","creator_name":"Patel","creator_url":"https://huggingface.co/SachinPatel248","description":"SachinPatel248/mqnli dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Tasmay-Tib/sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600","creator_name":"Tasmay Pankaj Tibrewal","creator_url":"https://huggingface.co/Tasmay-Tib","description":"Dataset for sarvam's entity normalisation task. More detailed information can be found here, in the main model repo: Hugging Face\\nDetailed Report (Writeup): Google Drive\\nIt also has a gguf variant, with certain additional gguf based innstructions: Hugging Face\\nModel inference script can be found here: Colab\\nModel predictions can be found in this dataset and both the repo files. named as: \\n\\neval_data_001_predictions.csv and eval_data_001_predictions_excel.csv.\\ntrain_data_001_predictions.csvand‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tasmay-Tib/sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600."},
  {"name":"english-hindi-colloquial-dataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/KumariPrerna2905/english-hindi-colloquial-dataset","creator_name":"Prerna Kumari","creator_url":"https://huggingface.co/KumariPrerna2905","description":"This dataset consists of a thoughtfully assembled collection of everyday English phrases and their Hindi translations. It highlights informal language, including slang, idiomatic expressions, and common phrases, making it ideal for training models that process casual conversations.\\nDataset Details:\\nSize:e.g., 100+ phrase pairs\\nSource: Gathered from publicly available datasets and crowd-contributed inputs.\\nLanguage Pair: English to Hindi\\nUse Cases:  \\n\\nDeveloping and optimizing translation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KumariPrerna2905/english-hindi-colloquial-dataset."},
  {"name":"ncert_upsc_text_6to12","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ritik22912/ncert_upsc_text_6to12","creator_name":"Ritik Kumar","creator_url":"https://huggingface.co/ritik22912","description":"ritik22912/ncert_upsc_text_6to12 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"bhashini","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/DivaJais/bhashini","creator_name":"Devanshi Jaiswal","creator_url":"https://huggingface.co/DivaJais","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DivaJais/bhashini."},
  {"name":"hindiTabQA","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/vaishali/hindiTabQA","creator_name":"Vaishali Pal","creator_url":"https://huggingface.co/vaishali","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"hindiTabQA\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport pandas as pd\\nfrom datasets import load_dataset\\n\\nhinditableQA = load_dataset(\\\"vaishali/hindiTabQA\\\")\\n\\nfor sample in hinditableQA['train']:\\n  question = sample['question']\\n  input_table = pd.read_json(sample['table'], orient='split')\\n  answer = pd.read_json(sample['answer'], orient='split')\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBibTeX entry and citation info\\n\\t\\n\\n@inproceedings{pal-etal-2024-table,\\n    title = \\\"Table Question Answering for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vaishali/hindiTabQA."},
  {"name":"COMI-LINGUA","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LingoIITGN/COMI-LINGUA","creator_name":"Lingo Research Group","creator_url":"https://huggingface.co/LingoIITGN","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nCOMI-LINGUA (COde-MIxing and LINGuistic Insights on Natural Hinglish Usage and Annotation) is a high-quality Hindi-English code-mixed dataset, manually annotated by three annotators. It serves as a benchmark for multilingual NLP models by covering multiple foundational tasks.\\nCOMI-LINGUA provides annotations for several key NLP tasks:\\n\\nLanguage Identification (LID): Token-wise classification of Hindi, English, and other linguistic units.\\nMatrix Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LingoIITGN/COMI-LINGUA."},
  {"name":"ghazals-nazms-shers-rekhta","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Pranjalya/ghazals-nazms-shers-rekhta","creator_name":"Pranjalya Tiwari","creator_url":"https://huggingface.co/Pranjalya","description":"Pranjalya/ghazals-nazms-shers-rekhta dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"product-database","license":"GNU Affero General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Food Facts Database\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is üçä Open Food Facts?\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tA food products database\\n\\t\\n\\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\\n\\n\\t\\n\\t\\t\\n\\t\\tMade by everyone\\n\\t\\n\\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database."},
  {"name":"test_4","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4."},
  {"name":"prompt-injection-multilingual","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/rikka-snow/prompt-injection-multilingual","creator_name":"Le Xuan Hoang","creator_url":"https://huggingface.co/rikka-snow","description":"rikka-snow/prompt-injection-multilingual dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Hindi-Normalisation","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Rahul-1337/Hindi-Normalisation","creator_name":"Rahul Singh","creator_url":"https://huggingface.co/Rahul-1337","description":"Rahul-1337/Hindi-Normalisation dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Telugu-NLP-AI-Dialect-Comedy-video-Dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Automation-Tribe/Telugu-NLP-AI-Dialect-Comedy-video-Dataset","creator_name":"AUTTRIBE-AI-AUTOMATION","creator_url":"https://huggingface.co/Automation-Tribe","description":"Telugu is one of the sweetest and oldest languages of India. A deep Dive into Telugu its spoken in 2 states and majorly 16 regional dailects.\\nThis Dataset help you perform operations in NLP and Speech Recognition Models towards telugu Dialects.\\n"},
  {"name":"M-ABSA","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tM-ABSA\\n\\t\\n\\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Description:\\n\\t\\n\\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\\nAll datasets are stored in the data/ folder:\\n\\nAll dataset contains 7 domains.\\n\\ndomains = [\\\"coursera\\\", \\\"hotel\\\", \\\"laptop\\\", \\\"restaurant\\\", \\\"phone\\\", \\\"sight\\\", \\\"food\\\"]\\n\\n\\nEach dataset contains 21 languages.\\n\\nlangs = [\\\"ar\\\", \\\"da\\\", \\\"de\\\", \\\"en\\\", \\\"es\\\", \\\"fr\\\", \\\"hi\\\", \\\"hr\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA."},
  {"name":"fka-awesome-chatgpt-prompts-hindi","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/bingbangboom/fka-awesome-chatgpt-prompts-hindi","creator_name":"Ding","creator_url":"https://huggingface.co/bingbangboom","description":"üß† Awesome ChatGPT Prompts in Hindi [CSV dataset]\\n\\nThis is a hindi translated dataset repository of Awesome ChatGPT Prompts fka/awesome-chatgpt-prompts\\nView All Original Prompts on GitHub\\n"},
  {"name":"Pralekha","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ai4bharat/Pralekha","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\\n\\t\\n\\t\\t\\n\\t\\tPralekha: Cross-Lingual Document Alignment for Indic Languages\\n\\t\\n\\n\\n  \\n    \\n  \\n  \\n    \\n  \\n  \\n    \\n  \\n  \\n    \\n  \\n\\n\\nPralekha is a large-scale parallel document dataset spanning across 11 Indic languages and English. It comprises over 3 milliondocument pairs, with 1.5 million being English-centric. This dataset serves both as a benchmark for evaluating Cross-Lingual Document Alignment (CLDA) techniques and as a domain-specific parallel corpus for training document-level Machine Translation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Pralekha."},
  {"name":"hindi_parsed_dict_1lakh","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/utkarsh2299/hindi_parsed_dict_1lakh","creator_name":"Utkarsh Pathak","creator_url":"https://huggingface.co/utkarsh2299","description":"utkarsh2299/hindi_parsed_dict_1lakh dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"webfaq","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\\n\\n   \\n       Overview |\\n       Details  |\\n       Structure  |\\n       Examples |\\n       Considerations |\\n       License |\\n       Citation |\\n       Contact |\\n       Acknowledgement\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq."},
  {"name":"xtreme","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xtreme\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme."},
  {"name":"toxi-text-3M","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\\n\\n\\t\\n\\t\\t\\n\\nToxic\\nNeutral\\nTotal\\n\\n\\n\\t\\t\\nmultilingual-train-deduplicated.csv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M."},
  {"name":"belebele","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\\n\\t\\n\\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele."},
  {"name":"librivox-tracks","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\n"},
  {"name":"multilingual-pl-bert","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\\n"},
  {"name":"sib200","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200."},
  {"name":"aya_dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_dataset","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\n\\nCurated by: Contributors of Aya Open Science Intiative.\\n\\nLanguage(s): 65 languages (71 including dialects &‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_dataset."},
  {"name":"aya_collection","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_collection","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection."},
  {"name":"aya_evaluation_suite","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\\n\\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\\nmachine-translations of handpicked examples into 101 languages ‚Üí‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite."},
  {"name":"CulturaY","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \\nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \\nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY."},
  {"name":"aya_collection_language_split","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_collection_language_split","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection_language_split."},
  {"name":"GlotCC-V1","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
  {"name":"GlotCC-V1","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
  {"name":"muri-it","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it."},
  {"name":"HPLT2.0_cleaned","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned."},
  {"name":"belebele-fleurs","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBelebele-Fleurs\\n\\t\\n\\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\\n\\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs."},
  {"name":"sib-fleurs","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs."},
  {"name":"2M-Belebele","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2M-Belebele\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\\n\\t\\n\\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \\nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele."},
  {"name":"reranker_continuous_filt_max7_train","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReranker training data\\n\\t\\n\\nThis data was generated using 4 steps:\\n\\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \\\"1\\\", \\\"2\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train."},
  {"name":"reranking-datasets-light","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"unkown","creator_url":"https://huggingface.co/abdoelsayed","description":"\\n\\t\\n\\t\\t\\n\\t\\tüî• Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation üî•\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\\n\\t\\n\\n\\n    \\n    \\n    \\n    \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n    \\n\\n\\n\\nA curated collection of ready-to-use datasets for retrieval and reranking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light."},
  {"name":"degeneration-html-multilingual","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe Degeneration of the Nation Multilingual Dataset\\n\\t\\n\\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual."},
  {"name":"Synthdog-Multilingual-100","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthdog Multilingual\\n\\t\\n\\n\\n\\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100."},
  {"name":"smol","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tSMOL\\n\\t\\n\\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\\ntranslations into 221 Low-Resource Languages, for the purpose of training\\ntranslation models, and otherwise increasing the representations of said\\nlanguages in NLP and technology.\\nPlease read the SMOL Paper and the\\nGATITOS Paper for a much more\\nthorough description!\\nThere are four resources in this directory:\\n\\nSmolDoc: document-level translations into 100 languages\\nSmolSent: sentence-level translations into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/smol."},
  {"name":"high-quality-multilingual-sentences","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tHigh Quality Multilingual Sentences\\n\\t\\n\\n\\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\\n\\nExample row (from the all config):\\n{\\n    \\\"text\\\": \\\"ÿßŸÖÿßŸÖ ÿ¨ŸÖÿπŸá ÿßÿµŸÅŸáÿßŸÜ ⁄ØŸÅÿ™: ŸÖ€åÿ≤ÿßŸÜ ŸÜ€åÿßÿ≤ ÿ¢ÿ® ÿ¥ÿ±ÿ® ÿßÿµŸÅŸáÿßŸÜ €±€±.€µ ŸÖÿ™ÿ± ŸÖ⁄©ÿπÿ® ÿßÿ≥ÿ™ ⁄©Ÿá ÿ™ŸÖÿßŸÖ ÿßÿ≥ÿ™ÿßŸÜ ÿßÿµŸÅŸáÿßŸÜ ÿ±ÿß ŸæŸàÿ¥ÿ¥ ŸÖ€åÿØŸáÿØ Ÿà ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸÇÿ®ŸÑ ÿßÿ≤ ÿßŸÜŸÇŸÑÿßÿ® €å⁄©€å ÿßÿ≤ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿáÿß ÿØÿ± ÿ≠Ÿàÿ≤Ÿá ÿ¢ÿ® ÿ®ŸàÿØŸá ÿßÿ≥ÿ™.\\\",\\n    \\\"fasttext\\\": \\\"fa\\\",\\n    \\\"gcld3\\\": \\\"fa\\\"\\n}\\n\\nFields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences."},
  {"name":"wikipedia_quality_wikirank","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy It‚Äôs Important\\n\\t\\n\\n\\nEnhances Trust: For readers and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank."},
  {"name":"multilingual_translation_sft","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"opus_ubuntu","license":"BSD 3-Clause \"New\" or \"Revised\" License","language":"en","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu."},
  {"name":"flores_101","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
  {"name":"wit_base","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base."},
  {"name":"HashtagPrediction","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\\n\\t\\n\\n  \\nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \\n[arXiv]\\n[HuggingFace Models]\\n[Github repo]\\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDownload\\n\\t\\n\\nUse the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction."},
  {"name":"flores_101","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
  {"name":"xP3x-sample","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities."},
  {"name":"wikianc","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc."},
  {"name":"entity_cs","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EntityCS\\n\\t\\n\\n\\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \\nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \\nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \\nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs."},
  {"name":"CommonVoiceCorpusHindi15","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/yagnikposhiya/CommonVoiceCorpusHindi15","creator_name":"Yagnik Poshiya","creator_url":"https://huggingface.co/yagnikposhiya","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCommonVoiceCorpusHindi15\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDirectory structure:\\n\\t\\n\\n\\nassets \\n a. Download whole compressed dataset by clicking on the cv-corpus-15.0-2023-09-08-hi.tar.gz file. \\n b. splitdata.py, python script contains code to split \\\"clips\\\" direcrtory in the original dataset. Because HuggingFace supports 10,000 files per directory but in the original dataset \\\"clips\\\" directory contains 14,000 files almost. So, \\\"clips\\\" directory is splitted into two directories \\\"clips0\\\" and \\\"clips1\\\".‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yagnikposhiya/CommonVoiceCorpusHindi15."},
  {"name":"MultiCoNER","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/tomaarsen/MultiCoNER","creator_name":"Tom Aarsen","creator_url":"https://huggingface.co/tomaarsen","description":"We present MultiCoNER, a large multilingual dataset for Named Entity Recognition that covers 3 domains (Wiki sentences, questions, and search queries) across 11 languages, as well as multilingual and code-mixing subsets. This dataset is designed to represent contemporary challenges in NER, including low-context scenarios (short and uncased text), syntactically complex entities like movie titles, and long-tail entity distributions. The 26M token dataset is compiled from public resources using techniques such as heuristic-based sentence sampling, template extraction and slotting, and machine translation. We applied two NER models on our dataset: a baseline XLM-RoBERTa model, and a state-of-the-art GEMNET model that leverages gazetteers. The baseline achieves moderate performance (macro-F1=54%), highlighting the difficulty of our data. GEMNET, which uses gazetteers, improvement significantly (average improvement of macro-F1=+30%). MultiCoNER poses challenges even for large pre-trained language models, and we believe that it can help further research in building robust NER systems. MultiCoNER is publicly available at https://registry.opendata.aws/multiconer/ and we hope that this resource will help advance research in various aspects of NER."},
  {"name":"udhr-lid","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUDHR-LID\\n\\t\\n\\nWhy UDHR-LID?\\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \\\"missing\\\" or \\\"?\\\". Also, about 1/3 of the sentences consist only of \\\"articles 1-30\\\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid."},
  {"name":"mC4-hindi","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zicsx/mC4-hindi","creator_name":"Satish Kumar Mishra","creator_url":"https://huggingface.co/zicsx","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"mC4-hindi\\\"\\n\\t\\n\\nThis dataset is a subset of the mC4 dataset, which is a multilingual colossal, cleaned version of Common Crawl's web crawl corpus. It contains natural text in 101 languages, including Hindi. This dataset is specifically focused on Hindi text, and contains a variety of different types of text, including news articles, blog posts, and social media posts.\\nThis dataset is intended to be used for training and evaluating natural language processing models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zicsx/mC4-hindi."},
  {"name":"seamless-align","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to use the data\\n\\t\\n\\nThere are two ways to access the data:\\n\\nVia the Hugging Face Python datasets library\\n\\nScripts coming soon‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align."},
  {"name":"WEATHub","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/iamshnoo/WEATHub","creator_name":"Anjishnu Mukherjee","creator_url":"https://huggingface.co/iamshnoo","description":"\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"WEATHub\\\"\\n\\t\\n\\nThis dataset corresponds to the data described in the paper \\\"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\\\"\\naccepted to EMNLP 2023.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)\\nto measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub."},
  {"name":"ntx_llm_instructions","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format\\n\\t\\n\\nThis dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license and conditions.\\nIt contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you utilize this dataset version, feel free to cite/footnote this huggingface dataset repo, but please also cite the original dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions."},
  {"name":"ntx_llm_inst_hindi","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_hindi","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format - Hindi subset\\n\\t\\n\\nThis dataset is a format conversion for the Hindi data from the original NTX into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nFor the original NTX dataset, the conversion to the Aya instructions format, or more details, please refer to the full dataset in instruction form (https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions) or to the paper‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_hindi."},
  {"name":"hindi_instruct_v1","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/smangrul/hindi_instruct_v1","creator_name":"Sourab Mangrulkar","creator_url":"https://huggingface.co/smangrul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHindi Instruct V1 Dataset\\n\\t\\n\\nThis dataset is curated by Sourab Mangrulkar. It was developed on top of HuggingFaceH4/no_robots dataset. \\nFirst, the dataset was translated using ai4bharat/indictrans2-en-indic-1B SoTA translation model developed by AI4Bharat. \\nHere, it is important to note that the sequence length limit is 256 for input and output sequences. \\nHence, I split the individual sentences on full stop and create minibatches for translation and then stitch them back properly.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smangrul/hindi_instruct_v1."},
  {"name":"HelpSteer-hindi","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SherryT997/HelpSteer-hindi","creator_name":"Sherry Thomas","creator_url":"https://huggingface.co/SherryT997","description":"SherryT997/HelpSteer-hindi dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"hinglish_open_hathi_dataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/shuvom/hinglish_open_hathi_dataset","creator_name":"shuvam mandal","creator_url":"https://huggingface.co/shuvom","description":"shuvom/hinglish_open_hathi_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"BB-Ultrachat-IndicLingual6-12k","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/rohansolo/BB-Ultrachat-IndicLingual6-12k","creator_name":"Rohan","creator_url":"https://huggingface.co/rohansolo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBB-Ultrachat-IndicLingual6-12k\\n\\t\\n\\nThis dataset is created by bhaiyabot ai to enrich language model training data, especially in the context of Indic languages. code for creation is also open source at https://github.com/ro-hansolo/IndicTrans2HuggingFaceDatasets\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nBB-Ultrachat-IndicLingual6-12k is a curated dataset comprising 12,000 multi-turn conversations, which are a subset of the larger HuggingFaceH4/ultrachat_200k dataset. These conversations have been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rohansolo/BB-Ultrachat-IndicLingual6-12k."},
  {"name":"YThindi","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/shuvom/YThindi","creator_name":"shuvam mandal","creator_url":"https://huggingface.co/shuvom","description":"This Hindi text dataset, comprising 10,000 rows, offers a comprehensive array of content encompassing diverse aspects of Hindi topics, \\nranging from education and comedy to computer science and machine learning. The dataset serves as a valuable resource for finetuning or training models, \\nwith a specific emphasis on Hinglish language processing. Its extensive coverage across various domains makes it particularly advantageous for enhancing the performance of models tailored to Hinglish, such as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shuvom/YThindi."},
  {"name":"YThindi","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/shuvom/YThindi","creator_name":"shuvam mandal","creator_url":"https://huggingface.co/shuvom","description":"This Hindi text dataset, comprising 10,000 rows, offers a comprehensive array of content encompassing diverse aspects of Hindi topics, \\nranging from education and comedy to computer science and machine learning. The dataset serves as a valuable resource for finetuning or training models, \\nwith a specific emphasis on Hinglish language processing. Its extensive coverage across various domains makes it particularly advantageous for enhancing the performance of models tailored to Hinglish, such as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shuvom/YThindi."},
  {"name":"WikidataLabels","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/rayliuca/WikidataLabels","creator_name":"Ray Liu","creator_url":"https://huggingface.co/rayliuca","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikidata Labels\\n\\t\\n\\nLarge parallel corpus for machine translation\\n\\nEntity label data extracted from Wikidata (2022-01-03), filtered for item entities only  \\nOnly download the languages you need with datasets>=2.14.0\\nSimilar dataset: https://huggingface.co/datasets/wmt/wikititles (18 Wikipedia titles pairs instead of all Wikidata entities)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nWikidata JSON dump (wikidata-20220103-all.json.gz)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rayliuca/WikidataLabels."},
  {"name":"ai2_arc-hi","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ai4bharat/ai2_arc-hi","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"ai2_arc\\\" translated into Hindi\\n\\t\\n\\nThis is Hindi translated version of \\\"ai2_arc\\\" using the IndicTrans2 model (Gala et al., 2023).\\nWe recommend you to visit the \\\"ai2_arc\\\" huggingface dataset card (link) for the details.\\n"},
  {"name":"alpaca_hindi_small","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/QuantumMik/alpaca_hindi_small","creator_name":"mik","creator_url":"https://huggingface.co/QuantumMik","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAlpaca Hindi Small\\n\\t\\n\\nThis is a synthesized dataset created by translation of alpaca dataset from English to Hindi language.\\n"},
  {"name":"megawika-report-generation","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika for Report Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. \\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation."},
  {"name":"Custom_common_voice_dataset_using_RVC","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Aniket-Tathe-08/Custom_common_voice_dataset_using_RVC","creator_name":"Aniket Tathe","creator_url":"https://huggingface.co/Aniket-Tathe-08","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCustom Data Augmentation for low resource ASR using Bark and    Retrieval-Based Voice Conversion\\n\\t\\n\\nCustom common_voice_v11 corpus with a custom voice was was created using RVC(Retrieval-Based Voice Conversion) \\nThe model underwent 200 epochs of training, utilizing a total of 1 hour of audio clips. The data was scraped from Youtube.\\nThe audio in the custom generated dataset is of a YouTuber named \\nAjay Pandey\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlicense: cc0-1.0\\nlanguage:\\n- hi‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniket-Tathe-08/Custom_common_voice_dataset_using_RVC."},
  {"name":"English-Hinglish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rvv-karma/English-Hinglish","creator_name":"Rahul Vishwakarma","creator_url":"https://huggingface.co/rvv-karma","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnglish Hinglish\\n\\t\\n\\nEnglish to Hinglish Dataset processed from findnitai/english-to-hinglish.\\nSources:\\n\\nHinglish TOP Dataset\\nCMU English Dog\\nHinGE\\nPHINC\\n\\n"},
  {"name":"English-Hinglish-TOP","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rvv-karma/English-Hinglish-TOP","creator_name":"Rahul Vishwakarma","creator_url":"https://huggingface.co/rvv-karma","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnglish Hinglish (TOP Dataset)\\n\\t\\n\\nThis dataset is generated from Hinglish-TOP Dataset.\\nData distribution:\\n\\nTrain a. Human Generated - 6513 b. Synthetically generated - 170083  \\nValidation a. Human Generated - 1390 b. Synthetically generated - 0  \\nTest a. Human Generated - 6513 b. Synthetically generated - 0\\n\\n"},
  {"name":"Pontoon-Translations","license":"Mozilla Public License 2.0","language":"en","url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations."},
  {"name":"language_tags","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"Fran√ßais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog convention‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags."},
  {"name":"Hindi_Mithai","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/VishalMysore/Hindi_Mithai","creator_name":"Vishal Mysore","creator_url":"https://huggingface.co/VishalMysore","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Indian Sweets\\n\\t\\n\\n"},
  {"name":"Deltacorpus_1.1","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, Portoro≈æ, Slovenia).\\nChanges in version 1.1: \\n\\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \\n\\nSVM classifier trained on Universal Dependencies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1."},
  {"name":"Saka-Alpaca-v1","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Sakalti/Saka-Alpaca-v1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"https://chatgpt.com\\n"},
  {"name":"MMMLU","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLU‚Äôs test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU."},
  {"name":"hindi-malayalam-dataset","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/YADHU1234/hindi-malayalam-dataset","creator_name":"YADHU","creator_url":"https://huggingface.co/YADHU1234","description":"\\n\\t\\n\\t\\t\\n\\t\\tHindi-Malayalam Dataset\\n\\t\\n\\nThis dataset contains parallel translations between Hindi and Malayalam, extracted from the bible_para dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nLanguages: Hindi (hin_Deva) and Malayalam (mal_Mlym)\\nSource: nllb\\nLicense: CC BY 4.0\\nUse Cases: Machine translation, linguistic research.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tExample\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nHindi\\nMalayalam\\n\\n\\n\\t\\t\\n‡§®‡§Æ‡§∏‡•ç‡§§‡•á\\n‡¥π‡¥≤‡µã\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLicense\\n\\t\\n\\nThe dataset is licensed under the CC BY 4.0 License.\\n"},
  {"name":"Bharat_NanoClimateFEVER_hi","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hi."},
  {"name":"Bharat_NanoFEVER_hi","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hi."},
  {"name":"Bharat_NanoFiQA2018_hi","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hi."},
  {"name":"Bharat_NanoNFCorpus_hi","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hi."},
  {"name":"Bharat_NanoQuoraRetrieval_hi","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hi."},
  {"name":"Bharat_NanoSciFact_hi","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoSciFact dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hi."},
  {"name":"Hindi-Poetry-Dataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ReySajju742/Hindi-Poetry-Dataset","creator_name":"Muhammad Sajjad Rasool","creator_url":"https://huggingface.co/ReySajju742","description":"\\n\\t\\n\\t\\t\\n\\t\\tHindi Transliteration of Urdu Poetry Dataset\\n\\t\\n\\nWelcome to the Hindi Transliteration of Urdu Poetry Dataset! This dataset features Hindi transliterations of traditional Urdu poetry. Each entry in the dataset includes two columns:\\n\\nTitle: The transliterated title of the poem in Hindi.\\nPoem: The transliterated text of the Urdu poem rendered in Hindi script.\\n\\nThis dataset is perfect for researchers and developers working on cross-script language processing, transliteration models, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ReySajju742/Hindi-Poetry-Dataset."},
  {"name":"Hindi-Poetry-Dataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ReySajju742/Hindi-Poetry-Dataset","creator_name":"Muhammad Sajjad Rasool","creator_url":"https://huggingface.co/ReySajju742","description":"\\n\\t\\n\\t\\t\\n\\t\\tHindi Transliteration of Urdu Poetry Dataset\\n\\t\\n\\nWelcome to the Hindi Transliteration of Urdu Poetry Dataset! This dataset features Hindi transliterations of traditional Urdu poetry. Each entry in the dataset includes two columns:\\n\\nTitle: The transliterated title of the poem in Hindi.\\nPoem: The transliterated text of the Urdu poem rendered in Hindi script.\\n\\nThis dataset is perfect for researchers and developers working on cross-script language processing, transliteration models, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ReySajju742/Hindi-Poetry-Dataset."},
  {"name":"gsm8k-hindi","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bingbangboom/gsm8k-hindi","creator_name":"Ding","creator_url":"https://huggingface.co/bingbangboom","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for GSM8K-Hindi\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a machine-translated hindi version of the popular GSM8K dataset from OpenAI. GSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\\n\\nThese problems take between 2 and 8 steps to solve.\\nSolutions primarily involve performing a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bingbangboom/gsm8k-hindi."},
  {"name":"indic_sentiment_analyzer","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/dhruv0808/indic_sentiment_analyzer","creator_name":"Dhruv Bhatnagar","creator_url":"https://huggingface.co/dhruv0808","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Sentiment Analysis Dataset for Indian Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis repository contains a comprehensive sentiment analysis dataset covering 11 Indian languages and English. The dataset is designed to support sentiment analysis tasks across multiple domains and languages, making it valuable for developing multilingual sentiment analysis models and applications.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages Covered\\n\\t\\n\\n\\nEnglish (en) - Original\\nHindi (hi)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dhruv0808/indic_sentiment_analyzer."},
  {"name":"Language_Identification_v1","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Process-Venue/Language_Identification_v1","creator_name":"ProcessVenue","creator_url":"https://huggingface.co/Process-Venue","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Language Identification Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA comprehensive dataset for Indian language identification and text classification. The dataset contains text samples across 10 major Indian languages, making it suitable for developing language identification systems and multilingual NLP applications.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages and Distribution\\n\\t\\n\\nLanguage Distribution:\\nUrdu         1000\\nHindi        1000\\nOdia         1000\\nTamil        1000\\nKannada      1000\\nBengali‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Process-Venue/Language_Identification_v1."},
  {"name":"V1Q","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q."},
  {"name":"Bharat_NanoArguAna_hi","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoArguAna dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hi."},
  {"name":"Bharat_NanoTouche2020_hi","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hi."},
  {"name":"hindi-poetry","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rahul7star/hindi-poetry","creator_name":"rahul7star","creator_url":"https://huggingface.co/rahul7star","description":"rahul7star/hindi-poetry dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"multilingual_translation_gen_binarized","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"squad_v1.1_np","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/suban244/squad_v1.1_np","creator_name":"Suban Shrestha","creator_url":"https://huggingface.co/suban244","description":"\\n\\t\\n\\t\\t\\n\\t\\tSQuAD-NP: Nepali Translation of SQuAD\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nSQuAD-NP is a Nepali translation of the SQuAD dataset, the standard dataset for question answering task. The dataset consists of Nepali translations of the original English passages, questions, and answers from the SQuAD dataset. \\nThis resource is useful for training machine learning models on extractive question-answering tasks in Nepali.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nLanguage: Nepali (ne)\\nSource: Translated from SQuAD-English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suban244/squad_v1.1_np."},
  {"name":"HPLT2.0_cleaned","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned."}
];
