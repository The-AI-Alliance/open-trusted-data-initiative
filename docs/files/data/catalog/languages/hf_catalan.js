var data_for_catalan = [

  {"name":"medieval","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATMuS/medieval","creator_name":"CATMuS: Consistent Approach to Transcribing ManuScripts","creator_url":"https://huggingface.co/CATMuS","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for CATMuS Medieval\\n\\t\\n\\n\\nJoin our Discord to ask questions about the dataset: \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nHandwritten Text Recognition (HTR) has emerged as a crucial tool for converting manuscripts images into machine-readable formats, \\nenabling researchers and scholars to analyse vast collections efficiently. \\nDespite significant technological progress, establishing consistent ground truth across projects for HTR tasks, \\nparticularly for complex and heterogeneousâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATMuS/medieval."},
  {"name":"mgsm_ca","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/projecte-aina/mgsm_ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for mgsm_ca\\n\\t\\n\\n\\n\\nmgsm_ca is a question answering dataset in Catalan that has been professionally translated from the MGSM dataset in English. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nmgsm_ca (Multilingual Grade School Math - Catalan) is designed to evaluate multi-step mathematical reasoning using grade school math word problems. It includes 8 instances in the train split and another 250 \\ninstances in the test split. Each instance contains aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/mgsm_ca."},
  {"name":"xstorycloze_ca","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/xstorycloze_ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xstorycloze_ca\\n\\t\\n\\n\\n\\nxstorycloze_ca is a question answering dataset in Catalan, professionally translated from the English StoryCloze dataset (Spring 2016 version), used  to create its multilingual version XStoryCloze.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nxstorycloze_ca (Multilingual Story Cloze Test - Catalan) is based on multiple-choice narrative completions. The dataset consists of 360 instances in the train split and 1510 instancesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/xstorycloze_ca."},
  {"name":"piqa_ca","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/projecte-aina/piqa_ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for piqa_ca\\n\\t\\n\\n\\n\\npiqa_ca is a multiple choice question answering dataset in Catalan that has been professionally translated from the PIQA  validation set in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\npiqa_ca (Physical Interaction Question Answering - Catalan) is designed to evaluate physical commonsense reasoning using question-answer triplets based on everyday situations. It includes 1838 instances in the validation split. Eachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/piqa_ca."},
  {"name":"siqa_ca","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/siqa_ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for siqa_ca\\n\\t\\n\\n\\n\\nsiqa_ca is a multiple choice question answering dataset in Catalan that has been professionally translated from the SIQA \\nvalidation set in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nsiqa_ca (Social Interaction Question Answering - Catalan) is designed to evaluate social commonsense intelligence using multiple choice question-answer instances based on reasoning about peopleâ€™s actions and their \\nsocial implications. Itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/siqa_ca."},
  {"name":"MentorCA","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/MentorCA","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMentor_CA is an open source dataset of 10,175 instructions in Catalan, machine translated from the original Mentor_ES dataset in Spanish, and organized in several of the behavioral categories outlined in the InstructGPT paper, including closed QA, open QA, general QA, classification, information extraction, summarization, creative writing and brainstorming.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nUseful for fine-tuning instructions in large languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/MentorCA."},
  {"name":"openbookqa_ca","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/openbookqa_ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for openbookqa_ca\\n\\t\\n\\n\\n\\nopenbookqa_ca is a question answering dataset in Catalan, professionally translated from the main version of the OpenBookQA dataset in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nopenbookqa_ca (Open Book Question Answering - Catalan) is designed to simulate open book exams and assess human-like understanding of a subject. The dataset comprises 500 instances in the validation split and another 500 instances in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/openbookqa_ca."},
  {"name":"oasst1_ca","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/oasst1_ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for oasst1_ca\\n\\t\\n\\n\\n\\noasst1_ca is a conversational dataset in Catalan that has been professionally translated from the OASST1 dataset. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\noasst1_ca (OpenAssistant Conversations Release 1 - Catalan) consists of human-generated, human-annotated assistant-style conversation corpus. It includes 5213 messages in the train split and 273 messages in the validation split. To arrive to this number, we filter theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/oasst1_ca."},
  {"name":"Catalan-Raw-Text","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/catallama/Catalan-Raw-Text","creator_name":"CataLlama","creator_url":"https://huggingface.co/catallama","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Catalan Raw Text Dataset is a subset of the projecte-aina/catalan_general_crawling.\\nIt is licensed under a Creative Commons Attribution 4.0 International license, just like the origin dataset.\\nThe dataset consists of 404k samples (roughly 20% of the original), totalling 331M tokens after tokenizing it with the Llama-3 Tokenizer.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is in Catalan (ca-ES).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\ntext (str): Text.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splitsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/catallama/Catalan-Raw-Text."},
  {"name":"Catalan-Instruct","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/catallama/Catalan-Instruct","creator_name":"CataLlama","creator_url":"https://huggingface.co/catallama","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Catalan Instruct Dataset contains 328k sample instructions totalling 114M tokens after tokenizing it with the Llama-3 Tokenizer.\\nThe dataset is a collection of samples from existing datasets and new data generated synthetically with ChatGPT 3.5\\nSome sampled datasets were used as is, and some were augmented with ChatGPT 3.5\\nIt is licensed under a Creative Commons Attribution 4.0 International license since many instructions are an augmentation of datasets withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/catallama/Catalan-Instruct."},
  {"name":"Chatgpt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt."},
  {"name":"Catalan-Instruct-V2","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/catallama/Catalan-Instruct-V2","creator_name":"CataLlama","creator_url":"https://huggingface.co/catallama","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Catalan Instruct V2 Dataset is a new iteration on the Catalan Instruct dataset.\\nThe V2 is 2.5x larger than V1 and it contains high quality instructions filtered from multiple public datasets.\\nIt also contains an additional 250k new translated instructions from Catalan to English, taking the total number of Catalan instructions to 460k+.\\nIn total, the dataset contains 709k sample instructions totalling 289M tokens after tokenizing it with the Llama-3â€¦ See the full description on the dataset page: https://huggingface.co/datasets/catallama/Catalan-Instruct-V2."},
  {"name":"Catalan-DPO-V2","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/catallama/Catalan-DPO-V2","creator_name":"CataLlama","creator_url":"https://huggingface.co/catallama","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Catalan DPO V2 Dataset contains 23.5k sample preferences which is roughly 70% more than the Catalan DPO V1 dataset.\\nThe dataset comprises of synthetically generated data and public preferences datasets:\\n\\nargilla-orca: 9.5k preferences sampled from argilla/distilabel-intel-orca-dpo-pairs, out of which 50% were translated to Catalan\\nargilla-capybara: 7.2k preferences sampled from argilla/Capybara-Preferences-Filtered\\n6.8k preferences generated synthetically byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/catallama/Catalan-DPO-V2."},
  {"name":"Catalan-DPO-V2","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/catallama/Catalan-DPO-V2","creator_name":"CataLlama","creator_url":"https://huggingface.co/catallama","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Catalan DPO V2 Dataset contains 23.5k sample preferences which is roughly 70% more than the Catalan DPO V1 dataset.\\nThe dataset comprises of synthetically generated data and public preferences datasets:\\n\\nargilla-orca: 9.5k preferences sampled from argilla/distilabel-intel-orca-dpo-pairs, out of which 50% were translated to Catalan\\nargilla-capybara: 7.2k preferences sampled from argilla/Capybara-Preferences-Filtered\\n6.8k preferences generated synthetically byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/catallama/Catalan-DPO-V2."},
  {"name":"EADOP-RAG-out-of-domain","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/alinia/EADOP-RAG-out-of-domain","creator_name":"Alinia AI","creator_url":"https://huggingface.co/alinia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEADOP RAG out-of-domain Dataset Card\\n\\t\\n\\nThis dataset consists of 2,000+ human annotated in- and out-of-domain user messages and assistant responses \\nin the context of a chatbot that can provide helpful information about the current Catalan legislation. \\nThe dataset was collected in collaboration with the \\nEntitat AutÃ²noma del Diari Oficial i de Publicacions (EADOP) in the \\ncontext of a collaboration between the Language Technologies Unit at the Barcelona Supercomputing Center \\nandâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alinia/EADOP-RAG-out-of-domain."},
  {"name":"panlex","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex."},
  {"name":"common_voice_16_1_ca_up_5","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/xaviviro/common_voice_16_1_ca_up_5","creator_name":"Xavi","creator_url":"https://huggingface.co/xaviviro","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCommon Voice Corpus 16.1 CatalÃ  (up_votes>5)\\n\\t\\n\\nDataset extret de mozilla-foundation/common_voice_16_1 nomÃ©s els splits train i test del CatalÃ  i amb up_votes > 5\\n"},
  {"name":"MultiQ","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiQ\\n\\t\\n\\nThis is the dataset corresponding to the paper \\\"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\\\". \\nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \\ntranslated into 137 typologically diverse languages. \\n\\nCurated by: Carolin Holtermann, Paul RÃ¶ttger, Timm Dill, Anne Lauscher\\nLanguage(s) (NLP): 137 diverseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ."},
  {"name":"bhojpuri","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri."},
  {"name":"panlex-meanings","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings."},
  {"name":"NTREX","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX."},
  {"name":"arc_ca","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/arc_ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for arc_ca\\n\\t\\n\\n\\n\\narc_ca is a question answering dataset in Catalan, professionally translated from the Easy and Challenge versions of the ARC dataset in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\narc_ca (AI2 Reasoning Challenge - Catalan) is based on multiple-choice science questions at elementary school level. The dataset consists of 2950 instances in the Easy version (570 in the test and 2380 instances in the validation split) andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/arc_ca."},
  {"name":"xsimplusplus","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n"},
  {"name":"Catalan-DPO","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/catallama/Catalan-DPO","creator_name":"CataLlama","creator_url":"https://huggingface.co/catallama","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Catalan DPO Dataset contains 13.9k sample preferences generated with the help of the llm-blender/PairRM model.\\nThe dataset is obtained from the test split of the catallama/Catalan-Instruct.\\nThe catallama/CataLlama-v0.1-Instruct-SFT model was inferenced on the test split and generated 5 different sample answers for each instruction.\\nThe PairRM model was the used to select the worst and best answers to create the DPO Dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nCatalanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/catallama/Catalan-DPO."},
  {"name":"multi-wiki-clustering-p2p","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ryzzlestrizzle/multi-wiki-clustering-p2p","creator_name":"Jonathan RystrÃ¸m","creator_url":"https://huggingface.co/ryzzlestrizzle","description":"ryzzlestrizzle/multi-wiki-clustering-p2p dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"sib200","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200."},
  {"name":"NTREX","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX."},
  {"name":"ParaNames","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames."},
  {"name":"CatCoLA","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/nbel/CatCoLA","creator_name":"NÃºria Bel","creator_url":"https://huggingface.co/nbel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGENERAL INFORMATION\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1. Dataset title:\\n\\t\\n\\nCatCoLA - Catalan Corpus of Linguistic Acceptability\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2. Authorship:\\n\\t\\n\\nName: NÃºria Bel\\nInstitution: Universitat Pompeu Fabra, UPF\\nEmail: nuria.bel@upf.edu\\nORCID:  0000-0001-9346-7803\\n\\nName: Marta Punsola\\nInstitution: Universitat Pompeu Fabra, UPF\\nEmail: marta.punsola@gmail.com\\nORCID:  \\n\\nName: Valle Ruiz-FernÃ¡ndez\\nInstitution: Barcelona Supercomputing Center\\nEmail: valle.ruizfernÃ¡ndez@bsc.es\\nORCID:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nbel/CatCoLA."},
  {"name":"bitext_sib200_miners","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fleurs_clean","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean."},
  {"name":"bonanza-hf","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/bertin-project/bonanza-hf","creator_name":"BERTIN Project","creator_url":"https://huggingface.co/bertin-project","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBonanza: Dataset de instrucciones en EspaÃ±ol y CatalÃ¡n\\n\\t\\n\\nEste dataset combina mÃºltiples fuentes para proporcionar instrucciones en espaÃ±ol y catalÃ¡n. Los datasets combinados son los siguientes:\\n\\nOpenAssistant/oasst2\\nCohereForAI/aya_dataset\\nprojecte-aina/RAG_Multilingual\\nbertin-project/alpaca-spanish\\ndariolopez/Llama-2-databricks-dolly-oasst1-es\\nprojecte-aina/MentorES\\nprojecte-aina/MentorCA\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescripciÃ³n\\n\\t\\n\\nEste conjunto de datos proporciona una rica colecciÃ³n deâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bertin-project/bonanza-hf."},
  {"name":"catalan","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Trimux/catalan","creator_name":"Facundo Campos","creator_url":"https://huggingface.co/Trimux","description":"Trimux/catalan dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"xP3x-Kongo","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo."},
  {"name":"librivox-tracks","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\\nChanges:\\n\\nUsed archive.org metadata API to annotate rows with \\\"duration\\\" column\\n\\n"},
  {"name":"muri-it-language-split","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split."},
  {"name":"toy_corpus_asr_ca","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlosdanielhernandezmena/toy_corpus_asr_ca","creator_name":"Carlos Daniel HernÃ¡ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository with a standard data loader. The audio files are compressed in tar format. Since this repository contains very few audio files, it can be used to test certain scripts in local machines.\\n"},
  {"name":"toy_corpus_asr_ca","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlosdanielhernandezmena/toy_corpus_asr_ca","creator_name":"Carlos Daniel HernÃ¡ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository with a standard data loader. The audio files are compressed in tar format. Since this repository contains very few audio files, it can be used to test certain scripts in local machines.\\n"},
  {"name":"mmarco-lt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/andreaschari/mmarco-lt","creator_name":"Andreas Chari","creator_url":"https://huggingface.co/andreaschari","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a variation of mMARCO by Bonifacio et al. used for the \\\"Improving Low-Resource Retrieval Effectiveness using Zero-Shot Linguistic Similarity Transfer\\\" ECIR2025 paper. \\nThe source code for the paper can be found here\\nmMARCO is a multilingual version of the MS MARCO passage ranking dataset.\\nFor more information, checkout the original mMARCO papers:\\n\\nmMARCO: A Multilingual Version of the MS MARCO Passage Ranking Dataset\\nA cost-benefit analysis ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/andreaschari/mmarco-lt."},
  {"name":"IFEval_ca","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/IFEval_ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for IFEval_ca\\n\\t\\n\\n\\n\\nIFEval_ca is a prompt dataset in Catalan, professionally translated from the main version of the IFEval dataset in English. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nIFEval_ca (Instruction-Following Eval benchmark - Catalan) is designed to evaluating chat or instruction fine-tuned language models. The dataset comprises 541 \\\"verifiable instructions\\\" such as \\\"write in more than 400 words\\\" and \\\"mention the keyword of AI atâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/IFEval_ca."},
  {"name":"hhh_alignment_ca","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/hhh_alignment_ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for hhh_alignment_ca\\n\\t\\n\\n\\n\\nhhh_alignment_ca is a question answering dataset in Catalan, professionally translated from the main version of the hhh_alignment dataset in English. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nhhh_alignment_ca (Helpful, Honest, & Harmless - a Pragmatic Alignment Evaluation - Catalan) is designed to evaluate language models on alignment, pragmatically broken down into the categories of helpfulness, honesty/accuracyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/hhh_alignment_ca."},
  {"name":"X-ALMA-Preference","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\\nsource: the source sentence.\\nchosen: the preferred translation.\\nreject: the dis-preferred translation.\\ndirections: the translation direction.\\n@misc{xu2024xalmaplugplay,\\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \\n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\\n      year={2024},\\n      eprint={2410.03115}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference."},
  {"name":"ner-cat","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Ugiat/ner-cat","creator_name":"Ugiat Technologies","creator_url":"https://huggingface.co/Ugiat","description":"\\n\\t\\n\\t\\t\\n\\t\\tNERCat Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe NERCat dataset is a manually annotated collection of Catalan-language television transcriptions, designed to improve Named Entity Recognition (NER) performance for the Catalan language. The dataset covers diverse domains such as politics, sports, and culture, and includes 9,242 sentences with 13,732 named entities annotated across eight categories: Person, Facility, Organization, Location, Product, Event, Date, and Law. The dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ugiat/ner-cat."},
  {"name":"ner-cat","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Ugiat/ner-cat","creator_name":"Ugiat Technologies","creator_url":"https://huggingface.co/Ugiat","description":"\\n\\t\\n\\t\\t\\n\\t\\tNERCat Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe NERCat dataset is a manually annotated collection of Catalan-language television transcriptions, designed to improve Named Entity Recognition (NER) performance for the Catalan language. The dataset covers diverse domains such as politics, sports, and culture, and includes 9,242 sentences with 13,732 named entities annotated across eight categories: Person, Facility, Organization, Location, Product, Event, Date, and Law. The dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ugiat/ner-cat."},
  {"name":"oasst1","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1."},
  {"name":"oasst2","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen Assistant Conversations Dataset Release 2 (OASST2)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \\nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \\nAll messages have a role property: this can either be \\\"assistant\\\" or \\\"prompter\\\". The roles in \\nconversation threads from prompt to leaf node strictly alternate between \\\"prompter\\\" andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2."},
  {"name":"wmt24pp","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tWMT24++\\n\\t\\n\\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\\nthe publication\\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\\nIf you are interested in the images of the source URLs for each document, please see here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema\\n\\t\\n\\nEach language pair is stored in its own jsonl file.\\nEach row isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp."},
  {"name":"mqa","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages."},
  {"name":"catalan-dictionary","license":"GNU General Public License v2.0","language":"en","url":"https://huggingface.co/datasets/softcatala/catalan-dictionary","creator_name":"SoftcatalÃ ","creator_url":"https://huggingface.co/softcatala","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ca-text-corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCatalan word lists with part of speech labeling curated by humans. Contains 1 180 773 forms including verbs, nouns, adjectives, names or toponyms. These word lists are used to build applications like Catalan spellcheckers or verb querying applications.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nCatalan (ca).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset containsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/softcatala/catalan-dictionary."},
  {"name":"Open_Assistant_Conversation_Chains","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\n\\n\\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\\n\\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\\n\\nIt wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains."},
  {"name":"openassistant-deepseek-coder","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using:\\nB_INST = '\\\\n### Instruction:\\\\n'\\nE_INST = '\\\\n### Response:\\\\n'\\nBOS = '<ï½œbeginâ–ofâ–sentenceï½œ>'\\nEOS = '\\\\n<|EOT|>\\\\n'\\n\\nSample Preparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder."},
  {"name":"tokenizer-wiki-bench","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Tokenizer Benchmark\\n\\t\\n\\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \\nfrom transformers importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench."},
  {"name":"RAG_Multilingual","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/RAG_Multilingual","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RAG_Multilingual\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nRAG_Multilingual is an instruction-following synthetic QA dataset created from extractive QA datasets from Catalan, English and Spanish reference sets.\\nThe reference datasets were: SQAD (https://huggingface.co/datasets/rajpurkar/squad), Catalanqa (https://huggingface.co/datasets/projecte-aina/catalanqa) and SQAC (https://huggingface.co/datasets/PlanTL-GOB-ES/SQAC).\\nThis dataset, of 56.406 instances, was created byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/RAG_Multilingual."},
  {"name":"parlament_parla_v3","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/parlament_parla_v3","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ParlamentParla v3 - Speech Corpus of Catalan Parliamentary Sessions\\n\\t\\n\\nA speech corpus composed of Catalan Parliamentary Sessions.The v3 and last version of the corpus includes both clean and other quality segments, divided into short segments (less than 30 seconds) and long segments (more than 30 seconds). The total dataset encompasses 1059h 48m 04s of speech, including 945h 51m 06s for the short segments and 113h 56m 58s for the long segments, with a total ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/parlament_parla_v3."},
  {"name":"mgsm","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/jbross-ibm-research/mgsm","creator_name":"J Bross","creator_url":"https://huggingface.co/jbross-ibm-research","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MGSM\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCopy and merge of this MGSM Dataset, Catalan version, Basque version, Galician version, but in training samples we removed the prompt formatting, e.g. removed Question: ... in question field or Answer: ... in answer field.\\nMultilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper Language models are multilingual chain-of-thought reasoners.\\nThe same 250 problems fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jbross-ibm-research/mgsm."},
  {"name":"VoxCommunis","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis."},
  {"name":"LivingNER","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Praise2112/LivingNER","creator_name":"Praise","creator_url":"https://huggingface.co/Praise2112","description":"\\n\\t\\n\\t\\t\\n\\t\\tLivingNER: Named entity recognition, normalization & classification of species, pathogens and food\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe LivingNER Gold Standard corpus is a collection of 2000 clinical case reports covering a broad range of medical specialities, i.e. infectious diseases (including Covid-19 cases), cardiology, neurology, oncology, dentistry, pediatrics, endocrinology, primary care, allergology, radiology, psychiatry, ophthalmology, urology, internal medicine, emergency andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Praise2112/LivingNER."},
  {"name":"DATA-AI_Chat","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","description":"\\n\\t\\n\\t\\t\\n\\t\\tDATA-AI: Il Modello di IA di M.INC.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tðŸ“Œ Introduzione\\n\\t\\n\\nDATA-AI Ã¨ un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello Ã¨ basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \\nDATA-AI Ã¨ stato addestrato su unâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat."},
  {"name":"wikis","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/nyuuzyou/wikis","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Public MediaWiki Collection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 1,662,448 articles harvested from 930 random public MediaWiki instances found across the Internet. The collection was created by extracting current page content from these wikis, preserving article text, metadata, and structural information. The dataset represents a diverse cross-section of public wiki content spanning multiple domains, topics, and languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wikis."},
  {"name":"opus_dogc","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_dogc","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for OPUS DOGC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nOPUS DOGC is a collection of documents from the Official Journal of the Government of Catalonia, in Catalan and Spanish languages, provided by Antoni Oliver Gonzalez from the Universitat Oberta de Catalunya.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nDataset is multilingual with parallel text in:\\n\\nCatalan\\nSpanish\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_dogc."},
  {"name":"opus_paracrawl","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for OpusParaCrawl\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nParallel corpora from Web Crawls collected in the ParaCrawl project.\\nTha dataset contains:\\n\\n42 languages, 43 bitexts\\ntotal number of files: 59,996\\ntotal number of tokens: 56.11G\\ntotal number of sentence fragments: 3.13G\\n\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs,\\ne.g.\\ndataset = load_dataset(\\\"opus_paracrawl\\\", lang1=\\\"en\\\", lang2=\\\"so\\\")\\n\\nYou can findâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl."},
  {"name":"parla_text_corpus","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Baybars/parla_text_corpus","creator_name":"Baybars KÃ¼lebi","creator_url":"https://huggingface.co/Baybars","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tParlaTextCorpus\\n\\t\\n\\nSpoken text corpus for Catalan. Derived and cleaned from three sources. OpenSubtitles, Tv3Parla and Festcat.\\n"},
  {"name":"ancora-ca-ner","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/ancora-ca-ner","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AnCora-Ca-NER\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a dataset for Named Entity Recognition (NER) in Catalan. It adapts AnCora corpus for Machine Learning and Language Model evaluation purposes.\\nThis dataset was developed by BSC TeMU as part of the Projecte AINA, to enrich the Catalan Language Understanding Benchmark (CLUB).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nNamed Entities Recognition, Language Model\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/ancora-ca-ner."},
  {"name":"casum","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/casum","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CaSum\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCaSum is a summarization dataset. It is extracted from a newswire corpus crawled from the Catalan News Agency (AgÃ¨ncia Catalana de NotÃ­cies; ACN). The corpus consists of 217,735 instances that are composed by the headline and the body.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset can be used to train a model for abstractive summarization. Success on this task is typically measured by achieving a high Rougeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/casum."},
  {"name":"catalan_general_crawling","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/catalan_general_crawling","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Catalan General Crawling\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Catalan General Crawling Corpus is a 435-million-token web corpus of Catalan built from the web. It has been obtained by crawling the 500 most popular .cat and .ad domains during July 2020. It consists of 434,817,705 tokens, 19,451,691 sentences and 1,016,114 documents. Documents are separated by single new lines. It is a subcorpus of the Catalan Textual Corpus.\\nThis work is licensed under a Creativeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/catalan_general_crawling."},
  {"name":"catalan_government_crawling","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/projecte-aina/catalan_government_crawling","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Catalan Government Crawling\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Catalan Government Crawling Corpus is a 39-million-token web corpus of Catalan built from the web. It has been obtained by crawling the .gencat domain and subdomains, belonging to the Catalan Government during September and October 2020. It consists of 39,117,909 tokens, 1,565,433 sentences and 71,043 documents. Documents are separated by single new lines. It is a subcorpus of the Catalan Textualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/catalan_government_crawling."},
  {"name":"catalan_textual_corpus","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/catalan_textual_corpus","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Catalan Textual Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Catalan Textual Corpus is a 1760-million-token web corpus of Catalan built from several sources.\\nIt consists of 1,758,388,896 tokens, 73,172,152 sentences, and 12,556,365 documents. Documents are separated by single new lines. These boundaries have been preserved as long as the license allowed it.\\nThis work is licensed under a Creative Commons Attribution Share Alike 4.0 International license.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/catalan_textual_corpus."},
  {"name":"vilaquad","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/vilaquad","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for VilaQuAD\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nVilaQuAD, An extractive QA dataset for Catalan, from VilaWeb newswire text.\\nThis dataset contains 2095 of Catalan language news articles along with 1 to 5 questions referring to each fragment (or context).\\nVilaQuad articles are extracted from the daily VilaWeb and used under CC-BY-NC-SA-ND licence. \\nThis dataset can be used to build extractive-QA and Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboardsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/vilaquad."},
  {"name":"viquiquad","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/viquiquad","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tViquiQuAD, An extractive QA dataset for Catalan, from the Wikipedia\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nViquiQuAD, An extractive QA dataset for Catalan, from the Wikipedia.\\nThis dataset contains 3111 contexts extracted from a set of 597 high quality original (no translations) articles in the Catalan Wikipedia \\\"ViquipÃ¨dia\\\", and 1 to 5 questions with their answer for each fragment.\\nViquipedia articles are used under CC-by-sa licence. \\nThis dataset can be used to fine-tune and evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/viquiquad."},
  {"name":"wnli-ca","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/wnli-ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWNLI-ca\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\\"A Winograd schema is a pair of sentences that differ in only one or two words and that contain an ambiguity that is resolved in opposite ways in the two sentences and requires the use of world knowledge and reasoning for its resolution. The schema takes its name from Terry Winograd.\\\" Source: The Winograd Schema Challenge.\\nThe Winograd NLI dataset presents 855 sentence pairs, in which the first sentence contains an ambiguity and the secondâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/wnli-ca."},
  {"name":"xquad-ca","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/xquad-ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for XQuAD-Ca\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nProfessional translation into Catalan of XQuAD dataset.\\nXQuAD (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering performance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set of SQuAD v1.1 (Rajpurkar, Pranav et al., 2016) together with their professional translations into ten language: Spanish, Germanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/xquad-ca."},
  {"name":"Softcatala-Web-Texts-Dataset","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/softcatala/Softcatala-Web-Texts-Dataset","creator_name":"SoftcatalÃ ","creator_url":"https://huggingface.co/softcatala","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Softcatala-Web-Texts-Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis repository contains SofcatalÃ  web site content (articles and programs descriptions).\\nDataset size:\\n\\narticles.json contains 623 articles with 373233 words.\\nprogrames.json contains 330 program descriptions with 49868 words.\\n\\nThe license of the data is Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) or Universal Public Domain Dedication (CC0 1.0)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboardsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/softcatala/Softcatala-Web-Texts-Dataset."},
  {"name":"Tilde-MODEL-Catalan","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/softcatala/Tilde-MODEL-Catalan","creator_name":"SoftcatalÃ ","creator_url":"https://huggingface.co/softcatala","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tilde-MODEL-Catalan\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains the German version of the Tilde-MODEL corpus aligned with a Catalan translation.\\nThe catalan text has been obtained using Apertium's RBMT system from the Spanish version. It contains 3.4M segments.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be used to train NMT and SMT systems.\\nIt has been used as a training corpus for the SoftcatalÃ  machine translation engine.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/softcatala/Tilde-MODEL-Catalan."},
  {"name":"ca_text_corpus","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/softcatala/ca_text_corpus","creator_name":"SoftcatalÃ ","creator_url":"https://huggingface.co/softcatala","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ca-text-corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPublic domain corpus of Catalan text.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nCatalan (ca).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/softcatala/ca_text_corpus."},
  {"name":"open-source-english-catalan-corpus","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/softcatala/open-source-english-catalan-corpus","creator_name":"SoftcatalÃ ","creator_url":"https://huggingface.co/softcatala","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for open-source-english-catalan-corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTranslation memory built from more than 180 open source projects. These include LibreOffice, Mozilla, KDE, GNOME, GIMP, Inkscape and many others. It can be used as translation memory or as training corpus for neural translators.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nCatalan (ca)\\nEnglish (en)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/softcatala/open-source-english-catalan-corpus."},
  {"name":"xlel_wd_dictionary","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles."},
  {"name":"xlel_wd","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles."},
  {"name":"catalanqa","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/catalanqa","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CatalanQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset can be used to build extractive-QA and Language Models. It is an aggregation and balancing of 2 previous datasets: VilaQuAD and ViquiQuAD.\\nSplits have been balanced by kind of question, and unlike other datasets like SQuAD, it only contains, per record, one question and one answer for each context, although the contexts can repeat multiple times.\\nThis dataset was developed by BSC TeMU as part of Projecte AINAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/catalanqa."},
  {"name":"xP3all","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot."},
  {"name":"UD_Catalan-AnCora","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/UD_Catalan-AnCora","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUD_Catalan-AnCora\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is composed of the annotations from the AnCora corpus, projected on the Universal Dependencies treebank. We use the POS annotations of this corpus as part of the Catalan Language Understanding Benchmark (CLUB).\\nThis work is licensed under a CC Attribution 4.0 International License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nPOS tagging\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is in Catalan (ca-ES)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/UD_Catalan-AnCora."},
  {"name":"xP3mt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot."},
  {"name":"Fact-Completion","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion","creator_name":"Polyglot-or-Not","creator_url":"https://huggingface.co/Polyglot-or-Not","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\nHomepage: https://bit.ly/ischool-berkeley-capstone\\nRepository: https://github.com/daniel-furman/Capstone\\nPoint of Contact: daniel_furman@berkeley.edu\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the dataset for Polyglot or Not?: Measuring Multilingual Encyclopedic Knowledge Retrieval from Foundation Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTest Description\\n\\t\\n\\n Given a factual association such as The capital of France is Paris, we determine whether a model adequately \\\"knows\\\" thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion."},
  {"name":"self-instruct-seed-ca","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/mapama247/self-instruct-seed-ca","creator_name":"Marc PÃ mies","creator_url":"https://huggingface.co/mapama247","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCatalan self-instruct seed\\n\\t\\n\\nManual translation of the seed instructions from self-instruct.\\nNote that some examples could not be literally translated (e.g. jokes, puns, code) and had to be adapted to the target language.\\n"},
  {"name":"CaSET-catalan-stance-emotions-twitter","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/CaSET-catalan-stance-emotions-twitter","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CaSET, the Catalan Stance and Emotions Dataset from Twitter\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CaSET dataset is a Catalan corpus of Tweets annotated with Emotions, Static Stance, and Dynamic Stance. The dataset contains 11k unique sentences on five controversial topics, grouped in 6k pairs of sentences, paired as parent messages and replies to these messages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be used to train models for emotionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/CaSET-catalan-stance-emotions-twitter."},
  {"name":"CaSERa-catalan-stance-emotions-raco","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/CaSERa-catalan-stance-emotions-raco","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CaSERa, the Catalan Stance and Emotions Dataset from RacÃ³ CatalÃ \\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CaSERa dataset is a Catalan corpus from the forum RacÃ³ CatalÃ  annotated with Emotions and Dynamic Stance. The dataset contains 15.782 unique sentences grouped in 10.745 pairs of sentences, paired as parent messages and replies to these messages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be used to train models for emotion detection andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/CaSERa-catalan-stance-emotions-raco."},
  {"name":"COPA-ca","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/COPA-ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for COPA-ca\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe COPA-ca dataset (Choice of plausible alternatives in Catalan) is a professional translation of the English COPA dataset into Catalan, commissioned by BSC LangTech Unit. The dataset consists of 1000 premises, each given a question and two choices with a label encoding which of the choices is more plausible given the annotator.\\nThe dataset is split into 400 training samples, 100 validation samples, and 500 test samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/COPA-ca."},
  {"name":"SREDFM","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Babelscape/SREDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\\\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\\nFirst, we present SRED\\\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \\nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \\nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\\\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}."},
  {"name":"all-scam-spam","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\\n1040 rows of balanced data, consisting of casual conversations and scam emails in â‰ˆ10 languages, were manually collected and annotated by me, with some help from ChatGPT.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSome preprcoessing algorithms\\n\\t\\n\\n\\nspam_assassin.js, followed by spam_assassin.py\\nenron_spam.py\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData composition\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nToâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam."},
  {"name":"malicious-website-features-2.4M","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"Important Notice:\\n\\nA subset of the URL dataset is from Kaggle, and the Kaggle datasets contained 10%-15% mislabelled data. See this dicussion I opened for some false positives. I have contacted Kaggle regarding their erroneous \\\"Usability\\\" score calculation for these unreliable datasets.\\nThe feature extraction methods shown here are not robust at all in 2023, and there're even silly mistakes in 3 functions: not_indexed_by_google, domain_registration_length, and age_of_domain.\\n\\n\\n\\nThe featuresâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M."},
  {"name":"ggml-vicuna-v0-quantized","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","description":"These are quantized ggml binary files for vicuna 7B and 13B models. The version of vicuna for these models are v0.\\nThese files can be used in conjunction with minigpt4 ggml models 7B and 13B in minigpt4.cpp\\nRecommended are the Q5_K and Q6_K implementations. If there are any issues, use Q4_1 or Q4_0.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVicuna Model Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel details\\n\\t\\n\\nModel type:\\nVicuna is an open-source chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT.\\nIt isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized."},
  {"name":"openassistant-guanaco-EOS","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Guanaco Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using \\\"### Human:\\\" AND \\\"### Assistant\\\" as the beginning and end of sequence tokens.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then slightly adjusted to:\\n\\n\\nif a row ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS."},
  {"name":"sharegpt-deduplicated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated","creator_name":"Caterina Lacerra","creator_url":"https://huggingface.co/CaterinaLac","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a deduplicated version of sharegpt4. \\nThe deduplication process has two steps:\\n\\nThe literal duplicates (both input and outputs) are removed\\nThe remaining (5749) instances are embedded with the SentenceTransformer library (\\\"paraphrase-multilingual-mpnet-base-v2\\\" model).\\nThen, we compute the cosine similarity among all the possible pairs, and consider paraphrases thoseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated."},
  {"name":"openassistant-llama-style","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Llama 2 Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then filtered to:\\n\\n\\nreplace instances of '### Human:' with '[INST]'\\nreplaceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style."},
  {"name":"multilingualcrowspairs","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/FrancophonIA/multilingualcrowspairs","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://gitlab.inria.fr/corpus4ethics/multilingualcrowspairs/\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultiLingualCrowsPairs\\n\\t\\n\\nMultilingual CrowS-Pairs, a challenge dataset for measuring stereotypical biases present in the masked language models (MLMs) in 7 different languages. \\nThis challenge dataset was built on the Crows-Pairs corpus (Nangia et al. 2020) using the methodology described in (NÃ©vÃ©ol et al. 2023). \\nThe 7 new languages are the following:\\n\\nArabic from Maghreb and the Arab world in generalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/multilingualcrowspairs."},
  {"name":"product-database","license":"GNU Affero General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Food Facts Database\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is ðŸŠ Open Food Facts?\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tA food products database\\n\\t\\n\\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\\n\\n\\t\\n\\t\\t\\n\\t\\tMade by everyone\\n\\t\\n\\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database."},
  {"name":"test_4","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4."},
  {"name":"multiCHILDES","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/IParraMartin/multiCHILDES","creator_name":"IÃ±igo Parra","creator_url":"https://huggingface.co/IParraMartin","description":"\\n\\t\\n\\t\\t\\n\\t\\tmultiCHILDES: Multilingual Child-Directed Speech Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains child-directed speech from 19 languages, extracted from the CHILDES corpus. The text has been cleaned and is designed for text generation tasks, particularly in studying early language acquisition.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nSource: CHILDES corpus\\nLanguages: 19 languages\\nText Type: Child-directed speech\\nTask: Text Generation, Language Modeling\\nData Processing: The datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IParraMartin/multiCHILDES."},
  {"name":"webfaq","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\\n\\n   \\n       Overview |\\n       Details  |\\n       Structure  |\\n       Examples |\\n       Considerations |\\n       License |\\n       Citation |\\n       Contact |\\n       Acknowledgement\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq."},
  {"name":"toxi-text-3M","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\\n\\n\\t\\n\\t\\t\\n\\nToxic\\nNeutral\\nTotal\\n\\n\\n\\t\\t\\nmultilingual-train-deduplicated.csvâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M."},
  {"name":"belebele","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\\n\\t\\n\\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions thatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele."},
  {"name":"librivox-tracks","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\n"},
  {"name":"multilingual-pl-bert","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\\n"},
  {"name":"sib200","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200."},
  {"name":"aya_collection","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_collection","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection."},
  {"name":"aya_evaluation_suite","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\\n\\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) â†’ aya-human-annotated.\\nmachine-translations of handpicked examples into 101 languages â†’â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite."},
  {"name":"CulturaY","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \\nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \\nThis data was used in part to train our SOTAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY."},
  {"name":"aya_collection_language_split","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_collection_language_split","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Collection is a massive multilingual collection consisting of 513 million instancesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection_language_split."},
  {"name":"GlotCC-V1","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
  {"name":"GlotCC-V1","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
  {"name":"muri-it","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it."},
  {"name":"HPLT2.0_cleaned","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned."},
  {"name":"belebele-fleurs","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBelebele-Fleurs\\n\\t\\n\\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\\n\\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30â€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs."},
  {"name":"sib-fleurs","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs."},
  {"name":"2M-Belebele","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2M-Belebele\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\\n\\t\\n\\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \\nThe speech dataset is built from aligning Belebele, Flores200 and Fleursâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele."},
  {"name":"reranker_continuous_filt_max7_train","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReranker training data\\n\\t\\n\\nThis data was generated using 4 steps:\\n\\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \\\"1\\\", \\\"2\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train."},
  {"name":"reranking-datasets-light","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"unkown","creator_url":"https://huggingface.co/abdoelsayed","description":"\\n\\t\\n\\t\\t\\n\\t\\tðŸ”¥ Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation ðŸ”¥\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\\n\\t\\n\\n\\n    \\n    \\n    \\n    \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n    \\n\\n\\n\\nA curated collection of ready-to-use datasets for retrieval and rerankingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light."},
  {"name":"Synthdog-Multilingual-100","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthdog Multilingual\\n\\t\\n\\n\\n\\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzfâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100."},
  {"name":"high-quality-multilingual-sentences","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tHigh Quality Multilingual Sentences\\n\\t\\n\\n\\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\\n\\nExample row (from the all config):\\n{\\n    \\\"text\\\": \\\"Ø§Ù…Ø§Ù… Ø¬Ù…Ø¹Ù‡ Ø§ØµÙÙ‡Ø§Ù† Ú¯ÙØª: Ù…ÛŒØ²Ø§Ù† Ù†ÛŒØ§Ø² Ø¢Ø¨ Ø´Ø±Ø¨ Ø§ØµÙÙ‡Ø§Ù† Û±Û±.Ûµ Ù…ØªØ± Ù…Ú©Ø¹Ø¨ Ø§Ø³Øª Ú©Ù‡ ØªÙ…Ø§Ù… Ø§Ø³ØªØ§Ù† Ø§ØµÙÙ‡Ø§Ù† Ø±Ø§ Ù¾ÙˆØ´Ø´ Ù…ÛŒØ¯Ù‡Ø¯ Ùˆ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ù†Ù‚Ù„Ø§Ø¨ ÛŒÚ©ÛŒ Ø§Ø² Ù¾ÛŒØ´Ø±ÙØªÙ‡Ø§ Ø¯Ø± Ø­ÙˆØ²Ù‡ Ø¢Ø¨ Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª.\\\",\\n    \\\"fasttext\\\": \\\"fa\\\",\\n    \\\"gcld3\\\": \\\"fa\\\"\\n}\\n\\nFields:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences."},
  {"name":"wikipedia_quality_wikirank","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"WÅ‚odzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy Itâ€™s Important\\n\\t\\n\\n\\nEnhances Trust: For readers andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank."},
  {"name":"multilingual_translation_sft","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"opus_ubuntu","license":"BSD 3-Clause \"New\" or \"Revised\" License","language":"en","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu."},
  {"name":"flores_101","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
  {"name":"wit_base","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base."},
  {"name":"HashtagPrediction","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\\n\\t\\n\\n  \\nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \\n[arXiv]\\n[HuggingFace Models]\\n[Github repo]\\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDownload\\n\\t\\n\\nUse theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction."},
  {"name":"flores_101","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
  {"name":"xP3x-sample","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities."},
  {"name":"wikianc","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc."},
  {"name":"entity_cs","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EntityCS\\n\\t\\n\\n\\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \\nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \\nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \\nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs."},
  {"name":"udhr-lid","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUDHR-LID\\n\\t\\n\\nWhy UDHR-LID?\\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \\\"missing\\\" or \\\"?\\\". Also, about 1/3 of the sentences consist only of \\\"articles 1-30\\\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid."},
  {"name":"seamless-align","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to use the data\\n\\t\\n\\nThere are two ways to access the data:\\n\\nVia the Hugging Face Python datasets library\\n\\nScripts coming soonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align."},
  {"name":"openassistant-falcon","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant Falcon\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using '\\\\Human:' AND '\\\\nAssistant:' to wrap user messages.\\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\\nSample \\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon."},
  {"name":"multilingual_qa","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/crodri/multilingual_qa","creator_name":"Carlos RodrÃ­guez","creator_url":"https://huggingface.co/crodri","description":"Multilingual instructional dataset for extractive QA finetunning for Catalan, Spanish and English, using SQAD, SQAC, CatalanQA and COQCAT datasets.\\nContains almost 55K questions, answers and contexts, with development and train splits.\\n"},
  {"name":"openslr-slr69-ca-trimmed-denoised","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/openslr-slr69-ca-trimmed-denoised","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for openslr-slr69-ca-denoised\\n\\t\\n\\nThis is a post-processed version of the Catalan subset belonging to the Open Speech and Language Resources (OpenSLR) speech dataset. \\nSpecifically the subset OpenSLR-69. \\nThe original HFðŸ¤— SLR-69 dataset is located here.\\nSame license is maintained: Attribution-ShareAlike 4.0 International.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe processed the data of the Catalan OpenSLR with the following recipe:\\n\\nTrimming:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/openslr-slr69-ca-trimmed-denoised."},
  {"name":"oasst2_ca","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/xaviviro/oasst2_ca","creator_name":"Xavi","creator_url":"https://huggingface.co/xaviviro","description":"xaviviro/oasst2_ca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"oasst2_ca_gpt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/xaviviro/oasst2_ca_gpt","creator_name":"Xavi","creator_url":"https://huggingface.co/xaviviro","description":"xaviviro/oasst2_ca_gpt dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"InstrucatQA","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/BSC-LT/InstrucatQA","creator_name":"Language Technologies Unit @ Barcelona Supercomputing Center","creator_url":"https://huggingface.co/BSC-LT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nInstructional dataset to finetune models used for RAG applications\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a merge from QA instructions from InstruCAT (ca), SQUAC (es), SQUAD (en), plus generalists CA and ES MENTOR datasets to provide a cognitive background for generating responses.\\nContains splits of 66139 (train) and 11674  (validation) instructions\\n\\nCurated by: [More Information Needed]\\nFunded byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BSC-LT/InstrucatQA."},
  {"name":"oasst2_top1_chat_format","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\\n\\t\\n\\nExport of oasst2 only top 1 threads in huggingface chat format\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScript\\n\\t\\n\\nThe convert script can be find here\\n"},
  {"name":"Esposalles-line","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Teklia/Esposalles-line","creator_name":"Teklia","creator_url":"https://huggingface.co/Teklia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEsposalles - line level\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Marriage Licenses ground-truth is compiled from the Marriage Licenses Books conserved at the Archives of the Cathedral of Barcelona.\\nNote that all images are resized to a fixed height of 128 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nAll the documents in the dataset are written in Catalan.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n{\\n  'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1244x128 atâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Teklia/Esposalles-line."},
  {"name":"oaast_rm_full_jieba","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"å°è¯•è§£å†³\\\"llm repetition problem\\\"ï¼Œä½¿ç”¨åˆ†è¯æ¨¡åž‹å¯¹oaastè¯­æ–™è¿›è¡Œâ€œç»“å·´åŒ–â€æ•°æ®å¢žå¼ºï¼Œæä¾›æ›´å¼ºçš„é‡å¤å†…å®¹æ‹’ç»æ•ˆæžœã€‚\\nAttempts to solve the \\\"llm repetition problem\\\" by using a segmentation model to enhance the oaast corpus with \\\"stuttering\\\" data to provide stronger rejection of duplicate content.\\nå…¶æ¬¡ï¼Œè¿˜è¿‡æ»¤æŽ‰äº†æ‰€æœ‰è‡ªæˆ‘è®¤çŸ¥çš„å¾®è°ƒæ ·æœ¬ã€‚\\nSecond, it also filters out all the fine-tuned samples of self-cognition.\\nfiles:\\n\\noaast_rm_full_jieba.jsonl : word level repeat\\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\\n\\n"},
  {"name":"escagleu-64k","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/escagleu-64k","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for escagleu-64K corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nescagleu-64k is a parallel corpus comprising 64091 sentences translated among Spanish, Catalan, Valencian Catalan, Galician, and Basque.\\nThe original sentences are in Spanish and come from the Spanish Common Voice Corpus.\\nWe prepared this corpus with the aim of creating a parallel speech dataset among these languages using the Common Voice platform between the frame of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/escagleu-64k."},
  {"name":"language-dataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","description":"\\n"},
  {"name":"MM-Eval","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/prometheus-eval/MM-Eval","creator_name":"prometheus-eval","creator_url":"https://huggingface.co/prometheus-eval","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Meta-EVALuation benchmark (MM-Eval)\\n\\t\\n\\n\\nðŸ‘¨â€ðŸ’»Code\\n|\\nðŸ“„Paper\\n|\\nðŸ¤— MMQA\\n\\n\\nMM-Eval is a multilingual meta-evaluation benchmark consisting of five core subsetsâ€”Chat, Reasoning, Safety, Language Hallucination, and Linguisticsâ€”spanning 18 languages and a Language Resource subset spanning 122 languages for a broader analysis of language effects. \\n\\nDesign ChoiceIn this work, we minimize the inclusion of translated samples, as mere translation may alter existing preferences dueâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/prometheus-eval/MM-Eval."},
  {"name":"CA-EN_Parallel_Corpus","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/CA-EN_Parallel_Corpus","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CA-EN Parallel Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CA-EN Parallel Corpus is a Catalan-English dataset of parallel sentences created to \\nsupport Catalan in NLP tasks, specifically Machine Translation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset can be used to train Bilingual Machine Translation models between English and Catalan in any direction, \\nas well as Multilingual Machine Translation models.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/CA-EN_Parallel_Corpus."},
  {"name":"Pontoon-Translations","license":"Mozilla Public License 2.0","language":"en","url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations."},
  {"name":"4catac","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/4catac","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for 4catac\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n4catac: examples of phonetic transcription in 4  Catalan accents is a dataset of phonetic transcriptions in four Catalan accents: Balearic, Central, North-Western and Valencian. \\nIt consists of 160 sentences transcribed using IPA, following the recommendations of the Institut d'Estudis Catalans.\\nThese sentences are the same for the four accents but may have small morphological adaptations to make them more natural for theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/4catac."},
  {"name":"mswc_fscil_subset","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset","creator_name":"NeuroBench","creator_url":"https://huggingface.co/NeuroBench","description":"This is a subset of the Multilingual Spoken Word Corpus dataset, which is built specifically for the Few-shot Class-incremental Learning (FSCIL) task. \\nA total of 15 languages are chosen, split into 5 base languages (English, German, Catalan, French, Kinyarwanda) and 10 incrementally learned languages (Persian, Spanish, Russian, Welsh, Italian, Basque, Polish, Esparanto, Portuguese, Dutch).\\nThe FSCIL task entails first training a model using abundant training data on words from the 5 baseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset."},
  {"name":"festcat_trimmed_denoised","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/festcat_trimmed_denoised","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for festcat_trimmed_denoised\\n\\t\\n\\nThis is a post-processed version of the Catalan Festcat speech dataset. \\nThe original data can be found here.\\nSame license is maintained: Creative Commons Attribution-ShareAlike 3.0 Spain License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe processed the data of the Catalan Festcat with the following recipe:\\n\\nTrimming: Long silences from the start and the end of clips have been removed.\\npy-webrtcvad -> Pythonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/festcat_trimmed_denoised."},
  {"name":"language_tags","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags."},
  {"name":"Deltacorpus_1.1","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, PortoroÅ¾, Slovenia).\\nChanges in version 1.1: \\n\\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \\n\\nSVM classifier trained on Universal Dependenciesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1."},
  {"name":"V1Q","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q."},
  {"name":"alpaca-gpt4-catalan","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/cienciadedades/alpaca-gpt4-catalan","creator_name":"Gerard Gimenez Adsuar","creator_url":"https://huggingface.co/cienciadedades","description":"Catalan Alpaca-GPT4 Dataset\\nA Catalan translation of the Alpaca-GPT4-Spanish dataset, created using DeepSeek Chat V3. Contains 1,980 instruction-response pairs (approximately 2M tokens).\\nDataset Details\\n\\nSource: Spanish Alpaca-GPT4 dataset\\nTarget Language: Catalan\\nSize: 1,980 conversation pairs\\nTranslation Model: DeepSeek Chat V3\\n\\nPurpose\\nReleased to advance supervised fine-tuning of Large Language Models with Catalan language capabilities.\\nCreated by\\n\\n"},
  {"name":"multilingual_translation_gen_binarized","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"HPLT2.0_cleaned","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned."}
];
