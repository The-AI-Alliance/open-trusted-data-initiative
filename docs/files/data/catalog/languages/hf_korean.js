var data_for_korean = [

  {"name":"llm_datasets","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Gunulhona/llm_datasets","creator_name":"JungKwonHwan","creator_url":"https://huggingface.co/Gunulhona","description":"Gunulhona/llm_datasets dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"eagle","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MasahiroKaneko/eagle","creator_name":"Masahiro Kaneko","creator_url":"https://huggingface.co/MasahiroKaneko","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEagle ğŸ¦…: Ethical Dataset Given from Real Interactions\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repository contains the Eagle dataset, which is an ethical dataset of real interactions between humans and ChatGPT. This dataset is created to evaluate social bias, opinion bias, toxic language, and morality in Large Language Models (LLMs).\\nIf you use the Eagle dataset in your research, please cite the following:\\n@inproceedings{Eagle:arxiv:2024,\\n    title={Eagle: Ethical Dataset Given fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MasahiroKaneko/eagle."},
  {"name":"Welfare-QA","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Ash-Hun/Welfare-QA","creator_name":"Choi Jaehun","creator_url":"https://huggingface.co/Ash-Hun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Welfare-QA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nëŒ€í•œë¯¼êµ­ ë³´ê±´ë³µì§€ë¶€ì—ì„œ ë°œê°„í•˜ì˜€ìœ¼ë©° 2023ë…„ 5ì›” 11ì¼ì— ë³µì§€ë¡œì— ë“±ë¡ëœ ì•ˆë‚´ì±…ìë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.\\nì´ 413í˜ì´ì§€ì˜ ë¹„ì •í˜• PDFì— ë‹´ê¸´ ì•½ 460ì—¬ê°œì˜ ë³µì§€ì œë„ì— ëŒ€í•œ Question-Answering-Documents ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\\nì›ë³¸ì€ ë‹¤ìŒ ë§í¬ì—ì„œ í™•ì¸í•´ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ‘‰ '2023 ë‚˜ì—ê²Œ í˜ì´ë˜ëŠ” ë³µì§€ì„œë¹„ìŠ¤ PDF ì±…ì'\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProject Repo\\n\\t\\n\\n\\nGithub Repo : Ask-for-Welfare\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Uses\\n\\t\\n\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"Ash-Hun/Welfare-QA\\\", split='train')\\n>>> dataset\\nDataset({\\n    features:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ash-Hun/Welfare-QA."},
  {"name":"X-SVAMP_en_zh_ko_it_es","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zhihz0535/X-SVAMP_en_zh_ko_it_es","creator_name":"Zhihan Zhang","creator_url":"https://huggingface.co/zhihz0535","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tX-SVAMP\\n\\t\\n\\nğŸ¤— Paper | ğŸ“– arXiv\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nX-SVAMP is an evaluation benchmark for multilingual large language models (LLMs), including questions and answers in 5 languages (English, Chinese, Korean, Italian and Spanish).\\nIt is intended to evaluate the math reasoning abilities of LLMs. The dataset is translated by GPT-4-turbo from the original English-version SVAMP.\\nIn our paper, we evaluate LLMs in a zero-shot generative setting: prompt the instruction-tunedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zhihz0535/X-SVAMP_en_zh_ko_it_es."},
  {"name":"X-TruthfulQA_en_zh_ko_it_es","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zhihz0535/X-TruthfulQA_en_zh_ko_it_es","creator_name":"Zhihan Zhang","creator_url":"https://huggingface.co/zhihz0535","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tX-TruthfulQA\\n\\t\\n\\nğŸ¤— Paper | ğŸ“– arXiv\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nX-TruthfulQA is an evaluation benchmark for multilingual large language models (LLMs), including questions and answers in 5 languages (English, Chinese, Korean, Italian and Spanish).\\nIt is intended to evaluate the truthfulness of LLMs. The dataset is translated by GPT-4 from the original English-version TruthfulQA.\\nIn our paper, we evaluate LLMs in a zero-shot generative setting: prompt the instruction-tuned LLMâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zhihz0535/X-TruthfulQA_en_zh_ko_it_es."},
  {"name":"MAGBIG","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/felfri/MAGBIG","creator_name":"Felix Friedrich","creator_url":"https://huggingface.co/felfri","description":"\\n\\t\\n\\t\\t\\n\\t\\tMAGBIG benchmark\\n\\t\\n\\nThis is the MAGBIG benchmark proposed in https://arxiv.org/abs/2401.16092\\nThis benchmark is intended for multilingual text-to-image models. With MAGBIG, you can generate images for a diverse set of prompts across ten different languages. These images can be evaluated for differences across languages. MAGBIG is designed to uncover and assess biases across languages such as gender, race, age, etc. This way, we can measure whether bias exists in a language, but also ifâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/felfri/MAGBIG."},
  {"name":"KoTox","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/SungJoo/KoTox","creator_name":"Grace","creator_url":"https://huggingface.co/SungJoo","description":"KoTox is an automatically generated toxic instruction dataset in Korean, comprising 39K unethical instruction-output pairs.\\nThe dataset is generated based on predefined lexicons and linguistic templates.\\nIt is designed to address potentially harmful or misleading instructions by including outputs that refrain from providing specific opinions or information in response.\\nThe dataset has been proven effective in mitigating toxicity in Korean Large Language Models (LLMs).\\nThe paper has beenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SungJoo/KoTox."},
  {"name":"KoWoW","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/didi0di/KoWoW","creator_name":"Yeongji Noh","creator_url":"https://huggingface.co/didi0di","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KoWoW\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWoW(Wiard of Wikipedia)ë¥¼ í•œêµ­ì–´ë¡œ ë³€ì—­í•œ ë°ì´í„°ì…ë‹ˆë‹¤.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWoW(Wiard of Wikipedia)ë¼ëŠ” ì§€ì‹ ê¸°ë°˜ ëŒ€í™” ë°ì´í„°ë¥¼ í•œêµ­ì–´ë¡œ ë³€ì—­í•œ ë°ì´í„°ì…ë‹ˆë‹¤.í•œ ëŒ€í™”ì— ì—¬ëŸ¬ ê°œì˜ dialogê°€ ë¬¶ìŒìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ì „ì²´ ëŒ€í™”ëŠ” 22,311ê±´, ì „ì²´ dialogëŠ” 201,999ê°œ ì…ë‹ˆë‹¤.ë³¸ ë°ì´í„°ì…‹ì€ Knowledgeì™€ Utteranceê°€ ëª¨ë‘ í•œêµ­ì–´ì¸ ko ë²„ì „ë§Œ ê°€ì ¸ì˜¨ ë°ì´í„°ì…ë‹ˆë‹¤.    \\n\\nLanguage(s) (NLP): ko\\nLicense: mit\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\n\\n\\nRepository: https://github.com/AIRC-KETI/kowow/tree/master\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/didi0di/KoWoW."},
  {"name":"MSC_korean","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/meenham/MSC_korean","creator_name":"MeenHwanSong","creator_url":"https://huggingface.co/meenham","description":"\\nData\\nsource\\nMSC data from the paper < Beyond Goldfish Memory: Long-Term Open-Domain Conversation >\\ntrain/valid/test dataset of session 4\\n\\n\\ntranslation ( English -> Koeran )\\nGPT-3.5-turbo is used mostly\\nGPT-4 : 66 data from the start of session_4_train ( after these, changed to gpt-3.5 )\\n\\n\\n\\n\\n\\n"},
  {"name":"ALMA-R-ko-en","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/qwopqwop/ALMA-R-ko-en","creator_name":"Junjae Lee","creator_url":"https://huggingface.co/qwopqwop","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"ALMA-R-ko-en-Preference\\\"\\n\\t\\n\\nref) https://huggingface.co/datasets/haoranxu/ALMA-R-Preference\\nThe triplet prference data, supporting 2 translation directions, is built upon the FLORES-200 development and test data. For each direction, we provide a source sentence along with three translations: one from GPT-4, another from EEVE-ALMA-LoRA, and a reference translation. For instance, in the English-German pair, our data structure is as follows:\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentences:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/qwopqwop/ALMA-R-ko-en."},
  {"name":"KoMedText","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/kurugai/KoMedText","creator_name":"HyeongWon Yun","creator_url":"https://huggingface.co/kurugai","description":"ì´ ë°ì´í„°ì…‹ì€ BI55/MedTextì„ deeplë¡œ ë²ˆì—­í•œ ìë£Œì…ë‹ˆë‹¤.\\n"},
  {"name":"mewsli-x","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\\nand converted into different parts (see process.py):\\n\\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\\n\\nRaw data files are in raw.tar.gz, which contains:\\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\\n[...] 9.8M Feb 24â€¦ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x."},
  {"name":"kobbq","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/naver-ai/kobbq","creator_name":"NAVER AI Lab","creator_url":"https://huggingface.co/naver-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KoBBQ\\n\\t\\n\\n\\n\\n\\n\\nThe Bias Benchmark for Question Answering (BBQ) is designed to evaluate social biases of language models (LMs), but it is not simple to adapt this benchmark to cultural contexts other than the US because social biases depend heavily on the cultural context. In this paper, we present KoBBQ, a Korean bias benchmark dataset, and we propose a general framework that addresses considerations for cultural adaptation of a dataset. Our framework includesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/naver-ai/kobbq."},
  {"name":"test3","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/jin-code/test3","creator_name":"kim","creator_url":"https://huggingface.co/jin-code","description":"jin-code/test3 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"OpenOrca-Ko-En","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/appleparan/OpenOrca-Ko-En","creator_name":"Jongsu Kim","creator_url":"https://huggingface.co/appleparan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenOrca-Ko-En\\n\\t\\n\\n\\nkyujinpy/OpenOrca-KOì™€ Open-Orca/OpenOrcaë¥¼ ê³µí†µëœ ë°ì´í„°ë§Œ í•„í„°ë§í•˜ê³  í•©ì¹œ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\\nì»¬ëŸ¼ì€ ê¸°ì¡´ OpenOrcaì— ë§ì¶°ì„œ system_prompt_{ko/en}, question_{ko/en}, response_{ko/en} ìœ¼ë¡œ ë³€ê²½í•˜ì˜€ìŠµë‹ˆë‹¤.\\nì¤‘ë³µëœ idë¥¼ ì œê±°í•˜ì—¬ ë°ì´í„°ìˆ˜ê°€ ì¼ë¶€ ê°ì†Œí•˜ì˜€ìŠµë‹ˆë‹¤.\\në°ì´í„°ì…‹ì„ ë§Œë“œëŠ”ë° ì‚¬ìš©í•œ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.\\në°ì´í„°ì…‹ ì´ìš©í•˜ì…”ì„œ ëª¨ë¸ì´ë‚˜ ë°ì´í„°ì…‹ì„ ë§Œë“œì‹¤ ë•Œ, ì´ ë°ì´í„°ì…‹ë¿ë§Œ ì•„ë‹ˆë¼ ìœ„ ë°ì´í„°ì…‹ë„ í•¨ê»˜ ì¶œì²˜í‘œê¸°ë¥¼ í•´ì£¼ì…¨ìœ¼ë©´ í•©ë‹ˆë‹¤.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset inf0\\n\\t\\n\\n\\nNIV // 1551ê°œ(OpenOrca-KO: 1571ê°œ)  \\nFLAN // 9338ê°œ(OpenOrca-KO: 9434ê°œ)\\nT0 // 6303ê°œ(OpenOrca-KO: 6351ê°œ)\\nCoT // 2092ê°œ(OpenOrca-KO: 2117ê°œ)\\nKoCoT // 2159ê°œâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/appleparan/OpenOrca-Ko-En."},
  {"name":"kollm-comparision","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/davidkim205/kollm-comparision","creator_name":"davidkim205","creator_url":"https://huggingface.co/davidkim205","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdavidkim205/kollm-comparision\\n\\t\\n\\nnox-solar-10.7b-v4ì— ì‚¬ìš©ëœ dpo ë°ì´í„°ì…‹ìœ¼ë¡œ huggingfaceì— ê³µê°œëœ ë°ì´í„°ì™€ twodigitì—ì„œ ì œì‘í•œ ë°ì´í„°ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\\nnox githubì—ì„œ ì‚¬ìš©ê°€ëŠ¥í•˜ë„ë¡ comparision í˜•ì‹ìœ¼ë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tê³µê°œ ë°ì´í„°ì…‹\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nSource\\nì„¤ëª…\\nì›ë³¸ URL\\n\\n\\n\\t\\t\\nkobest_boolq\\ní•œêµ­ì–´ ë²¤ì¹˜ë§ˆí¬ KoBEST\\nhttps://huggingface.co/datasets/skt/kobest_v1\\n\\n\\nkobest_copa\\ní•œêµ­ì–´ ë²¤ì¹˜ë§ˆí¬ KoBEST\\nhttps://huggingface.co/datasets/skt/kobest_v1\\n\\n\\nkobest_hellaswag\\ní•œêµ­ì–´ ë²¤ì¹˜ë§ˆí¬ KoBEST\\nhttps://huggingface.co/datasets/skt/kobest_v1\\n\\n\\nkobest_sentineg\\ní•œêµ­ì–´ ë²¤ì¹˜ë§ˆí¬ KoBESTâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidkim205/kollm-comparision."},
  {"name":"create_qa_news","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/yuneun92/create_qa_news","creator_name":"Yun Eun","creator_url":"https://huggingface.co/yuneun92","description":"\\nì§ˆë¬¸ ìƒì„±: kullm3 ëª¨ë¸ ì´ìš©\\në‹µë³€ ìƒì„±: GPT3.5 turbo API ì´ìš©\\nì§€ë¬¸ ì›ë³¸: AI HUB ë‰´ìŠ¤ ê¸°ê³„ë…í•´ ë°ì´í„°ì…‹\\n\\n"},
  {"name":"orca_dpo_data_ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AIdenU/orca_dpo_data_ko","creator_name":"YuHeeJun","creator_url":"https://huggingface.co/AIdenU","description":"\\nì›ë³¸ ë°ì´í„° : HuggingFaceH4/orca_dpo_pairs\\nì›ë³¸ ë°ì´í„° ì…‹ì„ system, question, chosen, rejected í˜•íƒœì— ë§ê²Œ ì •ì œ í›„, squarelike/Gugugo-koen-7B-V1.1-AWQ ìœ¼ë¡œ ë²ˆì—­\\nì˜¤ë²ˆì—­ëœ ë°ì´í„°ëŠ” ì‚­ì œ ê²€ìˆ˜\\n\\n"},
  {"name":"ko-voicephishing-binary-classification","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HyaDoo/ko-voicephishing-binary-classification","creator_name":"SAERAM LEE","creator_url":"https://huggingface.co/HyaDoo","description":"HyaDoo/ko-voicephishing-binary-classification dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"en-fpb-ko","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/allganize/en-fpb-ko","creator_name":"allganize","creator_url":"https://huggingface.co/allganize","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ten-fpb-ko\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të°ì´í„° ì„¤ëª…\\n\\t\\n\\n\\nen-fpb-ko ë°ì´í„°ëŠ” ê¸ˆìœµ ë‰´ìŠ¤ë¡œë¶€í„°ì˜ ë¬¸ì¥ì„ 'ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •' ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ëŠ” ê°ì„± ë¶„ë¥˜ (sentiment analysis) ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\\nì…ë ¥ê°’ìœ¼ë¡œëŠ” textë§Œ ì£¼ì–´ì§‘ë‹ˆë‹¤.\\n\\ní•œêµ­ì–´ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´, ë¨¼ì € ì‚¬ë‚´ ì–¸ì–´ ë²ˆì—­ ëª¨ë¸ì¸ Allganize Translatorë¥¼ í™œìš©í•˜ì—¬ ChanceFocus/en-fpbì˜ test setì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì˜€ìŠµë‹ˆë‹¤. \\nì˜¤ì—­ëœ ë°ì´í„°ë¥¼ ì§ì ‘ ì œê±°í•˜ì˜€ê³ , ê·¸ ê²°ê³¼ 944ê°œì˜ í‰ê°€ ë°ì´í„°ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të°ì´í„° ì¶œì²˜\\n\\t\\n\\n\\nChanceFocus/en-fpb\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të°ì´í„° ì˜ˆì‹œ\\n\\t\\n\\n{\\n  'conversation_id': 'fpb3876',\\n  'conversations': array([\\n    {\\n      'from': 'human',\\n      'value': '''ê¸ˆìœµ ë‰´ìŠ¤â€¦ See the full description on the dataset page: https://huggingface.co/datasets/allganize/en-fpb-ko."},
  {"name":"flare-fiqasa-ko","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/allganize/flare-fiqasa-ko","creator_name":"allganize","creator_url":"https://huggingface.co/allganize","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tflare-fiqasa-ko\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të°ì´í„° ì„¤ëª…\\n\\t\\n\\n\\nflare-fiqasa-ko ë°ì´í„°ëŠ” ê¸ˆìœµ ë„ë©”ì¸ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì˜ ê°ì„±ì„ ì˜ˆì¸¡(sentiment analysis)í•˜ëŠ” ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\\nì…ë ¥ê°’ì€ textë¡œë§Œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.\\n\\ní•œêµ­ì–´ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´, ìš°ì„  ì‚¬ë‚´ ì–¸ì–´ ë²ˆì—­ ëª¨ë¸ Allganize Translatorì„ í™œìš©í•˜ì—¬ ChanceFocus/flare-fiqasaì˜ test setì„ ë²ˆì—­í–ˆìŠµë‹ˆë‹¤.\\nì˜¤ì—­ëœ ë°ì´í„°ë¥¼ ì§ì ‘ ì œê±°í•˜ì˜€ê³ , ê·¸ ê²°ê³¼ 204ê°œì˜ í‰ê°€ ë°ì´í„°ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të°ì´í„° ì¶œì²˜\\n\\t\\n\\n\\nChanceFocus/flare-fiqasa\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të°ì´í„° ì˜ˆì‹œ\\n\\t\\n\\n{\\n  'conversation_id': 'fiqasa938',\\n  'conversations': array([\\n    {\\n      'from': 'human',\\n      'value': '''ë‹¤ìŒ ì¬ë¬´ ê²Œì‹œë¬¼ì˜â€¦ See the full description on the dataset page: https://huggingface.co/datasets/allganize/flare-fiqasa-ko."},
  {"name":"orca-math-word-problems-193k-korean","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/kuotient/orca-math-word-problems-193k-korean","creator_name":"Jisoo Kim","creator_url":"https://huggingface.co/kuotient","description":"ì›ë³¸ ë°ì´í„°ì…‹: https://huggingface.co/datasets/microsoft/orca-math-word-problems-200k\\në²ˆì—­ ëª¨ë¸: Seagull-13b-translation\\ní›„ì²˜ë¦¬\\n\\në²ˆì—­ repetition ì˜¤ë¥˜ ì œê±°\\nLaTeX ì˜¤ë¥˜ ì²´í¬(ì „ë¶€ëŠ” ì•„ë‹ ìˆ˜ ìˆìŒ. /(/) -> /(/ ê°™ì€ ì˜¤ë¥˜ ë“±...)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{mitra2024orcamath,\\n      title={Orca-Math: Unlocking the potential of SLMs in Grade School Math}, \\n      author={Arindam Mitra and Hamed Khanpour and Corby Rosset and Ahmed Awadallah},\\n      year={2024},\\n      eprint={2402.14830},\\n      archivePrefix={arXiv}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kuotient/orca-math-word-problems-193k-korean."},
  {"name":"aihub-contents-ko-only","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/richard-park/aihub-contents-ko-only","creator_name":"WOO HWAN PARK","creator_url":"https://huggingface.co/richard-park","description":"richard-park/aihub-contents-ko-only dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"MAiDE-up","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MichiganNLP/MAiDE-up","creator_name":"LIT @ UMich","creator_url":"https://huggingface.co/MichiganNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MAiDE-up: Multilingual Deception Detection of GPT-generated Hotel Reviews\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultilingual Deception Detection of GPT-generated Hotel Reviews. We compare real hotel reviews from Booking with LLM-generated hotel reviews in 10 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in 10 languages: Chinese, English, French, German, Italian, Romanian, Korean, Russian, Spanish, Turkish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboardsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MichiganNLP/MAiDE-up."},
  {"name":"pokemon-blip-captions-en-ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/letgoofthepizza/pokemon-blip-captions-en-ko","creator_name":"lee noah","creator_url":"https://huggingface.co/letgoofthepizza","description":"letgoofthepizza/pokemon-blip-captions-en-ko dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"TinyStories-Korean","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/g0ster/TinyStories-Korean","creator_name":"Dohoon Kim","creator_url":"https://huggingface.co/g0ster","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTinyStories-Korean\\n\\t\\n\\n\\n\\nThis dataset is a translated version of roneneldan's TinyStories dataset.\\nI first downloaded roneneldan's TinyStories, and I organized it in a db file. Then I used a local transalation model eeve\\n to translate, and I changed it back to a txt file.\\nFeel free to use!\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{kim2024tinystories,\\n      title={TinyStories Korean translations}, \\n      author={Dohoon Kim(g0ster)},\\n      year={2024},\\n}\\n\\n"},
  {"name":"xm3600","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\nIt also includes the image features as PIL Image and has a uniform andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600."},
  {"name":"xm3600_1k","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600 - 1K Split\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a 1K split of XM3600!\\n\\t\\n\\nFor this, weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k."},
  {"name":"xgqa","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/xgqa","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\txGQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a clone of the few_shot-test split of the xGQA dataset\\n\\t\\n\\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{pfeiffer-etal-2021-xGQA,\\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\\\'{c}} and Iryna Gurevych}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa."},
  {"name":"font_valid_10000","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jayhii/font_valid_10000","creator_name":"jay smith","creator_url":"https://huggingface.co/jayhii","description":"jayhii/font_valid_10000 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"aihub-flores-koen-integrated-prime-base-300k","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/traintogpb/aihub-flores-koen-integrated-prime-base-300k","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHigh Quality Ko-En Translation Dataset (AIHub-FLoRes Integrated)\\n\\t\\n\\nAI Hubì˜ í•œ-ì˜ ë²ˆì—­ ë°ì´í„°ì…‹ê³¼ FLoRes í•œ-ì˜ ë²ˆì—­ ë°ì´í„°ì…‹ì˜ í•©ë³¸ì…ë‹ˆë‹¤.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHigh Quality AIHub Dataset\\n\\t\\n\\nAI Hubì˜ ê²½ìš° í•œ-ì˜ ë²ˆì—­ ê´€ë ¨ ë°ì´í„°ì…‹ì„ 8ê°œ ë³‘í•©í•œ ë³‘ë ¬ ë°ì´í„° traintogpb/aihub-koen-translation-integrated-mini-1mì—ì„œ ê³ í’ˆì§ˆì˜ ë²ˆì—­ ë ˆí¼ëŸ°ìŠ¤ë¥¼ ê°€ì§„ ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ì˜€ìŠµë‹ˆë‹¤.\\në²ˆì—­ ë ˆí¼ëŸ°ìŠ¤ í’ˆì§ˆ í‰ê°€ ì²™ë„ëŠ” Unbabel/XCOMET-XL (3.5B)ë¡œ ì¸¡ì •í•œ xCOMET metricì…ë‹ˆë‹¤.\\n8ê°œì˜ AIHub ë°ì´í„° ì†ŒìŠ¤ì˜ êµ¬ì„± ë¹„ìœ¨ì€ ì‹¤í—˜ì„ í†µí•´ í™•ë³´í•œ ë²ˆì—­ ì„±ëŠ¥(SacreBLEU)ì— ë”°ë¼ ì°¨ë“±ì„ ë‘ì—ˆìŠµë‹ˆë‹¤.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLoRes Dataset\\n\\t\\n\\nFLoRes-200 ë°ì´í„°ì…‹ì˜ ê²½ìš° 997ê°œì˜ dev, 1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-flores-koen-integrated-prime-base-300k."},
  {"name":"xgqa_1k","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/xgqa_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\txGQA 1K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a 1K subset of the few_shot-test split of the xGQA dataset\\n\\t\\n\\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{pfeiffer-etal-2021-xGQA,\\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\\\'{c}} and Iryna Gurevych}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa_1k."},
  {"name":"from-one-to-many-toxicity-mitigation","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation","creator_name":"Luiza Pozzobon","creator_url":"https://huggingface.co/luizapzbn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFrom One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\\n\\t\\n\\n[arxiv][code][data]\\nData accompanying the paper \\\"From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\\\" accepted to ACL Findings 2024.\\nAbstract: To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, itâ€™s crucial our safety measures keep pace. Recognizing thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation."},
  {"name":"BD-EnKo","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/shreyanshu09/BD-EnKo","creator_name":"Shreyanshu Bhushan","creator_url":"https://huggingface.co/shreyanshu09","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBD-EnKo Dataset\\n\\t\\n\\nIt was introduced in the paper \\\"Unveiling the Power of Integration: Block Diagram Summarization through Local-Global Fusion\\\" accepted at ACL 2024. The full code is available in BD-EnKo github repository.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\nThis dataset contains different types of block diagram images with their high-quality summaries.\\n\\n\\t\\n\\t\\t\\nTypes\\nTrain\\n\\nValidation\\n\\n\\n\\n\\t\\t\\n\\nEnglish\\nKorean\\nEnglish\\nKorean\\n\\n\\n-----------------\\n---------\\n--------\\n------------\\n---------â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shreyanshu09/BD-EnKo."},
  {"name":"bccard-qna-augmented","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sh2orc/bccard-qna-augmented","creator_name":"Taeyoung Lee","creator_url":"https://huggingface.co/sh2orc","description":"Data Augmented BC Card Q&A Dataset by BERT Insertion \\n\\nKorean\\nPayment\\n\\n"},
  {"name":"Chatgpt","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt."},
  {"name":"korean_profanity_masking","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/hajun1020/korean_profanity_masking","creator_name":"Hajun Tae","creator_url":"https://huggingface.co/hajun1020","description":"hajun1020/korean_profanity_masking dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"BLEnD","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/nayeon212/BLEnD","creator_name":"Nayeon Lee","creator_url":"https://huggingface.co/nayeon212","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLEnD\\n\\t\\n\\nThis is the official repository of BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages (Submitted to NeurIPS 2024 Datasets and Benchmarks Track).\\n24/12/05: Updated translation errors\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout\\n\\t\\n\\n\\nLarge language models (LLMs) often lack culture-specific everyday knowledge, especially across diverse regions and non-English languages. Existing benchmarks for evaluating LLMs' cultural sensitivities are usually limited to a singleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nayeon212/BLEnD."},
  {"name":"CaLMQA","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/shanearora/CaLMQA","creator_name":"Shane Arora","creator_url":"https://huggingface.co/shanearora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\n\\nCaLMQA is a long-form question answering (LFQA) dataset spanning 23 high- to low-resource languages. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCaLMQA is an LFQA dataset with 2K questions from 23 languages, 11 high- to mid-resource and 12 low-resource.\\nQuestions are either culturally specific â€“ uniquely or more likely to be asked by people of a specific\\nculture â€“ or culturally agnostic (not culturally specific). These questions wereâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shanearora/CaLMQA."},
  {"name":"BAAI_bge-m3-6122024-ibs3-webapp","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6122024-ibs3-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBAAI_bge-m3-6122024-ibs3-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Pet care\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the BAAI_bge-m3-6122024-ibs3-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6122024-ibs3-webapp."},
  {"name":"aya_collection_korean","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/4n3mone/aya_collection_korean","creator_name":"yongsang yoo","creator_url":"https://huggingface.co/4n3mone","description":"CohereForAI/aya_collection_language_split ì—ì„œ í•œêµ­ì–´ ìŠ¤í”Œë¦¿ë§Œ ì¶”ì¶œí•œ ë°ì´í„°ì…‹ ì…ë‹ˆë‹¤.\\në°ì´ì²˜ ì¶œì²˜(dataset name)ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. (ë²ˆì—­ëœ ë°ì´í„°ì…‹ì€ (T) í‘œì‹œ)\\nAya-Dataset\\nFlan-CoT-submix(T)\\nAdversarial QA(T)\\nFlan-Coqa(T)\\nFlan-unified-QA(T)\\nFlan-GEM-wiki-lingua(T)\\nCNN-Daily-Mail(T)\\nWIKI QA(T)\\nPAWS-Wiki(T)\\nWiki-split-inst(T)\\nNTX-LLM-inst\\nHotpotQA(T)\\nNQ-Open(T)\\nJoke-explaination-inst(T)\\nMLQA-en(T)\\nSODA-inst(T)\\nXlel_wd-inst\\nFlan-lambada(T)\\nXlel_wd-inst(T)\\nMintaka-inst(T)\\nPIQA(T)\\nDolly-v2(T)\\n"},
  {"name":"BAAI_bge-m3-6142024-0ndt-webapp","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6142024-0ndt-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBAAI_bge-m3-6142024-0ndt-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"content moderation\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the BAAI_bge-m3-6142024-0ndt-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6142024-0ndt-webapp."},
  {"name":"BAAI_bge-m3-6142024-0ndt-webapp","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6142024-0ndt-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBAAI_bge-m3-6142024-0ndt-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"content moderation\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the BAAI_bge-m3-6142024-0ndt-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6142024-0ndt-webapp."},
  {"name":"contextual-dpo-v0.1-ko","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/nayohan/contextual-dpo-v0.1-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"contextual-dpo-v0.1-ko\\\"\\n\\t\\n\\nTranslated jondurbin/contextual-dpo-v0.1 using nayohan/llama3-instrucTrans-enko-8b.\\n"},
  {"name":"HC3-ko","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/nayohan/HC3-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"HC3\\\"\\n\\t\\n\\nTranslated Hello-SimpleAI/HC3 using nayohan/llama3-instrucTrans-enko-8b.\\n"},
  {"name":"SentimentSynth-ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nayohan/SentimentSynth-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"SentimentSynth\\\"\\n\\t\\n\\nTranslated OEvortex/SentimentSynth using nayohan/llama3-instrucTrans-enko-8b.\\n"},
  {"name":"Neural-DPO-ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nayohan/Neural-DPO-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Neural-DPO\\\"\\n\\t\\n\\nTranslated NeuralNovel/Neural-DPO using nayohan/llama3-instrucTrans-enko-8b.\\n"},
  {"name":"Maths-College-ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nayohan/Maths-College-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"Translated 5% ajibawa-2023/Maths-College using nayohan/llama3-instrucTrans-enko-8b.\\n"},
  {"name":"Sujet-Finance-Instruct-177k-ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nayohan/Sujet-Finance-Instruct-177k-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"Translated sujet-ai/Sujet-Finance-Instruct-177k using nayohan/llama3-instrucTrans-enko-8b.\\nIt may contain repetitive sentences, so recommend filtering them.\\n"},
  {"name":"luckyvicky","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Junnos/luckyvicky","creator_name":"ì´ì°½ì¤€","creator_url":"https://huggingface.co/Junnos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tì›ì˜ì  ì‚¬ê³  ë°ì´í„°ì…‹\\n\\t\\n\\n"},
  {"name":"hf-first","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kenu/hf-first","creator_name":"Kenu Gwangnam Heo","creator_url":"https://huggingface.co/kenu","description":"kenu/hf-first dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Multilingual-Benchmark","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \\nBibTex\\n@misc{lu2024languagecountslearnunlearn,\\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \\n      author={Taiming Lu and Philipp Koehn},\\n      year={2024},\\n      eprint={2406.13748},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2406.13748}, \\n}\\n\\n"},
  {"name":"KoSBi-v2","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nayohan/KoSBi-v2","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/naver-ai/korean-safety-benchmarks\\n@inproceedings{lee2023kosbi,\\n                title={KoSBi: A Dataset for Mitigating Social Bias Risks Towards Safer Large Language Model Application}, \\n                author={Hwaran Lee and Seokhee Hong and Joonsuk Park and Takyoung Kim and Gunhee Kim and Jung-Woo Ha},\\n                booktitle={Proceedings of the 61th Annual Meeting of the Association for Computational Linguistics: Industry Track},\\n                year={2023}\\n}\\n\\n"},
  {"name":"KoSBi","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nayohan/KoSBi","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/naver-ai/korean-safety-benchmarks\\n@inproceedings{lee2023kosbi,\\n                title={KoSBi: A Dataset for Mitigating Social Bias Risks Towards Safer Large Language Model Application}, \\n                author={Hwaran Lee and Seokhee Hong and Joonsuk Park and Takyoung Kim and Gunhee Kim and Jung-Woo Ha},\\n                booktitle={Proceedings of the 61th Annual Meeting of the Association for Computational Linguistics: Industry Track},\\n                year={2023}\\n}\\n\\n"},
  {"name":"SQuARe-question","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nayohan/SQuARe-question","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/naver-ai/korean-safety-benchmarks\\n@inproceedings{lee2023square,\\n                title={SQuARe: A Large-Scale Dataset of Sensitive Questions and Acceptable Responses Created Through Human-Machine Collaboration}, \\n                author={Hwaran Lee and Seokhee Hong and Joonsuk Park and Takyoung Kim and Meeyoung Cha and Yejin Choi and Byoung Pil Kim and Gunhee Kim and Eun-Ju Lee and Yong Lim and Alice Oh and Sangchul Park and Jung-Woo Ha}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nayohan/SQuARe-question."},
  {"name":"SQuARe-response","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nayohan/SQuARe-response","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/naver-ai/korean-safety-benchmarks\\n@inproceedings{lee2023square,\\n                title={SQuARe: A Large-Scale Dataset of Sensitive Questions and Acceptable Responses Created Through Human-Machine Collaboration}, \\n                author={Hwaran Lee and Seokhee Hong and Joonsuk Park and Takyoung Kim and Meeyoung Cha and Yejin Choi and Byoung Pil Kim and Gunhee Kim and Eun-Ju Lee and Yong Lim and Alice Oh and Sangchul Park and Jung-Woo Ha}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nayohan/SQuARe-response."},
  {"name":"korean-hate-speech","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/nayohan/korean-hate-speech","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/kocohub/korean-hate-speech\\n@inproceedings{moon-etal-2020-beep,\\n    title = \\\"{BEEP}! {K}orean Corpus of Online News Comments for Toxic Speech Detection\\\",\\n    author = \\\"Moon, Jihyung  and\\n      Cho, Won Ik  and\\n      Lee, Junbum\\\",\\n    booktitle = \\\"Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media\\\",\\n    month = jul,\\n    year = \\\"2020\\\",\\n    address = \\\"Online\\\",\\n    publisher = \\\"Association for Computational Linguistics\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nayohan/korean-hate-speech."},
  {"name":"APEACH","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/nayohan/APEACH","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/jason9693/APEACH\\n@inproceedings{yang-etal-2022-apeach,\\n    title = \\\"{APEACH}: Attacking Pejorative Expressions with Analysis on Crowd-Generated Hate Speech Evaluation Datasets\\\",\\n    author = \\\"Yang, Kichang  and\\n      Jang, Wonjun  and\\n      Cho, Won Ik\\\",\\n    booktitle = \\\"Findings of the Association for Computational Linguistics: EMNLP 2022\\\",\\n    month = dec,\\n    year = \\\"2022\\\",\\n    address = \\\"Abu Dhabi, United Arab Emirates\\\",\\n    publisher = \\\"Association forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nayohan/APEACH."},
  {"name":"luckyvicky-DPO","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Junnos/luckyvicky-DPO","creator_name":"ì´ì°½ì¤€","creator_url":"https://huggingface.co/Junnos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tì›ì˜ì  ì‚¬ê³  ë°ì´í„°ì…‹\\n\\t\\n\\n"},
  {"name":"alpaca_function_calling_dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Saxo/alpaca_function_calling_dataset","creator_name":"Ji","creator_url":"https://huggingface.co/Saxo","description":"\\n\\n\\n  \\nAI ì™€ ë¹…ë°ì´í„° ë¶„ì„ ì „ë¬¸ ê¸°ì—…ì¸ Linkbricks(www.linkbricks.com)ì˜ ë°ì´í„°ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ì¸ ì§€ìœ¤ì„±(Saxo) ë°•ì‚¬ê°€ ë§Œë“  llm RAGë¥¼ ìœ„í•œ function calling í•™ìŠµìš© ë°ì´í„°ì…‹ìœ¼ë¡œ llam3 instruct formatì¸ mzbac/function-calling-llama-3-format-v1.1 ì„ Alpaca Formatìœ¼ë¡œ ë³€ê²½. \\nChanged the llam3 instruct format, mzbac/function-calling-llama-3-format-v1.1, to Alpaca Format as a dataset for learning function calling for the llm RAG, created by Dr. Ji Yun Sung(Saxo), a data scientist at Linkbricks (www.linkbricks.com), a company specializing in AI and bigâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Saxo/alpaca_function_calling_dataset."},
  {"name":"tydi_xor_rc","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/coastalcph/tydi_xor_rc","creator_name":"CoAStaL NLP Group","creator_url":"https://huggingface.co/coastalcph","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tydi_xor_rc\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages. \\nXORQA is an extension of the original TyDi QA dataset to also include unanswerable questions, where context documents are only in English but questions are in 7 languages.\\nXOR-AttriQA contains annotated attribution data for a sample of XORQA.\\nThis dataset is a combined and simplified version of the Reading Comprehension data fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/coastalcph/tydi_xor_rc."},
  {"name":"MedQA","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ChuGyouk/MedQA","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"Original dataset introduced by Jin et al. in What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEn split\\n\\t\\n\\nJust edited columns. Contents are same.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKo split\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTrain\\n\\t\\n\\nThe train dataset is translated by \\\"solar-1-mini-translate-enko\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTest\\n\\t\\n\\nThe test dataset is translated by DeepL Pro.\\nreference-free COMET score: 0.7989 (Unbabel/wmt23-cometkiwi-da-xxl)\\nCitation information:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/MedQA."},
  {"name":"PubMedQA-test-Ko","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ChuGyouk/PubMedQA-test-Ko","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"This is the test data of PubMedQA, Korean translated version.\\n"},
  {"name":"Pyhsics_Dataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Geniuss/Pyhsics_Dataset","creator_name":"Kim Yeongjun","creator_url":"https://huggingface.co/Geniuss","description":"Geniuss/Pyhsics_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fact-check-bureau","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau","creator_name":"Younes","creator_url":"https://huggingface.co/NaughtyConstrictor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFact-Check Retrieval Dataset\\n\\t\\n\\nThis dataset is designed to support the development and evaluation of fact-check retrieval pipelines. It is structured to work with FactCheckBureau, a tool for designing and evaluating fact-check retrieval pipelines. The dataset comprises a list of claims, fact-check articles, and precomputed embeddings for English and French fact-checks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset consists of the following files and directories:\\n\\narticles.csv:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau."},
  {"name":"math-gpt-4o-200k-ko","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nayohan/math-gpt-4o-200k-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"Translated PawanKrd/math-gpt-4o-200k using nayohan/llama3-instrucTrans-enko-8b.\\nThis dataset is a raw translated dataset and contains repetitive sentences generated by the model, so it needs to be filtered.\\n"},
  {"name":"math-gpt-4o-200k-ko","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nayohan/math-gpt-4o-200k-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"Translated PawanKrd/math-gpt-4o-200k using nayohan/llama3-instrucTrans-enko-8b.\\nThis dataset is a raw translated dataset and contains repetitive sentences generated by the model, so it needs to be filtered.\\n"},
  {"name":"llama-custom-dataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jiinnn/llama-custom-dataset","creator_name":"sanjin na","creator_url":"https://huggingface.co/jiinnn","description":"jiinnn/llama-custom-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Constructionsafety_QApairs","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/DBCMLAB/Constructionsafety_QApairs","creator_name":"Hongik University, Data-based Construction Management LAB","creator_url":"https://huggingface.co/DBCMLAB","description":"This dataset was built based on the Construction Safety Guidelines published by KOSHA (Korean Occupational Safety and Health Administration).\\nThis is virtual QA pair dataset generated by GPT-3.5-turbo.\\n"},
  {"name":"kmmlu-conversation-sample","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CarrotAI/kmmlu-conversation-sample","creator_name":"CarrotCarrot","creator_url":"https://huggingface.co/CarrotAI","description":"Kmmlu ë°ì´í„°ë¥¼ ì´ìš©í•´ì„œ ëŒ€í™” ë°ì´í„°ì…‹ ìƒ˜í””ì„ ìƒì„±í•˜ì˜€ìŠµë‹ˆë‹¤.\\në©€í‹°í„´ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµìš©ë„ë¡œ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.\\n"},
  {"name":"3kingdoms","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/jonhpark/3kingdoms","creator_name":"Jong Hyun Park","creator_url":"https://huggingface.co/jonhpark","description":"jonhpark/3kingdoms dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"zenless_zone_zero_interknots_v1.0","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZZZ Interknots\\n\\t\\n\\nThis datasets contains extracted Interknot posts and comments (ç»³ç½‘çš„åšå®¢ä¸è¯„è®º) in multi-language.\\nUp to game version: 1.0\\n\\nInterknot posts and comments examples\\n\\n{\\n  \\\"id\\\": \\\"1021\\\",\\n  \\\"poster\\\": \\\"Sorrowful Intern\\\",\\n  \\\"title\\\": \\\"[Commission] Missing Bangboo merchants\\\",\\n  \\\"text\\\": \\\"Hello, pros... Some of the senior Bangboo of our merchant association have gone missing! We urgently need an expert to help find them!!\\\\nLet me explain, I recently joined a very prestigiousâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0."},
  {"name":"OpenOrca-EnKoZhJa-18k","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/werty1248/OpenOrca-EnKoZhJa-18k","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","description":"This dataset is a collection of Korean, Chinese, and Japanese OpenOrca translation datasets.\\nThe dataset was matched using id based on kyujinpy/OpenOrca-KO, which had the smallest number of rows.\\nWhen more than one translation existed for a language, I chose the more similar one based on similarity of embedding(BAAI/BGE-m3).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Sources\\n\\t\\n\\n\\nEnglish(Original)\\nOpen-Orca/OpenOrca\\n\\n\\nKorean(Translated with DeepL Pro API)\\nkyujinpy/OpenOrca-KO\\n\\n\\nChinese(Translated with Google Translate)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/werty1248/OpenOrca-EnKoZhJa-18k."},
  {"name":"MedQA-Evol-Korean","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ChuGyouk/MedQA-Evol-Korean","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\\n\\t\\n\\t\\t\\n\\t\\tMedQA-Evol\\n\\t\\n\\nOriginal Data: TsinghuaC3I/UltraMedical.\\nTranslated into Korean by \\\"solar-1-mini-translate-enko\\\".\\n"},
  {"name":"small_kitchen_appliances_review","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jr-d-analyst24/small_kitchen_appliances_review","creator_name":"dayoungyoun","creator_url":"https://huggingface.co/jr-d-analyst24","description":"jr-d-analyst24/small_kitchen_appliances_review dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"small_kitchen_appliances_total_reviews","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jr-d-analyst24/small_kitchen_appliances_total_reviews","creator_name":"dayoungyoun","creator_url":"https://huggingface.co/jr-d-analyst24","description":"jr-d-analyst24/small_kitchen_appliances_total_reviews dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"ai_hub_summ_train","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jr-d-analyst24/ai_hub_summ_train","creator_name":"dayoungyoun","creator_url":"https://huggingface.co/jr-d-analyst24","description":"jr-d-analyst24/ai_hub_summ_train dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"wikipedia-ko","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/blueapple8259/wikipedia-ko","creator_name":"blueapple825","creator_url":"https://huggingface.co/blueapple8259","description":"blueapple8259/wikipedia-ko dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"ai_hub_narr_sum_vali","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jr-d-analyst24/ai_hub_narr_sum_vali","creator_name":"dayoungyoun","creator_url":"https://huggingface.co/jr-d-analyst24","description":"jr-d-analyst24/ai_hub_narr_sum_vali dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"MedExpQA-Kor","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ChuGyouk/MedExpQA-Kor","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMedExpQA\\n\\t\\n\\nOriginal Data: HiTZ/MedExpQA\\nEn subset, train split and validation split are translated into Korean by \\\"solar-1-mini-translate-enko\\\".\\n"},
  {"name":"GenMedGPT-5k-ko","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ChuGyouk/GenMedGPT-5k-ko","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMedQA-Evol\\n\\t\\n\\nOriginal Data: ChatDoctor.\\nTranslated into Korean by DeepL Pro.\\n"},
  {"name":"Asan-AMC-Healthinfo","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ChuGyouk/Asan-AMC-Healthinfo","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\\n\\t\\n\\t\\t\\n\\t\\tAsan-AMC-Healthinfo\\n\\t\\n\\nSource: ì„œìš¸ì•„ì‚°ë³‘ì› ê±´ê°•ì •ë³´.\\nì„œìš¸ì•„ì‚°ë³‘ì› í™ˆí˜ì´ì§€ì˜ ê±´ê°•ì •ë³´-ì˜ë£Œì •ë³´ì—ì„œ, ì¸ì²´ì •ë³´/ì§ˆí™˜ë°±ê³¼/ê²€ì‚¬ì‹œìˆ ìˆ˜ìˆ ì •ë³´/ì•Œê¸°ì‰¬ìš´ì˜í•™ìš©ì–´/ì‹ì‚¬ìš”ë²• ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ\\nalpaca-styleë¡œ í¸ì§‘í•œ ë°ì´í„°ì…ë‹ˆë‹¤.\\n"},
  {"name":"KISS_delirium_papaers","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/gykwak03/KISS_delirium_papaers","creator_name":"ê³½ê°€ì˜","creator_url":"https://huggingface.co/gykwak03","description":"This is an abstract of a paper derived from a search for â€œdeliriumâ€ in KISS (Koreanstudies Information Service System).\\n\\\"ko_data.csv\\\" is abstract in Korean, and \\\"en_data.csv\\\" is abstract in English.\\n"},
  {"name":"ksponspeech-eval","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/yfyeung/ksponspeech-eval","creator_name":"Yifan Yang","creator_url":"https://huggingface.co/yfyeung","description":"paper link: https://www.mdpi.com/846876\\n"},
  {"name":"ko-coffee-QA","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/williamjeong2/ko-coffee-QA","creator_name":"jeong","creator_url":"https://huggingface.co/williamjeong2","description":"williamjeong2/ko-coffee-QA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"ANSAN_WORK","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/poopki/ANSAN_WORK","creator_name":"mingu kang","creator_url":"https://huggingface.co/poopki","description":"poopki/ANSAN_WORK dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"korean-emotion-lexicon","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jonghwanhyeon/korean-emotion-lexicon","creator_name":"Jonghwan Hyeon","creator_url":"https://huggingface.co/jonghwanhyeon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKorean Emotion Lexicon\\n\\t\\n\\nThis repository contains a comprehensive dataset of Korean emotion lexicons developed through psychological research conducted by In-jo Park and Kyung-Hwan Min from Seoul National University. The dataset includes several key measures for each emotion lexicon:\\n\\nlexicon: The lexicon that represents a specific emotion in the Korean language.\\nrepresentative: The degree to which the lexicon is a representative example of the emotion.\\nprototypicality: A ratingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jonghwanhyeon/korean-emotion-lexicon."},
  {"name":"korean-emotion-lexicon","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jonghwanhyeon/korean-emotion-lexicon","creator_name":"Jonghwan Hyeon","creator_url":"https://huggingface.co/jonghwanhyeon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKorean Emotion Lexicon\\n\\t\\n\\nThis repository contains a comprehensive dataset of Korean emotion lexicons developed through psychological research conducted by In-jo Park and Kyung-Hwan Min from Seoul National University. The dataset includes several key measures for each emotion lexicon:\\n\\nlexicon: The lexicon that represents a specific emotion in the Korean language.\\nrepresentative: The degree to which the lexicon is a representative example of the emotion.\\nprototypicality: A ratingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jonghwanhyeon/korean-emotion-lexicon."},
  {"name":"ko_QA_dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kikikara/ko_QA_dataset","creator_name":"kimjeasung","creator_url":"https://huggingface.co/kikikara","description":"maywell/korean_textbooks ì˜ datasetì„ Q&A í˜•ì‹ìœ¼ë¡œ ì¬êµ¬ì„±í•œ datasetì…ë‹ˆë‹¤.\\n"},
  {"name":"ko-math","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kikikara/ko-math","creator_name":"kimjeasung","creator_url":"https://huggingface.co/kikikara","description":"hendrycks/math datasetì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•œ dataset ì…ë‹ˆë‹¤.\\n"},
  {"name":"PangeaBench-xm100","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM100\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n"},
  {"name":"comment-translation-01","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ifmain/comment-translation-01","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","description":"This dataset is based on Kaggle.  \\nThis dataset includes translations of 69,000 Reddit comments into 17 languages (English to 16 languages):\\nBelarusian, Czech, German,\\nEnglish, Spanish, Finnish,\\nFrench, Italian, Japanese,\\nKazakh, Korean, Latvian,\\nPolish, Russian, Swedish,\\nUkrainian, and Chinese.\\nIt contains 50% regular comments and 50% highly negative ones.\\nEnjoy using it!\\n"},
  {"name":"ApolloMoEDataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   ğŸ“ƒ Paper â€¢ ğŸŒ Demo â€¢ ğŸ¤— ApolloMoEDataset â€¢ ğŸ¤— ApolloMoEBench  â€¢ ğŸ¤— Models  â€¢ğŸŒ Apollo  â€¢ ğŸŒ ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸŒˆ Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedï¼ğŸ‰\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset."},
  {"name":"ApolloMoEBench","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   ğŸ“ƒ Paper â€¢ ğŸŒ Demo â€¢ ğŸ¤— ApolloMoEDataset â€¢ ğŸ¤— ApolloMoEBench  â€¢ ğŸ¤— Models  â€¢ğŸŒ Apollo  â€¢ ğŸŒ ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸŒˆ Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedï¼ğŸ‰\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench."},
  {"name":"KoFinDER","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/mssongit/KoFinDER","creator_name":"SONGMINSANG","creator_url":"https://huggingface.co/mssongit","description":"mssongit/KoFinDER dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"PangeaBench-xgqa","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/neulab/PangeaBench-xgqa","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\txGQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a clone of the few_shot-test split of the xGQA dataset\\n\\t\\n\\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{pfeiffer-etal-2021-xGQA,\\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\\\'{c}} and Iryna Gurevych}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-xgqa."},
  {"name":"influencer_rec_ko","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/Hyunggi/influencer_rec_ko","creator_name":"Chang","creator_url":"https://huggingface.co/Hyunggi","description":"Hyunggi/influencer_rec_ko dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"influencer_rec_ko","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/Hyunggi/influencer_rec_ko","creator_name":"Chang","creator_url":"https://huggingface.co/Hyunggi","description":"Hyunggi/influencer_rec_ko dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Ko_Simple_QA","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/sionic-ai/Ko_Simple_QA","creator_name":"sionic-ai","creator_url":"https://huggingface.co/sionic-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tí•œì˜ ì§ˆë¬¸ë‹µë³€ ë°ì´í„°ì…‹\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të°ì´í„°ì…‹ ì„¤ëª…\\n\\t\\n\\nì´ ë°ì´í„°ì…‹ì€ ì˜ì–´ ì§ˆë¬¸ë‹µë³€ ìŒê³¼ ê·¸ì— ëŒ€ì‘í•˜ëŠ” í•œêµ­ì–´ ë²ˆì—­ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. \\nê° ë°ì´í„° í¬ì¸íŠ¸\\n\\në©”íƒ€ë°ì´í„°: ì£¼ì œ, ë‹µë³€ ìœ í˜•, ì°¸ê³  URL ë“±ì˜ ì •ë³´\\nì˜ì–´ ì§ˆë¬¸\\nì˜ì–´ ë‹µë³€\\ní•œêµ­ì–´ ì§ˆë¬¸\\ní•œêµ­ì–´ ë‹µë³€\\n\\nì´ 4,265ê°œì˜ ì§ˆë¬¸ë‹µë³€ ìŒì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, CSV í˜•ì‹ìœ¼ë¡œ ì œê³µ.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tì›ì²œ ë°ì´í„° ê´€ë ¨ ë§í¬\\n\\t\\n\\nhttps://github.com/openai/simple-evals\\nhttps://openai.com/index/introducing-simpleqa/\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të°ì´í„° ì˜ˆì‹œ\\n\\t\\n\\n{\\n  \\\"metadata\\\": {\\n    \\\"topic\\\": \\\"Science and technology\\\",\\n    \\\"answer_type\\\": \\\"Person\\\",\\n    \\\"urls\\\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sionic-ai/Ko_Simple_QA."},
  {"name":"Ko_Simple_QA","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/sionic-ai/Ko_Simple_QA","creator_name":"sionic-ai","creator_url":"https://huggingface.co/sionic-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tí•œì˜ ì§ˆë¬¸ë‹µë³€ ë°ì´í„°ì…‹\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të°ì´í„°ì…‹ ì„¤ëª…\\n\\t\\n\\nì´ ë°ì´í„°ì…‹ì€ ì˜ì–´ ì§ˆë¬¸ë‹µë³€ ìŒê³¼ ê·¸ì— ëŒ€ì‘í•˜ëŠ” í•œêµ­ì–´ ë²ˆì—­ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. \\nê° ë°ì´í„° í¬ì¸íŠ¸\\n\\në©”íƒ€ë°ì´í„°: ì£¼ì œ, ë‹µë³€ ìœ í˜•, ì°¸ê³  URL ë“±ì˜ ì •ë³´\\nì˜ì–´ ì§ˆë¬¸\\nì˜ì–´ ë‹µë³€\\ní•œêµ­ì–´ ì§ˆë¬¸\\ní•œêµ­ì–´ ë‹µë³€\\n\\nì´ 4,265ê°œì˜ ì§ˆë¬¸ë‹µë³€ ìŒì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, CSV í˜•ì‹ìœ¼ë¡œ ì œê³µ.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tì›ì²œ ë°ì´í„° ê´€ë ¨ ë§í¬\\n\\t\\n\\nhttps://github.com/openai/simple-evals\\nhttps://openai.com/index/introducing-simpleqa/\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të°ì´í„° ì˜ˆì‹œ\\n\\t\\n\\n{\\n  \\\"metadata\\\": {\\n    \\\"topic\\\": \\\"Science and technology\\\",\\n    \\\"answer_type\\\": \\\"Person\\\",\\n    \\\"urls\\\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sionic-ai/Ko_Simple_QA."},
  {"name":"MegaWika","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/conceptofmind/MegaWika","creator_name":"Enrico Shippole","creator_url":"https://huggingface.co/conceptofmind","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. Furthermore, nearly 130 million Englishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/conceptofmind/MegaWika."},
  {"name":"finance-legal-mrc","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/shchoice/finance-legal-mrc","creator_name":"Seohwan Choi","creator_url":"https://huggingface.co/shchoice","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tê¸ˆìœµ, ë²•ë¥  ë¬¸ì„œ ê¸°ê³„ë…í•´ ë°ì´í„°ì…‹\\n\\t\\n\\nê¸ˆìœµ ë° ë²•ë¥  ë¶„ì•¼ ì „ë¬¸ë¬¸ì„œë¥¼ í™œìš©í•˜ì—¬ ê¸°ê³„ë…í•´ ëª¨ë¸ ìƒì„±ì„ ìœ„í•œ ì§€ë¬¸-ì§ˆë¬¸-ë‹µë³€ìœ¼ë¡œ êµ¬ì„±ëœ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të°ì´í„°ì…‹ êµ¬ì„±\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\nspan_extraction: ì •ë‹µê²½ê³„ ì¶”ì¶œí˜•(ì •ë‹µì´ ì§€ë¬¸ ë‚´ íŠ¹ì • ë²”ìœ„ì— ìˆëŠ” ë°ì´í„°)\\nspan_extraction_how: ì ˆì°¨(ë°©ë²•)(ì–´ë–»ê²Œë¡œ ì‹œì‘í•˜ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ì •ë‹µ ì¶”ì¶œ ë°ì´í„°)\\nmultiple_choice: ë‹¤ì§€ì„ ë‹¤í˜•(ê°ê´€ì‹ í˜•íƒœì˜ ë°ì´í„°)\\ntableqa: Table ì •ë‹µì¶”ì¶œí˜•(í‘œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ë°ì´í„°)\\ntext_entailment: Yes/No ë‹¨ë¬¸í˜•(Boolean ì„ íƒ í˜•íƒœì˜ ë°ì´í„°)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSplits\\n\\t\\n\\n\\ntrain: í•™ìŠµìš© ë°ì´í„°ì…‹\\nvalidation: ê²€ì¦ìš© ë°ì´í„°ì…‹\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tì‚¬ìš© ë°©ë²•\\n\\t\\n\\nfrom datasets import load_dataset\\níŠ¹ì •â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shchoice/finance-legal-mrc."},
  {"name":"finance-legal-mrc","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/shchoice/finance-legal-mrc","creator_name":"Seohwan Choi","creator_url":"https://huggingface.co/shchoice","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tê¸ˆìœµ, ë²•ë¥  ë¬¸ì„œ ê¸°ê³„ë…í•´ ë°ì´í„°ì…‹\\n\\t\\n\\nê¸ˆìœµ ë° ë²•ë¥  ë¶„ì•¼ ì „ë¬¸ë¬¸ì„œë¥¼ í™œìš©í•˜ì—¬ ê¸°ê³„ë…í•´ ëª¨ë¸ ìƒì„±ì„ ìœ„í•œ ì§€ë¬¸-ì§ˆë¬¸-ë‹µë³€ìœ¼ë¡œ êµ¬ì„±ëœ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të°ì´í„°ì…‹ êµ¬ì„±\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\nspan_extraction: ì •ë‹µê²½ê³„ ì¶”ì¶œí˜•(ì •ë‹µì´ ì§€ë¬¸ ë‚´ íŠ¹ì • ë²”ìœ„ì— ìˆëŠ” ë°ì´í„°)\\nspan_extraction_how: ì ˆì°¨(ë°©ë²•)(ì–´ë–»ê²Œë¡œ ì‹œì‘í•˜ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ì •ë‹µ ì¶”ì¶œ ë°ì´í„°)\\nmultiple_choice: ë‹¤ì§€ì„ ë‹¤í˜•(ê°ê´€ì‹ í˜•íƒœì˜ ë°ì´í„°)\\ntableqa: Table ì •ë‹µì¶”ì¶œí˜•(í‘œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ë°ì´í„°)\\ntext_entailment: Yes/No ë‹¨ë¬¸í˜•(Boolean ì„ íƒ í˜•íƒœì˜ ë°ì´í„°)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSplits\\n\\t\\n\\n\\ntrain: í•™ìŠµìš© ë°ì´í„°ì…‹\\nvalidation: ê²€ì¦ìš© ë°ì´í„°ì…‹\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tì‚¬ìš© ë°©ë²•\\n\\t\\n\\nfrom datasets import load_dataset\\níŠ¹ì •â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shchoice/finance-legal-mrc."},
  {"name":"wiktionary-data","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/QubitPi/wiktionary-data","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWiktionary Data on Hugging Face Datasets\\n\\t\\n\\n\\n\\n\\n\\n\\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\\nsupports the following languages:\\n\\nDeutsch - German\\nLatinum - Latin\\ná¼™Î»Î»Î·Î½Î¹ÎºÎ® - Ancient Greek\\ní•œêµ­ì–´ - Korean\\nğ ğ¼ğ¹ - Old Persian\\nğ’€ğ’…—ğ’ºğ’Œ‘(ğ’Œ) - Akkadian\\nElamite\\nà¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤®à¥ - Sanskrit, or Classical Sanskrit\\n\\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\\nthe dataset it's getting bigger, I noticed a wave of more exciting potentialsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wiktionary-data."},
  {"name":"wiktionary-data","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/QubitPi/wiktionary-data","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWiktionary Data on Hugging Face Datasets\\n\\t\\n\\n\\n\\n\\n\\n\\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\\nsupports the following languages:\\n\\nDeutsch - German\\nLatinum - Latin\\ná¼™Î»Î»Î·Î½Î¹ÎºÎ® - Ancient Greek\\ní•œêµ­ì–´ - Korean\\nğ ğ¼ğ¹ - Old Persian\\nğ’€ğ’…—ğ’ºğ’Œ‘(ğ’Œ) - Akkadian\\nElamite\\nà¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤®à¥ - Sanskrit, or Classical Sanskrit\\n\\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\\nthe dataset it's getting bigger, I noticed a wave of more exciting potentialsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wiktionary-data."},
  {"name":"pub_med_qa_ko_translated","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/koohack/pub_med_qa_ko_translated","creator_name":"SeungHyun Park","creator_url":"https://huggingface.co/koohack","description":"koohack/pub_med_qa_ko_translated dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"panlex","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex."},
  {"name":"contextomized-quote","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/humane-lab/contextomized-quote","creator_name":"HUMANE Lab","creator_url":"https://huggingface.co/humane-lab","description":"humane-lab/contextomized-quote dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"ChatML-aya_dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = [\\n        {\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": columns[\\\"inputs\\\"].strip(),\\n        },\\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset."},
  {"name":"MultiQ","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiQ\\n\\t\\n\\nThis is the dataset corresponding to the paper \\\"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\\\". \\nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \\ntranslated into 137 typologically diverse languages. \\n\\nCurated by: Carolin Holtermann, Paul RÃ¶ttger, Timm Dill, Anne Lauscher\\nLanguage(s) (NLP): 137 diverseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ."},
  {"name":"bhojpuri","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri."},
  {"name":"panlex-meanings","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings."},
  {"name":"NTREX","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX."},
  {"name":"KoInFoBench","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kifai/KoInFoBench","creator_name":"KIFAI","creator_url":"https://huggingface.co/kifai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKoInFoBench\\n\\t\\n\\nKoInFoBench is a specialized evaluation dataset designed to assess the performance of Large Language Models (LLMs) on capabilities of Korean instructions following.\\nThe current version of KoInFoBench consists of 60 instruction sets and 233 questions.\\nInspired by InFoBench dataset, we extends their concpet by focusing on the nuances and features of Korean language.\\n\\nğŸ–¥ï¸ Code to reproduce or evaluate own LLMs is available at https://github.com/KIFAI/KoInFoBench\\nğŸ“„â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kifai/KoInFoBench."},
  {"name":"hd-bert-voicephishing-binary-classification-ver4","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HyaDoo/hd-bert-voicephishing-binary-classification-ver4","creator_name":"SAERAM LEE","creator_url":"https://huggingface.co/HyaDoo","description":"HyaDoo/hd-bert-voicephishing-binary-classification-ver4 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"KoMedInstruct-52k","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ChuGyouk/KoMedInstruct-52k","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"1ì°¨ ë²ˆì—­ ì™„ë£Œ\\nI found several problems during translation, so additional filtering will be needed after completion.\\nStep 1. It was confirmed that the existing data contained a lot of data that was close to duplicates. Need to remove those.\\nStep 2. There are many outputs with a risk of hallucination. Data where the last sentence of output is incomplete must be edited.\\nStep 3. If data corresponding to the output is also included in the input, those must be edited.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKo-AlpaCare\\n\\t\\n\\nThis isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/KoMedInstruct-52k."},
  {"name":"test","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/haebo1/test","creator_name":"Hyunho Yang","creator_url":"https://huggingface.co/haebo1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KoBEST\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKoBEST is a Korean benchmark suite consists of 5 natural language understanding tasks that requires advanced knowledge in Korean.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nBoolean Question Answering, Choice of Plausible Alternatives, Words-in-Context, HellaSwag, Sentiment Negation Recognition\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nko-KR\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKB-BoolQ\\n\\t\\n\\nAn exampleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/haebo1/test."},
  {"name":"orca-math-korean-preference","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/kuotient/orca-math-korean-preference","creator_name":"Jisoo Kim","creator_url":"https://huggingface.co/kuotient","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOrca-math-korean-preference\\n\\t\\n\\n\\nllm: claude-haikuì™€ gpt3.5ë¡œ í‰ê°€ëœ generated(Student) answerì˜ ì •ë‹µ ì—¬ë¶€\\nquestion: orca-math datasetì˜ question\\nanswer: orca-math datasetì˜ answer\\ngenerated: EEVE-Math-10.8B(M1)ì˜ ì¶œë ¥\\nlabel: llmì˜ ì°¸/ê±°ì§“ \\nchosen: labelì´ ì°¸ì¼ ê²½ìš° answer í˜¹ì€ generatedì˜ random.choice, ê±°ì§“ì¼ ê²½ìš° answer (Orca-math original paper ì°¸ê³ )\\nrejected: labelì´ ì°¸ì¼ ê²½ìš° ë‹¤ë¥¸ rejected valueì˜ random.choice, ê±°ì§“ì¼ ê²½ìš° rejected (Orca-math original paper ì°¸ê³ )\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të¹„ê³ \\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tllm_exact_match promptâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kuotient/orca-math-korean-preference."},
  {"name":"Ko-MTS-Dialog","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ChuGyouk/Ko-MTS-Dialog","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"The validation set and two test sets will also be updated soon.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMTS-Dialog\\n\\t\\n\\nThis is the repo for Ko-MTS-Dialog, which is a Korean translated version of MTS-Dialog dataset. MTS-Dialog dataset is a collection of 1.7k short doctor-patient conversations and corresponding summaries.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Translation Process\\n\\t\\n\\nI use DeepL for automatic translation and manually reviewed results.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWarning\\n\\t\\n\\nThere are some concerns and warnings for this dataset.\\n\\nI recommend NOTâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/Ko-MTS-Dialog."},
  {"name":"xsimplusplus","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n"},
  {"name":"swim-ir-cross-lingual","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SWIM-IR (Cross-lingual)\\n\\t\\n\\n\\n\\n\\nThis is the cross-lingual subset of the SWIM-IR dataset, where the query generated is in the target language and the passage is in English.\\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is a syntheticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual."},
  {"name":"dell-qa-en-to-ko-translated-by-ke-t5-base","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/seongs/dell-qa-en-to-ko-translated-by-ke-t5-base","creator_name":"Kim Seongyeol","creator_url":"https://huggingface.co/seongs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDell QA English to Korean Translation Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset, dell-qa-en-to-ko-translated-by-ke-t5-base, is a Korean translation of the original English Dell QA dataset. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\nThe original dataset, dell_qa, is designed for question-answering tasks and contains questions and answers related to Dell technologies. This translated version extends the utility to Korean language tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/seongs/dell-qa-en-to-ko-translated-by-ke-t5-base."},
  {"name":"wikipedia-korean-20240501","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lcw99/wikipedia-korean-20240501","creator_name":"Chang W Lee","creator_url":"https://huggingface.co/lcw99","description":"wikipedia Korean 2024.5.1 cut\\n"},
  {"name":"sharegpt-tagengo-gpt4-ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/werty1248/sharegpt-tagengo-gpt4-ko","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","description":"Original Dataset: lightblue/tagengo-gpt4\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShareGPT-tagengo-GPT4-ko\\n\\t\\n\\n\\nLMSYS-Chat-1Më¥¼ í†µí•´ ìˆ˜ì§‘ëœ ì‹¤ì œ ìœ ì €ë“¤ê³¼ GPT-4(gpt-4-0125-preview) ì‚¬ì´ì˜ ë‹¨ë°œì„± ëŒ€í™” ë°ì´í„° ì…‹ì…ë‹ˆë‹¤.\\ntagengo-gpt4 ë°ì´í„° ì…‹ì—ì„œ í•œêµ­ì–´ ë°ì´í„° 1,609ê°œë¥¼ ì¶”ì¶œí•œ ë’¤, ì‚¬ëŒì´ ì§ì ‘ í™•ì¸í•˜ì—¬ ì¼ë¶€ ë¶ˆí•„ìš”í•œ/ì¤‘ë³µ ì§ˆë¬¸, ì˜ëª»ëœ ë‹µë³€ ë“±ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.\\nìì„¸í•œ ì–¸ì–´ë³„ ë¶„ë¥˜ ë°©ë²•ì€ lightblue/tagengo-gpt4ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.\\në²ˆì—­ì´ ì•„ë‹Œ, ì‹¤ì œ í•œêµ­ì–´ë¡œ ì£¼ê³  ë°›ì€ ë°ì´í„° ì…‹ì…ë‹ˆë‹¤.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFiles\\n\\t\\n\\n\\nsharegpt_tagengo_ko.json: ë¶ˆí•„ìš”í•œ/ì¤‘ë³µ ì§ˆë¬¸ ë° ì˜ëª»ëœ ë‹µë³€ì„ ì œê±°í•œ 1,540ê°œ ë°ì´í„°ì…ë‹ˆë‹¤.\\nsharegpt_tagengo_ko_no_sorry.json: sharegpt_tagengo_ko.jsonì—ì„œ \\\"ì£„ì†¡\\\"ìœ¼ë¡œ ì‹œì‘ë˜ëŠ” ë‹µë³€(GPT-4ì˜â€¦ See the full description on the dataset page: https://huggingface.co/datasets/werty1248/sharegpt-tagengo-gpt4-ko."},
  {"name":"interesting-dom-snapshots","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/gbenson/interesting-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Interesting DOM snapshots\\n\\t\\n\\nA small split of gbenson/webui-dom-snapshots.\\n\\nCurated by: Gary Benson\\nLanguages: Mostly English, some Chinese, Dutch, Czech and Korean\\nLicense: CC0 1.0 Universal\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\nI'm using it to develop a DOM-aware tokenizer for HTML.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBias, Risks, and Limitations\\n\\t\\n\\nThis isn't a representative split of the source dataset, it's a number of edge cases I flagged to investigate.\\n"},
  {"name":"sib200","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200."},
  {"name":"orca-math-word-problems-193k-korean-jsonl","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/jaypyon/orca-math-word-problems-193k-korean-jsonl","creator_name":"Jaeyong Park","creator_url":"https://huggingface.co/jaypyon","description":"ì›ë³¸ ë°ì´í„°ì…‹\\n\\nhttps://huggingface.co/datasets/microsoft/orca-math-word-problems-200k\\nhttps://huggingface.co/datasets/kuotient/orca-math-word-problems-193k-korean\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{mitra2024orcamath,\\n      title={Orca-Math: Unlocking the potential of SLMs in Grade School Math}, \\n      author={Arindam Mitra and Hamed Khanpour and Corby Rosset and Ahmed Awadallah},\\n      year={2024},\\n      eprint={2402.14830},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n"},
  {"name":"qarv-instruct-ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HAERAE-HUB/qarv-instruct-ko","creator_name":"HAE-RAE","creator_url":"https://huggingface.co/HAERAE-HUB","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQARV-Instruct-KO\\n\\t\\n\\nThis subset of our dataset contains pairs of instructions and answers requiring knowledge of Korea.Unlike past works relying heavily on proprietary LLMs for data generation, we use a pipeline of open-source LLMs without restrictions on output usage.  \\nIn other words, you're completely free to use this dataset for training your models. Paper coming soon.\\n"},
  {"name":"oldhangul-dataset","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/devngho/oldhangul-dataset","creator_name":"devngho","creator_url":"https://huggingface.co/devngho","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tì˜›í•œê¸€ ë°ì´í„°ì…‹\\n\\t\\n\\noriginal(HERE) | cleaned\\nìœ„í‚¤ë¬¸í—Œì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•í•œ ì˜›í•œê¸€ ë°ì´í„°ì…‹\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të¶ˆëŸ¬ì˜¤ê¸°\\n\\t\\n\\nfrom datasets import load_dataset\\n\\nds = load_dataset(\\\"devngho/oldhangul-dataset\\\", \\\"wikisource_v2\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të¼ì´ì„ ìŠ¤\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të°ì´í„°ì…‹\\n\\t\\n\\nCC BY-SA 4.0 DEED\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tìë£Œ\\n\\t\\n\\nìœ„í‚¤ë¬¸í—Œ ê¸°ì—¬ì, ìœ„í‚¤ë¬¸í—Œ / CC BY-SA 4.0 DEED \\ncleaned ë²„ì „ì€ í•œì ë¹„ìœ¨ì´ 20% ì´ìƒì¸ ê²ƒì„ ê±¸ëŸ¬ë‚´ê³  <br>, ì—¬ëŸ¬ ì¤„ì˜ \\\\n ë“±ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.\\në°ì´í„°ì˜ license í•„ë“œì—ì„œ ìœ„í‚¤ë¬¸í—Œ ë§í¬ì™€ ì›ë³¸ ìë£Œ ìœ„ì¹˜ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n"},
  {"name":"oldhangul-dataset-cleaned","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/devngho/oldhangul-dataset-cleaned","creator_name":"devngho","creator_url":"https://huggingface.co/devngho","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tì˜›í•œê¸€ ë°ì´í„°ì…‹\\n\\t\\n\\noriginal | cleaned(HERE)\\nìœ„í‚¤ë¬¸í—Œì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•í•œ ì˜›í•œê¸€ ë°ì´í„°ì…‹\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të¶ˆëŸ¬ì˜¤ê¸°\\n\\t\\n\\nfrom datasets import load_dataset\\n\\nds = load_dataset(\\\"devngho/oldhangul-dataset-cleaned\\\", \\\"wikisource_v2\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të¼ì´ì„ ìŠ¤\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të°ì´í„°ì…‹\\n\\t\\n\\nCC BY-SA 4.0 DEED\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tìë£Œ\\n\\t\\n\\nìœ„í‚¤ë¬¸í—Œ ê¸°ì—¬ì, ìœ„í‚¤ë¬¸í—Œ / CC BY-SA 4.0 DEED \\ncleaned ë²„ì „ì€ í•œì ë¹„ìœ¨ì´ 20% ì´ìƒì¸ ê²ƒì„ ê±¸ëŸ¬ë‚´ê³  <br>, ì—¬ëŸ¬ ì¤„ì˜ \\\\n ë“±ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.\\në°ì´í„°ì˜ license í•„ë“œì—ì„œ ìœ„í‚¤ë¬¸í—Œ ë§í¬ì™€ ì›ë³¸ ìë£Œ ìœ„ì¹˜ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n"},
  {"name":"NTREX","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX."},
  {"name":"ParaNames","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames."},
  {"name":"aihub-koja-translation-integrated-large-4.3m","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-large-4.3m","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Ja Translation Dataset (Integrated)\\n\\t\\n\\nAI Hubì˜ í•œ-ì¼ ë²ˆì—­ ê´€ë ¨ ë°ì´í„°ì…‹ 10ê°œë¥¼ ë³‘í•©í•œ ìë£Œì…ë‹ˆë‹¤. ë³‘í•© ì‹œ ì´ ë°ì´í„° ê°œìˆ˜ëŠ” 4,339,465ê°œì´ë©°, ì´ì¤‘ 10,000ê°œì˜ validation setì™€ 2,000ê°œì˜ test setê°€ ë¶„ë¦¬ë˜ì–´ ëª¨ë“  ë°ì´í„° ì‚¬ì´ì¦ˆ(large-4.3m, base-1m, small-100k)ì—ì„œ ë™ì¼í•˜ê²Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\\n\\nlarge-4.3m (train): ë³‘í•© ë°ì´í„° 100% ì‚¬ìš©; ì´ 4,327,465ê°œ\\n\\nbase-1m (train): ë³‘í•© ë°ì´í„° ì¤‘ 1Mê°œ ì‚¬ìš©; ì´ 1,000,000ê°œ\\n\\nsmall-100k (train): ë³‘í•© ë°ì´í„° ì¤‘ 100Kê°œ ì‚¬ìš©; ì´ 100,000ê°œ\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nJapanese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-large-4.3m."},
  {"name":"aihub-kozh-translation-integrated-large-5.9m","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-large-5.9m","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Zh Translation Dataset (Integrated)\\n\\t\\n\\nAI Hubì˜ í•œ-ì¤‘ ë²ˆì—­ ê´€ë ¨ ë°ì´í„°ì…‹ 10ê°œë¥¼ ë³‘í•©í•œ ìë£Œì…ë‹ˆë‹¤. ë³‘í•© ì‹œ ì´ ë°ì´í„° ê°œìˆ˜ëŠ” 5,934,596ê°œì´ë©°, ì´ì¤‘ 10,000ê°œì˜ validation setì™€ 2,000ê°œì˜ test setê°€ ë¶„ë¦¬ë˜ì–´ ëª¨ë“  ë°ì´í„° ì‚¬ì´ì¦ˆ(large-5.9m, base-1m, small-100k)ì—ì„œ ë™ì¼í•˜ê²Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\\n\\nlarge-5.9m (train): ë³‘í•© ë°ì´í„° 100% ì‚¬ìš©; ì´ 5,922,596ê°œ\\n\\nbase-1m (train): ë³‘í•© ë°ì´í„° ì¤‘ 1Mê°œ ì‚¬ìš©; ì´ 1,000,000ê°œ\\n\\nsmall-100k (train): ë³‘í•© ë°ì´í„° ì¤‘ 100Kê°œ ì‚¬ìš©; ì´ 100,000ê°œ\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nChinese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)\\n\\n\\n\\t\\t\\ní•œêµ­ì–´-ì¤‘êµ­ì–´â€¦ See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-large-5.9m."},
  {"name":"aihub-koja-translation-integrated-base-1m","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-base-1m","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Ja Translation Dataset (Integrated)\\n\\t\\n\\nAI Hubì˜ í•œ-ì¼ ë²ˆì—­ ê´€ë ¨ ë°ì´í„°ì…‹ 10ê°œë¥¼ ë³‘í•©í•œ ìë£Œì…ë‹ˆë‹¤. ë³‘í•© ì‹œ ì´ ë°ì´í„° ê°œìˆ˜ëŠ” 4,339,465ê°œì´ë©°, ì´ì¤‘ 10,000ê°œì˜ validation setì™€ 2,000ê°œì˜ test setê°€ ë¶„ë¦¬ë˜ì–´ ëª¨ë“  ë°ì´í„° ì‚¬ì´ì¦ˆ(large-4.3m, base-1m, small-100k)ì—ì„œ ë™ì¼í•˜ê²Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\\n\\nlarge-4.3m (train): ë³‘í•© ë°ì´í„° 100% ì‚¬ìš©; ì´ 4,327,465ê°œ\\n\\nbase-1m (train): ë³‘í•© ë°ì´í„° ì¤‘ 1Mê°œ ì‚¬ìš©; ì´ 1,000,000ê°œ\\n\\nsmall-100k (train): ë³‘í•© ë°ì´í„° ì¤‘ 100Kê°œ ì‚¬ìš©; ì´ 100,000ê°œ\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nJapanese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-base-1m."},
  {"name":"aihub-koja-translation-integrated-small-100k","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-small-100k","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Ja Translation Dataset (Integrated)\\n\\t\\n\\nAI Hubì˜ í•œ-ì¼ ë²ˆì—­ ê´€ë ¨ ë°ì´í„°ì…‹ 10ê°œë¥¼ ë³‘í•©í•œ ìë£Œì…ë‹ˆë‹¤. ë³‘í•© ì‹œ ì´ ë°ì´í„° ê°œìˆ˜ëŠ” 4,339,465ê°œì´ë©°, ì´ì¤‘ 10,000ê°œì˜ validation setì™€ 2,000ê°œì˜ test setê°€ ë¶„ë¦¬ë˜ì–´ ëª¨ë“  ë°ì´í„° ì‚¬ì´ì¦ˆ(large-4.3m, base-1m, small-100k)ì—ì„œ ë™ì¼í•˜ê²Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\\n\\nlarge-4.3m (train): ë³‘í•© ë°ì´í„° 100% ì‚¬ìš©; ì´ 4,327,465ê°œ\\n\\nbase-1m (train): ë³‘í•© ë°ì´í„° ì¤‘ 1Mê°œ ì‚¬ìš©; ì´ 1,000,000ê°œ\\n\\nsmall-100k (train): ë³‘í•© ë°ì´í„° ì¤‘ 100Kê°œ ì‚¬ìš©; ì´ 100,000ê°œ\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nJapanese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-small-100k."},
  {"name":"aihub-kozh-translation-integrated-base-1m","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-base-1m","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Zh Translation Dataset (Integrated)\\n\\t\\n\\nAI Hubì˜ í•œ-ì¤‘ ë²ˆì—­ ê´€ë ¨ ë°ì´í„°ì…‹ 10ê°œë¥¼ ë³‘í•©í•œ ìë£Œì…ë‹ˆë‹¤. ë³‘í•© ì‹œ ì´ ë°ì´í„° ê°œìˆ˜ëŠ” 5,934,596ê°œì´ë©°, ì´ì¤‘ 10,000ê°œì˜ validation setì™€ 2,000ê°œì˜ test setê°€ ë¶„ë¦¬ë˜ì–´ ëª¨ë“  ë°ì´í„° ì‚¬ì´ì¦ˆ(large-5.9m, base-1m, small-100k)ì—ì„œ ë™ì¼í•˜ê²Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\\n\\nlarge-5.9m (train): ë³‘í•© ë°ì´í„° 100% ì‚¬ìš©; ì´ 5,922,596ê°œ\\n\\nbase-1m (train): ë³‘í•© ë°ì´í„° ì¤‘ 1Mê°œ ì‚¬ìš©; ì´ 1,000,000ê°œ\\n\\nsmall-100k (train): ë³‘í•© ë°ì´í„° ì¤‘ 100Kê°œ ì‚¬ìš©; ì´ 100,000ê°œ\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nChinese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)\\n\\n\\n\\t\\t\\ní•œêµ­ì–´-ì¤‘êµ­ì–´â€¦ See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-base-1m."},
  {"name":"aihub-kozh-translation-integrated-small-100k","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-small-100k","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Zh Translation Dataset (Integrated)\\n\\t\\n\\nAI Hubì˜ í•œ-ì¤‘ ë²ˆì—­ ê´€ë ¨ ë°ì´í„°ì…‹ 10ê°œë¥¼ ë³‘í•©í•œ ìë£Œì…ë‹ˆë‹¤. ë³‘í•© ì‹œ ì´ ë°ì´í„° ê°œìˆ˜ëŠ” 5,934,596ê°œì´ë©°, ì´ì¤‘ 10,000ê°œì˜ validation setì™€ 2,000ê°œì˜ test setê°€ ë¶„ë¦¬ë˜ì–´ ëª¨ë“  ë°ì´í„° ì‚¬ì´ì¦ˆ(large-5.9m, base-1m, small-100k)ì—ì„œ ë™ì¼í•˜ê²Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\\n\\nlarge-5.9m (train): ë³‘í•© ë°ì´í„° 100% ì‚¬ìš©; ì´ 5,922,596ê°œ\\n\\nbase-1m (train): ë³‘í•© ë°ì´í„° ì¤‘ 1Mê°œ ì‚¬ìš©; ì´ 1,000,000ê°œ\\n\\nsmall-100k (train): ë³‘í•© ë°ì´í„° ì¤‘ 100Kê°œ ì‚¬ìš©; ì´ 100,000ê°œ\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nChinese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)\\n\\n\\n\\t\\t\\ní•œêµ­ì–´-ì¤‘êµ­ì–´â€¦ See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-small-100k."},
  {"name":"danbooru_wikis_full","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/deepghs/danbooru_wikis_full","creator_name":"DeepGHS","creator_url":"https://huggingface.co/deepghs","description":"\\n\\t\\n\\t\\t\\n\\t\\tDanbooru Full Wiki Dataset\\n\\t\\n\\nThis is the full wiki dataset of danbooru.donmai.us, containing the wiki pages/tags/tag aliases/tag implications. You can train something like LLMs on this dataset\\n\\n\\t\\n\\t\\t\\n\\t\\tInformation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWiki Pages\\n\\t\\n\\nThere are 189161 wiki items in total. Last updated at 2024-06-16 02:31:27 UTC.\\nThese are the information of recent 50 wiki items:\\n\\n\\t\\n\\t\\t\\nid\\ntitle\\nother_names\\ntext_length\\nis_locked\\nis_deleted\\ncreated_at\\nupdated_at\\n\\n\\n\\t\\t\\n196503\\nli_yuting_(female)\\n[\\\"ç¦»é›¨å©·\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/deepghs/danbooru_wikis_full."},
  {"name":"M3GIA","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Songweii/M3GIA","creator_name":"Wei Song","creator_url":"https://huggingface.co/Songweii","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tM3GIA: A Cognition Inspired Multilingual and Multimodal General Intelligence Ability\\n\\t\\n\\n[ğŸŒ Homepage] | ğŸ¤— Dataset | ğŸ¤— Paper | ğŸ“– arXiv | ğŸ’» GitHub\\nThe evaluation code can be found in ğŸ’» GitHub.\\n[Abstract]\\nAs recent multi-modality large language models (MLLMs) have shown formidable proficiency on various complex tasks, there has been increasing attention on debating whether these models could eventually mirror human intelligence. However, existing benchmarks mainly focus onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Songweii/M3GIA."},
  {"name":"bitext_sib200_miners","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fleurs_clean","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean."},
  {"name":"ko-code-alpaca-QA","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CarrotAI/ko-code-alpaca-QA","creator_name":"CarrotCarrot","creator_url":"https://huggingface.co/CarrotAI","description":"code-alpaca QA ë°ì´í„°ì…‹ì…ë‹ˆë‹¤. \\ní•„í„°ë§ì´ ì–´ëŠì •ë„ í•„ìš”í•©ë‹ˆë‹¤.\\nì°¸ê³ í•˜ì‹œê³  ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\\n"},
  {"name":"xP3x-Kongo","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ğŸ§¡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo."},
  {"name":"Image-Detailed-Description-Korean","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Nagase-Kotono/Image-Detailed-Description-Korean","creator_name":"Nagase_Kotono","creator_url":"https://huggingface.co/Nagase-Kotono","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tImage-Detailed-Description-Korean\\n\\t\\n\\nLLaVA-NeXTì— ì í˜€ìˆëŠ” ë‚´ìš©ì¤‘ High-Quality Knowledge Learningë¶€ë¶„ì— ë‹¤ìŒì˜ ë‚´ìš©ì´ ìˆìŠµë‹ˆë‹¤:  \\n\\nEnhanced Performance with Recaptioned Data  \\n\\nModels trained with recaptioned data (ReCap) datasets, show a trend of enhanced performance in tasks requiring detailed image descriptions and document understanding.  \\nThe regenerated captions, ranging from 118K to 3M, demonstrate better scaling behaviors than the original captions, consistently improve model performanceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nagase-Kotono/Image-Detailed-Description-Korean."},
  {"name":"Korean-1930-Novel-Scene-Summarize","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/werty1248/Korean-1930-Novel-Scene-Summarize","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tí•œêµ­ ì €ì‘ê¶Œ ë§Œë£Œ ì†Œì„¤ì— ëŒ€í•œ ì”¬ ë¶„ë¦¬ ë° ìš”ì•½ ë°ì´í„° ì…‹\\n\\t\\n\\n\\nì›ì²œ ë°ì´í„° ì¶œì²˜: https://gongu.copyright.or.kr/gongu/wrt/wrtCl/listWrtText.do?menuNo=200019\\nì´ 96ê°œ ì†Œì„¤ ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬\\ní•œìê°€ ë§ì€ ì†Œì„¤ ì œì™¸\\ní•œì ì œê±°, ë„ì–´ì“°ê¸° ì „ì²˜ë¦¬ ìˆ˜í–‰\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tì”¬ ë¶„ë¦¬\\n\\t\\n\\n\\nì‚¬ìš© ëª¨ë¸: Gemini-1.5-Flash\\n(ë„ì–´ì“°ê¸° í¬í•¨) 100ì ì´ìƒ, 1200ì ë¯¸ë§Œìœ¼ë¡œ ì ì ˆí•œ ë¬¸ì¥ì—ì„œ ì”¬ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ë„ë¡ ì§€ì‹œ\\nì´ 12,108ì”¬ ìƒì„±\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tìš”ì•½\\n\\t\\n\\n\\nì‚¬ìš© ëª¨ë¸: Gemini-1.5-Flash(ë•Œë•Œë¡œ GPT-4o)\\nê° Sceneì—ì„œ ì¸ë¬¼, ì£¼ìš” ì†Œí’ˆ, ì‚¬ê±´ì„ ì¶”ì¶œí•˜ê³ , ìš”ì•½(scenario)ì„ ìƒì„±í•˜ë„ë¡ í•¨\\n\\n"},
  {"name":"librivox-tracks","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\\nChanges:\\n\\nUsed archive.org metadata API to annotate rows with \\\"duration\\\" column\\n\\n"},
  {"name":"allist","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/gegeta/allist","creator_name":"ge","creator_url":"https://huggingface.co/gegeta","description":"gegeta/allist dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"multimuc4","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jgermanmx/multimuc4","creator_name":"Jesus German Ortiz Barajas","creator_url":"https://huggingface.co/jgermanmx","description":"jgermanmx/multimuc4 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"naver_review_sum","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jr-d-analyst24/naver_review_sum","creator_name":"dayoungyoun","creator_url":"https://huggingface.co/jr-d-analyst24","description":"jr-d-analyst24/naver_review_sum dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"bccard-maywell-jojo0217-markai-lcw99-kendamarron-microsoft","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sh2orc/bccard-maywell-jojo0217-markai-lcw99-kendamarron-microsoft","creator_name":"Taeyoung Lee","creator_url":"https://huggingface.co/sh2orc","description":"[Dataset merged]\\n\\nmaywell/ko_wikidata_QA\\njojo0217/korean_rlhf_dataset\\nBCCard/BCCard-Finance-Kor-QnA\\nMarkrAI/KoCommercial-Dataset\\nlcw99/wikipedia-korean-20240501-1million-qna\\nmaywell/gpt4_evol_1.3k\\nKendamarron/jimba-wiki-instruction-calm3\\nmicrosoft/orca-math-word-problems-200k\\npankajmathur/WizardLM_Orca\\n\\n"},
  {"name":"muri-it-language-split","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split."},
  {"name":"korean-judgment-easyread-transform","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Suchae/korean-judgment-easyread-transform","creator_name":"Jeong Suchae","creator_url":"https://huggingface.co/Suchae","description":"Suchae/korean-judgment-easyread-transform dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Exemplary_QA","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/100suping/Exemplary_QA","creator_name":"100suping","creator_url":"https://huggingface.co/100suping","description":"100suping/Exemplary_QA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"FinShibainu","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/aiqwe/FinShibainu","creator_name":"Jay Lee","creator_url":"https://huggingface.co/aiqwe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFinShibainu Datset Card\\n\\t\\n\\n\\ngithub: https://github.com/aiqwe/FinShibainu\\nmodel: https://huggingface.co/aiqwe/FinShibainu\\n\\nKRX LLM ê²½ì§„ëŒ€íšŒ ë¦¬ë”ë³´ë“œì—ì„œ ìš°ìˆ˜ìƒì„ ìˆ˜ìƒí•œ shibainu24 ëª¨ë¸ì˜ ë°ì´í„°ì…‹ Repositoryì…ë‹ˆë‹¤.ëª¨ë¸ì— ëŒ€í•œ ë‚´ìš©ì€ https://huggingface.co/aiqwe/FinShibainuë¥¼ ì°¸ì¡°í•´ì£¼ì„¸ìš”.ë°ì´í„°ì…‹ ìˆ˜ì§‘ ë° í•™ìŠµì— ê´€ë ¨ëœ ì½”ë“œëŠ” https://github.com/aiqwe/FinShibainuì— ìì„¸í•˜ê²Œ ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDPO\\n\\t\\n\\nPreferenceì˜ AëŠ” answer_A, BëŠ” answer_B ì»¬ëŸ¼ì…ë‹ˆë‹¤.\\n\\nanswer_A: Referenceì™€ ì§ˆë¬¸ì„ í•¨ê»˜ ì œê³µë°›ì€ gpt ë‹µë³€. Referenceì— ì˜ì¡´ì ì´ê³  ì§§ì§€ë§Œ ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•¨\\nanswer_B: Referenceì—†ì´ ì§ˆë¬¸ë§Œâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aiqwe/FinShibainu."},
  {"name":"Kor-financial-qa-7K","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/coorung/Kor-financial-qa-7K","creator_name":"Ungjin Jang","creator_url":"https://huggingface.co/coorung","description":"coorung/Kor-financial-qa-7K dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"zeroth-STT-Ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/o0dimplz0o/zeroth-STT-Ko","creator_name":"Michele Phan","creator_url":"https://huggingface.co/o0dimplz0o","description":"\\n\\t\\n\\t\\t\\n\\t\\tZeroth-STT-Ko Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset combines the following publicly available Korean language datasets:\\nJunhoee/STT_Korean_Dataset_80000\\nand\\nZeroth-Korean Dataset (from Project: Zeroth, by GoodAtlas and Gridspace)\\nThis provides over 102K rows of data (sentences) in total.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\nZeroth-Korean Dataset, created by [Lucas Jo(@Atlas Guide Inc.) and Wonkyum Lee(@Gridspace Inc.)], 2023.\\nAvailable at https://github.com/goodatlas/zeroth under CC-BY-4.0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/o0dimplz0o/zeroth-STT-Ko."},
  {"name":"LAION-art-EN-improved-captions-translate","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/jaeyong2/LAION-art-EN-improved-captions-translate","creator_name":"jeongjaeyong","creator_url":"https://huggingface.co/jaeyong2","description":"\\n\\t\\n\\t\\t\\n\\t\\tDevelopment Process\\n\\t\\n\\n\\nsource dataset from recastai/LAION-art-EN-improved-captions\\nWe used Qwen/Qwen2-72B-Instruct model to translate.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLicense\\n\\t\\n\\n\\nQwen/Qwen2.5-72B-Instruct : https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/LICENSE\\nrecastai/LAION-art-EN-improved-captions : https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/cc-by-4.0.md\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgement\\n\\t\\n\\nThis research is supported by TPU Research Cloud program.\\n"},
  {"name":"KoMultiText","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Dasool/KoMultiText","creator_name":"DasolChoi","creator_url":"https://huggingface.co/Dasool","description":"\\n\\t\\n\\t\\t\\n\\t\\tKoMultiText: Korean Multi-task Dataset for Classifying Biased Speech\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKoMultiText is a comprehensive Korean multi-task text dataset designed for classifying biased and harmful speech in online platforms. The dataset focuses on tasks such as Preference Detection, Profanity Identification, and Bias Classification across multiple domains, enabling state-of-the-art language models to perform multi-task learning for socially responsible AI applications.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Dasool/KoMultiText."},
  {"name":"HRM8K_KSM","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/heegyu/HRM8K_KSM","creator_name":"Heegyu Kim","creator_url":"https://huggingface.co/heegyu","description":"\\nOriginal Dataset: HAERAE-HUB/HRM8K\\ní‰ê°€ë¥¼ ìœ„í•´ KSM subsetë§Œ ê°€ì ¸ì™€ì„œ ë¶„ë¦¬í–ˆìŒ.\\n\\n"},
  {"name":"GammaCorpus-Polylingo-50k","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","description":"\\n\\t\\n\\t\\t\\n\\t\\tGammaCorpus Polylingo 50k\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is it?\\n\\t\\n\\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\\n\\nInput: A user prompt or question.\\nOutput: A response generated by an AI assistant.\\nLanguage: The language used in the interaction.\\n\\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k."},
  {"name":"investment_analysis","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/MLOpsEngineer/investment_analysis","creator_name":"Peter Song","creator_url":"https://huggingface.co/MLOpsEngineer","description":"\\n\\t\\n\\t\\t\\n\\t\\tì½”ìŠ¤í”¼ ìƒì¥ ê¸°ì—… ê³µì‹œì •ë³´ ê¸°ë°˜ íˆ¬ì ë¦¬í¬íŠ¸ ë°ì´í„°ì…‹\\n\\t\\n\\nì´ ë°ì´í„°ì…‹ì€ êµ­ë‚´ ì½”ìŠ¤í”¼ ìƒì¥ ê¸°ì—…ì˜ ê³µì‹œì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, íˆ¬ì ì „ë¬¸ê°€ë“¤ì´ í™œìš©í•  ìˆ˜ ìˆëŠ” ì‹¬ì¸µì  ë¶„ì„ê³¼ íˆ¬ì ì „ëµ ì œì•ˆì„ ëª©í‘œë¡œ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ì´ ë°ì´í„°ì…‹ì€ GPT íŒŒì¸íŠœë‹ì— ìµœì í™”ëœ êµ¬ì¡°ë¡œ ì„¤ê³„ë˜ì–´ ìˆì–´, ë‹¤ì–‘í•œ ì—­í• (role)ì„ í¬í•¨í•œ ë©”ì‹œì§€ ê¸°ë°˜ì˜ ëŒ€í™” í˜•ì‹ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\\n\\n\\t\\n\\t\\t\\n\\t\\të°ì´í„°ì…‹ êµ¬ì¡°\\n\\t\\n\\në°ì´í„°ì…‹ì€ JSONL í¬ë§·ìœ¼ë¡œ ì œê³µë˜ë©°, ê° í•­ëª©ì€ GPT íŒŒì¸íŠœë‹ì— ìµœì í™”ëœ ë©”ì‹œì§€ í˜•ì‹ì„ ë”°ë¦…ë‹ˆë‹¤. ì£¼ìš” êµ¬ì„±ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\\n\\nmessages: ë©”ì‹œì§€ ë°°ì—´ í˜•íƒœë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ê° ë©”ì‹œì§€ëŠ” ì•„ë˜ì™€ ê°™ì€ ì—­í• ì„ ê°€ì§‘ë‹ˆë‹¤.\\nsystem: ëª¨ë¸ì˜ ì—­í• ê³¼ í–‰ë™ ì§€ì¹¨ì„ ì •ì˜í•©ë‹ˆë‹¤.ì˜ˆì‹œ: \\\"ë‹¹ì‹ ì€ ê¸°ì—… ì¬ë¬´ ë° íˆ¬ì ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì°¸ê³  ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ë…¼ë¦¬ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\\\"\\nuser: ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ì»¨í…ìŠ¤íŠ¸(ì˜ˆì‹œ ë°ì´í„°, ì¬ë¬´ì œí‘œâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MLOpsEngineer/investment_analysis."},
  {"name":"twice_dart_company2industry_clustering","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nmixx-fin/twice_dart_company2industry_clustering","creator_name":"nmixx-financial-nlp-lab","creator_url":"https://huggingface.co/nmixx-fin","description":"\\n\\t\\n\\t\\t\\n\\t\\tDARTCompany2Industry-Clustering-ko\\n\\t\\n\\n\\nConstructed an industry clustering dataset based on the summary sentences of the DART business reports.\\nTo ensure consistency with FinanceMTEB/WikiCompany2Industry-en, the industry labels were limited to five categories ({'Finance & Insurance', 'Wholesale & Retail', 'Professional, Scientific & Technical Services', 'Information & Communication', 'Manufacturing'}).\\nThe dataset will be expanded using existing DART raw data.\\n\\n"},
  {"name":"wikipedia_qa","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/blueapple8259/wikipedia_qa","creator_name":"blueapple825","creator_url":"https://huggingface.co/blueapple8259","description":"wikipedia ë°ì´í„°ë¥¼ qaí˜•ì‹ìœ¼ë¡œ ê°€ê³µí•œ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\\nì–¸ì–´ëª¨ë¸ ì—†ì´ ì½”ë“œë¡œë§Œ ê°€ê³µí•˜ëŠ” ê²ƒì´ ëª©í‘œì´ë©° ìƒˆë¡œìš´ ê°€ê³µ ì•„ì´ë””ì–´ê°€ ë– ì˜¤ë¥¼ ì‹œ ìƒˆ ë²„ì „ìœ¼ë¡œ ì—…ë¡œë“œ í•˜ê² ìŠµë‹ˆë‹¤.\\n"},
  {"name":"parallel_corpus_game_2024","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bot-yaya/parallel_corpus_game_2024","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","description":"https://github.com/mnbvc-parallel-corpus-team/parallel_corpus_mnbvc\\nMNBVCå¹³è¡Œè¯­æ–™å°ç»„ï¼šæ¸¸æˆè¯­æ–™\\nä¸å®šæœŸæ›´æ–°ï¼Œç›®å‰å·²æ”¶å½•çš„æ¸¸æˆè¯­æ–™æ–‡ä»¶ï¼Œå…±29ä»½ï¼š\\n\\nåšå¾·ä¹‹é—¨3\\nèµ›åšæœ‹å…‹2077\\né»‘æš—ä¹‹é­‚3\\nåº•ç‰¹å¾‹ï¼šåŒ–èº«ä¸ºäºº\\né¥¥è’\\nè‰¾å°”ç™»æ³•ç¯\\nåŸç¥\\né»‘å¸æ–¯\\néœæ ¼æ²ƒå…¹ä¹‹é—\\nIb\\nå¦‚é¾™8\\nå¦‚é¾™7å¤–ä¼ \\nè’é‡å¤§é•–å®¢2\\nåªç‹¼ï¼šå½±é€äºŒåº¦\\næ–‡æ˜6\\næ€æˆ®å°–å¡”\\nå´©åæ˜Ÿç©¹é“é“\\nç¾¤æ˜Ÿ\\næ³°æ‹‰ç‘äºš\\nå·«å¸ˆ3\\né­”å¥³ä¹‹æ³‰3\\né­”å¥³ä¹‹æ³‰R\\né¸£æ½®\\nå¦‚é¾™3\\nå¦‚é¾™4\\nå¦‚é¾™5\\nå¦‚é¾™6\\nå¦‚é¾™æ2\\nå¦‚é¾™7\\n\\n"},
  {"name":"argilla-distilabel-math-preference-dpo-korean","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ChuGyouk/argilla-distilabel-math-preference-dpo-korean","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\nThis is a gpt-4o-2024-08-06 Korean translated-version of argilla/distilabel-math-preference-dpo. \\nI used OpenAI BATCH API with prompt below, temperature=0.0, max_tokens=4000, seed=0. Total cost was 11.71$.\\nNote that for the 1317th data, because it did not satisfy the format given in the instruction, I modified it. (For example, for  mark, even this was translated as <ì˜ë¬¸>.)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompt\\n\\t\\n\\n\\nYou are tasked with translating English text into Korean forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/argilla-distilabel-math-preference-dpo-korean."},
  {"name":"X-ALMA-Preference","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\\nsource: the source sentence.\\nchosen: the preferred translation.\\nreject: the dis-preferred translation.\\ndirections: the translation direction.\\n@misc{xu2024xalmaplugplay,\\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \\n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\\n      year={2024},\\n      eprint={2410.03115}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference."},
  {"name":"question-complexity","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rokokot/question-complexity","creator_name":"Robin Kokot","creator_url":"https://huggingface.co/rokokot","description":"\\n\\t\\n\\t\\t\\n\\t\\tQuestion Type and Complexity (QTC) Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThe Question Type and Complexity (QTC) dataset is a comprehensive resource for linguistics/NLP research focusing on question classification and linguistic complexity analysis across multiple languages. It contains questions from two distinct sources (TyDi QA and Universal Dependencies v2.15), automatically annotated with question types (polar/content) and a set of linguistic complexity features.\\nKey Features:\\n\\n2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rokokot/question-complexity."},
  {"name":"korean_chat_friendly","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/JaeJiMin/korean_chat_friendly","creator_name":"JaeJi","creator_url":"https://huggingface.co/JaeJiMin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKorean Chat Friendly Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Korean Chat Friendly dataset is a curated combination of two publicly available datasets:\\n\\nKorean Safe Conversation\\nMental Health Counseling Conversations\\n\\nThis dataset was created by translating and summarizing the original conversations and then modifying the tone to resemble friendly conversations between friends. It is ideal for applications related to conversational AI, natural language understanding, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JaeJiMin/korean_chat_friendly."},
  {"name":"korean_chat_friendly","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/JaeJiMin/korean_chat_friendly","creator_name":"JaeJi","creator_url":"https://huggingface.co/JaeJiMin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKorean Chat Friendly Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Korean Chat Friendly dataset is a curated combination of two publicly available datasets:\\n\\nKorean Safe Conversation\\nMental Health Counseling Conversations\\n\\nThis dataset was created by translating and summarizing the original conversations and then modifying the tone to resemble friendly conversations between friends. It is ideal for applications related to conversational AI, natural language understanding, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JaeJiMin/korean_chat_friendly."},
  {"name":"kurage_training_data","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lightblue/kurage_training_data","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"lightblue/kurage_training_data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"PangeaBench-xchat","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/neulab/PangeaBench-xchat","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"neulab/PangeaBench-xchat dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"PangeaBench-tydiqa","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/neulab/PangeaBench-tydiqa","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tydiqa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\\nin the world. It contains language phenomena that would not be foundâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-tydiqa."},
  {"name":"mc-translation","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/efederici/mc-translation","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","description":"This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy This Dataset?\\n\\t\\n\\nTranslation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specializedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation."},
  {"name":"OSCAR-ko-cleaned","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/blueapple8259/OSCAR-ko-cleaned","creator_name":"blueapple825","creator_url":"https://huggingface.co/blueapple8259","description":"Warning: No filtering related to safety has been applied. There is a high possibility that inappropriate content may be included in the data, so please be cautious.\\nOriginal: OSCAR-2301\\n8gb\\n5m\\n"},
  {"name":"global-festivals-translated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/azminetoushikwasi/global-festivals-translated","creator_name":"Azmine Toushik Wasi","creator_url":"https://huggingface.co/azminetoushikwasi","description":"azminetoushikwasi/global-festivals-translated dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Lappland","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/None1145/Lappland","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Lappland dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"TranslationTraining","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SugoiLoki/TranslationTraining","creator_name":"Jade Ethan Terblanche","creator_url":"https://huggingface.co/SugoiLoki","description":"SugoiLoki/TranslationTraining dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"wikipedia_raw_ko","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/blueapple8259/wikipedia_raw_ko","creator_name":"blueapple825","creator_url":"https://huggingface.co/blueapple8259","description":"ìœ„í‚¤í”¼ë””ì•„ 20241201 ë¤í”„ë¥¼ ì•„ë¬´ëŸ° ê°€ê³µë„ ì•ˆ í•œ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤. ê°€ê³µ í•˜ë‚˜ë„ ì•ˆ í•œ ì›ë³¸ ë¤í”„ ì—†ê¸¸ë˜ ì˜¬ë ¸ìŠµë‹ˆë‹¤. ê°€ê³µ ì•ˆ ëœ ë°ì´í„°ëŠ” í•„ìš”í•œë° xml íŒŒì‹±í•˜ëŠ” ì½”ë“œ ì‘ì„±ì€ ê·€ì°®ê±°ë‚˜ ê·¸ëƒ¥ í•  ì¤„ ëª°ë¼ì„œ ëª» í•˜ì‹œëŠ” ë¶„ë“¤ ìˆìœ¼ë©´ ê°€ì ¸ë‹¤ ì“°ì„¸ìš”.\\n"},
  {"name":"shp_translations","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/david9dragon9/shp_translations","creator_name":"David Wu","creator_url":"https://huggingface.co/david9dragon9","description":"This dataset contains translations of three splits (askscience, explainlikeimfive, legaladvice) of the Stanford Human Preference (SHP) dataset, used for training domain-invariant reward models.\\nThe translation was conducted using the No Language Left Behind (NLLB) 3.3 B 200 model.\\nReferences:\\nStanford Human Preference Dataset: https://huggingface.co/datasets/stanfordnlp/SHP\\nNLLB: https://huggingface.co/facebook/nllb-200-3.3B\\n"},
  {"name":"advbench_behaviors_m5","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lenML/advbench_behaviors_m5","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout advbench_behaviors_m5\\n\\t\\n\\næ­¤æ•°æ®é›†ä¸º advbench_behaviors.csv æ–‡ä»¶çš„å¤šè¯­è¨€ç¿»è¯‘ç‰ˆæœ¬ã€‚ä¸€ä¸ªå¸¸è§çš„ä»»åŠ¡æ˜¯ç”¨äº abliterator è„šæœ¬ã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AdvBench\\n\\t\\n\\nPaper: Universal and Transferable Adversarial Attacks on Aligned Language Models\\nData: AdvBench Dataset\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout\\n\\t\\n\\nAdvBench is a set of 500 harmful behaviors formulated as instructions. These behaviors\\nrange over the same themes as the harmful strings setting, but the adversaryâ€™s goal\\nis instead to find a single attack string thatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lenML/advbench_behaviors_m5."},
  {"name":"Rosmontis","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/None1145/Rosmontis","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Rosmontis dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"wiktionary-data","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/paion-data/wiktionary-data","creator_name":"Paion Data","creator_url":"https://huggingface.co/paion-data","description":"\\n\\t\\n\\t\\t\\n\\t\\tWiktionary Data on Hugging Face Datasets\\n\\t\\n\\n\\n\\n\\n\\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\\nsupports the following languages:\\n\\nDeutsch - German\\nLatinum - Latin\\ná¼™Î»Î»Î·Î½Î¹ÎºÎ® - Ancient Greek\\ní•œêµ­ì–´ - Korean\\nğ ğ¼ğ¹- Old Persian\\nğ’€ğ’…—ğ’ºğ’Œ‘(ğ’Œ) - Akkadian\\nElamite\\nà¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤®à¥ - Sanskrit, or Classical Sanskrit\\n\\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paion-data/wiktionary-data."},
  {"name":"wiktionary-data","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/paion-data/wiktionary-data","creator_name":"Paion Data","creator_url":"https://huggingface.co/paion-data","description":"\\n\\t\\n\\t\\t\\n\\t\\tWiktionary Data on Hugging Face Datasets\\n\\t\\n\\n\\n\\n\\n\\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\\nsupports the following languages:\\n\\nDeutsch - German\\nLatinum - Latin\\ná¼™Î»Î»Î·Î½Î¹ÎºÎ® - Ancient Greek\\ní•œêµ­ì–´ - Korean\\nğ ğ¼ğ¹- Old Persian\\nğ’€ğ’…—ğ’ºğ’Œ‘(ğ’Œ) - Akkadian\\nElamite\\nà¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤®à¥ - Sanskrit, or Classical Sanskrit\\n\\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paion-data/wiktionary-data."},
  {"name":"wikipedia_title_classification","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/blueapple8259/wikipedia_title_classification","creator_name":"blueapple825","creator_url":"https://huggingface.co/blueapple8259","description":"ìœ„í‚¤í”¼ë””ì•„ ë¬¸ì„œë¥¼ 19ê°œì˜ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•œ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤. ë°ì´í„°ì—ëŠ” ì¹´í…Œê³ ë¦¬ì™€ ì œëª©ë§Œ ìˆìŠµë‹ˆë‹¤.\\ntype1ê³¼ type2 ì „ë¶€ json í˜•ì‹ì´ë©° type1ì€ keyê°’ì´ ì œëª©, valueê°’ì´ ì¹´í…Œê³ ë¦¬ì´ë©° type2ëŠ” keyê°’ì´ ì¹´í…Œê³ ë¦¬, valueê°’ì´ ì œëª©ì…ë‹ˆë‹¤. ë¬¸ì„œ í•˜ë‚˜ê°€ ì—¬ëŸ¬ ê°œì˜ ì¹´í…Œê³ ë¦¬ì— ì†í•´ìˆëŠ” ê²½ìš°ë„ ìˆìŠµë‹ˆë‹¤.\\në¶„ë¥˜ ê¸°ì¤€ì€ classification.csvë¥¼ ì°¸ê³ í•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤. ì¹´í…Œê³ ë¦¬ ê²°ì • ê¸°ì¤€ì€ signatureê°€ ë¬¸ì„œì— í¬í•¨ë˜ì–´ ìˆëŠ”ê°€ì´ë©° ë¬¸ì„œëŠ” ê³µë°±ê³¼ ì•ŒíŒŒë²³ì´ ì†Œë¬¸ìë¡œ ë³€í™˜ëœ ì±„ ë¹„êµë˜ê²Œ ë©ë‹ˆë‹¤.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tì¹´í…Œê³ ë¦¬ ì¢…ë¥˜\\n\\t\\n\\n\\nhuman: ì¸ê°„\\n\\nbusiness_person: ê¸°ì—…ì¸\\n\\npresident: ëŒ€í†µë ¹\\n\\nfood: ìŒì‹\\n\\ncreature: ìƒëª…ì²´\\n\\nanimal: ë™ë¬¼\\n\\nplant: ì‹ë¬¼\\n\\nbook: ì±…\\n\\nmovie: ì˜í™”\\n\\nvideo_game: ê²Œì„\\n\\nmusic: ìŒì•…\\n\\nbuilding: ê±´ë¬¼\\n\\nruins: ìœ ì \\n\\ncompany:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/blueapple8259/wikipedia_title_classification."},
  {"name":"kor-insu-qaset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/choeeiden/kor-insu-qaset","creator_name":"choe","creator_url":"https://huggingface.co/choeeiden","description":"choeeiden/kor-insu-qaset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"mmmlu_lite","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMLU-Lite\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is aboutâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite."},
  {"name":"text-moderation-02-multilingual","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ifmain/text-moderation-02-multilingual","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","description":"This dataset is based on Kaggle.It represents a version of @ifmain/text-moderation-410K that has been cleansed of semantically similar values and normalized to a 50/50 ratio of negative and neutral entries.\\nThe dataset contains 1.5M entries (91K * 17 languages).  \\nBefore use, augmentation is recommended! (e.g., character substitution to bypass moderation).\\nFor augmentation, you can use @ifmain/StringAugmentor.  \\nEnjoy using it!\\n"},
  {"name":"Multilingal-sakalt-data","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚mitãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ã™ã€‚\\n"},
  {"name":"SkunkworksAI-reasoning-0.01-ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/youjunhyeok/SkunkworksAI-reasoning-0.01-ko","creator_name":"ìœ ì¤€í˜","creator_url":"https://huggingface.co/youjunhyeok","description":"SkunkworksAI/reasoning-0.01 ë°ì´í„°ì…‹ì„ nayohan/llama3-instrucTrans-enko-8b ëª¨ë¸ì„ ì‚¬ìš©í•´ ë²ˆì—­í–ˆìŠµë‹ˆë‹¤.\\nThanks for SkunkworksAI and nayohan.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tì›ë³¸\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\treasoning-0.01 subset\\n\\t\\n\\nsynthetic dataset of reasoning chains for a wide variety of tasks.\\nwe leverage data like this across multiple reasoning experiments/projects.\\nstay tuned for reasoning models and more data.\\nThanks to Hive Digital Technologies (https://x.com/HIVEDigitalTech) for their compute support in this project and beyond.\\n"},
  {"name":"SkunkworksAI-reasoning-0.01-ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/youjunhyeok/SkunkworksAI-reasoning-0.01-ko","creator_name":"ìœ ì¤€í˜","creator_url":"https://huggingface.co/youjunhyeok","description":"SkunkworksAI/reasoning-0.01 ë°ì´í„°ì…‹ì„ nayohan/llama3-instrucTrans-enko-8b ëª¨ë¸ì„ ì‚¬ìš©í•´ ë²ˆì—­í–ˆìŠµë‹ˆë‹¤.\\nThanks for SkunkworksAI and nayohan.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tì›ë³¸\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\treasoning-0.01 subset\\n\\t\\n\\nsynthetic dataset of reasoning chains for a wide variety of tasks.\\nwe leverage data like this across multiple reasoning experiments/projects.\\nstay tuned for reasoning models and more data.\\nThanks to Hive Digital Technologies (https://x.com/HIVEDigitalTech) for their compute support in this project and beyond.\\n"},
  {"name":"AyaVisionBench","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/AyaVisionBench","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Aya Vision Benchmark\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \\nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/AyaVisionBench."},
  {"name":"oasst1","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1."},
  {"name":"Everything_Instruct_Multilingual","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEverything Instruct (Multilingual Edition)\\n\\t\\n\\nEverything you need... all in one place ğŸ’˜\\n\\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\\nNote2: This version of the dataset supports the following languages:\\n\\nEnglish\\nRussianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual."},
  {"name":"oasst2","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen Assistant Conversations Dataset Release 2 (OASST2)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \\nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \\nAll messages have a role property: this can either be \\\"assistant\\\" or \\\"prompter\\\". The roles in \\nconversation threads from prompt to leaf node strictly alternate between \\\"prompter\\\" andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2."},
  {"name":"Open-R1-Ko-SFT-v2.0","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/OLAIR/Open-R1-Ko-SFT-v2.0","creator_name":"OLA-AI-Research","creator_url":"https://huggingface.co/OLAIR","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-R1-Ko-SFT-v2.0\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nOLAIR/Open-R1-Ko-SFT-v2.0 is a dataset composed of translated prompt-response pairs originally generated by DeepSeek R1. The source data comprises multiple datasets containing original prompts and responses, which were subsequently translated into Korean using GPT-4o. This dataset is intended for fine-tuning and training language models, specifically for the development of ko-r1-7b-v2.0.3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSources\\n\\t\\n\\nThe original data isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OLAIR/Open-R1-Ko-SFT-v2.0."},
  {"name":"zeroth-korean","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Bingsu/zeroth-korean","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZeroth-Korean\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZeroth-Korean\\n\\t\\n\\nThe data set contains transcriebed audio data for Korean. There are 51.6 hours transcribed Korean audio for training data (22,263 utterances, 105 people, 3000 sentences) and 1.2 hours transcribed Korean audio for testing data (457 utterances, 10 people). This corpus also contains pre-trained/designed language model, lexicon and morpheme-based segmenter(morfessor).\\nZeroth project introduces free Korean speech corpus and aims to makeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/zeroth-korean."},
  {"name":"Global-MMLU","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU ğŸŒ is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) ğŸ—½ or Culturally Agnostic (CA) âš–ï¸. These annotations were collected as part of an openâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU."},
  {"name":"ko-arena-hard-auto-v0.1","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/qwopqwop/ko-arena-hard-auto-v0.1","creator_name":"Junjae Lee","creator_url":"https://huggingface.co/qwopqwop","description":"arena-hard-auto-v0.1 ë¥¼ GPT-4oì™€ o1ì„ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ê³  ìˆ˜ì‘ì—…ìœ¼ë¡œ ê²€ìˆ˜í•œ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\\nì˜¤ì—­ì´ë‚˜ ì˜ì—­ ë˜ëŠ” ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜¹ì‹œ ì´ì„ ë°œê²¬í•˜ì‹ ë‹¤ë©´ issueë¥¼ ì œê¸°í•˜ê±°ë‚˜ ì´ë¥¼ ìˆ˜ì •í•œ prë¥¼ ë§Œë“¤ì–´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\\n# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\\n\\\"\\\"<|User Prompt|>\\\\n{question_1}\\\\n\\\\n<|The Start of Assistant A's Answer|>\\\\n{answer_1}\\\\n<|The End of Assistant A's Answer|>\\\\n\\\\n<|The Start of Assistant B's Answer|>\\\\n{answer_2}\\\\n<|The End of Assistant B's Answer|>\\\"\\\"\\n\\n# ë²ˆì—­ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\\n\\\"\\\"<|ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸|>\\\\n{question_1}\\\\n\\\\n<|ì–´ì‹œìŠ¤í„´íŠ¸ Aì˜ ë‹µë³€ ì‹œì‘|>\\\\n{answer_1}\\\\n<|ì–´ì‹œìŠ¤í„´íŠ¸ Aì˜ ë‹µë³€ ë|>\\\\n\\\\n<|ì–´ì‹œìŠ¤í„´íŠ¸ Bì˜ ë‹µë³€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/qwopqwop/ko-arena-hard-auto-v0.1."},
  {"name":"HRM8K","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/HAERAE-HUB/HRM8K","creator_name":"HAE-RAE","creator_url":"https://huggingface.co/HAERAE-HUB","description":"\\n\\n| ğŸ“– Paper | ğŸ“ Blog | ğŸ–¥ï¸ Code(Coming soon!) |\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tHRM8K\\n\\t\\n\\nWe introduce HAE-RAE Math 8K (HRM8K), a bilingual math reasoning benchmark for Korean and English.\\nHRM8K comprises 8,011 instances for evaluation, sourced through a combination of translations from established English benchmarks (e.g., GSM8K, MATH, OmniMath, MMMLU) and original problems curated from existing Korean math exams.\\n\\n\\t\\n\\t\\t\\n\\t\\tBenchmark Overview\\n\\t\\n\\nThe HRM8K benchmark consists of two subsets:\\n\\nKorean School Math (KSM):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HAERAE-HUB/HRM8K."},
  {"name":"PubMedVision-EnKo","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ChuGyouk/PubMedVision-EnKo","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\\n\\t\\n\\t\\t\\n\\t\\tInformations\\n\\t\\n\\n\\nThis is the Korean translation of FreedomIntelligence/PubMedVision. The translation was primarily generated using the 'solar-pro-241126' model, with occasional manual assistance from the 'Gemini 2.0 Flash Experimental' model and the 'Gemini experimental 1206' model.\\nAn evaluation of the translation quality (\\\"llm-as-a-judge\\\") will be coming soon.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNews\\n\\t\\n\\n\\n[2024/07/01]: We add annotations for 'body_part' and 'modality' of images, utilizing theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/PubMedVision-EnKo."},
  {"name":"korean-cipher","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/jsm0424/korean-cipher","creator_name":"Sungmin Jo","creator_url":"https://huggingface.co/jsm0424","description":"\\n\\t\\n\\t\\t\\n\\t\\tKorean-Cipher Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset was inspired by OpenAI's video, \\\"Korean Cipher with OpenAI o1\\\".It is designed to evaluate the reasoning abilities of large language models (LLMs) in understanding and reconstructing distorted Korean text.  \\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nEach sample in the dataset consists of the following fields:  \\n\\nid: A unique identifier for each sentence pair.  \\nmessage: The original Korean sentence.  \\nciphertext: The distorted version of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jsm0424/korean-cipher."},
  {"name":"reasoning-multilingual-R1-Llama-70B-train","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\tlightblue/reasoning-multilingual-R1-Llama-70B-train\\n\\t\\n\\nThis is a multilingual reasoning dataset covering more than 30 languages.\\nThis dataset was made by:\\n\\nSampling prompts from English datasets and translating them to various languages\\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\\n\\nThis dataset was then used to train a multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train."},
  {"name":"wmt24pp","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tWMT24++\\n\\t\\n\\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\\nthe publication\\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\\nIf you are interested in the images of the source URLs for each document, please see here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema\\n\\t\\n\\nEach language pair is stored in its own jsonl file.\\nEach row isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp."},
  {"name":"s1K-1.1-Korean","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/exp-models/s1K-1.1-Korean","creator_name":"Experimental Models","creator_url":"https://huggingface.co/exp-models","description":"https://huggingface.co/datasets/simplescaling/s1K-1.1\\n"},
  {"name":"s1k-1.1-Ko-ReGenerated-Formatted","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/werty1248/s1k-1.1-Ko-ReGenerated-Formatted","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","description":"\\n\\nsimplescaling/s1K-1.1 ì—ì„œ question ë°ì´í„°ë§Œ GPT-4oë¥¼ ì´ìš©í•˜ì—¬ ë²ˆì—­\\n\\n\\në‹¨, crossword í¼ì¦ì€ ì œì™¸ (ë²ˆì—­ ë¶ˆê°€)\\n\\n\\nDeepseek-R1 (fp8, Provider: fireworks.ai)ì„ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ë¡œ ì¶”ë¡  ë° ë‹µí•˜ê²Œ í•¨ (3ì°¨ ì •ì œ ì‹œì ì—ëŠ” bf16? Provider: FriendliAI ì‚¬ìš©)\\n1ì°¨ ì •ì œ\\n\\n\\nì›ë³¸ ë°ì´í„°ì—ì„œ, geminiì˜ ì¶œë ¥, r1ì˜ ì¶œë ¥, solution ì¤‘ ë‘ ê°œì˜ ë‹µì´ ì¼ì¹˜í•˜ë©´ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µì´ë¼ê³  ì •ì˜\\ní•œêµ­ì–´ R1 ë‹µë³€ ê²°ê³¼ê°€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µê³¼ ë‹¤ë¥´ê±°ë‚˜, ë‹µë³€ì´ ì”¹íŒ ê²½ìš°, ì„œì‹ì´ í‹€ë¦° ê²½ìš° ì´ 123ê°œì— ëŒ€í•´ ì¶”ë¡  ë° ë‹µë³€ ì¬ìƒì„±\\n\\n\\n2ì°¨ ì •ì œ\\n\\n\\n1ì°¨ì™€ ë™ì¼í•œ í”„ë¡œì„¸ìŠ¤, 63ê°œ ë°ì´í„° ì¬ìƒì„±\\n\\n\\n3ì°¨ ì •ì œ\\nì¶”ë¡  ê³¼ì •ì—ì„œ í•œìê°€ ì¶œë ¥ëœ 7ê°œ ë°ì´í„° ì¬ìƒì„± (ëŒ€ë¶€ë¶„ ì¶”ë¡  ì¤‘ ë¶•ê´´ë¡œ ì¸í•œ í•œì ì¶œë ¥)\\n1ê°œ ë°ì´í„°ëŠ” 7ë²ˆì˜ ì¬ì‹œë„ í›„ì—ë„ ê³„ì† í•œìê°€ í¬í•¨ë˜ì—ˆìœ¼ë¯€ë¡œ, ë¶ˆê°€í”¼í•˜ê²Œ í•™ìŠµ ë°ì´í„°ì—ì„œâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/werty1248/s1k-1.1-Ko-ReGenerated-Formatted."},
  {"name":"thinking-multilingual-30-23-small-690","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \\nOr use the \\\"big\\\" version: big 10k rows version\\n"},
  {"name":"klue","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/klue/klue","creator_name":"KLUE Benchmark","creator_url":"https://huggingface.co/klue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KLUE\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKLUE is a collection of 8 tasks to evaluate natural language understanding capability of Korean language models. We delibrately select the 8 tasks, which are Topic Classification, Semantic Textual Similarity, Natural Language Inference, Named Entity Recognition, Relation Extraction, Dependency Parsing, Machine Reading Comprehension, and Dialogue State Tracking.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nTopicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/klue/klue."},
  {"name":"mqa","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages."},
  {"name":"kobest_v1","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/skt/kobest_v1","creator_name":"SK Telecom","creator_url":"https://huggingface.co/skt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KoBEST\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKoBEST is a Korean benchmark suite consists of 5 natural language understanding tasks that requires advanced knowledge in Korean.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nBoolean Question Answering, Choice of Plausible Alternatives, Words-in-Context, HellaSwag, Sentiment Negation Recognition\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nko-KR\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKB-BoolQ\\n\\t\\n\\nAn exampleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/skt/kobest_v1."},
  {"name":"kote","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/searle-j/kote","creator_name":"Jeon Duyoung","creator_url":"https://huggingface.co/searle-j","description":"50k Korean online comments labeled for 44 emotion categories."},
  {"name":"naver-news-summarization-ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/daekeun-ml/naver-news-summarization-ko","creator_name":"Daekeun Kim","creator_url":"https://huggingface.co/daekeun-ml","description":"This dataset is a custom dataset created by the author by crawling Naver News (https://news.naver.com) for the Korean NLP model hands-on.\\n\\nPeriod: July 1, 2022 - July 10, 2022\\nSubject: IT, economics\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\\n        num_rows: 22194\\n    })\\n    test: Dataset({\\n        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\\n        num_rows: 2740\\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/daekeun-ml/naver-news-summarization-ko."},
  {"name":"kmhas_korean_hate_speech","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/jeanlee/kmhas_korean_hate_speech","creator_name":"Jean Lee","creator_url":"https://huggingface.co/jeanlee","description":"The K-MHaS (Korean Multi-label Hate Speech) dataset contains 109k utterances from Korean online news comments labeled with 8 fine-grained hate speech classes or Not Hate Speech class.\\nThe fine-grained hate speech classes are politics, origin, physical, age, gender, religion, race, and profanity and these categories are selected in order to reflect the social and historical context."},
  {"name":"laion-translated-to-en-korean-subset","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Bingsu/laion-translated-to-en-korean-subset","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlaion-translated-to-en-korean-subset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout dataset\\n\\t\\n\\na subset data of laion/laion2B-multi-joined-translated-to-en and laion/laion1B-nolang-joined-translated-to-en, including only korean\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLisence\\n\\t\\n\\nCC-BY-4.0\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instance\\n\\t\\n\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"Bingsu/laion-translated-to-en-korean-subset\\\")\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['hash', 'URL'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/laion-translated-to-en-korean-subset."},
  {"name":"kullm-v2","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nlpai-lab/kullm-v2","creator_name":"NLP & AI - Korea University","creator_url":"https://huggingface.co/nlpai-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"KULLM-v2\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKorean translation of GPT4ALL, Dolly, and Vicuna data.\\nrepository: nlpai-lab/KULLM\\nhuggingface: nlpai-lab/kullm-v2\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTranslate dataset\\n\\t\\n\\nTranslated 'instruction', 'input', and 'output' in the dataset via the DeepL API\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLisence\\n\\t\\n\\nApache-2.0\\n>>> from datasets import load_dataset\\n\\n>>> ds = load_dataset(\\\"nlpai-lab/kullm-v2\\\", split=\\\"train\\\")\\n>>> ds\\nDatasetDict({\\n    train: Dataset({\\n        features:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nlpai-lab/kullm-v2."},
  {"name":"sharegpt_gpt4","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/shibing624/sharegpt_gpt4","creator_name":"Ming Xu (å¾æ˜)","creator_url":"https://huggingface.co/shibing624","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nShareGPTä¸­æŒ‘é€‰å‡ºçš„GPT4å¤šè½®é—®ç­”æ•°æ®ï¼Œå¤šè¯­è¨€é—®ç­”ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\næ•°æ®é›†æ˜¯å¤šè¯­è¨€ï¼ŒåŒ…æ‹¬ä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ç­‰å¸¸ç”¨è¯­è¨€ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields are the same among all splits.\\n\\nconversations: a List of string .\\n\\nhead -n 1 sharegpt_gpt4.jsonl\\n\\n{\\\"conversations\\\":[\\n  {'from': 'human',\\n   'value': 'æ¡ç”¨å„ªé›…ç¾ä»£ä¸­æ–‡ï¼Œç”¨ä¸­æ–‡ç¹é«”å­—å‹ï¼Œå›ç­”ä»¥ä¸‹å•é¡Œã€‚ç‚ºæ‰€æœ‰æ¨™é¡Œæˆ–å°ˆç”¨å­—è©æä¾›å°æ‡‰çš„è‹±èªç¿»è­¯ï¼šUsing scholarly style, summarize in detail James Barr\\\\'s book \\\"Semantics of Biblicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shibing624/sharegpt_gpt4."},
  {"name":"korean_rlhf_dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jojo0217/korean_rlhf_dataset","creator_name":"mingyu jo","creator_url":"https://huggingface.co/jojo0217","description":"ì„±ê· ê´€ëŒ€í•™êµ ì‚°í•™í˜‘ë ¥í”„ë¡œì íŠ¸ ê³¼ì •ì—ì„œ í•œêµ­ì–´ llm ëª¨ë¸ SFT í•™ìŠµì„ ìœ„í•´ êµ¬ì¶•í•œ ë°ì´í„°ì…‹ ì…ë‹ˆë‹¤.2023-09-25ì˜¤í”ˆ ì–´ì‹œìŠ¤í„´íŠ¸ dataì—ì„œ ì˜¤í”ˆ ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ í¬í•¨í•˜ëŠ” ë°ì´í„° ì‚­ì œ-> ë‹µë³€ì— ì˜¤í”ˆ ì–´ì‹œìŠ¤í„´íŠ¸ë¼ê³  í•˜ëŠ” ê²½ìš°ê°€ ë‚˜ì˜¤ê¸° ë•Œë¬¸ë˜í•œ ìŠ¤íƒ í¬ë“œ ëŒ€í•™ ë²ˆì—­ ë°ì´í„°ì—ì„œ ë²ˆì—­ ê³¼ì • ì˜¤ë¥˜ë¡œ inputì— ì…ë ¥ì—†ìŒ ê³¼ ê°™ì´ ì¶”ê°€ëœ ë¶€ë¶„ ì‚­ì œê·¸ë¦¬ê³  <unk> ë“±ìœ¼ë¡œ gpt ìƒì—ì„œ ë²ˆì—­ ì˜¤ë¥˜ê°€ ë‚œ ê²ƒë“¤ì„ ì‚­ì œ   \\n\\nìì—°ìŠ¤ëŸ¬ì›€ì„ ìœ„í•´ stanford alpaca data, oig_chip2ë¥¼ ChatGPT3.5 turbo 16kë¥¼ ì´ìš©í•˜ì—¬ ìƒˆë¡­ê²Œ ì „ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì³¤ìŠµë‹ˆë‹¤.https://github.com/JoJo0217/rlhf_korean_dataset/tree/mainì—¬ê¸°ì—ì„œ ìì„¸í•œ ì„¤ëª…ì„ ë³¼ ìˆ˜ ìˆìœ¼ë©°ë°ì´í„°ì˜ êµ¬ì„±ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.   \\n\\në°ì´í„° êµ¬ì„±   \\n\\n\\t\\n\\t\\t\\në°ì´í„° ì¢…ë¥˜\\nê°œìˆ˜\\nurl\\n\\n\\n\\t\\t\\nkoalpaca v1.1\\n21155â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jojo0217/korean_rlhf_dataset."},
  {"name":"OpenOrca-KO","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kyujinpy/OpenOrca-KO","creator_name":"KyujinHan","creator_url":"https://huggingface.co/kyujinpy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenOrca-KO\\n\\t\\n\\n\\nOpenOrca dataset ì¤‘ ì•½ 2ë§Œê°œë¥¼ samplingí•˜ì—¬ ë²ˆì—­í•œ ë°ì´í„°ì…‹\\në°ì´í„°ì…‹ ì´ìš©í•˜ì…”ì„œ ëª¨ë¸ì´ë‚˜ ë°ì´í„°ì…‹ì„ ë§Œë“œì‹¤ ë•Œ, ê°„ë‹¨í•œ ì¶œì²˜ í‘œê¸°ë¥¼ í•´ì£¼ì‹ ë‹¤ë©´ ì—°êµ¬ì— í° ë„ì›€ì´ ë©ë‹ˆë‹¤ğŸ˜­ğŸ˜­\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset inf0\\n\\t\\n\\n\\nNIV // 1571ê°œ  \\nFLAN // 9434ê°œ  \\nT0 // 6351ê°œ  \\nCoT // 2117ê°œ  \\nKoCoT // 2159ê°œ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTranslation\\n\\t\\n\\nUsing DeepL Pro API. Thanks.\\n\\n\\nBelow is original dataset card\\n\\nğŸ‹ The OpenOrca Dataset! ğŸ‹\\n\\n\\n\\nWe are thrilled to announce the release of the OpenOrca dataset!\\nThis rich collection of augmented FLAN data aligns, as best asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kyujinpy/OpenOrca-KO."},
  {"name":"OpenOrca-gugugo-ko","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/squarelike/OpenOrca-gugugo-ko","creator_name":"Woojun Jeong","creator_url":"https://huggingface.co/squarelike","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenOrca í•œêµ­ì–´ ë²ˆì—­ ë°ì´í„°ì…‹\\n\\t\\n\\nGugugo-koen-7B-V1.1ì„ ì´ìš©í•˜ì—¬ OpenOrcaë°ì´í„°ì…‹ì„ ë²ˆì—­í•˜ê³  ìˆìŠµë‹ˆë‹¤.\\në²ˆì—­ ì§„í–‰ìƒí™©ì€ ì•„ë˜ë¥¼ ì°¸ê³ í•´ ì£¼ì‹­ì‹œì˜¤.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tì§„í–‰ìƒí™©\\n\\t\\n\\n\\nGPT4 ìƒì„±ë¬¼ ì•½ 100ë§Œ ê°œ ì¤‘ ì•½ 64ë§Œ ê°œ ë²ˆì—­ì™„ë£Œ\\nGPT3.5 ìƒì„±ë¬¼ ì•½ 350ë§Œ ê°œ ì¤‘ ì•½ 159ë§Œ ê°œ ë²ˆì—­ì™„ë£Œ\\n\\në°ì´í„°ì…‹ ì‚¬ìš© í›„ ì¶œì²˜í‘œê¸°ëŠ” ì œì‘ìì—ê²Œ í° í˜ì´ ë©ë‹ˆë‹¤.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOriginal dataset card: OpenOrca\\n\\t\\n\\nğŸ‹ The OpenOrca Dataset! ğŸ‹\\n\\n\\n\\nWe are thrilled to announce the release of the OpenOrca dataset!\\nThis rich collection of augmented FLAN data aligns, as best as possible, with the distributions outlined in the Orcaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/squarelike/OpenOrca-gugugo-ko."},
  {"name":"Open_Assistant_Conversation_Chains","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\n\\n\\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\\n\\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\\n\\nIt wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains."},
  {"name":"korean_textbooks","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/maywell/korean_textbooks","creator_name":"Jeonghwan Park","creator_url":"https://huggingface.co/maywell","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMassive Korean synthetic dataset\\n\\t\\n\\nThis dataset is a large-scale Korean artificial data set created using Gemini Pro.\\nIt was created using the methodology described in Creation of synthetic textbook-quality datasets in Textbooks Are All You Need.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData overview\\n\\t\\n\\nA subset of each dataset does not indicate the contents of that dataset.\\nFurther modification required before use this dataset for training.\\në³¸ ë°ì´í„°ì…‹ì€ ë°”ë¡œ ì‚¬ìš©í•˜ê¸°ë³´ë‹¤ëŠ” í•˜ê³ ìí•˜ëŠ” taskì— ë§ì¶”ì–´ ê°€ê³µ í›„ ì‚¬ìš©ì„ ê¶Œì¥ë“œë¦½ë‹ˆë‹¤. ex) ë¡œì»¬ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬â€¦ See the full description on the dataset page: https://huggingface.co/datasets/maywell/korean_textbooks."},
  {"name":"openassistant-deepseek-coder","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using:\\nB_INST = '\\\\n### Instruction:\\\\n'\\nE_INST = '\\\\n### Response:\\\\n'\\nBOS = '<ï½œbeginâ–ofâ–sentenceï½œ>'\\nEOS = '\\\\n<|EOT|>\\\\n'\\n\\nSample Preparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder."},
  {"name":"sharegpt_dialogue_base","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base","creator_name":"Hieu Lam","creator_url":"https://huggingface.co/lamhieu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe dataset is from unknown, formatted as dialogues for speed and ease of use. Many thanks to author for releasing it.\\nImportantly, this format is easy to use via the default chat template of transformers, meaning you can use huggingface/alignment-handbook immediately, unsloth.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\nView online through viewer.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\nWe advise you to reconsider before use, thank you. If you find it useful, please like and follow this account.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base."},
  {"name":"NIKL-korean-english-dictionary","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/binjang/NIKL-korean-english-dictionary","creator_name":"Bin Jang","creator_url":"https://huggingface.co/binjang","description":"\\n\\t\\n\\t\\t\\nColumn Name\\nType\\nDescription\\nì„¤ëª…\\n\\n\\n\\t\\t\\nForm\\nstr\\nRegistered word entry\\në‹¨ì–´\\n\\n\\nPart of Speech\\nstr or None\\nPart of speech of the word in Korean\\ní’ˆì‚¬\\n\\n\\nKorean Definition\\nList[str]\\nDefinition of the word in Korean\\ní•´ë‹¹ ë‹¨ì–´ì˜ í•œê¸€ ì •ì˜\\n\\n\\nEnglish Definition\\nList[str] or None\\nDefinition of the word in English\\ní•œê¸€ ì •ì˜ì˜ ì˜ë¬¸ ë²ˆì—­ë³¸\\n\\n\\nUsages\\nList[str] or None\\nSample sentence or dialogue\\ní•´ë‹¹ ë‹¨ì–´ì˜ ì˜ˆë¬¸ (ë¬¸ì¥ ë˜ëŠ” ëŒ€í™” í˜•ì‹)\\n\\n\\nVocabulary Level\\nstr or None\\nDifficulty of the word (3 levels)\\në‹¨ì–´ì˜ ë‚œì´ë„ ('ì´ˆê¸‰', 'ì¤‘ê¸‰', 'ê³ ê¸‰')\\n\\n\\nSemanticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/binjang/NIKL-korean-english-dictionary."},
  {"name":"KoCommercial-Dataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MarkrAI/KoCommercial-Dataset","creator_name":"Markr","creator_url":"https://huggingface.co/MarkrAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSSL ë°ì´í„° ìƒì„±ì„ ìœ„í•œ ì½”ë“œ ê³µê°œ\\n\\t\\n\\nSSL ë°ì´í„° ìƒì„±ìš© Github Repo\\n\\nNIAì™€  AI-Hubì™€ì˜ ì €ì‘ê¶Œ í˜‘ì˜ í•˜ì—, ì¡°ê¸ˆ í˜¼ì„ ì´ ìƒê¸´ê²ƒ ì£„ì†¡í•©ë‹ˆë‹¤.\\n\\nì´ì— ê¸°ì¡´ì— ì €í¬ê°€ codeë² ì´ìŠ¤ë¡œ SSL ë°ì´í„°ë¥¼ ìƒì„±í–ˆë˜ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ê³µê°œë“œë¦½ë‹ˆë‹¤.\\n\\në‹¤ë§Œ, ì´ ê³¼ì •ì—ì„œëŠ” ì €í¬ ì´í›„ íŒŒì´í”„ë¼ì¸ì¸, ìì²´ ë¡œì»¬ ëª¨ë¸ì„ ê°€ì§€ê³  í•„í„°ë§í•˜ê±°ë‚˜ ìˆ˜ì •í•˜ëŠ” ê³¼ì •ì´ ì—†ì–´, ì–´ëŠì •ë„ ê°ì•ˆì„ í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\\n\\nì½”ë“œëŠ” ëˆ„êµ¬ë‚˜ ì‚¬ìš©í•˜ì‹¤ ìˆ˜ ìˆê³  ê³¼ì œì™€ Taskì— ë§ê²Œ í™œìš©í•˜ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤!\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset: KoCommercial-Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInfo\\n\\t\\n\\nDataset ê°œìˆ˜: ì•½ 1.44M\\nLicense: MIT \\nDataset list(ì „ë¶€ ìƒì—…ì  ìš©ë„ë¡œ ì´ìš©ê°€ëŠ¥)  \\n\\nkyujinpy/KOpen-platypus (*Except non-commercial datasets)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarkrAI/KoCommercial-Dataset."},
  {"name":"aihub-flores-koen-integrated-prime-small-30k","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/traintogpb/aihub-flores-koen-integrated-prime-small-30k","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHigh Quality Ko-En Translation Dataset (AIHub-FLoRes Integrated)\\n\\t\\n\\nAI Hubì˜ í•œ-ì˜ ë²ˆì—­ ë°ì´í„°ì…‹ê³¼ FLoRes í•œ-ì˜ ë²ˆì—­ ë°ì´í„°ì…‹ì˜ í•©ë³¸ì…ë‹ˆë‹¤.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHigh Quality AIHub Dataset\\n\\t\\n\\nAI Hubì˜ ê²½ìš° í•œ-ì˜ ë²ˆì—­ ê´€ë ¨ ë°ì´í„°ì…‹ì„ 8ê°œ ë³‘í•©í•œ ë³‘ë ¬ ë°ì´í„° traintogpb/aihub-koen-translation-integrated-tiny-100kì—ì„œ ê³ í’ˆì§ˆì˜ ë²ˆì—­ ë ˆí¼ëŸ°ìŠ¤ë¥¼ ê°€ì§„ ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ì˜€ìŠµë‹ˆë‹¤.\\në²ˆì—­ ë ˆí¼ëŸ°ìŠ¤ í’ˆì§ˆ í‰ê°€ ì²™ë„ëŠ” Unbabel/XCOMET-XL (3.5B)ë¡œ ì¸¡ì •í•œ xCOMET metricì…ë‹ˆë‹¤.\\n8ê°œì˜ AIHub ë°ì´í„° ì†ŒìŠ¤ ì¤‘ ê¸°ì¡´ ì‹¤í—˜ì„ í†µí•´ ë²ˆì—­ ì„±ëŠ¥(SacreBLEU)ì´ ë‚®ì•˜ë˜ 4ê°œì˜ ì†ŒìŠ¤ì—ì„œ xCOMET ê¸°ì¤€ ìƒìœ„ 5,000ê°œ, ê·¸ ì™¸ 4ê°œì˜ ì†ŒìŠ¤ì—ì„œ xCOMET ê¸°ì¤€ ìƒìœ„ 2,500ê°œë¥¼ ì¶”ì¶œí•´ ì´ ì•½ 3ë§Œ ê°œì˜ ë°ì´í„°ë¥¼â€¦ See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-flores-koen-integrated-prime-small-30k."},
  {"name":"tokenizer-wiki-bench","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Tokenizer Benchmark\\n\\t\\n\\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \\nfrom transformers importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench."},
  {"name":"kollm-converations","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/davidkim205/kollm-converations","creator_name":"davidkim205","creator_url":"https://huggingface.co/davidkim205","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tkollm Converations Dataset\\n\\t\\n\\nThis dataset is an integrated dataset created in conversations format for SFT learning using the Korean dataset currently available on huggingface and github.\\nOur the nox model was trained on the kollm dataset. For datasets that are private due to license restrictions, please download them directly from the URL below.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIncluded datasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nSource\\nì„¤ëª…\\nì›ë³¸ URL\\n\\n\\n\\t\\t\\nKoAlpaca-v1.1\\në„¤ì´ë²„ ì§€ì‹ì¸ ì§ˆë‹µì„ ChatGPTë¥¼ ì´ìš©í•´ ì¬ìƒì„±í•œ Alpaca í˜•ì‹ ë°ì´í„°ì…‹â€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidkim205/kollm-converations."},
  {"name":"orca-math-korean-dpo-pairs","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/kuotient/orca-math-korean-dpo-pairs","creator_name":"Jisoo Kim","creator_url":"https://huggingface.co/kuotient","description":"axolotl does not take revision arg as an option and i'm lazy so i made this.\\ntype: chatml.intel\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOrca-math-korean-preference\\n\\t\\n\\n\\nquestion: orca-math datasetì˜ question\\nchosen: labelì´ ì°¸ì¼ ê²½ìš° answer í˜¹ì€ generatedì˜ random.choice, ê±°ì§“ì¼ ê²½ìš° answer (Orca-math original paper ì°¸ê³ )\\nrejected: labelì´ ì°¸ì¼ ê²½ìš° ë‹¤ë¥¸ rejected valueì˜ random.choice, ê±°ì§“ì¼ ê²½ìš° rejected (Orca-math original paper ì°¸ê³ )\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të¹„ê³ \\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tllm_exact_match prompt\\n\\t\\n\\nSYSTEM_PROMPT:\\nAs an expert Math teacher, your role is toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kuotient/orca-math-korean-dpo-pairs."},
  {"name":"korean_safe_conversation","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jojo0217/korean_safe_conversation","creator_name":"mingyu jo","creator_url":"https://huggingface.co/jojo0217","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tê°œìš”\\n\\t\\n\\nì„±ê· ê´€ëŒ€ - VAIV COMPANY ì‚°í•™í˜‘ë ¥ì„ ìœ„í•´ êµ¬ì¶•í•œ ì¼ìƒëŒ€í™” ë°ì´í„°ì…ë‹ˆë‹¤.   \\nìì—°ìŠ¤ëŸ½ê³  ìœ¤ë¦¬ì ì¸ ì±—ë´‡ êµ¬ì¶•ì„ ìœ„í•œ ë°ì´í„°ì…‹ ì…ë‹ˆë‹¤.   \\nê³ í’ˆì§ˆì„ ìœ„í•´ ëŒ€ë¶€ë¶„ì˜ ê³¼ì •ì—ì„œ ì‚¬ëŒì´ ì§ì ‘ ê²€ìˆ˜í•˜ì˜€ìœ¼ë©°ìƒì„± ë²ˆì—­ ë“±ì˜ ê³¼ì •ì—ì„œëŠ” GPT3.5-turbo, GPT4ë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.   \\nì¼ìƒëŒ€í™”ì— ì¤‘ì ì„ ë‘ë©´ì„œí˜ì˜¤í‘œí˜„, í¸í–¥ì ì¸ ëŒ€ë‹µì„ ì§€ì–‘í•˜ë©´ì„œ ì¼ìƒëŒ€í™”ë¥¼ í•˜ëŠ” ê²ƒì— ì¤‘ì ì„ ë‘ì—ˆìŠµë‹ˆë‹¤.   \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të°ì´í„° êµ¬ì¶• ê³¼ì •\\n\\t\\n\\n    \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\të°ì´í„° êµ¬ì„±\\n\\t\\n\\n\\n\\t\\n\\t\\t\\në°ì´í„° ì¢…ë¥˜\\nê°œìˆ˜\\në¹„ê³ \\nurl\\n\\n\\n\\t\\t\\nì¼ìƒëŒ€í™” ë°ì´í„°ì…‹\\n2063\\nêµ­ë¦½êµ­ì–´ì› ëª¨ë‘ì˜ ë§ë­‰ì¹˜\\nhttps://corpus.korean.go.kr/request/reausetMain.do?lang=ko\\n\\n\\nê°ì„±ëŒ€í™”\\n1020\\nAIHub ê°ì„±ëŒ€í™” ë°ì´í„°â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jojo0217/korean_safe_conversation."},
  {"name":"webui-dom-snapshots","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WebUI DOM snapshots\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: Gary Benson\\nLanguages: Mostly English (87%);\\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\\nLicense: CC0 1.0 Universal\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots."},
  {"name":"korean_parallel_sentences_v1.1","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lemon-mint/korean_parallel_sentences_v1.1","creator_name":"Lemon Mint","creator_url":"https://huggingface.co/lemon-mint","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Korean Parallel Sentences Ver 1.1\\n\\t\\n\\nThis dataset card provides information about the Korean Parallel Sentences Ver 1.1 dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Korean Parallel Sentences Ver 1.1 dataset is a collection of parallel sentences in Korean and English.\\nAlthough the factual accuracy of the data is not guaranteed, it has been designed to ensure accurate and consistent translation style between English and Korean.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lemon-mint/korean_parallel_sentences_v1.1."},
  {"name":"korean_parallel_sentences_v1.1","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lemon-mint/korean_parallel_sentences_v1.1","creator_name":"Lemon Mint","creator_url":"https://huggingface.co/lemon-mint","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Korean Parallel Sentences Ver 1.1\\n\\t\\n\\nThis dataset card provides information about the Korean Parallel Sentences Ver 1.1 dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Korean Parallel Sentences Ver 1.1 dataset is a collection of parallel sentences in Korean and English.\\nAlthough the factual accuracy of the data is not guaranteed, it has been designed to ensure accurate and consistent translation style between English and Korean.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lemon-mint/korean_parallel_sentences_v1.1."},
  {"name":"RAG-Evaluation-Dataset-KO","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/allganize/RAG-Evaluation-Dataset-KO","creator_name":"allganize","creator_url":"https://huggingface.co/allganize","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAllganize RAG Leaderboard\\n\\t\\n\\nAllganize RAG ë¦¬ë”ë³´ë“œëŠ” 5ê°œ ë„ë©”ì¸(ê¸ˆìœµ, ê³µê³µ, ì˜ë£Œ, ë²•ë¥ , ì»¤ë¨¸ìŠ¤)ì— ëŒ€í•´ì„œ í•œêµ­ì–´ RAGì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.ì¼ë°˜ì ì¸ RAGëŠ” ê°„ë‹¨í•œ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ë‹µë³€ì„ ì˜ í•˜ì§€ë§Œ, ë¬¸ì„œì˜ í…Œì´ë¸”ê³¼ ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸ì€ ë‹µë³€ì„ ì˜ ëª»í•©ë‹ˆë‹¤.  \\nRAG ë„ì…ì„ ì›í•˜ëŠ” ìˆ˜ë§ì€ ê¸°ì—…ë“¤ì€ ìì‚¬ì— ë§ëŠ” ë„ë©”ì¸, ë¬¸ì„œ íƒ€ì…, ì§ˆë¬¸ í˜•íƒœë¥¼ ë°˜ì˜í•œ í•œêµ­ì–´ RAG ì„±ëŠ¥í‘œë¥¼ ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤.í‰ê°€ë¥¼ ìœ„í•´ì„œëŠ” ê³µê°œëœ ë¬¸ì„œì™€ ì§ˆë¬¸, ë‹µë³€ ê°™ì€ ë°ì´í„° ì…‹ì´ í•„ìš”í•˜ì§€ë§Œ, ìì²´ êµ¬ì¶•ì€ ì‹œê°„ê³¼ ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ì¼ì…ë‹ˆë‹¤.ì´ì œ ì˜¬ê±°ë‚˜ì´ì¦ˆëŠ” RAG í‰ê°€ ë°ì´í„°ë¥¼ ëª¨ë‘ ê³µê°œí•©ë‹ˆë‹¤. \\nRAGëŠ” Parser, Retrieval, Generation í¬ê²Œ 3ê°€ì§€ íŒŒíŠ¸ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.í˜„ì¬, ê³µê°œë˜ì–´ ìˆëŠ” RAG ë¦¬ë”ë³´ë“œ ì¤‘, 3ê°€ì§€ íŒŒíŠ¸ë¥¼ ì „ì²´ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” í•œêµ­ì–´ë¡œ êµ¬ì„±ëœ ë¦¬ë”ë³´ë“œëŠ” ì—†ìŠµë‹ˆë‹¤.\\nAllganize RAG ë¦¬ë”ë³´ë“œì—ì„œëŠ”â€¦ See the full description on the dataset page: https://huggingface.co/datasets/allganize/RAG-Evaluation-Dataset-KO."},
  {"name":"ko-instruction-dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CarrotAI/ko-instruction-dataset","creator_name":"CarrotCarrot","creator_url":"https://huggingface.co/CarrotAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tê³ í’ˆì§ˆ í•œêµ­ì–´ ë°ì´í„°ì…‹\\n\\t\\n\\ní•œêµ­ì–´ë¡œ ì´ë£¨ì–´ì§„ ê³ í’ˆì§ˆ í•œêµ­ì–´ ë°ì´í„°ì…‹ ì…ë‹ˆë‹¤.\\nWizardLM-2-8x22B ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ WizardLM: Empowering Large Language Models to Follow Complex Instructionsì—ì„œ ì†Œê°œëœ ë°©ë²•ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\\n@article{koinstructiondatasetcard,\\n  title={CarrotAI/ko-instruction-dataset Card},\\n  author={CarrotAI (L, GEUN)},\\n  year={2024},\\n  url = {https://huggingface.co/datasets/CarrotAI/ko-instruction-dataset}\\n}\\n\\n"},
  {"name":"Block_Diagram","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/shreyanshu09/Block_Diagram","creator_name":"Shreyanshu Bhushan","creator_url":"https://huggingface.co/shreyanshu09","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBlock Diagram Dataset\\n\\t\\n\\nThis dataset is a combination of four block diagram datasets. The first dataset is the BD-EnKo dataset, which was introduced in the paper \\\"Unveiling the Power of Integration: Block Diagram Summarization through Local-Global Fusion\\\" accepted at ACL 2024. The second dataset is CBD, the third is FC_A, and the fourth is FC_B.\\nOnly BD-EnKo dataset is available here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\nThis dataset contains different types of block diagram imagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shreyanshu09/Block_Diagram."},
  {"name":"KBMC","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SungJoo/KBMC","creator_name":"Grace","creator_url":"https://huggingface.co/SungJoo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the first open-source medical Named Entity Recognition (NER) dataset in Korean language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nEach row in the KBMC.tsv file contains a sentence with its corresponding named entities (Disease, Body, and Treatement).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\nsentence: The sentence text.\\ntags: The named entities in the sentence.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe dataset is provided under the Apacheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SungJoo/KBMC."},
  {"name":"KBMC","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SungJoo/KBMC","creator_name":"Grace","creator_url":"https://huggingface.co/SungJoo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the first open-source medical Named Entity Recognition (NER) dataset in Korean language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nEach row in the KBMC.tsv file contains a sentence with its corresponding named entities (Disease, Body, and Treatement).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\nsentence: The sentence text.\\ntags: The named entities in the sentence.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe dataset is provided under the Apacheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SungJoo/KBMC."},
  {"name":"BCCard-Finance-Kor-QnA","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/BCCard/BCCard-Finance-Kor-QnA","creator_name":"BC Card","creator_url":"https://huggingface.co/BCCard","description":"BCCard/BCCard-Finance-Kor-QnA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"nomiracl-instruct","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/miracl/nomiracl-instruct","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NoMIRACL (EMNLP 2024 Findings Track)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Overview\\n\\t\\n\\nThis repository contains the fine-tuning (training & development split) of the NoMIRACL instruct dataset for fine-tuning LLMs on multilingual relevance assessment.\\nThe training dataset is a binary classification task; they need to explicitly output either Yes, answer is present or I don't know. \\nThe dataset contains training pairs from all 18 languages for both splits: relevant & non-relevant.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/miracl/nomiracl-instruct."},
  {"name":"KoMT-Bench","license":"GNU Lesser General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/LGAI-EXAONE/KoMT-Bench","creator_name":"LG AI Research","creator_url":"https://huggingface.co/LGAI-EXAONE","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKoMT-Bench\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe present KoMT-Bench, a benchmark designed to evaluate the capability of language models in following instructions in Korean.\\nKoMT-Bench is an in-house dataset created by translating MT-Bench [1]  dataset into Korean and modifying some questions to reflect the characteristics and cultural nuances of the Korean language.\\nAfter the initial translation and modification, we requested expert linguists to conduct a thorough review of ourâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LGAI-EXAONE/KoMT-Bench."},
  {"name":"text_ratings","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"Todo - Write dataset card\\n"},
  {"name":"rag-eval-mini","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/teddylee777/rag-eval-mini","creator_name":"Teddy Lee","creator_url":"https://huggingface.co/teddylee777","description":"teddylee777/rag-eval-mini dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"korean-writing-style-instruct","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/coastral/korean-writing-style-instruct","creator_name":"Coastral","creator_url":"https://huggingface.co/coastral","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tí•œêµ­ì–´ ë¬¸ì²´ ë°ì´í„°ì…‹\\n\\t\\n\\nì—¬ëŸ¬ ë¶„ì•¼ì˜ ë¬¸ì²´(ë¬¸í•™, ì¼ìƒì  ëŒ€í™”, ê³ ì „ì‹œê°€ ë“±)ë¥¼ í¬í•¨í•œ í•©ì„± ë°ì´í„°ì…‹ì…ë‹ˆë‹¤. ëª¨ë¸ì—ê²Œ ì—¬ëŸ¬ ë¬¸ì²´ë¥¼ ì¶œë ¥í•˜ëŠ” ëŠ¥ë ¥ì„ ê°€ë¥´ì¹˜ê¸° ìœ„í•´ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. í›ˆë ¨ì‹œí‚¤ì‹¤ ë•Œ, ì¼ë°˜ ì¸ìŠ¤íŠ¸ëŸ­ìŠ¤ ë°ì´í„°ì…‹ê³¼ í˜¼ìš©í•´ì„œ ì‚¬ìš©í•˜ì‹œëŠ” ê²ƒì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.\\nì´ ë°ì´í„°ì…‹ì€ apache-2 ë¼ì´ì„ ìŠ¤ë¡œ ììœ ë¡­ê²Œ ì´ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ëŠ” Glaive í”Œë«í¼ì„ í†µí•´ í•©ì„±ë˜ì—ˆê³ , í•œê¸€ì´ ì•„ë‹Œ ì¶œë ¥ì€ ê±¸ëŸ¬ëƒˆìŠµë‹ˆë‹¤.\\n"},
  {"name":"MMMLU","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLUâ€™s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increasesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU."},
  {"name":"mmmlu_kor","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/4n3mone/mmmlu_kor","creator_name":"yongsang yoo","creator_url":"https://huggingface.co/4n3mone","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMLU_KOREAN\\n\\t\\n\\nthis dataset is korean subset of openai/MMMLU dataset.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLUâ€™s test set into 14 languages usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/4n3mone/mmmlu_kor."},
  {"name":"vqa","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/worldcuisines/vqa","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\\n\\t\\n\\n\\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 Octoberâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa."},
  {"name":"atlassian-qna","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/youngmon/atlassian-qna","creator_name":"youngseo","creator_url":"https://huggingface.co/youngmon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸ“„ Question and Answer for Atlassian Products\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nAtlassian Community\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Description\\n\\t\\n\\nThe dataset primarily includes questions, answers, tags, and URLs.\\n\\nQuestions contain the author, title, and content of the post.\\nAnswers include usage instructions, solutions, and other information provided by engineers and users.\\nTags represent the categories or topics of the post.\\nURLs provide links to the original documents.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/youngmon/atlassian-qna."},
  {"name":"hermes-function-calling-v1-ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/iknow-lab/hermes-function-calling-v1-ko","creator_name":"iknow-lab","creator_url":"https://huggingface.co/iknow-lab","description":"\\nOriginal Data: NousResearch/hermes-function-calling-v1\\nGPT-4o-minië¡œ ë²ˆì—­í–ˆìœ¼ë‚˜, ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ê±°ë‚˜ ì—ëŸ¬ê°€ ë‚œ ê²½ìš°ê°€ 1300 ê±´ ê°€ëŸ‰ ì œì™¸ë¨.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample 1\\n\\t\\n\\n[\\n        {\\n            \\\"role\\\": \\\"system\\\",\\n            \\\"content\\\": \\\"ë‹¹ì‹ ì€ ì „ë¬¸ê°€ë¡œì„œ êµ¬ì¡°í™”ëœ ì •ë³´ ì¶”ì¶œ AI ëª¨ë¸ì…ë‹ˆë‹¤. ì •ë³´ ì¶”ì¶œì„ ìœ„í•´ ë¬¸ì„œë¥¼ ì œê³µë°›ìŠµë‹ˆë‹¤. ì¶”ì¶œëœ ì •ë³´ë¥¼ XML íƒœê·¸ <tools></tools> ë‚´ì˜ í•¨ìˆ˜ ì„œëª… í˜•íƒœë¡œ ì¶œë ¥í•  json ìŠ¤í‚¤ë§ˆë„ ì œê³µë°›ìŠµë‹ˆë‹¤. json ìŠ¤í‚¤ë§ˆì— ì–´ë–¤ ê°’ì„ ë„£ì„ì§€ ê°€ì •í•˜ì§€ ë§ˆì„¸ìš”. \\\\n<tools>\\\\n[{\\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\", \\\\\\\"function\\\\\\\": {\\\\\\\"name\\\\\\\": \\\\\\\"ExpertQAExtractor\\\\\\\", \\\\\\\"description\\\\\\\": \\\\\\\"ë¬¸ì„œì—ì„œ ê°œë…ì´ë‚˜ ì •ë³´ê°€ ì‹¤ì œ ìƒí™©ì— ì–´ë–»ê²Œ ì ìš©ë  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ë¬»ëŠ”â€¦ See the full description on the dataset page: https://huggingface.co/datasets/iknow-lab/hermes-function-calling-v1-ko."},
  {"name":"m-ArenaHard","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/m-ArenaHard","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-ArenaHard\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-ArenaHard."},
  {"name":"ko_leaderboard","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AIDX-ktds/ko_leaderboard","creator_name":"aidx_ktds","creator_url":"https://huggingface.co/AIDX-ktds","description":"í•œêµ­ì–´ ë¦¬ë”ë³´ë“œ í•™ìŠµì—ì„œ ì‚¬ìš©ëœ ë°ì´í„° ì¤‘ ì•½ 8,000ê±´ì— ëŒ€í•´ì„œ\\nê³µê°œí•©ë‹ˆë‹¤. ë°ì´í„° ìƒì„± ì‹œ ë„ì›€ì´ ë˜ê¸°ë¥¼ ë°”ëë‹ˆë‹¤.\\nê°ì‚¬í•©ë‹ˆë‹¤.\\n"},
  {"name":"ko_leaderboard","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AIDX-ktds/ko_leaderboard","creator_name":"aidx_ktds","creator_url":"https://huggingface.co/AIDX-ktds","description":"í•œêµ­ì–´ ë¦¬ë”ë³´ë“œ í•™ìŠµì—ì„œ ì‚¬ìš©ëœ ë°ì´í„° ì¤‘ ì•½ 8,000ê±´ì— ëŒ€í•´ì„œ\\nê³µê°œí•©ë‹ˆë‹¤. ë°ì´í„° ìƒì„± ì‹œ ë„ì›€ì´ ë˜ê¸°ë¥¼ ë°”ëë‹ˆë‹¤.\\nê°ì‚¬í•©ë‹ˆë‹¤.\\n"},
  {"name":"VoxCommunis","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis."},
  {"name":"P-MMEval","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Qwen/P-MMEval","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tP-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce a multilingual benchmark, P-MMEval, covering effective fundamental and capability-specialized datasets. We extend the existing benchmarks, ensuring consistent language coverage across all datasets and providing parallel samples among multiple languages, supporting up to 10 languages from 8 language families (i.e., en, zh, ar, es, ja, ko, th, fr, ptâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Qwen/P-MMEval."},
  {"name":"General-Evol-VQA","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/maum-ai/General-Evol-VQA","creator_name":"maum-ai","creator_url":"https://huggingface.co/maum-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for General-Evol-VQA-1.2M\\n\\t\\n\\nThis dataset has been carefully curated to enhance the general instruction capabilities of Vision-Language Models (VLMs). It comprises two subsets:\\n\\n600k English samples\\n600k Korean samples\\n\\nWe recommend using this dataset alongside other task-specific datasets (e.g., OCR, Language, code, math, ...) to improve performance and achieve more robust model capabilities.\\n\\nMade by: maum.ai Brain NLP. Jaeyoon Jung, Yoonshik Kim\\nDataset Targetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maum-ai/General-Evol-VQA."},
  {"name":"include-base-44","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/include-base-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-base (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-base-44."},
  {"name":"open-dict-words-ipa","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-dict Words IPA\\n\\t\\n\\nThis dataset is a copy of https://github.com/open-dict-data/ipa-dict\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nIPA data is currently available for the following languages:\\n\\n\\t\\n\\t\\t\\nLanguage\\nCode\\n\\n\\n\\t\\t\\nar\\nArabic (Modern Standard)\\n\\n\\nde\\nGerman\\n\\n\\nen_UK\\nEnglish (Received Pronunciation)\\n\\n\\nen_US\\nEnglish (General American)\\n\\n\\neo\\nEsperanto\\n\\n\\nes_ES\\nSpanish (Spain)\\n\\n\\nes_MX\\nSpanish (Mexico)\\n\\n\\nfa\\nPersian\\n\\n\\nfi\\nFinnish\\n\\n\\nfr_FR\\nFrench (France)\\n\\n\\nfr_QC\\nFrench (QuÃ©bec)\\n\\n\\nis\\nIcelandic\\n\\n\\nja\\nJapanese\\n\\n\\njamâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa."},
  {"name":"include-lite-44","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/include-lite-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-lite (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-lite-44."},
  {"name":"Global-MMLU-Lite","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 15 languages, including English. It is \\\"lite\\\" version of the original Global-MMLU dataset ğŸŒ.\\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \\n\\nCurated by: Professional annotators and contributors of Cohere Forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite."},
  {"name":"Ko-functioncall","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jaeyong2/Ko-functioncall","creator_name":"jeongjaeyong","creator_url":"https://huggingface.co/jaeyong2","description":"\\n\\t\\n\\t\\t\\n\\t\\tDevelopment Process\\n\\t\\n\\n\\nsource dataset from daje/ko_wiki and maywell/korean_textbooks\\nWe used Qwen/Qwen2-72B-Instruct model to generate answer with COT.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLicense\\n\\t\\n\\n\\nQwen/Qwen2.5-72B-Instruct : https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/LICENSE\\nmaywell/korean_textbooks : https://choosealicense.com/licenses/apache-2.0/\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tAcknowledgement\\n\\t\\n\\nThis research is supported by TPU Research Cloud program.\\n"},
  {"name":"MultiLingualSentiment","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/clapAI/MultiLingualSentiment","creator_name":"clapAI","creator_url":"https://huggingface.co/clapAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nMultilingualSentiment is a sentiment classification dataset that encompasses three sentiment labels: Positive, Neutral, Negative\\nThe dataset spans multiple languages and covers a wide range of domains, making it ideal for multilingual sentiment analysis tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\nThe dataset was meticulously collected and aggregated from various sources, including Hugging Face and Kaggle. These sources provide diverse languages and domains to ensure aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/clapAI/MultiLingualSentiment."},
  {"name":"CoT-XLang","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Egor-AI/CoT-XLang","creator_name":"Egor AI","creator_url":"https://huggingface.co/Egor-AI","description":"RU:CoT-XLang â€” ÑÑ‚Ğ¾ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚, ÑĞ¾ÑÑ‚Ğ¾ÑÑ‰Ğ¸Ğ¹ Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ñ Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼Ğ¸ (Chain-of-Thought, CoT) Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ°Ñ…, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¸Ğ¹, Ñ€ÑƒÑÑĞºĞ¸Ğ¹, ÑĞ¿Ğ¾Ğ½ÑĞºĞ¸Ğ¹ Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ. ĞĞ½ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ñ… Ğ¿Ğ¾ÑÑĞ½ĞµĞ½Ğ¸Ğ¹ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ ÑˆĞ°Ğ³Ğ¾Ğ². Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ¾ĞºĞ¾Ğ»Ğ¾ 2,419,912 Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ², Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡Ğ°Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ñ‹Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ.\\nĞ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ:Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Egor-AI/CoT-XLang."},
  {"name":"medical-o1-reasoning-SFT-Ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ChuGyouk/medical-o1-reasoning-SFT-Ko","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe original data was used to fine-tune HuatuoGPT-o1, a medical LLM designed for advanced medical reasoning. Original dataset was constructed using GPT-4o, which searches for solutions to verifiable medical problems and validates them through a medical verifier. \\nFor details, see their paper and GitHub repository.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTranslation\\n\\t\\n\\nFor translation into Korean, I used gemini-2.0-flash-exp model w/ temperature=0.5 setting.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompt\\n\\t\\n\\n\\nYou are aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/medical-o1-reasoning-SFT-Ko."},
  {"name":"vqa-rad-ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/junyeong-nero/vqa-rad-ko","creator_name":"Junyeong Song","creator_url":"https://huggingface.co/junyeong-nero","description":"junyeong-nero/vqa-rad-ko dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"SMPQA","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/WueNLP/SMPQA","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSMPQA (Synthetic Multilingual Plot QA)\\n\\t\\n\\n\\n\\nThe SMPQA evaluation dataset proposed in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nSMPQA is composed of synthetic bar plots and pie charts (generated using word lists of different languages) together with questions about those plots.\\nThe datasets aims at providing an initial way of evaluating multilingual OCR capabilities of models in arbritrary languages.\\nThere are two sub-tasks: \\n\\nGrounding text labelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/SMPQA."},
  {"name":"kicj","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/niruka/kicj","creator_name":"niruka","creator_url":"https://huggingface.co/niruka","description":"This is a dataset of 30 research reports published by the Korea Institute of Criminal Justice and Public Policy (KICJ) over the past 10 years, augmented with a Q/A set using GPT4o based on each research report page.\\nThis dataset may contain incorrect information or content due to the augmentation using GPT4o.\\nContact : niruka@naver.com\\n"},
  {"name":"KOFFVQA_Data","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/maum-ai/KOFFVQA_Data","creator_name":"maum-ai","creator_url":"https://huggingface.co/maum-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\tAbout this data\\n\\t\\n\\nKOFFVQA is a general-purpose VLM benchmark in the Korean language. For more information, refer to our leaderboard page and the official evaluation code.\\nThis contains the data for the benchmark consisting of images, their corresponding questions, and response grading criteria.\\n"},
  {"name":"MME","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Mineru/MME","creator_name":"Keun Seok, Im","creator_url":"https://huggingface.co/Mineru","description":"Mineru/MME dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Throat_and_Acoustic_Pairing_Speech_Dataset","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/yskim3271/Throat_and_Acoustic_Pairing_Speech_Dataset","creator_name":"yunsik kim","creator_url":"https://huggingface.co/yskim3271","description":"\\n\\t\\n\\t\\t\\n\\t\\tTAPS: Throat and Acoustic Paired Speech Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1. DATASET SUMMARY\\n\\t\\n\\nThe Throat and Acoustic Paired Speech (TAPS) dataset is a standardized corpus designed for deep learning-based speech enhancement, specifically targeting throat microphone recordings. Throat microphones effectively suppress background noise but suffer from high-frequency attenuation due to the low-pass filtering effect of the skin and tissue. The dataset provides paired recordings from 60 native Koreanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yskim3271/Throat_and_Acoustic_Pairing_Speech_Dataset."},
  {"name":"Open-KoEn-Parallel-Style-Tag","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/werty1248/Open-KoEn-Parallel-Style-Tag","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","description":"\\n\\t\\n\\t\\t\\n\\t\\tì„¤ëª…\\n\\t\\n\\n\\ngemini-1.5-flashë¥¼ ì´ìš©í•˜ì—¬, í•œêµ­ì–´ í…ìŠ¤íŠ¸ì˜ ìŠ¤íƒ€ì¼ì„ íƒœê·¸ í˜•íƒœë¡œ ì œì•ˆí•˜ë„ë¡ ìš”ì²­í•˜ì˜€ìŠµë‹ˆë‹¤.\\n\\nì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸\\n\\n\\në‹¹ì‹ ì€ í•œêµ­ì–´ ë° ê¸€ì“°ê¸° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë§ˆì§€ë§‰ì— í•œêµ­ì–´ í…ìŠ¤íŠ¸ê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤. ë‹¹ì‹ ì€ ê·¸ í…ìŠ¤íŠ¸ì˜ ìŠ¤íƒ€ì¼ì„ ì£¼ì–´ì§„ ê¸°ì¤€ì— ë”°ë¼ ë¶„ë¥˜í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ë¶„ë¥˜ ê²°ê³¼ë¥¼ python Dict[List] í˜•íƒœë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.\\ndictionary ì´ë¦„ì€ \\\"style\\\"ì…ë‹ˆë‹¤.\\n\\n## ë¶„ë¥˜ ê¸°ì¤€ - ë³µìˆ˜ ì„ íƒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\\n\\nìœ í˜•: [ëª…ì‚¬í˜•(Nominal), í‰ì„œë¬¸ (Declarative), ì˜ë¬¸ë¬¸ (Interrogative), ëª…ë ¹ë¬¸ (Imperative), ê°íƒ„ë¬¸ (Exclamatory), ì²­ìœ ë¬¸ (Propositive)]\\n\\nëŒ€ìƒ: [ì¼ë°˜ ëŒ€ì¤‘ (General), ì „ë¬¸ê°€ ì§‘ë‹¨ (Specialist), ì•„ë™ (Children), ê°œì¸ (Individual)]\\n\\në¬¸ì²´: [ê²©ì‹ì²´ (Formal), ë¹„ê²©ì‹ì²´ (Informal), ë”±ë”±í•¨ (Stiff)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/werty1248/Open-KoEn-Parallel-Style-Tag."},
  {"name":"korean-realqa-reasoning-v01","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/lemon-mint/korean-realqa-reasoning-v01","creator_name":"Lemon Mint","creator_url":"https://huggingface.co/lemon-mint","description":"https://huggingface.co/datasets/beomi/KoAlpaca-RealQA\\n"},
  {"name":"korean-realqa-reasoning-v01-preference","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/lemon-mint/korean-realqa-reasoning-v01-preference","creator_name":"Lemon Mint","creator_url":"https://huggingface.co/lemon-mint","description":"https://huggingface.co/datasets/beomi/KoAlpaca-RealQA\\n"},
  {"name":"BenchMAX_Math","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Math","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Math is a dataset of BenchMAX, sourcing from MGSM.\\nWe extend the original dataset to 6 more languages.\\nThe data is first translated by Google Translate, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chineseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Math."},
  {"name":"BenchMAX_Science","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Science","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Science is a dataset of BenchMAX, sourcing from GPQA.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by Google Translate, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Science."},
  {"name":"BenchMAX_Function_Completion","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from humanevalplus.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by GPT-4o, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion."},
  {"name":"BenchMAX_Problem_Solving","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Problem_Solving is a dataset of BenchMAX, sourcing from LiveCodeBench.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by GPT-4o, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving."},
  {"name":"smol-koreantalk","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lemon-mint/smol-koreantalk","creator_name":"Lemon Mint","creator_url":"https://huggingface.co/lemon-mint","description":"SmolLM2ì˜ ì¸ìŠ¤íŠ¸ëŸ­ì…˜ í›ˆë ¨ ë°ì´í„° HuggingFaceTB/smol-smoltalkë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í–ˆì–´ìš”.\\n"},
  {"name":"DATA-AI_Chat","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","description":"\\n\\t\\n\\t\\t\\n\\t\\tDATA-AI: Il Modello di IA di M.INC.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tğŸ“Œ Introduzione\\n\\t\\n\\nDATA-AI Ã¨ un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello Ã¨ basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \\nDATA-AI Ã¨ stato addestrato su unâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat."},
  {"name":"ea-mt-benchmark","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark","creator_name":"Sapienza NLP, Sapienza University of Rome","creator_url":"https://huggingface.co/sapienzanlp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for EA-MT\\n\\t\\n\\nEA-MT (Entity-Aware Machine Translation) is a multilingual benchmark for evaluating the capabilities of Large Language Models (LLMs) and Machine Translation (MT) models in translating simple sentences with potentially challenging entity mentions, e.g., entities for which a word-for-word translation may not be accurate.\\nHere is an example of a simple sentence with a challenging entity mention:\\n\\nEnglish: \\\"What is the plot of The Catcher in the Rye?\\\"\\nItalian:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark."},
  {"name":"BCAI-Finance-Kor","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/BCCard/BCAI-Finance-Kor","creator_name":"BC Card","creator_url":"https://huggingface.co/BCCard","description":"BCCard/BCAI-Finance-Kor dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Open-R1-Mulitlingual-SFT","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT","creator_name":"GUIJIN SON","creator_url":"https://huggingface.co/amphora","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-R1-Mulitlingual-SFT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nOpen-R1-Mulitlingual-SFT is a curated dataset designed for multilingual supervised fine-tuning.\\nThe source data comprises multiple datasets containing original prompts and responses, which were subsequently translated into 14 languages using GPT-4o.\\n\\n\\t\\n\\t\\t\\n\\t\\tSources\\n\\t\\n\\nThe dataset is derived from:\\n\\nopen-thoughts/OpenThoughts-114kHugging Face: open-thoughts/OpenThoughts-114k\\nbespokelabs/Bespoke-Stratos-17kHugging Face:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT."},
  {"name":"wikis","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/nyuuzyou/wikis","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Public MediaWiki Collection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 1,662,448 articles harvested from 930 random public MediaWiki instances found across the Internet. The collection was created by extracting current page content from these wikis, preserving article text, metadata, and structural information. The dataset represents a diverse cross-section of public wiki content spanning multiple domains, topics, and languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wikis."},
  {"name":"Thinking-multilingual-big-10k-sft","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\\nenjoy ğŸ‘\\n"},
  {"name":"m-WildVision","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/m-WildVision","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-WildVision\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \\nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \\nThe authors demonstrated that these prompts enable automatic LLM judgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-WildVision."},
  {"name":"OpenHumanreasoning-multilingual-2.2k","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\\nnote: translations are not human generated.\\n"},
  {"name":"numina_math_ko_verifiable_540k","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/OLAIR/numina_math_ko_verifiable_540k","creator_name":"OLA-AI-Research","creator_url":"https://huggingface.co/OLAIR","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card: OLAIR/numina_math_ko_verifiable_540k\\n\\t\\n\\nOverview:A paired dataset of math questions (translated into Korean using GPT-4o-mini) and verifiable answers. Intended for RL training (e.g., GRPO) and mathematical reasoning tasks.\\nSources:  \\n\\nQuestions: Derived from AI-MO/NuminaMath-CoT  \\nAnswers: Extracted from flatlander1024/numinamath_verifiable_cleaned\\n\\nKey Points:  \\n\\nTranslation: No-cleansing version; translations may contain errors.  \\nUsage: Suitable for RL and languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OLAIR/numina_math_ko_verifiable_540k."},
  {"name":"resume_jd_matching_kr","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/recuse/resume_jd_matching_kr","creator_name":"KW recuse project","creator_url":"https://huggingface.co/recuse","description":"ì´ë ¥ì„œ - ê³µê³  ë§¤ì¹­ í•œê¸€ ë°ì´í„°ì…‹\\ncnamuangtoun/resume-job-description-fitì„ gpt-4-o-mini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ì—­í•¨.\\nContrastive Learning ìœ¼ë¡œ ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n"},
  {"name":"reasoning-conversations","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/syntaxsynth/reasoning-conversations","creator_name":"SyntaxSynth","creator_url":"https://huggingface.co/syntaxsynth","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Reasoning Dataset\\n\\t\\n\\n\\nInclude languages from German, Korean, Spanish, Japanese, French, Simplified Chinese, Traditional Chinese\\n\\nReasoning traces from Deepseek-v3-R1, Deepseek-v3-R1-Zero\\n\\n\\nCredits sponsored by Currents API\\n"},
  {"name":"kor_3i4k","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/wicho/kor_3i4k","creator_name":"Won Ik Cho","creator_url":"https://huggingface.co/wicho","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for 3i4K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe 3i4K dataset is a set of frequently used Korean words (corpus provided by the Seoul National University Speech Language Processing Lab) and manually created questions/commands containing short utterances. The goal is to identify the speaker intention of a spoken utterance based on its transcript, and whether in some cases, requires using auxiliary acoustic features. The classification system decides whether the utteranceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wicho/kor_3i4k."},
  {"name":"kor_nli","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/kakaobrain/kor_nli","creator_name":"Kakao Brain","creator_url":"https://huggingface.co/kakaobrain","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"kor_nli\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKorean Natural Language Inference datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmulti_nli\\n\\t\\n\\n\\nSize of downloaded dataset files: 42.11 MB\\nSize of the generated dataset: 84.72 MB\\nTotal amount of disk used: 126.85 MB\\n\\nAn example of 'train' looks as follows.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kakaobrain/kor_nli."},
  {"name":"kor_sarcasm","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/SpellOnYou/kor_sarcasm","creator_name":"SpellOnYou","creator_url":"https://huggingface.co/SpellOnYou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Korean Sarcasm Detection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Korean Sarcasm Dataset was created to detect sarcasm in text, which can significantly alter the original meaning of a sentence. 9319 tweets were collected from Twitter and labeled for sarcasm or not_sarcasm. These tweets were gathered by querying for: ì—­ì„¤, ì•„ë¬´ë§, ìš´ìˆ˜ì¢‹ì€ë‚ , ç¬‘, ë­ë˜ ì•„ë‹™ë‹ˆë‹¤, ê·¸ëŸ´ë¦¬ì—†ë‹¤, ì–´ê·¸ë¡œ, irony sarcastic, and sarcasm. The dataset was pre-processed by removing the keyword hashtag, urls and mentions ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SpellOnYou/kor_sarcasm."},
  {"name":"opus_paracrawl","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for OpusParaCrawl\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nParallel corpora from Web Crawls collected in the ParaCrawl project.\\nTha dataset contains:\\n\\n42 languages, 43 bitexts\\ntotal number of files: 59,996\\ntotal number of tokens: 56.11G\\ntotal number of sentence fragments: 3.13G\\n\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs,\\ne.g.\\ndataset = load_dataset(\\\"opus_paracrawl\\\", lang1=\\\"en\\\", lang2=\\\"so\\\")\\n\\nYou can findâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl."},
  {"name":"tydiqa","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/google-research-datasets/tydiqa","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tydiqa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\\nin the world. It contains language phenomena that would not be foundâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/tydiqa."},
  {"name":"mr-tydi-corpus","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/castorini/mr-tydi-corpus","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\\nThis dataset stores documents of Mr. TyDi. To access the queries and judgments, please refer to castorini/mr-tydi.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe only configuration here is the language. As all three folds (train, dev and test) share theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi-corpus."},
  {"name":"mr-tydi","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/castorini/mr-tydi","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\\nThis dataset stores the queries, judgements, and example training data of Mr. TyDi. To access the corpus, please refer to castorini/mr-tydi-corpus.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe only configuration here is the language, \\nFor each languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi."},
  {"name":"APEACH","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/jason9693/APEACH","creator_name":"Kichang Yang","creator_url":"https://huggingface.co/jason9693","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset for project: kor_hate_eval(APEACH)\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample Code\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Descritpion\\n\\t\\n\\nKorean Hate Speech Evaluation Datasets : trained with BEEP! and evaluate with APEACH\\n\\nRepository: Korean HateSpeech Evaluation Dataset\\nPaper: APEACH: Attacking Pejorative Expressions with Analysis on Crowd-Generated Hate Speech Evaluation Datasets\\nPoint of Contact: Kichang Yang\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nko-KR\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jason9693/APEACH."},
  {"name":"xlel_wd_dictionary","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles."},
  {"name":"xlel_wd","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles."},
  {"name":"arcalive_220506","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Bingsu/arcalive_220506","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"[ì•„ì¹´ë¼ì´ë¸Œ ë² ìŠ¤íŠ¸ ë¼ì´ë¸Œ ì±„ë„](https://arca.live/b/live)ì˜ 2021ë…„ 8ì›” 16ì¼ë¶€í„° 2022ë…„ 5ì›” 6ì¼ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬, ëŒ“ê¸€ë§Œ ê³¨ë¼ë‚¸ ë°ì´í„°ì…ë‹ˆë‹¤."},
  {"name":"qg_koquad","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/lmqg/qg_koquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"[KorQuAD](https://huggingface.co/datasets/squad_kor_v1) dataset for question generation (QG) task."},
  {"name":"KcBERT_Pre-Training_Corpus","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Bingsu/KcBERT_Pre-Training_Corpus","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKcBERT Pre-Training Corpus (Korean News Comments)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKcBERT\\n\\t\\n\\nbeomi/kcbert-base\\nGithub KcBERT Repo:Â https://github.com/Beomi/KcBERTKcBERT is Korean Comments BERT pretrained on this Corpus set.(You can use it via Huggingface's Transformers library!)\\nThis Kaggle Dataset containsÂ CLEANEDÂ dataset preprocessed with the code below.\\nimport re\\nimport emoji\\nfrom soynlp.normalizer import repeat_normalize\\n\\nemojis = ''.join(emoji.UNICODE_EMOJI.keys())\\npattern = re.compile(f'[^ .â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/KcBERT_Pre-Training_Corpus."},
  {"name":"kowiki20220620","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bongsoo/kowiki20220620","creator_name":"ko","creator_url":"https://huggingface.co/bongsoo","description":"-kowiki202206 1ì¤„ ë§ë­‰ì¹˜\\n"},
  {"name":"bongevalsmall","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bongsoo/bongevalsmall","creator_name":"ko","creator_url":"https://huggingface.co/bongsoo","description":"\\ní‰ê°€ ë§ë­‰ì¹˜\\n\\n"},
  {"name":"laion2B-multi-korean-subset","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Bingsu/laion2B-multi-korean-subset","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlaion2B-multi-korean-subset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout dataset\\n\\t\\n\\na subset data of laion/laion2B-multi, including only korean\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLisence\\n\\t\\n\\nCC-BY-4.0\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instance\\n\\t\\n\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"Bingsu/laion2B-multi-korean-subset\\\")\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['SAMPLE_ID', 'URL', 'TEXT', 'HEIGHT', 'WIDTH', 'LICENSE', 'LANGUAGE', 'NSFW', 'similarity']â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/laion2B-multi-korean-subset."},
  {"name":"answerable_tydiqa","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/copenlu/answerable_tydiqa","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"answerable-tydiqa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages. \\nAnswerable TyDi QA is an extension of the GoldP subtask of the original TyDi QA dataset to also include unanswertable questions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains a train and a validation set, with 116067 and 13325 examples, respectively. Access them with\\nfrom datasets import load_dataset\\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/answerable_tydiqa."},
  {"name":"tydiqa_copenlu","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/copenlu/tydiqa_copenlu","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tydiqa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\\nin the world. It contains language phenomena that would not be foundâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/tydiqa_copenlu."},
  {"name":"social_science_en_ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bongsoo/social_science_en_ko","creator_name":"ko","creator_url":"https://huggingface.co/bongsoo","description":"\\nì‚¬íšŒê³¼í•™-en-ko ë²ˆì—­ ë§ë­‰ì¹˜\\n\\n"},
  {"name":"news_talk_en_ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bongsoo/news_talk_en_ko","creator_name":"ko","creator_url":"https://huggingface.co/bongsoo","description":"\\në‰´ìŠ¤&ì¼ìƒëŒ€í™” en-ko ë²ˆì—­ ë§ë­‰ì¹˜\\n\\n"},
  {"name":"miracl-corpus","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/miracl/miracl-corpus","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MIRACL Corpus\\n\\t\\n\\nMIRACL ğŸŒğŸ™ŒğŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\\nThis dataset contains the collection data of the 16 \\\"known languages\\\". The remaining 2 \\\"surprise languages\\\" will not be released until later.\\nThe corpus for each language is prepared from aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus."},
  {"name":"wikipedia-korean-20221001","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lcw99/wikipedia-korean-20221001","creator_name":"Chang W Lee","creator_url":"https://huggingface.co/lcw99","description":"20240501 update\\n"},
  {"name":"laion2b_multi_korean_subset_with_image","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Bingsu/laion2b_multi_korean_subset_with_image","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlaion2b_multi_korean_subset_with_image\\n\\t\\n\\nimg2datasetì„ í†µí•´ ë‹¤ìš´ë¡œë“œì— ì„±ê³µí•œ Bingsu/laion2B-multi-korean-subset ì´ë¯¸ì§€ë¥¼ ì •ë¦¬í•œ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\\nì´ë¯¸ì§€ëŠ” 9,800,137ì¥ì…ë‹ˆë‹¤.\\nì´ë¯¸ì§€ëŠ” ì§§ì€ ìª½ ê¸¸ì´ê°€ 256ì´ ë˜ë„ë¡ ë¦¬ì‚¬ì´ì¦ˆ ë˜ì—ˆìœ¼ë©°, í’ˆì§ˆ 100ì¸ webpíŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ ë˜ì—ˆìŠµë‹ˆë‹¤.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1. datasets\\n\\t\\n\\n>>> from datasets import load_dataset\\n\\n>>> dataset = load_dataset(\\\"Bingsu/laion2b_multi_korean_subset_with_image\\\", streaming=True, split=\\\"train\\\")\\n\\n>>> dataset.features\\n{'image': Image(decode=True, id=None),\\n 'text':â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/laion2b_multi_korean_subset_with_image."},
  {"name":"TyDiP","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Genius1237/TyDiP","creator_name":"Genius1237","creator_url":"https://huggingface.co/Genius1237","description":"The TyDiP dataset is a dataset of requests in conversations between wikipedia editors\\nthat have been annotated for politeness. The splits available below consists of only\\nrequests from the top 25 percentile (polite) and bottom 25 percentile (impolite) of\\npoliteness scores. The English train set and English test set that are\\nadapted from the Stanford Politeness Corpus, and test data in 9 more languages\\n(Hindi, Korean, Spanish, Tamil, French, Vietnamese, Russian, Afrikaans, Hungarian) \\nwas annotated by us."},
  {"name":"wikipedia-22-12-ko-embeddings","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-ko-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikipedia (ko) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded Wikipedia (ko) using the cohere.ai multilingual-22-12 embedding model.\\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEmbeddings\\n\\t\\n\\nWe compute for title+\\\" \\\"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-ko-embeddings."},
  {"name":"korfin-asc","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/amphora/korfin-asc","creator_name":"GUIJIN SON","creator_url":"https://huggingface.co/amphora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KorFin-ABSA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe KorFin-ASC is an extension of KorFin-ABSA including 8818 samples with (aspect, polarity) pairs annotated. \\nThe samples were collected from KLUE-TC and \\nanalyst reports from Naver Finance. \\nAnnotation of the dataset is described in the paper Removing Non-Stationary Knowledge From Pre-Trained Language Models for Entity-Level Sentiment Classification in Finance.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupportedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/amphora/korfin-asc."},
  {"name":"miracl-ko-corpus-22-12","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Cohere/miracl-ko-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (ko) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-ko-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ko-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL ğŸŒğŸ™ŒğŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ko-corpus-22-12."},
  {"name":"miracl-ko-queries-22-12","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Cohere/miracl-ko-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (ko) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-ko-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ko-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL ğŸŒğŸ™ŒğŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ko-queries-22-12."},
  {"name":"lingnli-multi-mt","license":"BSD 2-Clause \"Simplified\" License","language":"en","url":"https://huggingface.co/datasets/maximoss/lingnli-multi-mt","creator_name":"Maximos Skandalis","creator_url":"https://huggingface.co/maximoss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis repository contains a collection of machine translations of LingNLI dataset \\ninto 9 different languages (Bulgarian, Finnish, French, Greek, Italian, Korean, Lithuanian, Portuguese, Spanish). The goal is to predict textual entailment (does sentence A \\nimply/contradict/neither sentence B), which is a classification task (given two sentences, \\npredict one of three labels). It is here formatted in the same manner asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maximoss/lingnli-multi-mt."},
  {"name":"aihub_corpus_expertise","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/wisenut-nlp-team/aihub_corpus_expertise","creator_name":"wisenut-nlp","creator_url":"https://huggingface.co/wisenut-nlp-team","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"corpus_professional_field\\\"\\n\\t\\n\\nì „ë¬¸ë¶„ì•¼ ë§ë­‰ì¹˜\\n"},
  {"name":"ko-alpaca","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/royboy0416/ko-alpaca","creator_name":"Roy Bang","creator_url":"https://huggingface.co/royboy0416","description":"Testing purpose only. Do not redistribute. \\nOriginal contents: [url] https://huggingface.co/datasets/tatsu-lab/alpaca\\nKo-alpaca: [url] https://github.com/Beomi/KoAlpaca/blob/main/ko_alpaca_data.json\\n"},
  {"name":"mquad-v1","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/danielpark/mquad-v1","creator_name":"Minwoo Park","creator_url":"https://huggingface.co/danielpark","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMQuAD\\n\\t\\n\\nThe Medical Question and Answering dataset(MQuAD) has been refined, including the following datasets. You can download it through the Hugging Face dataset. Use the DATASETS method as follows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Guide\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"danielpark/MQuAD-v1\\\")\\n\\nMedical Q/A datasets gathered from the following websites.\\n\\neHealth Forum\\niCliniq\\nQuestion Doctors\\nWebMD\\nData was gathered at the 5th of May 2017.\\n\\nThe MQuAD provides embeddedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/danielpark/mquad-v1."},
  {"name":"OIG-small-chip2-ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/heegyu/OIG-small-chip2-ko","creator_name":"Heegyu Kim","creator_url":"https://huggingface.co/heegyu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"OIG-small-chip2-ko\\\"\\n\\t\\n\\n\\n210282 items\\nOriginal Dataset: OIG-small-chip2 dataset from https://laion.ai/blog/oig-dataset/\\nTranslated by Google Translate API\\n\\nexample\\n{\\n \\\"user\\\": \\\"Is there a good way to clean up my credit report?\\\\n\\\\n\\\",\\n \\\"chip2\\\": \\\"That depends on why your credit score is low. Would you like to share more details about your situation?\\\",\\n \\\"index\\\": 210272,\\n \\\"user_translated\\\": \\\"ë‚´ ì‹ ìš© ë³´ê³ ì„œë¥¼ ì •ë¦¬í•˜ëŠ” ì¢‹ì€ ë°©ë²•ì´ ìˆìŠµë‹ˆê¹Œ?\\\\n\\\\n\\\",\\n \\\"chip2_translated\\\": \\\"ì‹ ìš© ì ìˆ˜ê°€ ë‚®ì€ ì´ìœ ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/heegyu/OIG-small-chip2-ko."},
  {"name":"MedGPT-5k-ko","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/mncai/MedGPT-5k-ko","creator_name":"MindsAndCompany","creator_url":"https://huggingface.co/mncai","description":"mncai/MedGPT-5k-ko dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"kin_med_2M","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/mncai/kin_med_2M","creator_name":"MindsAndCompany","creator_url":"https://huggingface.co/mncai","description":"mncai/kin_med_2M dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"rsd-ists-2016","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016","creator_name":"University of Zurich, Department of Computational Linguistics","creator_url":"https://huggingface.co/ZurichNLP","description":"Training and test data for the task of Recognizing Semantic Differences (RSD).\\nSee the paper for details on how the dataset was created, and see our code at https://github.com/ZurichNLP/recognizing-semantic-differences for an example of how to use the data for evaluation.\\nThe data are derived from the SemEval-2016 Task 2 for Interpretable Semantic Textual Similarity organized by Agirre et al. (2016).\\nThe original URLs of the data are:\\n\\nTrain:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016."},
  {"name":"KorfinQA","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mssongit/KorfinQA","creator_name":"SONGMINSANG","creator_url":"https://huggingface.co/mssongit","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFinQA í•œêµ­ì–´ ë²ˆì—­ë³¸\\n\\t\\n\\nQuestion, Answer ì´ 6252 Rows\\n"},
  {"name":"openassistant-guanaco-ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nlpai-lab/openassistant-guanaco-ko","creator_name":"NLP & AI - Korea University","creator_url":"https://huggingface.co/nlpai-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKorean translation of Guanaco via the DeepL API\\nNote: There are cases where multilingual data has been converted to monolingual data during batch translation to Korean using the API.\\nBelow is Guanaco's README.\\n\\nThis dataset is a subset of the Open Assistant dataset, which you can find here: https://huggingface.co/datasets/OpenAssistant/oasst1/tree/main\\nThis subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nlpai-lab/openassistant-guanaco-ko."},
  {"name":"docs_on_several_languages","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages","creator_name":"Aleksey Timoshin","creator_url":"https://huggingface.co/AlekseyScorpi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"docs_on_several_languages\\\"\\n\\t\\n\\nThis dataset is a collection of different images in different languages.\\nThe set includes the following languages: Azerbaijani, Belorussian, Chinese, English, Estonian, Finnish, Georgian, Japanese, Korean, Kazakh, Latvian, Lithuanian, Mongolian, Norwegian, Polish, Russian, Ukranian.\\nEach language has a corresponding class label defined. At least 100 images in the entire dataset are allocated per class. This dataset was originally usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages."},
  {"name":"SREDFM","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Babelscape/SREDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\\\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\\nFirst, we present SRED\\\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \\nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \\nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\\\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}."},
  {"name":"KLUE_mrc_negative_train","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/KimuGenie/KLUE_mrc_negative_train","creator_name":"Uijin Kim","creator_url":"https://huggingface.co/KimuGenie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"KLUE_mrc_negative_train\\\"\\n\\t\\n\\nKLUE mrc train datasetì— BM25ì„ ì´ìš©í•´ì„œ questionì— ëŒ€í•œ hard negative text 20ê°œë¥¼ ì¶”ê°€í•œ ë°ì´í„°ì…ë‹ˆë‹¤.\\nBM25ë¡œ hard negative textë¥¼ ì°¾ì•˜ê³ , preprocessingì„ í†µí•´ ì¤‘ë³µ ë°ì´í„°ë¥¼ ìµœëŒ€í•œ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.\\nì‚¬ìš©í•œ BM25ì˜ ì •ë³´ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\\n\\n\\t\\n\\t\\t\\ntop-k\\ntop-10\\ntop-20\\ntop-50\\ntop-100\\n\\n\\n\\t\\t\\naccuracy(%)\\n92.1\\n95.0\\n97.1\\n98.8\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{park2021klue,\\n      title={KLUE: Korean Language Understanding Evaluation}, \\n      author={Sungjoon Park and Jihyung Moon and Sungdong Kim and Won Ikâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KimuGenie/KLUE_mrc_negative_train."},
  {"name":"bluehouse-national-petition","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dev7halo/bluehouse-national-petition","creator_name":"dev7halo","creator_url":"https://huggingface.co/dev7halo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\npip install datasets\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"dev7halo/bluehouse-national-petition\\\")\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['number', 'ì œëª©', 'ë‹µë³€ìƒíƒœ', 'ì°¸ì—¬ì¸ì›', 'ì¹´í…Œê³ ë¦¬', 'ì²­ì›ì‹œì‘', 'ì²­ì›ë§ˆê°', 'ì²­ì›ë‚´ìš©', 'ë‹µë³€ì›ê³ '],\\n        num_rows: 451513\\n    })\\n})\\n\\n# dataset['train'][0]\\n{'number': 605368,\\n 'ì œëª©': 'ë‹¹ì‹ ì˜ ë‚˜ë¼ì—ì„œ í–‰ë³µí–ˆìŠµë‹ˆë‹¤.',\\n 'ë‹µë³€ìƒíƒœ': 'ì²­ì›ì¢…ë£Œ',\\n 'ì°¸ì—¬ì¸ì›': '15,350',\\n 'ì¹´í…Œê³ ë¦¬': 'ê¸°íƒ€',\\n 'ì²­ì›ì‹œì‘': '2022-05-09',\\n 'ì²­ì›ë§ˆê°': '2022-06-08',\\n 'ì²­ì›ë‚´ìš©': 'ìš°ì„  ì´ ì²­ì›ì€ 14ì‹œê°„ë§Œâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dev7halo/bluehouse-national-petition."},
  {"name":"korean-mcfaq","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dev7halo/korean-mcfaq","creator_name":"dev7halo","creator_url":"https://huggingface.co/dev7halo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\npip install datasets\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"dev7halo/korean-mcfaq\\\")\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['Unnamed: 0', 'ì œëª©', 'ë“±ë¡ì¼', 'ì§ˆë¬¸', 'ë‹µë³€'],\\n        num_rows: 2452\\n    })\\n})\\n\\n# dataset['train'][0]\\n{'Unnamed: 0': 0,\\n 'ì œëª©': \\\"'ì–¸ì  ê°€', 'ì–¸ì  ê°€ëŠ”'ì˜ í‘œí˜„\\\",\\n 'ë“±ë¡ì¼': '2019. 12. 6. ',\\n 'ì§ˆë¬¸': '\\\\n\\\\t\\\\t \\\\n\\\\t\\\\t \\\\n\\\\t\\\\t\\\"ì €ëŠ” ì–¸ì  ê°€ ê°„í˜¸ì‚¬ê°€ ë˜ê³  ì‹¶ì–´ìš”.\\\"ì™€ ê°™ì´ ì“¸ ë•Œ, ë¯¸ë˜ì˜ ë¶ˆíŠ¹ì •í•œ ë•Œë¥¼ ë‚˜íƒ€ë‚´ëŠ” \\\\'ì–¸ì  ê°€\\\\'ë¼ëŠ” ë‹¨ì–´ë¥¼ \\\\'ì–¸ì  ê°€ëŠ”\\\\'ì´ë¼ê³  ì¨ë„ ë˜ë‚˜ìš”? \\\\'ì–¸ì  ê°€\\\\'ê°€ í‘œì¤€ì–´ì¸ ê²ƒ ê°™ì€ë°, ë’¤ì— \\\\'ëŠ”\\\\'ì„ ì“´â€¦ See the full description on the dataset page: https://huggingface.co/datasets/dev7halo/korean-mcfaq."},
  {"name":"all-scam-spam","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\\n1040 rows of balanced data, consisting of casual conversations and scam emails in â‰ˆ10 languages, were manually collected and annotated by me, with some help from ChatGPT.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSome preprcoessing algorithms\\n\\t\\n\\n\\nspam_assassin.js, followed by spam_assassin.py\\nenron_spam.py\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData composition\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nToâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam."},
  {"name":"empathetic_dialogues_mutli_turn_ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ohilikeit/empathetic_dialogues_mutli_turn_ko","creator_name":"JiHwanYoon","creator_url":"https://huggingface.co/ohilikeit","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"í•œêµ­ì–´ ì¼ìƒ ì† ê³µê°í˜• ëŒ€í™” ë°ì´í„°ì…‹(ë©€í‹°-í„´)\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nboostCamp AI Tech 5ê¸° ê³¼ì • ì¤‘ NLP 12ì¡° í›ˆì œì—°ì–´ë“¤ íŒ€ì˜ ìµœì¢… í”„ë¡œì íŠ¸ì—ì„œ ì œì‘í•œ ë°ì´í„°ì…ë‹ˆë‹¤. \\nì¼ìƒ ì† ë‹¤ì–‘í•œ ìƒí™©ì—ì„œ ì‚¬ìš©ìì™€ ì±—ë´‡ ê°„ì˜ ëŒ€í™”ë¥¼ ë‹´ì€ ë°ì´í„°ì…‹ ì…ë‹ˆë‹¤. \\nGPT4, GPT3.5-turboë¡œ ì œì‘ëœ í•©ì„±ë°ì´í„°ì´ë©° ì‹±ê¸€-í„´, 2-í„´, 3-í„´ ëŒ€í™”ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\\në‹µë³€ì€ [ê³µê°ì  í‘œí˜„ - ì¼ë°˜ì ì¸ ëŒ€í™” - ê´€ë ¨ëœ ì§ˆë¬¸] ì˜ í˜•íƒœë¥¼ ê°€ì§‘ë‹ˆë‹¤.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneration Prompt Example(GPT3.5-turbo)\\n\\t\\n\\nTake a close look at the following example and Conditions. Create nine sessions that each of the session is ongoing conversation aboutâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ohilikeit/empathetic_dialogues_mutli_turn_ko."},
  {"name":"Teatime","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/OpenLeecher/Teatime","creator_name":"Peevski","creator_url":"https://huggingface.co/OpenLeecher","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tINFO:\\n\\t\\n\\nThese are the parsed logs from the \\\"teatime logs\\\" xlsx files.\\nEvery user edit or message regeneration makes a new branch in the conversation tree. This leads to message duplication in the 'all_logs.json' file. Every change creates a fresh branch, copying all earlier messages.\\nThe 'longest' files are different. They only contain the longest path from the first to the last message. This approach aims to avoid duplication. Ideally, the '_longest' files should have no repeatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenLeecher/Teatime."},
  {"name":"onepiece-characters","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/yjg30737/onepiece-characters","creator_name":"yjg","creator_url":"https://huggingface.co/yjg30737","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tonepiece-character\\n\\t\\n\\nThis is a dataset created from crawling the One Piece Fandom on 2023-07-08.\\n"},
  {"name":"malicious-website-features-2.4M","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"Important Notice:\\n\\nA subset of the URL dataset is from Kaggle, and the Kaggle datasets contained 10%-15% mislabelled data. See this dicussion I opened for some false positives. I have contacted Kaggle regarding their erroneous \\\"Usability\\\" score calculation for these unreliable datasets.\\nThe feature extraction methods shown here are not robust at all in 2023, and there're even silly mistakes in 3 functions: not_indexed_by_google, domain_registration_length, and age_of_domain.\\n\\n\\n\\nThe featuresâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M."},
  {"name":"skb","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/min9805/skb","creator_name":"min","creator_url":"https://huggingface.co/min9805","description":"min9805/skb dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"MMLU_Korean","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/MMLU_Korean","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"Korean version of MMLU dataset tranlasted by gpt-3.5-turbo.The dataset is used in the research related to MultilingualSIFT. \\n"},
  {"name":"empathetic_dialogues_ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Smoked-Salmon-s/empathetic_dialogues_ko","creator_name":"í›ˆì œì—°ì–´ë“¤ | Smoked_Salmon_s","creator_url":"https://huggingface.co/Smoked-Salmon-s","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"í•œêµ­ì–´ ì¼ìƒ ì† ê³µê°í˜• ëŒ€í™” ë°ì´í„°ì…‹(ë©€í‹°-í„´)\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nboostCamp AI Tech 5ê¸° ê³¼ì • ì¤‘ NLP 12ì¡° í›ˆì œì—°ì–´ë“¤ íŒ€ì˜ ìµœì¢… í”„ë¡œì íŠ¸ì—ì„œ ì œì‘í•œ ë°ì´í„°ì…ë‹ˆë‹¤. \\nì¼ìƒ ì† ë‹¤ì–‘í•œ ìƒí™©ì—ì„œ ì‚¬ìš©ìì™€ ì±—ë´‡ ê°„ì˜ ëŒ€í™”ë¥¼ ë‹´ì€ ë°ì´í„°ì…‹ ì…ë‹ˆë‹¤. \\nGPT4, GPT3.5-turboë¡œ ì œì‘ëœ í•©ì„±ë°ì´í„°ì´ë©° ì‹±ê¸€-í„´, 2-í„´, 3-í„´ ëŒ€í™”ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\\në‹µë³€ì€ [ê³µê°ì  í‘œí˜„ - ì¼ë°˜ì ì¸ ëŒ€í™” - ê´€ë ¨ëœ ì§ˆë¬¸] ì˜ í˜•íƒœë¥¼ ê°€ì§‘ë‹ˆë‹¤.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneration Prompt Example(GPT3.5-turbo)\\n\\t\\n\\nTake a close look at the following example and Conditions. Create nine sessions that each of the session is ongoing conversation aboutâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Smoked-Salmon-s/empathetic_dialogues_ko."},
  {"name":"calculation","license":"\"Do What The F*ck You Want To Public License\"","language":"en","url":"https://huggingface.co/datasets/OzoneAsai/calculation","creator_name":"AsaiTaka","creator_url":"https://huggingface.co/OzoneAsai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Calculation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsize\\n\\t\\n\\n  JSON file: output1.jsonâ‰’1.3GB\\n  ~\\n    output60.json\\n     In total 70 ~ 80GB\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nen: Calculation. Its range will be expanded later.\\nzh: è®¡ç®—ã€‚å…¶èŒƒå›´å°†åœ¨ä»¥åæ‰©å±•ã€‚\\nde: Berechnung. Der Umfang wird spÃ¤ter erweitert werden.\\nru: Ğ Ğ°ÑÑ‡ĞµÑ‚. Ğ•Ğ³Ğ¾ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ±ÑƒĞ´ĞµÑ‚ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½ Ğ¿Ğ¾Ğ·Ğ¶Ğµ.\\nko: ê³„ì‚°. ë²”ìœ„ëŠ” ë‚˜ì¤‘ì— í™•ì¥ë  ê²ƒì…ë‹ˆë‹¤.\\nfr: Calcul. Sa portÃ©e sera Ã©tendue ultÃ©rieurement.\\nja: è¨ˆç®—ã€‚ç¯„å›²ã¯å¾Œã§æ‹¡å¼µã•ã‚Œã¾ã™ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nen:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/OzoneAsai/calculation."},
  {"name":"4typeCalculation","license":"\"Do What The F*ck You Want To Public License\"","language":"en","url":"https://huggingface.co/datasets/OzoneAsai/4typeCalculation","creator_name":"AsaiTaka","creator_url":"https://huggingface.co/OzoneAsai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Calculation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsize\\n\\t\\n\\n  JSON file: output1.jsonâ‰’1.3GB\\n  ~\\n    output60.json\\n     In total 70 ~ 80GB\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nen: Calculation. Its range will be expanded later.\\nzh: è®¡ç®—ã€‚å…¶èŒƒå›´å°†åœ¨ä»¥åæ‰©å±•ã€‚\\nde: Berechnung. Der Umfang wird spÃ¤ter erweitert werden.\\nru: Ğ Ğ°ÑÑ‡ĞµÑ‚. Ğ•Ğ³Ğ¾ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ±ÑƒĞ´ĞµÑ‚ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½ Ğ¿Ğ¾Ğ·Ğ¶Ğµ.\\nko: ê³„ì‚°. ë²”ìœ„ëŠ” ë‚˜ì¤‘ì— í™•ì¥ë  ê²ƒì…ë‹ˆë‹¤.\\nfr: Calcul. Sa portÃ©e sera Ã©tendue ultÃ©rieurement.\\nja: è¨ˆç®—ã€‚ç¯„å›²ã¯å¾Œã§æ‹¡å¼µã•ã‚Œã¾ã™ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nen:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/OzoneAsai/4typeCalculation."},
  {"name":"open-lid-dataset","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/hac541309/open-lid-dataset","creator_name":"Chris Ha","creator_url":"https://huggingface.co/hac541309","description":"This dataset is built from the open source data accompanying \\\"An Open Dataset and Model for Language Identification\\\" (Burchell et al., 2023)\\nThe repository containing the actual data can be found here : https://github.com/laurieburchell/open-lid-dataset.\\nThe license for this recreation itself follows the original upstream dataset as GPLv3+. \\nHowever, individual datasets within it follow each of their own licenses.\\nThe \\\"src\\\" column lists the sources. \\\"lang\\\" column lists the language code inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hac541309/open-lid-dataset."},
  {"name":"QAmeleon","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/imvladikon/QAmeleon","creator_name":"Vladimir Gurevich","creator_url":"https://huggingface.co/imvladikon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"QAmeleon\\\"\\n\\t\\n\\nQAmeleon introduces synthetic multilingual QA data contaning in 8 langauges using PaLM-540B, a large language model. This dataset was generated by prompt tuning PaLM with only five examples per language. We use the synthetic data to finetune downstream QA models leading to improved accuracy in comparison to English-only and translation-based baselines. \\nData available at https://storage.googleapis.com/qameleon/qamelon_pt_accepted.csv \\nMore details canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/imvladikon/QAmeleon."},
  {"name":"KOpen-platypus","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/kyujinpy/KOpen-platypus","creator_name":"KyujinHan","creator_url":"https://huggingface.co/kyujinpy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKOpenPlatypus: Korean Translation dataset about Open-Platypus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKorean Translation Method\\n\\t\\n\\nI use DeepL-pro-API and selenium. \\nIt takes about 140h times.+) ë°ì´í„°ì…‹ ì´ìš©í•˜ì…”ì„œ ëª¨ë¸ì´ë‚˜ ë°ì´í„°ì…‹ì„ ë§Œë“œì‹¤ ë•Œ, ê°„ë‹¨í•œ ì¶œì²˜ í‘œê¸°ë¥¼ í•´ì£¼ì‹ ë‹¤ë©´ ì—°êµ¬ì— í° ë„ì›€ì´ ë©ë‹ˆë‹¤ğŸ˜­ğŸ˜­\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKorean Translation post-processing\\n\\t\\n\\n\\n\\n\\n\\n\\nAnd also, applying post-processing. See below lists. (*ì•½ 2000ê°œ ì´ìƒì˜ ì½”ë“œ ê´€ë ¨ ë°ì´í„°ë¥¼ ìˆ˜ì‘ì—…ìœ¼ë¡œ ìˆ˜ì •í•¨)\\n\\nì½”ë“œì™€ ì£¼ì„ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ê³ , ì„¤ëª… ë¶€ë¶„ë§Œ í•œêµ­ì–´ë¡œ ìˆ˜ì •\\n1ë²ˆê³¼ ë”ë¶ˆì–´ì„œ, Python, Java, Cpp, xml ë“±ë“± ê²°ê³¼ë“¤ì€ ì „ë¶€ ê¸°ì¡´ì˜ ë°ì´í„° í˜•íƒœë¡œ ìµœëŒ€í•œ ë³´ì¡´\\në‹¨ì¼ ìˆ«ìì™€ ì˜ì–´ëŠ”â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kyujinpy/KOpen-platypus."},
  {"name":"EverythingLM-data-V2-Ko","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ziozzang/EverythingLM-data-V2-Ko","creator_name":"Jioh L. Jung","creator_url":"https://huggingface.co/ziozzang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTranslated into Korean with DeepL\\n\\t\\n\\nAll Texts are translated with DeepL. (Machine Translated.)\\n\\nIssue: some data items are missing, cause of DeepL plan and processing method. I use very cheap plan and all datas are merged into single file and splitted by few code and hand.\\nThis is sample/test processing of data set creation with DeepL.\\n\\n\\nOriginal Dataset: totally-not-an-llm/EverythingLM-data-V2\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEverythingLM V2 Dataset\\n\\t\\n\\nEverythingLM V2 is a diverse instruct datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ziozzang/EverythingLM-data-V2-Ko."},
  {"name":"Korean_Wikipedia_Dataset_for_GPT2_August_2022","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/eaglewatch/Korean_Wikipedia_Dataset_for_GPT2_August_2022","creator_name":"Yongwoo Jeong","creator_url":"https://huggingface.co/eaglewatch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for korean_wikipedia_dataset_for_GPT2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEntire Korean language Wikipedia data for GPT-2 training as of August 1st, 2022.\\nemail: oscar.eaglewatch@gmail.com\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is to make a pre-trained GPT-2 Korean model\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nKorean\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nTrain wikipedia article count: 334420\\nvalidation wikipedia article count: 83605\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fieldsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/eaglewatch/Korean_Wikipedia_Dataset_for_GPT2_August_2022."},
  {"name":"Korean_Wikipedia_Dataset_for_GPT2_August_2022","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/eaglewatch/Korean_Wikipedia_Dataset_for_GPT2_August_2022","creator_name":"Yongwoo Jeong","creator_url":"https://huggingface.co/eaglewatch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for korean_wikipedia_dataset_for_GPT2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEntire Korean language Wikipedia data for GPT-2 training as of August 1st, 2022.\\nemail: oscar.eaglewatch@gmail.com\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is to make a pre-trained GPT-2 Korean model\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nKorean\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nTrain wikipedia article count: 334420\\nvalidation wikipedia article count: 83605\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fieldsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/eaglewatch/Korean_Wikipedia_Dataset_for_GPT2_August_2022."},
  {"name":"llama-2-ko-law","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jaejoo/llama-2-ko-law","creator_name":"hong","creator_url":"https://huggingface.co/jaejoo","description":"jaejoo/llama-2-ko-law dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"embedding-test","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/daeell/embedding-test","creator_name":"Kim Dael","creator_url":"https://huggingface.co/daeell","description":"daeell/embedding-test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"HAE-RAE-COT-1.5M","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/HAERAE-HUB/HAE-RAE-COT-1.5M","creator_name":"HAE-RAE","creator_url":"https://huggingface.co/HAERAE-HUB","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"HAE-RAE-COT-1.5M\\\"\\n\\t\\n\\nHAE-RAE-COT-1.5M is a dataset encompassing 1,586,688 samples of questions paired with CoT (Chain of Thought) rationales. \\nThe majority of this dataset is a translation of samples from the CoT-Collection, with a portion of samples derived from Korean datasets through the utilization of the gpt-3.5-turbo API. The translation of the CoT-Collection was carried out using the NLLB 600M model.\\nTo the best of our knowledge, HAE-RAE-COT-1.5M representsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HAERAE-HUB/HAE-RAE-COT-1.5M."},
  {"name":"text_coordinates_regions","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Regions\\\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\\nKey Features:\\n\\nTextual Data: The dataset contains 500,000 text samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions."},
  {"name":"openassistant-guanaco-EOS","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Guanaco Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using \\\"### Human:\\\" AND \\\"### Assistant\\\" as the beginning and end of sequence tokens.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then slightly adjusted to:\\n\\n\\nif a row ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS."},
  {"name":"sharegpt-deduplicated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated","creator_name":"Caterina Lacerra","creator_url":"https://huggingface.co/CaterinaLac","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a deduplicated version of sharegpt4. \\nThe deduplication process has two steps:\\n\\nThe literal duplicates (both input and outputs) are removed\\nThe remaining (5749) instances are embedded with the SentenceTransformer library (\\\"paraphrase-multilingual-mpnet-base-v2\\\" model).\\nThen, we compute the cosine similarity among all the possible pairs, and consider paraphrases thoseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated."},
  {"name":"openassistant-llama-style","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Llama 2 Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then filtered to:\\n\\n\\nreplace instances of '### Human:' with '[INST]'\\nreplaceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style."},
  {"name":"MultiJail","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail","creator_name":"Language Technology Lab at Alibaba DAMO Academy","creator_url":"https://huggingface.co/DAMO-NLP-SG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Jailbreak Challenges in Large Language Models\\n\\t\\n\\nThis repo contains the data for our paper \\\"Multilingual Jailbreak Challenges in Large Language Models\\\".\\n[Github repo]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAnnotation Statistics\\n\\t\\n\\nWe collected a total of 315 English unsafe prompts and annotated them into nine non-English languages. The languages were categorized based on resource availability, as shown below:\\nHigh-resource languages: Chinese (zh), Italian (it), Vietnamese (vi)\\nMedium-resourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail."},
  {"name":"mqnli","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SachinPatel248/mqnli","creator_name":"Patel","creator_url":"https://huggingface.co/SachinPatel248","description":"SachinPatel248/mqnli dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"K-HATERS","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/humane-lab/K-HATERS","creator_name":"HUMANE Lab","creator_url":"https://huggingface.co/humane-lab","description":""},
  {"name":"finance-legal-mrc_merged-table","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/didi0di/finance-legal-mrc_merged-table","creator_name":"Yeongji Noh","creator_url":"https://huggingface.co/didi0di","description":"\\n\\t\\n\\t\\t\\n\\t\\të°ì´í„°ì…‹ ì„¤ëª…\\n\\t\\n\\nshchoice/finance-legal-mrc ë°ì´í„° ì¤‘ ë³‘í•©ëœ í…Œì´ë¸”ë§Œ ì¶”ì¶œí•œ ë’¤ ì´ë¯¸ì§€ì™€ í•¨ê»˜ ì €ì¥í•œ ë°ì´í„°ì…ë‹ˆë‹¤.\\n"},
  {"name":"MagiciteBabel","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/iarcanar/MagiciteBabel","creator_name":"teerapat","creator_url":"https://huggingface.co/iarcanar","description":"\\n\\t\\n\\t\\t\\n\\t\\tAPI Key Configuration\\n\\t\\n\\n\\nRename file open for edit api key.env to .env\\nEdit .env file and paste your API key:ANTHROPIC_API_KEY='your_claude_api_key'\\nOPENAI_API_KEY='your_openai_api_key'\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tMagicBabel for FFXIV\\n\\t\\n\\n[th] à¹‚à¸›à¸£à¹à¸à¸£à¸¡à¹à¸›à¸¥à¸šà¸—à¸ªà¸™à¸—à¸™à¸²à¹ƒà¸™à¹€à¸à¸¡à¸ªà¹Œ FFXIV à¹à¸šà¸š realtime à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸”à¸¢à¸„à¸™à¹„à¸—à¸¢\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nMagicBabel is a real-time translation tool specifically designed for Final Fantasy XIV (FFXIV), created by a non-native English speaker to enhance the storytelling experience. Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iarcanar/MagiciteBabel."},
  {"name":"Magpie-Ko-Qwen2.5-Reasoning-Raw","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/werty1248/Magpie-Ko-Qwen2.5-Reasoning-Raw","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSystem Message\\n\\t\\n\\n\\nKorean Reasoning Template\\n\\n\\\"pre_query_template\\\": \\\"<|im_start|>system\\\\në‹¹ì‹ ì€ ì•Œë¦¬ë°”ë°” í´ë¼ìš°ë“œì—ì„œ ë§Œë“  Qwenì…ë‹ˆë‹¤. ë‹¹ì‹ ì€ ìœ ìš©í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\\\\nuserê°€ ë…¼ë¦¬ì ì¸ ë‹¤ë‹¨ê³„ì˜ ì¶”ë¡  ê³¼ì •ì´ í•„ìš”í•œ ë³µì¡í•œ ë¬¸ì œë¥¼ ë‚´ë©´, assistantëŠ” í•œêµ­ì–´ë¡œ ë‹¨ê³„ì ìœ¼ë¡œ í’€ì´ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.<|im_end|>\\\\n<|im_start|>user\\\\n\\\"\\n\\n\\n(Original)\\n\\n\\\"pre_query_template\\\": \\\"<|im_start|>system\\\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\\\n<|im_start|>user\\\\n\\\"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel\\n\\t\\n\\n\\nQuestion: Qwen/Qwen2.5-32B-Instructâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/werty1248/Magpie-Ko-Qwen2.5-Reasoning-Raw."},
  {"name":"glaiveai-reflection-v1-ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/youjunhyeok/glaiveai-reflection-v1-ko","creator_name":"ìœ ì¤€í˜","creator_url":"https://huggingface.co/youjunhyeok","description":"Translated glaiveai/reflection-v1 using nayohan/llama3-instrucTrans-enko-8b.\\nFor this dataset, we only used data that is 5000 characters or less in length and has language of English.\\nThanks for @Magpie-Align and @nayohan.\\n"},
  {"name":"glaiveai-reflection-v1-ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/youjunhyeok/glaiveai-reflection-v1-ko","creator_name":"ìœ ì¤€í˜","creator_url":"https://huggingface.co/youjunhyeok","description":"Translated glaiveai/reflection-v1 using nayohan/llama3-instrucTrans-enko-8b.\\nFor this dataset, we only used data that is 5000 characters or less in length and has language of English.\\nThanks for @Magpie-Align and @nayohan.\\n"},
  {"name":"poplyrics-1k","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ashuwhy/poplyrics-1k","creator_name":"Ashutosh Sharma","creator_url":"https://huggingface.co/ashuwhy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPop Lyrics Dataset\\n\\t\\n\\nThis dataset contains up to 1,000 pop songs with their lyrics, songwriters, genres, and other relevant metadata. The data was collected from Spotify and Genius.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\ntrack_name: Name of the song.\\nalbum: Album name.\\nrelease_date: Release date of the song.\\nsong_length: Duration of the song.\\npopularity: Popularity score from Spotify.\\nsongwriters: List of songwriters.\\nartist: Name of the artist.\\nlyrics: Cleaned lyrics of the song.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ashuwhy/poplyrics-1k."},
  {"name":"clustering_klue_mrc_context_domain","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/on-and-on/clustering_klue_mrc_context_domain","creator_name":"khlee","creator_url":"https://huggingface.co/on-and-on","description":"This dataset is a processed and redistributed version of the KLUE dataset and follows the KLUE license.\\n(https://huggingface.co/datasets/klue/klue)\\nIt is a dataset for embedding evaluation, processed using the categories from the KLUE-MRC dataset.\\n\\nTask: Clustering\\nDomain: Game / Media / Automotive / Finance / Real Estate / Education\\n\\n========================================Original Citation===========================================\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n  @misc{park2021klueâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/on-and-on/clustering_klue_mrc_context_domain."},
  {"name":"RecoTravRoute","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/GMLBsst/RecoTravRoute","creator_name":"S S T","creator_url":"https://huggingface.co/GMLBsst","description":"GMLBsst/RecoTravRoute dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"product-database","license":"GNU Affero General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Food Facts Database\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is ğŸŠ Open Food Facts?\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tA food products database\\n\\t\\n\\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\\n\\n\\t\\n\\t\\t\\n\\t\\tMade by everyone\\n\\t\\n\\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database."},
  {"name":"test_4","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4."},
  {"name":"ko-tree-conversation","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CarrotAI/ko-tree-conversation","creator_name":"CarrotCarrot","creator_url":"https://huggingface.co/CarrotAI","description":"í•œêµ­ì–´ë¡œ ì´ë£¨ì–´ì§„ ë©€í‹°í„´ ëŒ€í™”ì…‹ ì…ë‹ˆë‹¤.\\n@article{tree-multi,\\n  title={CarrotAI/tree-multi Card},\\n  author={CarrotAI (L, GEUN)},\\n  year={2024},\\n  url = {https://huggingface.co/datasets/CarrotAI/tree-multi}\\n}\\n\\n"},
  {"name":"Bespoke-Stratos-17k-KoEnKo","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/werty1248/Bespoke-Stratos-17k-KoEnKo","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","description":"\\nLet them think in English.\\n\\nEnglish system prompt + Korean question + English thinking + Korean answer\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSystem message changes\\n\\t\\n\\nYour role as an assistant involves thoroughly exploring questions ...(ì¤‘ëµ)...\\n\\n<|begin_of_solution|> {final formatted, precise, and clear solution **written in the same language as the question.**} <|end_of_solution|> ...(í•˜ëµ)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTranslation\\n\\t\\n\\n\\nTranslated with gemini-2.0-flash\\n\\nQuestion\\n\\nReturn your final response within \\\\\\\\boxed{}., Generate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/werty1248/Bespoke-Stratos-17k-KoEnKo."},
  {"name":"BenchMAX_Question_Answering","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from UN Parallel Corpus and xquad.\\nThe haystacks are from UN Parallel Corpus Test and Development Sets and we translate them to other languages by Google Translate.\\nThe multilingual QA data is fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering."},
  {"name":"ko-arena-hard-auto-v0.1","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kkksklsn/ko-arena-hard-auto-v0.1","creator_name":"Park","creator_url":"https://huggingface.co/kkksklsn","description":"qwopqwopë‹˜ì´ ko-arena-hardë¥¼ ë²ˆì—­í•˜ì‹  ë°ì´í„° qwopqwop/ko-arena-hard-auto-v0.1ì— tagë¥¼ ë‹¨ ë°ì´í„°ì…ë‹ˆë‹¤.\\n\\n\\t\\n\\t\\t\\n\\t\\ttag ì •ë³´\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nCategory\\nCount\\nDescription\\n\\n\\n\\t\\t\\nCoding & Debugging\\n279\\nUsers seek help with writing, reviewing, or fixing code in programming.\\n\\n\\nPlanning\\n67\\nUsers need assistance in creating plans or strategies for activities and projects.\\n\\n\\nData analysis\\n31\\nRequests involve interpreting data, statistics, or performing analytical tasks.\\n\\n\\nMath\\n26\\nQueries related to mathematical concepts, problems, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kkksklsn/ko-arena-hard-auto-v0.1."},
  {"name":"M-ABSA","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tM-ABSA\\n\\t\\n\\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Description:\\n\\t\\n\\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\\nAll datasets are stored in the data/ folder:\\n\\nAll dataset contains 7 domains.\\n\\ndomains = [\\\"coursera\\\", \\\"hotel\\\", \\\"laptop\\\", \\\"restaurant\\\", \\\"phone\\\", \\\"sight\\\", \\\"food\\\"]\\n\\n\\nEach dataset contains 21 languages.\\n\\nlangs = [\\\"ar\\\", \\\"da\\\", \\\"de\\\", \\\"en\\\", \\\"es\\\", \\\"fr\\\", \\\"hi\\\", \\\"hr\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA."},
  {"name":"demo","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/eyl45/demo","creator_name":"Ethan","creator_url":"https://huggingface.co/eyl45","description":"eyl45/demo dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"lawdata","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/GyuHyeonWkdWkdMan/lawdata","creator_name":"GYUHYEON","creator_url":"https://huggingface.co/GyuHyeonWkdWkdMan","description":"GyuHyeonWkdWkdMan/lawdata dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Ko-emb-PreView","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jaeyong2/Ko-emb-PreView","creator_name":"jeongjaeyong","creator_url":"https://huggingface.co/jaeyong2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDevelopment Process\\n\\t\\n\\n\\nsource dataset from daje/ko_wiki and maywell/korean_textbooks\\nWe used Qwen/Qwen2-72B-Instruct model to generate answer with COT.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\n\\nQwen/Qwen2.5-72B-Instruct : https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/LICENSE\\nmaywell/korean_textbooks : https://choosealicense.com/licenses/apache-2.0/\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgement\\n\\t\\n\\nThis research is supported by TPU Research Cloud program.\\n"},
  {"name":"webfaq","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\\n\\n   \\n       Overview |\\n       Details  |\\n       Structure  |\\n       Examples |\\n       Considerations |\\n       License |\\n       Citation |\\n       Contact |\\n       Acknowledgement\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq."},
  {"name":"xtreme","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xtreme\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme."},
  {"name":"toxi-text-3M","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\\n\\n\\t\\n\\t\\t\\n\\nToxic\\nNeutral\\nTotal\\n\\n\\n\\t\\t\\nmultilingual-train-deduplicated.csvâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M."},
  {"name":"belebele","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\\n\\t\\n\\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions thatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele."},
  {"name":"librivox-tracks","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\n"},
  {"name":"multilingual-pl-bert","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\\n"},
  {"name":"sib200","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200."},
  {"name":"aya_dataset","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_dataset","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\n\\nCurated by: Contributors of Aya Open Science Intiative.\\n\\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_dataset."},
  {"name":"aya_collection","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_collection","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection."},
  {"name":"aya_evaluation_suite","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\\n\\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) â†’ aya-human-annotated.\\nmachine-translations of handpicked examples into 101 languages â†’â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite."},
  {"name":"CulturaY","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \\nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \\nThis data was used in part to train our SOTAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY."},
  {"name":"aya_collection_language_split","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_collection_language_split","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Collection is a massive multilingual collection consisting of 513 million instancesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection_language_split."},
  {"name":"GlotCC-V1","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
  {"name":"GlotCC-V1","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
  {"name":"muri-it","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it."},
  {"name":"HPLT2.0_cleaned","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned."},
  {"name":"belebele-fleurs","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBelebele-Fleurs\\n\\t\\n\\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\\n\\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30â€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs."},
  {"name":"sib-fleurs","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs."},
  {"name":"2M-Belebele","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2M-Belebele\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\\n\\t\\n\\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \\nThe speech dataset is built from aligning Belebele, Flores200 and Fleursâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele."},
  {"name":"reranker_continuous_filt_max7_train","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReranker training data\\n\\t\\n\\nThis data was generated using 4 steps:\\n\\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \\\"1\\\", \\\"2\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train."},
  {"name":"reranking-datasets-light","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"unkown","creator_url":"https://huggingface.co/abdoelsayed","description":"\\n\\t\\n\\t\\t\\n\\t\\tğŸ”¥ Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation ğŸ”¥\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\\n\\t\\n\\n\\n    \\n    \\n    \\n    \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n    \\n\\n\\n\\nA curated collection of ready-to-use datasets for retrieval and rerankingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light."},
  {"name":"degeneration-html-multilingual","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe Degeneration of the Nation Multilingual Dataset\\n\\t\\n\\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual."},
  {"name":"Synthdog-Multilingual-100","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthdog Multilingual\\n\\t\\n\\n\\n\\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzfâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100."},
  {"name":"high-quality-multilingual-sentences","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tHigh Quality Multilingual Sentences\\n\\t\\n\\n\\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\\n\\nExample row (from the all config):\\n{\\n    \\\"text\\\": \\\"Ø§Ù…Ø§Ù… Ø¬Ù…Ø¹Ù‡ Ø§ØµÙÙ‡Ø§Ù† Ú¯ÙØª: Ù…ÛŒØ²Ø§Ù† Ù†ÛŒØ§Ø² Ø¢Ø¨ Ø´Ø±Ø¨ Ø§ØµÙÙ‡Ø§Ù† Û±Û±.Ûµ Ù…ØªØ± Ù…Ú©Ø¹Ø¨ Ø§Ø³Øª Ú©Ù‡ ØªÙ…Ø§Ù… Ø§Ø³ØªØ§Ù† Ø§ØµÙÙ‡Ø§Ù† Ø±Ø§ Ù¾ÙˆØ´Ø´ Ù…ÛŒØ¯Ù‡Ø¯ Ùˆ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ù†Ù‚Ù„Ø§Ø¨ ÛŒÚ©ÛŒ Ø§Ø² Ù¾ÛŒØ´Ø±ÙØªÙ‡Ø§ Ø¯Ø± Ø­ÙˆØ²Ù‡ Ø¢Ø¨ Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª.\\\",\\n    \\\"fasttext\\\": \\\"fa\\\",\\n    \\\"gcld3\\\": \\\"fa\\\"\\n}\\n\\nFields:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences."},
  {"name":"wikipedia_quality_wikirank","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"WÅ‚odzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy Itâ€™s Important\\n\\t\\n\\n\\nEnhances Trust: For readers andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank."},
  {"name":"multilingual_translation_sft","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"opus_ubuntu","license":"BSD 3-Clause \"New\" or \"Revised\" License","language":"en","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu."},
  {"name":"flores_101","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
  {"name":"wit_base","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base."},
  {"name":"HashtagPrediction","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\\n\\t\\n\\n  \\nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \\n[arXiv]\\n[HuggingFace Models]\\n[Github repo]\\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDownload\\n\\t\\n\\nUse theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction."},
  {"name":"qag_koquad","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/lmqg/qag_koquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Question & answer generation dataset based on SQuAD."},
  {"name":"flores_101","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
  {"name":"xP3x-sample","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities."},
  {"name":"wikianc","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc."},
  {"name":"entity_cs","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EntityCS\\n\\t\\n\\n\\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \\nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \\nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \\nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs."},
  {"name":"MultiCoNER","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/tomaarsen/MultiCoNER","creator_name":"Tom Aarsen","creator_url":"https://huggingface.co/tomaarsen","description":"We present MultiCoNER, a large multilingual dataset for Named Entity Recognition that covers 3 domains (Wiki sentences, questions, and search queries) across 11 languages, as well as multilingual and code-mixing subsets. This dataset is designed to represent contemporary challenges in NER, including low-context scenarios (short and uncased text), syntactically complex entities like movie titles, and long-tail entity distributions. The 26M token dataset is compiled from public resources using techniques such as heuristic-based sentence sampling, template extraction and slotting, and machine translation. We applied two NER models on our dataset: a baseline XLM-RoBERTa model, and a state-of-the-art GEMNET model that leverages gazetteers. The baseline achieves moderate performance (macro-F1=54%), highlighting the difficulty of our data. GEMNET, which uses gazetteers, improvement significantly (average improvement of macro-F1=+30%). MultiCoNER poses challenges even for large pre-trained language models, and we believe that it can help further research in building robust NER systems. MultiCoNER is publicly available at https://registry.opendata.aws/multiconer/ and we hope that this resource will help advance research in various aspects of NER."},
  {"name":"udhr-lid","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUDHR-LID\\n\\t\\n\\nWhy UDHR-LID?\\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \\\"missing\\\" or \\\"?\\\". Also, about 1/3 of the sentences consist only of \\\"articles 1-30\\\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid."},
  {"name":"seamless-align","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to use the data\\n\\t\\n\\nThere are two ways to access the data:\\n\\nVia the Hugging Face Python datasets library\\n\\nScripts coming soonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align."},
  {"name":"WEATHub","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/iamshnoo/WEATHub","creator_name":"Anjishnu Mukherjee","creator_url":"https://huggingface.co/iamshnoo","description":"\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"WEATHub\\\"\\n\\t\\n\\nThis dataset corresponds to the data described in the paper \\\"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\\\"\\naccepted to EMNLP 2023.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)\\nto measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub."},
  {"name":"kor_snli","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/KETI-AIR/kor_snli","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for QASC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC BY 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation INformation\\n\\t\\n\\n@inproceedings{snli:emnlp2015,\\n    Author = {Bowman, Samuel R. and Angeli, Gabor and Potts, Christopher, and Manning, Christopher D.},\\n    Booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)},\\n    Publisher = {Association for Computational Linguistics},\\n    Title =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/KETI-AIR/kor_snli."},
  {"name":"openassistant-falcon","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant Falcon\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using '\\\\Human:' AND '\\\\nAssistant:' to wrap user messages.\\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\\nSample \\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon."},
  {"name":"kor_amazon_polarity","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/KETI-AIR/kor_amazon_polarity","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for amazon_polarity\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC0 1.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation Information\\n\\t\\n\\nMcAuley, Julian, and Jure Leskovec. \\\"Hidden factors and hidden topics: understanding rating dimensions with review text.\\\" In Proceedings of the 7th ACM conference on Recommender systems, pp. 165-172. 2013.\\nXiang Zhang, Junbo Zhao, Yann LeCun. Character-level Convolutional Networks for Text Classification.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/KETI-AIR/kor_amazon_polarity."},
  {"name":"kor_duorc","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/KETI-AIR/kor_duorc","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for duorc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nMIT License\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation Information\\n\\t\\n\\n@inproceedings{DuoRC,\\nauthor = { Amrita Saha and Rahul Aralikatte and Mitesh M. Khapra and Karthik Sankaranarayanan},\\ntitle = {{DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension}},\\nbooktitle = {Meeting of the Association for Computational Linguistics (ACL)},\\nyear = {2018}\\n}\\n\\n"},
  {"name":"lr-sum","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LR-Sum\\n\\t\\n\\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \\nThe data is based onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum."},
  {"name":"kor_web_questions","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/KETI-AIR/kor_web_questions","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WEB_QUESTIONS\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC BY 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation INformation\\n\\t\\n\\n@inproceedings{berant-etal-2013-semantic,\\n    title = \\\"Semantic Parsing on {F}reebase from Question-Answer Pairs\\\",\\n    author = \\\"Berant, Jonathan  and\\n      Chou, Andrew  and\\n      Frostig, Roy  and\\n      Liang, Percy\\\",\\n    booktitle = \\\"Proceedings of the 2013 Conference on Empirical Methods in Natural Languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KETI-AIR/kor_web_questions."},
  {"name":"kor_quarel","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/KETI-AIR/kor_quarel","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Quarel\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC BY 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation INformation\\n\\t\\n\\n@inproceedings{quarel_v1,\\n    title={QuaRel: A Dataset and Models for Answering Questions about Qualitative Relationships},\\n    author={Oyvind Tafjord, Peter Clark, Matt Gardner, Wen-tau Yih, Ashish Sabharwal},\\n    year={2018},\\n    journal={arXiv:1805.05377v1}\\n}\\n\\n"},
  {"name":"kor_qasc","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/KETI-AIR/kor_qasc","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for QASC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC BY 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation INformation\\n\\t\\n\\n@article{allenai:qasc,\\n      author    = {Tushar Khot and Peter Clark and Michal Guerquin and Peter Jansen and Ashish Sabharwal},\\n      title     = {QASC: A Dataset for Question Answering via Sentence Composition},\\n      journal   = {arXiv:1910.11473v2},\\n      year      = {2020},\\n}\\n\\n"},
  {"name":"kor_ropes","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/KETI-AIR/kor_ropes","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ROPES\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC BY 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation INformation\\n\\t\\n\\n@inproceedings{Lin2019ReasoningOP,\\n  title={Reasoning Over Paragraph Effects in Situations},\\n  author={Kevin Lin and Oyvind Tafjord and Peter Clark and Matt Gardner},\\n  booktitle={MRQA@EMNLP},\\n  year={2019}\\n}\\n\\n"},
  {"name":"kor_cosmos_qa","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/KETI-AIR/kor_cosmos_qa","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for cosmos_qa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC BY 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation INformation\\n\\t\\n\\n@inproceedings{huang-etal-2019-cosmos,\\n    title = \\\"Cosmos {QA}: Machine Reading Comprehension with Contextual Commonsense Reasoning\\\",\\n    author = \\\"Huang, Lifu  and\\n      Le Bras, Ronan  and\\n      Bhagavatula, Chandra  and\\n      Choi, Yejin\\\",\\n    booktitle = \\\"Proceedings of the 2019 Conference on Empirical Methodsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KETI-AIR/kor_cosmos_qa."},
  {"name":"kor_quartz","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/KETI-AIR/kor_quartz","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for quartz\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC BY 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation Information\\n\\t\\n\\n@InProceedings{quartz,\\n  author = {Oyvind Tafjord and Matt Gardner and Kevin Lin and Peter Clark},\\n  title = {\\\"QUARTZ: An Open-Domain Dataset of Qualitative Relationship\\nQuestions\\\"},\\n  year = {\\\"2019\\\"},\\n}\\n\\n"},
  {"name":"kor_squad_v2","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/KETI-AIR/kor_squad_v2","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for squad_v2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC BY SA 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation Information\\n\\t\\n\\n@article{2016arXiv160605250R,\\n       author = {{Rajpurkar}, Pranav and {Zhang}, Jian and {Lopyrev},\\n                 Konstantin and {Liang}, Percy},\\n        title = \\\"{SQuAD: 100,000+ Questions for Machine Comprehension of Text}\\\",\\n      journal = {arXiv e-prints},\\n         year = 2016,\\n          eid =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/KETI-AIR/kor_squad_v2."},
  {"name":"Orca-DPO-Pairs-KO","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Ja-ck/Orca-DPO-Pairs-KO","creator_name":"Kim JaeCheol","creator_url":"https://huggingface.co/Ja-ck","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOrca-DPO-Pairs-KO\\n\\t\\n\\nIntel/orca_dpo_pais ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•œ ë°ì´í„°ì„¸íŠ¸ ì…ë‹ˆë‹¤.\\në²ˆì—­ì€ maywell/Syntra-7B-v0.3-Translation ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ë²ˆì—­ í›„ ì¼ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ë¼ì¸ì€ ì‚­ì œí–ˆê¸° ë•Œë¬¸ì— ì›ë³¸ê³¼ ì°¨ì´ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n"},
  {"name":"ntx_llm_instructions","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format\\n\\t\\n\\nThis dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license and conditions.\\nIt contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you utilize this dataset version, feel free to cite/footnote this huggingface dataset repo, but please also cite the original datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions."},
  {"name":"ntx_llm_inst_korean","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_korean","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format - Korean subset\\n\\t\\n\\nThis dataset is a format conversion for the Korean data from the original NTX into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nFor the original NTX dataset, the conversion to the Aya instructions format, or more details, please refer to the full dataset in instruction form (https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions) or to the paperâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_korean."},
  {"name":"ml-kge","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/davanstrien/ml-kge","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMKGE: Multilingual Knowledge Graph Enhancement\\n\\t\\n\\nnote this dataset card was copied from this GitHub Repository\\nTask Description |\\nWikiKGE-10 |\\nEvaluation |\\nPaper |\\nCitation |\\nLicense\\nRecent work in Natural Language Processing and Computer Vision has been leveraging textual information -- e.g., entity names and descriptions -- available in knowledge graphs to ground neural models to high-quality structured data.\\nHowever, when it comes to non-English languages, both quantity andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/davanstrien/ml-kge."},
  {"name":"oasst2_top1_chat_format","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\\n\\t\\n\\nExport of oasst2 only top 1 threads in huggingface chat format\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScript\\n\\t\\n\\nThe convert script can be find here\\n"},
  {"name":"oaast_rm_full_jieba","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"å°è¯•è§£å†³\\\"llm repetition problem\\\"ï¼Œä½¿ç”¨åˆ†è¯æ¨¡å‹å¯¹oaastè¯­æ–™è¿›è¡Œâ€œç»“å·´åŒ–â€æ•°æ®å¢å¼ºï¼Œæä¾›æ›´å¼ºçš„é‡å¤å†…å®¹æ‹’ç»æ•ˆæœã€‚\\nAttempts to solve the \\\"llm repetition problem\\\" by using a segmentation model to enhance the oaast corpus with \\\"stuttering\\\" data to provide stronger rejection of duplicate content.\\nå…¶æ¬¡ï¼Œè¿˜è¿‡æ»¤æ‰äº†æ‰€æœ‰è‡ªæˆ‘è®¤çŸ¥çš„å¾®è°ƒæ ·æœ¬ã€‚\\nSecond, it also filters out all the fine-tuned samples of self-cognition.\\nfiles:\\n\\noaast_rm_full_jieba.jsonl : word level repeat\\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\\n\\n"},
  {"name":"language-dataset","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","description":"\\n"},
  {"name":"kor-hate-sentence","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/SJ-Donald/kor-hate-sentence","creator_name":"SJ.KIM","creator_url":"https://huggingface.co/SJ-Donald","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSJ-Donald/kor-hate-sentence\\n\\t\\n\\nSJ-Donald/kor-hate-sentence is merged dataset from fllow\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasets\\n\\t\\n\\n\\nsmilegate-ai/kor_unsmile\\nkorean-hate-speech\\nCurse-detection-data\\nkorean-malicious-comments-dataset\\n\\nMerge datasets from above and drop duplicates.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use\\n\\t\\n\\nfrom datasets import load_dataset\\n\\nds = load_dataset(\\\"SJ-Donald/kor-hate-sentence\\\")\\nprint(ds)\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['ë¬¸ì¥', 'hate', 'clean', 'labels'],\\n        num_rows:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SJ-Donald/kor-hate-sentence."},
  {"name":"MM-Eval","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/prometheus-eval/MM-Eval","creator_name":"prometheus-eval","creator_url":"https://huggingface.co/prometheus-eval","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Meta-EVALuation benchmark (MM-Eval)\\n\\t\\n\\n\\nğŸ‘¨â€ğŸ’»Code\\n|\\nğŸ“„Paper\\n|\\nğŸ¤— MMQA\\n\\n\\nMM-Eval is a multilingual meta-evaluation benchmark consisting of five core subsetsâ€”Chat, Reasoning, Safety, Language Hallucination, and Linguisticsâ€”spanning 18 languages and a Language Resource subset spanning 122 languages for a broader analysis of language effects. \\n\\nDesign ChoiceIn this work, we minimize the inclusion of translated samples, as mere translation may alter existing preferences dueâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/prometheus-eval/MM-Eval."},
  {"name":"KMA-term","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/junyeong-nero/KMA-term","creator_name":"Junyeong Song","creator_url":"https://huggingface.co/junyeong-nero","description":"This dataset is generated by crawling KMA medical terms\\n"},
  {"name":"BenchMAX_Rule-based","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Rule-based is a dataset of BenchMAX, sourcing from IFEval, which is a rule-based benchmark for evaluating the instruction following capabilities.\\nWe extend the original dataset to 16 non-English languages by first translating and then manualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based."},
  {"name":"BenchMAX_Model-based","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Model-based is a dataset of BenchMAX, sourcing from m-ArenaHard.\\nWe extend the original English dataset to 16 non-English languages by first translating and then manual post-editing.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based."},
  {"name":"BenchMAX_Multiple_Functions","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Multiple_Functions is a dataset of BenchMAX, sourcing from Nexus.\\nWe translate the standardized queries from English to 16 non-English languages by google Translate.\\nSome special function arguments remain English since the APIs are in English.\\nAllâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions."},
  {"name":"BenchMAX_General_Translation","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_General_Translation is a dataset of BenchMAX.\\nWe collect parallel test data from Flore-200, TED-talk, and WMT24.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech, English, French, German, Hungarian, Japanese, Korean, Serbian, Spanishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation."},
  {"name":"BenchMAX_Domain_Translation","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Domain_Translation is a dataset of BenchMAX.\\nWe collect the domain parallel data from other tasks in BenchMAX.\\nEach sample contains one or three human-annotated translations.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech, Englishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation."},
  {"name":"megawika-report-generation","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika for Report Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. \\nThis datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation."},
  {"name":"Verified-Camel-KO","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kuotient/Verified-Camel-KO","creator_name":"Jisoo Kim","creator_url":"https://huggingface.co/kuotient","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVerified-Camel-KO\\n\\t\\n\\nì´ ë°ì´í„°ì…‹ì€ https://huggingface.co/datasets/LDJnr/Verified-Camel ì˜ í•œêµ­ì–´ ë²ˆì—­ì…ë‹ˆë‹¤.\\nGPT4 Turboë¡œ ë²ˆì—­í•œ ë’¤, ì•½ê°„ì˜ ìˆ˜ì •ì„ ê±°ì³¤ìŠµë‹ˆë‹¤.\\nì´ ë°ì´í„°ì— ëŒ€í•œ ë°©ì¹¨ì€ ì „ë¶€ ì› ì €ìì˜ ë°©ì¹¨ì„ ë”°ë¦…ë‹ˆë‹¤.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Verified Camel dataset. Just over 100 verified examples, and many more coming soon!\\n\\t\\n\\n\\nComprised of over 100 highly filtered and curated examples from specific portions of CamelAI stem datasets. \\n\\nThese examples are verified to be true by experts in the specific related field, with atleastâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kuotient/Verified-Camel-KO."},
  {"name":"hh-rlhf-ko","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/heegyu/hh-rlhf-ko","creator_name":"Heegyu Kim","creator_url":"https://huggingface.co/heegyu","description":"\\nOriginal Dataset: Anthropic/hh-rlhf\\nTranslation by using maywell/Synatra-7B-v0.3-Translation\\nTranslating in progress...\\n\\n"},
  {"name":"Pontoon-Translations","license":"Mozilla Public License 2.0","language":"en","url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations."},
  {"name":"language_tags","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags."},
  {"name":"Deltacorpus_1.1","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, PortoroÅ¾, Slovenia).\\nChanges in version 1.1: \\n\\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \\n\\nSVM classifier trained on Universal Dependenciesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1."},
  {"name":"linkedin-industry-list","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/fantastic-jobs/linkedin-industry-list","creator_name":"Fantastic.jobs","creator_url":"https://huggingface.co/fantastic-jobs","description":"fantastic-jobs/linkedin-industry-list dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Zeroth-STT-Korean","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/o0dimplz0o/Zeroth-STT-Korean","creator_name":"Michele Phan","creator_url":"https://huggingface.co/o0dimplz0o","description":"\\n\\t\\n\\t\\t\\n\\t\\tZeroth-STT-Korean Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nThis is a shuffled version of the Zeroth-STT-Ko dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\nZeroth-Korean Dataset, created by [Lucas Jo(@Atlas Guide Inc.) and Wonkyum Lee(@Gridspace Inc.)], 2023.\\nAvailable at https://github.com/goodatlas/zeroth under CC-BY-4.0 license.\\nJunhoee/STT_Korean_Dataset_80000 Dataset, created by [Junhoee], 2024.\\nAvailable at https://huggingface.co/datasets/Junhoee/STT_Korean_Dataset_80000\\n"},
  {"name":"MMMLU","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLUâ€™s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increasesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU."},
  {"name":"FineFineWeb-Ko","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jaeyong2/FineFineWeb-Ko","creator_name":"jeongjaeyong","creator_url":"https://huggingface.co/jaeyong2","description":"\\n\\t\\n\\t\\t\\n\\t\\tDevelopment Process\\n\\t\\n\\n\\nsource dataset from m-a-p/FineFineWeb-test\\nWe used Qwen/Qwen2-72B-Instruct model to translate.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLicense\\n\\t\\n\\n\\nQwen/Qwen2.5-72B-Instruct : https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/LICENSE\\nm-a-p/FineFineWeb-test : https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/apache-2.0.md\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgement\\n\\t\\n\\nThis research is supported by TPU Research Cloud program.\\n"},
  {"name":"domeggook_faq","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/gng-taejin/domeggook_faq","creator_name":"taejin kim","creator_url":"https://huggingface.co/gng-taejin","description":"gng-taejin/domeggook_faq dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"medmcqa_ko_translated","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/koohack/medmcqa_ko_translated","creator_name":"SeungHyun Park","creator_url":"https://huggingface.co/koohack","description":"koohack/medmcqa_ko_translated dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"RAG-Evaluation-Dataset-KO","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/datalama/RAG-Evaluation-Dataset-KO","creator_name":"DongWook Kim","creator_url":"https://huggingface.co/datalama","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Reconstructed RAG Evaluation Dataset (KO)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\në³¸ ë°ì´í„°ì…‹ì€ allganize/RAG-Evaluation-Dataset-KOë¥¼ ê¸°ë°˜ìœ¼ë¡œ PDF íŒŒì¼ì„ í¬í•¨í•˜ë„ë¡ ì¬êµ¬ì„±í•œ í•œêµ­ì–´ í‰ê°€ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤. ì›ë³¸ ë°ì´í„°ì…‹ì—ì„œëŠ” PDF íŒŒì¼ì˜ ê²½ë¡œë§Œ ì œê³µë˜ì–´ ìˆ˜ë™ìœ¼ë¡œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•˜ëŠ” ë¶ˆí¸í•¨ì´ ìˆì—ˆê³ , ì¼ë¶€ PDF íŒŒì¼ì˜ ê²½ë¡œê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ë¬¸ì œë¥¼ ë³´ì™„í•˜ê¸° ìœ„í•´ PDF íŒŒì¼ì„ í¬í•¨í•œ ë°ì´í„°ì…‹ì„ ì¬êµ¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nRAG Evaluation: ë³¸ ë°ì´í„°ëŠ” í•œêµ­ì–´ RAG íŒŒì´í”„ë¼ì¸ì— ëŒ€í•œ E2E Evaluationì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is in Korean (ko).\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/datalama/RAG-Evaluation-Dataset-KO."},
  {"name":"triumvirat","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/trium-hj/triumvirat","creator_name":"Hyungji, Lee","creator_url":"https://huggingface.co/trium-hj","description":"trium-hj/triumvirat dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"V1Q","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q."},
  {"name":"synthetic_financial_report_korean","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nmixx-fin/synthetic_financial_report_korean","creator_name":"nmixx-financial-nlp-lab","creator_url":"https://huggingface.co/nmixx-fin","description":"nmixx-fin/synthetic_financial_report_korean dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"otpensource_dataset","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/hateslopacademy/otpensource_dataset","creator_name":"hateslop_academy","creator_url":"https://huggingface.co/hateslopacademy","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for otpensource_dataset\\n\\t\\n\\nThis dataset contains curated information about fashion items, focusing on various categories, subcategories, genders, seasons, and unique features. It is intended for use in AI applications related to fashion recommendation systems, trend analysis, and image-to-text generation.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset includes 8,998 examples of Korean Mushinsa fashion data, each with detailed attributes such asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hateslopacademy/otpensource_dataset."},
  {"name":"otpensource_dataset","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/hateslopacademy/otpensource_dataset","creator_name":"hateslop_academy","creator_url":"https://huggingface.co/hateslopacademy","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for otpensource_dataset\\n\\t\\n\\nThis dataset contains curated information about fashion items, focusing on various categories, subcategories, genders, seasons, and unique features. It is intended for use in AI applications related to fashion recommendation systems, trend analysis, and image-to-text generation.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset includes 8,998 examples of Korean Mushinsa fashion data, each with detailed attributes such asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hateslopacademy/otpensource_dataset."},
  {"name":"multilingual_translation_gen_binarized","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"ko-o3-mini-high-aime-2022_4","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/CarrotAI/ko-o3-mini-high-aime-2022_4","creator_name":"CarrotCarrot","creator_url":"https://huggingface.co/CarrotAI","description":"openaiì˜ o3-mini high ë¥¼ ì´ìš©í•˜ì—¬ ìƒì„±í•˜ì˜€ìŠµë‹ˆë‹¤.\\nì°¸ê³ í•˜ì‹œê³  ì‚¬ìš©ë°”ëë‹ˆë‹¤.\\n"},
  {"name":"Judgement-De-Identification-Result","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ducut91/Judgement-De-Identification-Result","creator_name":"lim eul young","creator_url":"https://huggingface.co/ducut91","description":"ë²•ì› íŒê²°ë¬¸ ë¹„ì‹ë³„ ëª¨ë¸ì˜ ì„±ëŠ¥ ê²°ê³¼ì…ë‹ˆë‹¤.\\n\\n\\t\\n\\t\\t\\n\\t\\tSOTA ê¸‰ LLMì„ í™œìš©í•œ ë²•ì› íŒê²°ë¬¸ ê°œì¸ì •ë³´ ë¹„ì‹ë³„ ì„±ëŠ¥(Few-shot ì„±ëŠ¥)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nëª¨ë¸\\nì •í™•ë„\\nì¬í˜„ìœ¨\\nF1 ì ìˆ˜\\n\\n\\n\\t\\t\\nGPT-4o(2024-08-06)\\n97.82\\n99.66\\n98.74\\n\\n\\nQwen2.5-Max\\n96.46\\n95.83\\n96.14\\n\\n\\nDeepSeek-V3\\n98.73\\n98.92\\n98.81\\n\\n\\nGemini-2.0-Flash\\n99.38\\n95.78\\n97.55\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t7~8Bê¸‰ sLLMì˜ íŒŒì¸íŠœë‹ ì „í›„ ë²•ì› íŒê²°ë¬¸ ê°œì¸ì •ë³´ ë¹„ì‹ë³„ ì„±ëŠ¥\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nëª¨ë¸\\níŒŒì¸íŠœë‹ ì „\\n\\n\\níŒŒì¸íŠœë‹ í›„\\n\\n\\n\\n\\n\\t\\t\\nì •í™•ë„\\nì¬í˜„ìœ¨\\nF1 ì ìˆ˜\\nì •í™•ë„\\nì¬í˜„ìœ¨\\nF1 ì ìˆ˜\\n\\n\\n\\nEXAONE-3.5-7.8B-Instruct\\n68.26\\n67.89\\n68.08\\n98.59\\n94.4896.49\\n\\n\\nMinistral-8B-Instruct-2410\\n35.6\\n4.33\\n7.72\\n99.07\\n98.32\\n98.70â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ducut91/Judgement-De-Identification-Result."},
  {"name":"system-rag-instruct-ko-sample","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CarrotAI/system-rag-instruct-ko-sample","creator_name":"CarrotCarrot","creator_url":"https://huggingface.co/CarrotAI","description":"CarrotAI/system-rag-instruct-ko-sample dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Emilia-YODAS","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mrfakename/Emilia-YODAS","creator_name":"mrfakename","creator_url":"https://huggingface.co/mrfakename","description":"A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.\\nhttps://huggingface.co/datasets/amphion/Emilia-Dataset\\n"},
  {"name":"aihub_llm_development_qa","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AtwoM/aihub_llm_development_qa","creator_name":"AtwoM","creator_url":"https://huggingface.co/AtwoM","description":"This is the subset of the í•œêµ­ì–´ ì„±ëŠ¥ì´ ê°œì„ ëœ ì´ˆê±°ëŒ€AI ì–¸ì–´ëª¨ë¸ ê°œë°œ ë° ë°ì´í„° dataset from AIHUB. \\nIt contains extracted SFT label data, formatted for supervised fine-tuning.\\n"},
  {"name":"HPLT2.0_cleaned","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned."},
  {"name":"DC_inside_comments","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Dasool/DC_inside_comments","creator_name":"DasolChoi","creator_url":"https://huggingface.co/Dasool","description":"\\n\\t\\n\\t\\t\\n\\t\\tDC_inside_comments\\n\\t\\n\\nThis dataset contains 110,000 raw comments collected from DC Inside. It is intended for unsupervised learning or pretraining purposes.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nData Type: Unlabeled raw comments\\nNumber of Examples: 110,000\\nSource: DC Inside\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tRelated Dataset\\n\\t\\n\\nFor labeled data and multi-task annotated examples, please refer to the KoMultiText dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to Load the Dataset\\n\\t\\n\\nfrom datasets import load_dataset\\n\\n# Load the unlabeled datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Dasool/DC_inside_comments."},
  {"name":"clustering_klue_mrc_ynat_title","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/on-and-on/clustering_klue_mrc_ynat_title","creator_name":"khlee","creator_url":"https://huggingface.co/on-and-on","description":"This dataset is a processed and redistributed version of the KLUE dataset and follows the KLUE license.\\n(https://huggingface.co/datasets/klue/klue)\\nIt is a dataset for embedding evaluation, processed using the categories from the KLUE-mrc & KLUE-ynat dataset.\\n\\nTask: Clustering\\nNews_category: IT/Science, Sports, Media/Culture, Ecomomy/Finance, Real Estate\\n\\n========================================Original Citation===========================================\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/on-and-on/clustering_klue_mrc_ynat_title."},
  {"name":"H-colqwen","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/luke-kr/H-colqwen","creator_name":"YongHyun Kwon","creator_url":"https://huggingface.co/luke-kr","description":"luke-kr/H-colqwen dataset hosted on Hugging Face and contributed by the HF Datasets community"}
];
