const data_for_domain_logic = 
[
	{"name":"panlex","keyword":"lojban","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex."},
	{"name":"ChatML-Capybara","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-Capybara","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"LDJnr/Capybara in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"LDJnr/Capybara\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = []\\n    conversationColumn = columns[\\\"conversation\\\"]\\n\\n    for i in range(len(conversationColumn)):\\n        messages.append({\\n            \\\"role\\\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-Capybara."},
	{"name":"LOGIC-701","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hivaze/LOGIC-701","creator_name":"Sergey Bratchikov","creator_url":"https://huggingface.co/hivaze","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLOGIC-701 Benchmark\\n\\t\\n\\nThis is a synthetic and filtered dataset for benchmarking large language models (LLMs). It consists of 701 medium and hard logic puzzles with solutions on 10 distinct topics.\\nA feature of the dataset is that it tests exclusively logical/reasoning abilities, offering only 5 answer options. There are no or very few tasks in the dataset that require external knowledge about events, people, facts, etc.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThis benchmark is also part of an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hivaze/LOGIC-701."},
	{"name":"distilabel-capybara-kto-15k-binarized","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla/distilabel-capybara-kto-15k-binarized","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCapybara-KTO 15K binarized\\n\\t\\n\\n\\nA KTO signal transformed version of the highly loved Capybara-DPO 7K binarized, A DPO dataset built with distilabel atop the awesome LDJnr/Capybara\\n\\n\\nThis is a preview version to collect feedback from the community. v2 will include the full base dataset and responses from more powerful models.\\n\\n\\n    \\n\\n\\n\\n  \\n    \\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy KTO?\\n\\t\\n\\nThe KTO paper states:\\n\\nKTO matches or exceeds DPO performance at scales from 1B to 30B parameters.1 That is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/argilla/distilabel-capybara-kto-15k-binarized."},
	{"name":"panlex-meanings","keyword":"lojban","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings."},
	{"name":"ParaNames","keyword":"lojban","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames."},
	{"name":"flo","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/florianhoenicke/flo","creator_name":"Florian H√∂nicke","creator_url":"https://huggingface.co/florianhoenicke","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tflo Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"general domain\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the flo model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import load_dataset\\n\\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/florianhoenicke/flo."},
	{"name":"BAAI_bge-large-en-v1_5-05062024-m8dn-webapp","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-m8dn-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBAAI_bge-large-en-v1_5-05062024-m8dn-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"general domain\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the BAAI_bge-large-en-v1_5-05062024-m8dn-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-m8dn-webapp."},
	{"name":"Kapibara","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alban-labs/Kapibara","creator_name":"Albanian Labs","creator_url":"https://huggingface.co/alban-labs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKapibara: Albanian Multi-turn Conversation Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKapibara is a comprehensive Albanian language dataset designed for multi-turn conversations. It contains over 5,300 entries covering a wide range of topics including physics, biology, mathematics, chemistry, culture, and logic. The dataset is aimed at improving text generation and question-answering capabilities in the Albanian language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\nThe dataset supports the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alban-labs/Kapibara."},
	{"name":"llm-complex-reasoning-train-qwen2-72b-instruct-correct","keyword":"logical reasoning","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/llm-complex-reasoning-train-qwen2-72b-instruct-correct","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\n\\nData Seed from Âü∫‰∫éÂ∞ÅÈó≠‰∏ñÁïåÂÅáËÆæÁöÑÂ§çÊùÇÈÄªËæëÊé®ÁêÜ\\nGenerate from Qwen2-72B-Instruct with prompt\\ntrain.jsonl for Êé®ÁêÜÁ≠îÊ°àÂíåÈ¢òÁõÆÁ≠îÊ°à‰∏ÄËá¥, no_train.jsonlÊé®ÁêÜÁ≠îÊ°àÂíåÈ¢òÁõÆÁ≠îÊ°à‰∏ç‰∏ÄËá¥\\nÊ≥®: È¢òÁõÆÁ≠îÊ°à‰∏ç‰∏ÄÂÆöÊ≠£Á°Æ\\n\\n"},
	{"name":"CleverBoi","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/CleverBoi","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCleverBoi\\n\\t\\n\\nThe CleverBoi Collection is based on a number of data sets that emphasize logic, inference, empathy, math and coding.\\nThe data set has been formatted to follow the alpaca format (instruction + input -> output) when fine tuning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Sets\\n\\t\\n\\nThe source data sets used in the CleverBoi Collection are listed below, ordered by size.\\n\\nKK04/LogicInference_OA\\nmlabonne/Evol-Instruct-Python-26k\\ngarage-bAInd/Open-Platypus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/theprint/CleverBoi."},
	{"name":"CoreReasoning","keyword":"logical reasoning","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayjays132/CoreReasoning","creator_name":"Phillip Holland","creator_url":"https://huggingface.co/ayjays132","description":"\\n  üåü Core Reasoning Dataset üåü\\n  \\n  Overview\\n  \\n    Welcome to the Core Reasoning Dataset‚Äîa meticulously crafted collection of prompts, contexts, outputs, and reasoning types. This dataset is designed to push the boundaries of text-generation models, enabling them to excel in logical reasoning, ethical problem-solving, and contextual understanding.\\n  \\n\\n  ‚ú® Dataset Features\\n  \\n    \\n      Input: A question or prompt requiring critical thinking or creative problem-solving.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayjays132/CoreReasoning."},
	{"name":"CoreReasoningPrime","keyword":"logical reasoning","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayjays132/CoreReasoningPrime","creator_name":"Phillip Holland","creator_url":"https://huggingface.co/ayjays132","description":"\\n  üåü Core Reasoning Prime Dataset üåü\\n  \\n  üåå Ultimate Overview\\n  \\n    Welcome to the Core Reasoning Prime Dataset‚Äîa pioneering collection designed for next-generation AI models. Crafted to cultivate logical reasoning, creative problem-solving, ethical thinking, and beyond, this dataset sets the benchmark for intelligence training.\\n  \\n\\n  ‚ú® Revolutionary Features\\n  \\n    \\n      üîçInput: Engaging prompts designed to challenge AI‚Äôs reasoning and creativity.\\n    \\n    \\n      üß†Context: Enriched‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayjays132/CoreReasoningPrime."},
	{"name":"LOGIC-701-instruct","keyword":"logic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/evilfreelancer/LOGIC-701-instruct","creator_name":"Pavel Zloi","creator_url":"https://huggingface.co/evilfreelancer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLOGIC-701 (instruct)\\n\\t\\n\\nBased on https://huggingface.co/datasets/hivaze/LOGIC-701\\nSources https://github.com/EvilFreelancer/LOGIC-701-instruct\\n"},
	{"name":"RelatLogic","keyword":"logic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shb777/RelatLogic","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"RelatLogic: A Dataset for Comparative and Conditional Reasoning\\nThis is a comparative logic and conditional reasoning dataset. \\nEach data point has a premise, question, answer, reasoning and attribute.\\nPlease cite this dataset using the provided BibTeX if you find it useful.\\n@misc {sb_2025,\\n    author       = { {SB} },\\n    title        = { RelatLogic (Revision 15b1922) },\\n    year         = 2025,\\n    url          = { https://huggingface.co/datasets/shb777/RelatLogic },\\n    doi          = {‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shb777/RelatLogic."},
	{"name":"CleverBoi-Data-20k","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/CleverBoi-Data-20k","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"theprint/CleverBoi-Data-20k dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"dpo-merged","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CultriX/dpo-merged","creator_name":"CultriX","creator_url":"https://huggingface.co/CultriX","description":"CultriX/dpo-merged dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"dpo-merged-binarized","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CultriX/dpo-merged-binarized","creator_name":"CultriX","creator_url":"https://huggingface.co/CultriX","description":"CultriX/dpo-merged-binarized dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Spurline","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Spurline","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Spurline is a dataset containing complex responses, emphasizing logical reasoning and using Shining Valiant's friendly, magical personality style.\\nThe 2024-10-30 version contains:\\n\\n10.7k rows of synthetic queries, using randomly selected prompts from migtissera/Synthia-v1.5-I and responses generated using Llama 3.1 405b Instruct.\\n\\nThis dataset contains synthetically generated data and has not been subject to manual review.\\n"},
	{"name":"SWAP","keyword":"logic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sxiong/SWAP","creator_name":"Siheng Xiong","creator_url":"https://huggingface.co/sxiong","description":"\\n\\t\\n\\t\\t\\n\\t\\tSWAP: A Synthetic Dataset for Complex Reasoning with Trajectories and Process Supervision\\n\\t\\n\\nThis repository contains the data for the paper Deliberate Reasoning for LLMs as Structure-aware Planning with Accurate World Model.\\nSWAP (Structure-aware Planning) solves complex reasoning by introducing a Generator-Discriminator architecture, and incorporates structural information to guide the reasoning process and provides a soft verification mechanism over the steps.\\nWe generate the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sxiong/SWAP."},
	{"name":"MathVista","keyword":"logical-reasoning","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI4Math/MathVista","creator_name":"AI for Math Reasoning","creator_url":"https://huggingface.co/AI4Math","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MathVista\\n\\t\\n\\n\\nDataset Description\\nPaper Information\\nDataset Examples\\nLeaderboard\\nDataset Usage\\nData Downloading\\nData Format\\nData Visualization\\nData Source\\nAutomatic Evaluation\\n\\n\\nLicense\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMathVista is a consolidated Mathematical reasoning benchmark within Visual contexts. It consists of three newly created datasets, IQTest, FunctionQA, and PaperQA, which address the missing visual domains and are tailored to evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI4Math/MathVista."},
	{"name":"Puffin","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/Puffin","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Puffin dataset. Exactly 3,000 examples with each response created using GPT-4.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPLEASE USE THE NEWER VERSION OF PUFFIN CALLED PURE-DOVE, IT IS NO LONGER RECCOMENDED TO USE PUFFIN\\n\\t\\n\\n\\nComprised of over 2,000 multi-turn conversations between GPT-4 and real humans.\\n\\nAverage context length per conversation is over 1,000 tokens. (will measure this more accurately soon)\\n\\nAverage turns per conversation is more than 10. (will measure this more accurately‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Puffin."},
	{"name":"LessWrong-Amplify-Instruct","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/LessWrong-Amplify-Instruct","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official LessWrong-Amplify-Instruct dataset. Over 500 multi-turn examples, and many more coming soon!\\n\\t\\n\\n\\nThis leverages Amplify-Instruct method to extend thousands of scraped Less-Wrong posts into advanced in-depth multi-turn conversations.\\n\\nComprised of over 500 highly filtered multi-turn synthetic conversations.\\n\\nAverage context length per conversation is over 2,000 tokens. (will measure this more accurately soon)\\n\\nSynthetically created using a newly developed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/LessWrong-Amplify-Instruct."},
	{"name":"Pure-Dove","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/Pure-Dove","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Pure-Dove dataset. Over 3K multi-turn examples, and many more coming soon!\\n\\t\\n\\nThis dataset aims to be the largest highest quality cluster of real human back and forth conversations with GPT-4.\\nSteps have even been done to ensure that only the best GPT-4 conversations in comparisons are kept, there are many instances where two GPT-4 responses are rated as equal to eachother or as both bad. We exclude all such responses from Pure Dove and make sure to only‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Pure-Dove."},
	{"name":"Capybara","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/Capybara","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Capybara dataset. Over 10,000 multi-turn examples.\\n\\t\\n\\nCapybara is the culmination of insights derived from synthesis techniques like Evol-instruct (used for WizardLM), Alpaca, Orca, Vicuna, Lamini, FLASK and others.\\nThe single-turn seeds used to initiate the Amplify-Instruct synthesis of conversations are mostly based on datasets that i've personally vetted extensively, and are often highly regarded for their diversity and demonstration of logical robustness‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Capybara."},
	{"name":"distilabel-capybara-dpo-7k-binarized","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla/distilabel-capybara-dpo-7k-binarized","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCapybara-DPO 7K binarized\\n\\t\\n\\n\\nA DPO dataset built with distilabel atop the awesome LDJnr/Capybara\\n\\n\\nThis is a preview version to collect feedback from the community. v2 will include the full base dataset and responses from more powerful models.\\n\\n\\n    \\n\\n\\n\\n  \\n    \\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy?\\n\\t\\n\\nMulti-turn dialogue data is key to fine-tune capable chat models. Multi-turn preference data has been used by the most relevant RLHF works (Anthropic, Meta Llama2, etc.). Unfortunately, there are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/argilla/distilabel-capybara-dpo-7k-binarized."},
	{"name":"Maths-Grade-School","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Maths-Grade-School","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Maths-Grade-School\\nI am releasing large Grade School level Mathematics datatset.\\nThis extensive dataset, comprising nearly one million instructions in JSON format, encapsulates a diverse array of topics fundamental to building a strong mathematical foundation.\\nThis dataset is in instruction format so that model developers, researchers etc. can easily use this dataset.\\nFollowing Fields & sub Fields are covered:\\nCalculus\\nProbability\\nAlgebra\\nLiner Algebra\\nTrigonometry\\nDifferential Equations‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ajibawa-2023/Maths-Grade-School."},
	{"name":"Maths-Grade-School","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pt-sk/Maths-Grade-School","creator_name":"Sathish Kumar","creator_url":"https://huggingface.co/pt-sk","description":"Maths-Grade-School\\nI am releasing large Grade School level Mathematics datatset.\\nThis extensive dataset, comprising nearly one million instructions in JSON format, encapsulates a diverse array of topics fundamental to building a strong mathematical foundation.\\nThis dataset is in instruction format so that model developers, researchers etc. can easily use this dataset.\\nFollowing Fields & sub Fields are covered:\\nCalculus\\nProbability\\nAlgebra\\nLiner Algebra\\nTrigonometry\\nDifferential Equations‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pt-sk/Maths-Grade-School."},
	{"name":"FOL-nli","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tasksource/FOL-nli","creator_name":"tasksource","creator_url":"https://huggingface.co/tasksource","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"FOL-nli\\\"\\n\\t\\n\\nhttps://github.com/sileod/unigram/\\nhttps://arxiv.org/abs/2406.11035\\nCitation:\\n@article{sileo2024scaling,\\n  title={Scaling Synthetic Logical Reasoning Datasets with Context-Sensitive Declarative Grammars},\\n  author={Sileo, Damien},\\n  journal={arXiv preprint arXiv:2406.11035},\\n  year={2024}\\n}\\n\\n"},
	{"name":"LoGiPT-data","keyword":"logical reasoning","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jzfeng/LoGiPT-data","creator_name":"Jamie Jiazhan Feng","creator_url":"https://huggingface.co/jzfeng","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThese are the training data for LoGiPT from NAACL'24 paper: \\\"Language Models can be Deductive Solvers\\\".\\n\\nLoGiPT-data-ProofWriter.json: Instruction-tuning data for LoGiPT constructed from ProofWriter.\\nLoGiPT-data-PrOntoQA.json: Instruction-tuning data for LoGiPT constructed from PrOntoQA.\\n\\nAll training examples are organised in Json-format and Vicuna-style.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIf you find this data helpful, please cite our NAACL'24 paper: (or Arxiv version:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jzfeng/LoGiPT-data."},
	{"name":"GlotCC-V1","keyword":"lojban","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
	{"name":"polymath","keyword":"logical-reasoning","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/him1411/polymath","creator_name":"Himanshu Gupta","creator_url":"https://huggingface.co/him1411","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper Information\\n\\t\\n\\nWe present PolyMATH, a challenging benchmark aimed at evaluating the general cognitive reasoning abilities of MLLMs. \\nPolyMATH comprises 5,000 manually collected high-quality images of cognitive textual and visual challenges across 10 distinct categories, including pattern recognition, spatial reasoning, and relative reasoning. \\nWe conducted a comprehensive, and quantitative evaluation of 15 MLLMs using four diverse prompting strategies, including‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/him1411/polymath."},
	{"name":"Geoperception","keyword":"logical-reasoning","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/euclid-multimodal/Geoperception","creator_name":"Euclid Multimodal LLM","creator_url":"https://huggingface.co/euclid-multimodal","description":"Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Geoperception\\n\\t\\n\\nA Benchmark for Low-level Geometric Perception\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nGeoperception is a benchmark focused specifically on accessing model's low-level visual perception ability in 2D geometry.\\nIt is sourced from the Geometry-3K corpus, which offers precise logical forms for geometric diagrams, compiled from popular‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/euclid-multimodal/Geoperception."},
	{"name":"short_COT_48k","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrankL/short_COT_48k","creator_name":"FrankLiu","creator_url":"https://huggingface.co/FrankL","description":"FrankL/short_COT_48k dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"LogicPro","keyword":"logical reasoning","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jiangjin/LogicPro","creator_name":"jiangjin","creator_url":"https://huggingface.co/jiangjin","description":"\\n  \\n  \\n  LogicPro: Improving Complex Logical Reasoning via Program-Guided Learning\\n\\n\\n\\n  [üìë Paper] ‚Ä¢\\n  [ü§ó HF Dataset] ‚Ä¢\\n  [üëª GitHub]\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData description\\n\\t\\n\\n{\\n  \\\"id\\\": \\\"logicpro_lc679_225531-43120\\\",\\n  \\\"title\\\": \\\"24 Game\\\", # Title of the original leetcode algorithm problem.\\n  \\\"difficulty\\\": \\\"Hard\\\",\\n  \\\"content\\\": \\\"...\\\", # The questions of the original leetcode algorithm problem.\\n  \\\"python\\\": \\\"...\\\", # The original gold python solution\\n  \\\"test_input_string\\\": \\\"...\\\", # Current Test Case‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jiangjin/LogicPro."},
	{"name":"opus_ubuntu","keyword":"lojban","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu."},
	{"name":"probability_words_nli","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/probability_words_nli","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Probing neural language models for understanding of words of estimative probability"},
	{"name":"autotrain-data-lojban-translation","keyword":"lojban","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/woctordho/autotrain-data-lojban-translation","creator_name":"woctordho","creator_url":"https://huggingface.co/woctordho","description":"This is a very early experiment of Lojban machine translation. For a larger dataset, see https://huggingface.co/datasets/smuske/Korpora\\n"},
	{"name":"probability_words_nli","keyword":"logical reasoning","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/probability_words_nli","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Probing neural language models for understanding of words of estimative probability"},
	{"name":"PARARULE-Plus","keyword":"logical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPARARULE-Plus\\n\\t\\n\\nThis is a branch which includes the dataset from PARARULE-Plus Depth=2, Depth=3, Depth=4 and Depth=5. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus."},
	{"name":"PARARULE-Plus-Depth-2","keyword":"logical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-2","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPARARULE-Plus-Depth-2\\n\\t\\n\\nThis is a branch which includes the dataset from PARARULE-Plus Depth=2. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-2."},
	{"name":"PARARULE-Plus-Depth-3","keyword":"logical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-3","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPARARULE-Plus-Depth-3\\n\\t\\n\\nThis is a branch which includes the dataset from PARARULE-Plus Depth=3. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-3."},
	{"name":"PARARULE-Plus-Depth-4","keyword":"logical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-4","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPARARULE-Plus-Depth-4\\n\\t\\n\\nThis is a branch which includes the dataset from PARARULE-Plus Depth=4. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-4."},
	{"name":"PARARULE-Plus-Depth-5","keyword":"logical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-5","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPARARULE-Plus-Depth-5\\n\\t\\n\\nThis is a branch which includes the dataset from PARARULE-Plus Depth=5. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-5."},
	{"name":"mindgames","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/mindgames","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Mindgame dataset\\nCode:\\nhttps://github.com/sileod/llm-theory-of-mind\\nArticle (Accepted at EMNLP 2023 Findings):\\nhttps://arxiv.org/abs/2305.03353\\n@article{sileo2023mindgames,\\n  title={MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic},\\n  author={Sileo, Damien and Lernould, Antoine},\\n  journal={arXiv preprint arXiv:2305.03353},\\n  year={2023}\\n}\\n\\n"},
	{"name":"mindgames","keyword":"logical-reasoning","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/mindgames","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Mindgame dataset\\nCode:\\nhttps://github.com/sileod/llm-theory-of-mind\\nArticle (Accepted at EMNLP 2023 Findings):\\nhttps://arxiv.org/abs/2305.03353\\n@article{sileo2023mindgames,\\n  title={MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic},\\n  author={Sileo, Damien and Lernould, Antoine},\\n  journal={arXiv preprint arXiv:2305.03353},\\n  year={2023}\\n}\\n\\n"},
	{"name":"wikianc","keyword":"lojban","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc."},
	{"name":"Verified-Camel","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/Verified-Camel","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Verified Camel dataset. Just over 100 verified examples, and many more coming soon!\\n\\t\\n\\n\\nComprised of over 100 highly filtered and curated examples from specific portions of CamelAI stem datasets. \\n\\nThese examples are verified to be true by experts in the specific related field, with atleast a bachelors degree in the subject.\\n\\nRoughly 30-40% of the originally curated data from CamelAI was found to have atleast minor errors and/or incoherent questions(as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Verified-Camel."},
	{"name":"Verified-Camel-KO","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuotient/Verified-Camel-KO","creator_name":"Jisoo Kim","creator_url":"https://huggingface.co/kuotient","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVerified-Camel-KO\\n\\t\\n\\nÏù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùÄ https://huggingface.co/datasets/LDJnr/Verified-Camel Ïùò ÌïúÍµ≠Ïñ¥ Î≤àÏó≠ÏûÖÎãàÎã§.\\nGPT4 TurboÎ°ú Î≤àÏó≠Ìïú Îí§, ÏïΩÍ∞ÑÏùò ÏàòÏ†ïÏùÑ Í±∞Ï≥§ÏäµÎãàÎã§.\\nÏù¥ Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú Î∞©Ïπ®ÏùÄ Ï†ÑÎ∂Ä Ïõê Ï†ÄÏûêÏùò Î∞©Ïπ®ÏùÑ Îî∞Î¶ÖÎãàÎã§.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Verified Camel dataset. Just over 100 verified examples, and many more coming soon!\\n\\t\\n\\n\\nComprised of over 100 highly filtered and curated examples from specific portions of CamelAI stem datasets. \\n\\nThese examples are verified to be true by experts in the specific related field, with atleast‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kuotient/Verified-Camel-KO."},
	{"name":"Pontoon-Translations","keyword":"lojban","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations."},
	{"name":"Verified-Camel-zh","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/noobmaster29/Verified-Camel-zh","creator_name":"Victor Sung","creator_url":"https://huggingface.co/noobmaster29","description":"This is a direct Chinese translation using GPT4 of the Verified-Camel dataset. I hope you find it useful. \\nhttps://huggingface.co/datasets/LDJnr/Verified-Camel\\nCitation:\\n@article{daniele2023amplify-instruct,\\n  title={Amplify-Instruct: Synthetically Generated Diverse Multi-turn Conversations for Effecient LLM Training.},\\n  author={Daniele, Luigi and Suphavadeeprasit},\\n  journal={arXiv preprint arXiv:(comming soon)},\\n  year={2023}\\n}\\n\\n"},
	{"name":"Capybara-Converted","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cfahlgren1/Capybara-Converted","creator_name":"Caleb Fahlgren","creator_url":"https://huggingface.co/cfahlgren1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Capybara dataset. Over 10,000 multi-turn examples.\\n\\t\\n\\nCapybara is the culmination of insights derived from synthesis techniques like Evol-instruct (used for WizardLM), Alpaca, Orca, Vicuna, Lamini, FLASK and others.\\nThe single-turn seeds used to intiate the Amplify-Instruct synthesis of conversations are mostly based on datasets that i've personally vetted extensively, and are often highly regarded for their diversity and demonstration of logical robustness and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cfahlgren1/Capybara-Converted."},
	{"name":"language_tags","keyword":"lojban","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"Fran√ßais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog convention‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags."},
	{"name":"capybara-sharegpt","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Doctor-Shotgun/capybara-sharegpt","creator_name":"Doctor Shotgun","creator_url":"https://huggingface.co/Doctor-Shotgun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcapybara-sharegpt\\n\\t\\n\\nLDJnr/Capybara converted to ShareGPT format for use in common training repositories.\\nPlease refer to the original repository's dataset card for more information. All credit goes to the original creator.\\n"},
	{"name":"mm-astronomy","keyword":"logical reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vvsotnikov/mm-astronomy","creator_name":"Vladimir Sotnikov","creator_url":"https://huggingface.co/vvsotnikov","description":"A set of NER-related questions about multimessenger astronomy.\\n"}
]
;
