const data_for_domain_logic = 
[
	{"name":"SocialMaze","keyword":"logical reasoning","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI/SocialMaze","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","description":"\n\t\n\t\t\n\t\tSocialMaze Benchmark\n\t\n\nThis dataset is a component of the SocialMaze: A Benchmark for Evaluating Social Reasoning in Large Language Models project. It specifically features the Hidden Role Deduction task, which we consider one of the most challenging scenarios for testing complex social reasoning, deception handling, and inferential capabilities in Large Language Models (LLMs).\nWe have curated and formatted this task into a convenient question-answering (QA) structure to facilitate… See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/SocialMaze.","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"reddit-logic","keyword":"logic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/reddit-logic","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tReddit Logic: A Dataset for Evaluating Clear and Consistent Reasoning in Natural Language Discourse\n\t\n\nThis dataset studies how people construct and express logical arguments in everyday online discussions. \nUsing posts from Reddit's r/ChangeMyView subreddit, \nthis collection provides well-structured argument analyses that are engaging for humans and machines.\nDataset Construction & Annotation\n\nA curated subset of 10 000 posts was selected from the \"HuggingFaceGECLM/REDDIT_comments\"… See the full description on the dataset page: https://huggingface.co/datasets/agentlans/reddit-logic.","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"SocratesEval","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zhx123/SocratesEval","creator_name":"zz","creator_url":"https://huggingface.co/zhx123","description":"zhx123/SocratesEval dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"compositional_causal_reasoning","keyword":"logical-reasoning","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jmaasch/compositional_causal_reasoning","creator_name":"Jacqueline Maasch","creator_url":"https://huggingface.co/jmaasch","description":"\n    \n    https://jmaasch.github.io/ccr/\n\n\n\nCausal reasoning and compositional reasoning are two core aspirations in AI. Measuring these behaviors requires principled \nevaluation methods. Maasch et al. (2025) consider both behaviors simultaneously, under \nthe umbrella of compositional causal reasoning (CCR): the ability to infer how causal measures compose and, equivalently, how causal quantities propagate \nthrough graphs. CCR.GB applies the theoretical foundations provided by Maasch et al.… See the full description on the dataset page: https://huggingface.co/datasets/jmaasch/compositional_causal_reasoning.","first_N":5,"first_N_keywords":["question-answering","English","gpl-3.0","arxiv:2503.04556","arxiv:2410.03767"],"keywords_longer_than_N":true},
	{"name":"rule-reasoning","keyword":"logical reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/RuleReasoner/rule-reasoning","creator_name":"RuleReasoner","creator_url":"https://huggingface.co/RuleReasoner","description":"\n\t\n\t\t\n\t\tRule Reasoning Datasets\n\t\n\nThis repository contains datasets for rule-based reasoning tasks, organized into two main categories:\n\n\t\n\t\t\n\t\tIn-Distribution (ID) Datasets\n\t\n\n\nar_lsat: Analytical Reasoning from LSAT\nclutrr: CLUTtRR (Compositional Language Understanding and Text-based Relational Reasoning)\nfolio: FOLIO (First-Order Logic in Natural Language)\nlogic_nli: Logic-based Natural Language Inference\nlogical_deduction: Logical Deduction tasks\nlogiqa: LogiQA (Logical Reasoning QA)… See the full description on the dataset page: https://huggingface.co/datasets/RuleReasoner/rule-reasoning.","first_N":5,"first_N_keywords":["reinforcement-learning","text-classification","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"arabic-reasoning-dataset-logic","keyword":"logical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/beetleware/arabic-reasoning-dataset-logic","creator_name":"beetleware","creator_url":"https://huggingface.co/beetleware","description":"\n\t\n\t\t\n\t\tArabic Logical Reasoning Tasks Dataset (Maximum 1000 Tasks)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset comprises a series of logical reasoning tasks designed to evaluate and train artificial intelligence models on understanding and generating logical inferences in the Arabic language. Each task includes a unique identifier, the task type, the task text (a question and a proposed answer), and a detailed solution that outlines the thinking steps and the final answer.\n\n\t\n\t\t\n\t\tData Format\n\t\n\nThe… See the full description on the dataset page: https://huggingface.co/datasets/beetleware/arabic-reasoning-dataset-logic.","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"SynLogic","keyword":"logical reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MiniMaxAI/SynLogic","creator_name":"MiniMax","creator_url":"https://huggingface.co/MiniMaxAI","description":"\n\t\n\t\t\n\t\tSynLogic Dataset\n\t\n\nSynLogic is a comprehensive synthetic logical reasoning dataset designed to enhance logical reasoning capabilities in Large Language Models (LLMs) through reinforcement learning with verifiable rewards. \n\n🐙 GitHub Repo: https://github.com/MiniMax-AI/SynLogic\n📜 Paper (arXiv): https://arxiv.org/abs/2505.19641\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nSynLogic contains 35 diverse logical reasoning tasks with automatic verification capabilities, making it ideal for… See the full description on the dataset page: https://huggingface.co/datasets/MiniMaxAI/SynLogic.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"wikipedia-monthly","keyword":"lojban","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/omarkamali/wikipedia-monthly","creator_name":"Omar Kamali","creator_url":"https://huggingface.co/omarkamali","description":"\n\t\n\t\t\n\t\t🚀 Wikipedia Monthly\n\t\n\nLast updated: July 16, 2025, 22:53 UTC\nThis repository provides monthly, multilingual dumps of Wikipedia, processed and prepared for easy use in NLP projects.\nNOTE: The first run is still in progress and languages are still being processed and uploaded.\n\n\n\t\n\t\t\n\t\t📊 Live Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\n🌍 Languages Available\n341\n\n\n📄 Total Articles\n64.5M\n\n\n💾 Total Size\n205.54 GB\n\n\n\t\n\n\n\n\t\n\t\t\n\t\tWhy Use This Dataset?\n\t\n\n\nFreshness: We run our pipeline monthly… See the full description on the dataset page: https://huggingface.co/datasets/omarkamali/wikipedia-monthly.","first_N":5,"first_N_keywords":["Abkhaz","Achinese","Adyghe","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"Pure-Dove","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/Pure-Dove","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\n\t\n\t\t\n\t\tThis is the Official Pure-Dove dataset. Over 3K multi-turn examples, and many more coming soon!\n\t\n\nThis dataset aims to be the largest highest quality cluster of real human back and forth conversations with GPT-4.\nSteps have even been done to ensure that only the best GPT-4 conversations in comparisons are kept, there are many instances where two GPT-4 responses are rated as equal to eachother or as both bad. We exclude all such responses from Pure Dove and make sure to only include… See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Pure-Dove.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Verified-Camel","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/Verified-Camel","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\n\t\n\t\t\n\t\tThis is the Official Verified Camel dataset. Just over 100 verified examples, and many more coming soon!\n\t\n\n\nComprised of over 100 highly filtered and curated examples from specific portions of CamelAI stem datasets. \n\nThese examples are verified to be true by experts in the specific related field, with atleast a bachelors degree in the subject.\n\nRoughly 30-40% of the originally curated data from CamelAI was found to have atleast minor errors and/or incoherent questions(as determined… See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Verified-Camel.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MathVista","keyword":"logical-reasoning","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI4Math/MathVista","creator_name":"AI for Math Reasoning","creator_url":"https://huggingface.co/AI4Math","description":"\n\t\n\t\t\n\t\tDataset Card for MathVista\n\t\n\n\nDataset Description\nPaper Information\nDataset Examples\nLeaderboard\nDataset Usage\nData Downloading\nData Format\nData Visualization\nData Source\nAutomatic Evaluation\n\n\nLicense\nCitation\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nMathVista is a consolidated Mathematical reasoning benchmark within Visual contexts. It consists of three newly created datasets, IQTest, FunctionQA, and PaperQA, which address the missing visual domains and are tailored to evaluate logical… See the full description on the dataset page: https://huggingface.co/datasets/AI4Math/MathVista.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","text-classification","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"Capybara","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/Capybara","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\n\t\n\t\t\n\t\tThis is the Official Capybara dataset. Over 10,000 multi-turn examples.\n\t\n\nCapybara is the culmination of insights derived from synthesis techniques like Evol-instruct (used for WizardLM), Alpaca, Orca, Vicuna, Lamini, FLASK and others.\nThe single-turn seeds used to initiate the Amplify-Instruct synthesis of conversations are mostly based on datasets that i've personally vetted extensively, and are often highly regarded for their diversity and demonstration of logical robustness and… See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Capybara.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"distilabel-capybara-dpo-7k-binarized","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla/distilabel-capybara-dpo-7k-binarized","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\n\t\n\t\t\n\t\tCapybara-DPO 7K binarized\n\t\n\n\nA DPO dataset built with distilabel atop the awesome LDJnr/Capybara\n\n\nThis is a preview version to collect feedback from the community. v2 will include the full base dataset and responses from more powerful models.\n\n\n    \n\n\n\n  \n    \n  \n\n\n\n\t\n\t\n\t\n\t\tWhy?\n\t\n\nMulti-turn dialogue data is key to fine-tune capable chat models. Multi-turn preference data has been used by the most relevant RLHF works (Anthropic, Meta Llama2, etc.). Unfortunately, there are very few… See the full description on the dataset page: https://huggingface.co/datasets/argilla/distilabel-capybara-dpo-7k-binarized.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"QAMLC","keyword":"logical reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PulkitSahu/QAMLC","creator_name":"Pulkit Sahu","creator_url":"https://huggingface.co/PulkitSahu","description":"\n\t\n\t\t\n\t\tQAMLC: Questions and Answers in Mathematics, Logical and Critical Thinking\n\t\n\nQAMLC is a living, open-source dataset of manually created questions and answers designed to train/benchmark AI in mathematical reasoning, logical thinking, and critical analysis skills for learners up to Grade 6. It currently contains 944 questions with step-by-step solutions and final answers. All content is written in English (UK).\n\n\t\n\t\t\n\t\n\t\n\t\tKey Points\n\t\n\n\nContent Focus: Mathematics, logical reasoning… See the full description on the dataset page: https://huggingface.co/datasets/PulkitSahu/QAMLC.","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Mitakihara-DeepSeek-R1-0528","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Mitakihara-DeepSeek-R1-0528","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Click here to support our open-source dataset and model releases!\nMitakihara-DeepSeek-R1-0528 is a dataset focused on artificial intelligence, testing the limits of DeepSeek R1 0528's AI-reasoning skills!\nThis dataset contains:\n\n16.9k synthetically generated prompts about AI, with all responses generated using DeepSeek R1 0528.\nSubjects include computer science, artificial intelligence, MLOps, LLMs and diffusion models, math and CUDA, cutting-edge and future technologies, complex adaptive and… See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Mitakihara-DeepSeek-R1-0528.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"lojban","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for Opus Ubuntu\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\nE.g.\ndataset = load_dataset(\"opus_ubuntu\", lang1=\"it\", lang2=\"pl\")\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards… See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"autotrain-data-lojban-translation","keyword":"lojban","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/woctordho/autotrain-data-lojban-translation","creator_name":"woctordho","creator_url":"https://huggingface.co/woctordho","description":"This is a very early experiment of Lojban machine translation. For a larger dataset, see https://huggingface.co/datasets/smuske/Korpora\n","first_N":5,"first_N_keywords":["translation","English","Lojban","mit","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"probability_words_nli","keyword":"logical reasoning","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/probability_words_nli","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Probing neural language models for understanding of words of estimative probability","first_N":5,"first_N_keywords":["text-classification","multiple-choice","question-answering","open-domain-qa","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"probability_words_nli","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/probability_words_nli","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Probing neural language models for understanding of words of estimative probability","first_N":5,"first_N_keywords":["text-classification","multiple-choice","question-answering","open-domain-qa","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"PARARULE-Plus","keyword":"logical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","description":"\n\t\n\t\t\n\t\tPARARULE-Plus\n\t\n\nThis is a branch which includes the dataset from PARARULE-Plus Depth=2, Depth=3, Depth=4 and Depth=5. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the… See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus.","first_N":5,"first_N_keywords":["text-classification","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"PARARULE-Plus-Depth-2","keyword":"logical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-2","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","description":"\n\t\n\t\t\n\t\tPARARULE-Plus-Depth-2\n\t\n\nThis is a branch which includes the dataset from PARARULE-Plus Depth=2. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater than… See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-2.","first_N":5,"first_N_keywords":["text-classification","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"PARARULE-Plus-Depth-3","keyword":"logical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-3","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","description":"\n\t\n\t\t\n\t\tPARARULE-Plus-Depth-3\n\t\n\nThis is a branch which includes the dataset from PARARULE-Plus Depth=3. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater than… See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-3.","first_N":5,"first_N_keywords":["text-classification","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"PARARULE-Plus-Depth-4","keyword":"logical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-4","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","description":"\n\t\n\t\t\n\t\tPARARULE-Plus-Depth-4\n\t\n\nThis is a branch which includes the dataset from PARARULE-Plus Depth=4. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater than… See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-4.","first_N":5,"first_N_keywords":["text-classification","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"PARARULE-Plus-Depth-5","keyword":"logical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-5","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","description":"\n\t\n\t\t\n\t\tPARARULE-Plus-Depth-5\n\t\n\nThis is a branch which includes the dataset from PARARULE-Plus Depth=5. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater than… See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-5.","first_N":5,"first_N_keywords":["text-classification","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"mindgames","keyword":"logical-reasoning","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/mindgames","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Mindgame dataset\nCode:\nhttps://github.com/sileod/llm-theory-of-mind\nArticle (Accepted at EMNLP 2023 Findings):\nhttps://arxiv.org/abs/2305.03353\n@article{sileo2023mindgames,\n  title={MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic},\n  author={Sileo, Damien and Lernould, Antoine},\n  journal={arXiv preprint arXiv:2305.03353},\n  year={2023}\n}\n\n","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"mindgames","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/mindgames","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Mindgame dataset\nCode:\nhttps://github.com/sileod/llm-theory-of-mind\nArticle (Accepted at EMNLP 2023 Findings):\nhttps://arxiv.org/abs/2305.03353\n@article{sileo2023mindgames,\n  title={MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic},\n  author={Sileo, Damien and Lernould, Antoine},\n  journal={arXiv preprint arXiv:2305.03353},\n  year={2023}\n}\n\n","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Puffin","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/Puffin","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\n\t\n\t\t\n\t\tThis is the Official Puffin dataset. Exactly 3,000 examples with each response created using GPT-4.\n\t\n\n\n\t\n\t\t\n\t\tPLEASE USE THE NEWER VERSION OF PUFFIN CALLED PURE-DOVE, IT IS NO LONGER RECCOMENDED TO USE PUFFIN\n\t\n\n\nComprised of over 2,000 multi-turn conversations between GPT-4 and real humans.\n\nAverage context length per conversation is over 1,000 tokens. (will measure this more accurately soon)\n\nAverage turns per conversation is more than 10. (will measure this more accurately soon)… See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Puffin.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Verified-Camel-zh","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/noobmaster29/Verified-Camel-zh","creator_name":"Victor Sung","creator_url":"https://huggingface.co/noobmaster29","description":"This is a direct Chinese translation using GPT4 of the Verified-Camel dataset. I hope you find it useful. \nhttps://huggingface.co/datasets/LDJnr/Verified-Camel\nCitation:\n@article{daniele2023amplify-instruct,\n  title={Amplify-Instruct: Synthetically Generated Diverse Multi-turn Conversations for Effecient LLM Training.},\n  author={Daniele, Luigi and Suphavadeeprasit},\n  journal={arXiv preprint arXiv:(comming soon)},\n  year={2023}\n}\n\n","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"lojban","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\n\t\n\t\t\n\t\tDataset Card for WikiAnc\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \nThe code for generating the dataset can be found here.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nwikificiation: The dataset can be used to train a model for Wikification.\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in all 320… See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Capybara-Converted","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cfahlgren1/Capybara-Converted","creator_name":"Caleb Fahlgren","creator_url":"https://huggingface.co/cfahlgren1","description":"\n\t\n\t\t\n\t\tThis is the Official Capybara dataset. Over 10,000 multi-turn examples.\n\t\n\nCapybara is the culmination of insights derived from synthesis techniques like Evol-instruct (used for WizardLM), Alpaca, Orca, Vicuna, Lamini, FLASK and others.\nThe single-turn seeds used to intiate the Amplify-Instruct synthesis of conversations are mostly based on datasets that i've personally vetted extensively, and are often highly regarded for their diversity and demonstration of logical robustness and… See the full description on the dataset page: https://huggingface.co/datasets/cfahlgren1/Capybara-Converted.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"lojban","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Loïck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Français\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.… See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","Pará Arára","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"capybara-sharegpt","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Doctor-Shotgun/capybara-sharegpt","creator_name":"Doctor Shotgun","creator_url":"https://huggingface.co/Doctor-Shotgun","description":"\n\t\n\t\t\n\t\tcapybara-sharegpt\n\t\n\nLDJnr/Capybara converted to ShareGPT format for use in common training repositories.\nPlease refer to the original repository's dataset card for more information. All credit goes to the original creator.\n","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"LOGIC-701","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hivaze/LOGIC-701","creator_name":"Sergey Bratchikov","creator_url":"https://huggingface.co/hivaze","description":"\n\t\n\t\t\n\t\tLOGIC-701 Benchmark\n\t\n\nThis is a synthetic and filtered dataset for benchmarking large language models (LLMs). It consists of 701 medium and hard logic puzzles with solutions on 10 distinct topics.\nA feature of the dataset is that it tests exclusively logical/reasoning abilities, offering only 5 answer options. There are no or very few tasks in the dataset that require external knowledge about events, people, facts, etc.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThis benchmark is also part of an… See the full description on the dataset page: https://huggingface.co/datasets/hivaze/LOGIC-701.","first_N":5,"first_N_keywords":["English","Russian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"LessWrong-Amplify-Instruct","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/LessWrong-Amplify-Instruct","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\n\t\n\t\t\n\t\tThis is the Official LessWrong-Amplify-Instruct dataset. Over 500 multi-turn examples, and many more coming soon!\n\t\n\n\nThis leverages Amplify-Instruct method to extend thousands of scraped Less-Wrong posts into advanced in-depth multi-turn conversations.\n\nComprised of over 500 highly filtered multi-turn synthetic conversations.\n\nAverage context length per conversation is over 2,000 tokens. (will measure this more accurately soon)\n\nSynthetically created using a newly developed pipeline… See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/LessWrong-Amplify-Instruct.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"distilabel-capybara-kto-15k-binarized","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla/distilabel-capybara-kto-15k-binarized","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\n\t\n\t\t\n\t\tCapybara-KTO 15K binarized\n\t\n\n\nA KTO signal transformed version of the highly loved Capybara-DPO 7K binarized, A DPO dataset built with distilabel atop the awesome LDJnr/Capybara\n\n\nThis is a preview version to collect feedback from the community. v2 will include the full base dataset and responses from more powerful models.\n\n\n    \n\n\n\n  \n    \n\t\n\t\t\n\t\tWhy KTO?\n\t\n\nThe KTO paper states:\n\nKTO matches or exceeds DPO performance at scales from 1B to 30B parameters.1 That is, taking a… See the full description on the dataset page: https://huggingface.co/datasets/argilla/distilabel-capybara-kto-15k-binarized.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"lojban","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separate… See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"GeneralLogic","keyword":"logic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Gusarich/GeneralLogic","creator_name":"Daniil Sedov","creator_url":"https://huggingface.co/Gusarich","description":"\n\t\n\t\t\n\t\tGeneralLogic\n\t\n\nGeneralLogic is a dataset of 3,807,700 unique natural language reasoning questions designed for training large language models on general-purpose logical thinking.\nThe dataset avoids math, programming, or trivia-style tasks, and instead focuses on broad, diverse reasoning expressed in plain language. Each question is aligned with one or more of 13 core reasoning types and organized into a tree-like structure.\n\n\n\t\n\t\t\n\t\n\t\n\t\tStructure\n\t\n\nEach entry is a JSON object with… See the full description on the dataset page: https://huggingface.co/datasets/Gusarich/GeneralLogic.","first_N":5,"first_N_keywords":["question-answering","text-generation","mit","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"mm-astronomy","keyword":"logical reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vvsotnikov/mm-astronomy","creator_name":"Vladimir Sotnikov","creator_url":"https://huggingface.co/vvsotnikov","description":"A set of NER-related questions about multimessenger astronomy.\n","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","multiple-choice-qa","English","mit"],"keywords_longer_than_N":true},
	{"name":"ChatML-Capybara","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-Capybara","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"LDJnr/Capybara in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"LDJnr/Capybara\", split=\"train\")\n\ndef format(columns):\n    messages = []\n    conversationColumn = columns[\"conversation\"]\n\n    for i in range(len(conversationColumn)):\n        messages.append({\n            \"role\":… See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-Capybara.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Verified-Camel-KO","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuotient/Verified-Camel-KO","creator_name":"Jisoo Kim","creator_url":"https://huggingface.co/kuotient","description":"\n\t\n\t\t\n\t\tVerified-Camel-KO\n\t\n\n이 데이터셋은 https://huggingface.co/datasets/LDJnr/Verified-Camel 의 한국어 번역입니다.\nGPT4 Turbo로 번역한 뒤, 약간의 수정을 거쳤습니다.\n이 데이터에 대한 방침은 전부 원 저자의 방침을 따릅니다.\n\n\t\n\t\t\n\t\tThis is the Official Verified Camel dataset. Just over 100 verified examples, and many more coming soon!\n\t\n\n\nComprised of over 100 highly filtered and curated examples from specific portions of CamelAI stem datasets. \n\nThese examples are verified to be true by experts in the specific related field, with atleast a… See the full description on the dataset page: https://huggingface.co/datasets/kuotient/Verified-Camel-KO.","first_N":5,"first_N_keywords":["question-answering","text-generation","Korean","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"lojban","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Loïck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds to… See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arbëreshë Albanian"],"keywords_longer_than_N":true},
	{"name":"Pontoon-Translations","keyword":"lojban","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\n\t\n\t\t\n\t\tDataset Card for Pontoon Translations\n\t\n\n\n\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\nSource strings are in English.\nTo avoid rows with values like \"None\" and \"N/A\" being interpreted as missing values, pass the keep_default_na parameter like this:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ayymen/Pontoon-Translations\", keep_default_na=False)… See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","crowdsourced","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"lojban","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)… See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"FOL-nli","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tasksource/FOL-nli","creator_name":"tasksource","creator_url":"https://huggingface.co/tasksource","description":"\n\t\n\t\t\n\t\tDataset Card for \"FOL-nli\"\n\t\n\nhttps://github.com/sileod/unigram/\nhttps://arxiv.org/abs/2406.11035\nCitation:\n@article{sileo2024scaling,\n  title={Scaling Synthetic Logical Reasoning Datasets with Context-Sensitive Declarative Grammars},\n  author={Sileo, Damien},\n  journal={arXiv preprint arXiv:2406.11035},\n  year={2024}\n}\n\n","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","original","English"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-05062024-m8dn-webapp","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-m8dn-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-05062024-m8dn-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-05062024-m8dn-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-m8dn-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"LoGiPT-data","keyword":"logical reasoning","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jzfeng/LoGiPT-data","creator_name":"Jamie Jiazhan Feng","creator_url":"https://huggingface.co/jzfeng","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThese are the training data for LoGiPT from NAACL'24 paper: \"Language Models can be Deductive Solvers\".\n\nLoGiPT-data-ProofWriter.json: Instruction-tuning data for LoGiPT constructed from ProofWriter.\nLoGiPT-data-PrOntoQA.json: Instruction-tuning data for LoGiPT constructed from PrOntoQA.\n\nAll training examples are organised in Json-format and Vicuna-style.\n\n\t\n\t\t\n\t\n\t\n\t\tIf you find this data helpful, please cite our NAACL'24 paper: (or Arxiv version:… See the full description on the dataset page: https://huggingface.co/datasets/jzfeng/LoGiPT-data.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"llm-complex-reasoning-train-qwen2-72b-instruct-correct","keyword":"logical reasoning","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/llm-complex-reasoning-train-qwen2-72b-instruct-correct","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\n\t\n\t\t\n\t\tNote\n\t\n\n\nData Seed from 基于封闭世界假设的复杂逻辑推理\nGenerate from Qwen2-72B-Instruct with prompt\ntrain.jsonl for 推理答案和题目答案一致, no_train.jsonl推理答案和题目答案不一致\n注: 题目答案不一定正确\n\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Maths-Grade-School","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Maths-Grade-School","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Maths-Grade-School\nI am releasing large Grade School level Mathematics datatset.\nThis extensive dataset, comprising nearly one million instructions in JSON format, encapsulates a diverse array of topics fundamental to building a strong mathematical foundation.\nThis dataset is in instruction format so that model developers, researchers etc. can easily use this dataset.\nFollowing Fields & sub Fields are covered:\nCalculus\nProbability\nAlgebra\nLiner Algebra\nTrigonometry\nDifferential Equations… See the full description on the dataset page: https://huggingface.co/datasets/ajibawa-2023/Maths-Grade-School.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Kapibara","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alban-labs/Kapibara","creator_name":"Albanian Labs","creator_url":"https://huggingface.co/alban-labs","description":"\n\t\n\t\t\n\t\n\t\n\t\tKapibara: Albanian Multi-turn Conversation Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nKapibara is a comprehensive Albanian language dataset designed for multi-turn conversations. It contains over 5,300 entries covering a wide range of topics including physics, biology, mathematics, chemistry, culture, and logic. The dataset is aimed at improving text generation and question-answering capabilities in the Albanian language.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\nThe dataset supports the… See the full description on the dataset page: https://huggingface.co/datasets/alban-labs/Kapibara.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Albanian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"lojban","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"flo","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/florianhoenicke/flo","creator_name":"Florian Hönicke","creator_url":"https://huggingface.co/florianhoenicke","description":"\n\t\n\t\t\n\t\tflo Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the flo model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"florianhoenicke/flo\")… See the full description on the dataset page: https://huggingface.co/datasets/florianhoenicke/flo.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Maths-Grade-School","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pt-sk/Maths-Grade-School","creator_name":"Sathish Kumar","creator_url":"https://huggingface.co/pt-sk","description":"Maths-Grade-School\nI am releasing large Grade School level Mathematics datatset.\nThis extensive dataset, comprising nearly one million instructions in JSON format, encapsulates a diverse array of topics fundamental to building a strong mathematical foundation.\nThis dataset is in instruction format so that model developers, researchers etc. can easily use this dataset.\nFollowing Fields & sub Fields are covered:\nCalculus\nProbability\nAlgebra\nLiner Algebra\nTrigonometry\nDifferential Equations… See the full description on the dataset page: https://huggingface.co/datasets/pt-sk/Maths-Grade-School.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"CleverBoi","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/CleverBoi","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"\n\n\n\t\n\t\t\n\t\tCleverBoi\n\t\n\nThe CleverBoi Collection is based on a number of data sets that emphasize logic, inference, empathy, math and coding.\nThe data set has been formatted to follow the alpaca format (instruction + input -> output) when fine tuning.\n\n\t\n\t\t\n\t\tSource Data Sets\n\t\n\nThe source data sets used in the CleverBoi Collection are listed below, ordered by size.\n\nKK04/LogicInference_OA\nmlabonne/Evol-Instruct-Python-26k\ngarage-bAInd/Open-Platypus\niamtarun/python_code_instructions_18k_alpaca… See the full description on the dataset page: https://huggingface.co/datasets/theprint/CleverBoi.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"dpo-merged","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CultriX/dpo-merged","creator_name":"CultriX","creator_url":"https://huggingface.co/CultriX","description":"CultriX/dpo-merged dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"dpo-merged-binarized","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CultriX/dpo-merged-binarized","creator_name":"CultriX","creator_url":"https://huggingface.co/CultriX","description":"CultriX/dpo-merged-binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Geoperception","keyword":"logical-reasoning","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/euclid-multimodal/Geoperception","creator_name":"Euclid Multimodal LLM","creator_url":"https://huggingface.co/euclid-multimodal","description":"Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions\n\n\t\n\t\t\n\t\tDataset Card for Geoperception\n\t\n\nA Benchmark for Low-level Geometric Perception\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nGeoperception is a benchmark focused specifically on accessing model's low-level visual perception ability in 2D geometry.\nIt is sourced from the Geometry-3K corpus, which offers precise logical forms for geometric diagrams, compiled from popular high-school… See the full description on the dataset page: https://huggingface.co/datasets/euclid-multimodal/Geoperception.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"CleverBoi-Data-20k","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/CleverBoi-Data-20k","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"theprint/CleverBoi-Data-20k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"polymath","keyword":"logical-reasoning","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/him1411/polymath","creator_name":"Himanshu Gupta","creator_url":"https://huggingface.co/him1411","description":"\n\t\n\t\t\n\t\tPaper Information\n\t\n\nWe present PolyMATH, a challenging benchmark aimed at evaluating the general cognitive reasoning abilities of MLLMs. \nPolyMATH comprises 5,000 manually collected high-quality images of cognitive textual and visual challenges across 10 distinct categories, including pattern recognition, spatial reasoning, and relative reasoning. \nWe conducted a comprehensive, and quantitative evaluation of 15 MLLMs using four diverse prompting strategies, including Chain-of-Thought… See the full description on the dataset page: https://huggingface.co/datasets/him1411/polymath.","first_N":5,"first_N_keywords":["multiple-choice","expert-generated","found","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"Spurline","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Spurline","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Spurline is a dataset containing complex responses, emphasizing logical reasoning and using Shining Valiant's friendly, magical personality style.\nThe 2024-10-30 version contains:\n\n10.7k rows of synthetic queries, using randomly selected prompts from migtissera/Synthia-v1.5-I and responses generated using Llama 3.1 405b Instruct.\n\nThis dataset contains synthetically generated data and has not been subject to manual review.\n","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"short_COT_48k","keyword":"logic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrankL/short_COT_48k","creator_name":"FrankLiu","creator_url":"https://huggingface.co/FrankL","description":"FrankL/short_COT_48k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"SocialMaze","keyword":"logical reasoning","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xzx34/SocialMaze","creator_name":"Zixiang Xu","creator_url":"https://huggingface.co/xzx34","description":"\n⚠️ Notice: This dataset is no longer maintained under this repository. It has been officially migrated to the MBZUAI organization for ongoing development and updates.👉 Access the latest version here: MBZUAI/SocialMaze\n\n\n\t\n\t\t\n\t\tSocialMaze Benchmark\n\t\n\nThis dataset is a component of the SocialMaze: A Benchmark for Evaluating Social Reasoning in Large Language Models project. It specifically features the Hidden Role Deduction task, which we consider one of the most challenging scenarios for… See the full description on the dataset page: https://huggingface.co/datasets/xzx34/SocialMaze.","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"IneqMath","keyword":"logical-reasoning","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI4Math/IneqMath","creator_name":"AI for Math Reasoning","creator_url":"https://huggingface.co/AI4Math","description":"\n\n  \n\n  \n\n  \n    Solving Inequality Proofs with Large Language Models\n  \n\n  \n\n  \n    \n      🌐 Project\n    \n    |\n    \n       arXiv\n    \n    |\n    \n      HF Paper\n    \n    |\n    \n       Github\n    \n    |\n    \n      🏆 Leaderboard\n    \n    |\n    \n      🔮 Visualization\n    \n  \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nInequality proving, crucial across diverse scientific and mathematical fields, tests advanced reasoning skills such as discovering tight bounds and strategically applying theorems. This… See the full description on the dataset page: https://huggingface.co/datasets/AI4Math/IneqMath.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-retrieval","text-classification","English"],"keywords_longer_than_N":true},
	{"name":"LOGIC-701-instruct","keyword":"logic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/evilfreelancer/LOGIC-701-instruct","creator_name":"Pavel Zloi","creator_url":"https://huggingface.co/evilfreelancer","description":"\n\t\n\t\t\n\t\tLOGIC-701 (instruct)\n\t\n\nBased on https://huggingface.co/datasets/hivaze/LOGIC-701\nSources https://github.com/EvilFreelancer/LOGIC-701-instruct\n","first_N":5,"first_N_keywords":["question-answering","Russian","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"LogicPro","keyword":"logical reasoning","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jiangjin/LogicPro","creator_name":"jiangjin","creator_url":"https://huggingface.co/jiangjin","description":"\n  \n  \n  LogicPro: Improving Complex Logical Reasoning via Program-Guided Learning\n\n\n\n  [📑 Paper] •\n  [🤗 HF Dataset] •\n  [👻 GitHub]\n\n\n\n\n\n\n\n\n\n\n\n\t\n\t\t\n\t\tData description\n\t\n\n{\n  \"id\": \"logicpro_lc679_225531-43120\",\n  \"title\": \"24 Game\", # Title of the original leetcode algorithm problem.\n  \"difficulty\": \"Hard\",\n  \"content\": \"...\", # The questions of the original leetcode algorithm problem.\n  \"python\": \"...\", # The original gold python solution\n  \"test_input_string\": \"...\", # Current Test Case… See the full description on the dataset page: https://huggingface.co/datasets/jiangjin/LogicPro.","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"SWAP","keyword":"logic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sxiong/SWAP","creator_name":"Siheng Xiong","creator_url":"https://huggingface.co/sxiong","description":"\n\t\n\t\t\n\t\tSWAP: A Synthetic Dataset for Complex Reasoning with Trajectories and Process Supervision\n\t\n\nThis repository contains the data for the paper Deliberate Reasoning for LLMs as Structure-aware Planning with Accurate World Model.\nSWAP (Structure-aware Planning) solves complex reasoning by introducing a Generator-Discriminator architecture, and incorporates structural information to guide the reasoning process and provides a soft verification mechanism over the steps.\nWe generate the… See the full description on the dataset page: https://huggingface.co/datasets/sxiong/SWAP.","first_N":5,"first_N_keywords":["English","mit","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"CoreReasoning","keyword":"logical reasoning","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayjays132/CoreReasoning","creator_name":"Phillip Holland","creator_url":"https://huggingface.co/ayjays132","description":"\n  🌟 Core Reasoning Dataset 🌟\n  \n  Overview\n  \n    Welcome to the Core Reasoning Dataset—a meticulously crafted collection of prompts, contexts, outputs, and reasoning types. This dataset is designed to push the boundaries of text-generation models, enabling them to excel in logical reasoning, ethical problem-solving, and contextual understanding.\n  \n\n  ✨ Dataset Features\n  \n    \n      Input: A question or prompt requiring critical thinking or creative problem-solving.… See the full description on the dataset page: https://huggingface.co/datasets/ayjays132/CoreReasoning.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"CoreReasoningPrime","keyword":"logical reasoning","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayjays132/CoreReasoningPrime","creator_name":"Phillip Holland","creator_url":"https://huggingface.co/ayjays132","description":"\n  🌟 Core Reasoning Prime Dataset 🌟\n  \n  🌌 Ultimate Overview\n  \n    Welcome to the Core Reasoning Prime Dataset—a pioneering collection designed for next-generation AI models. Crafted to cultivate logical reasoning, creative problem-solving, ethical thinking, and beyond, this dataset sets the benchmark for intelligence training.\n  \n\n  ✨ Revolutionary Features\n  \n    \n      🔍Input: Engaging prompts designed to challenge AI’s reasoning and creativity.\n    \n    \n      🧠Context: Enriched… See the full description on the dataset page: https://huggingface.co/datasets/ayjays132/CoreReasoningPrime.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"RelatLogic","keyword":"logic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shb777/RelatLogic","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"RelatLogic: A Dataset for Comparative and Conditional Reasoning\nThis is a comparative logic and conditional reasoning dataset. \nEach data point has a premise, question, answer, reasoning and attribute.\nMore about the generation process here.\nPlease cite this dataset using the provided BibTeX if you find it useful.\n@misc {sb_2025,\n    author       = { {SB} },\n    title        = { RelatLogic (Revision 15b1922) },\n    year         = 2025,\n    url          = {… See the full description on the dataset page: https://huggingface.co/datasets/shb777/RelatLogic.","first_N":5,"first_N_keywords":["text-generation","English","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"syllogistic-logic","keyword":"logic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/leobertolazzi/syllogistic-logic","creator_name":"Leonardo Bertolazzi","creator_url":"https://huggingface.co/leobertolazzi","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSyllogistic-logic is a synthetic dataset designed to evaluate the logical reasoning abilities of LLMs. It focuses on the task of logical premise selection — identifying the minimal set of premises in a knowledge base that entails a given hypothesis. The dataset is built on the syllogistic fragment of first-order logic and supports systematic generalization experiments, including generalization to unseen knowledge bases and reasoning with longer or shorter inference… See the full description on the dataset page: https://huggingface.co/datasets/leobertolazzi/syllogistic-logic.","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"SLR-Bench","keyword":"logic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIML-TUDA/SLR-Bench","creator_name":"Artificial Intelligence & Machine Learning Lab at TU Darmstadt","creator_url":"https://huggingface.co/AIML-TUDA","description":" \n\n\n\t\n\t\t\n\t\tSLR-Bench: Scalable Logical Reasoning Benchmark for LLMs\n\t\n\n\n\n\n\n🆕 June 2024: Reward Model & Evaluation Pipeline Released!Systematically evaluate model-generated rules via symbolic execution, fully automatic and verifiable. Supports evaluation and RLVR. 👉 Demo on Hugging Face SpacesSLR-Bench is a scalable, fully-automated benchmark designed to systematically evaluate and train Large Language Models (LLMs) in logical reasoning via inductive logic programming (ILP) tasks. Built with… See the full description on the dataset page: https://huggingface.co/datasets/AIML-TUDA/SLR-Bench.","first_N":5,"first_N_keywords":["English","cc-by-4.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"Tengentoppa-grpo-v1.0","keyword":"logic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-grpo-v1.0","creator_name":"Taisei Ozaki","creator_url":"https://huggingface.co/DeL-TaiseiOzaki","description":"\n\t\n\t\t\n\t\tTengentoppa-grpo-v1.0\n\t\n\n\n\t\n\t\t\n\t\t1. データセットの読み込み\n\t\n\nfrom datasets import load_dataset\n\n# Hugging Faceから直接読み込み\ndataset = load_dataset(\"your-username/japanese-edu-problems-tex\")\n\n# またはローカルファイルから\nimport json\nwith open(\"corrected_problems_tex.json\", \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\n","first_N":5,"first_N_keywords":["question-answering","text-generation","Japanese","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MathVista_with_difficulty_level","keyword":"logical-reasoning","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JierunChen/MathVista_with_difficulty_level","creator_name":"Jierun Chen","creator_url":"https://huggingface.co/JierunChen","description":"\n\t\n\t\t\n\t\tMathVista with difficulty level tags\n\t\n\nThis dataset extends the 🤗 MathVista testmini benchmark by introducing two additional tags: passrate_for_qwen2.5_vl_7b and difficulty_level_for_qwen2.5_vl_7b. Further details are available in our paper  The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs.\n\n\t\n\t\t\n\t\n\t\n\t\t🚀 Data Usage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"JierunChen/MathVista_with_difficulty_level\")… See the full description on the dataset page: https://huggingface.co/datasets/JierunChen/MathVista_with_difficulty_level.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","text-classification","multiple-choice-qa"],"keywords_longer_than_N":true}
]
;
