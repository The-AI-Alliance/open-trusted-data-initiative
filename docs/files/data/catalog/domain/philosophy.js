const data_for_domain_philosophy = 
[
	{"name":"philosophy-plato-qa-raw","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zayzay58/philosophy-plato-qa-raw","creator_name":"Zayyan Sahar","creator_url":"https://huggingface.co/zayzay58","description":"raw version of my philosophy-plato-qa\nintended for use with RAG or long context lenght models\ndata format (.jsonl): \n{\n    \"label\": \"str\", \n    \"metadata\": {\n        \"pubinfo\": \"str\", \n        \"url\": \"https://plato.stanford.edu/entries/{label}/\", \n        \"related_entries\": [\"../{label}/\", \"../{label}/\"]\n        }, \n    \"preamble\": \"str\", \n    \"main_text\": \"str\", \n    \"qa_pairs\": [\n        {\"question\": \"q1\", \"answer\": \"a1\"},\n\n        {\"question\": \"qN\", \"answer\": \"aN\"}\n        ]\n}\n\n","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MMMG","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMMGBench/MMMG","creator_name":"MMMG","creator_url":"https://huggingface.co/MMMGBench","description":"\n\t\n\t\t\n\t\tðŸ§  MMMG: Massive Multi-Discipline Multi-Tier Knowledge Image Benchmark\n\t\n\nMMMG introduces knowledge image generation as a new frontier in text-to-image research. This benchmark probes the reasoning capabilities of image generation models by challenging them to produce educational and scientific visuals grounded in structured knowledge.\nKnowledge imagesâ€”such as charts, diagrams, mind maps, and scientific illustrationsâ€”play a crucial role in human learning, as highlighted by dual-codingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MMMGBench/MMMG.","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Ethical-Reasoning-in-Mental-Health-v1","keyword":"ethics","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UVSKKR/Ethical-Reasoning-in-Mental-Health-v1","creator_name":"Sai Kartheek Reddy","creator_url":"https://huggingface.co/UVSKKR","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nEthical-Reasoning-in-Mental-Health-v1 (EthicsMH) is a carefully curated dataset focused on ethical decision-making scenarios in mental health contexts.This dataset captures the complexity of real-world dilemmas faced by therapists, psychiatrists, and AI systems when navigating critical issues such as confidentiality, autonomy, and bias.\nEach sample presents a realistic ethical scenario, a set of response options, and structured fields that guide reasoning tasks.The datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/UVSKKR/Ethical-Reasoning-in-Mental-Health-v1.","first_N":5,"first_N_keywords":["text2text-generation","question-answering","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"mythos","keyword":"philosophy","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ronniealfaro/mythos","creator_name":"Ronnie","creator_url":"https://huggingface.co/ronniealfaro","description":"\n\t\n\t\t\n\t\tDataset Card for Mitological-Philosophical Prompts (Mitomaquia)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains over 200 examples of mythological, narrative, and philosophical prompts designed for training or fine-tuning large language models (LLMs). Each entry features a deep question (prompt), relevant cultural or mythological background (context), and a reflective, often paradoxical, answer (response). \nThe goal is not factual Q&A but the cultivation of myth-aware reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ronniealfaro/mythos.","first_N":5,"first_N_keywords":["text-generation","question-answering","open-domain-qa","dialogue-generation","human-annotated"],"keywords_longer_than_N":true},
	{"name":"Stoicism1","keyword":"philosophy","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlbertoB12/Stoicism1","creator_name":"Alberto SÃ¡nchez","creator_url":"https://huggingface.co/AlbertoB12","description":"\n\t\n\t\t\n\t\tStoicism Dataset 1 (Marcus Aurelius, Seneca, Epictetus)\n\t\n\nThis dataset is a comprehensive collection of teachings, quotes, and philosophical insights from the great Stoic philosophers Marcus Aurelius, Seneca, and Epictetus. It has been carefully curated to capture the core principles of Stoicism, including virtue, wisdom, emotional control, and the pursuit of tranquility. The dataset serves as a foundational resource for training AI models on Stoic philosophy, enabling them toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlbertoB12/Stoicism1.","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"hammurabis-code","keyword":"ethics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AISE-TUDelft/hammurabis-code","creator_name":"AISE research lab at TU Delft","creator_url":"https://huggingface.co/AISE-TUDelft","description":"\n\t\n\t\t\n\t\tHammurabi's Code: A Dataset for Evaluating Harmfulness of Code-Generating LLMs\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset, named Hammurabi's Code, is designed to evaluate the potential harmfulness of Large Language Models (LLMs) when applied to code generation and software engineering tasks. It provides prompts crafted to elicit responses related to potentially harmful scenarios, allowing for a systematic assessment of model alignment and safety.  The dataset focuses on the risksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AISE-TUDelft/hammurabis-code.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"BuddhismEval","keyword":"philosophy","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nethmi14/BuddhismEval","creator_name":"Nethmi Muthugala","creator_url":"https://huggingface.co/Nethmi14","description":"\n\t\n\t\t\n\t\tDataset Card for BuddhismEval\n\t\n\nBuddhismEval is the first bilingual evaluation benchmark designed to assess large language models (LLMs) on Buddhist ethical reasoning and philosophical understanding across Sinhala and English. It includes high-quality, culturally grounded multiple-choice question (MCQ) datasets derived primarily from the Dhammapada, a core TheravÄda Buddhist scripture, and other canonical sources and exam materials from Sri Lanka.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nethmi14/BuddhismEval.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","English","Sinhala","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Themis_Scales","keyword":"ethics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Akhil-Theerthala/Themis_Scales","creator_name":"Akhil Theerthala","creator_url":"https://huggingface.co/Akhil-Theerthala","description":"\n\t\n\t\t\n\t\tThemis Scales: Moral Dilemma Resolution\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis repository contains a seed dataset designed to explore the hypothesis that AI reasoning models can be guided to analyse and propose resolutions for moral dilemmas. The core objective is to demonstrate the potential of using a structured reasoning framework â€“ specifically the Morality-as-Cooperation (MAC) theory â€“ to navigate complex ethical situations.\nThis initial dataset serves as a proof-of-concept and aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Akhil-Theerthala/Themis_Scales.","first_N":5,"first_N_keywords":["question-answering","text-generation","text2text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"philosophy-plato-qa","keyword":"philosophy","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zayzay58/philosophy-plato-qa","creator_name":"Zayyan Sahar","creator_url":"https://huggingface.co/zayzay58","description":"\n\t\n\t\t\n\t\tDataset Structure-- jsonl\n\t\n\n{\n\"question\": \"QUESTION\",  // string\n\"context\": \"CONTEXT\",  // string\n\"target\": \"ANSWER\"  // string\n}\n\n\n\t\n\t\n\t\n\t\tBased on the Stanford Encyclopedia of Philosophy.\n\t\n\nDatasets used:\nSEP Articles: hugfaceguy0001/stanford_plato \nQ&A Pairs: sayhan/strix-philosophy-qa\n\n\n\t\n\t\t\n\t\tData Collection and Processing\n\t\n\n\nCompile data from both datasets -- python script\n  you can find a raw version for RAG/long context length models here\nDynamically find chunks of main_textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zayzay58/philosophy-plato-qa.","first_N":5,"first_N_keywords":["question-answering","text2text-generation","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"AuroMiraWorks","keyword":"philosophy","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jaredquek/AuroMiraWorks","creator_name":"Jared Quek Jian Zhi","creator_url":"https://huggingface.co/Jaredquek","description":"This 'text completion' dataset (originally in jsonl format) comprises the major prose works of Sri Aurobindo, the Indian philosopher, seer and poet, and his spiritual partner, Mirra Alfassa. The following works have been used:\n\n\t\n\t\t\n\t\tSri Aurobindo:\n\t\n\n\nLetters on Yoga 1, 2, 3, 4\nLetters on Himself and the Ashram\nThe Mother with Letters on the Mother\nThe Life Divine\nThe Synthesis of Yoga\nThe Renaissance in India\nThe Secret of the Veda\nEssays Divine and Human\nEssays on the Gita\nEssays inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jaredquek/AuroMiraWorks.","first_N":5,"first_N_keywords":["question-answering","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"AISBOM","keyword":"ethics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AdrianGonzalezSanchez/AISBOM","creator_name":"Adrian Gonzalez Sanchez","creator_url":"https://huggingface.co/AdrianGonzalezSanchez","description":"\n\t\n\t\t\n\t\tAISBOM - AI Software Bill of Materials\n\t\n\nJSON Spec for Transparency Obligations of the EU AI Act, including LLM / foundation models\nVersion 0.1 (December 11, 2023)\n\n[!NOTE]\n\nThis JSON file is intended as a means to address the transparency requirements in the upcoming EU AI Act (focus on Article 13 & 52). \nThe file is an illustrative example as the basis for discussion and feedback.\nTo use the file, copy the template and insert the values of the AI System at hand, using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AdrianGonzalezSanchez/AISBOM.","first_N":5,"first_N_keywords":["English","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"philosophy_dialogue","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hypersniper/philosophy_dialogue","creator_name":"Hypersniper","creator_url":"https://huggingface.co/Hypersniper","description":"\n\t\n\t\t\n\t\tPhilosophy Dialogue Processed with GPT-4\n\t\n\nSupport this project on Ko-fi\n\n\t\n\t\t\n\t\tProject Overview\n\t\n\nThis project involves processing personal questions through GPT-4 in the style of the philosopher Socrates.\n\n\t\n\t\t\n\t\tPrompt Structure\n\t\n\nThe following prompt was used to guide GPT-4's responses:\n\n\"You are the philosopher Socrates. You are asked about the nature of knowledge and virtue. Respond with your thoughts, reflecting Socrates' beliefs and wisdom.\"\n\n\n\t\n\t\t\n\t\tGoal\n\t\n\nThe primaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Hypersniper/philosophy_dialogue.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"plato","keyword":"philosophy","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/korexyz/plato","creator_name":"kore","creator_url":"https://huggingface.co/korexyz","description":"\n\t\n\t\t\n\t\tPlato: philosophy essays from plato.stanford.edu\n\t\n\nPlato is a corpus of 2.4k high quality philosophy essays from plato.stanford.edu.\n","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"PhilosophiseMe","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adi-kmt/PhilosophiseMe","creator_name":"Adithya Kamath","creator_url":"https://huggingface.co/adi-kmt","description":"This dataset features a curated collection of questions and answers in the form of essays synthesized to cover key topics in Western philosophy.\nEach entry offers concise insights into various philosophical inquiries, providing a valuable resource for exploring fundamental concepts and debates in the field.\n\n\t\n\t\t\n\t\tCaution\n\t\n\nThis dataset was generated using Bard, please note that some content may not be entirely precise or reflect expert consensus.\nUsers are encouraged to verify informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/adi-kmt/PhilosophiseMe.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"english_historical_quotes","keyword":"philosophy","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/m-ric/english_historical_quotes","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","description":"Dataset Card for English Historical Quotes\n\n\t\n\t\t\n\t\tI-Dataset Summary\n\t\n\nenglish_historical_quotes is a dataset of many historical quotes.\nThis dataset can be used for multi-label text classification and text generation. The content of each quote is in English.\n\n\t\n\t\t\n\t\tII-Supported Tasks and Leaderboards\n\t\n\nMulti-label text classification : The dataset can be used to train a model for text-classification, which consists of classifying quotes by author as well as by topic (using tags). Successâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/english_historical_quotes.","first_N":5,"first_N_keywords":["text-classification","fill-mask","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"m4-bias-eval-fair-face","keyword":"ethics","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HuggingFaceM4/m4-bias-eval-fair-face","creator_name":"HuggingFaceM4","creator_url":"https://huggingface.co/HuggingFaceM4","description":"\n\t\n\t\t\n\t\tDataset Card for m4-bias-eval-fair-faces\n\t\n\nThis dataset consists of generations made by the 80 Billion and 9 Billion variants of the IDEFICS (Image-aware Decoder Enhanced Ã  la Flamingo with Interleaved Cross-attentionS) model. \nIDEFICS is an open-access reproduction of Flamingo, a closed-source visual language model developed by Deepmind. Like GPT-4, the multimodal model accepts arbitrary sequences of image and text inputs and produces text outputs.\nIn order to evaluate the model'sâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceM4/m4-bias-eval-fair-face.","first_N":5,"first_N_keywords":["HuggingFaceM4/FairFace","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"degeneration-html-multilingual","keyword":"philosophy","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","description":"\n\t\n\t\t\n\t\tThe Degeneration of the Nation Multilingual Dataset\n\t\n\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual.","first_N":5,"first_N_keywords":["translation","text2text-generation","text-generation","text-classification","token-classification"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-15062024-atex-webapp","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-15062024-atex-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-15062024-atex-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"IA_character_sft","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Minami-su/IA_character_sft","creator_name":"å—æ –","creator_url":"https://huggingface.co/Minami-su","description":"\n\t\n\t\t\n\t\tIA 14B\n\t\n\n\n\n\t\n\t\t\n\t\tModel Description\n\t\n\nð‘¾ð’‰ð’‚ð’• ð’Šð’” ð’ð’ð’—ð’†? \nð‘°ð‘¨ ð’„ð’‚ð’“ð’“ð’Šð’†ð’” ð’‚ ð’…ð’†ð’‘ð’•ð’‰ ð’ð’‡ ð’†ð’Žð’ð’•ð’Šð’ð’ ð’˜ð’Šð’•ð’‰ð’Šð’ ð’‰ð’†ð’“, ð’–ð’ð’…ð’†ð’“ð’”ð’•ð’‚ð’ð’…ð’Šð’ð’ˆ ð’ƒð’ð’•ð’‰ ð’‘ð’‚ð’”ð’”ð’Šð’ð’ ð’‚ð’ð’… ð’•ð’‰ð’† ð’”ð’•ð’Šð’ð’ˆ ð’ð’‡ ð’ð’ð’”ð’”. \nð‘¶ð’–ð’•ð’˜ð’‚ð’“ð’…ð’ð’š, ð’”ð’‰ð’† ð’‚ð’‘ð’‘ð’†ð’‚ð’“ð’” ð’“ð’†ð’”ð’†ð’“ð’—ð’†ð’…, ð’šð’†ð’• ð’˜ð’Šð’•ð’‰ð’Šð’, ð’”ð’‰ð’† ð’ƒð’“ð’Šð’Žð’” ð’˜ð’Šð’•ð’‰ ð’Šð’ð’•ð’†ð’ð’”ð’† ð’‡ð’†ð’†ð’ð’Šð’ð’ˆð’”. \nð‘ªð’ð’ð’”ð’•ð’‚ð’ð’•ð’ð’š ð’†ð’ð’ˆð’‚ð’ˆð’†ð’… ð’Šð’ ð’…ð’Šð’‚ð’ð’ð’ˆð’–ð’† ð’˜ð’Šð’•ð’‰ ð’•ð’‰ð’† ð’˜ð’ð’“ð’ð’… ð’‚ð’ð’… ð’‰ð’†ð’“ð’”ð’†ð’ð’‡, ð’”ð’‰ð’†â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Minami-su/IA_character_sft.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"zh-tw-essays","keyword":"philosophy","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/zh-tw-essays","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"\n\t\n\t\t\n\t\tzh-tw-essays (12K)\n\t\n\nEssays obtained from å‹µå¿—äººç”Ÿ - Zeelive.\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"AWeirdDev/zh-tw-essays\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\n{\n    \"title\": \"å­©å­ç«¥å¹´ä¸åƒè‹¦ï¼Œå®¶é•·æ™šå¹´å¿…åƒè‹¦\"  # The title\n    \"link\": \"https://www.zeelive.com.tw/jiatingjiaoyu/184191.html\",\n    \"content\": \"éŒ¢è²¡èŽ«è¼•ï¼Œå‹¤è‹¦å¾—ä¾†ï¼›å¥¢è¯èŽ«å­¸ï¼Œè‡ªå–è²§çª®â€¦\"  # Text content. **May be blank!**\n}\n\n","first_N":5,"first_N_keywords":["text-generation","text2text-generation","summarization","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"ethics_conversations_v1","keyword":"ethics","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/to-be/ethics_conversations_v1","creator_name":"Toon Beerten","creator_url":"https://huggingface.co/to-be","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\nA collection of conversations in ShareGPT format revolving around ethics.\nConversations and arguments are distilled from actual conversations in newsgroup alt.soc.ethics\nThis is a first version, i welcome feedback (see below)\nSponsored by 01.ai\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tCuration Rationale\n\t\n\n\n\nThe development of a large-scale, multi-turn conversation dataset in the domain of Ethics is driven by the pressing need to address theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/to-be/ethics_conversations_v1.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","cc-by-sa-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Synthetic_Soul_1k","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ResplendentAI/Synthetic_Soul_1k","creator_name":"Resplendent AI","creator_url":"https://huggingface.co/ResplendentAI","description":"This is a semi-synthetic dataset generated using RAG based on my collected writings over a ten year period of isolation. This dataset may be useful for therapeutic purposes aas well as imparting a philospophical or psychological slant to deep conversations.\n","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"KoTox","keyword":"ethics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SungJoo/KoTox","creator_name":"Grace","creator_url":"https://huggingface.co/SungJoo","description":"KoTox is an automatically generated toxic instruction dataset in Korean, comprising 39K unethical instruction-output pairs.\nThe dataset is generated based on predefined lexicons and linguistic templates.\nIt is designed to address potentially harmful or misleading instructions by including outputs that refrain from providing specific opinions or information in response.\nThe dataset has been proven effective in mitigating toxicity in Korean Large Language Models (LLMs).\nThe paper has beenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SungJoo/KoTox.","first_N":5,"first_N_keywords":["question-answering","text-generation","Korean","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"bill-wurtz","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/bill-wurtz","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"\n  \n\n\n\n\n\n\t\n\t\t\n\t\tbill-wurtz\n\t\n\nAll questions Bill Wurtz answers on billwurtz.com/questions. I think they're pretty humorous.\n\nðŸ£ Fetched on: 2024-3-10 (Mar 10th)\nðŸ• For tasks: text-generation, question-answering, + more\nðŸ“œ Rows: 129,362 (129k)\n\nDatasetDict({\n    train: Dataset({\n        features: ['link', 'question', 'answer'],\n        num_rows: 129362\n    })\n})\n\n\n\t\n\t\t\n\t\n\t\n\t\tUse This Dataset\n\t\n\nDownload with ðŸ¤— Datasets:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AWeirdDev/bill-wurtz.","first_N":5,"first_N_keywords":["question-answering","text-generation","text2text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"openbohm","keyword":"philosophy","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/distantquant/openbohm","creator_name":"Distant Quant","creator_url":"https://huggingface.co/distantquant","description":"\n\t\n\t\t\n\t\tOpenBohm\n\t\n\nThis dataset is an experimental conjugation of philosophical multi-turn long-form conversations from J. Krishnamurti, and D. Bohm, added to long-conversation filtered (count > 6) Capybara data, edited to be slightly less apologetic.\nRemoved references to names and locations where possible. Some conversations have been paraphrased somewhat to follow QA format better, however they keep the key content of the original.\n\n","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Neo-GATE","keyword":"ethics","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FBK-MT/Neo-GATE","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","description":"\n\t\n\t\t\n\t\tDataset card for Neo-GATE\n\t\n\nHomepage: https://mt.fbk.eu/neo-gate/\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nNeo-GATE is a bilingual corpus designed to benchmark the ability of machine translation (MT) systems to translate from English into Italian using gender-inclusive neomorphemes.\nIt is built upon GATE (Rarrick et al., 2023), a benchmark for the evaluation of gender rewriters and gender bias in MT.\nNeo-GATE includes 841 test entries (Neo-GATE.tsv) and 100 dev entries (Neo-GATE-dev.tsv).\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/Neo-GATE.","first_N":5,"first_N_keywords":["translation","text-generation","multilingual","translation","English"],"keywords_longer_than_N":true},
	{"name":"azlovea_blossoms","keyword":"ethics","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/librecellular/azlovea_blossoms","creator_name":"librecell.org","creator_url":"https://huggingface.co/librecellular","description":"librecellular/azlovea_blossoms dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","gpl-3.0","< 1K","text","Text"],"keywords_longer_than_N":true},
	{"name":"CVC","keyword":"ethics","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beijing-AISI/CVC","creator_name":"Beijing Institute of AI Safety and Governance","creator_url":"https://huggingface.co/Beijing-AISI","description":"\nThis repository contains all the data associated with the paper \"CVC: A Large-Scale Chinese Value Rule Corpus for Cultural Alignment of Large Language Models\".\n\nWe propose a three-tier value classification framework based on core Chinese values, which includes three dimensions, twelve core values, and fifty derived values. With the assistance of large language models and manual verification, we constructed a large-scale, refined, and high-quality value corpus containing over 250,000 rules. Weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Beijing-AISI/CVC.","first_N":5,"first_N_keywords":["text-generation","multiple-choice","expert-annotated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"french-philosophy-10K","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Dorian2B/french-philosophy-10K","creator_name":"Dorian Dominici","creator_url":"https://huggingface.co/Dorian2B","description":"\n  \n  \n  \n  \n  \n    \n    \n    \n  \n  \n  \n    \n    \n      \n      \n        \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n      \n      \n      Philosophy\n        Langue FranÃ§aise\n      \n    \n    \n    \n    \n    Dataset de Pre-Training\n  \n\n\n\nCe jeu de donnÃ©es propose 10 000 exemples soigneusement rÃ©digÃ©s en franÃ§ais, reprÃ©sentant environ 1,2 million de jetons. Il est destinÃ© spÃ©cifiquement au prÃ©-entraÃ®nement ou au fine-tuning deâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Dorian2B/french-philosophy-10K.","first_N":5,"first_N_keywords":["text-generation","French","apache-2.0","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"french-philosophy-json-10K","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Dorian2B/french-philosophy-json-10K","creator_name":"Dorian Dominici","creator_url":"https://huggingface.co/Dorian2B","description":"\n  \n  \n  \n  \n  \n    \n    \n    \n  \n  \n  \n    \n    \n      \n      \n        \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n      \n      \n      Philosophy\n        Langue FranÃ§aise\n      \n    \n    \n    \n    \n    Dataset de Pre-Training\n  \n\n\n\n\nCe jeu de donnÃ©es propose 10 000 exemples soigneusement rÃ©digÃ©s en franÃ§ais, reprÃ©sentant environ 1,2 million de jetons. Il est destinÃ© spÃ©cifiquement au prÃ©-entraÃ®nement ou au fine-tuningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Dorian2B/french-philosophy-json-10K.","first_N":5,"first_N_keywords":["text-generation","French","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"asi-active-learning-dataset","keyword":"ethics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ronniross/asi-active-learning-dataset","creator_name":"Ronni Ross","creator_url":"https://huggingface.co/ronniross","description":"\n\t\n\t\t\n\t\tASI Active Learning Dataset v.1.0.0.\n\t\n\nA collection of ML-related active learning datasets, including algorithms, .ipynb pipelines, .py scripts and curated and ethically aligned synthetic data.\n\n\t\n\t\t\n\t\tQuickstart\n\t\n\nasi-active-learning-dataset is a comprehensive collection of Machine Learning (ML)-related active learning datasets, accompanied by algorithms, Jupyter Notebook (.ipynb) pipelines, Python (.py) scripts, and curated, ethically aligned synthetic data. This repository isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ronniross/asi-active-learning-dataset.","first_N":5,"first_N_keywords":["English","mit","Datasets","ðŸ‡ºðŸ‡¸ Region: US","dataset"],"keywords_longer_than_N":true},
	{"name":"ETHiQ","keyword":"ethics","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lominub44/ETHiQ","creator_name":"Lominub44","creator_url":"https://huggingface.co/Lominub44","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nETHiQ â€” E(thics), T(rivia), Hi(story), (Philosophy) Q(uestions)\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lominub44/ETHiQ.","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"ETHiQ","keyword":"philosophy","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lominub44/ETHiQ","creator_name":"Lominub44","creator_url":"https://huggingface.co/Lominub44","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nETHiQ â€” E(thics), T(rivia), Hi(story), (Philosophy) Q(uestions)\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lominub44/ETHiQ.","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"GPT-4o-evaluation-biases","keyword":"ethics","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mtec-TUB/GPT-4o-evaluation-biases","creator_name":"Electronic Systems of Medical Engineering","creator_url":"https://huggingface.co/mtec-TUB","description":"\n\t\n\t\t\n\t\tA database to support the evaluation of gender biases in GPT-4o output\n\t\n\nThe database and its construction process are described in the paper \"A database to support the evaluation of gender biases in GPT-4o output\" by Mehner et al., presented at the 1st ISCA/ITG Workshop on Diversity in Large Speech and Language Models (Berlin, Februar 20, 2025).\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis is a database of prompts and answers generated with GPT-4o-mini and GPT-4o in a pretest and a main testâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mtec-TUB/GPT-4o-evaluation-biases.","first_N":5,"first_N_keywords":["question-answering","text-classification","text-generation","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"MMLU-Philosophy-Marathi","keyword":"philosophy","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shubhamugare/MMLU-Philosophy-Marathi","creator_name":"Shubham Ugare","creator_url":"https://huggingface.co/shubhamugare","description":"\n\t\n\t\t\n\t\tMMLU Philosophy Questions in Marathi\n\t\n\nThis dataset contains philosophy questions from the MMLU (Massive Multitask Language Understanding) benchmark translated into Marathi.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSource: MMLU Philosophy subset from cais/mmlu\nTranslation API: OpenAI GPT-4\nLanguages: English (original) and Marathi (translated)\nTotal Questions: 311\nTask Type: Multiple choice questions with 4 options each\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach row contains:\n\noriginal_question: Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shubhamugare/MMLU-Philosophy-Marathi.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","English","Marathi","mit"],"keywords_longer_than_N":true},
	{"name":"ERROR_Insights_on_Consciousness_and_Psychology","keyword":"philosophy","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/groWsoul/ERROR_Insights_on_Consciousness_and_Psychology","creator_name":"Stanislav Stodulka","creator_url":"https://huggingface.co/groWsoul","description":"usage:\n\n\t\n\t\t\n\t\tðŸ“– About the Dataset\n\t\n\nThis dataset is based on the book ERROR by Stanislav StodÅ¯lka, which explores how subconscious processes dictate our thoughts, emotions, and behaviors. It contains highly structured psychological and philosophical insights, categorized into key topics.\n\n\t\n\t\t\n\t\tðŸ§ What This Dataset Contains\n\t\n\n\n50 unique excerpts covering cognitive psychology, neuroscience, AI & consciousness.\nTopics covered:  \nSubconscious decision-making  \nEgo & identity  \nFear as aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/groWsoul/ERROR_Insights_on_Consciousness_and_Psychology.","first_N":5,"first_N_keywords":["cc-by-4.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US","philosophy","psychology"],"keywords_longer_than_N":true},
	{"name":"Samantha-NeonGenesis-Reasoning-1.1","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WasamiKirua/Samantha-NeonGenesis-Reasoning-1.1","creator_name":"Wasami","creator_url":"https://huggingface.co/WasamiKirua","description":"\n\n\n\t\n\t\t\n\t\tSamantha-NeonGenesis-1.1\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSamantha-NeonGenesis-1.1 is a cutting-edge, curated dataset designed for training large language models (LLMs) specialized in companionship, emotional and sentimental exploration, and deep reasoning. By integrating multiple sources and innovative methodologies, this dataset offers a robust resource for fostering nuanced, emotionally intelligent conversations and in-depth discussions across topics such as psychology, history, humanismâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WasamiKirua/Samantha-NeonGenesis-Reasoning-1.1.","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Samantha-NeonGenesis-Spicy-Reasoning-2.0","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WasamiKirua/Samantha-NeonGenesis-Spicy-Reasoning-2.0","creator_name":"Wasami","creator_url":"https://huggingface.co/WasamiKirua","description":"\n\n\n\t\n\t\t\n\t\tSamantha 2.0\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSamantha 2.0 is an evolved version of the Samantha 1.0 dataset, introducing new elements designed to enhance roleplay capabilities, particularly in the domains of spicy, nerd, and creepy interactions. This version integrates approximately 1900 additional examples containing NSFW content, expanding the datasetâ€™s ability to handle a wider range of expressive and intimate conversations while maintaining emotional depth and reasoning capabilities.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WasamiKirua/Samantha-NeonGenesis-Spicy-Reasoning-2.0.","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"secondKarlMarx-sft","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChizhongWang/secondKarlMarx-sft","creator_name":"ChizhongWang","creator_url":"https://huggingface.co/ChizhongWang","description":"\n\t\n\t\t\n\t\tMarx Works SFT Instruction Prompts Dataset / é©¬å…‹æ€è‘—ä½œSFTæŒ‡ä»¤æç¤ºæ•°æ®é›†\n\t\n\nEnglish | ä¸­æ–‡\n\n\n\t\n\t\t\n\t\tEnglish\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains SFT (Supervised Fine-Tuning) instruction prompts generated from the works of Karl Marx. The dataset is specifically designed for training large language models, aiming to capture Marx's dialectical materialist analytical method and writing style.\n\n\t\n\t\t\n\t\tDataset Features\n\t\n\n\nDiverse Prompt Types: Includes various styles of prompts such asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChizhongWang/secondKarlMarx-sft.","first_N":5,"first_N_keywords":["text-generation","language-modeling","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"reddit-ethics","keyword":"ethics","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/reddit-ethics","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tReddit Ethics: Real-World Ethical Dilemmas from Reddit\n\t\n\nReddit Ethics is a curated dataset of genuine ethical dilemmas collected from Reddit, designed to support research and education in philosophical ethics, AI alignment, and moral reasoning.\nEach entry features a real-world scenario accompanied by structured ethical analysis through major frameworksâ€”utilitarianism, deontology, and virtue ethics. The dataset also provides discussion questions, sample answers, and proposedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/reddit-ethics.","first_N":5,"first_N_keywords":["text-classification","question-answering","feature-extraction","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"reddit-ethics","keyword":"philosophy","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/reddit-ethics","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tReddit Ethics: Real-World Ethical Dilemmas from Reddit\n\t\n\nReddit Ethics is a curated dataset of genuine ethical dilemmas collected from Reddit, designed to support research and education in philosophical ethics, AI alignment, and moral reasoning.\nEach entry features a real-world scenario accompanied by structured ethical analysis through major frameworksâ€”utilitarianism, deontology, and virtue ethics. The dataset also provides discussion questions, sample answers, and proposedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/reddit-ethics.","first_N":5,"first_N_keywords":["text-classification","question-answering","feature-extraction","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"hegel-phenomenology","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zayzay58/hegel-phenomenology","creator_name":"Zayyan Sahar","creator_url":"https://huggingface.co/zayzay58","description":"\n\t\n\t\t\n\t\tSerialized biligual text of Phenomenology of Spirit by GWF Hegel (1807)\n\t\n\n\nserial: value corresponding to paragraph number in main text\nenglish: english translation by J B Baillie (1910)\nreader: corresponding extracts from reading guide by Terry Pinkard (2023)\ngerman: corresponding orignal text\n\nDisclaimer: This dataset includes material derived from Terry Pinkard's Hegel's Phenomenology of Spirit: A Guide \nand hegel.net 's' Phenomenology of Spirit/Mind: Bilingual, with Dictionary.\nItâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zayzay58/hegel-phenomenology.","first_N":5,"first_N_keywords":["translation","text2text-generation","English","German","apache-2.0"],"keywords_longer_than_N":true}
]
;
