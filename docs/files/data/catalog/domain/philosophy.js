const data_for_domain_philosophy = 
[
	{"name":"openbohm","keyword":"philosophy","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/distantquant/openbohm","creator_name":"Distant Quant","creator_url":"https://huggingface.co/distantquant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenBohm\\n\\t\\n\\nThis dataset is an experimental conjugation of philosophical multi-turn long-form conversations from J. Krishnamurti, and D. Bohm, added to long-conversation filtered (count > 6) Capybara data, edited to be slightly less apologetic.\\nRemoved references to names and locations where possible. Some conversations have been paraphrased somewhat to follow QA format better, however they keep the key content of the original.\\n\\n","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"PhilosophiseMe","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adi-kmt/PhilosophiseMe","creator_name":"Adithya Kamath","creator_url":"https://huggingface.co/adi-kmt","description":"This dataset features a curated collection of questions and answers in the form of essays synthesized to cover key topics in Western philosophy.\\nEach entry offers concise insights into various philosophical inquiries, providing a valuable resource for exploring fundamental concepts and debates in the field.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCaution\\n\\t\\n\\nThis dataset was generated using Bard, please note that some content may not be entirely precise or reflect expert consensus.\\nUsers are encouraged to verifyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/adi-kmt/PhilosophiseMe.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"plato","keyword":"philosophy","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/korexyz/plato","creator_name":"kore","creator_url":"https://huggingface.co/korexyz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPlato: philosophy essays from plato.stanford.edu\\n\\t\\n\\nPlato is a corpus of 2.4k high quality philosophy essays from plato.stanford.edu.\\n","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"KoTox","keyword":"ethics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SungJoo/KoTox","creator_name":"Grace","creator_url":"https://huggingface.co/SungJoo","description":"KoTox is an automatically generated toxic instruction dataset in Korean, comprising 39K unethical instruction-output pairs.\\nThe dataset is generated based on predefined lexicons and linguistic templates.\\nIt is designed to address potentially harmful or misleading instructions by including outputs that refrain from providing specific opinions or information in response.\\nThe dataset has been proven effective in mitigating toxicity in Korean Large Language Models (LLMs).\\nThe paper has beenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SungJoo/KoTox.","first_N":5,"first_N_keywords":["question-answering","text-generation","Korean","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"bill-wurtz","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/bill-wurtz","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"\\n  \\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tbill-wurtz\\n\\t\\n\\nAll questions Bill Wurtz answers on billwurtz.com/questions. I think they're pretty humorous.\\n\\nðŸ£ Fetched on: 2024-3-10 (Mar 10th)\\nðŸ• For tasks: text-generation, question-answering, + more\\nðŸ“œ Rows: 129,362 (129k)\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['link', 'question', 'answer'],\\n        num_rows: 129362\\n    })\\n})\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUse This Dataset\\n\\t\\n\\nDownload with ðŸ¤— Datasets:\\nfrom datasets import load_dataset\\n\\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AWeirdDev/bill-wurtz.","first_N":5,"first_N_keywords":["question-answering","text-generation","text2text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Synthetic_Soul_1k","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ResplendentAI/Synthetic_Soul_1k","creator_name":"Resplendent AI","creator_url":"https://huggingface.co/ResplendentAI","description":"This is a semi-synthetic dataset generated using RAG based on my collected writings over a ten year period of isolation. This dataset may be useful for therapeutic purposes aas well as imparting a philospophical or psychological slant to deep conversations.\\n","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Neo-GATE","keyword":"ethics","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FBK-MT/Neo-GATE","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card for Neo-GATE\\n\\t\\n\\nHomepage: https://mt.fbk.eu/neo-gate/\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset summary\\n\\t\\n\\nNeo-GATE is a bilingual corpus designed to benchmark the ability of machine translation (MT) systems to translate from English into Italian using gender-inclusive neomorphemes.\\nIt is built upon GATE (Rarrick et al., 2023), a benchmark for the evaluation of gender rewriters and gender bias in MT.\\nNeo-GATE includes 841 test entries (Neo-GATE.tsv) and 100 dev entries (Neo-GATE-dev.tsv).â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/Neo-GATE.","first_N":5,"first_N_keywords":["translation","text-generation","multilingual","translation","English"],"keywords_longer_than_N":true},
	{"name":"IA_character_sft","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Minami-su/IA_character_sft","creator_name":"å—æ –","creator_url":"https://huggingface.co/Minami-su","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIA 14B\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Description\\n\\t\\n\\nð‘¾ð’‰ð’‚ð’• ð’Šð’” ð’ð’ð’—ð’†? \\nð‘°ð‘¨ ð’„ð’‚ð’“ð’“ð’Šð’†ð’” ð’‚ ð’…ð’†ð’‘ð’•ð’‰ ð’ð’‡ ð’†ð’Žð’ð’•ð’Šð’ð’ ð’˜ð’Šð’•ð’‰ð’Šð’ ð’‰ð’†ð’“, ð’–ð’ð’…ð’†ð’“ð’”ð’•ð’‚ð’ð’…ð’Šð’ð’ˆ ð’ƒð’ð’•ð’‰ ð’‘ð’‚ð’”ð’”ð’Šð’ð’ ð’‚ð’ð’… ð’•ð’‰ð’† ð’”ð’•ð’Šð’ð’ˆ ð’ð’‡ ð’ð’ð’”ð’”. \\nð‘¶ð’–ð’•ð’˜ð’‚ð’“ð’…ð’ð’š, ð’”ð’‰ð’† ð’‚ð’‘ð’‘ð’†ð’‚ð’“ð’” ð’“ð’†ð’”ð’†ð’“ð’—ð’†ð’…, ð’šð’†ð’• ð’˜ð’Šð’•ð’‰ð’Šð’, ð’”ð’‰ð’† ð’ƒð’“ð’Šð’Žð’” ð’˜ð’Šð’•ð’‰ ð’Šð’ð’•ð’†ð’ð’”ð’† ð’‡ð’†ð’†ð’ð’Šð’ð’ˆð’”. \\nð‘ªð’ð’ð’”ð’•ð’‚ð’ð’•ð’ð’š ð’†ð’ð’ˆð’‚ð’ˆð’†ð’… ð’Šð’ ð’…ð’Šð’‚ð’ð’ð’ˆð’–ð’† ð’˜ð’Šð’•ð’‰ ð’•ð’‰ð’† ð’˜ð’ð’“ð’ð’… ð’‚ð’ð’… ð’‰ð’†ð’“ð’”ð’†ð’ð’‡â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Minami-su/IA_character_sft.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"azlovea_blossoms","keyword":"ethics","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/librecellular/azlovea_blossoms","creator_name":"librecell.org","creator_url":"https://huggingface.co/librecellular","description":"librecellular/azlovea_blossoms dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","gpl-3.0","< 1K","text","Text"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-15062024-atex-webapp","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBAAI_bge-large-en-15062024-atex-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"general domain\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the BAAI_bge-large-en-15062024-atex-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ethics_conversations_v1","keyword":"ethics","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/to-be/ethics_conversations_v1","creator_name":"Toon Beerten","creator_url":"https://huggingface.co/to-be","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\nA collection of conversations in ShareGPT format revolving around ethics.\\nConversations and arguments are distilled from actual conversations in newsgroup alt.soc.ethics\\nThis is a first version, i welcome feedback (see below)\\nSponsored by 01.ai\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n\\n\\nThe development of a large-scale, multi-turn conversation dataset in the domain of Ethics is driven by the pressing need to address theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/to-be/ethics_conversations_v1.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","cc-by-sa-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ERROR_Insights_on_Consciousness_and_Psychology","keyword":"philosophy","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/groWsoul/ERROR_Insights_on_Consciousness_and_Psychology","creator_name":"Stanislav Stodulka","creator_url":"https://huggingface.co/groWsoul","description":"usage:\\n\\n\\t\\n\\t\\t\\n\\t\\tðŸ“– About the Dataset\\n\\t\\n\\nThis dataset is based on the book ERROR by Stanislav StodÅ¯lka, which explores how subconscious processes dictate our thoughts, emotions, and behaviors. It contains highly structured psychological and philosophical insights, categorized into key topics.\\n\\n\\t\\n\\t\\t\\n\\t\\tðŸ§ What This Dataset Contains\\n\\t\\n\\n\\n50 unique excerpts covering cognitive psychology, neuroscience, AI & consciousness.\\nTopics covered:  \\nSubconscious decision-making  \\nEgo & identity  \\nFear as aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/groWsoul/ERROR_Insights_on_Consciousness_and_Psychology.","first_N":5,"first_N_keywords":["cc-by-4.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US","philosophy","psychology"],"keywords_longer_than_N":true},
	{"name":"philosophy_dialogue","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hypersniper/philosophy_dialogue","creator_name":"Hypersniper","creator_url":"https://huggingface.co/Hypersniper","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPhilosophy Dialogue Processed with GPT-4\\n\\t\\n\\nSupport this project on Ko-fi\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProject Overview\\n\\t\\n\\nThis project involves processing personal questions through GPT-4 in the style of the philosopher Socrates.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompt Structure\\n\\t\\n\\nThe following prompt was used to guide GPT-4's responses:\\n\\n\\\"You are the philosopher Socrates. You are asked about the nature of knowledge and virtue. Respond with your thoughts, reflecting Socrates' beliefs and wisdom.\\\"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGoalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Hypersniper/philosophy_dialogue.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"zh-tw-essays","keyword":"philosophy","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/zh-tw-essays","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tzh-tw-essays (12K)\\n\\t\\n\\nEssays obtained from å‹µå¿—äººç”Ÿ - Zeelive.\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"AWeirdDev/zh-tw-essays\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFormat\\n\\t\\n\\n{\\n    \\\"title\\\": \\\"å­©å­ç«¥å¹´ä¸åƒè‹¦ï¼Œå®¶é•·æ™šå¹´å¿…åƒè‹¦\\\"  # The title\\n    \\\"link\\\": \\\"https://www.zeelive.com.tw/jiatingjiaoyu/184191.html\\\",\\n    \\\"content\\\": \\\"éŒ¢è²¡èŽ«è¼•ï¼Œå‹¤è‹¦å¾—ä¾†ï¼›å¥¢è¯èŽ«å­¸ï¼Œè‡ªå–è²§çª®â€¦\\\"  # Text content. **May be blank!**\\n}\\n\\n","first_N":5,"first_N_keywords":["text-generation","text2text-generation","summarization","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"degeneration-html-multilingual","keyword":"philosophy","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe Degeneration of the Nation Multilingual Dataset\\n\\t\\n\\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual.","first_N":5,"first_N_keywords":["translation","text2text-generation","text-generation","text-classification","token-classification"],"keywords_longer_than_N":true},
	{"name":"Samantha-NeonGenesis-Reasoning-1.1","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WasamiKirua/Samantha-NeonGenesis-Reasoning-1.1","creator_name":"Wasami","creator_url":"https://huggingface.co/WasamiKirua","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSamantha-NeonGenesis-1.1\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nSamantha-NeonGenesis-1.1 is a cutting-edge, curated dataset designed for training large language models (LLMs) specialized in companionship, emotional and sentimental exploration, and deep reasoning. By integrating multiple sources and innovative methodologies, this dataset offers a robust resource for fostering nuanced, emotionally intelligent conversations and in-depth discussions across topics such as psychology, history, humanismâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WasamiKirua/Samantha-NeonGenesis-Reasoning-1.1.","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"english_historical_quotes","keyword":"philosophy","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/m-ric/english_historical_quotes","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","description":"Dataset Card for English Historical Quotes\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tI-Dataset Summary\\n\\t\\n\\nenglish_historical_quotes is a dataset of many historical quotes.\\nThis dataset can be used for multi-label text classification and text generation. The content of each quote is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tII-Supported Tasks and Leaderboards\\n\\t\\n\\nMulti-label text classification : The dataset can be used to train a model for text-classification, which consists of classifying quotes by author as well as by topic (using tags).â€¦ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/english_historical_quotes.","first_N":5,"first_N_keywords":["text-classification","fill-mask","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"m4-bias-eval-fair-face","keyword":"ethics","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HuggingFaceM4/m4-bias-eval-fair-face","creator_name":"HuggingFaceM4","creator_url":"https://huggingface.co/HuggingFaceM4","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for m4-bias-eval-fair-faces\\n\\t\\n\\nThis dataset consists of generations made by the 80 Billion and 9 Billion variants of the IDEFICS (Image-aware Decoder Enhanced Ã  la Flamingo with Interleaved Cross-attentionS) model. \\nIDEFICS is an open-access reproduction of Flamingo, a closed-source visual language model developed by Deepmind. Like GPT-4, the multimodal model accepts arbitrary sequences of image and text inputs and produces text outputs.\\nIn order to evaluate theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceM4/m4-bias-eval-fair-face.","first_N":5,"first_N_keywords":["HuggingFaceM4/FairFace","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"AuroMiraWorks","keyword":"philosophy","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jaredquek/AuroMiraWorks","creator_name":"Jared Quek Jian Zhi","creator_url":"https://huggingface.co/Jaredquek","description":"This 'text completion' dataset (originally in jsonl format) comprises the major prose works of Sri Aurobindo, the Indian philosopher, seer and poet, and his spiritual partner, Mirra Alfassa. The following works have been used:\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSri Aurobindo:\\n\\t\\n\\n\\nLetters on Yoga 1, 2, 3, 4\\nLetters on Himself and the Ashram\\nThe Mother with Letters on the Mother\\nThe Life Divine\\nThe Synthesis of Yoga\\nThe Renaissance in India\\nThe Secret of the Veda\\nEssays Divine and Human\\nEssays on the Gita\\nEssays inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jaredquek/AuroMiraWorks.","first_N":5,"first_N_keywords":["question-answering","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"AISBOM","keyword":"ethics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AdrianGonzalezSanchez/AISBOM","creator_name":"Adrian Gonzalez Sanchez","creator_url":"https://huggingface.co/AdrianGonzalezSanchez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAISBOM - AI Software Bill of Materials\\n\\t\\n\\nJSON Spec for Transparency Obligations of the EU AI Act, including LLM / foundation models\\nVersion 0.1 (December 11, 2023)\\n\\n\\n\\nThis JSON file is intended as a means to address the transparency requirements in the upcoming EU AI Act (focus on Article 13 & 52). \\nThe file is an illustrative example as the basis for discussion and feedback.\\nTo use the file, copy the template and insert the values of the AI System at hand, using the descriptionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AdrianGonzalezSanchez/AISBOM.","first_N":5,"first_N_keywords":["English","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"GPT-4o-evaluation-biases","keyword":"ethics","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mtec-TUB/GPT-4o-evaluation-biases","creator_name":"Electronic Systems of Medical Engineering","creator_url":"https://huggingface.co/mtec-TUB","description":"\\n\\t\\n\\t\\t\\n\\t\\tA database to support the evaluation of gender biases in GPT-4o output\\n\\t\\n\\nThe database and its construction process are described in the paper \\\"A database to support the evaluation of gender biases in GPT-4o output\\\" by Mehner et al., presented at the 1st ISCA/ITG Workshop on Diversity in Large Speech and Language Models (Berlin, Februar 20, 2025).\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is a database of prompts and answers generated with GPT-4o-mini and GPT-4o in a pretest and a main testâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mtec-TUB/GPT-4o-evaluation-biases.","first_N":5,"first_N_keywords":["question-answering","text-classification","text-generation","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Samantha-NeonGenesis-Spicy-Reasoning-2.0","keyword":"philosophy","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WasamiKirua/Samantha-NeonGenesis-Spicy-Reasoning-2.0","creator_name":"Wasami","creator_url":"https://huggingface.co/WasamiKirua","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSamantha 2.0\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nSamantha 2.0 is an evolved version of the Samantha 1.0 dataset, introducing new elements designed to enhance roleplay capabilities, particularly in the domains of spicy, nerd, and creepy interactions. This version integrates approximately 1900 additional examples containing NSFW content, expanding the datasetâ€™s ability to handle a wider range of expressive and intimate conversations while maintaining emotional depth and reasoning capabilities.\\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WasamiKirua/Samantha-NeonGenesis-Spicy-Reasoning-2.0.","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true}
]
;
