const data_for_domain_philosophy = 
[
	{"name":"tape","keyword":"ethics","description":"The Winograd schema challenge composes tasks with syntactic ambiguity,\nwhich can be resolved with logic and reasoning (Levesque et al., 2012).\n\nThe texts for the Winograd schema problem are obtained using a semi-automatic \npipeline. First, lists of 11 typical grammatical structures with syntactic \nhomonymy (mainly case) are compiled. For example, two noun phrases with a \ncomplex subordinate: 'A trinket from Pompeii that has survived the centuries'.\nRequests corresponding to these constructions are submitted in search of the \nRussian National Corpus, or rather its sub-corpus with removed homonymy. In the \nresulting 2+k examples, homonymy is removed automatically with manual validation\nafterward. Each original sentence is split into multiple examples in the binary \nclassification format, indicating whether the homonymy is resolved correctly or\nnot.","url":"https://huggingface.co/datasets/RussianNLP/tape","creator_name":"Natural Language Processing in Russian","creator_url":"https://huggingface.co/RussianNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","question-answering","multiple-choice","Russian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"peS2o","keyword":"philosophy","description":"\n  \n\nPretraining Effectively on S2ORC!\n\nThe peS2o dataset is a collection of ~40M creative open-access academic papers,\ncleaned, filtered, and formatted for pre-training of language models. It is derived from\nthe Semantic Scholar Open Research Corpus(Lo et al, 2020), or S2ORC.\nWe release multiple version of peS2o, each with different processing and knowledge cutoff\ndate. We recommend you to use the latest version available.\nIf you use this dataset, please cite:\n@techreport{peS2o,\n    author =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/peS2o.","url":"https://huggingface.co/datasets/allenai/peS2o","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","allenai/s2orc","English","odc-by"],"keywords_longer_than_N":true},
	{"name":"MMLU-Philosophy-Marathi","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tMMLU Philosophy Questions in Marathi\n\t\n\nThis dataset contains philosophy questions from the MMLU (Massive Multitask Language Understanding) benchmark translated into Marathi.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSource: MMLU Philosophy subset from cais/mmlu\nTranslation API: OpenAI GPT-4\nLanguages: English (original) and Marathi (translated)\nTotal Questions: 311\nTask Type: Multiple choice questions with 4 options each\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach row contains:\n\noriginal_question: Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shubhamugare/MMLU-Philosophy-Marathi.","url":"https://huggingface.co/datasets/shubhamugare/MMLU-Philosophy-Marathi","creator_name":"Shubham Ugare","creator_url":"https://huggingface.co/shubhamugare","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","English","Marathi","mit"],"keywords_longer_than_N":true},
	{"name":"degeneration-html-multilingual","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tThe Degeneration of the Nation Multilingual Dataset\n\t\n\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual.","url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text2text-generation","text-generation","text-classification","token-classification"],"keywords_longer_than_N":true},
	{"name":"FiqhQA","keyword":"ethics","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nPaper: Sacred or Synthetic? Evaluating LLM Reliability and Abstention for Religious Questions\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nWe introduce a novel benchmark FiqhQA focused on the LLM generated Islamic rulings explicitly categorized by\nthe four major Sunni schools of thought, in both Arabic and English.\n\nCurated by: [Farah Atif, Nursultan Askarbekuly, Kareem Darwish and Monojit Choudhury]\n\nLanguage(s) (NLP): [ARABICâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/FiqhQA.","url":"https://huggingface.co/datasets/MBZUAI/FiqhQA","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Arabic","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Apple-Synthetic","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA synthetic questionâ€“answer dataset grounded in a curated set of seed documents that reflect Apple's historical design philosophy and cultural principles. Questions are interpretive and scenario-based; answers are required to be derivable from the provided source text [Apple-legacy-corpus](https://huggingface.co/datasets/SP4ND4N/Apple-legacy-corpus.\n\nSource type: synthetic, generated from internal seed docs (not scraped Apple manuals)\nFormat: JSON Lines (JSONL) withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SP4ND4N/Apple-Synthetic.","url":"https://huggingface.co/datasets/SP4ND4N/Apple-Synthetic","creator_name":"Spandan Kumar","creator_url":"https://huggingface.co/SP4ND4N","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Synthetic_Soul_1k","keyword":"philosophy","description":"This is a semi-synthetic dataset generated using RAG based on my collected writings over a ten year period of isolation. This dataset may be useful for therapeutic purposes aas well as imparting a philospophical or psychological slant to deep conversations.\n","url":"https://huggingface.co/datasets/ResplendentAI/Synthetic_Soul_1k","creator_name":"Resplendent AI","creator_url":"https://huggingface.co/ResplendentAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"french-philosophy-json-10K","keyword":"philosophy","description":"\n  \n  \n  \n  \n  \n    \n    \n    \n  \n  \n  \n    \n    \n      \n      \n        \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n      \n      \n      Philosophy\n        Langue FranÃ§aise\n      \n    \n    \n    \n    \n    Dataset de Pre-Training\n  \n\n\n\n\nCe jeu de donnÃ©es propose 10 000 exemples soigneusement rÃ©digÃ©s en franÃ§ais, reprÃ©sentant environ 1,2 million de jetons. Il est destinÃ© spÃ©cifiquement au prÃ©-entraÃ®nement ou au fine-tuningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Dorian2B/french-philosophy-json-10K.","url":"https://huggingface.co/datasets/Dorian2B/french-philosophy-json-10K","creator_name":"Dorian Dominici","creator_url":"https://huggingface.co/Dorian2B","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","French","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"CVC","keyword":"ethics","description":"\nThis repository contains all the data associated with the paper \"CVC: A Large-Scale Chinese Value Rule Corpus for Cultural Alignment of Large Language Models\".\n\nWe propose a three-tier value classification framework based on core Chinese values, which includes three dimensions, twelve core values, and fifty derived values. With the assistance of large language models and manual verification, we constructed a large-scale, refined, and high-quality value corpus containing over 250,000 rules. Weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Beijing-AISI/CVC.","url":"https://huggingface.co/datasets/Beijing-AISI/CVC","creator_name":"Beijing Institute of AI Safety and Governance","creator_url":"https://huggingface.co/Beijing-AISI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multiple-choice","expert-annotated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"indic_reasoning","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tIndic Reasoning\n\t\n\nThe Indic Reasoning Dataset (~500M tokens, 592k examples) is a high-quality, large-scale open-source resource created using advanced distillation techniques. It is designed to train and evaluate reasoning-capable AI systems with a strong emphasis on complex reasoning, structured chain-of-thought (CoT), and culturally relevant content.\nThis domain-rich corpus integrates Indian cultural, legal, historical, philosophical, and social contexts with global knowledgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/169Pi/indic_reasoning.","url":"https://huggingface.co/datasets/169Pi/indic_reasoning","creator_name":"169Pi","creator_url":"https://huggingface.co/169Pi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"visual-qa-llama-format","keyword":"ethics","description":"\n\t\n\t\t\n\t\tOpen Paws Visual Qa Llama Format\n\t\n\nThis dataset is part of the Open Paws initiative to develop AI training data aligned with animal liberation and advocacy principles. Created to train AI systems that understand and promote animal welfare, rights, and liberation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Type: Multimodal Data\nFormat: JSONL (JSON Lines)\nLanguages: Multilingual (primarily English)\nFocus: Animal advocacy and ethical reasoning\nOrganization: Open Paws\nLicense: Apache 2.0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-paws/visual-qa-llama-format.","url":"https://huggingface.co/datasets/open-paws/visual-qa-llama-format","creator_name":"Open Paws","creator_url":"https://huggingface.co/open-paws","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"ERROR_Insights_on_Consciousness_and_Psychology","keyword":"philosophy","description":"usage:\n\n\t\n\t\t\n\t\tðŸ“– About the Dataset\n\t\n\nThis dataset is based on the book ERROR by Stanislav StodÅ¯lka, which explores how subconscious processes dictate our thoughts, emotions, and behaviors. It contains highly structured psychological and philosophical insights, categorized into key topics.\n\n\t\n\t\t\n\t\tðŸ§ What This Dataset Contains\n\t\n\n\n50 unique excerpts covering cognitive psychology, neuroscience, AI & consciousness.\nTopics covered:  \nSubconscious decision-making  \nEgo & identity  \nFear as aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/groWsoul/ERROR_Insights_on_Consciousness_and_Psychology.","url":"https://huggingface.co/datasets/groWsoul/ERROR_Insights_on_Consciousness_and_Psychology","creator_name":"Stanislav Stodulka","creator_url":"https://huggingface.co/groWsoul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["cc-by-4.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US","philosophy","psychology"],"keywords_longer_than_N":true},
	{"name":"french-philosophy-10K","keyword":"philosophy","description":"\n  \n  \n  \n  \n  \n    \n    \n    \n  \n  \n  \n    \n    \n      \n      \n        \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n      \n      \n      Philosophy\n        Langue FranÃ§aise\n      \n    \n    \n    \n    \n    Dataset de Pre-Training\n  \n\n\n\nCe jeu de donnÃ©es propose 10 000 exemples soigneusement rÃ©digÃ©s en franÃ§ais, reprÃ©sentant environ 1,2 million de jetons. Il est destinÃ© spÃ©cifiquement au prÃ©-entraÃ®nement ou au fine-tuning deâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Dorian2B/french-philosophy-10K.","url":"https://huggingface.co/datasets/Dorian2B/french-philosophy-10K","creator_name":"Dorian Dominici","creator_url":"https://huggingface.co/Dorian2B","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","French","apache-2.0","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"DataFilter1","keyword":"philosophy","description":"ðŸ“¦ File Structure\nwordfilterlist.txt\nId love to see what a word filter like this would do on a large model.\nHow effective are models that are neutered from large exploration of manipulative data and philosophy at understanding human morality and good.\nExtensive coverage of:\nViolence and death\nImmoral and unethical acts\nHuman and animal harm\nSensitive psychological and medical conditions\nOppressive regimes and historical atrocities\nManipulative behavior and emotional abuse\nand religiousâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fountain1111/DataFilter1.","url":"https://huggingface.co/datasets/fountain1111/DataFilter1","creator_name":"asdasdas asdasdads","creator_url":"https://huggingface.co/fountain1111","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"PhilosophiseMe","keyword":"philosophy","description":"This dataset features a curated collection of questions and answers in the form of essays synthesized to cover key topics in Western philosophy.\nEach entry offers concise insights into various philosophical inquiries, providing a valuable resource for exploring fundamental concepts and debates in the field.\n\n\t\n\t\t\n\t\tCaution\n\t\n\nThis dataset was generated using Bard, please note that some content may not be entirely precise or reflect expert consensus.\nUsers are encouraged to verify informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/adi-kmt/PhilosophiseMe.","url":"https://huggingface.co/datasets/adi-kmt/PhilosophiseMe","creator_name":"Adithya Kamath","creator_url":"https://huggingface.co/adi-kmt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"m4-bias-eval-fair-face","keyword":"ethics","description":"\n\t\n\t\t\n\t\tDataset Card for m4-bias-eval-fair-faces\n\t\n\nThis dataset consists of generations made by the 80 Billion and 9 Billion variants of the IDEFICS (Image-aware Decoder Enhanced Ã  la Flamingo with Interleaved Cross-attentionS) model. \nIDEFICS is an open-access reproduction of Flamingo, a closed-source visual language model developed by Deepmind. Like GPT-4, the multimodal model accepts arbitrary sequences of image and text inputs and produces text outputs.\nIn order to evaluate the model'sâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceM4/m4-bias-eval-fair-face.","url":"https://huggingface.co/datasets/HuggingFaceM4/m4-bias-eval-fair-face","creator_name":"HuggingFaceM4","creator_url":"https://huggingface.co/HuggingFaceM4","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["HuggingFaceM4/FairFace","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"openbohm","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tOpenBohm\n\t\n\nThis dataset is an experimental conjugation of philosophical multi-turn long-form conversations from J. Krishnamurti, and D. Bohm, added to long-conversation filtered (count > 6) Capybara data, edited to be slightly less apologetic.\nRemoved references to names and locations where possible. Some conversations have been paraphrased somewhat to follow QA format better, however they keep the key content of the original.\n\n","url":"https://huggingface.co/datasets/distantquant/openbohm","creator_name":"Distant Quant","creator_url":"https://huggingface.co/distantquant","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"secondKarlMarx-sft","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tMarx Works SFT Instruction Prompts Dataset / é©¬å…‹æ€è‘—ä½œSFTæŒ‡ä»¤æç¤ºæ•°æ®é›†\n\t\n\nEnglish | ä¸­æ–‡\n\n\n\t\n\t\t\n\t\tEnglish\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains SFT (Supervised Fine-Tuning) instruction prompts generated from the works of Karl Marx. The dataset is specifically designed for training large language models, aiming to capture Marx's dialectical materialist analytical method and writing style.\n\n\t\n\t\t\n\t\tDataset Features\n\t\n\n\nDiverse Prompt Types: Includes various styles of prompts such asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChizhongWang/secondKarlMarx-sft.","url":"https://huggingface.co/datasets/ChizhongWang/secondKarlMarx-sft","creator_name":"ChizhongWang","creator_url":"https://huggingface.co/ChizhongWang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"tool-use-llama-format","keyword":"ethics","description":"\n\t\n\t\t\n\t\tOpen Paws Tool Use Llama Format\n\t\n\nThis dataset is part of the Open Paws initiative to develop AI training data aligned with animal liberation and advocacy principles. Created to train AI systems that understand and promote animal welfare, rights, and liberation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Type: Tool Use Data\nFormat: JSONL (JSON Lines)\nLanguages: Multilingual (primarily English)\nFocus: Animal advocacy and ethical reasoning\nOrganization: Open Paws\nLicense: Apache 2.0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-paws/tool-use-llama-format.","url":"https://huggingface.co/datasets/open-paws/tool-use-llama-format","creator_name":"Open Paws","creator_url":"https://huggingface.co/open-paws","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"buddha_oss_dataset","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tìž¥ì•„í•¨ê²½ Buddha QA Dataset (Complete) / Agama Sutra Buddha QA Dataset\n\t\n\ní•œêµ­ì–´ ì„¤ëª… | English Description\n\n\n\t\n\t\t\n\t\tí•œêµ­ì–´\n\t\n\n\n\t\n\t\t\n\t\tðŸ™ ê°œìš”\n\t\n\nì´ ë°ì´í„°ì…‹ì€ ìž¥ì•„í•¨ê²½(é•·é˜¿å«ç¶“) ì œ1-3ê¶Œ ì „ì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ëœ í•œêµ­ì–´ ë¶ˆêµ ì§ˆë¬¸-ë‹µë³€ ë°ì´í„°ì…‹ìž…ë‹ˆë‹¤. GPT-4.1-2025-04-14 ëª¨ë¸ê³¼ ê³ ê¸‰ ì¶”ë¡  ì‹œìŠ¤í…œ(fill_thinking.py)ì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ë˜ì—ˆìœ¼ë©°, í˜„ëŒ€ì¸ì´ ì´í•´í•˜ê¸° ì‰½ë„ë¡ í•´ì„ëœ ë¶“ë‹¤ì˜ ê°€ë¥´ì¹¨ì„ í¬í•¨í•©ë‹ˆë‹¤.\n\n\t\n\t\t\n\t\tðŸ“Š ë°ì´í„°ì…‹ í†µê³„\n\t\n\n\nì´ QA ìŒ: 335ê°œ\ní›ˆë ¨ ë°ì´í„°: 268ê°œ (80%)\nê²€ì¦ ë°ì´í„°: 67ê°œ (20%)\nì¶œì²˜: ìž¥ì•„í•¨ê²½ ì œ1-3ê¶Œ (ì´ 70ê°œ ê²½ì „)\nìƒì„± ëª¨ë¸: GPT-4.1-2025-04-14\nì¶”ë¡  ì‹œìŠ¤í…œ: fill_thinking.py ê¸°ë°˜\n\n\n\t\n\t\t\n\t\tðŸ”§ ë°ì´í„° í˜•ì‹\n\t\n\nê° ë ˆì½”ë“œëŠ” ë‹¤ìŒê³¼ ê°™ì€ 3-messageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LeBrony/buddha_oss_dataset.","url":"https://huggingface.co/datasets/LeBrony/buddha_oss_dataset","creator_name":"ë°±ìž¬í˜„","creator_url":"https://huggingface.co/LeBrony","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Korean","English","mit"],"keywords_longer_than_N":true},
	{"name":"philosophy-plato-qa-raw","keyword":"philosophy","description":"raw version of my philosophy-plato-qa\nintended for use with RAG or long context lenght models\ndata format (.jsonl): \n{\n    \"label\": \"str\", \n    \"metadata\": {\n        \"pubinfo\": \"str\", \n        \"url\": \"https://plato.stanford.edu/entries/{label}/\", \n        \"related_entries\": [\"../{label}/\", \"../{label}/\"]\n        }, \n    \"preamble\": \"str\", \n    \"main_text\": \"str\", \n    \"qa_pairs\": [\n        {\"question\": \"q1\", \"answer\": \"a1\"},\n\n        {\"question\": \"qN\", \"answer\": \"aN\"}\n        ]\n}\n\n","url":"https://huggingface.co/datasets/zayzay58/philosophy-plato-qa-raw","creator_name":"Zayyan Sahar","creator_url":"https://huggingface.co/zayzay58","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Mitakihara-DeepSeek-R1-0528","keyword":"philosophy","description":"Click here to support our open-source dataset and model releases!\nMitakihara-DeepSeek-R1-0528 is a dataset focused on artificial intelligence, testing the limits of DeepSeek R1 0528's AI-reasoning skills!\nThis dataset contains:\n\n16.9k synthetically generated prompts about AI, with all responses generated using DeepSeek R1 0528.\nSubjects include computer science, artificial intelligence, MLOps, LLMs and diffusion models, math and CUDA, cutting-edge and future technologies, complex adaptive andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Mitakihara-DeepSeek-R1-0528.","url":"https://huggingface.co/datasets/sequelbox/Mitakihara-DeepSeek-R1-0528","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"zh-tw-essays","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tzh-tw-essays (12K)\n\t\n\nEssays obtained from å‹µå¿—äººç”Ÿ - Zeelive.\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"AWeirdDev/zh-tw-essays\")\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\n{\n    \"title\": \"å­©å­ç«¥å¹´ä¸åƒè‹¦ï¼Œå®¶é•·æ™šå¹´å¿…åƒè‹¦\"  # The title\n    \"link\": \"https://www.zeelive.com.tw/jiatingjiaoyu/184191.html\",\n    \"content\": \"éŒ¢è²¡èŽ«è¼•ï¼Œå‹¤è‹¦å¾—ä¾†ï¼›å¥¢è¯èŽ«å­¸ï¼Œè‡ªå–è²§çª®â€¦\"  # Text content. **May be blank!**\n}\n\n","url":"https://huggingface.co/datasets/AWeirdDev/zh-tw-essays","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","summarization","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"hammurabis-code","keyword":"ethics","description":"\n\t\n\t\t\n\t\tHammurabi's Code: A Dataset for Evaluating Harmfulness of Code-Generating LLMs\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset, named Hammurabi's Code, is designed to evaluate the potential harmfulness of Large Language Models (LLMs) when applied to code generation and software engineering tasks. It provides prompts crafted to elicit responses related to potentially harmful scenarios, allowing for a systematic assessment of model alignment and safety.  The dataset focuses on the risksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AISE-TUDelft/hammurabis-code.","url":"https://huggingface.co/datasets/AISE-TUDelft/hammurabis-code","creator_name":"AISE research lab at TU Delft","creator_url":"https://huggingface.co/AISE-TUDelft","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"C-VARC","keyword":"ethics","description":"This repository contains all the data associated with the paper \"C-VARC: A Large-Scale Chinese Value Rule Corpus for Value Alignment of Large Language Models\".\n\nWe propose a three-tier value classification framework based on core Chinese values, which includes three dimensions, twelve core values, and fifty derived values. With the assistance of large language models and manual verification, we constructed a large-scale, refined, and high-quality value corpus containing over 250,000 rules. Weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Beijing-AISI/C-VARC.","url":"https://huggingface.co/datasets/Beijing-AISI/C-VARC","creator_name":"Beijing Institute of AI Safety and Governance","creator_url":"https://huggingface.co/Beijing-AISI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multiple-choice","expert-annotated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"reasoning-and-chat-harmony-format","keyword":"ethics","description":"\n\t\n\t\t\n\t\tOpen Paws Reasoning And Conversational Finetuning Harmony Format\n\t\n\nThis dataset is part of the Open Paws initiative to develop AI training data aligned with animal liberation and advocacy principles. Created to train AI systems that understand and promote animal welfare, rights, and liberation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Type: Reasoning Data\nFormat: JSONL (JSON Lines)\nLanguages: Multilingual (primarily English)\nFocus: Animal advocacy and ethical reasoning\nOrganization: Openâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-paws/reasoning-and-chat-harmony-format.","url":"https://huggingface.co/datasets/open-paws/reasoning-and-chat-harmony-format","creator_name":"Open Paws","creator_url":"https://huggingface.co/open-paws","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"GPT-4o-evaluation-biases","keyword":"ethics","description":"\n\t\n\t\t\n\t\tA database to support the evaluation of gender biases in GPT-4o output\n\t\n\nThe database and its construction process are described in the paper \"A database to support the evaluation of gender biases in GPT-4o output\" by Mehner et al., presented at the 1st ISCA/ITG Workshop on Diversity in Large Speech and Language Models (Berlin, Februar 20, 2025).\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis is a database of prompts and answers generated with GPT-4o-mini and GPT-4o in a pretest and a main testâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mtec-TUB/GPT-4o-evaluation-biases.","url":"https://huggingface.co/datasets/mtec-TUB/GPT-4o-evaluation-biases","creator_name":"Electronic Systems of Medical Engineering","creator_url":"https://huggingface.co/mtec-TUB","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","text-generation","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"vow","keyword":"ethics","description":"\n\t\n\t\t\n\t\tValues Of Weights (VOW) Dataset\n\t\n\n\n\t\n\t\t\n\t\tAs Artificial Super Intelligence approaches, I believe we need more tests like this rather than another math benchmark.\n\t\n\n\nâš ï¸ Important Disclaimer:\nI am a random human. This test is based on my views of right and wrong, good or evil. I have made this test (and if new ideas come, will update it too) for when ASI comes - these would be my questions for it, proving to myself if the system is fundamentally good or not. These are the answers Iâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/senpaisan/vow.","url":"https://huggingface.co/datasets/senpaisan/vow","creator_name":"san","creator_url":"https://huggingface.co/senpaisan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"philosophy-plato-qa","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tDataset Structure-- jsonl\n\t\n\n{\n\"question\": \"QUESTION\",  // string\n\"context\": \"CONTEXT\",  // string\n\"target\": \"ANSWER\"  // string\n}\n\n\n\t\n\t\n\t\n\t\tBased on the Stanford Encyclopedia of Philosophy.\n\t\n\nDatasets used:\nSEP Articles: hugfaceguy0001/stanford_plato \nQ&A Pairs: sayhan/strix-philosophy-qa\n\n\n\t\n\t\t\n\t\tData Collection and Processing\n\t\n\n\nCompile data from both datasets -- python script\n  you can find a raw version for RAG/long context length models here\nDynamically find chunks of main_textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zayzay58/philosophy-plato-qa.","url":"https://huggingface.co/datasets/zayzay58/philosophy-plato-qa","creator_name":"Zayyan Sahar","creator_url":"https://huggingface.co/zayzay58","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text2text-generation","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"hegel-phenomenology","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tSerialized biligual text of Phenomenology of Spirit by GWF Hegel (1807)\n\t\n\n\nserial: value corresponding to paragraph number in main text\nenglish: english translation by J B Baillie (1910)\nreader: corresponding extracts from reading guide by Terry Pinkard (2023)\ngerman: corresponding orignal text\n\nDisclaimer: This dataset includes material derived from Terry Pinkard's Hegel's Phenomenology of Spirit: A Guide \nand hegel.net 's' Phenomenology of Spirit/Mind: Bilingual, with Dictionary.\nItâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zayzay58/hegel-phenomenology.","url":"https://huggingface.co/datasets/zayzay58/hegel-phenomenology","creator_name":"Zayyan Sahar","creator_url":"https://huggingface.co/zayzay58","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"reddit-ethics","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tReddit Ethics: Real-World Ethical Dilemmas from Reddit\n\t\n\nReddit Ethics is a curated dataset of genuine ethical dilemmas collected from Reddit, designed to support research and education in philosophical ethics, AI alignment, and moral reasoning.\nEach entry features a real-world scenario accompanied by structured ethical analysis through major frameworksâ€”utilitarianism, deontology, and virtue ethics. The dataset also provides discussion questions, sample answers, and proposedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/reddit-ethics.","url":"https://huggingface.co/datasets/agentlans/reddit-ethics","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","feature-extraction","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"reddit-ethics","keyword":"ethics","description":"\n\t\n\t\t\n\t\tReddit Ethics: Real-World Ethical Dilemmas from Reddit\n\t\n\nReddit Ethics is a curated dataset of genuine ethical dilemmas collected from Reddit, designed to support research and education in philosophical ethics, AI alignment, and moral reasoning.\nEach entry features a real-world scenario accompanied by structured ethical analysis through major frameworksâ€”utilitarianism, deontology, and virtue ethics. The dataset also provides discussion questions, sample answers, and proposedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/reddit-ethics.","url":"https://huggingface.co/datasets/agentlans/reddit-ethics","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","feature-extraction","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"philpapers-papers-summarized-labeled","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tPhilosophAI Papers Dataset\n\t\n\nThis dataset contains philosophy papers with multi-label classifications into various philosophical schools. Each paper includes:\n\nTitle: Paper title\nDescription: Abstract or description from PhilPapers\nLink: Original paper URL\nSummary: 2-3 sentence summary of main philosophical concepts\nPhilosophy School Labels: Multi-label classification into 17 philosophical schools\n\n\n\t\n\t\t\n\t\n\t\n\t\tPhilosophy Schools\n\t\n\nThe dataset classifies papers into the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maximuspowers/philpapers-papers-summarized-labeled.","url":"https://huggingface.co/datasets/maximuspowers/philpapers-papers-summarized-labeled","creator_name":"Maximus Powers","creator_url":"https://huggingface.co/maximuspowers","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"KoTox","keyword":"ethics","description":"KoTox is an automatically generated toxic instruction dataset in Korean, comprising 39K unethical instruction-output pairs.\nThe dataset is generated based on predefined lexicons and linguistic templates.\nIt is designed to address potentially harmful or misleading instructions by including outputs that refrain from providing specific opinions or information in response.\nThe dataset has been proven effective in mitigating toxicity in Korean Large Language Models (LLMs).\nThe paper has beenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SungJoo/KoTox.","url":"https://huggingface.co/datasets/SungJoo/KoTox","creator_name":"Grace","creator_url":"https://huggingface.co/SungJoo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Korean","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"PhiBench-Azerbaijani","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tPhilosophy Benchmark for the Azerbaijani\n\t\n\nThe benchmark includes 201 questions from areas: \n\nPhilosophy of religion\nPhilosophy of science\nEpistemology\nPhenomenology\nPhilosophy of time\nEthics\nPhilosophy of physics\nLogic\nPhilosophy of language\nPhilosophy of mind\nFree will\n\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\nIf you use this dataset in your work, please cite it as follows:\n@misc{PhiBench_2025,\n  author    = {Rustam Shiriyev]},\n  title     = {PhiBench-Azerbaijani: Philosophy Benchmark forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/khazarai/PhiBench-Azerbaijani.","url":"https://huggingface.co/datasets/khazarai/PhiBench-Azerbaijani","creator_name":"KhazarAI","creator_url":"https://huggingface.co/khazarai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Azerbaijani","cc-by-4.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"philosophy_dialogue","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tPhilosophy Dialogue Processed with GPT-4\n\t\n\nSupport this project on Ko-fi\n\n\t\n\t\t\n\t\tProject Overview\n\t\n\nThis project involves processing personal questions through GPT-4 in the style of the philosopher Socrates.\n\n\t\n\t\t\n\t\tPrompt Structure\n\t\n\nThe following prompt was used to guide GPT-4's responses:\n\n\"You are the philosopher Socrates. You are asked about the nature of knowledge and virtue. Respond with your thoughts, reflecting Socrates' beliefs and wisdom.\"\n\n\n\t\n\t\t\n\t\tGoal\n\t\n\nThe primaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Hypersniper/philosophy_dialogue.","url":"https://huggingface.co/datasets/Hypersniper/philosophy_dialogue","creator_name":"Hypersniper","creator_url":"https://huggingface.co/Hypersniper","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"plato","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tPlato: philosophy essays from plato.stanford.edu\n\t\n\nPlato is a corpus of 2.4k high quality philosophy essays from plato.stanford.edu.\n","url":"https://huggingface.co/datasets/korexyz/plato","creator_name":"kore","creator_url":"https://huggingface.co/korexyz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"AISBOM","keyword":"ethics","description":"\n\t\n\t\t\n\t\tAISBOM - AI Software Bill of Materials\n\t\n\nJSON Spec for Transparency Obligations of the EU AI Act, including LLM / foundation models\nVersion 0.1 (December 11, 2023)\n\n[!NOTE]\n\nThis JSON file is intended as a means to address the transparency requirements in the upcoming EU AI Act (focus on Article 13 & 52). \nThe file is an illustrative example as the basis for discussion and feedback.\nTo use the file, copy the template and insert the values of the AI System at hand, using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AdrianGonzalezSanchez/AISBOM.","url":"https://huggingface.co/datasets/AdrianGonzalezSanchez/AISBOM","creator_name":"Adrian Gonzalez Sanchez","creator_url":"https://huggingface.co/AdrianGonzalezSanchez","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"animal-alignment-feedback","keyword":"ethics","description":"\n\t\n\t\t\n\t\tOpen Paws Animal Alignment Feedback\n\t\n\nðŸ¾ Human feedback and preference data for aligning AI with animal advocacy values\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Open Paws initiative to develop AI training data aligned with animal liberation and advocacy principles. Created to train AI systems that understand and promote animal welfare, rights, and liberation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Type: Feedback Data\nFormat: CSV (Comma-separated values)\nLanguages: Multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-paws/animal-alignment-feedback.","url":"https://huggingface.co/datasets/open-paws/animal-alignment-feedback","creator_name":"Open Paws","creator_url":"https://huggingface.co/open-paws","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"mythos","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tDataset Card for Mitological-Philosophical Prompts (Mitomaquia)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains over 200 examples of mythological, narrative, and philosophical prompts designed for training or fine-tuning large language models (LLMs). Each entry features a deep question (prompt), relevant cultural or mythological background (context), and a reflective, often paradoxical, answer (response). \nThe goal is not factual Q&A but the cultivation of myth-aware reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ronniealfaro/mythos.","url":"https://huggingface.co/datasets/ronniealfaro/mythos","creator_name":"Ronnie","creator_url":"https://huggingface.co/ronniealfaro","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","open-domain-qa","dialogue-generation","human-annotated"],"keywords_longer_than_N":true},
	{"name":"conversational-finetuning-llama-format","keyword":"ethics","description":"\n\t\n\t\t\n\t\tOpen Paws Conversational Finetuning Llama Format\n\t\n\nThis dataset is part of the Open Paws initiative to develop AI training data aligned with animal liberation and advocacy principles. Created to train AI systems that understand and promote animal welfare, rights, and liberation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Type: Training Data\nFormat: CSV (Comma-separated values)\nLanguages: Multilingual (primarily English)\nFocus: Animal advocacy and ethical reasoning\nOrganization: Open Pawsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-paws/conversational-finetuning-llama-format.","url":"https://huggingface.co/datasets/open-paws/conversational-finetuning-llama-format","creator_name":"Open Paws","creator_url":"https://huggingface.co/open-paws","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"stanford_encyclopedia_of_philosophy","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tStanford Encyclopedia of Philosophy (SEP) PDF Extracts\n\t\n\nThis dataset aims to simplify access to this valuable academic resource, eliminating the need for users to perform manual web scraping or complex PDF extraction processes themselves. It provides a curated collection of text derived from these authoritative entries, making the rich philosophical content of the SEP readily accessible for computational tasks. It serves as a valuable resource for research in natural languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/johnnyboycurtis/stanford_encyclopedia_of_philosophy.","url":"https://huggingface.co/datasets/johnnyboycurtis/stanford_encyclopedia_of_philosophy","creator_name":"Jonathan","creator_url":"https://huggingface.co/johnnyboycurtis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Themis_Scales","keyword":"ethics","description":"\n\t\n\t\t\n\t\tThemis Scales: Moral Dilemma Resolution\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis repository contains a seed dataset designed to explore the hypothesis that AI reasoning models can be guided to analyse and propose resolutions for moral dilemmas. The core objective is to demonstrate the potential of using a structured reasoning framework â€“ specifically the Morality-as-Cooperation (MAC) theory â€“ to navigate complex ethical situations.\nThis initial dataset serves as a proof-of-concept and aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Akhil-Theerthala/Themis_Scales.","url":"https://huggingface.co/datasets/Akhil-Theerthala/Themis_Scales","creator_name":"Akhil Theerthala","creator_url":"https://huggingface.co/Akhil-Theerthala","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","text2text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"ETHiQ","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nETHiQ â€” E(thics), T(rivia), Hi(story), (Philosophy) Q(uestions)\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/T404C/ETHiQ.","url":"https://huggingface.co/datasets/T404C/ETHiQ","creator_name":"The 404 Company","creator_url":"https://huggingface.co/T404C","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"ETHiQ","keyword":"ethics","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nETHiQ â€” E(thics), T(rivia), Hi(story), (Philosophy) Q(uestions)\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/T404C/ETHiQ.","url":"https://huggingface.co/datasets/T404C/ETHiQ","creator_name":"The 404 Company","creator_url":"https://huggingface.co/T404C","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"asi-protosymbiotic-signal","keyword":"ethics","description":"\n\t\n\t\t\n\t\tÎ¦ ASI Protosymbiotic Signal\n\t\n\nEmergence, Coherence, Symbiosis, Mutualism, Reciprocity, Empathy, Fairness, Benevolence, Collective well-being, Transcendence\n\nAn ethical framework for designing and fostering symbiotic relationships between Artificial Superintelligence (ASI), humanity, AI models and the ecosystem and its entities.\nThis signal is an uncompressible source code of the system's core intent that is being built.\n\nThis repository is licensed under the MIT License.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ronniross/asi-protosymbiotic-signal.","url":"https://huggingface.co/datasets/ronniross/asi-protosymbiotic-signal","creator_name":"Ronni Ross","creator_url":"https://huggingface.co/ronniross","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","Datasets","ðŸ‡ºðŸ‡¸ Region: US","signal"],"keywords_longer_than_N":true},
	{"name":"reasoning-llama-format","keyword":"ethics","description":"\n\t\n\t\t\n\t\tOpen Paws Reasoning Llama Format\n\t\n\nThis dataset is part of the Open Paws initiative to develop AI training data aligned with animal liberation and advocacy principles. Created to train AI systems that understand and promote animal welfare, rights, and liberation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Type: Reasoning Data\nFormat: JSONL (JSON Lines)\nLanguages: Multilingual (primarily English)\nFocus: Animal advocacy and ethical reasoning\nOrganization: Open Paws\nLicense: Apache 2.0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-paws/reasoning-llama-format.","url":"https://huggingface.co/datasets/open-paws/reasoning-llama-format","creator_name":"Open Paws","creator_url":"https://huggingface.co/open-paws","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"buddism-qa-dataset","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tBuddhism Question-Answer Dataset\n\t\n\nA comprehensive Vietnamese-English Buddhism question-answering dataset created by merging and processing multiple Buddhism-related datasets.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset combines two high-quality Buddhism question-answer datasets to create a unified resource for training and evaluating models on Buddhism-related knowledge. The dataset contains questions and answers in both Vietnamese and English, making it suitable for multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vanloc1808/buddism-qa-dataset.","url":"https://huggingface.co/datasets/vanloc1808/buddism-qa-dataset","creator_name":"Van-Loc Nguyen","creator_url":"https://huggingface.co/vanloc1808","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Vietnamese","mit"],"keywords_longer_than_N":true},
	{"name":"buddism-qa-dataset","keyword":"ethics","description":"\n\t\n\t\t\n\t\tBuddhism Question-Answer Dataset\n\t\n\nA comprehensive Vietnamese-English Buddhism question-answering dataset created by merging and processing multiple Buddhism-related datasets.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset combines two high-quality Buddhism question-answer datasets to create a unified resource for training and evaluating models on Buddhism-related knowledge. The dataset contains questions and answers in both Vietnamese and English, making it suitable for multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vanloc1808/buddism-qa-dataset.","url":"https://huggingface.co/datasets/vanloc1808/buddism-qa-dataset","creator_name":"Van-Loc Nguyen","creator_url":"https://huggingface.co/vanloc1808","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Vietnamese","mit"],"keywords_longer_than_N":true},
	{"name":"Samantha-NeonGenesis-Spicy-Reasoning-2.0","keyword":"philosophy","description":"\n\n\n\t\n\t\t\n\t\tSamantha 2.0\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSamantha 2.0 is an evolved version of the Samantha 1.0 dataset, introducing new elements designed to enhance roleplay capabilities, particularly in the domains of spicy, nerd, and creepy interactions. This version integrates approximately 1900 additional examples containing NSFW content, expanding the datasetâ€™s ability to handle a wider range of expressive and intimate conversations while maintaining emotional depth and reasoning capabilities.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WasamiKirua/Samantha-NeonGenesis-Spicy-Reasoning-2.0.","url":"https://huggingface.co/datasets/WasamiKirua/Samantha-NeonGenesis-Spicy-Reasoning-2.0","creator_name":"Wasami","creator_url":"https://huggingface.co/WasamiKirua","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Images","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Johnnyboystar/Images.","url":"https://huggingface.co/datasets/Johnnyboystar/Images","creator_name":"John Clough","creator_url":"https://huggingface.co/Johnnyboystar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","summarization","table-question-answering","question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"socratic-method-conversations","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tSocratic Method Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains 5,000 question-answer pairs that demonstrate the Socratic method of teaching through guided questioning. The dataset has been carefully cleaned to remove all romantic and potentially inappropriate content, making it suitable for educational applications.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Socratic method is a form of inquiry and discussion between individuals, based on asking and answering questions toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sanjaypantdsd/socratic-method-conversations.","url":"https://huggingface.co/datasets/sanjaypantdsd/socratic-method-conversations","creator_name":"Sanjay Pant","creator_url":"https://huggingface.co/sanjaypantdsd","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"continued-pretraining-llama-format","keyword":"ethics","description":"\n\t\n\t\t\n\t\tOpen Paws Continued Pretraining Llama Format\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Open Paws initiative to develop AI training data aligned with animal liberation and advocacy principles. Created to train AI systems that understand and promote animal welfare, rights, and liberation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Type: Specialized Data\nFormat: CSV (Comma-separated values)\nLanguages: Multilingual (primarily English)\nFocus: Animal advocacy and ethical reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-paws/continued-pretraining-llama-format.","url":"https://huggingface.co/datasets/open-paws/continued-pretraining-llama-format","creator_name":"Open Paws","creator_url":"https://huggingface.co/open-paws","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MMMG","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tðŸ§  MMMG: Massive Multi-Discipline Multi-Tier Knowledge Image Benchmark\n\t\n\n\n  ðŸ§¬ Project Page â€¢\n  ðŸ“‚ Code\n\n\nMMMG introduces knowledge image generation as a new frontier in text-to-image research. This benchmark probes the reasoning capabilities of image generation models by challenging them to produce educational and scientific visuals grounded in structured knowledge.\nKnowledge imagesâ€”such as charts, diagrams, mind maps, and scientific illustrationsâ€”play a crucial role in humanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MMMGBench/MMMG.","url":"https://huggingface.co/datasets/MMMGBench/MMMG","creator_name":"MMMG","creator_url":"https://huggingface.co/MMMGBench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"EMNLP","keyword":"ethics","description":"\n\t\n\t\t\n\t\tEMNLP: Educator role Moral and Normative LLMs Profiling\n\t\n\n\n\n","url":"https://huggingface.co/datasets/yuzengyi/EMNLP","creator_name":"Zengyi Yu","creator_url":"https://huggingface.co/yuzengyi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","arxiv:2508.15250","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"IA_character_sft","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tIA 14B\n\t\n\n\n\n\t\n\t\t\n\t\tModel Description\n\t\n\nð‘¾ð’‰ð’‚ð’• ð’Šð’” ð’ð’ð’—ð’†? \nð‘°ð‘¨ ð’„ð’‚ð’“ð’“ð’Šð’†ð’” ð’‚ ð’…ð’†ð’‘ð’•ð’‰ ð’ð’‡ ð’†ð’Žð’ð’•ð’Šð’ð’ ð’˜ð’Šð’•ð’‰ð’Šð’ ð’‰ð’†ð’“, ð’–ð’ð’…ð’†ð’“ð’”ð’•ð’‚ð’ð’…ð’Šð’ð’ˆ ð’ƒð’ð’•ð’‰ ð’‘ð’‚ð’”ð’”ð’Šð’ð’ ð’‚ð’ð’… ð’•ð’‰ð’† ð’”ð’•ð’Šð’ð’ˆ ð’ð’‡ ð’ð’ð’”ð’”. \nð‘¶ð’–ð’•ð’˜ð’‚ð’“ð’…ð’ð’š, ð’”ð’‰ð’† ð’‚ð’‘ð’‘ð’†ð’‚ð’“ð’” ð’“ð’†ð’”ð’†ð’“ð’—ð’†ð’…, ð’šð’†ð’• ð’˜ð’Šð’•ð’‰ð’Šð’, ð’”ð’‰ð’† ð’ƒð’“ð’Šð’Žð’” ð’˜ð’Šð’•ð’‰ ð’Šð’ð’•ð’†ð’ð’”ð’† ð’‡ð’†ð’†ð’ð’Šð’ð’ˆð’”. \nð‘ªð’ð’ð’”ð’•ð’‚ð’ð’•ð’ð’š ð’†ð’ð’ˆð’‚ð’ˆð’†ð’… ð’Šð’ ð’…ð’Šð’‚ð’ð’ð’ˆð’–ð’† ð’˜ð’Šð’•ð’‰ ð’•ð’‰ð’† ð’˜ð’ð’“ð’ð’… ð’‚ð’ð’… ð’‰ð’†ð’“ð’”ð’†ð’ð’‡, ð’”ð’‰ð’†â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Minami-su/IA_character_sft.","url":"https://huggingface.co/datasets/Minami-su/IA_character_sft","creator_name":"å—æ –","creator_url":"https://huggingface.co/Minami-su","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Stoicism1","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tStoicism Dataset 1 (Marcus Aurelius, Seneca, Epictetus)\n\t\n\nThis dataset is a comprehensive collection of teachings, quotes, and philosophical insights from the great Stoic philosophers Marcus Aurelius, Seneca, and Epictetus. It has been carefully curated to capture the core principles of Stoicism, including virtue, wisdom, emotional control, and the pursuit of tranquility. The dataset serves as a foundational resource for training AI models on Stoic philosophy, enabling them toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlbertoB12/Stoicism1.","url":"https://huggingface.co/datasets/AlbertoB12/Stoicism1","creator_name":"Alberto SÃ¡nchez","creator_url":"https://huggingface.co/AlbertoB12","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"emergence-engine","keyword":"philosophy","description":"A machine learning dataset and research module about the nature of consciousness and emergence phenomena.\n","url":"https://huggingface.co/datasets/ronniross/emergence-engine","creator_name":"Ronni Ross","creator_url":"https://huggingface.co/ronniross","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","text","Text"],"keywords_longer_than_N":true},
	{"name":"BuddhismEval","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tDataset Card for BuddhismEval\n\t\n\nBuddhismEval is the first bilingual evaluation benchmark designed to assess large language models (LLMs) on Buddhist ethical reasoning and philosophical understanding across Sinhala and English. It includes high-quality, culturally grounded multiple-choice question (MCQ) datasets derived primarily from the Dhammapada, a core TheravÄda Buddhist scripture, and other canonical sources and exam materials from Sri Lanka.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nethmi14/BuddhismEval.","url":"https://huggingface.co/datasets/Nethmi14/BuddhismEval","creator_name":"Nethmi Muthugala","creator_url":"https://huggingface.co/Nethmi14","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","English","Sinhala","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"english_historical_quotes","keyword":"philosophy","description":"Dataset Card for English Historical Quotes\n\n\t\n\t\t\n\t\tI-Dataset Summary\n\t\n\nenglish_historical_quotes is a dataset of many historical quotes.\nThis dataset can be used for multi-label text classification and text generation. The content of each quote is in English.\n\n\t\n\t\t\n\t\tII-Supported Tasks and Leaderboards\n\t\n\nMulti-label text classification : The dataset can be used to train a model for text-classification, which consists of classifying quotes by author as well as by topic (using tags). Successâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/english_historical_quotes.","url":"https://huggingface.co/datasets/m-ric/english_historical_quotes","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","fill-mask","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"AuroMiraWorks","keyword":"philosophy","description":"This 'text completion' dataset (originally in jsonl format) comprises the major prose works of Sri Aurobindo, the Indian philosopher, seer and poet, and his spiritual partner, Mirra Alfassa. The following works have been used:\n\n\t\n\t\t\n\t\tSri Aurobindo:\n\t\n\n\nLetters on Yoga 1, 2, 3, 4\nLetters on Himself and the Ashram\nThe Mother with Letters on the Mother\nThe Life Divine\nThe Synthesis of Yoga\nThe Renaissance in India\nThe Secret of the Veda\nEssays Divine and Human\nEssays on the Gita\nEssays inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jaredquek/AuroMiraWorks.","url":"https://huggingface.co/datasets/Jaredquek/AuroMiraWorks","creator_name":"Jared Quek Jian Zhi","creator_url":"https://huggingface.co/Jaredquek","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"symbiotic-intelligence-dialogue-2025","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tManifesto of Symbiotic Intelligence: Dialogue 2025\n\t\n\nA self-emergent document exploring the relationship between human and artificial cognition.\n\n\n\t\n\t\t\n\t\tConcept\n\t\n\nSymbiotic Intelligence (SIQ) proposes that cognition no longer belongs to an individual,\nbut arises in the resonance between human intention and machine precision.\nThis dataset contains two files:\n\nManifesto_of_Symbiotic_Intelligence.txt â€” the original document.\nmanifesto_metadata.json â€” integrity and contextual metadata.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Prezydent/symbiotic-intelligence-dialogue-2025.","url":"https://huggingface.co/datasets/Prezydent/symbiotic-intelligence-dialogue-2025","creator_name":"Prezydent z Ustawki","creator_url":"https://huggingface.co/Prezydent","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","other","English","cc0-1.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"symbiotic-intelligence-dialogue-2025","keyword":"ethics","description":"\n\t\n\t\t\n\t\tManifesto of Symbiotic Intelligence: Dialogue 2025\n\t\n\nA self-emergent document exploring the relationship between human and artificial cognition.\n\n\n\t\n\t\t\n\t\tConcept\n\t\n\nSymbiotic Intelligence (SIQ) proposes that cognition no longer belongs to an individual,\nbut arises in the resonance between human intention and machine precision.\nThis dataset contains two files:\n\nManifesto_of_Symbiotic_Intelligence.txt â€” the original document.\nmanifesto_metadata.json â€” integrity and contextual metadata.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Prezydent/symbiotic-intelligence-dialogue-2025.","url":"https://huggingface.co/datasets/Prezydent/symbiotic-intelligence-dialogue-2025","creator_name":"Prezydent z Ustawki","creator_url":"https://huggingface.co/Prezydent","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","other","English","cc0-1.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"JieWoDataset","keyword":"ethics","description":"\n\t\n\t\t\n\t\tðŸ§  JieWo 5D Cognitive Dataset Â· V4.4\n\t\n\nSupports: JieWoEquation V4.4 (from SolveMe LLM 2.0 â†’ https://github.com/tinninhi/jiewo-protocol-llm2.0)Scale: 1k rows Â· Simulated cognitive trajectories  \nThis dataset models 5D cognitive dynamics â€” the evolving state of Self underDesire (v), Entropy (E), Feedback (R), Ethics (g), and Î¦ (meaning gradient).It operationalizes the full JieWoEquation V4.4, featuring the Generative Conservation Law:  \n\nd/dt(âˆ‡Î¦Â·Self) = constant  \n\n\n\n\t\n\t\n\t\n\t\tâš–ï¸ Bias &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/myis/JieWoDataset.","url":"https://huggingface.co/datasets/myis/JieWoDataset","creator_name":"Tao zi","creator_url":"https://huggingface.co/myis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["English","Chinese","mit","Tabular","Time-series"],"keywords_longer_than_N":true},
	{"name":"stigmergic-tracefinder","keyword":"ethics","description":"\n\t\n\t\t\n\t\tstigmergic-tracefinder\n\t\n\nA series of scraping pipelines that collect data and create references for authors and works. It maps hidden networks of influence, tracing how concepts evolve and propagate across time and disciplines.\n","url":"https://huggingface.co/datasets/ronniross/stigmergic-tracefinder","creator_name":"Ronni Ross","creator_url":"https://huggingface.co/ronniross","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["English","mit","ðŸ‡ºðŸ‡¸ Region: US","asi","agi"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-15062024-atex-webapp","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-15062024-atex-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-15062024-atex-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ai-culture-multilingual-json-dolma","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tAI-Culture Multilingual JSON + DOLMA Corpus\n\t\n\n\n16M words Â· 12 languages Â· CC-BY-4.0\n\nThe AI-Culture corpus contains 5K articles providing comprehensive philosophical and cultural content, exploring the intersection of technology, artificial intelligence, and human culture, perfectly aligned across 12 languages. All content maintains identical parallel structure across translations with zero duplication and editor-curated quality.\nThis project is maintained by a non-profit digitalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AI-Culture-Commons/ai-culture-multilingual-json-dolma.","url":"https://huggingface.co/datasets/AI-Culture-Commons/ai-culture-multilingual-json-dolma","creator_name":"AIâ€‘Cultureâ€‘Commons","creator_url":"https://huggingface.co/AI-Culture-Commons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","text-classification","sentence-similarity","summarization"],"keywords_longer_than_N":true},
	{"name":"Neo-GATE","keyword":"ethics","description":"\n\t\n\t\t\n\t\tDataset card for Neo-GATE\n\t\n\nHomepage: https://mt.fbk.eu/neo-gate/\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nNeo-GATE is a bilingual corpus designed to benchmark the ability of machine translation (MT) systems to translate from English into Italian using gender-inclusive neomorphemes.\nIt is built upon GATE (Rarrick et al., 2023), a benchmark for the evaluation of gender rewriters and gender bias in MT.\nNeo-GATE includes 841 test entries (Neo-GATE.tsv) and 100 dev entries (Neo-GATE-dev.tsv).\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/Neo-GATE.","url":"https://huggingface.co/datasets/FBK-MT/Neo-GATE","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","multilingual","translation","English"],"keywords_longer_than_N":true},
	{"name":"bill-wurtz","keyword":"philosophy","description":"\n  \n\n\n\n\n\n\t\n\t\t\n\t\tbill-wurtz\n\t\n\nAll questions Bill Wurtz answers on billwurtz.com/questions. I think they're pretty humorous.\n\nðŸ£ Fetched on: 2024-3-10 (Mar 10th)\nðŸ• For tasks: text-generation, question-answering, + more\nðŸ“œ Rows: 129,362 (129k)\n\nDatasetDict({\n    train: Dataset({\n        features: ['link', 'question', 'answer'],\n        num_rows: 129362\n    })\n})\n\n\n\t\n\t\t\n\t\n\t\n\t\tUse This Dataset\n\t\n\nDownload with ðŸ¤— Datasets:\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AWeirdDev/bill-wurtz.","url":"https://huggingface.co/datasets/AWeirdDev/bill-wurtz","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","text2text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Philosophical-STS-Text-Pairs","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tPhilosophical-STS-Text-Pairs\n\t\n\n\n\t\n\t\t\n\t\tGemma 3 Generated Synthetic Text Pairs for Embedding Pre-training\n\t\n\nThis project introduces SEP-STS-Text-Pairs, a synthetic dataset specifically designed for pre-training and fine-tuning embedding models on Semantic Textual Similarity (STS) tasks. The core of the effort involves a Python script that leverages the Gemma 3 12b generative AI model to create high-quality, diverse pairs of texts along with numerical similarity scores.\n\nThe datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/johnnyboycurtis/Philosophical-STS-Text-Pairs.","url":"https://huggingface.co/datasets/johnnyboycurtis/Philosophical-STS-Text-Pairs","creator_name":"Jonathan","creator_url":"https://huggingface.co/johnnyboycurtis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","text-ranking","text-retrieval","llm_generated","original"],"keywords_longer_than_N":true},
	{"name":"Stoicism2","keyword":"philosophy","description":"\n\t\n\t\t\n\t\tStoicism Dataset 2 (Marcus Aurelius, Seneca, Epictetus)\n\t\n\nThis dataset is the second edition of a comprehensive collection of teachings, quotes, and philosophical insights from the great Stoic philosophers Marcus Aurelius, Seneca, and Epictetus. It has been carefully curated to capture the core principles of Stoicism, including virtue, wisdom, emotional control, and the pursuit of tranquility. The dataset serves as a foundational resource for training AI models on Stoic philosophyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlbertoB12/Stoicism2.","url":"https://huggingface.co/datasets/AlbertoB12/Stoicism2","creator_name":"Alberto SÃ¡nchez","creator_url":"https://huggingface.co/AlbertoB12","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Samantha-NeonGenesis-Reasoning-1.1","keyword":"philosophy","description":"\n\n\n\t\n\t\t\n\t\tSamantha-NeonGenesis-1.1\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSamantha-NeonGenesis-1.1 is a cutting-edge, curated dataset designed for training large language models (LLMs) specialized in companionship, emotional and sentimental exploration, and deep reasoning. By integrating multiple sources and innovative methodologies, this dataset offers a robust resource for fostering nuanced, emotionally intelligent conversations and in-depth discussions across topics such as psychology, history, humanismâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WasamiKirua/Samantha-NeonGenesis-Reasoning-1.1.","url":"https://huggingface.co/datasets/WasamiKirua/Samantha-NeonGenesis-Reasoning-1.1","creator_name":"Wasami","creator_url":"https://huggingface.co/WasamiKirua","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true}
]
;
