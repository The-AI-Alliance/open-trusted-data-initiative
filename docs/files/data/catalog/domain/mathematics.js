const data_for_domain_mathematics = 
[
	{"name":"IMO-geometry","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/theblackcat102/IMO-geometry","creator_name":"theblackcat102","creator_url":"https://huggingface.co/theblackcat102","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIMO geometry questions\\n\\t\\n\\n32 IMO geometry questions from 2000 to 2021 (filter by category \\\"IMO\\\")\\nData source : https://artofproblemsolving.com/wiki/index.php/Category:Olympiad_Geometry_Problems\\n55 more questions from others (other regional olympiad competition) as well as 13 GPT-4 generate ones.\\nOnly the raw questions are available, if you want to use them for alpha geometry there's still a missing translation step.\\nThis is the example shown in Alpha Geometry\\nQuestion:\\nLet ABC be… See the full description on the dataset page: https://huggingface.co/datasets/theblackcat102/IMO-geometry.","first_N":5,"first_N_keywords":["English","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"basic-math-1m","keyword":"math","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrfakename/basic-math-1m","creator_name":"mrfakename","creator_url":"https://huggingface.co/mrfakename","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBasic Math 1M\\n\\t\\n\\nA dataset of 1 million basic arithmetic problems with potential user prompts.\\nBasic Math 10M was inspired by Simple Math.\\n","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Luganda_Sci-Math-Bio_Translations","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allandclive/Luganda_Sci-Math-Bio_Translations","creator_name":"Allan D Clive","creator_url":"https://huggingface.co/allandclive","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLuganda Sci-Math-Bio Translations\\n\\t\\n\\nThis dataset contains Luganda and English translations of biologicial, mathematical and scientific terms\\n","first_N":5,"first_N_keywords":["text2text-generation","translation","Ganda","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"polytopes-4d","keyword":"math","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/calabi-yau-data/polytopes-4d","creator_name":"Calabi-Yau data","creator_url":"https://huggingface.co/calabi-yau-data","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFour-Dimensional Reflexive Lattice Polytopes\\n\\t\\n\\nThis dataset contains all four-dimensional reflexive lattice polytopes. The data was\\ncompiled by Maximilian Kreuzer and Harald Skarke in\\narXiv:hep-th/0002240. More information is\\navailable at the Calabi-Yau data website.\\nPlease cite the paper when referencing this dataset:\\n@article{Kreuzer:2000xy,\\n    author = \\\"Kreuzer, Maximilian and Skarke, Harald\\\",\\n    title = \\\"{Complete classification of reflexive polyhedra in four-dimensions}\\\"… See the full description on the dataset page: https://huggingface.co/datasets/calabi-yau-data/polytopes-4d.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","100M - 1B","parquet","Tabular","Datasets"],"keywords_longer_than_N":true},
	{"name":"ChatML-Capybara","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-Capybara","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"LDJnr/Capybara in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"LDJnr/Capybara\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = []\\n    conversationColumn = columns[\\\"conversation\\\"]\\n\\n    for i in range(len(conversationColumn)):\\n        messages.append({\\n            \\\"role\\\":… See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-Capybara.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MetaMathQA","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sharathhebbar24/MetaMathQA","creator_name":"Sharath S Hebbar","creator_url":"https://huggingface.co/Sharathhebbar24","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMeta Math Filtered\\n\\t\\n\\nThis is a combined and filtered (removed all the redundant rows) version of meta-math/MetaMathQA and meta-math/MetaMathQA-40K\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"Sharathhebbar24/MetaMathQA\\\", split=\\\"train\\\")\\n\\n","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"muInstruct","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EleutherAI/muInstruct","creator_name":"EleutherAI","creator_url":"https://huggingface.co/EleutherAI","description":"μInstruct is a dataset of 1600 instruction-response pairs collected from highly-rated Stack Exchange answers, the Khan Academy subset of AMPS, and the MATH training set. All training examples are valid Markdown have been manually reviewed by a human for quality. \\nThe μInstruct dataset is most useful when mixed in with larger instruction or chat datasets, such as OpenHermes. Because μInstruct is especially high-quality, you may consider oversampling it in your training mixture. \\nμInstruct was… See the full description on the dataset page: https://huggingface.co/datasets/EleutherAI/muInstruct.","first_N":5,"first_N_keywords":["text2text-generation","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Knowledge_Pile","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Query-of-CC/Knowledge_Pile","creator_name":"Query-of-CC","creator_url":"https://huggingface.co/Query-of-CC","description":"Knowledge Pile is a knowledge-related data leveraging Query of CC.\\nThis dataset is a partial of Knowledge Pile(about 40GB disk size), full datasets have been released in [🤗 knowledge_pile_full], a total of 735GB disk size and 188B tokens (using Llama2 tokenizer).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuery of CC\\n\\t\\n\\nJust like the figure below, we initially collected seed information in some specific domains, such as keywords, frequently asked questions, and textbooks, to serve as inputs for the Query Bootstrapping… See the full description on the dataset page: https://huggingface.co/datasets/Query-of-CC/Knowledge_Pile.","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"TemplateGSM","keyword":"mathematical-reasoning","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/math-ai/TemplateGSM","creator_name":"math-ai","creator_url":"https://huggingface.co/math-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\tTraining and Evaluating Language Models with Template-based Data Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTemplateGSM Dataset\\n\\t\\n\\nThe TemplateGSM dataset is a large-scale collection of over 7 million (with potential for unlimited generation) grade school math problems, each paired with both code-based and natural language solutions.  Designed to advance mathematical reasoning in language models, this dataset presents a diverse range of challenges to assess and improve model capabilities in solving… See the full description on the dataset page: https://huggingface.co/datasets/math-ai/TemplateGSM.","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","10M - 100M","Tabular"],"keywords_longer_than_N":true},
	{"name":"hercules-v2.0","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/hercules-v2.0","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Hercules-v2.0\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nDataset Name: Hercules-v2.0\\nVersion: 2.0\\nDate of Release: February 2, 2024\\nSize: 1,307,174\\nData Sources: \\nHercules-v2.0 is an enriched instruction dataset derived from OpenHermes-2.5, aimed at enhancing its diversity and scope. The dataset amalgamates contributions from various data sources, with a strong emphasis on Biology, Physics, Medicine, Math, Computer Science, Instruction Following, Function Calling, and Roleplay. The data… See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/hercules-v2.0.","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Math-Multiturn-1K-ShareGPT","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PJMixers/Math-Multiturn-1K-ShareGPT","creator_name":"Peanut Jar Mixers","creator_url":"https://huggingface.co/PJMixers","description":"All samples were created with this script, no GPT, just python.\\n","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Math-Multiturn-100K-ShareGPT","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PJMixers/Math-Multiturn-100K-ShareGPT","creator_name":"Peanut Jar Mixers","creator_url":"https://huggingface.co/PJMixers","description":"All samples were created with this script, no GPT, just python.\\n","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"Math-Multiturn-10K-ShareGPT","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PJMixers/Math-Multiturn-10K-ShareGPT","creator_name":"Peanut Jar Mixers","creator_url":"https://huggingface.co/PJMixers","description":"All samples were created with this script, no GPT, just python.\\n","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Open-Platypus","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sharathhebbar24/Open-Platypus","creator_name":"Sharath S Hebbar","creator_url":"https://huggingface.co/Sharathhebbar24","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen Platypus Code\\n\\t\\n\\nThis is a cleansed version of garage-bAInd/Open-Platypus\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"Sharathhebbar24/Open-Platypus\\\", split=\\\"train\\\")\\n\\n","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ZharfaTech-Open-Platypus-Persian-Farsi","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZharfaTech/ZharfaTech-Open-Platypus-Persian-Farsi","creator_name":"ZharfaTech","creator_url":"https://huggingface.co/ZharfaTech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPersian Open-Platypus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout ZharfaTech\\n\\t\\n\\nZharfaTech is a pioneer in developing Language Learning Models (LLMs) tailored for the Persian language, aiming to empower over 100 million Persian speakers worldwide. Our mission encompasses bridging the digital divide in LLM-related services like content generation, customer relationship systems, and more, with a dual approach of fostering open-source collaboration and delivering high-value, specialized closed-source… See the full description on the dataset page: https://huggingface.co/datasets/ZharfaTech/ZharfaTech-Open-Platypus-Persian-Farsi.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","summarization","question-answering","Persian"],"keywords_longer_than_N":true},
	{"name":"math_LinearAlgebra_ner","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hengzongshu/math_LinearAlgebra_ner","creator_name":"Xiaziye","creator_url":"https://huggingface.co/Hengzongshu","description":"这是一个基于维基百科制作的轻量训练集，主要用于数学线性代数领域的英语命名实体识别，以及知识图谱构建。\\n根据维基百科词条对链接进行串联选取，共有234句，无标点符号、数字，不区分字母大小写。\\n标签标注使用Doccano，有jsonl，dataset与txt版本。（jsonl可转换为json）\\nThis is a lightweight training dataset created based on Wikipedia, primarily used for English Named Entity Recognition (NER) in the field of mathematics linear algebra, as well as knowledge graph construction. \\nLink selections were made based on Wikipedia entries, resulting in 234 sentences. The sentences contain no punctuation, numbers, and are… See the full description on the dataset page: https://huggingface.co/datasets/Hengzongshu/math_LinearAlgebra_ner.","first_N":5,"first_N_keywords":["token-classification","English","mit","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"YarraEsrever","keyword":"math","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewiswatson/YarraEsrever","creator_name":"Lewis","creator_url":"https://huggingface.co/lewiswatson","description":"Introducing YarraEsrever: The Ultimate Integer Array Reversal Dataset for Cutting-Edge AI Research\\nPrepare to revolutionise your machine learning workflows with YarraEsrever, a groundbreaking dataset that pushes the boundaries of integer array reversal. This state-of-the-art collection boasts an impressive 1,000,000 unique supervised training pairs, meticulously curated to empower researchers and data scientists in their quest to master the art of reversing integer arrays.\\nDon't waste your… See the full description on the dataset page: https://huggingface.co/datasets/lewiswatson/YarraEsrever.","first_N":5,"first_N_keywords":["translation","afl-3.0","1M - 10M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"MMOS","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cyzhh/MMOS","creator_name":"Yezeng Chen","creator_url":"https://huggingface.co/cyzhh","description":"ArXiv | Models | Data | Code | \\nYou can download the dataset as follows\\nfrom datasets import load_dataset\\nds = load_dataset(\\\"cyzhh/MMOS\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema\\n\\t\\n\\nEach dataset row has the following structure\\n{\\n  \\\"idx\\\": ..., # problem id\\n  \\\"prompt\\\": ..., # problem \\n  \\\"completion\\\": ... # reasoning path with python\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nWe do not alter the license of any of the underlying data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nFor the MMOS, cite \\n@misc{chen2024empirical,\\n      title={An Empirical Study… See the full description on the dataset page: https://huggingface.co/datasets/cyzhh/MMOS.","first_N":5,"first_N_keywords":["question-answering","English","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"math-orca-arch","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pharaouk/math-orca-arch","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\n\\nThis dataset contains ~200K grade school math word problems. All the answers in this dataset is generated using Azure GPT4-Turbo. Please refer to Orca-Math: Unlocking the potential of\\nSLMs in Grade School Math for details about the dataset construction. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\n\\n\\nRepository: microsoft/orca-math-word-problems-200k\\nPaper: Orca-Math: Unlocking the potential of\\nSLMs in Grade School Math\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDirect Use\\n\\t\\n\\n\\n\\nThis dataset has been… See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/math-orca-arch.","first_N":5,"first_N_keywords":["question-answering","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"distilabel-capybara-kto-15k-binarized","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla/distilabel-capybara-kto-15k-binarized","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCapybara-KTO 15K binarized\\n\\t\\n\\n\\nA KTO signal transformed version of the highly loved Capybara-DPO 7K binarized, A DPO dataset built with distilabel atop the awesome LDJnr/Capybara\\n\\n\\nThis is a preview version to collect feedback from the community. v2 will include the full base dataset and responses from more powerful models.\\n\\n\\n    \\n\\n\\n\\n  \\n    \\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy KTO?\\n\\t\\n\\nThe KTO paper states:\\n\\nKTO matches or exceeds DPO performance at scales from 1B to 30B parameters.1 That is… See the full description on the dataset page: https://huggingface.co/datasets/argilla/distilabel-capybara-kto-15k-binarized.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"orca-math-word-problems-200k","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/agicorp/orca-math-word-problems-200k","creator_name":"agicorp","creator_url":"https://huggingface.co/agicorp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\n\\nThis dataset contains ~200K grade school math word problems. All the answers in this dataset is generated using Azure GPT4-Turbo. Please refer to Orca-Math: Unlocking the potential of\\nSLMs in Grade School Math for details about the dataset construction. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\n\\n\\nRepository: microsoft/orca-math-word-problems-200k\\nPaper: Orca-Math: Unlocking the potential of\\nSLMs in Grade School Math\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDirect Use\\n\\t\\n\\n\\n\\nThis dataset has been… See the full description on the dataset page: https://huggingface.co/datasets/agicorp/orca-math-word-problems-200k.","first_N":5,"first_N_keywords":["question-answering","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"MetaMathQA","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/agicorp/MetaMathQA","creator_name":"agicorp","creator_url":"https://huggingface.co/agicorp","description":"View the project page:\\nhttps://meta-math.github.io/\\nsee our paper at https://arxiv.org/abs/2309.12284\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\nAll MetaMathQA data are augmented from the training sets of GSM8K and MATH. \\nNone of the augmented data is from the testing set.\\nYou can check the original_question in meta-math/MetaMathQA, each item is from the GSM8K or MATH train set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Details\\n\\t\\n\\nMetaMath-Mistral-7B is fully fine-tuned on the MetaMathQA datasets and based on the powerful Mistral-7B model.… See the full description on the dataset page: https://huggingface.co/datasets/agicorp/MetaMathQA.","first_N":5,"first_N_keywords":["mit","100K - 1M","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"MathInstruct","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/agicorp/MathInstruct","creator_name":"agicorp","creator_url":"https://huggingface.co/agicorp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🦣 MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning\\n\\t\\n\\nMathInstruct is a meticulously curated instruction tuning dataset that is lightweight yet generalizable. MathInstruct is compiled from 13 math rationale datasets, six of which are newly curated by this work. It uniquely focuses on the hybrid use of chain-of-thought (CoT) and program-of-thought (PoT) rationales, and ensures extensive coverage of diverse mathematical fields. \\nProject Page:… See the full description on the dataset page: https://huggingface.co/datasets/agicorp/MathInstruct.","first_N":5,"first_N_keywords":["text-generation","English","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"basic-math-10m","keyword":"math","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrfakename/basic-math-10m","creator_name":"mrfakename","creator_url":"https://huggingface.co/mrfakename","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBasic Math 10M\\n\\t\\n\\nA dataset of 10 million basic arithmetic problems with potential user prompts. It is an extended version of Basic Math 1M.\\nBasic Math 10M was inspired by Simple Math.\\n","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","cc0-1.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"OpenCerebrum-SFT","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/OpenCerebrum-SFT","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenCerebrum SFT subset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nOpenCerebrum is my take on creating an open source version of Aether Research's proprietary Cerebrum dataset. This repository contains the SFT subset, which contains about 1,200,00 examples. Unfortunately, I was unsure about how I would compress this dataset to just 5,000 examples like in the original Cerebrum dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration\\n\\t\\n\\nThis dataset was curated using a simple and logical rationale. The goal was to use… See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/OpenCerebrum-SFT.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"dart-math-pool-math","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hkust-nlp/dart-math-pool-math","creator_name":"HKUST NLP Group","creator_url":"https://huggingface.co/hkust-nlp","description":"\\nThis dataset is the data pool synthesized from the query set of the MATH training set,\\ncontaining all answer-correct samples and other metadata produced during the work.\\nDART-Math-* datasets are extracted from dart-math-pool-* data pools.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🎯 DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving\\n\\t\\n\\n📝 Paper@arXiv | 🤗 Datasets&Models@HF | 🐱 Code@GitHub\\n🐦 Thread@X(Twitter) | 🐶 中文博客@知乎 | 📊 Leaderboard@PapersWithCode | 📑 BibTeX\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasets:… See the full description on the dataset page: https://huggingface.co/datasets/hkust-nlp/dart-math-pool-math.","first_N":5,"first_N_keywords":["text-generation","English","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"afrimgsm","keyword":"gsm8k","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/afrimgsm","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrimgsm\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIMGSM is an evaluation dataset comprising translations of a subset of the GSM8k dataset into 16 African languages. \\nIt includes test sets across all 18 languages, maintaining an English and French subsets from the original GSM8k dataset. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 18 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import… See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimgsm.","first_N":5,"first_N_keywords":["text2text-generation","natural-language-inference","multilingual","gsm8k","Amharic"],"keywords_longer_than_N":true},
	{"name":"grad_school_math_instructions_fr_Mixtral","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIffl/grad_school_math_instructions_fr_Mixtral","creator_name":"AIffl : AI For French Language","creator_url":"https://huggingface.co/AIffl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for grad_school_math_instructions_fr_Mixtral\\n\\t\\n\\nThis dataset was made thanks to the instruction of the vigogne's dataset but the output were generated with Mixtral-8x7B-Instruct instead of GPT3.5 to make it open-source.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card Contact\\n\\t\\n\\nrobinjo\\n","first_N":5,"first_N_keywords":["text-generation","French","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"orca-math-portuguese-64k","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rhaymison/orca-math-portuguese-64k","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","description":"translated for:\\n\\n\\nRepository: microsoft/orca-math-word-problems-200k\\nPaper: Orca-Math: Unlocking the potential of\\nSLMs in Grade School Math\\n\\n","first_N":5,"first_N_keywords":["text-generation","question-answering","Portuguese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ReAlign-GSM8K","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GAIR/ReAlign-GSM8K","creator_name":"SII - GAIR","creator_url":"https://huggingface.co/GAIR","description":"Please refer to our GitHub repo for more details.\\n","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"MathCodeInstruct","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MathLLMs/MathCodeInstruct","creator_name":"LLMs for Math Reasoning","creator_url":"https://huggingface.co/MathLLMs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning\\n\\t\\n\\nPaper: https://arxiv.org/pdf/2310.03731.pdf\\nRepo: https://github.com/mathllm/MathCoder\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce MathCoder, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving.\\n\\n\\t\\n\\t\\t\\nBase Model: Llama-2\\nBase Model: Code Llama\\n\\n\\n\\t\\t\\nMathCoder-L-7B\\nMathCoder-CL-7B\\n\\n\\nMathCoder-L-13B\\nMathCoder-CL-34B\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTraining Data… See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathCodeInstruct.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MGSM-eu","keyword":"math-word-problems","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/MGSM-eu","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for MGSM-eu\\n\\t\\n\\n\\nPoint of Contact: hitz@ehu.eus\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMGSM (Shi et al., 2023) is a subset of 250 grade-school math problems from the GSM8K dataset (Cobbe et al., 2021) that has been manually translated into 10 typologically diverse languages.\\nHere, we provide professional translations to yet another language: Basque.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\neu-ES\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Instances\\n\\t\\n\\nMGSM-eu train examples… See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/MGSM-eu.","first_N":5,"first_N_keywords":["text2text-generation","found","expert-generated","monolingual","extended|juletxara/mgsm"],"keywords_longer_than_N":true},
	{"name":"dart-math-pool-gsm8k","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hkust-nlp/dart-math-pool-gsm8k","creator_name":"HKUST NLP Group","creator_url":"https://huggingface.co/hkust-nlp","description":"\\nThis dataset is the data pool synthesized from the query set of the GSM8K training set,\\ncontaining all answer-correct samples and other metadata produced during the work.\\nDART-Math-* datasets are extracted from dart-math-pool-* data pools.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🎯 DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving\\n\\t\\n\\n📝 Paper@arXiv | 🤗 Datasets&Models@HF | 🐱 Code@GitHub\\n🐦 Thread@X(Twitter) | 🐶 中文博客@知乎 | 📊 Leaderboard@PapersWithCode | 📑 BibTeX\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasets:… See the full description on the dataset page: https://huggingface.co/datasets/hkust-nlp/dart-math-pool-gsm8k.","first_N":5,"first_N_keywords":["text-generation","English","mit","1M<n<10M","arxiv:2407.13690"],"keywords_longer_than_N":true},
	{"name":"DiagGSM8K","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pharaouk/DiagGSM8K","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"View the project page:\\nhttps://github.com/dvlab-research/DiagGSM8K\\nsee our paper at https://arxiv.org/abs/2312.17080\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nIn this work, we introduce a novel evaluation paradigm for Large Language Models, \\none that challenges them to engage in meta-reasoning. Our paradigm shifts the focus from result-oriented assessments, \\nwhich often overlook the reasoning process, to a more holistic evaluation that effectively differentiates \\nthe cognitive capabilities among models. For… See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/DiagGSM8K.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"OpenCerebrum-2.0-SFT","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/OpenCerebrum-2.0-SFT","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenCerebrum SFT subset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nOpenCerebrum is my take on creating an open source version of Aether Research's proprietary Cerebrum dataset. This repository contains the SFT subset, which contains about 6,400 examples. To compress this dataset to such a small size, I used an in-house curation technique at Cognitive Computations. More information about this technique will come in the future. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration\\n\\t\\n\\nAs mentioned earlier, I used an in-house… See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/OpenCerebrum-2.0-SFT.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"OpenCerebrum-2.0-DPO","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/OpenCerebrum-2.0-DPO","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenCerebrum DPO subset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nOpenCerebrum is my take on creating an open source version of Aether Research's proprietary Cerebrum dataset. This repository contains the DPO subset, which contains about 720 examples. To compress this dataset to such a small size, I used an in-house curation technique at Cognitive Computations. More information about this technique will come in the future. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration\\n\\t\\n\\nAs mentioned earlier, I used an in-house… See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/OpenCerebrum-2.0-DPO.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MetaMathQA-ShareGPT","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pbatra/MetaMathQA-ShareGPT","creator_name":"Piyush Batra","creator_url":"https://huggingface.co/pbatra","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMetaMathQA-ShareGPT\\n\\t\\n\\nThis repository contains the ShareGPT format version of the MetaMathQA dataset. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe MetaMathQA-ShareGPT dataset is a transformed version of the MetaMathQA dataset, which has been reformatted to fit the ShareGPT conversation format. Each entry in the dataset consists of a series of user-assistant interactions, making it suitable for training and evaluating conversational models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFormat\\n\\t\\n\\nEach entry in the… See the full description on the dataset page: https://huggingface.co/datasets/pbatra/MetaMathQA-ShareGPT.","first_N":5,"first_N_keywords":["mit","100K - 1M","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"dart-math-pool-gsm8k-query-info","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hkust-nlp/dart-math-pool-gsm8k-query-info","creator_name":"HKUST NLP Group","creator_url":"https://huggingface.co/hkust-nlp","description":"\\nThis dataset is the synthesis information of queries from the GSM8K training set,\\nsuch as the numbers of raw/correct samples of each synthesis job.\\nUsually used with dart-math-pool-gsm8k.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🎯 DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving\\n\\t\\n\\n📝 Paper@arXiv | 🤗 Datasets&Models@HF | 🐱 Code@GitHub\\n🐦 Thread@X(Twitter) | 🐶 中文博客@知乎 | 📊 Leaderboard@PapersWithCode | 📑 BibTeX\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasets: DART-Math\\n\\t\\n\\nDART-Math datasets are the state-of-the-art… See the full description on the dataset page: https://huggingface.co/datasets/hkust-nlp/dart-math-pool-gsm8k-query-info.","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"dart-math-pool-gsm8k-query-info","keyword":"statistics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hkust-nlp/dart-math-pool-gsm8k-query-info","creator_name":"HKUST NLP Group","creator_url":"https://huggingface.co/hkust-nlp","description":"\\nThis dataset is the synthesis information of queries from the GSM8K training set,\\nsuch as the numbers of raw/correct samples of each synthesis job.\\nUsually used with dart-math-pool-gsm8k.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🎯 DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving\\n\\t\\n\\n📝 Paper@arXiv | 🤗 Datasets&Models@HF | 🐱 Code@GitHub\\n🐦 Thread@X(Twitter) | 🐶 中文博客@知乎 | 📊 Leaderboard@PapersWithCode | 📑 BibTeX\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasets: DART-Math\\n\\t\\n\\nDART-Math datasets are the state-of-the-art… See the full description on the dataset page: https://huggingface.co/datasets/hkust-nlp/dart-math-pool-gsm8k-query-info.","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"dart-math-pool-math-query-info","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hkust-nlp/dart-math-pool-math-query-info","creator_name":"HKUST NLP Group","creator_url":"https://huggingface.co/hkust-nlp","description":"\\nThis dataset is the synthesis information of queries from the MATH training set,\\nsuch as the numbers of raw/correct samples of each synthesis job.\\nUsually used with dart-math-pool-math.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🎯 DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving\\n\\t\\n\\n📝 Paper@arXiv | 🤗 Datasets&Models@HF | 🐱 Code@GitHub\\n🐦 Thread@X(Twitter) | 🐶 中文博客@知乎 | 📊 Leaderboard@PapersWithCode | 📑 BibTeX\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasets: DART-Math\\n\\t\\n\\nDART-Math datasets are the state-of-the-art… See the full description on the dataset page: https://huggingface.co/datasets/hkust-nlp/dart-math-pool-math-query-info.","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"dart-math-pool-math-query-info","keyword":"statistics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hkust-nlp/dart-math-pool-math-query-info","creator_name":"HKUST NLP Group","creator_url":"https://huggingface.co/hkust-nlp","description":"\\nThis dataset is the synthesis information of queries from the MATH training set,\\nsuch as the numbers of raw/correct samples of each synthesis job.\\nUsually used with dart-math-pool-math.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🎯 DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving\\n\\t\\n\\n📝 Paper@arXiv | 🤗 Datasets&Models@HF | 🐱 Code@GitHub\\n🐦 Thread@X(Twitter) | 🐶 中文博客@知乎 | 📊 Leaderboard@PapersWithCode | 📑 BibTeX\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasets: DART-Math\\n\\t\\n\\nDART-Math datasets are the state-of-the-art… See the full description on the dataset page: https://huggingface.co/datasets/hkust-nlp/dart-math-pool-math-query-info.","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"alpaca_jp_math","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/alpaca_jp_math","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\talpaca_jp_math\\n\\t\\n\\n\\nalpaca_jp_mathは、  \\n\\nStanford Alpacaの手法  \\nmistralai/Mixtral-8x22B-Instruct-v0.1\\n\\nで作った合成データ(Synthetic data)です。モデルの利用にはDeepinfraを利用しています。  \\nまた、\\\"_cleaned\\\"がついたデータセットは以下の手法で精査されています。  \\n\\npythonの計算結果がきちんと、テキストの計算結果が同等であるか確認\\nLLM(mistralai/Mixtral-8x22B-Instruct-v0.1)による確認（詳細は下記）\\n\\ncode_result, text_resultは小数第三位で四捨五入してあります。\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\nCurated by: HachiML\\nLanguage(s) (NLP): Japanese\\nLicense: Apache 2.0\\nGithub:… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/alpaca_jp_math.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"dart-math-uniform","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hkust-nlp/dart-math-uniform","creator_name":"HKUST NLP Group","creator_url":"https://huggingface.co/hkust-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🎯 DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving\\n\\t\\n\\n📝 Paper@arXiv | 🤗 Datasets&Models@HF | 🐱 Code@GitHub\\n🐦 Thread@X(Twitter) | 🐶 中文博客@知乎 | 📊 Leaderboard@PapersWithCode | 📑 BibTeX\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasets: DART-Math\\n\\t\\n\\nDART-Math datasets are the state-of-the-art and data-efficient open-source instruction tuning datasets for mathematical reasoning.\\n\\n\\n    \\n    \\n\\n\\n  Figure 1: Left: Average accuracy on 6 mathematical benchmarks. We compare with models… See the full description on the dataset page: https://huggingface.co/datasets/hkust-nlp/dart-math-uniform.","first_N":5,"first_N_keywords":["text-generation","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"math-instruct-dataset","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/patrickjmcbride/math-instruct-dataset","creator_name":"Patrick McBride","creator_url":"https://huggingface.co/patrickjmcbride","description":"This is a reformatted version of Feynman Innovations' Maths-College dataset. \\nFull credit to Feynman Innovations for the dataset.\\nIt is just formatted to be ready for fine-tuning an instruct model \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields are as follows:\\ninstruction: describes the task that the model needs to perform. (all instructions are the same \\\"Write an educational piece related to the following text snippet:\\\")\\ncontext:     additional context containing the math concept to explain… See the full description on the dataset page: https://huggingface.co/datasets/patrickjmcbride/math-instruct-dataset.","first_N":5,"first_N_keywords":["text-generation","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"math-instruct-dataset","keyword":"mathematics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/patrickjmcbride/math-instruct-dataset","creator_name":"Patrick McBride","creator_url":"https://huggingface.co/patrickjmcbride","description":"This is a reformatted version of Feynman Innovations' Maths-College dataset. \\nFull credit to Feynman Innovations for the dataset.\\nIt is just formatted to be ready for fine-tuning an instruct model \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields are as follows:\\ninstruction: describes the task that the model needs to perform. (all instructions are the same \\\"Write an educational piece related to the following text snippet:\\\")\\ncontext:     additional context containing the math concept to explain… See the full description on the dataset page: https://huggingface.co/datasets/patrickjmcbride/math-instruct-dataset.","first_N":5,"first_N_keywords":["text-generation","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"math-instruct-dataset","keyword":"statistics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/patrickjmcbride/math-instruct-dataset","creator_name":"Patrick McBride","creator_url":"https://huggingface.co/patrickjmcbride","description":"This is a reformatted version of Feynman Innovations' Maths-College dataset. \\nFull credit to Feynman Innovations for the dataset.\\nIt is just formatted to be ready for fine-tuning an instruct model \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields are as follows:\\ninstruction: describes the task that the model needs to perform. (all instructions are the same \\\"Write an educational piece related to the following text snippet:\\\")\\ncontext:     additional context containing the math concept to explain… See the full description on the dataset page: https://huggingface.co/datasets/patrickjmcbride/math-instruct-dataset.","first_N":5,"first_N_keywords":["text-generation","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"math-instruct-dataset","keyword":"algebra","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/patrickjmcbride/math-instruct-dataset","creator_name":"Patrick McBride","creator_url":"https://huggingface.co/patrickjmcbride","description":"This is a reformatted version of Feynman Innovations' Maths-College dataset. \\nFull credit to Feynman Innovations for the dataset.\\nIt is just formatted to be ready for fine-tuning an instruct model \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields are as follows:\\ninstruction: describes the task that the model needs to perform. (all instructions are the same \\\"Write an educational piece related to the following text snippet:\\\")\\ncontext:     additional context containing the math concept to explain… See the full description on the dataset page: https://huggingface.co/datasets/patrickjmcbride/math-instruct-dataset.","first_N":5,"first_N_keywords":["text-generation","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"math-instruct-binned","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/patrickjmcbride/math-instruct-binned","creator_name":"Patrick McBride","creator_url":"https://huggingface.co/patrickjmcbride","description":"This is a pre-binned instruction formatted version of Feynman Innovations' Maths-College dataset. \\nCredit to Feynman Innovations for the base dataset.\\nIt is formatted to be ready for fine-tuning an instruct model. \\nThe splits are based on the size of the full instruction ('text') after being tokenized with the Llama-3-8B-Instruct tokenizer (based on tiktoken).\\nA non-split version is avalible as math-instruct-dataset\\nBinned by length of tokenized 'text' field\\n\\nsmall:  [min-1024)\\nmedium:… See the full description on the dataset page: https://huggingface.co/datasets/patrickjmcbride/math-instruct-binned.","first_N":5,"first_N_keywords":["text-generation","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"math-instruct-binned","keyword":"mathematics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/patrickjmcbride/math-instruct-binned","creator_name":"Patrick McBride","creator_url":"https://huggingface.co/patrickjmcbride","description":"This is a pre-binned instruction formatted version of Feynman Innovations' Maths-College dataset. \\nCredit to Feynman Innovations for the base dataset.\\nIt is formatted to be ready for fine-tuning an instruct model. \\nThe splits are based on the size of the full instruction ('text') after being tokenized with the Llama-3-8B-Instruct tokenizer (based on tiktoken).\\nA non-split version is avalible as math-instruct-dataset\\nBinned by length of tokenized 'text' field\\n\\nsmall:  [min-1024)\\nmedium:… See the full description on the dataset page: https://huggingface.co/datasets/patrickjmcbride/math-instruct-binned.","first_N":5,"first_N_keywords":["text-generation","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"math-instruct-binned","keyword":"statistics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/patrickjmcbride/math-instruct-binned","creator_name":"Patrick McBride","creator_url":"https://huggingface.co/patrickjmcbride","description":"This is a pre-binned instruction formatted version of Feynman Innovations' Maths-College dataset. \\nCredit to Feynman Innovations for the base dataset.\\nIt is formatted to be ready for fine-tuning an instruct model. \\nThe splits are based on the size of the full instruction ('text') after being tokenized with the Llama-3-8B-Instruct tokenizer (based on tiktoken).\\nA non-split version is avalible as math-instruct-dataset\\nBinned by length of tokenized 'text' field\\n\\nsmall:  [min-1024)\\nmedium:… See the full description on the dataset page: https://huggingface.co/datasets/patrickjmcbride/math-instruct-binned.","first_N":5,"first_N_keywords":["text-generation","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"math-instruct-binned","keyword":"algebra","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/patrickjmcbride/math-instruct-binned","creator_name":"Patrick McBride","creator_url":"https://huggingface.co/patrickjmcbride","description":"This is a pre-binned instruction formatted version of Feynman Innovations' Maths-College dataset. \\nCredit to Feynman Innovations for the base dataset.\\nIt is formatted to be ready for fine-tuning an instruct model. \\nThe splits are based on the size of the full instruction ('text') after being tokenized with the Llama-3-8B-Instruct tokenizer (based on tiktoken).\\nA non-split version is avalible as math-instruct-dataset\\nBinned by length of tokenized 'text' field\\n\\nsmall:  [min-1024)\\nmedium:… See the full description on the dataset page: https://huggingface.co/datasets/patrickjmcbride/math-instruct-binned.","first_N":5,"first_N_keywords":["text-generation","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"stem_mcqa_questions","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mvujas/stem_mcqa_questions","creator_name":"Milos Vujasinovic","creator_url":"https://huggingface.co/mvujas","description":"This is a dataset of questions in various stem field generated using GPT-4o. The fields contain math, physics, chemistry, biology, computer_science and technical_sciences with around 400 samples in each.\\n","first_N":5,"first_N_keywords":["question-answering","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mgsm_gl","keyword":"math-word-problems","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/proxectonos/mgsm_gl","creator_name":"Proxecto Nós","creator_url":"https://huggingface.co/proxectonos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for mgsm_gl\\n\\t\\n\\nmgsm_gl is a question answering dataset in Galician translated from the MGSM dataset in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is the Galician version of the MGSM (Multilingual Grade School Math) dataset. It serves as a benchmark of grade-school math problems as proposed in the paper Language models are multilingual chain-of-thought reasoners. It includes 8 instances in the train split and another 250… See the full description on the dataset page: https://huggingface.co/datasets/proxectonos/mgsm_gl.","first_N":5,"first_N_keywords":["question-answering","text-generation","Galician","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"mathcamps","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mathcamps/mathcamps","creator_name":"MathCAMPS","creator_url":"https://huggingface.co/mathcamps","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMathCAMPS - A dataset of mathematical problems synthesized from an educational curriculum\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nMathCAMPS is a dataset of synthetic math word problems derived from the Mathematics Common Core, a widely used curriculum in schools in the US. The Common Core contains a collection of standards for each grade (K-8, plus high school), each describing a specific mathematical ability that students should learn at that grade. Every problem in MathCAMPS is tied to a… See the full description on the dataset page: https://huggingface.co/datasets/mathcamps/mathcamps.","first_N":5,"first_N_keywords":["text2text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"MM_Math","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/THU-KEG/MM_Math","creator_name":"Knowledge Engineer Group @ Tsinghua University","creator_url":"https://huggingface.co/THU-KEG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMM_Math Datasets\\n\\t\\n\\nWe introduce our multimodal mathematics dataset, MM-MATH,. \\nThis dataset is collected from real middle school exams in China, and all the math problems are open-ended to evaluate the mathematical problem-solving abilities of current multimodal models. MM-MATH is annotated with fine-grained three-dimensional labels: difficulty, grade, and knowledge points. The difficulty level is determined based on the average scores of student exams, the grade labels are… See the full description on the dataset page: https://huggingface.co/datasets/THU-KEG/MM_Math.","first_N":5,"first_N_keywords":["text-to-image","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Maths-College-ko","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/Maths-College-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"Translated 5% ajibawa-2023/Maths-College using nayohan/llama3-instrucTrans-enko-8b.\\n","first_N":5,"first_N_keywords":["question-answering","Korean","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \\nBibTex\\n@misc{lu2024languagecountslearnunlearn,\\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \\n      author={Taiming Lu and Philipp Koehn},\\n      year={2024},\\n      eprint={2406.13748},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2406.13748}, \\n}\\n\\n","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"gsm8k_multiturn","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/euclaise/gsm8k_multiturn","creator_name":"Jade","creator_url":"https://huggingface.co/euclaise","description":"The \\\"socratic\\\" version of GSM8K has the model reflect and ask itself sub-questions about the initial question, before coming to a final answer.\\nThis dataset reformats the socratic GSM8K version into a multi-turn conversation, where the sub-questions are asked by the user rather than being self-asked by the model.\\n","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"afrimgsm","keyword":"gsm8k","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuntian-deng/afrimgsm","creator_name":"Yuntian Deng","creator_url":"https://huggingface.co/yuntian-deng","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrimgsm\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIMGSM is an evaluation dataset comprising translations of a subset of the GSM8k dataset into 16 African languages. \\nIt includes test sets across all 18 languages, maintaining an English and French subsets from the original GSM8k dataset. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 18 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import… See the full description on the dataset page: https://huggingface.co/datasets/yuntian-deng/afrimgsm.","first_N":5,"first_N_keywords":["text2text-generation","natural-language-inference","multilingual","gsm8k","Amharic"],"keywords_longer_than_N":true},
	{"name":"TigerMath-Evaluated","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/thesven/TigerMath-Evaluated","creator_name":"Michael Svendsen","creator_url":"https://huggingface.co/thesven","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTigerMath Evaluated\\n\\t\\n\\nTigerMath-Evaluated is a dataset comprising 101,000 rows of grade 4-5 ranked responses sourced from the TIGER-Lab/MathInstruct dataset.\\nThe responses were graded using Prometheus V2 with a GPTQ 4-bit quantized version of the V2 7B model.\\nThis dataset aims to support research and development in educational AI and automated grading systems.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nsource: The original source where the data was gathered by Tiger Lab\\nresponse: The original… See the full description on the dataset page: https://huggingface.co/datasets/thesven/TigerMath-Evaluated.","first_N":5,"first_N_keywords":["text-generation","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"vrt-baseline","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hkust-nlp/vrt-baseline","creator_name":"HKUST NLP Group","creator_url":"https://huggingface.co/hkust-nlp","description":"\\nThis dataset is the VRT baseline dataset used to train baseline models *-VRT in Table 2 of the paper.\\n\\nAnother ablation baseline to DART is vanilla rejection tuning (VRT), where we synthesize a dataset of the same size of 0.59M examples with DeepSeekMath-7B-RL, using vanilla rejection sampling as described in §2.1.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🎯 DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving\\n\\t\\n\\n📝 Paper@arXiv | 🤗 Datasets&Models@HF | 🐱 Code@GitHub\\n🐦 Thread@X(Twitter) | 🐶… See the full description on the dataset page: https://huggingface.co/datasets/hkust-nlp/vrt-baseline.","first_N":5,"first_N_keywords":["text-generation","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"PLoRA_datasets","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xiaochen233/PLoRA_datasets","creator_name":"wxc","creator_url":"https://huggingface.co/xiaochen233","description":"View the project page:\\nhttps://meta-math.github.io/\\nsee our paper at https://arxiv.org/abs/2309.12284\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\nAll MetaMathQA data are augmented from the training sets of GSM8K and MATH. \\nNone of the augmented data is from the testing set.\\nYou can check the original_question in meta-math/MetaMathQA, each item is from the GSM8K or MATH train set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Details\\n\\t\\n\\nMetaMath-Mistral-7B is fully fine-tuned on the MetaMathQA datasets and based on the powerful Mistral-7B model.… See the full description on the dataset page: https://huggingface.co/datasets/xiaochen233/PLoRA_datasets.","first_N":5,"first_N_keywords":["mit","100K - 1M","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"Kapibara","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alban-labs/Kapibara","creator_name":"Albanian Labs","creator_url":"https://huggingface.co/alban-labs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKapibara: Albanian Multi-turn Conversation Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKapibara is a comprehensive Albanian language dataset designed for multi-turn conversations. It contains over 5,300 entries covering a wide range of topics including physics, biology, mathematics, chemistry, culture, and logic. The dataset is aimed at improving text generation and question-answering capabilities in the Albanian language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\nThe dataset supports the… See the full description on the dataset page: https://huggingface.co/datasets/alban-labs/Kapibara.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Albanian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"math-expressions-1m","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Gusarich/math-expressions-1m","creator_name":"Daniil Sedov","creator_url":"https://huggingface.co/Gusarich","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMath Expressions 1M\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is a comprehensive collection of 1,000,000 mathematical expressions, including both valid and invalid expressions. This dataset is intended for use in various machine learning and natural language processing tasks, such as calculations, mathematical reasoning, and validation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset consists of mathematical expressions generated using a combination of basic arithmetic operations and… See the full description on the dataset page: https://huggingface.co/datasets/Gusarich/math-expressions-1m.","first_N":5,"first_N_keywords":["text-generation","mit","1M - 10M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Polytope","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Polytope","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Polytope is a dataset containing math-instruct data.\\nThe 2024-08-15 version contains:\\n\\n42.3k rows of synthetic math-instruct data, using randomly selected, permissively licensed CoT prompts from TIGER-Lab/MathInstruct and responses generated using Llama 3.1 405b Instruct.\\n\\nThis dataset contains synthetically generated data and has not been subject to manual review.\\n","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"NuminaMath-CoT-Small-215k","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NotASI/NuminaMath-CoT-Small-215k","creator_name":"Liu Hong Yuan Tom","creator_url":"https://huggingface.co/NotASI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis dataset is a scaled down version of the original AI-MO/NuminaMath-CoT dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource breakdown\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nSource\\nNumber of Originial Samples\\nNumber of Samples in This Dataset\\n\\n\\n\\t\\t\\naops_forum\\n30201\\n7548\\n\\n\\namc_aime\\n4072\\n1017\\n\\n\\ncn_k12\\n276591\\n69138\\n\\n\\ngsm8k\\n7345\\n1835\\n\\n\\nmath\\n7478\\n1869\\n\\n\\nolympiads\\n150581\\n37640\\n\\n\\norca_math\\n153334\\n38328\\n\\n\\nsynthetic_amc\\n62111\\n15527\\n\\n\\nsynthetic_math\\n167895\\n41968\\n\\n\\nTotal\\n859608\\n214870\\n\\n\\n\\t\\n\\n","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"NuminaMath-CoT-Small-Hard-200k","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NotASI/NuminaMath-CoT-Small-Hard-200k","creator_name":"Liu Hong Yuan Tom","creator_url":"https://huggingface.co/NotASI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis dataset is a scaled down version of the original AI-MO/NuminaMath-CoT dataset with more focus on hard math.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource breakdown\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nSource\\nNumber of Originial Samples\\nNumber of Samples in This Dataset\\n\\n\\n\\t\\t\\naops_forum\\n30201\\n5000\\n\\n\\namc_aime\\n4072\\n4070\\n\\n\\ncn_k12\\n276591\\n55310\\n\\n\\ngsm8k\\n7345\\n1000\\n\\n\\nmath\\n7478\\n1000\\n\\n\\nolympiads\\n150581\\n37640\\n\\n\\norca_math\\n153334\\n30662\\n\\n\\nsynthetic_amc\\n62111\\n31054\\n\\n\\nsynthetic_math\\n167895\\n33574\\n\\n\\nTotal\\n859608\\n199310\\n\\n\\n\\t\\n\\n","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"CleverBoi","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/CleverBoi","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCleverBoi\\n\\t\\n\\nThe CleverBoi Collection is based on a number of data sets that emphasize logic, inference, empathy, math and coding.\\nThe data set has been formatted to follow the alpaca format (instruction + input -> output) when fine tuning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Sets\\n\\t\\n\\nThe source data sets used in the CleverBoi Collection are listed below, ordered by size.\\n\\nKK04/LogicInference_OA\\nmlabonne/Evol-Instruct-Python-26k\\ngarage-bAInd/Open-Platypus… See the full description on the dataset page: https://huggingface.co/datasets/theprint/CleverBoi.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ko-math","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kikikara/ko-math","creator_name":"kimjeasung","creator_url":"https://huggingface.co/kikikara","description":"hendrycks/math dataset을 한국어로 번역한 dataset 입니다.\\n","first_N":5,"first_N_keywords":["question-answering","Korean","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Arabic_LLaMA_Math_Dataset","keyword":"math","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jr23xd23/Arabic_LLaMA_Math_Dataset","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic LLaMA Math Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample Entries\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\nDataset Name: Arabic_LLaMA_Math_Dataset.csv\\nNumber of Records: 12,496\\nNumber of Columns: 3\\nFile Format: CSV\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns:\\n\\t\\n\\n\\nInstruction: The problem statement or question (text, in Arabic)\\nInput: Additional input for model fine-tuning (empty in this dataset)\\nSolution: The solution or answer to the problem (text, in Arabic)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/Arabic_LLaMA_Math_Dataset.","first_N":5,"first_N_keywords":["question-answering","Arabic","cc0-1.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"bd-bcs-multimodal","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/azminetoushikwasi/bd-bcs-multimodal","creator_name":"Azmine Toushik Wasi","creator_url":"https://huggingface.co/azminetoushikwasi","description":"azminetoushikwasi/bd-bcs-multimodal dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Bengali","apache-2.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"fairseq2-lm-gsm8k","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/fairseq2-lm-gsm8k","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"facebook/fairseq2-lm-gsm8k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","monolingual","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"DIA-Bench","keyword":"mathematics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dia-bench/DIA-Bench","creator_name":"Dynamic Intelligence Assessment Benchmark","creator_url":"https://huggingface.co/dia-bench","description":"\\n\\t\\n\\t\\t\\n\\t\\tDynamic Intelligence Assessment Dataset\\n\\t\\n\\n\\n    \\n\\n\\n\\nThis dataset aims to test the problem-solving ability of LLMs with dynamically generated challenges that are difficult to guess.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe DIA Benchmark Dataset is a benchmarking tool consisting of 150 dynamic question generators for the evaluation of the problem-solving capability of LLMs. It primarily focuses on CTF-style (Capture the Flag) challenges that require knowledge from the fields of mathematics… See the full description on the dataset page: https://huggingface.co/datasets/dia-bench/DIA-Bench.","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Numina","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/artnoage/Numina","creator_name":"Vaios Laschos","creator_url":"https://huggingface.co/artnoage","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 41012\\nFiltered size: 38772\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word… See the full description on the dataset page: https://huggingface.co/datasets/artnoage/Numina.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Numina","keyword":"mathematical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/artnoage/Numina","creator_name":"Vaios Laschos","creator_url":"https://huggingface.co/artnoage","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 41012\\nFiltered size: 38772\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word… See the full description on the dataset page: https://huggingface.co/datasets/artnoage/Numina.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Numina","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/artnoage/Numina","creator_name":"Vaios Laschos","creator_url":"https://huggingface.co/artnoage","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 41012\\nFiltered size: 38772\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word… See the full description on the dataset page: https://huggingface.co/datasets/artnoage/Numina.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"EpicPRM","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SunW7777/EpicPRM","creator_name":"Sun","creator_url":"https://huggingface.co/SunW7777","description":"\\n\\t\\n\\t\\t\\n\\t\\tAn Efficient and Precise Training Data Construction Framework for Process-supervised Reward Model in Mathematical Reasoning\\n\\t\\n\\nWe propose a framework EpicPRM which improvements to existing automatic annotating methods. \\nOur framework refines the method for evaluating the correctness of intermediate reasoning steps, effectively reducing the prevalence of false positive and false negative labels. \\nAdditionally, we optimize the algorithm for identifying the first erroneous step by… See the full description on the dataset page: https://huggingface.co/datasets/SunW7777/EpicPRM.","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"Coq-HoTT","keyword":"theorem-proving","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-HoTT","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCoq-HoTT Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Coq-HoTT Dataset is derived from the Coq-HoTT repository, focusing on the formalization of Homotopy Type Theory in the Coq proof assistant. This dataset processes .v files from the theories directory to extract mathematical content in a structured format.\\nThis work builds upon the format established by Andreas Florath (@florath) in his Coq Facts, Propositions and Proofs dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset… See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-HoTT.","first_N":5,"first_N_keywords":["text-generation","feature-extraction","other","English","bsd-2-clause"],"keywords_longer_than_N":true},
	{"name":"Coq-HoTT","keyword":"coq","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-HoTT","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCoq-HoTT Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Coq-HoTT Dataset is derived from the Coq-HoTT repository, focusing on the formalization of Homotopy Type Theory in the Coq proof assistant. This dataset processes .v files from the theories directory to extract mathematical content in a structured format.\\nThis work builds upon the format established by Andreas Florath (@florath) in his Coq Facts, Propositions and Proofs dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset… See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-HoTT.","first_N":5,"first_N_keywords":["text-generation","feature-extraction","other","English","bsd-2-clause"],"keywords_longer_than_N":true},
	{"name":"simple-math-steps-7M","keyword":"maths","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shb777/simple-math-steps-7M","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"Simple math expression solving with 3-6 operands and +-*/%^ operators, small powers and numbers between 1,1000 as operands\\nPlease cite this dataset using the provided BibTeX if you find it useful.\\n@misc {sb_2025,\\n    author       = { {SB} },\\n    title        = { simple-math-steps-7M (Revision 42a591f) },\\n    year         = 2025,\\n    url          = { https://huggingface.co/datasets/shb777/simple-math-steps-7M },\\n    doi          = { 10.57967/hf/3985 },\\n    publisher    = { Hugging Face }\\n}\\n\\n","first_N":5,"first_N_keywords":["question-answering","English","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"Coq-HoTT-QA","keyword":"theorem-proving","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-HoTT-QA","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCoq-HoTT Q&A Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Coq-HoTT Q&A Dataset is a conversational extension of the Coq-HoTT Dataset, derived directly from the Coq-HoTT GitHub repository (https://github.com/HoTT/Coq-HoTT). This dataset transforms Homotopy Type Theory (HoTT) content into structured Q&A pairs, bridging the gap between formal mathematics and conversational AI.\\nEach entry in the dataset represents a mathematical statement, such as a definition or theorem… See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-HoTT-QA.","first_N":5,"first_N_keywords":["question-answering","text-generation","other","English","bsd-2-clause"],"keywords_longer_than_N":true},
	{"name":"Coq-HoTT-QA","keyword":"coq","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-HoTT-QA","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCoq-HoTT Q&A Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Coq-HoTT Q&A Dataset is a conversational extension of the Coq-HoTT Dataset, derived directly from the Coq-HoTT GitHub repository (https://github.com/HoTT/Coq-HoTT). This dataset transforms Homotopy Type Theory (HoTT) content into structured Q&A pairs, bridging the gap between formal mathematics and conversational AI.\\nEach entry in the dataset represents a mathematical statement, such as a definition or theorem… See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-HoTT-QA.","first_N":5,"first_N_keywords":["question-answering","text-generation","other","English","bsd-2-clause"],"keywords_longer_than_N":true},
	{"name":"BigGSM","keyword":"mathematics","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LightChen2333/BigGSM","creator_name":"Qiguang Chen","creator_url":"https://huggingface.co/LightChen2333","description":"\\n  Unlocking the Boundaries of Thought: A Reasoning Granularity Framework to Quantify and Optimize Chain-of-Thought\\n\\n\\n\\n      \\n    | [ArXiv] | [🤗HuggingFace] |\\n    \\n    \\n\\n\\n🌟 Any contributions via PRs, issues, emails or other methods are greatly appreciated.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🔥News\\n\\t\\n\\n\\n🎖️ Our work is accepted by NeurIPS 2024 (Oral).\\n🔥 We have release benchmark on [🤗HuggingFace].\\n🔥 The paper is also available on [ArXiv].\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t💡 Motivation\\n\\t\\n\\nChain-of-Thought (CoT) reasoning has emerged… See the full description on the dataset page: https://huggingface.co/datasets/LightChen2333/BigGSM.","first_N":5,"first_N_keywords":["text2text-generation","question-answering","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Math_small_corpus","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lap1official/Math_small_corpus","creator_name":"Lap","creator_url":"https://huggingface.co/Lap1official","description":"Lap1official/Math_small_corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"Numina_medium","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Numina_medium","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 37133\\nFiltered size: 37133\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word problem\\nA… See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Numina_medium.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Numina_medium","keyword":"mathematical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Numina_medium","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 37133\\nFiltered size: 37133\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word problem\\nA… See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Numina_medium.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Numina_medium","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Numina_medium","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 37133\\nFiltered size: 37133\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word problem\\nA… See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Numina_medium.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Olympiads_medium","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Olympiads_medium","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 13284\\nFiltered size: 13240\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word problem\\nA… See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads_medium.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Olympiads_medium","keyword":"mathematical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Olympiads_medium","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 13284\\nFiltered size: 13240\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word problem\\nA… See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads_medium.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Olympiads_medium","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Olympiads_medium","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 13284\\nFiltered size: 13240\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word problem\\nA… See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads_medium.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Olympiads_hard","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Olympiads_hard","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 21525\\nFiltered size: 21408\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word problem\\nA… See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads_hard.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Olympiads_hard","keyword":"mathematical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Olympiads_hard","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 21525\\nFiltered size: 21408\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word problem\\nA… See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads_hard.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Olympiads_hard","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Olympiads_hard","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 21525\\nFiltered size: 21408\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word problem\\nA… See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads_hard.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"NuminaMath-CoT-decontaminated-filtered","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/flatlander1024/NuminaMath-CoT-decontaminated-filtered","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Decontaminated version of AI-MO/NuminaMath-CoT/train that remove the collided data from math/test, gsm8k/test, olympiadbench/test, minerva_math/test, college_math/test, mmlu_stem/test, gaokao, amc23, aime24 and math500.\\nAligned with flatlander1024/QwQ-LongCoT-130K-decontaminated NuminaMath\\nTotal number of rows: 102238\\n","first_N":5,"first_N_keywords":["question-answering","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"QwQ-LongCoT-decontaminated-filtered","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/flatlander1024/QwQ-LongCoT-decontaminated-filtered","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Decontaminated version of gghfez/QwQ-LongCoT-130K-cleaned that remove the collided data from math/test, gsm8k/test, olympiadbench/test, minerva_math/test, college_math/test, mmlu_stem/test, gaokao, amc23, aime24 and math500.\\nWith source=='NuminaMath'.\\nTotal number of rows: 88083\\n","first_N":5,"first_N_keywords":["question-answering","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"NuminaMath-longcot-cot-combined","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/flatlander1024/NuminaMath-longcot-cot-combined","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Contains Decontaminated version of AI-MO/NuminaMath-CoT/train and the decontaminated version of gghfez/QwQ-LongCoT-130K-cleaned.\\nRemove duplicates and merged them into 1 data with 2 different solution rows.\\nTotal number of rows: 87057\\n","first_N":5,"first_N_keywords":["question-answering","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"flemish_multimodal_exams_physician","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jjzha/flemish_multimodal_exams_physician","creator_name":"Mike Zhang","creator_url":"https://huggingface.co/jjzha","description":"jjzha/flemish_multimodal_exams_physician dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Dutch","cc-by-4.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"subset_math_generated_solutions","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cupalex/subset_math_generated_solutions","creator_name":"Aleksandra","creator_url":"https://huggingface.co/cupalex","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for a Subset of MATH-500 Generated Solutions\\n\\t\\n\\nThis dataset contains model-generated answers and chain-of-thought solutions to a subset of 20 problems from the MATH-500 dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEach item in this dataset includes a problem from the MATH-500 dataset, along with pairs of chain-of-thought solutions and short answers generated using two different strategies:\\n\\nGreedy Chain-of-Thought Decoding\\n\\nWeighted Best-of-N… See the full description on the dataset page: https://huggingface.co/datasets/cupalex/subset_math_generated_solutions.","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"math-500-qwen-2.5-rpm-post-training","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hannayukhymenko/math-500-qwen-2.5-rpm-post-training","creator_name":"Hanna Yukhymenko","creator_url":"https://huggingface.co/hannayukhymenko","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card\\n\\t\\n\\nDataset consists of 20 randomly sampled problems for level 1-3 in MATH-500 dataset dataset and solutions, scored by a reward model.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\nThe dataset is based on MATH-500 dataset. The methods used reproduce the approach from Hugging Face blogpost \\\"Scaling Test Time Compute with Open Models\\\"\\n\\n\\t\\n\\t\\t\\n\\t\\tMethods\\n\\t\\n\\nWe used two methods to generate solutions and answers:\\n\\nGreedy decoding: sampling 1 solution using temperature=0… See the full description on the dataset page: https://huggingface.co/datasets/hannayukhymenko/math-500-qwen-2.5-rpm-post-training.","first_N":5,"first_N_keywords":["text-generation","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"math-problems-greedy-vs-best-of-n","keyword":"mathematical-reasoning","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tandogan/math-problems-greedy-vs-best-of-n","creator_name":"Zeynep","creator_url":"https://huggingface.co/Tandogan","description":"\\n\\t\\n\\t\\t\\n\\t\\tProblem Solving Math Dataset - Greedy vs Best-of-N\\n\\t\\n\\nThis dataset contains mathematical problems and their solutions generated using two decoding strategies:\\n\\nGreedy Decoding: Generates a single deterministic solution.\\nBest-of-N Decoding: Generates N solutions and selects the best one based on a scoring metric.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThis dataset is created with a filtered subset of 20 level 1-3 problems from the MATH-500 dataset.\\nTo have a balance across the levels, the… See the full description on the dataset page: https://huggingface.co/datasets/Tandogan/math-problems-greedy-vs-best-of-n.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"AWPCD","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HelloCephalopod/AWPCD","creator_name":"Matthew Waller","creator_url":"https://huggingface.co/HelloCephalopod","description":"\\n\\t\\n\\t\\t\\n\\t\\tArithmetic Word Problem Compendium Dataset (AWPCD)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a comprehensive collection of mathematical word problems spanning multiple domains with rich metadata and natural language variations. The problems contain 1 - 5 steps of mathematical operations that are specifically designed to encourage showing work and maintaining appropriate decimal precision throughout calculations. \\nThe available data is a sample of 1,000 problems, and commerical… See the full description on the dataset page: https://huggingface.co/datasets/HelloCephalopod/AWPCD.","first_N":5,"first_N_keywords":["English","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"r103","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zjrwtxtechstudio/r103","creator_name":"zjrwtx","creator_url":"https://huggingface.co/zjrwtxtechstudio","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"camel","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Wendong-Fan/camel","creator_name":"Wendong.Fan","creator_url":"https://huggingface.co/Wendong-Fan","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"camel_dataset_example_2","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Wendong-Fan/camel_dataset_example_2","creator_name":"Wendong.Fan","creator_url":"https://huggingface.co/Wendong-Fan","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"NuminaMath-1.5-Verifiable","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yentinglin/NuminaMath-1.5-Verifiable","creator_name":"Yen-Ting Lin","creator_url":"https://huggingface.co/yentinglin","description":"\\n\\t\\n\\t\\t\\n\\t\\tNuminaMath-1.5-Verifiable\\n\\t\\n\\nA filtered subset of NuminaMath-1.5, retaining only non-synthetic examples with valid answers.\\nFiltering Criteria\\n    •\\tExcludes synthetic examples.\\n    •\\tKeeps only entries with non-empty, meaningful answers.\\n    •\\tRemoves generic placeholders like “proof” and “notfound.”\\n\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"yentinglin/NuminaMath-1.5-Verifiable\\\")\\n\\n","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"gsm8k-thai","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VISAI-AI/gsm8k-thai","creator_name":"VISAI AI","creator_url":"https://huggingface.co/VISAI-AI","description":"\\n\\t\\n\\t\\t\\n\\t\\tgsm8k-thai\\n\\t\\n\\nThis dataset is a Thai translation of the GSM8k benchmark (https://huggingface.co/datasets/openai/gsm8k), a dataset of grade school math word problems. The translation was performed using Claude 3.5 Sonnet.  It is intended for evaluating the performance of language models on mathematical reasoning in the Thai language. The split of training and test data follows the original GSM8k dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAnnotations\\n\\t\\n\\n\\nsource: claude-3.5-sonnet\\nlanguage: en -> th… See the full description on the dataset page: https://huggingface.co/datasets/VISAI-AI/gsm8k-thai.","first_N":5,"first_N_keywords":["text2text-generation","Thai","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"NuminaMath-CoT-cn_k12-20000-old","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tttonyyy/NuminaMath-CoT-cn_k12-20000-old","creator_name":"shaozhen liu","creator_url":"https://huggingface.co/tttonyyy","description":"本数据集为NuminaMath-CoT在cn_k12类别下前20000条数据中进行的长CoT文本生成尝试。\\n里面有两个数据文件，completion.jsonl和distilled.jsonl。\\n其中，completion.jsonl是gemma2-27b-it生成的数据，因为gemma2-27b-it最后得到的结果可能提取不出\\\\boxed{}里面的内容等因素，所以最后生成了约18.6k的数据。\\n而distilled.jsonl是基于上面的回答成功的问题，使用DeepSeek-R1-Distill-Qwen-32B生成的数据（其实不应该这样，之后有机会再从20000条里面直接生成）。\\n因为NuminaMath-CoT的cn_k12数据大多是一些综合应用题，一条数据中会有多个子问题，回答的时候也要分别回答。对问题回答的答案进行验证较难，尚未进行答案验证，需要下载下来之后再进行更精细化的处理。\\ncompletion.jsonl中的数据标签描述：\\n\\nsource (String)：数据来源类别，为原始标签\\nproblem (String)：数学问题文本，为原始标签\\nsolution… See the full description on the dataset page: https://huggingface.co/datasets/tttonyyy/NuminaMath-CoT-cn_k12-20000-old.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","10K<n<100K","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"NMC-cn_k12-20k-r1_32b_distilled","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tttonyyy/NMC-cn_k12-20k-r1_32b_distilled","creator_name":"shaozhen liu","creator_url":"https://huggingface.co/tttonyyy","description":"本数据集数据来源为NuminaMath-CoT数据集的cn_k12数据。我们从这里面提取了20000条问题，并使用DeepSeek-R1-Distill-Qwen-32B模型进行了回答。\\ndistilled_s0_e20000.jsonl包含这个数据集的数据，下面介绍数据标签：\\n\\nidx：索引号（0~19999）\\nquestion：原数据集中的problem标签，是一个可能包含多个子问题的数学问题字符串\\ngt_cot：愿数据集中的solution标签，是经过GPT-4o整理的答案字符串\\npred_cot：根据question标签，模型DeepSeek-R1-Distill-Qwen-32B的回答字符串\\npred_cot_token_len：pred_cot标签下的字符串转化成token之后的长度（不包含最前面的<think>\\\\n部分，这个在生成的时候是在prompt里面，我后来加到这里了）\\nmessage：根据question标签和pred_cot标签，构造的问题-回答数据对\\n\\n统计了一下平均回答token长度，为3169.4251\\n","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"OpenR1-Math-220k-paired","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIR-hl/OpenR1-Math-220k-paired","creator_name":"Hsu Shihyueh","creator_url":"https://huggingface.co/AIR-hl","description":"\\n\\t\\n\\t\\t\\n\\t\\t!!! Is there anyone can help me? https://github.com/huggingface/trl/issues/2994\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset is built by filtering the open-r1/OpenR1-Math-220k dataset according to the following rules:\\n\\nFirst, filter all of rows with only correct answers\\nThe chosen contains the shortest and correct generation, the rejected contains the wrong generation.\\nAll data with a prompt+chosen length exceeding 16k are filtered out.\\nWe provide the length for both chosen and rejected… See the full description on the dataset page: https://huggingface.co/datasets/AIR-hl/OpenR1-Math-220k-paired.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"CNTXTAI-Ranking-Dataset","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CNTXTAI0/CNTXTAI-Ranking-Dataset","creator_name":"CNTXT AI","creator_url":"https://huggingface.co/CNTXTAI0","description":"General Overview\\nThis dataset is to be used for LLM Trainings, This is a sample, visit https://www.cntxt.tech/ to learn more\\nThe dataset consists of 50 rows (excluding headers) and 8 columns. The columns capture various aspects of ranked responses to prompts, including:\\nNumeric_ID (Unique Identifier - Integer)\\nPrompt (The Question or Task - Text)\\nAnswer_A / Answer_B (Response Options - Text)\\nCategory (Type of Task - Categorical)\\nBest Answer (Preferred Response - Categorical)\\nLikeRT Score… See the full description on the dataset page: https://huggingface.co/datasets/CNTXTAI0/CNTXTAI-Ranking-Dataset.","first_N":5,"first_N_keywords":["text-classification","English","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"dutch-central-exam-mcq","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jjzha/dutch-central-exam-mcq","creator_name":"Mike Zhang","creator_url":"https://huggingface.co/jjzha","description":"Multiple Choice Questions of the Dutch Central Exam 1999-2024\\n\\nWhat?\\n\\nThis dataset contains only multiple choice questions from the Dutch Central Exam (High School level). From Wikipedia:\\nThe Eindexamen (Dutch pronunciation: [ˈɛi̯ntɛksamən]) or centraal examen (CE) is the matriculation exam in the Netherlands, which takes place in a student's final year of high school education (voortgezet onderwijs; \\\"continued education\\\"). The exam is regulated by the Dutch Secondary Education Act[1] and the… See the full description on the dataset page: https://huggingface.co/datasets/jjzha/dutch-central-exam-mcq.","first_N":5,"first_N_keywords":["multiple-choice","Dutch","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Coq-UniMath","keyword":"theorem-proving","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-UniMath","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUniMath Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe UniMath Dataset is derived from the UniMath repository, focusing on the formalization of Univalent Mathematics in the Coq proof assistant. This dataset processes .v files from the core mathematical libraries to extract mathematical content in a structured format. This work builds upon the format established by Andreas Florath (@florath) in his Coq Facts, Propositions and Proofs dataset, providing a more focused and… See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-UniMath.","first_N":5,"first_N_keywords":["text-generation","feature-extraction","other","English","bsd-2-clause"],"keywords_longer_than_N":true},
	{"name":"Coq-UniMath","keyword":"coq","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-UniMath","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUniMath Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe UniMath Dataset is derived from the UniMath repository, focusing on the formalization of Univalent Mathematics in the Coq proof assistant. This dataset processes .v files from the core mathematical libraries to extract mathematical content in a structured format. This work builds upon the format established by Andreas Florath (@florath) in his Coq Facts, Propositions and Proofs dataset, providing a more focused and… See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-UniMath.","first_N":5,"first_N_keywords":["text-generation","feature-extraction","other","English","bsd-2-clause"],"keywords_longer_than_N":true},
	{"name":"MMMU_Pro","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMMU/MMMU_Pro","creator_name":"MMMU","creator_url":"https://huggingface.co/MMMU","description":"\\n\\t\\n\\t\\t\\n\\t\\tMMMU-Pro (A More Robust Multi-discipline Multimodal Understanding Benchmark)\\n\\t\\n\\n🌐 Homepage | 🏆 Leaderboard | 🤗 Dataset | 🤗 Paper | 📖 arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🔔News\\n\\t\\n\\n\\n🛠️🛠️ [2025-03-08] Fixed mismatch between inner image labels and shuffled options in Vision and Standard (10 options) settings. (test_Chemistry_5,94,147,216,314,345,354,461,560,570; test_Materials_450; test_Pharmacy_198; validation_Chemistry_12,26,29; validation_Materials_10,28; validation_Psychology_1)… See the full description on the dataset page: https://huggingface.co/datasets/MMMU/MMMU_Pro.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"OpenMath-GSM8K-masked","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VishwamAI/OpenMath-GSM8K-masked","creator_name":"VishwamAI","creator_url":"https://huggingface.co/VishwamAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenMath-GSM8K-masked Dataset\\n\\t\\n\\nThis dataset is a masked version of the GSM8K dataset, designed for training and evaluating generative AI models on math-related reasoning tasks. The masked dataset is provided as part of the VishwamAI initiative to enhance AI's understanding of mathematical problem solving, specifically in text-to-math problems and chain-of-thought reasoning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\nNumber of rows: 7,473\\nFile Size: 6.07 MB (auto-converted Parquet files:… See the full description on the dataset page: https://huggingface.co/datasets/VishwamAI/OpenMath-GSM8K-masked.","first_N":5,"first_N_keywords":["text-generation","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Coq-MetaCoq-QA","keyword":"theorem-proving","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-MetaCoq-QA","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMetaCoq Q&A Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe MetaCoq Q&A Dataset is a conversational extension of the MetaCoq Dataset, derived from the MetaCoq formalization of Coq's meta-theory (https://github.com/MetaCoq/metacoq). This dataset transforms meta-theoretical content into structured Q&A pairs, making formal meta-programming and verification concepts more accessible through natural language interactions.\\nEach entry represents a mathematical statement from MetaCoq… See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-MetaCoq-QA.","first_N":5,"first_N_keywords":["question-answering","text-generation","other","English","mit"],"keywords_longer_than_N":true},
	{"name":"Coq-MetaCoq-QA","keyword":"coq","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-MetaCoq-QA","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMetaCoq Q&A Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe MetaCoq Q&A Dataset is a conversational extension of the MetaCoq Dataset, derived from the MetaCoq formalization of Coq's meta-theory (https://github.com/MetaCoq/metacoq). This dataset transforms meta-theoretical content into structured Q&A pairs, making formal meta-programming and verification concepts more accessible through natural language interactions.\\nEach entry represents a mathematical statement from MetaCoq… See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-MetaCoq-QA.","first_N":5,"first_N_keywords":["question-answering","text-generation","other","English","mit"],"keywords_longer_than_N":true},
	{"name":"smolThink","keyword":"math","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AILaborant/smolThink","creator_name":"AI Laborant","creator_url":"https://huggingface.co/AILaborant","description":"A small dataset that contains reasoning and complex mathematical problems, along with physics, and a little bit of geometry.\\n","first_N":5,"first_N_keywords":["English","gpl-3.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"smolBasisTolk","keyword":"math","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AILaborant/smolBasisTolk","creator_name":"AI Laborant","creator_url":"https://huggingface.co/AILaborant","description":"Smol but a wide variety of topics dataset for basic AI training.\\n","first_N":5,"first_N_keywords":["English","gpl-3.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"DeepScaler-QwQ_32b","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tttonyyy/DeepScaler-QwQ_32b","creator_name":"shaozhen liu","creator_url":"https://huggingface.co/tttonyyy","description":"这个数据集是基于DeepScalerR数据集采样20000条数据，使用QwQ-32B进行回答而收集到的。\\n在这个数据集中，文件末尾是_final.json的文件是经过过滤，只保留了回答正确数据的版本。\\n而末尾是.jsonl的文件是原始文件，里面包含了所有回答正确和错误的数据。\\n整个生成的正确性为：78.3%\\n重要的属性标签：\\n\\nquestion：问题\\ngt_cot：原本数据集的回答\\ngt：原本的数字答案\\npred_cot：模型的回答\\npred_cot_token_len：模型回答的token长度\\ncorrect：模型回答的是否正确\\nmessage：（如果有）表示一个提问回答对，可以直接交给llama-factory微调\\n\\n","first_N":5,"first_N_keywords":["English","mit","10K<n<100K","🇺🇸 Region: US","math"],"keywords_longer_than_N":false},
	{"name":"math_problem_traces_test2","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Wendong-Fan/math_problem_traces_test2","creator_name":"Wendong.Fan","creator_url":"https://huggingface.co/Wendong-Fan","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"PyRe-v2","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/PyRe-v2","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"\\n\\t\\n\\t\\t\\n\\t\\tPyRe 2\\n\\t\\n\\nThis data set is a mix of samples from a number of public data sets (sources indidcated in the actual data). The goal with this set was to create a smaller set focused on coding (primarily Python), math, and reasoning.\\n","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"camel_loong_medicine","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zikaixiao1/camel_loong_medicine","creator_name":"zikaixiao","creator_url":"https://huggingface.co/zikaixiao1","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"CleverBoi-Data-20k","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/CleverBoi-Data-20k","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"theprint/CleverBoi-Data-20k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"enwikimath","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/s-kat0/enwikimath","creator_name":"Shota Kato","creator_url":"https://huggingface.co/s-kat0","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\nThis dataset is created from the English Wikipedia dump file (enwiki-20240901-pages-articles-multistream.xml.bz2), available for download from Wikimedia Dumps. It includes pages containing mathematical content, extracted using the wikimathextractor tool, which is an adaptation of the wikiextractor specifically designed to extract mathematical contents.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nRepository: s-kat0/wikimathextractor\\nData Source: Wikipedia Dumps… See the full description on the dataset page: https://huggingface.co/datasets/s-kat0/enwikimath.","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ru_OpenMathInstruct-2","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mizinovmv/ru_OpenMathInstruct-2","creator_name":"maksim","creator_url":"https://huggingface.co/mizinovmv","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenMathInstruct-2\\n\\t\\n\\nПереведено на русский Qwen2.5-32B-Instruct-GPTQ-Int8\\nOpenMathInstruct-2 is a math instruction tuning dataset with 14M problem-solution pairs \\ngenerated using the Llama3.1-405B-Instruct model.\\nThe training set problems of GSM8K\\nand MATH are used for constructing the dataset in the following ways: \\n\\nSolution augmentation: Generating chain-of-thought solutions for training set problems in GSM8K and MATH. \\nProblem-Solution augmentation: Generating new problems… See the full description on the dataset page: https://huggingface.co/datasets/mizinovmv/ru_OpenMathInstruct-2.","first_N":5,"first_N_keywords":["question-answering","text-generation","Russian","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"algebra_misconceptions","keyword":"algebra","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nanote/algebra_misconceptions","creator_name":"Nancy Otero","creator_url":"https://huggingface.co/nanote","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMaE: Math Misconceptions and Errors Dataset\\n\\t\\n\\nThis dataset supports the research described in the paper A Benchmark for Math Misconceptions: Bridging Gaps in Middle School Algebra with AI-Supported Instruction by Nancy Otero, Stefania Druga, and Andrew Lan.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe MaE (Math Misconceptions and Errors) dataset is a collection of 220 diagnostic examples designed by math learning researchers that represent 55 common algebra misconceptions among middle school… See the full description on the dataset page: https://huggingface.co/datasets/nanote/algebra_misconceptions.","first_N":5,"first_N_keywords":["English","mit","1K - 10K","text","Text"],"keywords_longer_than_N":true},
	{"name":"algebra_misconceptions","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nanote/algebra_misconceptions","creator_name":"Nancy Otero","creator_url":"https://huggingface.co/nanote","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMaE: Math Misconceptions and Errors Dataset\\n\\t\\n\\nThis dataset supports the research described in the paper A Benchmark for Math Misconceptions: Bridging Gaps in Middle School Algebra with AI-Supported Instruction by Nancy Otero, Stefania Druga, and Andrew Lan.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe MaE (Math Misconceptions and Errors) dataset is a collection of 220 diagnostic examples designed by math learning researchers that represent 55 common algebra misconceptions among middle school… See the full description on the dataset page: https://huggingface.co/datasets/nanote/algebra_misconceptions.","first_N":5,"first_N_keywords":["English","mit","1K - 10K","text","Text"],"keywords_longer_than_N":true},
	{"name":"MATH_LVL5_fr","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/le-leadboard/MATH_LVL5_fr","creator_name":"le-leadboard","creator_url":"https://huggingface.co/le-leadboard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MATH_LVL5_fr\\n\\t\\n\\nle-leadboard/MATH_LVL5_fr fait partie de l'initiative OpenLLM French Leaderboard, proposant une adaptation française des problèmes mathématiques de niveau avancé du dataset MATH.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMATH_LVL5_fr est une adaptation française des problèmes mathématiques de niveau 5 (le plus avancé) du dataset MATH original. Il comprend des problèmes de compétition mathématique de niveau lycée, formatés de manière cohérente avec LaTeX pour… See the full description on the dataset page: https://huggingface.co/datasets/le-leadboard/MATH_LVL5_fr.","first_N":5,"first_N_keywords":["text2text-generation","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"dpo-merged","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CultriX/dpo-merged","creator_name":"CultriX","creator_url":"https://huggingface.co/CultriX","description":"CultriX/dpo-merged dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"dpo-merged-binarized","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CultriX/dpo-merged-binarized","creator_name":"CultriX","creator_url":"https://huggingface.co/CultriX","description":"CultriX/dpo-merged-binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Qu-QA","keyword":"gsm8k","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ereeeeef3/Qu-QA","creator_name":"ffhs9","creator_url":"https://huggingface.co/Ereeeeef3","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQu QA Dataset\\n\\t\\n\\nQu QA is a large-scale question-answering (QA) dataset designed for training and evaluating machine learning models. It consists of question-answer pairs in English, making it suitable for general-purpose QA tasks, as well as specialized domains like code-related question answering and GSM8k-style problems.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nFeatures:\\n\\ninput: A string representing the question (dtype: string).\\noutput: A string representing the answer (dtype: string).… See the full description on the dataset page: https://huggingface.co/datasets/Ereeeeef3/Qu-QA.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"Qu-QA-v2","keyword":"gsm8k","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ereeeeef3/Qu-QA-v2","creator_name":"ffhs9","creator_url":"https://huggingface.co/Ereeeeef3","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQu QA v2 Dataset\\n\\t\\n\\nQu QA v2 is a large-scale question-answering (QA) dataset designed for training and evaluating machine learning models. It consists of question-answer pairs in English, making it suitable for general-purpose QA tasks, as well as specialized domains like code-related question answering and GSM8k-style problems.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nFeatures:\\n\\ninput: A string representing the question (dtype: string).\\noutput: A string representing the answer (dtype:… See the full description on the dataset page: https://huggingface.co/datasets/Ereeeeef3/Qu-QA-v2.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"Qu-QA-v2","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ereeeeef3/Qu-QA-v2","creator_name":"ffhs9","creator_url":"https://huggingface.co/Ereeeeef3","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQu QA v2 Dataset\\n\\t\\n\\nQu QA v2 is a large-scale question-answering (QA) dataset designed for training and evaluating machine learning models. It consists of question-answer pairs in English, making it suitable for general-purpose QA tasks, as well as specialized domains like code-related question answering and GSM8k-style problems.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nFeatures:\\n\\ninput: A string representing the question (dtype: string).\\noutput: A string representing the answer (dtype:… See the full description on the dataset page: https://huggingface.co/datasets/Ereeeeef3/Qu-QA-v2.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"SWAP","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sxiong/SWAP","creator_name":"Siheng Xiong","creator_url":"https://huggingface.co/sxiong","description":"\\n\\t\\n\\t\\t\\n\\t\\tSWAP: A Synthetic Dataset for Complex Reasoning with Trajectories and Process Supervision\\n\\t\\n\\nThis repository contains the data for the paper Deliberate Reasoning for LLMs as Structure-aware Planning with Accurate World Model.\\nSWAP (Structure-aware Planning) solves complex reasoning by introducing a Generator-Discriminator architecture, and incorporates structural information to guide the reasoning process and provides a soft verification mechanism over the steps.\\nWe generate the… See the full description on the dataset page: https://huggingface.co/datasets/sxiong/SWAP.","first_N":5,"first_N_keywords":["text2text-generation","English","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"Coq-MetaCoq","keyword":"theorem-proving","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-MetaCoq","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMetaCoq Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe MetaCoq Dataset is derived from the MetaCoq repository, focusing on the formalization of Coq's meta-theory in the Coq proof assistant. This dataset processes .v files from the core theory directories to extract mathematical content in a structured format. This work builds upon the format established by Andreas Florath (@florath) in his Coq Facts, Propositions and Proofs dataset, providing a specialized view of the MetaCoq… See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-MetaCoq.","first_N":5,"first_N_keywords":["text-generation","feature-extraction","other","English","mit"],"keywords_longer_than_N":true},
	{"name":"Coq-MetaCoq","keyword":"coq","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-MetaCoq","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMetaCoq Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe MetaCoq Dataset is derived from the MetaCoq repository, focusing on the formalization of Coq's meta-theory in the Coq proof assistant. This dataset processes .v files from the core theory directories to extract mathematical content in a structured format. This work builds upon the format established by Andreas Florath (@florath) in his Coq Facts, Propositions and Proofs dataset, providing a specialized view of the MetaCoq… See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-MetaCoq.","first_N":5,"first_N_keywords":["text-generation","feature-extraction","other","English","mit"],"keywords_longer_than_N":true},
	{"name":"mathematical_reasoning_preference","keyword":"mathematics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Shekswess/mathematical_reasoning_preference","creator_name":"Bojan Jakimovski","creator_url":"https://huggingface.co/Shekswess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\nTopic: Mathematical Reasoning\\nDomains: Mathematics, Reasoning, Thinking\\nFocus: This dataset can contain any type of mathematical reasoning and thinking.\\nNumber of Entries: 493\\nDataset Type: None\\nModel Used: bedrock/us.amazon.nova-pro-v1:0\\nLanguage: English\\nAdditional Information: The dataset is designed to provide a wide range of mathematical reasoning examples.\\nGenerated by: SynthGenAI Package\\n\\n","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Coq-Changelog-QA","keyword":"theorem-proving","license":"GNU Lesser General Public License v2.1","license_url":"https://choosealicense.com/licenses/lgpl-2.1/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-Changelog-QA","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCoq Changelog Q&A Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Coq Changelog Q&A Dataset is an extension of the original Coq Changelog Dataset, transforming each changelog entry into two Question–Answer pairs via two distinct prompts. One focuses on a straightforward query about the change itself, while the other aims at the rationale or motivation behind it. By applying both prompts to every changelog entry, the dataset approximately doubles in size compared to the source.… See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Changelog-QA.","first_N":5,"first_N_keywords":["question-answering","text-generation","other","English","lgpl-2.1"],"keywords_longer_than_N":true},
	{"name":"Coq-Changelog-QA","keyword":"coq","license":"GNU Lesser General Public License v2.1","license_url":"https://choosealicense.com/licenses/lgpl-2.1/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-Changelog-QA","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCoq Changelog Q&A Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Coq Changelog Q&A Dataset is an extension of the original Coq Changelog Dataset, transforming each changelog entry into two Question–Answer pairs via two distinct prompts. One focuses on a straightforward query about the change itself, while the other aims at the rationale or motivation behind it. By applying both prompts to every changelog entry, the dataset approximately doubles in size compared to the source.… See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Changelog-QA.","first_N":5,"first_N_keywords":["question-answering","text-generation","other","English","lgpl-2.1"],"keywords_longer_than_N":true},
	{"name":"Lean4-Changelog","keyword":"theorem-proving","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Lean4-Changelog","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLean 4 Changelog Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Lean 4 Changelog Dataset provides structured, machine-readable entries for changes in Lean 4, including language and library updates, fixes, deprecations, and other modifications. This dataset focuses on release notes from Lean 4’s official changelogs, capturing the key updates that are most likely to impact users, developers, or researchers working with Lean 4.\\nBy offering structured data for these changes, this… See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-Changelog.","first_N":5,"first_N_keywords":["text-generation","feature-extraction","other","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"entrance-exams-qna","keyword":"maths","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/grafite/entrance-exams-qna","creator_name":"grafite","creator_url":"https://huggingface.co/grafite","description":"\\n\\t\\n\\t\\t\\n\\t\\tTO DO Checklist:\\n\\t\\n\\n\\n Clean Data\\n Remove duplicates\\n Handle missing values\\n Standardize data formats\\n\\n","first_N":5,"first_N_keywords":["English","cc-by-4.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"math_problem_traces_test","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Wendong-Fan/math_problem_traces_test","creator_name":"Wendong.Fan","creator_url":"https://huggingface.co/Wendong-Fan","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"DeepScale-qwen2.5_7b-multi","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tttonyyy/DeepScale-qwen2.5_7b-multi","creator_name":"shaozhen liu","creator_url":"https://huggingface.co/tttonyyy","description":"使用Qwen2.5-7b-Instruct模型，从DeepScaler数据集中抽取20000条数据，使用多轮对话的方式获得数学答案。\\nprompt模板：\\n\\n使用的system_prompt是LLAMA_MATH_SYSTEM_PROMPT\\n多轮对话的prompt是ITER_GEN_MULTI_TURN_STEP_PROMPTS\\n\\nLLAMA_MATH_SYSTEM_PROMPT = \\\"\\\"\\nSolve the following math problem efficiently and clearly:\\n\\n- For simple problems (2 steps or fewer):\\nProvide a concise solution with minimal explanation.\\n\\n- For complex problems (3 steps or more):\\nUse this step-by-step format:\\n\\n## Step 1: [Concise description]\\n[Brief explanation and calculations]\\n\\n##… See the full description on the dataset page: https://huggingface.co/datasets/tttonyyy/DeepScale-qwen2.5_7b-multi.","first_N":5,"first_N_keywords":["question-answering","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"logical","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Satyam-Singh/logical","creator_name":"Satyam Singh","creator_url":"https://huggingface.co/Satyam-Singh","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for GSM8K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\\n\\nThese problems take between 2 and 8 steps to solve.\\nSolutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ − ×÷) to reach the… See the full description on the dataset page: https://huggingface.co/datasets/Satyam-Singh/logical.","first_N":5,"first_N_keywords":["text2text-generation","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"metamath_ja_950_reka3flash","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kurogane/metamath_ja_950_reka3flash","creator_name":"kurogane himaki","creator_url":"https://huggingface.co/kurogane","description":"\\n\\t\\n\\t\\t\\n\\t\\tmetamath_ja_950_reka3flash\\n\\t\\n\\nmeta-math/MetaMathQAの最初の1000件をRekaAI/reka-flash-3で翻訳した後、フォーマットが維持されなかったものを除去しました。\\nデータセットは1000件ありますが、実際は950件程度です。\\nまた、フォーマットのみでクリーニングしたので、出力自体がおかしいものは除去できていません。このあたりは各自でクリーニングし直してください。\\n\\n\\t\\n\\t\\t\\n\\t\\t例\\n\\t\\n\\ninput\\n\\\\nグレイシーとジョーは複素平面上で数を選んでいます。ジョーは点 $1+2i$ を選び、グレイシーは $-1+i$ を選びました。二人の点間の距離はどれくらいですか？\\\\n\\\\n\\n\\noutput\\n\\\\n複素平面上の点 $(x_1,y_1)$ と $(x_2,y_2)$ の距離は、式 $\\\\\\\\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}$ で求められます。  \\\\nこの場合、ジョーの点は$(1,2)$、グレイシーの点は$(-1,1)$です。  \\\\nしたがって、彼らの点間の距離は… See the full description on the dataset page: https://huggingface.co/datasets/kurogane/metamath_ja_950_reka3flash.","first_N":5,"first_N_keywords":["Japanese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"gs8k_thai_r1_example","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/StelleX/gs8k_thai_r1_example","creator_name":"StelleX","creator_url":"https://huggingface.co/StelleX","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"countdown-numbers-3-8","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/alexjackson17/countdown-numbers-3-8","creator_name":"Alex Jackson","creator_url":"https://huggingface.co/alexjackson17","description":"\\n\\t\\n\\t\\t\\n\\t\\tCountdown Numbers Game Dataset\\n\\t\\n\\nThis dataset contains configurations and solutions for variations of the Countdown numbers game. Each example comprises a sequence of numbers, a target number, the computed solution (closest value), the arithmetic expression that achieves that value, the difference between the target and the computed value, and the final Countdown score.\\n\\n\\t\\n\\t\\t\\n\\t\\tHuggingFace Download Links\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\nDataset Variant\\nDataset Name\\nDownload\\n\\n\\n\\t\\t\\nRandom… See the full description on the dataset page: https://huggingface.co/datasets/alexjackson17/countdown-numbers-3-8.","first_N":5,"first_N_keywords":["mit","1M - 10M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"countdown-numbers-3-8-nz","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/alexjackson17/countdown-numbers-3-8-nz","creator_name":"Alex Jackson","creator_url":"https://huggingface.co/alexjackson17","description":"\\n\\t\\n\\t\\t\\n\\t\\tCountdown Numbers Game Dataset\\n\\t\\n\\nThis dataset contains configurations and solutions for variations of the Countdown numbers game. Each example comprises a sequence of numbers, a target number, the computed solution (closest value), the arithmetic expression that achieves that value, the difference between the target and the computed value, and the final Countdown score.\\n\\n\\t\\n\\t\\t\\n\\t\\tHuggingFace Download Links\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\nDataset Variant\\nDataset Name\\nDownload\\n\\n\\n\\t\\t\\nRandom… See the full description on the dataset page: https://huggingface.co/datasets/alexjackson17/countdown-numbers-3-8-nz.","first_N":5,"first_N_keywords":["mit","1M - 10M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"AIME25","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/AIME25","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"The AIME25 part 1 exam from the website.\\n","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"gsm8k","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/oieieio/gsm8k","creator_name":"Jorge Alonso","creator_url":"https://huggingface.co/oieieio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for GSM8K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\\n\\nThese problems take between 2 and 8 steps to solve.\\nSolutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ − ×÷) to reach the… See the full description on the dataset page: https://huggingface.co/datasets/oieieio/gsm8k.","first_N":5,"first_N_keywords":["text2text-generation","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"upload-test","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/koookiy/upload-test","creator_name":"yaoke","creator_url":"https://huggingface.co/koookiy","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"simple-decimal-comparision","keyword":"maths","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shb777/simple-decimal-comparision","creator_name":"SB","creator_url":"https://huggingface.co/shb777","description":"Simple Decimal Comparision upto 5 decimal places\\nPlease cite this dataset using the provided BibTeX if you find it useful.\\n@misc {sb_2025,\\n    author       = { {SB} },\\n    title        = { simple-decimal-comparision (Revision f470b80) },\\n    year         = 2025,\\n    url          = { https://huggingface.co/datasets/shb777/simple-decimal-comparision },\\n    doi          = { 10.57967/hf/3986 },\\n    publisher    = { Hugging Face }\\n}\\n\\n","first_N":5,"first_N_keywords":["question-answering","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"QuadraticDataset","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jack010/QuadraticDataset","creator_name":"Jacob Anso","creator_url":"https://huggingface.co/Jack010","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuadratic Equations Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains a collection of quadratic equations along with their solutions, discriminant values, root types, and step-by-step solutions. It is designed for training and evaluating machine learning models that solve quadratic equations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nTask: Solving quadratic equations\\nLeaderboard: Not applicable\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nMathematics: The dataset is mathematical… See the full description on the dataset page: https://huggingface.co/datasets/Jack010/QuadraticDataset.","first_N":5,"first_N_keywords":["mit","10K - 100K","csv","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"QuadraticDataset","keyword":"algebra","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jack010/QuadraticDataset","creator_name":"Jacob Anso","creator_url":"https://huggingface.co/Jack010","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuadratic Equations Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains a collection of quadratic equations along with their solutions, discriminant values, root types, and step-by-step solutions. It is designed for training and evaluating machine learning models that solve quadratic equations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nTask: Solving quadratic equations\\nLeaderboard: Not applicable\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nMathematics: The dataset is mathematical… See the full description on the dataset page: https://huggingface.co/datasets/Jack010/QuadraticDataset.","first_N":5,"first_N_keywords":["mit","10K - 100K","csv","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"G15","keyword":"maths","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/brahmairesearch/G15","creator_name":"BRAHMAI Research","creator_url":"https://huggingface.co/brahmairesearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tG15 - v0.1\\n\\t\\n\\nG15-v0.1 is a part of G-series datasets which are pre-formatted in ChatML template.\\nThese datasets are useful for quickly finetuning LLMs for better responses.\\n\\n\\nThe G15-v0.1 is a combination of the following datasets:\\n\\nOpenHermes-2.5\\nMetaMathQA (100k entries)\\nA section of our in-house dataset used to finetune Cerberus-v0.1\\n\\nThis dataset is to be used on smaller LLMs (1B - 7B) to increase their response quality.\\n\\nFor queries please reach out to us at hello@brahmai.in\\n","first_N":5,"first_N_keywords":["text2text-generation","text-generation","Hindi","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"orca-math-word-reflection","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Harshkmr/orca-math-word-reflection","creator_name":"Harsh Kumar","creator_url":"https://huggingface.co/Harshkmr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"orca-math-word-reflection\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Orca-Math Word Problems with Reflection dataset is an extension of subset of the original ORCA Math Word Problems 200k dataset. This new version introduces a \\\"Thinking and Reflection\\\" format designed to enhance problem-solving approaches by encouraging step-by-step thinking before producing a solution. \\nIn this dataset, each math word problem and its corresponding solution from the original dataset… See the full description on the dataset page: https://huggingface.co/datasets/Harshkmr/orca-math-word-reflection.","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"CompositionalGSM_augmented","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuGyouk/CompositionalGSM_augmented","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCompositional GSM_augmented\\n\\t\\n\\nCompositional GSM_augmented is a math instruction dataset, inspired by Not All LLM Reasoners Are Created Equal.\\nIt is based on nvidia/OpenMathInstruct-2 dataset, so you can use this dataset as training dataset.\\nIt is generated using meta-llama/Meta-Llama-3.1-70B-Instruct model by Hyperbloic AI link. (Thanks for free credit!)\\nReplace the description of the data with the contents in the paper.\\n\\nEach question in compositional GSM consists of two… See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/CompositionalGSM_augmented.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"PropensityScores","keyword":"statistics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cjerzak/PropensityScores","creator_name":"Connor T. Jerzak","creator_url":"https://huggingface.co/cjerzak","description":"\\n\\t\\n\\t\\t\\n\\t\\tA Dataset on Propensity Score Matching Papers, 1964-2014\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset provides bibliographic and methodological information on a random sample of academic articles involving propensity score matching (PSM). Each row corresponds to a single article and contains information such as the article’s DOI, title, authors, publication year, and a series of binary or categorical indicators describing the methods used or reported within the study. These indicators focus… See the full description on the dataset page: https://huggingface.co/datasets/cjerzak/PropensityScores.","first_N":5,"first_N_keywords":["mit","< 1K","csv","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Coq-Changelog","keyword":"theorem-proving","license":"GNU Lesser General Public License v2.1","license_url":"https://choosealicense.com/licenses/lgpl-2.1/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-Changelog","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCoq Changelog Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Coq Changelog Dataset is derived from the official Coq changelogs, focusing on versions 8.17 to 8.20. These versions were specifically chosen as they represent changes that may be underrepresented or entirely absent from current language model training data. By targeting these recent versions, this dataset helps address knowledge gaps in formal methods tools and theorem proving systems.\\nThis dataset provides structured… See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Changelog.","first_N":5,"first_N_keywords":["text-generation","feature-extraction","other","English","lgpl-2.1"],"keywords_longer_than_N":true},
	{"name":"Coq-Changelog","keyword":"coq","license":"GNU Lesser General Public License v2.1","license_url":"https://choosealicense.com/licenses/lgpl-2.1/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-Changelog","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCoq Changelog Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Coq Changelog Dataset is derived from the official Coq changelogs, focusing on versions 8.17 to 8.20. These versions were specifically chosen as they represent changes that may be underrepresented or entirely absent from current language model training data. By targeting these recent versions, this dataset helps address knowledge gaps in formal methods tools and theorem proving systems.\\nThis dataset provides structured… See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Changelog.","first_N":5,"first_N_keywords":["text-generation","feature-extraction","other","English","lgpl-2.1"],"keywords_longer_than_N":true},
	{"name":"Olympiads","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/artnoage/Olympiads","creator_name":"Vaios Laschos","creator_url":"https://huggingface.co/artnoage","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 137830\\nFiltered size: 42607\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word… See the full description on the dataset page: https://huggingface.co/datasets/artnoage/Olympiads.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Olympiads","keyword":"mathematical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/artnoage/Olympiads","creator_name":"Vaios Laschos","creator_url":"https://huggingface.co/artnoage","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 137830\\nFiltered size: 42607\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word… See the full description on the dataset page: https://huggingface.co/datasets/artnoage/Olympiads.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Olympiads","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/artnoage/Olympiads","creator_name":"Vaios Laschos","creator_url":"https://huggingface.co/artnoage","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 137830\\nFiltered size: 42607\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word… See the full description on the dataset page: https://huggingface.co/datasets/artnoage/Olympiads.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"gsm8k-platinum","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/madrylab/gsm8k-platinum","creator_name":"Madry Lab","creator_url":"https://huggingface.co/madrylab","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for GSM8K-Platinum\\n\\t\\n\\n🏆 Homepage  |  📣 Blog  |  🖥️ Code  |  📖 Paper  |  🔍 Error Viewer\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGSM8K-Platinum is a revised version of the full test set of GSM8K (Grade School Math 8K), a dataset of grade school math word problems, providing a more accurate assessment of mathematical reasoning capabilities\\nTo revise this dataset, we ran a variety of frontier models each individual example and manually examined any example for which at least one… See the full description on the dataset page: https://huggingface.co/datasets/madrylab/gsm8k-platinum.","first_N":5,"first_N_keywords":["text2text-generation","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"gsm8k","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/openai/gsm8k","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for GSM8K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\\n\\nThese problems take between 2 and 8 steps to solve.\\nSolutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ − ×÷) to reach the… See the full description on the dataset page: https://huggingface.co/datasets/openai/gsm8k.","first_N":5,"first_N_keywords":["text2text-generation","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"VisualWebInstruct","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is the final dataset we used to train MAmmoTH-VL2.\\n\\n\\t\\n\\t\\t\\n\\t\\tSubset\\n\\t\\n\\n\\nconversation: this subset contains VisualWebInstruct + LLavaCoT in the form of conversation.\\nexample: this subset is mainly for visualizing the examples.\\nvisualwebinstruct: this subset contains our dataset in the QA format.\\nimage: all the images are in imgs.tar.gz\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLinks\\n\\t\\n\\nGithub|\\nPaper|\\nWebsite|\\nModel\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{visualwebinstruct,\\n    title={VisualWebInstruct: Scaling… See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"NuminaMath-CoT","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI-MO/NuminaMath-CoT","creator_name":"Project-Numina","creator_url":"https://huggingface.co/AI-MO","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NuminaMath CoT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nApproximately 860k math problems, where each solution is formatted in a Chain of Thought (CoT) manner. The sources of the dataset range from Chinese high school math exercises to US and international mathematics olympiad competition problems. The data were primarily collected from online exam paper PDFs and mathematics discussion forums. The processing steps include (a) OCR from the original PDFs, (b) segmentation… See the full description on the dataset page: https://huggingface.co/datasets/AI-MO/NuminaMath-CoT.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Light-R1-DPOData","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qihoo360/Light-R1-DPOData","creator_name":"北京奇虎科技有限公司","creator_url":"https://huggingface.co/qihoo360","description":"\\n\\t\\n\\t\\t\\n\\t\\tLight-R1: Surpassing R1-Distill from Scratch* with $1000 through Curriculum SFT & DPO\\n\\t\\n\\n*from models without long COT\\ntechnical report\\nGitHub page\\nHere is the DPO data we used to train Light-R1-32B.\\nSimply refer to dpo-pairs.json\\n\\n\\t\\n\\t\\t\\nModel\\nTrained From\\nRelease Date\\nAIME24\\nAIME25\\n\\n\\n\\t\\t\\nDeepSeek-R1-Distill-Llama-70B\\nLlama-3.3-70B-Instruct\\n25.1.20\\n70.0\\n54.1\\n\\n\\nDeepSeek-R1-Distill-Qwen-32B\\nQwen2.5-32B\\n25.1.20\\n72.6\\n54.9\\n\\n\\nLIMO (32B)\\nQwen2.5-32B-Instruct25.2.4\\n56.3\\n47.1\\n\\n\\ns1.1-32B… See the full description on the dataset page: https://huggingface.co/datasets/qihoo360/Light-R1-DPOData.","first_N":5,"first_N_keywords":["text-generation","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MetaMathQA","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meta-math/MetaMathQA","creator_name":"MetaMath","creator_url":"https://huggingface.co/meta-math","description":"View the project page:\\nhttps://meta-math.github.io/\\nsee our paper at https://arxiv.org/abs/2309.12284\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\nAll MetaMathQA data are augmented from the training sets of GSM8K and MATH. \\nNone of the augmented data is from the testing set.\\nYou can check the original_question in meta-math/MetaMathQA, each item is from the GSM8K or MATH train set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Details\\n\\t\\n\\nMetaMath-Mistral-7B is fully fine-tuned on the MetaMathQA datasets and based on the powerful Mistral-7B model.… See the full description on the dataset page: https://huggingface.co/datasets/meta-math/MetaMathQA.","first_N":5,"first_N_keywords":["mit","100K - 1M","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"OpenMathInstruct-2","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nvidia/OpenMathInstruct-2","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenMathInstruct-2\\n\\t\\n\\nOpenMathInstruct-2 is a math instruction tuning dataset with 14M problem-solution pairs \\ngenerated using the Llama3.1-405B-Instruct model.\\nThe training set problems of GSM8K\\nand MATH are used for constructing the dataset in the following ways: \\n\\nSolution augmentation: Generating chain-of-thought solutions for training set problems in GSM8K and MATH. \\nProblem-Solution augmentation: Generating new problems, followed by solutions for these new problems.… See the full description on the dataset page: https://huggingface.co/datasets/nvidia/OpenMathInstruct-2.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"MathVista","keyword":"mathematics","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI4Math/MathVista","creator_name":"AI for Math Reasoning","creator_url":"https://huggingface.co/AI4Math","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MathVista\\n\\t\\n\\n\\nDataset Description\\nPaper Information\\nDataset Examples\\nLeaderboard\\nDataset Usage\\nData Downloading\\nData Format\\nData Visualization\\nData Source\\nAutomatic Evaluation\\n\\n\\nLicense\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMathVista is a consolidated Mathematical reasoning benchmark within Visual contexts. It consists of three newly created datasets, IQTest, FunctionQA, and PaperQA, which address the missing visual domains and are tailored to evaluate… See the full description on the dataset page: https://huggingface.co/datasets/AI4Math/MathVista.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","text-classification","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"NuminaMath-1.5","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI-MO/NuminaMath-1.5","creator_name":"Project-Numina","creator_url":"https://huggingface.co/AI-MO","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for NuminaMath 1.5\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the second iteration of the popular NuminaMath dataset, bringing high quality post-training data for approximately 900k competition-level math problems.  Each solution is formatted in a Chain of Thought (CoT) manner. The sources of the dataset range from Chinese high school math exercises to US and international mathematics olympiad competition problems. The data were primarily collected from online exam paper PDFs… See the full description on the dataset page: https://huggingface.co/datasets/AI-MO/NuminaMath-1.5.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"HoT","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/groundingauburn/HoT","creator_name":"grounding_auburn","creator_url":"https://huggingface.co/groundingauburn","description":"\\n\\t\\n\\t\\t\\n\\t\\t📚 Fact-Enhanced Math Question Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains math word, logical reasoning, question answering and reading comprehension problems with automatically reformatted questions and answers using XML tags for facts. It is designed to facilitate research in explainable AI (XAI), Human-AI interaction.\\nEach question is reformatted to explicitly highlight key facts using XML-style tags (<fact1>, <fact2>, etc.), and the answer explanation follows a… See the full description on the dataset page: https://huggingface.co/datasets/groundingauburn/HoT.","first_N":5,"first_N_keywords":["English","mit","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"MathInstruct","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/MathInstruct","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🦣 MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning\\n\\t\\n\\nMathInstruct is a meticulously curated instruction tuning dataset that is lightweight yet generalizable. MathInstruct is compiled from 13 math rationale datasets, six of which are newly curated by this work. It uniquely focuses on the hybrid use of chain-of-thought (CoT) and program-of-thought (PoT) rationales, and ensures extensive coverage of diverse mathematical fields. \\nProject Page:… See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/MathInstruct.","first_N":5,"first_N_keywords":["text-generation","English","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"GSM8K_zh","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meta-math/GSM8K_zh","creator_name":"MetaMath","creator_url":"https://huggingface.co/meta-math","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\nGSM8K_zh is a dataset for mathematical reasoning in Chinese, question-answer pairs are translated from GSM8K (https://github.com/openai/grade-school-math/tree/master) by GPT-3.5-Turbo with few-shot prompting.\\nThe dataset consists of 7473 training samples and 1319 testing samples. The former is for supervised fine-tuning, while the latter is for evaluation.\\nfor training samples, question_zh and answer_zh are question and answer keys, respectively;\\nfor testing samples… See the full description on the dataset page: https://huggingface.co/datasets/meta-math/GSM8K_zh.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"aops","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sparsh35/aops","creator_name":"SPARSH TEWATIA","creator_url":"https://huggingface.co/sparsh35","description":"sparsh35/aops dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","apache-2.0","1K - 10K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"Omni-MATH","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KbsdJames/Omni-MATH","creator_name":"Bofei Gao","creator_url":"https://huggingface.co/KbsdJames","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Omni-MATH\\n\\t\\n\\n\\n\\nRecent advancements in AI, particularly in large language models (LLMs), have led to significant breakthroughs in mathematical reasoning capabilities. However, existing benchmarks like GSM8K or MATH are now being solved with high accuracy (e.g., OpenAI o1 achieves 94.8% on MATH dataset), indicating their inadequacy for truly challenging these models. To mitigate this limitation, we propose a comprehensive and challenging benchmark specifically… See the full description on the dataset page: https://huggingface.co/datasets/KbsdJames/Omni-MATH.","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"ProcessBench","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Qwen/ProcessBench","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProcessBench\\n\\t\\n\\nThis repository contains the dataset of the ProcessBench benchmark proposed by Qwen Team.\\nYou can refer to our GitHub repository for the evaluation code and the prompt templates we use in this work.\\nIf you find this work relevant or helpful to your work, please kindly cite us:\\n@article{processbench,\\n  title={ProcessBench: Identifying Process Errors in Mathematical Reasoning}, \\n  author={\\n    Chujie Zheng and Zhenru Zhang and Beichen Zhang and Runji Lin and Keming Lu… See the full description on the dataset page: https://huggingface.co/datasets/Qwen/ProcessBench.","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"aime-1983-2024","keyword":"mathematics","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gneubig/aime-1983-2024","creator_name":"Graham Neubig","creator_url":"https://huggingface.co/gneubig","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAIME Problem Set 1983-2024\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains problems from the American Invitational Mathematics Examination (AIME) from 1983 to 2024. The AIME is a prestigious mathematics competition for high school students in the United States and Canada.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nSource: Kaggle - AIME Problem Set 1983-2024\\nLicense: CC0: Public Domain\\nTotal Problems: 2,250\\nYears Covered: 1983 to 2024\\nMain Task: Mathematics Problem Solving… See the full description on the dataset page: https://huggingface.co/datasets/gneubig/aime-1983-2024.","first_N":5,"first_N_keywords":["text-classification","English","cc0-1.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"proof-pile","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hoskinson-center/proof-pile","creator_name":"Hoskinson Center for Formal Mathematics","creator_url":"https://huggingface.co/hoskinson-center","description":"A dataset of high quality mathematical text.","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"proof-pile","keyword":"mathematics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hoskinson-center/proof-pile","creator_name":"Hoskinson Center for Formal Mathematics","creator_url":"https://huggingface.co/hoskinson-center","description":"A dataset of high quality mathematical text.","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mgsm","keyword":"math-word-problems","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/juletxara/mgsm","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","description":"Multilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper [Language models are multilingual chain-of-thought reasoners](http://arxiv.org/abs/2210.03057).\\n\\nThe same 250 problems from [GSM8K](https://arxiv.org/abs/2110.14168) are each translated via human annotators in 10 languages. The 10 languages are:\\n- Spanish\\n- French\\n- German\\n- Russian\\n- Chinese\\n- Japanese\\n- Thai\\n- Swahili\\n- Bengali\\n- Telugu\\n\\nYou can find the input and targets for each of the ten languages (and English) as `.tsv` files.\\nWe also include few-shot exemplars that are also manually translated from each language in `exemplars.py`.","first_N":5,"first_N_keywords":["text2text-generation","found","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"naturalproofs-gen","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wellecks/naturalproofs-gen","creator_name":"Sean Welleck","creator_url":"https://huggingface.co/wellecks","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNaturalproofs-gen\\n\\t\\n\\nThis dataset contains the Naturalproofs-gen corpus from:\\nNaturalProver: Grounded Mathematical Proof Generation with Language ModelsSean Welleck*, Jiacheng Liu*, Ximing Lu, Hannaneh Hajishirzi, Yejin ChoiNeurIPS 2022\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nMIT\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\nPlease cite:\\n@inproceedings{welleck2022naturalprover,\\n    title={NaturalProver: Grounded Mathematical Proof Generation with Language Models},\\n    author={Sean Welleck and… See the full description on the dataset page: https://huggingface.co/datasets/wellecks/naturalproofs-gen.","first_N":5,"first_N_keywords":["mit","10K - 100K","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"naturalproofs-gen","keyword":"theorem-proving","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wellecks/naturalproofs-gen","creator_name":"Sean Welleck","creator_url":"https://huggingface.co/wellecks","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNaturalproofs-gen\\n\\t\\n\\nThis dataset contains the Naturalproofs-gen corpus from:\\nNaturalProver: Grounded Mathematical Proof Generation with Language ModelsSean Welleck*, Jiacheng Liu*, Ximing Lu, Hannaneh Hajishirzi, Yejin ChoiNeurIPS 2022\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nMIT\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\nPlease cite:\\n@inproceedings{welleck2022naturalprover,\\n    title={NaturalProver: Grounded Mathematical Proof Generation with Language Models},\\n    author={Sean Welleck and… See the full description on the dataset page: https://huggingface.co/datasets/wellecks/naturalproofs-gen.","first_N":5,"first_N_keywords":["mit","10K - 100K","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"gsm8k-ru","keyword":"gsm8k","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/gsm8k-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tgsm8k-ru\\n\\t\\n\\nTranslated version of gsm8k dataset into Russian.\\n","first_N":5,"first_N_keywords":["text2text-generation","crowdsourced","translated","monolingual","gsm8k"],"keywords_longer_than_N":true},
	{"name":"gsm8k-ru","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/gsm8k-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tgsm8k-ru\\n\\t\\n\\nTranslated version of gsm8k dataset into Russian.\\n","first_N":5,"first_N_keywords":["text2text-generation","crowdsourced","translated","monolingual","gsm8k"],"keywords_longer_than_N":true},
	{"name":"Puffin","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/Puffin","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Puffin dataset. Exactly 3,000 examples with each response created using GPT-4.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPLEASE USE THE NEWER VERSION OF PUFFIN CALLED PURE-DOVE, IT IS NO LONGER RECCOMENDED TO USE PUFFIN\\n\\t\\n\\n\\nComprised of over 2,000 multi-turn conversations between GPT-4 and real humans.\\n\\nAverage context length per conversation is over 1,000 tokens. (will measure this more accurately soon)\\n\\nAverage turns per conversation is more than 10. (will measure this more accurately… See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Puffin.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"LessWrong-Amplify-Instruct","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/LessWrong-Amplify-Instruct","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official LessWrong-Amplify-Instruct dataset. Over 500 multi-turn examples, and many more coming soon!\\n\\t\\n\\n\\nThis leverages Amplify-Instruct method to extend thousands of scraped Less-Wrong posts into advanced in-depth multi-turn conversations.\\n\\nComprised of over 500 highly filtered multi-turn synthetic conversations.\\n\\nAverage context length per conversation is over 2,000 tokens. (will measure this more accurately soon)\\n\\nSynthetically created using a newly developed… See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/LessWrong-Amplify-Instruct.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Pure-Dove","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/Pure-Dove","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Pure-Dove dataset. Over 3K multi-turn examples, and many more coming soon!\\n\\t\\n\\nThis dataset aims to be the largest highest quality cluster of real human back and forth conversations with GPT-4.\\nSteps have even been done to ensure that only the best GPT-4 conversations in comparisons are kept, there are many instances where two GPT-4 responses are rated as equal to eachother or as both bad. We exclude all such responses from Pure Dove and make sure to only… See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Pure-Dove.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Conic10K","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WenyangHui/Conic10K","creator_name":"huiwy","creator_url":"https://huggingface.co/WenyangHui","description":"WenyangHui/Conic10K dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"unarXive-en2ru","keyword":"mathematics","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/waleko/unarXive-en2ru","creator_name":"Alexander Kovrigin","creator_url":"https://huggingface.co/waleko","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for unarXive-en2ru\\n\\t\\n\\nThis dataset contains text excerpts from the unarXive citation recommendation dataset along with their translations into Russian. The translations have been obtained using OpenAI GPT-3.5-Turbo. The dataset is intended for machine translation research.\\n","first_N":5,"first_N_keywords":["translation","machine-generated","saier/unarXive_citrec","English","Russian"],"keywords_longer_than_N":true},
	{"name":"distilabel-math-preference-dpo","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla/distilabel-math-preference-dpo","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"distilabel-math-preference-dpo\\\"\\n\\t\\n\\nMore Information needed\\n","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MMMU","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMMU/MMMU","creator_name":"MMMU","creator_url":"https://huggingface.co/MMMU","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI)\\n\\t\\n\\n🌐 Homepage | 🏆 Leaderboard | 🤗 Dataset | 🤗 Paper | 📖 arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🔔News\\n\\t\\n\\n\\n🛠️[2024-05-30]: Fixed duplicate option issues in Materials dataset items (validation_Materials_25; test_Materials_17, 242) and content error in validation_Materials_25.\\n🛠️[2024-04-30]: Fixed missing \\\"-\\\" or \\\"^\\\" signs in Math dataset items (dev_Math_2, validation_Math_11, 12, 16;… See the full description on the dataset page: https://huggingface.co/datasets/MMMU/MMMU.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"gsm8k_chinese","keyword":"gsm8k","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/swulling/gsm8k_chinese","creator_name":"Alex Yang","creator_url":"https://huggingface.co/swulling","description":"swulling/gsm8k_chinese dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","gsm8k","Chinese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"gsm8k_chinese","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/swulling/gsm8k_chinese","creator_name":"Alex Yang","creator_url":"https://huggingface.co/swulling","description":"swulling/gsm8k_chinese dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","gsm8k","Chinese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"multilingual-mathematical-autoformalization","keyword":"mathematics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/casey-martin/multilingual-mathematical-autoformalization","creator_name":"Casey","creator_url":"https://huggingface.co/casey-martin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Mathematical Autoformalization\\n\\t\\n\\n\\\"Paper\\\"\\nThis repository contains parallel mathematical statements:\\n\\nInput: An informal proof in natural language\\nOutput: The corresponding formalization in either Lean or Isabelle\\n\\nThis dataset can be used to train models how to formalize mathematical statements into verifiable proofs, a form of machine translation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbstract\\n\\t\\n\\nAutoformalization is the task of translating natural language materials into machine-verifiable… See the full description on the dataset page: https://huggingface.co/datasets/casey-martin/multilingual-mathematical-autoformalization.","first_N":5,"first_N_keywords":["translation","text-generation","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"MetaMathQA_GSM8K_zh","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meta-math/MetaMathQA_GSM8K_zh","creator_name":"MetaMath","creator_url":"https://huggingface.co/meta-math","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\nMetaMathQA_GSM8K_zh is a dataset for mathematical reasoning in Chinese, \\nquestion-answer pairs are translated from MetaMathQA (https://huggingface.co/datasets/meta-math/MetaMathQA) by GPT-3.5-Turbo with few-shot prompting.\\nThe dataset consists of 231685 samples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you find the GSM8K_zh dataset useful for your projects/papers, please cite the following paper.\\n@article{yu2023metamath,\\n  title={MetaMath: Bootstrap Your Own Mathematical Questions for… See the full description on the dataset page: https://huggingface.co/datasets/meta-math/MetaMathQA_GSM8K_zh.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Capybara","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/Capybara","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Capybara dataset. Over 10,000 multi-turn examples.\\n\\t\\n\\nCapybara is the culmination of insights derived from synthesis techniques like Evol-instruct (used for WizardLM), Alpaca, Orca, Vicuna, Lamini, FLASK and others.\\nThe single-turn seeds used to initiate the Amplify-Instruct synthesis of conversations are mostly based on datasets that i've personally vetted extensively, and are often highly regarded for their diversity and demonstration of logical robustness… See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Capybara.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"jeebench","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/daman1209arora/jeebench","creator_name":"Daman","creator_url":"https://huggingface.co/daman1209arora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tJEEBench(EMNLP 2023)\\n\\t\\n\\nRepository for the code and dataset for the paper: \\\"Have LLMs Advanced Enough? A Harder Problem Solving Benchmark For Large Language Models\\\" accepted in EMNLP 2023 as a Main conference paper. \\nhttps://aclanthology.org/2023.emnlp-main.468/\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you use our dataset in your research, please cite it using the following\\n@inproceedings{arora-etal-2023-llms,\\n    title = \\\"Have {LLM}s Advanced Enough? A Challenging Problem Solving Benchmark For… See the full description on the dataset page: https://huggingface.co/datasets/daman1209arora/jeebench.","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ws-5d","keyword":"math","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/calabi-yau-data/ws-5d","creator_name":"Calabi-Yau data","creator_url":"https://huggingface.co/calabi-yau-data","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWeight Systems Defining Five-Dimensional IP Lattice Polytopes\\n\\t\\n\\nThis dataset contains all weight systems defining five-dimensional reflexive and\\nnon-reflexive IP lattice polytopes, instrumental in the study of Calabi-Yau fourfolds in\\nmathematics and theoretical physics. The data was compiled by Harald Skarke and Friedrich\\nSchöller in arXiv:1808.02422. More information is\\navailable at the Calabi-Yau data website. The\\ndataset can be explored using the search\\nfrontend. See below for… See the full description on the dataset page: https://huggingface.co/datasets/calabi-yau-data/ws-5d.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","100B - 1T","parquet","Tabular","Datasets"],"keywords_longer_than_N":true},
	{"name":"Mr-GSM8K","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Randolphzeng/Mr-GSM8K","creator_name":"Randolphzeng","creator_url":"https://huggingface.co/Randolphzeng","description":"View the project page:\\nhttps://github.com/dvlab-research/DiagGSM8K\\nsee our paper at https://arxiv.org/abs/2312.17080\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nIn this work, we introduce a novel evaluation paradigm for Large Language Models, \\none that challenges them to engage in meta-reasoning. Our paradigm shifts the focus from result-oriented assessments, \\nwhich often overlook the reasoning process, to a more holistic evaluation that effectively differentiates \\nthe cognitive capabilities among models. For… See the full description on the dataset page: https://huggingface.co/datasets/Randolphzeng/Mr-GSM8K.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"StackMathQA","keyword":"mathematical-reasoning","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/math-ai/StackMathQA","creator_name":"math-ai","creator_url":"https://huggingface.co/math-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\tStackMathQA\\n\\t\\n\\nStackMathQA is a meticulously curated collection of 2 million mathematical questions and answers, sourced from various Stack Exchange sites. This repository is designed to serve as a comprehensive resource for researchers, educators, and enthusiasts in the field of mathematics and AI research.\\n\\n\\t\\n\\t\\t\\n\\t\\tConfigs\\n\\t\\n\\nconfigs:\\n- config_name: stackmathqa1600k\\n  data_files: data/stackmathqa1600k/all.jsonl\\n  default: true\\n- config_name: stackmathqa800k\\n  data_files:… See the full description on the dataset page: https://huggingface.co/datasets/math-ai/StackMathQA.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Latex-VLM","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JosselinSom/Latex-VLM","creator_name":"Josselin Somerville","creator_url":"https://huggingface.co/JosselinSom","description":"JosselinSom/Latex-VLM dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Latex-VLM","keyword":"statistics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JosselinSom/Latex-VLM","creator_name":"Josselin Somerville","creator_url":"https://huggingface.co/JosselinSom","description":"JosselinSom/Latex-VLM dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"image2struct-latex-v1","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stanford-crfm/image2struct-latex-v1","creator_name":"Stanford CRFM","creator_url":"https://huggingface.co/stanford-crfm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tImage2Struct - Latex\\n\\t\\n\\nPaper | Website | Datasets (Webpages, Latex, Music sheets) | Leaderboard | HELM repo | Image2Struct repo\\nLicense: Apache License Version 2.0, January 2004\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\nImage2struct is a benchmark for evaluating vision-language models in practical tasks of extracting structured information from images.\\nThis subdataset focuses on LaTeX code. The model is given an image of the expected output with the prompt:\\nPlease provide the LaTex code… See the full description on the dataset page: https://huggingface.co/datasets/stanford-crfm/image2struct-latex-v1.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"image2struct-latex-v1","keyword":"statistics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stanford-crfm/image2struct-latex-v1","creator_name":"Stanford CRFM","creator_url":"https://huggingface.co/stanford-crfm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tImage2Struct - Latex\\n\\t\\n\\nPaper | Website | Datasets (Webpages, Latex, Music sheets) | Leaderboard | HELM repo | Image2Struct repo\\nLicense: Apache License Version 2.0, January 2004\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\nImage2struct is a benchmark for evaluating vision-language models in practical tasks of extracting structured information from images.\\nThis subdataset focuses on LaTeX code. The model is given an image of the expected output with the prompt:\\nPlease provide the LaTex code… See the full description on the dataset page: https://huggingface.co/datasets/stanford-crfm/image2struct-latex-v1.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"AutoMathText","keyword":"mathematical-reasoning","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/math-ai/AutoMathText","creator_name":"math-ai","creator_url":"https://huggingface.co/math-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\tAutoMathText\\n\\t\\n\\nAutoMathText is an extensive and carefully curated dataset encompassing around 200 GB of mathematical texts. It's a compilation sourced from a diverse range of platforms including various websites, arXiv, and GitHub (OpenWebMath, RedPajama, Algebraic Stack). This rich repository has been autonomously selected (labeled) by the state-of-the-art open-source language model, Qwen-72B. Each piece of content in the dataset is assigned a score lm_q1q2_score within the range of… See the full description on the dataset page: https://huggingface.co/datasets/math-ai/AutoMathText.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"distilabel-capybara-dpo-7k-binarized","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla/distilabel-capybara-dpo-7k-binarized","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCapybara-DPO 7K binarized\\n\\t\\n\\n\\nA DPO dataset built with distilabel atop the awesome LDJnr/Capybara\\n\\n\\nThis is a preview version to collect feedback from the community. v2 will include the full base dataset and responses from more powerful models.\\n\\n\\n    \\n\\n\\n\\n  \\n    \\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy?\\n\\t\\n\\nMulti-turn dialogue data is key to fine-tune capable chat models. Multi-turn preference data has been used by the most relevant RLHF works (Anthropic, Meta Llama2, etc.). Unfortunately, there are… See the full description on the dataset page: https://huggingface.co/datasets/argilla/distilabel-capybara-dpo-7k-binarized.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"UltraTextbooks","keyword":"math","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/UltraTextbooks","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"UltraTextbooks\\\"\\n\\t\\n\\n\\nIn the digital expanse, a Tree of Knowledge grows,\\nIts branches of code and words intertwine in prose.\\nSynthetic leaves shimmer, human insights compose,\\nA binary symphony where wisdom forever flows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRepository\\n\\t\\n\\nThe \\\"UltraTextbooks\\\" dataset is hosted on the Hugging Face platform.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nThe \\\"UltraTextbooks\\\" dataset is a comprehensive collection of high-quality synthetic and… See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/UltraTextbooks.","first_N":5,"first_N_keywords":["text-generation","English","code","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"distilabel-math-preference-dpo-de","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mayflowergmbh/distilabel-math-preference-dpo-de","creator_name":"Mayflower GmbH","creator_url":"https://huggingface.co/mayflowergmbh","description":"German azureml translation of argilla/distilabel-math-preference-dpo\\nfor dpo finetuning.\\n","first_N":5,"first_N_keywords":["text-generation","German","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"MathVision","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MathLLMs/MathVision","creator_name":"LLMs for Math Reasoning","creator_url":"https://huggingface.co/MathLLMs","description":"\\n\\t\\n\\t\\t\\n\\t\\tMeasuring Multimodal Mathematical Reasoning with the MATH-Vision Dataset\\n\\t\\n\\n[💻 Github] [🌐 Homepage]  [📊 Leaderboard ] [🔍 Visualization] [📖 ArXiv Paper]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🚀 Data Usage\\n\\t\\n\\n\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"MathLLMs/MathVision\\\")\\nprint(dataset)\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\t💥 News\\n\\t\\n\\n\\n[2025.03.10] 💥 Kimi k1.6 Preview 🥇 Sets New SOTA on MATH-V with 53.29%!See the full leaderboard.\\n[2025.02.28] 💥 Doubao-1.5-pro Sets New SOTA on MATH-V with 48.62%! Read more on the… See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathVision.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","visual-question-answering","text-generation","expert-generated"],"keywords_longer_than_N":true},
	{"name":"CriticBench","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-agents/CriticBench","creator_name":"LLM-Agents","creator_url":"https://huggingface.co/llm-agents","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nCriticBench is a comprehensive benchmark designed to assess LLMs' abilities to generate, critique/discriminate and correct reasoning across a variety of tasks. CriticBench encompasses five reasoning domains: mathematical, commonsense, symbolic, coding, and algorithmic. It compiles 15 datasets and incorporates responses from three LLM families.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: THU\\nFunded by… See the full description on the dataset page: https://huggingface.co/datasets/llm-agents/CriticBench.","first_N":5,"first_N_keywords":["question-answering","text-classification","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"orca-math-word-problems-200k","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/microsoft/orca-math-word-problems-200k","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\n\\nThis dataset contains ~200K grade school math word problems. All the answers in this dataset is generated using Azure GPT4-Turbo. Please refer to Orca-Math: Unlocking the potential of\\nSLMs in Grade School Math for details about the dataset construction. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\n\\n\\nRepository: microsoft/orca-math-word-problems-200k\\nPaper: Orca-Math: Unlocking the potential of\\nSLMs in Grade School Math\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDirect Use\\n\\t\\n\\n\\n\\nThis dataset has been… See the full description on the dataset page: https://huggingface.co/datasets/microsoft/orca-math-word-problems-200k.","first_N":5,"first_N_keywords":["question-answering","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"french_instruct","keyword":"gsm8k","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/angeluriot/french_instruct","creator_name":"Angel Uriot","creator_url":"https://huggingface.co/angeluriot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🧑‍🏫 French Instruct\\n\\t\\n\\nThe French Instruct dataset is a collection of instructions with their corresponding answers (sometimes multi-turn conversations) entirely in French. The dataset is also available on GitHub.\\n\\n    \\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📊 Overview\\n\\t\\n\\nThe dataset is composed of 276K conversations between a user and an assistant for a total of approximately 85M tokens.\\n\\n    \\n\\n\\nI also added annotations for each document to indicate if it was generated or written by a human, the… See the full description on the dataset page: https://huggingface.co/datasets/angeluriot/french_instruct.","first_N":5,"first_N_keywords":["question-answering","text2text-generation","text-generation","text-classification","token-classification"],"keywords_longer_than_N":true},
	{"name":"gsm8k-tr","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/malhajar/gsm8k-tr","creator_name":"Mohamad Alhajar","creator_url":"https://huggingface.co/malhajar","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GSM8K\\n\\t\\n\\nThis Dataset is part of a series of datasets aimed at advancing Turkish LLM Developments by establishing rigid Turkish benchmarks to evaluate the performance of LLM's Produced in the Turkish Language.\\nmalhajar/GSM8K-tr is a translated version of GSM8K aimed specifically to be used in the OpenLLMTurkishLeaderboard \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word… See the full description on the dataset page: https://huggingface.co/datasets/malhajar/gsm8k-tr.","first_N":5,"first_N_keywords":["text2text-generation","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"StackMathQA","keyword":"mathematical-reasoning","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agicorp/StackMathQA","creator_name":"agicorp","creator_url":"https://huggingface.co/agicorp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStackMathQA\\n\\t\\n\\nStackMathQA is a meticulously curated collection of 2 million mathematical questions and answers, sourced from various Stack Exchange sites. This repository is designed to serve as a comprehensive resource for researchers, educators, and enthusiasts in the field of mathematics and AI research.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tConfigs\\n\\t\\n\\nconfigs:\\n- config_name: stackmathqa1600k\\n  data_files: data/stackmathqa1600k/all.jsonl\\n  default: true\\n- config_name: stackmathqa800k\\n  data_files:… See the full description on the dataset page: https://huggingface.co/datasets/agicorp/StackMathQA.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"MATH-plus","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/MATH-plus","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"This dataset contains the MetaMath, MATH-orca and some additional MATH-augmented dataset with GPT-4. This dataset is being used to train MAmmoTH2-plus version (https://tiger-ai-lab.github.io/MAmmoTH2/).\\n","first_N":5,"first_N_keywords":["text-generation","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"MathCodeInstruct-Plus","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MathLLMs/MathCodeInstruct-Plus","creator_name":"LLMs for Math Reasoning","creator_url":"https://huggingface.co/MathLLMs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning\\n\\t\\n\\nPaper: https://arxiv.org/pdf/2310.03731.pdf\\nRepo: https://github.com/mathllm/MathCoder\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce MathCoder, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving.\\n\\n\\t\\n\\t\\t\\nBase Model: Llama-2\\nBase Model: Code Llama\\n\\n\\n\\t\\t\\nMathCoder-L-7B\\nMathCoder-CL-7B\\n\\n\\nMathCoder-L-13B\\nMathCoder-CL-34B\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTraining Data… See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathCodeInstruct-Plus.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"UniMER_Dataset","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanderkid/UniMER_Dataset","creator_name":"Bin Wang","creator_url":"https://huggingface.co/wanderkid","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUniMER Dataset\\n\\t\\n\\nFor detailed instructions on using the dataset, please refer to the project homepage: UniMERNet Homepage\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe UniMER dataset is a specialized collection curated to advance the field of Mathematical Expression Recognition (MER). It encompasses the comprehensive UniMER-1M training set, featuring over one million instances that represent a diverse and intricate range of mathematical expressions, coupled with the UniMER Test Set… See the full description on the dataset page: https://huggingface.co/datasets/wanderkid/UniMER_Dataset.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","1M<n<10M","arxiv:2404.15254"],"keywords_longer_than_N":true},
	{"name":"Maths-College","keyword":"maths","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Maths-College","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Maths-College\\nI am releasing a large Mathematics dataset in the instrution format. \\nThis extensive dataset, comprising nearly one million instructions in JSON format, encapsulates a wide array of mathematical disciplines essential for a profound understanding of the subject.\\nThis dataset is very useful to Researchers & Model developers.\\nFollowing Fields & sub Fields are covered:\\nProbability\\nStatistics\\nLiner Algebra\\nAlgebra\\nGroup Theory\\nTopology\\nAbstract Algebra\\nGraph Theory\\nCombinatorics… See the full description on the dataset page: https://huggingface.co/datasets/ajibawa-2023/Maths-College.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Maths-College","keyword":"mathematics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Maths-College","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Maths-College\\nI am releasing a large Mathematics dataset in the instrution format. \\nThis extensive dataset, comprising nearly one million instructions in JSON format, encapsulates a wide array of mathematical disciplines essential for a profound understanding of the subject.\\nThis dataset is very useful to Researchers & Model developers.\\nFollowing Fields & sub Fields are covered:\\nProbability\\nStatistics\\nLiner Algebra\\nAlgebra\\nGroup Theory\\nTopology\\nAbstract Algebra\\nGraph Theory\\nCombinatorics… See the full description on the dataset page: https://huggingface.co/datasets/ajibawa-2023/Maths-College.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Maths-College","keyword":"statistics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Maths-College","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Maths-College\\nI am releasing a large Mathematics dataset in the instrution format. \\nThis extensive dataset, comprising nearly one million instructions in JSON format, encapsulates a wide array of mathematical disciplines essential for a profound understanding of the subject.\\nThis dataset is very useful to Researchers & Model developers.\\nFollowing Fields & sub Fields are covered:\\nProbability\\nStatistics\\nLiner Algebra\\nAlgebra\\nGroup Theory\\nTopology\\nAbstract Algebra\\nGraph Theory\\nCombinatorics… See the full description on the dataset page: https://huggingface.co/datasets/ajibawa-2023/Maths-College.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Maths-College","keyword":"algebra","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Maths-College","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Maths-College\\nI am releasing a large Mathematics dataset in the instrution format. \\nThis extensive dataset, comprising nearly one million instructions in JSON format, encapsulates a wide array of mathematical disciplines essential for a profound understanding of the subject.\\nThis dataset is very useful to Researchers & Model developers.\\nFollowing Fields & sub Fields are covered:\\nProbability\\nStatistics\\nLiner Algebra\\nAlgebra\\nGroup Theory\\nTopology\\nAbstract Algebra\\nGraph Theory\\nCombinatorics… See the full description on the dataset page: https://huggingface.co/datasets/ajibawa-2023/Maths-College.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Maths-Grade-School","keyword":"maths","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Maths-Grade-School","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Maths-Grade-School\\nI am releasing large Grade School level Mathematics datatset.\\nThis extensive dataset, comprising nearly one million instructions in JSON format, encapsulates a diverse array of topics fundamental to building a strong mathematical foundation.\\nThis dataset is in instruction format so that model developers, researchers etc. can easily use this dataset.\\nFollowing Fields & sub Fields are covered:\\nCalculus\\nProbability\\nAlgebra\\nLiner Algebra\\nTrigonometry\\nDifferential Equations… See the full description on the dataset page: https://huggingface.co/datasets/ajibawa-2023/Maths-Grade-School.","first_N":5,"first_N_keywords":["text-generation","question-answering","text2text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Maths-Grade-School","keyword":"mathematics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Maths-Grade-School","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Maths-Grade-School\\nI am releasing large Grade School level Mathematics datatset.\\nThis extensive dataset, comprising nearly one million instructions in JSON format, encapsulates a diverse array of topics fundamental to building a strong mathematical foundation.\\nThis dataset is in instruction format so that model developers, researchers etc. can easily use this dataset.\\nFollowing Fields & sub Fields are covered:\\nCalculus\\nProbability\\nAlgebra\\nLiner Algebra\\nTrigonometry\\nDifferential Equations… See the full description on the dataset page: https://huggingface.co/datasets/ajibawa-2023/Maths-Grade-School.","first_N":5,"first_N_keywords":["text-generation","question-answering","text2text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Maths-Grade-School","keyword":"algebra","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Maths-Grade-School","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Maths-Grade-School\\nI am releasing large Grade School level Mathematics datatset.\\nThis extensive dataset, comprising nearly one million instructions in JSON format, encapsulates a diverse array of topics fundamental to building a strong mathematical foundation.\\nThis dataset is in instruction format so that model developers, researchers etc. can easily use this dataset.\\nFollowing Fields & sub Fields are covered:\\nCalculus\\nProbability\\nAlgebra\\nLiner Algebra\\nTrigonometry\\nDifferential Equations… See the full description on the dataset page: https://huggingface.co/datasets/ajibawa-2023/Maths-Grade-School.","first_N":5,"first_N_keywords":["text-generation","question-answering","text2text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Maths-Grade-School","keyword":"maths","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pt-sk/Maths-Grade-School","creator_name":"Sathish Kumar","creator_url":"https://huggingface.co/pt-sk","description":"Maths-Grade-School\\nI am releasing large Grade School level Mathematics datatset.\\nThis extensive dataset, comprising nearly one million instructions in JSON format, encapsulates a diverse array of topics fundamental to building a strong mathematical foundation.\\nThis dataset is in instruction format so that model developers, researchers etc. can easily use this dataset.\\nFollowing Fields & sub Fields are covered:\\nCalculus\\nProbability\\nAlgebra\\nLiner Algebra\\nTrigonometry\\nDifferential Equations… See the full description on the dataset page: https://huggingface.co/datasets/pt-sk/Maths-Grade-School.","first_N":5,"first_N_keywords":["text-generation","question-answering","text2text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Maths-Grade-School","keyword":"mathematics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pt-sk/Maths-Grade-School","creator_name":"Sathish Kumar","creator_url":"https://huggingface.co/pt-sk","description":"Maths-Grade-School\\nI am releasing large Grade School level Mathematics datatset.\\nThis extensive dataset, comprising nearly one million instructions in JSON format, encapsulates a diverse array of topics fundamental to building a strong mathematical foundation.\\nThis dataset is in instruction format so that model developers, researchers etc. can easily use this dataset.\\nFollowing Fields & sub Fields are covered:\\nCalculus\\nProbability\\nAlgebra\\nLiner Algebra\\nTrigonometry\\nDifferential Equations… See the full description on the dataset page: https://huggingface.co/datasets/pt-sk/Maths-Grade-School.","first_N":5,"first_N_keywords":["text-generation","question-answering","text2text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Maths-Grade-School","keyword":"algebra","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pt-sk/Maths-Grade-School","creator_name":"Sathish Kumar","creator_url":"https://huggingface.co/pt-sk","description":"Maths-Grade-School\\nI am releasing large Grade School level Mathematics datatset.\\nThis extensive dataset, comprising nearly one million instructions in JSON format, encapsulates a diverse array of topics fundamental to building a strong mathematical foundation.\\nThis dataset is in instruction format so that model developers, researchers etc. can easily use this dataset.\\nFollowing Fields & sub Fields are covered:\\nCalculus\\nProbability\\nAlgebra\\nLiner Algebra\\nTrigonometry\\nDifferential Equations… See the full description on the dataset page: https://huggingface.co/datasets/pt-sk/Maths-Grade-School.","first_N":5,"first_N_keywords":["text-generation","question-answering","text2text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"dart-math-hard","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hkust-nlp/dart-math-hard","creator_name":"HKUST NLP Group","creator_url":"https://huggingface.co/hkust-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🎯 DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving\\n\\t\\n\\n📝 Paper@arXiv | 🤗 Datasets&Models@HF | 🐱 Code@GitHub\\n🐦 Thread@X(Twitter) | 🐶 中文博客@知乎 | 📊 Leaderboard@PapersWithCode | 📑 BibTeX\\n\\n🔥 Excited to find our DART-Math-DSMath-7B (Prop2Diff) trained on DART-Math-Hard comparable to the AIMO winner NuminaMath-7B on CoT,\\nbut based solely on MATH & GSM8K prompt set, leaving much room to improve!\\nBesides, our DART method is also fully compatible with… See the full description on the dataset page: https://huggingface.co/datasets/hkust-nlp/dart-math-hard.","first_N":5,"first_N_keywords":["text-generation","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"BRIGHT","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xlangai/BRIGHT","creator_name":"XLang NLP Lab","creator_url":"https://huggingface.co/xlangai","description":"\\n\\t\\n\\t\\t\\n\\t\\tBRIGHT benchmark\\n\\t\\n\\nBRIGHT is the first text retrieval benchmark that requires intensive reasoning to retrieve relevant documents. \\nThe queries are collected from diverse domains (StackExchange, LeetCode, and math competitions), all sourced from realistic human data.\\nExperiments show that existing retrieval models perform poorly on BRIGHT, where the highest score is only 22.1 measured by nDCG@10.\\nBRIGHT provides a good testbed for future retrieval research in more realistic and… See the full description on the dataset page: https://huggingface.co/datasets/xlangai/BRIGHT.","first_N":5,"first_N_keywords":["text-retrieval","English","cc-by-4.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp","keyword":"mathematics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Mathematics - Geometry for k-6 kids aligned with California common core standards\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-6132024-wvrg-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"mathdial","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/eth-nlped/mathdial","creator_name":"Language, Reasoning and Education lab","creator_url":"https://huggingface.co/eth-nlped","description":"\\n\\t\\n\\t\\t\\n\\t\\tMathdial dataset\\n\\t\\n\\nhttps://arxiv.org/abs/2305.14536\\nMathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems.\\nMathDial is grounded in math word problems as well as student confusions which provide a challenging testbed for creating faithful and equitable dialogue tutoring models able to reason over complex information. Current models achieve high accuracy in solving such problems but they fail in the task of teaching.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData… See the full description on the dataset page: https://huggingface.co/datasets/eth-nlped/mathdial.","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"mathdial","keyword":"gsm8k","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/eth-nlped/mathdial","creator_name":"Language, Reasoning and Education lab","creator_url":"https://huggingface.co/eth-nlped","description":"\\n\\t\\n\\t\\t\\n\\t\\tMathdial dataset\\n\\t\\n\\nhttps://arxiv.org/abs/2305.14536\\nMathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems.\\nMathDial is grounded in math word problems as well as student confusions which provide a challenging testbed for creating faithful and equitable dialogue tutoring models able to reason over complex information. Current models achieve high accuracy in solving such problems but they fail in the task of teaching.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData… See the full description on the dataset page: https://huggingface.co/datasets/eth-nlped/mathdial.","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"BeyondX","keyword":"mathematics","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Johnson0213/BeyondX","creator_name":"Kuei-Chun Kao","creator_url":"https://huggingface.co/Johnson0213","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BeyondX\\n\\t\\n\\n\\nDataset Description\\nPaper Information\\nDataset Examples\\nLeaderboard\\nDataset Usage\\nData Downloading\\nData Format\\nData Visualization\\nData Construction\\nFormulate-and-Solve\\n\\n\\nLicense\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBeyondX is a novel algebra reasoning benchmark within multi-unknown, which addresses a limitation that existing math datasets are dominated by problems with at most two unknowns. In total, BeyondX includes 464 examples generated from 2… See the full description on the dataset page: https://huggingface.co/datasets/Johnson0213/BeyondX.","first_N":5,"first_N_keywords":["question-answering","English","cc-by-sa-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"NuminaMath-TIR","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI-MO/NuminaMath-TIR","creator_name":"Project-Numina","creator_url":"https://huggingface.co/AI-MO","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NuminaMath CoT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTool-integrated reasoning (TIR) plays a crucial role in this competition. However, collecting and annotating such data is both costly and time-consuming. To address this, we selected approximately 70k problems from the NuminaMath-CoT dataset, focusing on those with numerical outputs, most of which are integers. We then utilized a pipeline leveraging GPT-4 to generate TORA-like reasoning paths, executing the code and… See the full description on the dataset page: https://huggingface.co/datasets/AI-MO/NuminaMath-TIR.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"OlympiadBench","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hothan/OlympiadBench","creator_name":"Hothan Bega","creator_url":"https://huggingface.co/Hothan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems\\n\\t\\n\\n📖 arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nOlympiadBench is an Olympiad-level bilingual multimodal scientific benchmark, featuring 8,476 problems from Olympiad-level mathematics and physics competitions, including the Chinese college entrance exam. Each problem is detailed with expert-level annotations for step-by-step reasoning. Notably, the… See the full description on the dataset page: https://huggingface.co/datasets/Hothan/OlympiadBench.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"gsm8k-tr","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bezir/gsm8k-tr","creator_name":"Abdullah Bezir","creator_url":"https://huggingface.co/bezir","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGSM8K (Grade School Math 8K) Turkish\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nbezir/gsm8k-tr is the translated version of GSM8K (Grade School Math 8K)  which is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\\n\\nSome problems are missing, contributions are appreciated.\\nThe problems are localized to Turkish, where names… See the full description on the dataset page: https://huggingface.co/datasets/bezir/gsm8k-tr.","first_N":5,"first_N_keywords":["text2text-generation","Turkish","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"gsm8k-fix","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hkust-nlp/gsm8k-fix","creator_name":"HKUST NLP Group","creator_url":"https://huggingface.co/hkust-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGSM8K (Fixed)\\n\\t\\n\\nSome erroneous labels exist in the GSM8K dataset.\\nThis dataset is fixed from https://github.com/openai/grade-school-math/blob/master/grade_school_math/data/train.jsonl with the code appended at the end.\\nThe errors are located by delving into unreasonably low pass rates by the strong DeepSeekMath-7B-RL and hopefully should be exhaustive.\\nThis dataset is used by the 🎯DART-Math project to synthesize data.\\n\\n⚠️ Only the training set has been fixed so far.\\n\\nfor dp in… See the full description on the dataset page: https://huggingface.co/datasets/hkust-nlp/gsm8k-fix.","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"monkey_business","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ScalingIntelligence/monkey_business","creator_name":"Scaling Intelligence","creator_url":"https://huggingface.co/ScalingIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMonkey Business\\n\\t\\n\\nMonkey Business is a dataset of samples from large language models. It contains both correct and incorrect samples from a variety of models (the Llama-3, Gemma, and Pythia series) on a variety of tasks (problems from GSM8K, MATH, CodeContests, and MiniF2F-MATH). We hope that it can be useful for developing improved verification methods that assess whether a model generated answer is correct.\\nThis dataset was created as part of the project: \\\"Large Language… See the full description on the dataset page: https://huggingface.co/datasets/ScalingIntelligence/monkey_business.","first_N":5,"first_N_keywords":["monolingual","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"math-hard-calibration","keyword":"math","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/math-hard-calibration","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMath Hard Calibration\\n\\t\\n\\nThis dataset is generated from lighteval/MATH-Hard, intended for model quantization calibration.\\n","first_N":5,"first_N_keywords":["text-generation","English","gpl-3.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mgsm","keyword":"math-word-problems","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jbross-ibm-research/mgsm","creator_name":"J Bross","creator_url":"https://huggingface.co/jbross-ibm-research","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MGSM\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCopy and merge of this MGSM Dataset, Catalan version, Basque version, Galician version, but in training samples we removed the prompt formatting, e.g. removed Question: ... in question field or Answer: ... in answer field.\\nMultilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper Language models are multilingual chain-of-thought reasoners.\\nThe same 250 problems from… See the full description on the dataset page: https://huggingface.co/datasets/jbross-ibm-research/mgsm.","first_N":5,"first_N_keywords":["text2text-generation","found","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"polymath","keyword":"mathematics","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/him1411/polymath","creator_name":"Himanshu Gupta","creator_url":"https://huggingface.co/him1411","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper Information\\n\\t\\n\\nWe present PolyMATH, a challenging benchmark aimed at evaluating the general cognitive reasoning abilities of MLLMs. \\nPolyMATH comprises 5,000 manually collected high-quality images of cognitive textual and visual challenges across 10 distinct categories, including pattern recognition, spatial reasoning, and relative reasoning. \\nWe conducted a comprehensive, and quantitative evaluation of 15 MLLMs using four diverse prompting strategies, including… See the full description on the dataset page: https://huggingface.co/datasets/him1411/polymath.","first_N":5,"first_N_keywords":["multiple-choice","expert-generated","found","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"MMMU-Thai","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iapp/MMMU-Thai","creator_name":"iApp Technology","creator_url":"https://huggingface.co/iapp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU Thai (MMMU Benchmark Translated to Thai)\\n\\t\\n\\nMMMU Thai is a dataset for evaluating multimodal models on massive multi-discipline tasks requiring college-level knowledge and deliberate reasoning. This dataset is translated from MMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI) into Thai.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nMMMU Thai consists of 11,500 meticulously collected multimodal questions from college exams, quizzes, and textbooks… See the full description on the dataset page: https://huggingface.co/datasets/iapp/MMMU-Thai.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","Thai","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"24-game","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nlile/24-game","creator_name":"nathan lile","creator_url":"https://huggingface.co/nlile","description":"\\n\\t\\n\\t\\t\\n\\t\\tMath Twenty Four (24s Game) Dataset\\n\\t\\n\\nA comprehensive dataset for the classic math twenty four game (also known as the 4 numbers game / 24s game / Game of 24). This dataset of mathematical reasoning challenges was collected from 4nums.com, featuring over 1,300 unique puzzles of the Game of 24, with difficulty metrics derived from over 6.4 million human solution attempts since 2012.\\nIn each puzzle, players must use exactly four numbers and basic arithmetic operations (+, -, ×, /) to… See the full description on the dataset page: https://huggingface.co/datasets/nlile/24-game.","first_N":5,"first_N_keywords":["multiple-choice","text-generation","text2text-generation","other","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"24-game","keyword":"mathematics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nlile/24-game","creator_name":"nathan lile","creator_url":"https://huggingface.co/nlile","description":"\\n\\t\\n\\t\\t\\n\\t\\tMath Twenty Four (24s Game) Dataset\\n\\t\\n\\nA comprehensive dataset for the classic math twenty four game (also known as the 4 numbers game / 24s game / Game of 24). This dataset of mathematical reasoning challenges was collected from 4nums.com, featuring over 1,300 unique puzzles of the Game of 24, with difficulty metrics derived from over 6.4 million human solution attempts since 2012.\\nIn each puzzle, players must use exactly four numbers and basic arithmetic operations (+, -, ×, /) to… See the full description on the dataset page: https://huggingface.co/datasets/nlile/24-game.","first_N":5,"first_N_keywords":["multiple-choice","text-generation","text2text-generation","other","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"MAmmoTH-VL-Instruct-12M","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MAmmoTH-VL/MAmmoTH-VL-Instruct-12M","creator_name":"MAmmoTH-VL","creator_url":"https://huggingface.co/MAmmoTH-VL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMAmmoTH-VL-Instruct-12M\\n\\t\\n\\n🏠 Homepage | 🤖 MAmmoTH-VL-8B | 💻 Code | 📄 Arxiv | 📕 PDF | 🖥️ Demo\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nOur simple yet scalable visual instruction data rewriting pipeline consists of three steps: manual data source collection, rewriting using MLLMs/LLMs, and filtering via the same MLLM as a judge. Examples below illustrate transformations in math and science categories, showcasing detailed, step-by-step responses.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe data distribution of… See the full description on the dataset page: https://huggingface.co/datasets/MAmmoTH-VL/MAmmoTH-VL-Instruct-12M.","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"Geoperception","keyword":"mathematics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/euclid-multimodal/Geoperception","creator_name":"Euclid Multimodal LLM","creator_url":"https://huggingface.co/euclid-multimodal","description":"Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Geoperception\\n\\t\\n\\nA Benchmark for Low-level Geometric Perception\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nGeoperception is a benchmark focused specifically on accessing model's low-level visual perception ability in 2D geometry.\\nIt is sourced from the Geometry-3K corpus, which offers precise logical forms for geometric diagrams, compiled from popular… See the full description on the dataset page: https://huggingface.co/datasets/euclid-multimodal/Geoperception.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"VISCO","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/uclanlp/VISCO","creator_name":"UCLA NLP","creator_url":"https://huggingface.co/uclanlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVISCO\\n\\t\\n\\nBenchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning\\n🌐 Project | 📖 Paper | 💻 Github\\n\\n\\nOutline:\\n\\nIntroduction\\nData\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nVISCO is a benchmark for evaluating the critique and correction capabilities of LVLMs. VISCO contains:\\n\\n1645 pairs of questions and LVLM-generated answers. Each answer includes a chain-of-thought with multiple reasonign steps.\\n5604 step-wise annotations of critique, showing… See the full description on the dataset page: https://huggingface.co/datasets/uclanlp/VISCO.","first_N":5,"first_N_keywords":["visual-question-answering","English","mit","1K<n<10K","arxiv:2412.02172"],"keywords_longer_than_N":true},
	{"name":"u-math","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/toloka/u-math","creator_name":"Toloka","creator_url":"https://huggingface.co/toloka","description":"U-MATH is a comprehensive benchmark of 1,100 unpublished university-level problems sourced from real teaching materials. \\nIt is designed to evaluate the mathematical reasoning capabilities of Large Language Models (LLMs). The dataset is balanced across six core mathematical topics and includes 20% of multimodal problems (involving visual elements such as graphs and diagrams). \\nFor fine-grained performance evaluation results and detailed discussion, check out our paper.\\n\\n📊 U-MATH benchmark at… See the full description on the dataset page: https://huggingface.co/datasets/toloka/u-math.","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mu-math","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/toloka/mu-math","creator_name":"Toloka","creator_url":"https://huggingface.co/toloka","description":"μ-MATH (Meta U-MATH) is a meta-evaluation dataset derived from the U-MATH benchmark.\\nIt is intended to assess the ability of LLMs to judge free-form mathematical solutions. The dataset includes 1,084 labeled samples generated from 271 U-MATH tasks, covering problems of varying assessment complexity.\\nFor fine-grained performance evaluation results, in-depth analyses and detailed discussions on behaviors and biases of LLM judges, check out our paper.\\n\\n📊 U-MATH benchmark at Huggingface\\n🔎 μ-MATH… See the full description on the dataset page: https://huggingface.co/datasets/toloka/mu-math.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"STEM-en-ms","keyword":"mathematics","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Supa-AI/STEM-en-ms","creator_name":"Supahands","creator_url":"https://huggingface.co/Supa-AI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tA Bilingual Dataset for Evaluating Reasoning Skills in STEM Subjects\\n\\t\\n\\nThis dataset provides a comprehensive evaluation set for tasks assessing reasoning skills in Science, Technology, Engineering, and Mathematics (STEM) subjects. It features questions in both English and Malay, catering to a diverse audience.\\nKey Features\\n\\nBilingual: Questions are available in English and Malay, promoting accessibility for multilingual learners.\\nVisually Rich: Questions are accompanied by figures… See the full description on the dataset page: https://huggingface.co/datasets/Supa-AI/STEM-en-ms.","first_N":5,"first_N_keywords":["English","Malay","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"15000-Famous-People-Birth-Date-Location","keyword":"statistics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vedastro-org/15000-Famous-People-Birth-Date-Location","creator_name":"VedAstro","creator_url":"https://huggingface.co/vedastro-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🎯 Accurate Birth Date & Location of 15,000 Famous People from Earth 🌍\\n\\t\\n\\n\\nAccurate timezone (with DST correction)\\nRodden AA Rating (from birth certificate or birth record)\\nIncludes Politicians, Doctors, Authors, Singers, Actors, etc..\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📜 About\\n\\t\\n\\nThis dataset was created for research into validating principles of Vedic astrology.\\nEach birth date, location, and time zone was meticulously verified using reliable, paid API services.\\nIt is made available for FREE to… See the full description on the dataset page: https://huggingface.co/datasets/vedastro-org/15000-Famous-People-Birth-Date-Location.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"15000-Famous-People-Marriage-Divorce-Info","keyword":"statistics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vedastro-org/15000-Famous-People-Marriage-Divorce-Info","creator_name":"VedAstro","creator_url":"https://huggingface.co/vedastro-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🎯 Accurate Marriage and Divorce Info for 15,000 Famous People 🌍\\n\\t\\n\\n\\nIncludes information about marriage type, spouse, marriage/divorce dates, and outcomes.\\nHigh credibility data verified using reliable, paid API services.\\nCovers notable figures including Politicians, Authors, Singers, Actors, and more.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📜 About\\n\\t\\n\\nThis dataset was created to support research into validating principles of Vedic astrology.\\nEach record contains detailed information in a structured… See the full description on the dataset page: https://huggingface.co/datasets/vedastro-org/15000-Famous-People-Marriage-Divorce-Info.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"CodeMathGen","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lFelix/CodeMathGen","creator_name":"Fan Liu","creator_url":"https://huggingface.co/lFelix","description":"lFelix/CodeMathGen dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","text-generation","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Math-Solve","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Math-Solve","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Math-Solve dataset is a collection of math problems and their solutions, designed to facilitate training and evaluation of models for tasks such as text generation, question answering, and summarization. The dataset contains nearly 25k rows of math-related problems, each paired with a detailed solution.\\nThis dataset is particularly useful for researchers and developers working on AI models that require mathematical reasoning and problem-solving capabilities.… See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Math-Solve.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"PyThagoreans-Merged","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/PyThagoreans-Merged","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tPyThagoreans Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe PyThagoreans dataset is a comprehensive collection of math problems and their solutions, designed to assist in learning and practicing mathematical problem-solving. This dataset includes a variety of problems, expected answers, and predicted answers, making it a valuable resource for students, educators, and researchers.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tModalities\\n\\t\\n\\n\\nText: The dataset primarily contains text data, including math… See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/PyThagoreans-Merged.","first_N":5,"first_N_keywords":["question-answering","summarization","text2text-generation","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"Math-Forge-Hard","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Math-Forge-Hard","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tMath-Forge-Hard Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Math-Forge-Hard dataset is a collection of challenging math problems designed to test and improve problem-solving skills. This dataset includes a variety of word problems that cover different mathematical concepts, making it a valuable resource for students, educators, and researchers.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tModalities\\n\\t\\n\\n\\nText: The dataset primarily contains text data, including math word problems.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFormats… See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Math-Forge-Hard.","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Math-Question-Answer","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aixr/Math-Question-Answer","creator_name":"Aixr AI","creator_url":"https://huggingface.co/Aixr","description":"Aixr/Math-Question-Answer dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"numinamath_verifiable_cleaned","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/flatlander1024/numinamath_verifiable_cleaned","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Adapt from https://huggingface.co/datasets/AI-MO/NuminaMath-CoT and filtered problems with verifiable answers.\\nRemoved duplicates and decontaminated from test datasets.\\nTotal number of rows: 678759\\n","first_N":5,"first_N_keywords":["question-answering","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"math-squared","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/veds12/math-squared","creator_name":"Vedant Shah","creator_url":"https://huggingface.co/veds12","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Name\\n\\t\\n\\nMATH2\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMATH2 is a mathematical reasoning evaluation dataset curated using a human-in-the-loop approach proposed in the paper AI-Assisted Generation of Difficult Math Questions. The dataset consists of 210 questions formed by combining 2 math domain skills using frontier LLMs. These skills were extracted from the MATH [Hendrycks et al., 2021] dataset.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\n\\nPaper: AI-Assisted Generation of Difficult Math… See the full description on the dataset page: https://huggingface.co/datasets/veds12/math-squared.","first_N":5,"first_N_keywords":["question-answering","text-generation","text2text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"Grade-Math-18K","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Grade-Math-18K","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tGrade-Math-18K dataset\\n\\t\\n\\nThis dataset contains math question and answer pairs, designed for training and evaluating machine learning models in elementary and middle school math problem solving. \\nThe dataset includes text formatted in CSV and is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\nNumber of questions: 18,000\\nGrades: Elementary and Middle School\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tModalities\\n\\t\\n\\n\\nText\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFormats\\n\\t\\n\\n\\nCSV\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nEnglish\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLicense\\n\\t\\n\\nThe license for this dataset is… See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Grade-Math-18K.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Math-Solve-Singleshot","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Math-Solve-Singleshot","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tMath-Solve-Singleshot\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset, named Math-Solve-Singleshot, is designed for solving single-shot mathematical problems. It contains a variety of math problems formatted in text, suitable for training and evaluating models on mathematical reasoning tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\tModalities\\n\\t\\n\\n\\nText\\nFormats: CSV\\nSize: 1.05M rows\\nLibraries: pandas\\n\\n\\nCroissant\\nLicense: Apache-2.0\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nTrain Split: 1.05 million rows\\nProblem String Lengths:\\nLength 1: 16… See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Math-Solve-Singleshot.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"GSM8K_zh_tw","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DoggiAI/GSM8K_zh_tw","creator_name":"Doggi AI","creator_url":"https://huggingface.co/DoggiAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset\\n\\t\\n\\nGSM8K_zh_tw is a dataset for mathematical reasoning in Traditional Chinese. It is derived from the GSM8K_zh dataset by translating question-answer pairs into Traditional Chinese using OpenCC. The dataset consists of 7473 training samples and 1319 testing samples.\\nIn addition to translation, the dataset includes modifications to improve regional adaptation, such as replacing some China-specific terms with those more suitable for Traditional Chinese users. Simplified Chinese… See the full description on the dataset page: https://huggingface.co/datasets/DoggiAI/GSM8K_zh_tw.","first_N":5,"first_N_keywords":["question-answering","openai/gsm8k","Chinese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MetaMathQA-R1","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oumi-ai/MetaMathQA-R1","creator_name":"Oumi","creator_url":"https://huggingface.co/oumi-ai","description":"\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\toumi-ai/MetaMathQA-R1\\n\\t\\n\\nMetaMathQA-R1 is a text dataset designed to train Conversational Language Models with DeepSeek-R1 level reasoning.\\nPrompts were augmented from GSM8K and MATH training sets with responses directly from DeepSeek-R1.\\nMetaMathQA-R1 was used to train MiniMath-R1-1.5B, which achieves 44.4% accuracy on MMLU-Pro-Math, the highest of any model with <=1.5B parameters.\\n\\nCurated by: Oumi AI using Oumi inference on Parasail\\nLanguage(s) (NLP): English\\nLicense:… See the full description on the dataset page: https://huggingface.co/datasets/oumi-ai/MetaMathQA-R1.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"WebInstruct-CFT","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/WebInstruct-CFT","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\tWebInstruct-CFT Dataset\\n\\t\\n\\nThis dataset is introduced in our paper Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate.\\n| 🚀Project Page | 📖Paper | 🔗Github | 🤗7B Model | 🤗32B Model |\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nWebInstruct-CFT is a critique-based instruction dataset derived from WebInstruct. Unlike traditional instruction datasets that focus on correct answers, our dataset includes critiques of responses, enabling models to learn through critical… See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/WebInstruct-CFT.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"r1-reasoning-tr","keyword":"mathematics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SoAp9035/r1-reasoning-tr","creator_name":"Ahmet Burhan Kayalı","creator_url":"https://huggingface.co/SoAp9035","description":"\\n\\t\\n\\t\\t\\n\\t\\tR1 Reasoning TR\\n\\t\\n\\nThis is an R1 reasoning dataset translated into Turkish, containing conversations between users and assistants. Thanks to lightblue for the dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\tLicense\\n\\t\\n\\nThis dataset is released under the Apache 2.0 License.\\n","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Turkish","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"amc_aime_self_improving","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/camel-ai/amc_aime_self_improving","creator_name":"CAMEL-AI.org","creator_url":"https://huggingface.co/camel-ai","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"amc_aime_distilled","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/camel-ai/amc_aime_distilled","creator_name":"CAMEL-AI.org","creator_url":"https://huggingface.co/camel-ai","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"gsm8k_distilled","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/camel-ai/gsm8k_distilled","creator_name":"CAMEL-AI.org","creator_url":"https://huggingface.co/camel-ai","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"MiniF2F","keyword":"theorem-proving","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tonic/MiniF2F","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"\\n\\t\\n\\t\\t\\n\\t\\tminif2f Dataset\\n\\t\\n\\nThe minif2f dataset is a collection of mathematical problems and their formal statements, designed for formal mathematics and theorem proving tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe minif2f dataset contains mathematical problems from various sources (like AMC competitions) along with their formal statements in the Lean theorem prover format. Each example includes both informal mathematical statements and their corresponding formal… See the full description on the dataset page: https://huggingface.co/datasets/Tonic/MiniF2F.","first_N":5,"first_N_keywords":["text-generation","other","explanation-generation","language-modeling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"MiniF2F","keyword":"mathematical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tonic/MiniF2F","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"\\n\\t\\n\\t\\t\\n\\t\\tminif2f Dataset\\n\\t\\n\\nThe minif2f dataset is a collection of mathematical problems and their formal statements, designed for formal mathematics and theorem proving tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe minif2f dataset contains mathematical problems from various sources (like AMC competitions) along with their formal statements in the Lean theorem prover format. Each example includes both informal mathematical statements and their corresponding formal… See the full description on the dataset page: https://huggingface.co/datasets/Tonic/MiniF2F.","first_N":5,"first_N_keywords":["text-generation","other","explanation-generation","language-modeling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"aime2025-ru","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kristaller486/aime2025-ru","creator_name":"Kristaller486","creator_url":"https://huggingface.co/kristaller486","description":"\\n\\t\\n\\t\\t\\n\\t\\tRussian Description (English below)\\n\\t\\n\\nПереведенная версия бенчмарка AIME 2025 на русский язык. Модель-переводчик - Gemini 2.0 Pro Experimental.\\n\\n\\t\\n\\t\\t\\n\\t\\tEnglish Description\\n\\t\\n\\nTranslated version of AIME 2025 into Russian. Model-translator - Gemini 2.0 Pro Experimental.\\n\\n\\t\\n\\t\\t\\n\\t\\tLeaderboard\\n\\t\\n\\n\\n","first_N":5,"first_N_keywords":["text-generation","Russian","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Persian-Math-SFT","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xmanii/Persian-Math-SFT","creator_name":"mani mirzaei","creator_url":"https://huggingface.co/xmanii","description":"\\n\\t\\n\\t\\t\\n\\t\\t🎯 Persian Math Questions Dataset for SFT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t📝 Description\\n\\t\\n\\nThis dataset contains Persian questions primarily focused on mathematical concepts, designed for Supervised Fine-Tuning (SFT) of Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\t🔍 Features\\n\\t\\n\\n\\nHigh-quality Persian questions\\nDetailed subtopic categorization\\nFocused on mathematical concepts\\nTokens count for each conversation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t🚀 Coming Soon\\n\\t\\n\\n\\nDetailed answers for each question\\nAdditional topics beyond mathematics\\nEnhanced… See the full description on the dataset page: https://huggingface.co/datasets/xmanii/Persian-Math-SFT.","first_N":5,"first_N_keywords":["text-generation","Persian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"SciCode","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SciCode1/SciCode","creator_name":"SciCode","creator_url":"https://huggingface.co/SciCode1","description":"This dataset was presented in SciCode: A Research Coding Benchmark Curated by Scientists.\\n","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"OpenReasonerZero","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tonic/OpenReasonerZero","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-Reasoner-Zero Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Open-Reasoner-Zero dataset is a carefully curated collection of reasoning tasks designed to enhance the problem-solving capabilities of language models. It is optimized for scalable Reasoner-Zero training by focusing on three key aspects: quantity, diversity, and quality. The dataset comprises approximately 57,000 samples spanning STEM, mathematics, and reasoning domains.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nFeature\\nCount\\n\\n\\n\\t\\t\\nTotal… See the full description on the dataset page: https://huggingface.co/datasets/Tonic/OpenReasonerZero.","first_N":5,"first_N_keywords":["question-answering","fill-mask","text2text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"OpenReasonerZero","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tonic/OpenReasonerZero","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-Reasoner-Zero Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Open-Reasoner-Zero dataset is a carefully curated collection of reasoning tasks designed to enhance the problem-solving capabilities of language models. It is optimized for scalable Reasoner-Zero training by focusing on three key aspects: quantity, diversity, and quality. The dataset comprises approximately 57,000 samples spanning STEM, mathematics, and reasoning domains.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nFeature\\nCount\\n\\n\\n\\t\\t\\nTotal… See the full description on the dataset page: https://huggingface.co/datasets/Tonic/OpenReasonerZero.","first_N":5,"first_N_keywords":["question-answering","fill-mask","text2text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"OpenThoughts-TR-18k","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/selimc/OpenThoughts-TR-18k","creator_name":"selim","creator_url":"https://huggingface.co/selimc","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpenThoughts-TR-18k: Turkish Synthetic Reasoning Dataset\\n\\t\\n\\nOpenThoughts-TR-18k is a Turkish translation of a subset of the original Open-Thoughts-114k dataset. It contains ~18k high-quality synthetic reasoning examples covering mathematics, science, coding problems, and puzzles, all translated into Turkish. This dataset is designed to support reasoning task fine tuning for Turkish language models.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n~18k translated reasoning examples\\nCovers multiple domains:… See the full description on the dataset page: https://huggingface.co/datasets/selimc/OpenThoughts-TR-18k.","first_N":5,"first_N_keywords":["Turkish","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"HoT_User_Study_Data","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/groundingauburn/HoT_User_Study_Data","creator_name":"grounding_auburn","creator_url":"https://huggingface.co/groundingauburn","description":"\\n\\t\\n\\t\\t\\n\\t\\t📚 Fact-Enhanced Math Problem Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains mathematical reasoning problems where key facts are highlighted using fact tags (e.g., <fact1>, <fact2>). The dataset is designed for training and evaluating explainable AI (XAI) models, especially in fact-referencing reasoning tasks.\\nEach question and answer pair follows a structured format where supporting facts are explicitly referenced to improve transparency in mathematical problem-solving.… See the full description on the dataset page: https://huggingface.co/datasets/groundingauburn/HoT_User_Study_Data.","first_N":5,"first_N_keywords":["English","mit","< 1K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"kolmogorov-3","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/attn-signs/kolmogorov-3","creator_name":"Attention Signs","creator_url":"https://huggingface.co/attn-signs","description":"\\n\\t\\n\\t\\t\\n\\t\\tKolmogorov-3\\n\\t\\n\\nCarefully selected, checked and formatted PhD-level russian math instruction dataset.Contains olympiad/university/science-level tasks from various sources.\\n\\n\\t\\n\\t\\t\\n\\t\\tContents:\\n\\t\\n\\nMathematics\\n\\nPre-algebra\\nPre-calculus\\nCalculus\\nAlgebra\\nNumber theory\\nGeometry\\nProbability theory\\nSet theory\\nMathematical proofs\\n\\nCode\\n\\nCode-to-math problems\\nAlgorithms\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFormats:\\n\\t\\n\\nDataset is formatted in conversation manner, can be also used for GRPO problem-answer training\\n","first_N":5,"first_N_keywords":["question-answering","Russian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"unarXive_imrad_clf","keyword":"mathematics","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saier/unarXive_imrad_clf","creator_name":"Tarek Saier","creator_url":"https://huggingface.co/saier","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for unarXive IMRaD classification\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe unarXive IMRaD classification dataset contains 530k paragraphs from computer science papers and the IMRaD section they originate from. The paragraphs are derived from unarXive.\\nThe dataset can be used as follows.\\nfrom datasets import load_dataset\\n\\nimrad_data = load_dataset('saier/unarXive_imrad_clf')\\nimrad_data = imrad_data.class_encode_column('label')  # assign target label column\\nimrad_data =… See the full description on the dataset page: https://huggingface.co/datasets/saier/unarXive_imrad_clf.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"unarXive_citrec","keyword":"mathematics","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saier/unarXive_citrec","creator_name":"Tarek Saier","creator_url":"https://huggingface.co/saier","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for unarXive citation recommendation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe unarXive citation recommendation dataset contains 2.5 Million paragraphs from computer science papers and with an annotated citation marker. The paragraphs and citation information is derived from unarXive.\\nNote that citation infromation is only given as the OpenAlex ID of the cited paper. An important consideration for models is therefore if the data is used as is, or if additional information… See the full description on the dataset page: https://huggingface.co/datasets/saier/unarXive_citrec.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"oaCamel","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/checkai/oaCamel","creator_name":"Lucas Barker","creator_url":"https://huggingface.co/checkai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for oaCamel\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is the chemistry, biology, math, and physics datasets created by CAMEL ai. https://huggingface.co/camel-ai\\nThey have been combined and converted to the Open Assistant format.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThis dataset follows the OA format, which is:\\n\\nINSTRUCTION (string): Instruction text\\nRESPONSE (string): Expected response to the instruction\\nSOURCE (string): Original data… See the full description on the dataset page: https://huggingface.co/datasets/checkai/oaCamel.","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"reasoning-gsm-qna-oa","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/0x22almostEvil/reasoning-gsm-qna-oa","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GSM QnA reasoning with ~8.8K entries.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nContains Parquet of a list of instructions and answers.\\nEach row consists of\\n\\nINSTRUCTION\\nRESPONSE\\nSOURCE\\nMETADATA (json with language).\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOriginal Datasets are available here:\\n\\t\\n\\n\\nhttps://huggingface.co/datasets/gsm8k\\nhttps://huggingface.co/datasets/reasoning-machines/gsm-hard\\n\\n","first_N":5,"first_N_keywords":["question-answering","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"atlas-math-sets","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AtlasUnified/atlas-math-sets","creator_name":"Atlas Unified","creator_url":"https://huggingface.co/AtlasUnified","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tATLAS MATH SETS\\n\\t\\n\\n\\nThis set of data consists of mathematical computations. Simple in nature as it derived from python scripts, this dataset contains addition, subtraction, multiplication, division, fractions, decimals, square roots, cube roots, exponents, and factors.\\nFormat of the JSONL is as follows:\\n{\\\"answer\\\": \\\"[num]\\\", \\\"input\\\": \\\"[equation]\\\", \\\"output\\\": \\\"[num]\\\", \\\"instruction\\\": \\\"[pre-generated_instruction] [equation]\\\"}\\n","first_N":5,"first_N_keywords":["question-answering","English","mit","10M - 100M","json"],"keywords_longer_than_N":true},
	{"name":"cmath","keyword":"mathematics","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/weitianwen/cmath","creator_name":"Wei Tianwen","creator_url":"https://huggingface.co/weitianwen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCMATH\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe present the Chinese Elementary School Math Word Problems (CMATH) dataset, comprising 1.7k elementary school-level math word problems with detailed annotations, source from actual Chinese workbooks and exams. This dataset aims to provide a benchmark tool for assessing the following question: to what grade level of elementary school math do the abilities of popular large language models (LLMs) correspond? We evaluate a variety of popular LLMs… See the full description on the dataset page: https://huggingface.co/datasets/weitianwen/cmath.","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","1K - 10K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"Calc-svamp","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MU-NLPC/Calc-svamp","creator_name":"NLP Centre, Faculty of Informatics, Masaryk University","creator_url":"https://huggingface.co/MU-NLPC","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Calc-SVAMP\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nThe dataset is a collection of simple math word problems focused on arithmetics. It is derived from https://github.com/arkilpatel/SVAMP/.\\nThe main addition in this dataset variant is the chain column. It was created by converting the solution to a simple html-like language that can be easily\\nparsed (e.g. by BeautifulSoup). The data contains 3 types of tags:\\n\\ngadget: A tag whose content is intended to be evaluated by calling an external… See the full description on the dataset page: https://huggingface.co/datasets/MU-NLPC/Calc-svamp.","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Calc-mawps","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MU-NLPC/Calc-mawps","creator_name":"NLP Centre, Faculty of Informatics, Masaryk University","creator_url":"https://huggingface.co/MU-NLPC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Calc-MAWPS\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThe dataset is a collection of simple math word problems focused on arithmetics. It is derived from https://huggingface.co/datasets/omarxadel/MaWPS-ar.\\nThe main addition in this dataset variant is the chain column. It was created by converting the solution to a simple html-like language that can be easily\\nparsed (e.g. by BeautifulSoup). The data contains 3 types of tags:\\n\\ngadget: A tag whose content is intended to be evaluated… See the full description on the dataset page: https://huggingface.co/datasets/MU-NLPC/Calc-mawps.","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Verified-Camel","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/Verified-Camel","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Verified Camel dataset. Just over 100 verified examples, and many more coming soon!\\n\\t\\n\\n\\nComprised of over 100 highly filtered and curated examples from specific portions of CamelAI stem datasets. \\n\\nThese examples are verified to be true by experts in the specific related field, with atleast a bachelors degree in the subject.\\n\\nRoughly 30-40% of the originally curated data from CamelAI was found to have atleast minor errors and/or incoherent questions(as… See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Verified-Camel.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Arithmo-Data","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akjindal53244/Arithmo-Data","creator_name":"Ashvini Kumar Jindal","creator_url":"https://huggingface.co/akjindal53244","description":"Arithmo dataset is prepared as combination of MetaMathQA, MathInstruct, and lila ood. Refer to Model Training Data section in Arithmo-Mistral-7B project GitHub page for more details.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupport My Work\\n\\t\\n\\nBuilding LLMs takes time and resources; if you find my work interesting, your support would be epic!\\n\\nReferences\\n\\n@article{yu2023metamath,\\n  title={MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models},\\n  author={Yu, Longhui and Jiang, Weisen and Shi, Han and… See the full description on the dataset page: https://huggingface.co/datasets/akjindal53244/Arithmo-Data.","first_N":5,"first_N_keywords":["apache-2.0","100K - 1M","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"lumos_unified_plan_iterative","keyword":"maths","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai2lumos/lumos_unified_plan_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🪄 Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  🌐[Website]  \\n  📝[Paper]  \\n  🤗[Data]  \\n  🤗[Model]  \\n  🤗[Demo]  \\n\\n\\nWe introduce 🪄Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\n🧩 Modular Architecture:\\n🧩 Lumos consists of planning… See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_unified_plan_iterative.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"lumos_unified_ground_iterative","keyword":"maths","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai2lumos/lumos_unified_ground_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🪄 Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  🌐[Website]  \\n  📝[Paper]  \\n  🤗[Data]  \\n  🤗[Model]  \\n  🤗[Demo]  \\n\\n\\nWe introduce 🪄Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\n🧩 Modular Architecture:\\n🧩 Lumos consists of planning… See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_unified_ground_iterative.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"lumos_maths_ground_iterative","keyword":"maths","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai2lumos/lumos_maths_ground_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🪄 Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  🌐[Website]  \\n  📝[Paper]  \\n  🤗[Data]  \\n  🤗[Model]  \\n  🤗[Demo]  \\n\\n\\nWe introduce 🪄Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\n🧩 Modular Architecture:\\n🧩 Lumos consists of planning… See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_maths_ground_iterative.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"lumos_maths_plan_iterative","keyword":"maths","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai2lumos/lumos_maths_plan_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🪄 Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  🌐[Website]  \\n  📝[Paper]  \\n  🤗[Data]  \\n  🤗[Model]  \\n  🤗[Demo]  \\n\\n\\nWe introduce 🪄Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\n🧩 Modular Architecture:\\n🧩 Lumos consists of planning… See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_maths_plan_iterative.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"lumos_maths_ground_onetime","keyword":"maths","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai2lumos/lumos_maths_ground_onetime","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🪄 Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  🌐[Website]  \\n  📝[Paper]  \\n  🤗[Data]  \\n  🤗[Model]  \\n  🤗[Demo]  \\n\\n\\nWe introduce 🪄Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\n🧩 Modular Architecture:\\n🧩 Lumos consists of planning… See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_maths_ground_onetime.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"lumos_maths_plan_onetime","keyword":"maths","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai2lumos/lumos_maths_plan_onetime","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🪄 Agent Lumos: Unified and Modular Training for Open-Source Language Agents\\n\\t\\n\\n\\n  🌐[Website]  \\n  📝[Paper]  \\n  🤗[Data]  \\n  🤗[Model]  \\n  🤗[Demo]  \\n\\n\\nWe introduce 🪄Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \\nLumos has following features:\\n\\n🧩 Modular Architecture:\\n🧩 Lumos consists of planning… See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_maths_plan_onetime.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"minimath","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cxllin/minimath","creator_name":"Collin Heenan","creator_url":"https://huggingface.co/cxllin","description":"Condensed version of the meta-math dataset \\narxiv.org/abs/2309.12284\\nView the project page:\\nhttps://meta-math.github.io/\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{yu2023metamath,\\n  title={MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models},\\n  author={Yu, Longhui and Jiang, Weisen and Shi, Han and Yu, Jincheng and Liu, Zhengying and Zhang, Yu and Kwok, James T and Li, Zhenguo and Weller, Adrian and Liu, Weiyang},\\n  journal={arXiv preprint arXiv:2309.12284},\\n  year={2023}\\n}\\n\\n","first_N":5,"first_N_keywords":["mit","10K - 100K","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"Verified-Camel-KO","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuotient/Verified-Camel-KO","creator_name":"Jisoo Kim","creator_url":"https://huggingface.co/kuotient","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVerified-Camel-KO\\n\\t\\n\\n이 데이터셋은 https://huggingface.co/datasets/LDJnr/Verified-Camel 의 한국어 번역입니다.\\nGPT4 Turbo로 번역한 뒤, 약간의 수정을 거쳤습니다.\\n이 데이터에 대한 방침은 전부 원 저자의 방침을 따릅니다.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Verified Camel dataset. Just over 100 verified examples, and many more coming soon!\\n\\t\\n\\n\\nComprised of over 100 highly filtered and curated examples from specific portions of CamelAI stem datasets. \\n\\nThese examples are verified to be true by experts in the specific related field, with atleast… See the full description on the dataset page: https://huggingface.co/datasets/kuotient/Verified-Camel-KO.","first_N":5,"first_N_keywords":["question-answering","text-generation","Korean","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MATH_1GRADE","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mito0o852/MATH_1GRADE","creator_name":"Moustapha","creator_url":"https://huggingface.co/mito0o852","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"MATH_1GRADE\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1st Grade Math Problems Dataset\\n\\t\\n\\nThis dataset, available on Hugging Face, offers a unique collection of math problems tailored for first-grade students. The problems have been synthetically generated using Python scripts and are designed to challenge and enhance the mathematical skills of young learners in an engaging and accessible way. This README provides an overview of the dataset, including its structure, contents, and how to use… See the full description on the dataset page: https://huggingface.co/datasets/mito0o852/MATH_1GRADE.","first_N":5,"first_N_keywords":["apache-2.0","1M - 10M","parquet","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"manimation","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mediciresearch/manimation","creator_name":"Medici Research","creator_url":"https://huggingface.co/mediciresearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMedici Animation Instruct Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSmall instruct dataset for animation generation with ManimCE\\n\\t\\n\\n","first_N":5,"first_N_keywords":["text-generation","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Verified-Camel-zh","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/noobmaster29/Verified-Camel-zh","creator_name":"Victor Sung","creator_url":"https://huggingface.co/noobmaster29","description":"This is a direct Chinese translation using GPT4 of the Verified-Camel dataset. I hope you find it useful. \\nhttps://huggingface.co/datasets/LDJnr/Verified-Camel\\nCitation:\\n@article{daniele2023amplify-instruct,\\n  title={Amplify-Instruct: Synthetically Generated Diverse Multi-turn Conversations for Effecient LLM Training.},\\n  author={Daniele, Luigi and Suphavadeeprasit},\\n  journal={arXiv preprint arXiv:(comming soon)},\\n  year={2023}\\n}\\n\\n","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ibl-math","keyword":"mathematics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iblai/ibl-math","creator_name":"ibl.ai","creator_url":"https://huggingface.co/iblai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tibl-math\\n\\t\\n\\nThis dataset holds a collection of sample math problems and solution for multiple different topics in math.\\nThe dataset is intended to be used to test math applications on the correctness of their generated output.\\nFor ease of use and ability to render and preserve mathematical symbols, the solutions and questions are in latex format.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneration\\n\\t\\n\\nThe dataset is generated using gpt-4. Each datapoint is generated in the following steps\\n\\nA topic is passed to… See the full description on the dataset page: https://huggingface.co/datasets/iblai/ibl-math.","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"vi_math_problem_crawl","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hllj/vi_math_problem_crawl","creator_name":"Bui Van Hop","creator_url":"https://huggingface.co/hllj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Vietnamese Elementary Math Knowledge and Workbook\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe data includes information about elementary school math knowledge in Vietnam, as well as exercises compiled from books. This is a crawlable dataset that can be trained for text generation tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe majority of the data is in Vietnamese, but there is still some English from some bilingual workbooks.… See the full description on the dataset page: https://huggingface.co/datasets/hllj/vi_math_problem_crawl.","first_N":5,"first_N_keywords":["text-generation","Vietnamese","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"vi_grade_school_math_mcq","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hllj/vi_grade_school_math_mcq","creator_name":"Bui Van Hop","creator_url":"https://huggingface.co/hllj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Vietnamese Grade School Math Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset includes multiple-choice math exercises for elementary school students from grades 1 to 5 in Vietnam.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe majority of the data is in Vietnamese.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe data includes information about the page paths we crawled and some text that has been post-processed.… See the full description on the dataset page: https://huggingface.co/datasets/hllj/vi_grade_school_math_mcq.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","multiple-choice","Vietnamese","mit"],"keywords_longer_than_N":true},
	{"name":"Capybara-Converted","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cfahlgren1/Capybara-Converted","creator_name":"Caleb Fahlgren","creator_url":"https://huggingface.co/cfahlgren1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Capybara dataset. Over 10,000 multi-turn examples.\\n\\t\\n\\nCapybara is the culmination of insights derived from synthesis techniques like Evol-instruct (used for WizardLM), Alpaca, Orca, Vicuna, Lamini, FLASK and others.\\nThe single-turn seeds used to intiate the Amplify-Instruct synthesis of conversations are mostly based on datasets that i've personally vetted extensively, and are often highly regarded for their diversity and demonstration of logical robustness and… See the full description on the dataset page: https://huggingface.co/datasets/cfahlgren1/Capybara-Converted.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"capybara-sharegpt","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Doctor-Shotgun/capybara-sharegpt","creator_name":"Doctor Shotgun","creator_url":"https://huggingface.co/Doctor-Shotgun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcapybara-sharegpt\\n\\t\\n\\nLDJnr/Capybara converted to ShareGPT format for use in common training repositories.\\nPlease refer to the original repository's dataset card for more information. All credit goes to the original creator.\\n","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MMMU","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aslessor/MMMU","creator_name":"Alex","creator_url":"https://huggingface.co/aslessor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI)\\n\\t\\n\\n🌐 Homepage | 🤗 Dataset | 🤗 Paper | 📖 arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🔔News\\n\\t\\n\\n\\n🔥[2023-12-04]: Our evaluation server for test set is now availble on EvalAI. We welcome all submissions and look forward to your participation! 😆\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe introduce MMMU: a new benchmark designed to evaluate multimodal models on massive… See the full description on the dataset page: https://huggingface.co/datasets/aslessor/MMMU.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"rejection_sampling_phi_2_OA_rm","keyword":"gsm8k","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alizeepace/rejection_sampling_phi_2_OA_rm","creator_name":"Alizée Pace","creator_url":"https://huggingface.co/alizeepace","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Rejection Sampling Phi-2 with OpenAssistant RM\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Rejection Sampling Phi-2 with OpenAssistant RM\\\" dataset consists of 10 pairs of prompts and responses, which were generated using rejection sampling over 10 Phi-2 generation using the OpenAssistant Reward Model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset and its creation rationale could be used to support models for question-answering, text-generation, or… See the full description on the dataset page: https://huggingface.co/datasets/alizeepace/rejection_sampling_phi_2_OA_rm.","first_N":5,"first_N_keywords":["question-answering","text-generation","machine-generated","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"MATH-500-Overall","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fluently-sets/MATH-500-Overall","creator_name":"Fluently Datasets","creator_url":"https://huggingface.co/fluently-sets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMATH-500-Overall\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout the dataset\\n\\t\\n\\nThis dataset of only 500 examples combines mathematics, physics and logic in English with reasoning and step-by-step problem solving, the dataset was created synthetically, CoT of Qwen2.5-72B-Instruct and Llama3.3-70B-Instruct.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBrief information\\n\\t\\n\\n\\nNumber of rows: 500\\nType of dataset files: parquet\\nType of dataset: text, alpaca with system prompts\\nLanguage: English\\nLicense: MIT\\n\\nStructure:\\nmath¯¯¯¯¯⌉\\n   school-level… See the full description on the dataset page: https://huggingface.co/datasets/fluently-sets/MATH-500-Overall.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","text-classification","question-answering","English"],"keywords_longer_than_N":true},
	{"name":"Olympiads","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Olympiads","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 32926\\nFiltered size: 32926\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word… See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Olympiads","keyword":"mathematical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Olympiads","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 32926\\nFiltered size: 32926\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word… See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Olympiads","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Olympiads","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 32926\\nFiltered size: 32926\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word… See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Numina","keyword":"mathematics","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Numina","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 210350\\nFiltered size: 210350\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word… See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Numina.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Numina","keyword":"mathematical-reasoning","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Numina","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 210350\\nFiltered size: 210350\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word… See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Numina.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Numina","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Numina","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 210350\\nFiltered size: 210350\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word… See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Numina.","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"synmath-1-dsv3-87k","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Gusarich/synmath-1-dsv3-87k","creator_name":"Daniil Sedov","creator_url":"https://huggingface.co/Gusarich","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsynmath-1-dsv3-87k\\n\\t\\n\\nsynmath-1-dsv3-87k is a dataset consisting of 86,700 math problems and their corresponding solutions, formatted in a chain-of-thought manner. The problems span 867 distinct mathematical domains, providing diverse and comprehensive coverage for fine-tuning smaller models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nsynmath-1-dsv3-87k contains synthetically generated math problems and step-by-step solutions designed to enhance mathematical… See the full description on the dataset page: https://huggingface.co/datasets/Gusarich/synmath-1-dsv3-87k.","first_N":5,"first_N_keywords":["text2text-generation","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"step_sft","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xiaodongguaAIGC/step_sft","creator_name":"xiaodongguaAIGC","creator_url":"https://huggingface.co/xiaodongguaAIGC","description":"Mix:\\n\\n\\t\\n\\t\\t\\n数据集名称\\n是否有step\\n可用于PRM训练\\n标签形式\\nTitle\\n备注\\n\\n\\n\\t\\t\\nGSM8K\\n✅\\n❌\\n答案\\nTraining Verifiers to Solve Math Word Problems\\n\\n\\n\\nMATH\\n❌\\n❌\\n答案\\nMeasuring Mathematical Problem Solving With the MATH Dataset\\nNon-Step\\n\\n\\nPRM800K\\n✅\\n✅\\n正确类别\\nLet's Verify Step by Step\\nprompt deduplication\\n\\n\\nMath-Shepherd\\n✅\\n✅\\n正确类别\\nMath-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations\\nNot used\\n\\n\\nProcessBench\\n✅\\n✅\\n首个错误步骤\\nProcessBench: Identifying Process Errors in Mathematical Reasoning\\nonly label -1\\n\\n\\n\\t\\n\\n","first_N":5,"first_N_keywords":["text-generation","text-classification","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"Lean4-Changelog-QA","keyword":"theorem-proving","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Lean4-Changelog-QA","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLean 4 Changelog Q&A Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Lean 4 Changelog Q&A Dataset is derived from the Lean4-Changelog. Each Lean 4 changelog entry (including version, section, pull request number, and description) is converted into a single Q&A pair. This allows for straightforward question-answering tasks reflecting the evolution of Lean 4 features, bug fixes, and language decisions over time.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nEach record contains the following… See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-Changelog-QA.","first_N":5,"first_N_keywords":["question-answering","text-generation","other","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"that-one-google-math-dataset","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/metapoiesis/that-one-google-math-dataset","creator_name":"EVE","creator_url":"https://huggingface.co/metapoiesis","description":"apolocheese for poor format, it's because I Don't Care (i'm tired and still working)\\ndata from: https://github.com/google-deepmind/mathematics_dataset\\nfrom huggingface_hub import snapshot_download\\nfrom datasets import load_dataset\\nimport os\\n\\ndef get_all_files(directory):\\n    file_paths = []\\n    for root, dirs, files in os.walk(directory):\\n        for name in files:\\n            full_path = os.path.join(root, name)\\n            file_paths.append(os.path.abspath(full_path))\\n    return file_paths… See the full description on the dataset page: https://huggingface.co/datasets/metapoiesis/that-one-google-math-dataset.","first_N":5,"first_N_keywords":["English","apache-2.0","10M - 100M","json","Text"],"keywords_longer_than_N":true},
	{"name":"mathlib_handler_benchmark_410","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ruc-ai4math/mathlib_handler_benchmark_410","creator_name":"ruc-ai4math","creator_url":"https://huggingface.co/ruc-ai4math","description":"This dataset is used in the paper Assisting Mathematical Formalization with A Learning-based Premise Retriever.  It contains data for training and evaluating a premise retriever for the Lean theorem prover.\\nThe dataset is described in detail in the GitHub repository.  It consists of proof states and corresponding premises from the Mathlib library.  The data is designed to train a model to effectively retrieve relevant premises for a given proof state, assisting users in the mathematical… See the full description on the dataset page: https://huggingface.co/datasets/ruc-ai4math/mathlib_handler_benchmark_410.","first_N":5,"first_N_keywords":["question-answering","apache-2.0","Text","arxiv:2501.13959","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"ugmathbench","keyword":"math","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UGMathBench/ugmathbench","creator_name":"UGMathBench","creator_url":"https://huggingface.co/UGMathBench","description":"\\n\\t\\n\\t\\t\\n\\t\\tUGMathBench: A Diverse and Dynamic Benchmark for Undergraduate-Level Mathematical Reasoning with Large Language Models\\n\\t\\n\\nUGMathBench is a diverse and dynamic benchmark specifically designed for evaluating undergraduate-level mathematical reasoning with LLMs. \\nUGMathBench comprises 5,062 problems across 16 subjects and 111 topics, featuring 10 distinct answer types.\\nEach problem includes three randomized versions.\\nPaper: https://huggingface.co/papers/2501.13766\\nGitHub page:… See the full description on the dataset page: https://huggingface.co/datasets/UGMathBench/ugmathbench.","first_N":5,"first_N_keywords":["question-answering","English","gpl-3.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"camel_LongCoT","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tofu0142/camel_LongCoT","creator_name":"Zhang","creator_url":"https://huggingface.co/Tofu0142","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"countdown-numbers-6-gr","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/alexjackson17/countdown-numbers-6-gr","creator_name":"Alex Jackson","creator_url":"https://huggingface.co/alexjackson17","description":"\\n\\t\\n\\t\\t\\n\\t\\tCountdown Numbers Game Dataset\\n\\t\\n\\nThis dataset contains configurations and solutions for variations of the Countdown numbers game. Each example comprises a sequence of numbers, a target number, the computed solution (closest value), the arithmetic expression that achieves that value, the difference between the target and the computed value, and the final Countdown score.\\n\\n\\t\\n\\t\\t\\n\\t\\tHuggingFace Download Links\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\nDataset Variant\\nDataset Name\\nDownload\\n\\n\\n\\t\\t\\nRandom… See the full description on the dataset page: https://huggingface.co/datasets/alexjackson17/countdown-numbers-6-gr.","first_N":5,"first_N_keywords":["mit","100K - 1M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-Math-QA-2m","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Math-QA-2m","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","description":"\\n\\t\\n\\t\\t\\n\\t\\tGammaCorpus: Math QA 2m\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is it?\\n\\t\\n\\nGammaCorpus Math QA 2m is a dataset that consists of 2,760,000 mathematical question-and-answer. It consists of 917,196 addition questions, 916,662 subtraction questions, 917,015 multiplication questions, and 9,126 division questions.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nNumber of Rows: 2,760,000\\nFormat: JSONL\\nData Type: Mathematical Question Pairs\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe dataset is formatted in JSONL, where… See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Math-QA-2m.","first_N":5,"first_N_keywords":["text-generation","question-answering","apache-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"task2_advanced","keyword":"statistics","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litlsun/task2_advanced","creator_name":"Ekaterina","creator_url":"https://huggingface.co/litlsun","description":"\\n\\t\\n\\t\\t\\n\\t\\tЗадача 2: Разметка датасета с HF Datasets: статистический анализ и визуализация\\n\\t\\n\\nРазметка представленного датасета выполнена в рамках курса по компьютерной лингвистике НИУ ВШЭ (СПб).\\n\\n\\t\\n\\t\\t\\n\\t\\tПРОВЕДЕННЫЙ АНАЛИЗ\\n\\t\\n\\nБыл пороведен статистический анализ текста, включающий:\\n\\nАнализ уникальности данных\\nДоля уникальных слов: 0.0032\\n\\nЧастотный анализ биграмм и триграмм\\n\\n\\n\\n\\n\\nАнализ распределений: Длины предложений, слов и n-грамм\\n\\nСредняя длина предложения: 15.82\\nСтандартное отклонение длины… See the full description on the dataset page: https://huggingface.co/datasets/litlsun/task2_advanced.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"gsm8k-hindi","keyword":"math-word-problems","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bingbangboom/gsm8k-hindi","creator_name":"Ding","creator_url":"https://huggingface.co/bingbangboom","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for GSM8K-Hindi\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a machine-translated hindi version of the popular GSM8K dataset from OpenAI. GSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\\n\\nThese problems take between 2 and 8 steps to solve.\\nSolutions primarily involve performing a… See the full description on the dataset page: https://huggingface.co/datasets/bingbangboom/gsm8k-hindi.","first_N":5,"first_N_keywords":["text2text-generation","Hindi","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"NuminaMath-CoT","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oieieio/NuminaMath-CoT","creator_name":"Jorge Alonso","creator_url":"https://huggingface.co/oieieio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for NuminaMath CoT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nApproximately 860k math problems, where each solution is formatted in a Chain of Thought (CoT) manner. The sources of the dataset range from Chinese high school math exercises to US and international mathematics olympiad competition problems. The data were primarily collected from online exam paper PDFs and mathematics discussion forums. The processing steps include (a) OCR from the original PDFs, (b) segmentation into… See the full description on the dataset page: https://huggingface.co/datasets/oieieio/NuminaMath-CoT.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"NuminaMath-TIR","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oieieio/NuminaMath-TIR","creator_name":"Jorge Alonso","creator_url":"https://huggingface.co/oieieio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for NuminaMath CoT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTool-integrated reasoning (TIR) plays a crucial role in this competition. However, collecting and annotating such data is both costly and time-consuming. To address this, we selected approximately 70k problems from the NuminaMath-CoT dataset, focusing on those with numerical outputs, most of which are integers. We then utilized a pipeline leveraging GPT-4 to generate TORA-like reasoning paths, executing the code and… See the full description on the dataset page: https://huggingface.co/datasets/oieieio/NuminaMath-TIR.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"OCTAL-Math-CoT-47k","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qingy2024/OCTAL-Math-CoT-47k","creator_name":"Qingyun Li","creator_url":"https://huggingface.co/qingy2024","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOptimizing Chain of Thought for Adaptable LLMs\\n\\t\\n\\nOCTAL has high quality math chain-of-thought (CoT) data for LLM fine-tuning. It contains more discrete reasoning steps and logic than the original dataset, NuminaMathCoT.\\nReasoning based on QwQ 32B Preview, reformatting and cleaning based on Llama 3.1 70B Instruct. All answers cross-checked.\\n","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"subtractionerror","keyword":"maths","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TinaAbt/subtractionerror","creator_name":"Tina Abt","creator_url":"https://huggingface.co/TinaAbt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Subtractionerror\\n\\t\\n\\nThis dataset mimics a primary student that has troubles with substracting over the tens.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset mimics a primary student that has troubles with substracting over the tens.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe data is a json file with questions and answers\\n","first_N":5,"first_N_keywords":["question-answering","German","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"step_prm","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xiaodongguaAIGC/step_prm","creator_name":"xiaodongguaAIGC","creator_url":"https://huggingface.co/xiaodongguaAIGC","description":"\\n\\t\\n\\t\\t\\n数据集名称\\n是否有step\\n可用于PRM训练\\n标签形式\\nTitle\\n备注\\n\\n\\n\\t\\t\\nGSM8K\\n✅\\n❌\\n答案\\nTraining Verifiers to Solve Math Word Problems\\n\\n\\n\\nMATH\\n❌\\n❌\\n答案\\nMeasuring Mathematical Problem Solving With the MATH Dataset\\nNon-Step\\n\\n\\nPRM800K\\n✅\\n✅\\n正确类别\\nLet's Verify Step by Step\\nprompt deduplication\\n\\n\\nMath-Shepherd\\n✅\\n✅\\n正确类别\\nMath-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations\\nNot used\\n\\n\\nProcessBench\\n✅\\n✅\\n首个错误步骤\\nProcessBench: Identifying Process Errors in Mathematical Reasoning\\nonly label -1\\n\\n\\n\\t\\n\\n","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"QwQ-LongCoT-130K-decontaminated","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/flatlander1024/QwQ-LongCoT-130K-decontaminated","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Decontaminated version of gghfez/QwQ-LongCoT-130K-cleaned that remove the collided data from math/test, gsm8k/test, olympiadbench/test, minerva_math/test, college_math/test, mmlu_stem/test, gaokao, amc23, aime24 and math500.\\nTotal number of rows: 124594\\n","first_N":5,"first_N_keywords":["question-answering","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"math500_post-training","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cmpatino/math500_post-training","creator_name":"Carlos Miguel Patiño","creator_url":"https://huggingface.co/cmpatino","description":"\\n\\t\\n\\t\\t\\n\\t\\tMATH500 Subset for Small Model Post-Training\\n\\t\\n\\nThis dataset contains a subset of 20 problems from the MATH500 dataset.\\nThe dataset contains the following columns:\\n\\nproblem_id: Unique problem id that corresponds to the unique_id from the MATH500 dataset.\\nproblem: Text describing the problem the model needs to solve.\\nsolution: The solution generated by OpenAI available in the original dataset.\\nanswer: The ground truth answer.\\nsubject: Problem's subject from 7 possible values (Algebra… See the full description on the dataset page: https://huggingface.co/datasets/cmpatino/math500_post-training.","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"scicode","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Zilinghan/scicode","creator_name":"Zilinghan Li","creator_url":"https://huggingface.co/Zilinghan","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/Zilinghan/scicode.","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"DistillMath","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/csh0101/DistillMath","creator_name":"csh0101","creator_url":"https://huggingface.co/csh0101","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-CoT-Math-170k","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-CoT-Math-170k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","description":"\\n\\t\\n\\t\\t\\n\\t\\tGammaCorpus: CoT Math 170k\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is it?\\n\\t\\n\\nGammaCorpus CoT Math 170k is a dataset that consists of 170,000 math problems, each with step-by-step Chain-of-Thought (CoT) reasoning. It's designed to help in training and evaluating AI models for mathematical reasoning and problem-solving tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nNumber of Rows: 169,527\\nFormat: JSONL\\nLanguage: English\\nData Type: Math problems with step-by-step reasoning (Chain-of-Thought)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure… See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-CoT-Math-170k.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"distillation01","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zjrwtxtechstudio/distillation01","creator_name":"zjrwtx","creator_url":"https://huggingface.co/zjrwtxtechstudio","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"r101","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zjrwtxtechstudio/r101","creator_name":"zjrwtx","creator_url":"https://huggingface.co/zjrwtxtechstudio","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"r102","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zjrwtxtechstudio/r102","creator_name":"zjrwtx","creator_url":"https://huggingface.co/zjrwtxtechstudio","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"r109","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zjrwtxtechstudio/r109","creator_name":"zjrwtx","creator_url":"https://huggingface.co/zjrwtxtechstudio","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"arabic_dialects_question_and_answer","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CNTXTAI0/arabic_dialects_question_and_answer","creator_name":"CNTXT AI","creator_url":"https://huggingface.co/CNTXTAI0","description":"Data Content\\nThe file provided: Q/A Reasoning dataset\\ncontains the following columns:\\n\\n\\nID # : Denotes the reference ID for:\\na. Question\\nb. Answer to the question\\nc. Hint\\nd. Reasoning\\ne. Word count for items a to d above\\nDialects: Contains the following dialects in separate columns:\\na. English\\nb. MSA\\nc. Emirati\\nd. Egyptian\\ne. Levantine Syria\\nf. Levantine Jordan\\ng. Levantine Palestine\\nh. Levantine Lebanon\\nData Generation Process\\nThe following are the steps that were followed to curate the data:… See the full description on the dataset page: https://huggingface.co/datasets/CNTXTAI0/arabic_dialects_question_and_answer.","first_N":5,"first_N_keywords":["question-answering","text-generation","text2text-generation","Arabic","English"],"keywords_longer_than_N":true},
	{"name":"camel_dataset_example","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Wendong-Fan/camel_dataset_example","creator_name":"Wendong.Fan","creator_url":"https://huggingface.co/Wendong-Fan","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true}
]
;
