const data_for_domain_code = 
[
	{"name":"synthetic-search-filters","keyword":"bug-reporting-automation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic Search Filters\\n\\t\\n\\nThis is generated with GPT-4 Turbo possible search filters and theirs representations for the given business/service categories:\\nEducational Institutions, Job Recruitment Agencies, Banking Services, Investment Services, Insurance Services, Financial Planning and Advisory, Credit Services, Payment Processing, Mortgage and Real Estate Services, Taxation Services, Risk Management and Compliance, Digital and Mobile Banking, Retail Stores (Online and Offline)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters."},
	{"name":"synthetic-search-filters","keyword":"collaborative-dev-environments","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic Search Filters\\n\\t\\n\\nThis is generated with GPT-4 Turbo possible search filters and theirs representations for the given business/service categories:\\nEducational Institutions, Job Recruitment Agencies, Banking Services, Investment Services, Insurance Services, Financial Planning and Advisory, Credit Services, Payment Processing, Mortgage and Real Estate Services, Taxation Services, Risk Management and Compliance, Digital and Mobile Banking, Retail Stores (Online and Offline)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters."},
	{"name":"c-to-rust","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yijunyu/c-to-rust","creator_name":"Yu","creator_url":"https://huggingface.co/yijunyu","description":"yijunyu/c-to-rust dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Nepali","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SunilC/Nepali","creator_name":"Sunil Chaudhary","creator_url":"https://huggingface.co/SunilC","description":"SunilC/Nepali dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cubert_ETHPy150Open","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/claudios/cubert_ETHPy150Open","creator_name":"Claudio Spiess","creator_url":"https://huggingface.co/claudios","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuBERT ETH150 Open Benchmarks\\n\\t\\n\\nThis is an unofficial HuggingFace upload of the CuBERT ETH150 Open Benchmarks. This dataset was released along with Learning and Evaluating Contextual Embedding of Source Code.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBenchmarks and Fine-Tuned Models\\n\\t\\n\\nHere we describe the 6 Python benchmarks we created. All 6 benchmarks were derived from ETH Py150 Open. All examples are stored as sharded text files. Each text line corresponds to a separate example encoded as a JSON object.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/claudios/cubert_ETHPy150Open."},
	{"name":"oxford-pets-subset","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tomfern/oxford-pets-subset","creator_name":"Fernandez","creator_url":"https://huggingface.co/tomfern","description":"tomfern/oxford-pets-subset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"humanevalplus","keyword":"code-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/evalplus/humanevalplus","creator_name":"EvalPlus","creator_url":"https://huggingface.co/evalplus","description":"evalplus/humanevalplus dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"python-algorithm-sourcecode","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/annawleo/python-algorithm-sourcecode","creator_name":"Anna Wilson","creator_url":"https://huggingface.co/annawleo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nThis dataset provides algorithms and corresponding Python source code which can be leveraged for any type of code conversion applications. \\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annawleo/python-algorithm-sourcecode."},
	{"name":"relative-positioning","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LlameUser/relative-positioning","creator_name":"Antoine Angert","creator_url":"https://huggingface.co/LlameUser","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThis dataset aims to teach LLMs relative positioning (e.g. above, left from, below, etc.), \\nwhich in my findings most LLMs, even SOTA where not able to produce under all circumstances.\\nWill be pushing a fine-tuned mixtral-7x8B with this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nContains Data for relative positioning on a grid(256, 256).\\nAssumes Origin [0, 0] is in the bottom left.\\nTwo Objects (Object 1, Object 2) are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LlameUser/relative-positioning."},
	{"name":"FrontendCookbook","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tensoic/FrontendCookbook","creator_name":"Tensoic AI","creator_url":"https://huggingface.co/Tensoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset features a curated collection of questions and answers synthesized to cover key topics in Frontend development. Topics include HTML. CSS, JS, React JS, Next JS in a circullum manner.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCaution\\n\\t\\n\\nThis dataset was generated using Bard, please note that some content may not be entirely precise or reflect expert consensus. \\nUsers are encouraged to verify information independently for scholarly or critical purposes.\\n"},
	{"name":"bitaudit_verification_dataset","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/3it/bitaudit_verification_dataset","creator_name":"Franklin","creator_url":"https://huggingface.co/3it","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/3it/bitaudit_verification_dataset."},
	{"name":"WebSightDescribed","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/haidark1/WebSightDescribed","creator_name":"Haidar Khan","creator_url":"https://huggingface.co/haidark1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WebSightDescribed\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWebSightDescribed is a subset of WebSight v0.1, augmenting the dataset with \\nsynthetically generated natural language descriptions of the websites.\\nThis dataset serves as a valuable resource for the task of generating html code from a natural language description.\\n\\n  Details for WebSightDescribed\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nAn example of a sample appears as follows:\\n{\\n    'image': PIL.Image,\\n    'id': int‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haidark1/WebSightDescribed."},
	{"name":"MemGPT-Functions-DPO","keyword":"function calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/minchyeom/MemGPT-Functions-DPO","creator_name":"l","creator_url":"https://huggingface.co/minchyeom","description":"I hand crafted these. For MemGPT function calling.\\n"},
	{"name":"spider-realistic","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aherntech/spider-realistic","creator_name":"AhernTech s.r.o.","creator_url":"https://huggingface.co/aherntech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider-Releastic\\n\\t\\n\\nThis dataset variant contains only the Spider Realistic dataset used in \\\"Structure-Grounded Pretraining for Text-to-SQL\\\". The dataset is created based on the dev split of the Spider dataset (2020-06-07 version from https://yale-lily.github.io/spider). The authors of the dataset modified the original questions to remove the explicit mention of column names while keeping the SQL queries unchanged to better evaluate the model's capability in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aherntech/spider-realistic."},
	{"name":"code-review","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VatsaDev/code-review","creator_name":"Vatsa Pandey","creator_url":"https://huggingface.co/VatsaDev","description":"A Scrape of the codereview stack exchange, good for high quality code\\n"},
	{"name":"openeval","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NTUYG/openeval","creator_name":"Yang Guang","creator_url":"https://huggingface.co/NTUYG","description":"NTUYG/openeval dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"slimorca-dedup-chatml","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Radiantloom/slimorca-dedup-chatml","creator_name":"Radiantloom AI","creator_url":"https://huggingface.co/Radiantloom","description":"This is a chatml formatted version of original SlimOrca-Dedup dataset with few modifications to the system prompts.\\n"},
	{"name":"OpenHermes-2.5-Code-290k","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/OpenHermes-2.5-Code-290k","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"OpenHermes-2.5-Code-290k\\nThis dataset is amalgamation of two datasets. I have used OpenHermes-2.5 a super quality dataset made avaliable by teknium.\\nOther datset is my own Code-290k-ShareGPT.\\nThis dataset is in Vicuna/ShareGPT format. There are around 1.29 million set of conversations. \\nI have cleaned the dataset provided by Teknium and removed metadata such as \\\"source\\\" & \\\"category\\\" etc.\\nThis dataset has primarily synthetically generated instruction and chat samples.\\nThis dataset is very‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ajibawa-2023/OpenHermes-2.5-Code-290k."},
	{"name":"DABench","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/infiagent/DABench","creator_name":"InfiAgent","creator_url":"https://huggingface.co/infiagent","description":"infiagent/DABench dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Github-PR-BOT","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SIT-RiSE/Github-PR-BOT","creator_name":"Research in software engineering","creator_url":"https://huggingface.co/SIT-RiSE","description":"\\n  \\n\\n\\ngithub-bot-pr\\n\\nThe PR data for the GitHub Bot PR investigation Study.\\nThe PR Dataset contains three subsets:\\n\\nApache official projects\\nMicrosoft 200 most starred projects\\nGithub 200 most starred java projects\\n\\nThe time frame:\\nMay 1st 2022 -- May 1st 2023\\n"},
	{"name":"general-v-online-llm","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RealEmmettS/general-v-online-llm","creator_name":"Emmett Shaughnessy","creator_url":"https://huggingface.co/RealEmmettS","description":"RealEmmettS/general-v-online-llm dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ChatML-SlimOrca-Dedup","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-SlimOrca-Dedup","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"Open-Orca/SlimOrca-Dedup in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"Open-Orca/SlimOrca-Dedup\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = []\\n\\n    conversations = columns[\\\"conversations\\\"]\\n\\n    for i in range(len(conversations)):\\n        message =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-SlimOrca-Dedup."},
	{"name":"MMCode","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/likaixin/MMCode","creator_name":"Kaixin Li","creator_url":"https://huggingface.co/likaixin","description":"\\n    \\n    MMCode\\n\\n\\nMMCode Github Repo \\n\\nNote: Please find the files directly via the \\\"Files and versions\\\" panel. Preview is not available. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMMCode is a multi-modal code generation dataset designed to evaluate the problem-solving skills of code language models in visually rich contexts (i.e. images). \\nIt contains 3,548 questions paired with 6,620 images, derived from real-world programming challenges across 10 code competition websites, with Python solutions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/likaixin/MMCode."},
	{"name":"MemGPT-Functions-DPO-2","keyword":"function calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/minchyeom/MemGPT-Functions-DPO-2","creator_name":"l","creator_url":"https://huggingface.co/minchyeom","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIGRATED TO THE OFFICIAL MEMGPT HF PAGE!\\n\\t\\n\\nmade for MemGPT function calling. generated using gpt4.\\n"},
	{"name":"hibo-function-calling-v1","keyword":"function-calling","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/thibaud-perrin/hibo-function-calling-v1","creator_name":"Thibaud Perrin","creator_url":"https://huggingface.co/thibaud-perrin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\thibo-function-calling-v1\\n\\t\\n\\n\\n    \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìñ Dataset Description\\n\\t\\n\\nThis dataset, named \\\"hibo-function-calling-v1\\\", is designed to facilitate the fine-tuning of Large Language Models (LLMs) for function calling tasks. It comprises a single 'train' split containing 323,271 data points across three columns: 'dataset_origin', 'system', and 'chat'. \\nThe dataset is a result of merging two distinct sources: gathnex/Gath_baize and glaiveai/glaive-function-calling-v2, with an aim to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thibaud-perrin/hibo-function-calling-v1."},
	{"name":"SentiMP-En","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rbnuria/SentiMP-En","creator_name":"Nuria Rodr√≠guez Barroso","creator_url":"https://huggingface.co/rbnuria","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentiMP-En Dataset\\n\\t\\n\\nThe SentiMP-En Dataset is an english sentiment analysis dataset based on tweets written by members of parliament in United Kingdom in 2021.  It has been developed collaboratively by the Andalusian Research Institute in Data Science and Computational Intelligence (DaSCI) research  group from the University of Granada, the SINAI research group from the University of Ja√©n and the Cardiff NLP research group from the University of Cardiff.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rbnuria/SentiMP-En."},
	{"name":"LLM-EvaluationHub","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/strikoder/LLM-EvaluationHub","creator_name":"Mohamad Alamin Yassin","creator_url":"https://huggingface.co/strikoder","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLLM-EvaluationHub: Enhanced Dataset for Large Language Model Assessment\\n\\t\\n\\nThis repository, LLM-EvaluationHub, presents an enhanced dataset tailored for the evaluation and assessment of Large Language Models (LLMs). It builds upon the dataset originally provided by SafetyBench (THU-COAI), incorporating significant modifications and additions to address specific research objectives. Below is a summary of the key differences and enhancements:\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKey Modifications‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/strikoder/LLM-EvaluationHub."},
	{"name":"Prompts","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/UserIscool/Prompts","creator_name":"John Leo","creator_url":"https://huggingface.co/UserIscool","description":"UserIscool/Prompts dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"test","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ErikQQY/test","creator_name":"QingyuQu","creator_url":"https://huggingface.co/ErikQQY","description":"ErikQQY/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"AIEC-140K","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AgoraX/AIEC-140K","creator_name":"Agora","creator_url":"https://huggingface.co/AgoraX","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAgoraX/AIEC-140K Dataset\\n\\t\\n\\n===============================\\nExcited to Announce AgoraX/AIEC-140K!\\nAn all-new dataset with super high High Quality AI Engineering Code Tokens totaling 140k samples!\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nThe AgoraX/AIEC-140K dataset is a collection of AI engineering code tokens from top research labs such as OpenAI, Nvidia, Google, Lucidrains, and others. These tokens have been scraped from various repositories on GitHub, providing a valuable resource for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AgoraX/AIEC-140K."},
	{"name":"SentiMP-Sp","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rbnuria/SentiMP-Sp","creator_name":"Nuria Rodr√≠guez Barroso","creator_url":"https://huggingface.co/rbnuria","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentiMP-Sp Dataset\\n\\t\\n\\nThe SentiMP-Sp Dataset is a spanish sentiment analysis dataset based on tweets written by members of parliament in Spain in 2021.  It has been developed collaboratively by the Andalusian Research Institute in Data Science and Computational Intelligence (DaSCI) research  group from the University of Granada, the SINAI research group from the University of Ja√©n and the Cardiff NLP research group from the University of Cardiff.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rbnuria/SentiMP-Sp."},
	{"name":"SentiMP-Gr","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rbnuria/SentiMP-Gr","creator_name":"Nuria Rodr√≠guez Barroso","creator_url":"https://huggingface.co/rbnuria","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentiMP-Gr Dataset\\n\\t\\n\\nThe SentiMP-Gr Dataset is a greek sentiment analysis dataset based on tweets written by members of parliament in United Kingdom in 2021.  It has been developed collaboratively by the Andalusian Research Institute in Data Science and Computational Intelligence (DaSCI) research  group from the University of Granada, the SINAI research group from the University of Ja√©n and the Cardiff NLP research group from the University of Cardiff.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rbnuria/SentiMP-Gr."},
	{"name":"awesome-python","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dylanhogg/awesome-python","creator_name":"Dylan Hogg","creator_url":"https://huggingface.co/dylanhogg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\twww.awesomepython.org\\n\\t\\n\\nHand-picked awesome Python libraries, with an emphasis on data and machine learning üêç\\nDataset used by https://www.awesomepython.org/\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlicense: mit\\n\\t\\n\\n"},
	{"name":"spider-syn","keyword":"text-to-sql","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aherntech/spider-syn","creator_name":"AhernTech s.r.o.","creator_url":"https://huggingface.co/aherntech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Sypder-Syn\\n\\t\\n\\nSpyder-Syn is a human curated variant of the Spider Text-to-SQL database.\\nThe database was created to test the robustness of text-to-SQL models for robustness of synonym substitution.\\nThe source GIT repo for Sypder-Syn is located here: https://github.com/ygan/Spider-Syn\\nDetails regarding the data perterbation methods used and objectives are described in ACL 2021: arXiv\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper Abstract\\n\\t\\n\\n\\nRecently, there has been significant progress in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aherntech/spider-syn."},
	{"name":"data_set_test","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sg69291/data_set_test","creator_name":"Shubham Gupta","creator_url":"https://huggingface.co/sg69291","description":"This is README file.\\n"},
	{"name":"kittech_shona_dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kittech/kittech_shona_dataset","creator_name":"Bright Chirindo","creator_url":"https://huggingface.co/Kittech","description":"Kittech/kittech_shona_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Capybara","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AISE-TUDelft/Capybara","creator_name":"AISE research lab at TU Delft","creator_url":"https://huggingface.co/AISE-TUDelft","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Capybara\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDataset used to train BinT5. Please refer to the paper for more information. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n@inproceedings{alkaswan2023extending,\\n  title={Extending Source Code Pre-Trained Language Models to Summarise Decompiled Binaries},\\n  author={Al-Kaswan, Ali and Ahmed, Toufique and Izadi, Maliheh and Sawant, Anand Ashok and Devanbu, Premkumar and van Deursen, Arie},\\n  booktitle={2023 IEEE International‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AISE-TUDelft/Capybara."},
	{"name":"hercules-v2.0","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/hercules-v2.0","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Hercules-v2.0\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nDataset Name: Hercules-v2.0\\nVersion: 2.0\\nDate of Release: February 2, 2024\\nSize: 1,307,174\\nData Sources: \\nHercules-v2.0 is an enriched instruction dataset derived from OpenHermes-2.5, aimed at enhancing its diversity and scope. The dataset amalgamates contributions from various data sources, with a strong emphasis on Biology, Physics, Medicine, Math, Computer Science, Instruction Following, Function Calling, and Roleplay. The data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/hercules-v2.0."},
	{"name":"Evol-Instruct-Code-80k-v1","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sharathhebbar24/Evol-Instruct-Code-80k-v1","creator_name":"Sharath S Hebbar","creator_url":"https://huggingface.co/Sharathhebbar24","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEvol-Instruct-Code-80k-v1\\n\\t\\n\\nThis is a cleansed version of nickrosh/Evol-Instruct-Code-80k-v1\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"Sharathhebbar24/Evol-Instruct-Code-80k-v1\\\", split=\\\"train\\\")\\n\\n"},
	{"name":"sql-create-context","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sharathhebbar24/sql-create-context","creator_name":"Sharath S Hebbar","creator_url":"https://huggingface.co/Sharathhebbar24","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSQL Code\\n\\t\\n\\nThis is a cleansed version of b-mc2/sql-create-context\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"Sharathhebbar24/sql-create-context\\\", split=\\\"train\\\")\\n\\n"},
	{"name":"Purr-Data_example_source_codes","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParZiVal04/Purr-Data_example_source_codes","creator_name":"amrutk","creator_url":"https://huggingface.co/ParZiVal04","description":"Purr-Data Patch Source Code Dataset:\\n\\nThis dataset is designed for training language models to generate source code for Purr-Data patches. It focuses specifically on patches that output a particular message when a \\\"bang\\\" object is clicked.\\n\\nDataset Creation:\\n\\nThe dataset was created with the goal of evaluating the ability of large language models like Google's 2B GEMMA to be fine-tuned for Purr-Data source code generation.\\n\\nDataset Characteristics:\\n\\nContent: Each data point consists of two‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ParZiVal04/Purr-Data_example_source_codes."},
	{"name":"hcad_imdb","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Siki-77/hcad_imdb","creator_name":"Qiu Siki","creator_url":"https://huggingface.co/Siki-77","description":"Siki-77/hcad_imdb dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"synthetic-introduction-extraction","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/angelmmiguel/synthetic-introduction-extraction","creator_name":"Angel M De Miguel","creator_url":"https://huggingface.co/angelmmiguel","description":"angelmmiguel/synthetic-introduction-extraction dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"query-parsing-instructions-saiga","keyword":"bug-reporting-automation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EmbeddingStudio/query-parsing-instructions-saiga","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic Search Query Parsing Instruction for Saiga family\\n\\t\\n\\nThis is the version of EmbeddingStudio/synthetic-search-queries-ru dataset created the way to be aligned with Saiga-Mistral-7B instruction format.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneration details\\n\\t\\n\\nWe used synthetically generated query parsing instructions:\\n\\nWe generated lists of possible filters for 72 company categories: \\nRaw version of filters dataset\\nSplit by representations\\n\\n\\nSelect randomly up-to 150 possible combinations (1-3‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/query-parsing-instructions-saiga."},
	{"name":"synthetic-search-queries-ru","keyword":"bug-reporting-automation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-queries-ru","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic Search Queries : Russian\\n\\t\\n\\nThis is generated with GPT-4 Turbo synthetic search queries, that based on the given filters schema for the given business/service categories for Russian language domain:\\nArtificial Intelligence and Machine Learning, Automotive, Automotive Dealerships, Banking Services, Books and Media, Cloud Computing Services, Cloud-based Development Environments, Collaborative Development Environments, Commercial Real Estate, Continuous‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-queries-ru."},
	{"name":"synthetic-search-filters-ru","keyword":"bug-reporting-automation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters-ru","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic Search Filters\\n\\t\\n\\nThis is generated with GPT-4 Turbo possible search filters and theirs representations for the given business/service categories and for the Russian language domain:\\nArtificial Intelligence and Machine Learning, Automotive, Automotive Dealerships, Banking Services, Books and Media, Cloud Computing Services, Cloud-based Development Environments, Collaborative Development Environments, Commercial Real Estate, Continuous Integration/Continuous Deployment‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters-ru."},
	{"name":"synthetic-search-filters-ru-raw","keyword":"bug-reporting-automation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters-ru-raw","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic Search Filters Raw: Russian\\n\\t\\n\\nThis is the raw version of EmbeddingStudio/synthetic-search-filters-ru dataset for Russian language domain.\\nThis is generated with GPT-4 Turbo possible search filters and theirs representations for the given business/service categories:\\nArtificial Intelligence and Machine Learning, Automotive Dealerships, Banking Services, Books and Media, Cloud Computing Services, Cloud-based Development Environments, Collaborative Development Environments‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters-ru-raw."},
	{"name":"Coding_GPT4_Data","keyword":"coding","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MAsad789565/Coding_GPT4_Data","creator_name":"M Asad Iqbal","creator_url":"https://huggingface.co/MAsad789565","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Info\\n\\t\\n\\n** This dataset is generated by the GPT-4 based model.\\n** The whole dataset is about coding.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n[\\n  {\\n      \\\"user\\\": \\\"How can I implement a Python function to check if a given string is a palindrome or not? \\\\n\\\\nPlease generate the code for this task in Python.\\\",\\n      \\\"assistant\\\": \\\"Sure! Here's a Python function that checks whether a given string is a palindrome or not:\\\\n\\\\n```python\\\\ndef is_palindrome(input_string):\\\\n    # Convert the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MAsad789565/Coding_GPT4_Data."},
	{"name":"query-parsing-instructions-saiga","keyword":"collaborative-dev-environments","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EmbeddingStudio/query-parsing-instructions-saiga","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic Search Query Parsing Instruction for Saiga family\\n\\t\\n\\nThis is the version of EmbeddingStudio/synthetic-search-queries-ru dataset created the way to be aligned with Saiga-Mistral-7B instruction format.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneration details\\n\\t\\n\\nWe used synthetically generated query parsing instructions:\\n\\nWe generated lists of possible filters for 72 company categories: \\nRaw version of filters dataset\\nSplit by representations\\n\\n\\nSelect randomly up-to 150 possible combinations (1-3‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/query-parsing-instructions-saiga."},
	{"name":"synthetic-search-queries-ru","keyword":"collaborative-dev-environments","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-queries-ru","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic Search Queries : Russian\\n\\t\\n\\nThis is generated with GPT-4 Turbo synthetic search queries, that based on the given filters schema for the given business/service categories for Russian language domain:\\nArtificial Intelligence and Machine Learning, Automotive, Automotive Dealerships, Banking Services, Books and Media, Cloud Computing Services, Cloud-based Development Environments, Collaborative Development Environments, Commercial Real Estate, Continuous‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-queries-ru."},
	{"name":"synthetic-search-filters-ru","keyword":"collaborative-dev-environments","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters-ru","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic Search Filters\\n\\t\\n\\nThis is generated with GPT-4 Turbo possible search filters and theirs representations for the given business/service categories and for the Russian language domain:\\nArtificial Intelligence and Machine Learning, Automotive, Automotive Dealerships, Banking Services, Books and Media, Cloud Computing Services, Cloud-based Development Environments, Collaborative Development Environments, Commercial Real Estate, Continuous Integration/Continuous Deployment‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters-ru."},
	{"name":"synthetic-search-filters-ru-raw","keyword":"collaborative-dev-environments","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters-ru-raw","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic Search Filters Raw: Russian\\n\\t\\n\\nThis is the raw version of EmbeddingStudio/synthetic-search-filters-ru dataset for Russian language domain.\\nThis is generated with GPT-4 Turbo possible search filters and theirs representations for the given business/service categories:\\nArtificial Intelligence and Machine Learning, Automotive Dealerships, Banking Services, Books and Media, Cloud Computing Services, Cloud-based Development Environments, Collaborative Development Environments‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-filters-ru-raw."},
	{"name":"hercules-v2.0","keyword":"function calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/hercules-v2.0","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Hercules-v2.0\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nDataset Name: Hercules-v2.0\\nVersion: 2.0\\nDate of Release: February 2, 2024\\nSize: 1,307,174\\nData Sources: \\nHercules-v2.0 is an enriched instruction dataset derived from OpenHermes-2.5, aimed at enhancing its diversity and scope. The dataset amalgamates contributions from various data sources, with a strong emphasis on Biology, Physics, Medicine, Math, Computer Science, Instruction Following, Function Calling, and Roleplay. The data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/hercules-v2.0."},
	{"name":"baby-python","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nilq/baby-python","creator_name":"Niels Horn","creator_url":"https://huggingface.co/nilq","description":"\\n  \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBaby Python\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnglish + Python pretraining dataset.\\n\\t\\n\\nThis dataset contains the dataset from the BabyLM 100M dataset, evenly matched by a truncated subset of the small-python-stack.\\nEnglish / all of BabyLM 100M\\n\\nCHILDES (child-directed speech)\\nSubtitles (speech)\\nBNC (speech)\\nTED talks (speech)\\nchildren's books (simple written language)\\n\\nPython\\n\\nPython code (from small-python-stack) corresponding to 100M words of English.\\n\\n"},
	{"name":"sparc","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aherntech/sparc","creator_name":"AhernTech s.r.o.","creator_url":"https://huggingface.co/aherntech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SParC\\n\\t\\n\\nSParC is a context-dependant multi-turn version of the Spider task 1.0.\\nThis dataset provides a chat-bot oriented test set for text-to-sql problems. Additional details may be obtained in the paper:\\n\\nhttps://arxiv.org/abs/1906.02285\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper Abstract\\n\\t\\n\\n\\nWe present SParC, a dataset for cross-domainSemanticParsing inContext that consists of 4,298 coherent question sequences (12k+ individual questions annotated with SQL queries). It is obtained from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aherntech/sparc."},
	{"name":"haispider","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HusnaManakkot/haispider","creator_name":"HUSNA M","creator_url":"https://huggingface.co/HusnaManakkot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider\\n\\t\\n\\nTable of Contents\\nDataset Description\\nDataset Summary\\nSupported Tasks and Leaderboards\\nLanguages\\nDataset Structure\\nData Instances\\nData Fields\\nData Splits\\nDataset Creation\\nCuration Rationale\\nSource Data\\nAnnotations\\nPersonal and Sensitive Information\\nConsiderations for Using the Data\\nSocial Impact of Dataset\\nDiscussion of Biases\\nOther Known Limitations\\nAdditional Information\\nDataset Curators\\nLicensing Information\\nCitation Information\\nContributions\\nDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HusnaManakkot/haispider."},
	{"name":"ZharfaTech-Open-Platypus-Persian-Farsi","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZharfaTech/ZharfaTech-Open-Platypus-Persian-Farsi","creator_name":"ZharfaTech","creator_url":"https://huggingface.co/ZharfaTech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPersian Open-Platypus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout ZharfaTech\\n\\t\\n\\nZharfaTech is a pioneer in developing Language Learning Models (LLMs) tailored for the Persian language, aiming to empower over 100 million Persian speakers worldwide. Our mission encompasses bridging the digital divide in LLM-related services like content generation, customer relationship systems, and more, with a dual approach of fostering open-source collaboration and delivering high-value, specialized closed-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZharfaTech/ZharfaTech-Open-Platypus-Persian-Farsi."},
	{"name":"Nadi_Indic466k_Instruct","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct","creator_name":"Convai Innovations","creator_url":"https://huggingface.co/convaiinnovations","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNadi_Indic466K_Instruct Dataset\\n\\t\\n\\nThe Nadi_Indic466K_Instruct dataset is the world's first coding dataset with 18 Indian language support, 466k rows and 142 Million total tokens. This dataset can be used by developers to build Indian coding language models (LLMs) for various programming languages.\\nQ-LoRA based SFT/PPO/DPO fine-tuning can be done on the dataset in LLAMA-2 or Mistral or any opens-soure LLM for text generation.\\nThe dataset was carefully curated such that the coding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct."},
	{"name":"codeconv-fortran-to-rust","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/devesh5/codeconv-fortran-to-rust","creator_name":"Devesh Surve","creator_url":"https://huggingface.co/devesh5","description":"devesh5/codeconv-fortran-to-rust dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"vacancies_prompts","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlekseyScorpi/vacancies_prompts","creator_name":"Aleksey Timoshin","creator_url":"https://huggingface.co/AlekseyScorpi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout this dataset\\n\\t\\n\\nThis dataset was originally based on dataset from HH.ru company https://www.kaggle.com/datasets/vyacheslavpanteleev1/hhru-it-vacancies-from-20211025-to-20211202.\\nThis data is parsed from hh.ru for Moscow and Saint Petersburg (from 2021-10-25 to 2021-12-02).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCreate prompt and description\\n\\t\\n\\nTo create a dataset prompts, fields such as: employer, name, experience, schedule, keys are used. For description just used description field.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlekseyScorpi/vacancies_prompts."},
	{"name":"sql-create-context-chatml","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/recastai/sql-create-context-chatml","creator_name":"Re:cast AI","creator_url":"https://huggingface.co/recastai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset has been created by Re:cast AI to extend the existing dataset b-mc2/sql-create-context into a chatml friendly format for use in SFT tasks with pretrained models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nmessages = [\\n     {'content': \\\"You are a powerful text-to-SQL AI assistant that helps users ... etc.\\\", 'role': 'system'},\\n     {'content': '(Optional) Context information is below ... etc.', 'role': 'user'},\\n     {'content': 'SELECT COUNT(*) FROM head WHERE‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recastai/sql-create-context-chatml."},
	{"name":"tapilot-crossing","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/patrickNLP/tapilot-crossing","creator_name":"Malou Lab","creator_url":"https://huggingface.co/patrickNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTapilot-Crossing is the first benchmark to evaluate LLM agents on interactive data analysis. It includes 1024 user-machine interactions with 1176 user intents, spanning four practical scenarios: \\n\\n\\nNormal, where all questions and user requirements are explicit, requiring no actions from agents;\\n\\n\\n\\nAction, where agents must respond to diverse user feedback or instructions;\\n\\n\\n\\nPrivate, which examines the true semantic parsing capability of agents when encountering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/patrickNLP/tapilot-crossing."},
	{"name":"MMOS","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cyzhh/MMOS","creator_name":"Yezeng Chen","creator_url":"https://huggingface.co/cyzhh","description":"ArXiv | Models | Data | Code | \\nYou can download the dataset as follows\\nfrom datasets import load_dataset\\nds = load_dataset(\\\"cyzhh/MMOS\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema\\n\\t\\n\\nEach dataset row has the following structure\\n{\\n  \\\"idx\\\": ..., # problem id\\n  \\\"prompt\\\": ..., # problem \\n  \\\"completion\\\": ... # reasoning path with python\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nWe do not alter the license of any of the underlying data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nFor the MMOS, cite \\n@misc{chen2024empirical,\\n      title={An Empirical Study‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyzhh/MMOS."},
	{"name":"datasets-github-issues","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jamesLeeeeeee/datasets-github-issues","creator_name":"jk.lee","creator_url":"https://huggingface.co/jamesLeeeeeee","description":"jamesLeeeeeee/datasets-github-issues dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"SLTrans","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UKPLab/SLTrans","creator_name":"Ubiquitous Knowledge Processing Lab","creator_url":"https://huggingface.co/UKPLab","description":"The dataset consists of source code and LLVM IR pairs generated from accepted and de-duped programming contest solutions. The dataset is divided into language configs and mode splits. The language can be one of C, C++, D, Fortran, Go, Haskell, Nim, Objective-C, Python, Rust and Swift, indicating the source files' languages. The mode split indicates the compilation mode, which can be wither Size_Optimized or Perf_Optimized.\\nOnce you have submitted an access request which has been approved‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UKPLab/SLTrans."},
	{"name":"CodeGen4Libs","keyword":"code-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/CodeGen4Libs","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for FudanSELab CodeGen4Libs Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is used in the ASE2023 paper titled \\\"CodeGen4Libs: A Two-stage Approach for Library-oriented Code Generation\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"FudanSELab/CodeGen4Libs\\\")\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['id', 'method', 'clean_method', 'doc', 'comment'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/severo/CodeGen4Libs."},
	{"name":"pokedex","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/smartire/pokedex","creator_name":"Stefano Martire","creator_url":"https://huggingface.co/smartire","description":"Regional pokedex from the Pokemon games.\\nPokedex available at the moment:\\n\\nPaldea (utilised in https://medium.com/@virtualmartire/i-built-an-algorithm-that-finds-the-optimal-pokemon-team-01ea152824a9).\\n\\n"},
	{"name":"attackdex-paldea","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/smartire/attackdex-paldea","creator_name":"Stefano Martire","creator_url":"https://huggingface.co/smartire","description":"Single pokemon datasets containing all the attacks (from levelling or TMs) learnable by the relative monster. All the data refer to the Paldea region and they come from the project discussed in https://medium.com/@virtualmartire/i-built-an-algorithm-that-finds-the-optimal-pokemon-team-01ea152824a9.\\n"},
	{"name":"slimorca-dedup-chatml-100k","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/philschmid/slimorca-dedup-chatml-100k","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCopy of Open-Orca/SlimOrca-Dedup in ChatML format downsample to 100k\\n\\t\\n\\n\\n\\\"SlimOrca Dedup\\\" is a deduplicated, unfiltered subset of the SlimOrca dataset, excluding RLHF instances, resulting in 363k unique examples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKey Features\\n\\t\\n\\n\\nRemoval of RLHF instances.\\nDeduplication using minhash and Jaccard similarity techniques.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemo Models\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote: These models were trained on the full SlimOrca dataset, not the deduplicated, unfiltered version.\\n*‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/philschmid/slimorca-dedup-chatml-100k."},
	{"name":"slimorca-dedup-chatml","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/philschmid/slimorca-dedup-chatml","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCopy of Open-Orca/SlimOrca-Dedup in ChatML format\\n\\t\\n\\n\\n\\\"SlimOrca Dedup\\\" is a deduplicated, unfiltered subset of the SlimOrca dataset, excluding RLHF instances, resulting in 363k unique examples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKey Features\\n\\t\\n\\n\\nRemoval of RLHF instances.\\nDeduplication using minhash and Jaccard similarity techniques.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemo Models\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote: These models were trained on the full SlimOrca dataset, not the deduplicated, unfiltered version.\\n*‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/philschmid/slimorca-dedup-chatml."},
	{"name":"qdrant_doc","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/atitaarora/qdrant_doc","creator_name":"Atita","creator_url":"https://huggingface.co/atitaarora","description":"atitaarora/qdrant_doc dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Malicious_code_classification","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Er1111c/Malicious_code_classification","creator_name":"Lee","creator_url":"https://huggingface.co/Er1111c","description":""},
	{"name":"Handwritten-Latex-Datasets","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Shijiang/Handwritten-Latex-Datasets","creator_name":"Wang","creator_url":"https://huggingface.co/Shijiang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\nThis data set includes common handwritten formulas in junior high schools and high schools, and is labeled in Latex format. Can be used to train models that recognize common numbers, fractions, and sets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset source\\n\\t\\n\\nCollected in various junior high schools and high schools, handwritten by students.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThe label is stored at json folder and scanned hand-writted pictures are stored at pic folder.\\nScan the qr code of the picture to get‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Shijiang/Handwritten-Latex-Datasets."},
	{"name":"safim","keyword":"code-generation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gonglinyuan/safim","creator_name":"Linyuan Gong","creator_url":"https://huggingface.co/gonglinyuan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSAFIM Benchmark\\n\\t\\n\\nSyntax-Aware Fill-in-the-Middle (SAFIM) is a benchmark for evaluating Large Language Models (LLMs) on\\nthe code Fill-in-the-Middle (FIM) task. SAFIM has three subtasks: Algorithmic Block Completion,\\nControl-Flow Expression Completion, and API Function Call Completion. SAFIM is sourced from code\\nsubmitted from April 2022 to January 2023 to minimize the impact of data contamination on evaluation\\nresults.\\n\\nAuthors: Linyuan Gong, Sida Wang, Mostafa Elhoushi, Alvin‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gonglinyuan/safim."},
	{"name":"new-spider-HM","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HusnaManakkot/new-spider-HM","creator_name":"HUSNA M","creator_url":"https://huggingface.co/HusnaManakkot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at https://yale-lily.github.io/spider\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HusnaManakkot/new-spider-HM."},
	{"name":"updated-dataset","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HusnaManakkot/updated-dataset","creator_name":"HUSNA M","creator_url":"https://huggingface.co/HusnaManakkot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at https://yale-lily.github.io/spider\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HusnaManakkot/updated-dataset."},
	{"name":"CoderAPI_Dataset","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/IslamMesabah/CoderAPI_Dataset","creator_name":"Islam Mesabah","creator_url":"https://huggingface.co/IslamMesabah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLarge Language Models for instructed and effective code generation using Documentation of APIs\\n\\t\\n\\nThis thesis explores the effective utilization of Large Language Models, specifically the Instruct CodeT5+ 16 Billion model, for the generation of multi-line, ready-to-execute code in Python. Departing from conventional reliance solely on pre-trained LLM knowledge, we employ API documentation to enhance the correctness of generated code for both seen and unseen APIs in the LLM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IslamMesabah/CoderAPI_Dataset."},
	{"name":"colors_2_train","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/molchomen/colors_2_train","creator_name":"Molcho","creator_url":"https://huggingface.co/molchomen","description":"molchomen/colors_2_train dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"socratic-debugging-benchmark","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/taisazero/socratic-debugging-benchmark","creator_name":"Erfan Al-Hossami","creator_url":"https://huggingface.co/taisazero","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSocratic Debugging Benchmark\\n\\t\\n\\n\\n  \\n\\n\\nThe repository contains the dataset for the Socratic Debugging Benchmark accompanying the papers \\\"Socratic Questioning of Novice Debuggers: A Benchmark Dataset and Preliminary Evaluations\\\" in proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Application at ACL 2023 and \\\"Can Language Models Employ the Socratic Method? Experiments with Code Debugging\\\" in the proceedings of SIGCSE'24.\\nThe dataset is also hosted on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/taisazero/socratic-debugging-benchmark."},
	{"name":"pandora-tool-calling","keyword":"function-calling","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/danilopeixoto/pandora-tool-calling","creator_name":"Danilo Peixoto","creator_url":"https://huggingface.co/danilopeixoto","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPandora Tool Calling\\n\\t\\n\\nA tool-calling dataset for Supervised fine-tuning of the Pandora Large Language Model (LLM).\\nThe dataset is based on the glaiveai/glaive-function-calling-v2 dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCopyright and license\\n\\t\\n\\nCopyright (c) 2024, Danilo Peixoto Ferreira. All rights reserved.\\nProject developed under a BSD-3-Clause license.\\n"},
	{"name":"glaive-v2-single-turn-func-call-chatml","keyword":"function-calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/recastai/glaive-v2-single-turn-func-call-chatml","creator_name":"Re:cast AI","creator_url":"https://huggingface.co/recastai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"glaive-v2-single-turn-func-call-chatml\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset has been created by Re:cast AI to transform the existing dataset glaiveai/glaive-function-calling-v2 into a chatml friendly format for use in SFT tasks with pretrained models.\\nThe original dataset was filtered and altered with the following:\\n\\nRemoved examples that do not produce a function completion response.\\nEach example is a single-turn between user and assistant along with a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recastai/glaive-v2-single-turn-func-call-chatml."},
	{"name":"ObscuraX","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ObscuraCoder/ObscuraX","creator_name":"Obscura Coder","creator_url":"https://huggingface.co/ObscuraCoder","description":"ObscuraCoder/ObscuraX dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Wos","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gtceu/Wos","creator_name":"gt","creator_url":"https://huggingface.co/gtceu","description":"gtceu/Wos dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"mbpp-ja","keyword":"code-generation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-jp/mbpp-ja","creator_name":"LLM-jp","creator_url":"https://huggingface.co/llm-jp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmbpp-ja\\n\\t\\n\\nThis repository provides a mbpp dataset translated from English into Japanese by LLM-jp, a collaborative project launched in Japan.\\nFor English to Japanese translation, DeepL was used.\\nThe links of the original mbpp dataset are here(HuggingFace) or here(GitHub).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSend Questions to\\n\\t\\n\\nllm-jp(at)nii.ac.jp\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Card Authors\\n\\t\\n\\nThe names are listed in alphabetical order.\\nNamgi Han, Masatoshi Otake, Shintaro Ozaki, Yusuke Miyao.\\n"},
	{"name":"JetCopper-10B","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sudy-super/JetCopper-10B","creator_name":"Sudy","creator_url":"https://huggingface.co/sudy-super","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tJetCopper-10B\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nJetCopper-10B was created by extracting a portion of the data after cleaning, filtering, and deduplicating the following datasets.\\n\\nThe japanese subset of C4\\nThe japanese subset of CC-100\\nThe japanese subset of OSCAR-2301\\nThe japanese subset of HPLT Datasets v1.2\\nwiki40b-ja\\n\\nThis dataset was used to pre-train Contrail-200m-64k when we participated in LOCAL AI HACKATHON #000.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe number of tokens (Using tokenizer of calm2-chat)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sudy-super/JetCopper-10B."},
	{"name":"MiFirma-Ejemplo","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/devdroide/MiFirma-Ejemplo","creator_name":"devdroide","creator_url":"https://huggingface.co/devdroide","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMi Firma - Preguntas y respuestas\\n\\t\\n\\nEste colecci√≥n contiene preguntas y respuestas de una aplicaci√≥n web ficticia que se encarga de firmar documentos\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContenido\\n\\t\\n\\nTiene preguntas y repuestas con un contexto dado, como de:\\n\\nInformaci√≥n de la aplicaci√≥n\\nPerfiles\\nProductos que cubre\\nQuienes pueden firmar\\nErrores que comunes de la aplicaci√≥n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsos\\n\\t\\n\\nLa colecci√≥n tiene como objetivo ampliar la disponibilidad de datos conversacionales para la investigaci√≥n en IA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/devdroide/MiFirma-Ejemplo."},
	{"name":"vacancies_prompts_en","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlekseyScorpi/vacancies_prompts_en","creator_name":"Aleksey Timoshin","creator_url":"https://huggingface.co/AlekseyScorpi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout this dataset\\n\\t\\n\\nThis dataset is just a translation of the following dataset https://huggingface.co/datasets/AlekseyScorpi/vacancies_prompts . The translation was carried out using googletrans.\\n"},
	{"name":"Worldsim","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VatsaDev/Worldsim","creator_name":"Vatsa Pandey","creator_url":"https://huggingface.co/VatsaDev","description":"Bunch of worldsim text?\\n"},
	{"name":"Mod_Temperatura","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/albertomarun/Mod_Temperatura","creator_name":"ALBERTO MARUN","creator_url":"https://huggingface.co/albertomarun","description":"library_name: Mod_Temperatura\\nlibrary_version: 1.0.0\\ninference: false\\ndataset-index:\\n\\nname: albertomarun/Mod_Temperatura\\ndescription: This dataset has different numbers related to the temperature conversion between Celsius and Fahrenheit.\\nresults:\\ntask:\\n  type: temperature-conversion\\ndataset:\\n  type: Mod_Temperatura.h5\\n\\n\\n\\n\\nModelo to support this \\nSimpleTemperatureCalculation\\nMore models and dataset available at: AlbertoMarunIA\\n"},
	{"name":"Text-to-sql-v1","keyword":"sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agicorp/Text-to-sql-v1","creator_name":"agicorp","creator_url":"https://huggingface.co/agicorp","description":"agicorp/Text-to-sql-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"pecc","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PatrickHaller/pecc","creator_name":"Patrick Haller","creator_url":"https://huggingface.co/PatrickHaller","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\nCurated by: Patrick Haller\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PatrickHaller/pecc."},
	{"name":"EvoEval_difficult","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/evoeval/EvoEval_difficult","creator_name":"EvoEval","creator_url":"https://huggingface.co/evoeval","description":"evoeval/EvoEval_difficult dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"OpenCerebrum-SFT","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/OpenCerebrum-SFT","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenCerebrum SFT subset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nOpenCerebrum is my take on creating an open source version of Aether Research's proprietary Cerebrum dataset. This repository contains the SFT subset, which contains about 1,200,00 examples. Unfortunately, I was unsure about how I would compress this dataset to just 5,000 examples like in the original Cerebrum dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration\\n\\t\\n\\nThis dataset was curated using a simple and logical rationale. The goal was to use‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/OpenCerebrum-SFT."},
	{"name":"EvoEval_creative","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/evoeval/EvoEval_creative","creator_name":"EvoEval","creator_url":"https://huggingface.co/evoeval","description":"evoeval/EvoEval_creative dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"EvoEval_combine","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/evoeval/EvoEval_combine","creator_name":"EvoEval","creator_url":"https://huggingface.co/evoeval","description":"evoeval/EvoEval_combine dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"EvoEval_subtle","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/evoeval/EvoEval_subtle","creator_name":"EvoEval","creator_url":"https://huggingface.co/evoeval","description":"evoeval/EvoEval_subtle dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"EvoEval_tool_use","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/evoeval/EvoEval_tool_use","creator_name":"EvoEval","creator_url":"https://huggingface.co/evoeval","description":"evoeval/EvoEval_tool_use dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"harry_potter_conversational","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/krinal/harry_potter_conversational","creator_name":"Krinal Joshi","creator_url":"https://huggingface.co/krinal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset: Harry potter conversational text corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThis corpus contains conversational data in text format\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\n\\ntext classification\\ntoken classification\\nquestion answering\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguage\\n\\t\\n\\nen\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\napache 2.0\\n"},
	{"name":"aiysha-diction","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rofyray/aiysha-diction","creator_name":"Rofy Ray","creator_url":"https://huggingface.co/rofyray","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAIySha: yShade.AI AI Agent\\n\\t\\n\\nThis is the base dataset for customizing the diction of the bot backed by llama-2-7b-chat model.\\nThe dataset needs to be reformatted to fit the prompt template for the chat model in order to use for fine tuning purposes.\\nThe goal of the dataset is to train the model to be specialized as a beauty advisor.\\n"},
	{"name":"aiysha-diction-500","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rofyray/aiysha-diction-500","creator_name":"Rofy Ray","creator_url":"https://huggingface.co/rofyray","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAIySha: yShade.AI AI Agent\\n\\t\\n\\nThis is the formatted dataset for customizing the diction of the bot backed by llama-2-7b-chat model.\\nThe dataset fits the prompt template for the chat model and is ready to be used for fine tuning purposes.\\nThe goal of the dataset is to train the model to be specialized as a beauty advisor.\\n"},
	{"name":"CodeAlpaca-20K-Python","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/graycatHCO3/CodeAlpaca-20K-Python","creator_name":"graycat","creator_url":"https://huggingface.co/graycatHCO3","description":"graycatHCO3/CodeAlpaca-20K-Python dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CodeAlpaca-20K-Python","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/graycatHCO3/CodeAlpaca-20K-Python","creator_name":"graycat","creator_url":"https://huggingface.co/graycatHCO3","description":"graycatHCO3/CodeAlpaca-20K-Python dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"raw_data","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SilvioLima/raw_data","creator_name":"Silvio  Lima","creator_url":"https://huggingface.co/SilvioLima","description":"\\n"},
	{"name":"text-to-neo4j-cypher-chinese","keyword":"code","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Doraemon-AI/text-to-neo4j-cypher-chinese","creator_name":"AnitaSherry","creator_url":"https://huggingface.co/Doraemon-AI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÂä®Êú∫\\n\\t\\n\\nÈöèÁùÄ‰ø°ÊÅØÈáèÁöÑ‰∏çÊñ≠Â¢ûÂä†ÂíåÊäÄÊúØÁöÑËøõÊ≠•ÔºåÊàë‰ª¨ÁöÑÁ§æ‰ºöÊ≠£Âú®ÈÄêÊ∏êÂΩ¢Êàê‰∏Ä‰∏™Â∫ûÂ§ßËÄåÂ§çÊùÇÁöÑÁΩëÁªú„ÄÇÈöèÁùÄÂ§ßÊï∞ÊçÆÊó∂‰ª£ÁöÑÂà∞Êù•ÔºåÂçäÁªìÊûÑÂåñÂíåÈùûÁªìÊûÑÂåñÁöÑÊï∞ÊçÆÊ†ºÂºèË∂äÊù•Ë∂äÂ§ö„ÄÇ Ôºå‰º†ÁªüÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ìÈöæ‰ª•ÊúâÊïàÂ§ÑÁêÜËøô‰∫õÊï∞ÊçÆÔºåËÄåÂõæÊï∞ÊçÆÂ∫ìËÉΩÂ§üÊõ¥ÁÅµÊ¥ªÂú∞Â≠òÂÇ®ÂíåÊü•ËØ¢Ê≠§Á±ªÁ±ªÂûãÁöÑÊï∞ÊçÆÔºåNeo4jÂ∞±ÊòØÂÖ∂‰∏≠ÊúÄÊµÅË°åÁöÑ‰∫ßÂìÅ‰πã‰∏Ä\\n‰ΩÜÊòØ Neo4j ÁöÑÊü•ËØ¢ËØ≠Ë®Ä Cypher ÂèØ‰ª•ÂÆûÁé∞ÂØπÂõæÁöÑÈ´òÊïàÊü•ËØ¢„ÄÇCypher ÁöÑÂ§çÊùÇÊìç‰ΩúÂíåËØ≠Ê≥ïÂØπÁî®Êà∑ÁöÑÂ≠¶‰π†ÊàêÊú¨Ë¶ÅÊ±ÇÂêåÊ†∑È´ò„ÄÇÂõ†Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫Âπ∂ÂÆö‰πâ‰∫Ü‰∏ÄÁßçÁ±ª‰ººText-to-SQLÁöÑÊñ∞‰ªªÂä°Text-to-Neo4j-Cypher\\nText-to-Neo4j-CypherÊòØ‰∏ÄÁßçÊñ∞ÁöÑËØ≠‰πâËß£Êûê‰ªªÂä°ÔºåÂç≥Â∞ÜÁî®Êà∑ÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÊü•ËØ¢ËΩ¨Âåñ‰∏∫‰∏∫Neo4j-CypherqueryÔºå‰ª•Â∏ÆÂä©Èôç‰ΩéÁî®Êà∑ÁöÑÂ≠¶‰π†Âíå‰ΩøÁî®ÊàêÊú¨ÔºåÊèêÂçáÂõæÊï∞ÊçÆÂ∫ì‰∏éÁî®Êà∑ÁöÑ‰∫§‰∫íÁ®ãÂ∫¶\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t‰∫ÆÁÇπ\\n\\t\\n\\n1„ÄÅÊèêÂá∫Âπ∂Ê≠£ÂºèÂÆö‰πâ‰∫Ü Text-to-Neo4j-Cypher ‰ªªÂä°ÔºåËØ•‰ªªÂä°ÁöÑÁõÆÁöÑÊòØÂ∞ÜÁî®Êà∑Ëá™ÁÑ∂ËØ≠Ë®ÄÊü•ËØ¢Ëá™Âä®ËΩ¨Âåñ‰∏∫ Neo4j-Cypher Êü•ËØ¢ÔºåÈôç‰ΩéÂõæÊï∞ÊçÆÂ∫ì‰∏éÁî®Êà∑‰∫§‰∫íÁöÑÂ≠¶‰π†Âíå‰ΩøÁî®ÊàêÊú¨\\n2„ÄÅÂØπÂèÇËÄÉÊñáÁåÆ‰∏≠ÁöÑÊï∞ÊçÆËøõË°å‰∫ÜÊîπËøõÔºå‰ª•ÈÄÇÂ∫îLLMÁöÑËÆ≠ÁªÉ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Doraemon-AI/text-to-neo4j-cypher-chinese."},
	{"name":"Code-Feedback-decontamination","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Leon-Leee/Code-Feedback-decontamination","creator_name":"Leon Lee","creator_url":"https://huggingface.co/Leon-Leee","description":"A decontaminated version of m-a-p/Code-Feedback. \\nThe excluded (28) files are \\\"contaminated\\\" with only two code segments: \\n\\nsimple GCD function: while b: a, b = b, a % b return a\\nsum_to_n solution: return sum(range(n + 1))\\n\\nAnd reformated to sharegpt.\\nDecontamination is done in the same way as Magicoder (ie., bigcode decontamination process), which uses a substring-match-finding method to find overlaps between a target dataset and the following standard benchmarks:\\n\\nHumanEval\\nMBPP‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Leon-Leee/Code-Feedback-decontamination."},
	{"name":"Xerxes-Instruct-700K","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Instinct-AI/Xerxes-Instruct-700K","creator_name":"Instinct-AI","creator_url":"https://huggingface.co/Instinct-AI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Xerxes-Instruct-700K\\\"\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nXerxes, named after a Persian King renowned for his wisdom and strategic prowess, is an amalgamation of four distinct datasets. This dataset has been curated to cater to the burgeoning needs of natural language processing tasks, particularly in the domain of conversation modeling and comprehension.\\nThe dataset encompasses conversations sourced from a variety of sources, ranging from generative models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Instinct-AI/Xerxes-Instruct-700K."},
	{"name":"WizardLM_evol_instruct_V2_only_code","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Leon-Leee/WizardLM_evol_instruct_V2_only_code","creator_name":"Leon Lee","creator_url":"https://huggingface.co/Leon-Leee","description":"filtered from (WizardLM/WizardLM_evol_instruct_V2_196k)[https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k] using \\\"```\\\"\\n"},
	{"name":"ptbr-deita-8k","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botbot-ai/ptbr-deita-8k","creator_name":"BotBot","creator_url":"https://huggingface.co/botbot-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\tPTBR Deita 8k\\n\\t\\n\\nPortuguese translation of the Deita 8k dataset. \\n"},
	{"name":"urv_test","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/elmambru/urv_test","creator_name":"Albert Garcia Bernat","creator_url":"https://huggingface.co/elmambru","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/elmambru/urv_test."},
	{"name":"glaive-code-assistant-v3","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pharaouk/glaive-code-assistant-v3","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGlaive-code-assistant-v2\\n\\t\\n\\nGlaive-code-assistant-v2 is a dataset of ~1M code problems and solutions generated using Glaive‚Äôs synthetic data generation platform.\\nThis is built on top of the previous version of the dataset that can be found here. This already includes v1 and v2 of the dataset.\\nTo report any problems or suggestions in the data, join the Glaive discord\\n"},
	{"name":"glaive-code-assistant-v2","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pharaouk/glaive-code-assistant-v2","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGlaive-code-assistant-v2\\n\\t\\n\\nGlaive-code-assistant-v2 is a dataset of ~215k code problems and solutions generated using Glaive‚Äôs synthetic data generation platform.\\nThis is built on top of the previous version of the dataset that can be found here\\nTo report any problems or suggestions in the data, join the Glaive discord\\n"},
	{"name":"wangwei","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/guilty1987/wangwei","creator_name":"FAN","creator_url":"https://huggingface.co/guilty1987","description":"guilty1987/wangwei dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CodeEditSearch","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cassanof/CodeEditSearch","creator_name":"Federico Cassano","creator_url":"https://huggingface.co/cassanof","description":"This is a dataset built from CommitPackFT, providing ~1500 commits with diffs for several programming languages:\\n\\nPython\\nJavaScript\\nTypeScript\\nGo\\nRuby\\nJava\\nPHP\\nC\\nC++\\nRust\\nSwift\\nScala\\nBash\\n\\nThe goal of this dataset is to evaluate the ability of models to retrieve a diff given its instruction.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode To Produce Dataset\\n\\t\\n\\nBelow is the code to reproduce this dataset:\\nimport datasets\\nfrom tqdm import tqdm\\nimport difflib\\n\\n\\noutrepo = \\\"cassanof/CodeEditSearch\\\"\\nLANGS = [\\\"python\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cassanof/CodeEditSearch."},
	{"name":"spam_ham_spanish","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/softecapps/spam_ham_spanish","creator_name":"softecapps","creator_url":"https://huggingface.co/softecapps","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAn√°lisis de Dataset de Mensajes de Texto\\n\\t\\n\\nEste dataset contiene un total de 1000 mensajes de texto en espa√±ol, junto con una etiqueta que indica si el mensaje es considerado \\\"spam\\\" o \\\"ham\\\" (leg√≠timo).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tComposici√≥n del Dataset\\n\\t\\n\\nEl dataset est√° compuesto por dos columnas:\\nMensaje: Contiene el texto del mensaje.\\nEtiqueta: Indica si el mensaje es \\\"spam\\\" o \\\"ham\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPotenciales Usos\\n\\t\\n\\nEste dataset puede ser utilizado para entrenar modelos de Machine Learning con‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/softecapps/spam_ham_spanish."},
	{"name":"alpaca-cleaned-gpt4-turbo","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mylesgoose/alpaca-cleaned-gpt4-turbo","creator_name":"myles bruce","creator_url":"https://huggingface.co/mylesgoose","description":"I downloaded the dataset from Alpaca at https://huggingface.co/datasets/yahma/alpaca-cleaned and processed it using a script to convert the text to hashes. I removed any duplicate hashes along with their corresponding input and output columns. Subsequently, I utilized the GPT-4 Turbo API to feed each message, instruction, and input to the model for generating responses.\\nHere are the outputs generated by the GPT-4 Turbo model. The information in the input column and instruction column should be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mylesgoose/alpaca-cleaned-gpt4-turbo."},
	{"name":"sql-create-context-thai","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saksornr/sql-create-context-thai","creator_name":"Saksorn Ruangtanusak","creator_url":"https://huggingface.co/saksornr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from sql-create-context.\\n@misc{b-mc2_2023_sql-create-context,\\n  title   = {sql-create-context Dataset},\\n  author  = {b-mc2}, \\n  year    = {2023},\\n  url     = {https://huggingface.co/datasets/b-mc2/sql-create-context},\\n  note    = {This dataset was created by modifying data from the following sources: \\\\cite{zhongSeq2SQL2017, yu2018spider}.},\\n}\\n\\n"},
	{"name":"MathCodeInstruct","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MathLLMs/MathCodeInstruct","creator_name":"LLMs for Math Reasoning","creator_url":"https://huggingface.co/MathLLMs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning\\n\\t\\n\\nPaper: https://arxiv.org/pdf/2310.03731.pdf\\nRepo: https://github.com/mathllm/MathCoder\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce MathCoder, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving.\\n\\n\\t\\n\\t\\t\\nBase Model: Llama-2\\nBase Model: Code Llama\\n\\n\\n\\t\\t\\nMathCoder-L-7B\\nMathCoder-CL-7B\\n\\n\\nMathCoder-L-13B\\nMathCoder-CL-34B\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTraining Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathCodeInstruct."},
	{"name":"BanglaEnglishMixedAsrDataset","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/akhikhan123/BanglaEnglishMixedAsrDataset","creator_name":"Fatema Tuz Zohra Akhi","creator_url":"https://huggingface.co/akhikhan123","description":"akhikhan123/BanglaEnglishMixedAsrDataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sql-create-context-thai","keyword":"context-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saksornr/sql-create-context-thai","creator_name":"Saksorn Ruangtanusak","creator_url":"https://huggingface.co/saksornr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from sql-create-context.\\n@misc{b-mc2_2023_sql-create-context,\\n  title   = {sql-create-context Dataset},\\n  author  = {b-mc2}, \\n  year    = {2023},\\n  url     = {https://huggingface.co/datasets/b-mc2/sql-create-context},\\n  note    = {This dataset was created by modifying data from the following sources: \\\\cite{zhongSeq2SQL2017, yu2018spider}.},\\n}\\n\\n"},
	{"name":"sql-create-context-thai","keyword":"sqlglot","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saksornr/sql-create-context-thai","creator_name":"Saksorn Ruangtanusak","creator_url":"https://huggingface.co/saksornr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from sql-create-context.\\n@misc{b-mc2_2023_sql-create-context,\\n  title   = {sql-create-context Dataset},\\n  author  = {b-mc2}, \\n  year    = {2023},\\n  url     = {https://huggingface.co/datasets/b-mc2/sql-create-context},\\n  note    = {This dataset was created by modifying data from the following sources: \\\\cite{zhongSeq2SQL2017, yu2018spider}.},\\n}\\n\\n"},
	{"name":"sql-create-context-thai","keyword":"wikisql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saksornr/sql-create-context-thai","creator_name":"Saksorn Ruangtanusak","creator_url":"https://huggingface.co/saksornr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from sql-create-context.\\n@misc{b-mc2_2023_sql-create-context,\\n  title   = {sql-create-context Dataset},\\n  author  = {b-mc2}, \\n  year    = {2023},\\n  url     = {https://huggingface.co/datasets/b-mc2/sql-create-context},\\n  note    = {This dataset was created by modifying data from the following sources: \\\\cite{zhongSeq2SQL2017, yu2018spider}.},\\n}\\n\\n"},
	{"name":"sql-create-context-thai","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saksornr/sql-create-context-thai","creator_name":"Saksorn Ruangtanusak","creator_url":"https://huggingface.co/saksornr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from sql-create-context.\\n@misc{b-mc2_2023_sql-create-context,\\n  title   = {sql-create-context Dataset},\\n  author  = {b-mc2}, \\n  year    = {2023},\\n  url     = {https://huggingface.co/datasets/b-mc2/sql-create-context},\\n  note    = {This dataset was created by modifying data from the following sources: \\\\cite{zhongSeq2SQL2017, yu2018spider}.},\\n}\\n\\n"},
	{"name":"sql-create-context-thai","keyword":"sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saksornr/sql-create-context-thai","creator_name":"Saksorn Ruangtanusak","creator_url":"https://huggingface.co/saksornr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from sql-create-context.\\n@misc{b-mc2_2023_sql-create-context,\\n  title   = {sql-create-context Dataset},\\n  author  = {b-mc2}, \\n  year    = {2023},\\n  url     = {https://huggingface.co/datasets/b-mc2/sql-create-context},\\n  note    = {This dataset was created by modifying data from the following sources: \\\\cite{zhongSeq2SQL2017, yu2018spider}.},\\n}\\n\\n"},
	{"name":"sql-create-context-thai","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saksornr/sql-create-context-thai","creator_name":"Saksorn Ruangtanusak","creator_url":"https://huggingface.co/saksornr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from sql-create-context.\\n@misc{b-mc2_2023_sql-create-context,\\n  title   = {sql-create-context Dataset},\\n  author  = {b-mc2}, \\n  year    = {2023},\\n  url     = {https://huggingface.co/datasets/b-mc2/sql-create-context},\\n  note    = {This dataset was created by modifying data from the following sources: \\\\cite{zhongSeq2SQL2017, yu2018spider}.},\\n}\\n\\n"},
	{"name":"ds1000","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/claudios/ds1000","creator_name":"Claudio Spiess","creator_url":"https://huggingface.co/claudios","description":"This is a reupload of DS-1000. The metadata dictionary has been extracted into columns and the categorical variables are now ClassLabel types, and the dataset is natively a parquet. The features are as follows:\\n\\n\\t\\n\\t\\t\\nColumn\\nType\\n\\n\\n\\t\\t\\nproblem_id\\nValue(dtype='int64', id=None)\\n\\n\\nprompt\\nValue(dtype='string', id=None)\\n\\n\\nreference_code\\nValue(dtype='string', id=None)\\n\\n\\ncode_context\\nValue(dtype='string', id=None)\\n\\n\\nlibrary_problem_id\\nValue(dtype='int64', id=None)\\n\\n\\nlibrary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/claudios/ds1000."},
	{"name":"synthetic-text2cypher-gpt4turbo","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tomasonjo/synthetic-text2cypher-gpt4turbo","creator_name":"Toma≈æ Brataniƒç","creator_url":"https://huggingface.co/tomasonjo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic dataset created with GPT-4-Turbo\\n\\t\\n\\nSynthetic dataset of text2cypher over 16 different graph schemas.\\nBoth questions and cypher queries were generated using GPT-4-turbo.\\nThe demo database is available at:\\nURI: neo4j+s://demo.neo4jlabs.com\\nusername: name of the database, for example 'movies'\\npassword: name of the database, for example 'movies'\\ndatabase: name of the database, for example 'movies'\\n\\nNotebooks:\\n\\ngenerate_text2cypher_questions.ipynb: Generate questions and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tomasonjo/synthetic-text2cypher-gpt4turbo."},
	{"name":"verilog-wavedrom","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vkenbeek/verilog-wavedrom","creator_name":"Vincent","creator_url":"https://huggingface.co/vkenbeek","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVerilog Wavedrom\\n\\t\\n\\n\\n\\nA combination of verilog modules and their correspondig timing diagrams generated by wavedrom.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\nA collection of wavedrom timing diagrams in PNG format representing verilog modules.\\nThe Verilog modules were copied from shailja/Verilog_GitHub.The timing diagrams were generated by first generating testbenches for the individual verilog modules through the Verilog Testbench Generator from EDA Utils VlogTBGen.The resulting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vkenbeek/verilog-wavedrom."},
	{"name":"Select-Stack","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/H-D-T/Select-Stack","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Select-Stack."},
	{"name":"unstacked","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/H-D-T/unstacked","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/unstacked."},
	{"name":"Pangpuriye-public_alpaca-cleaned","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIAT/Pangpuriye-public_alpaca-cleaned","creator_name":"Artificial Intelligence Association of Thailand","creator_url":"https://huggingface.co/AIAT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü§ñ Super AI Engineer Development Program Season 4 - Pangpuriye House - Alpaca-Cleaned\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOriginal Dataset\\n\\t\\n\\nWe adopt this alpaca-cleaned dataset from https://huggingface.co/datasets/yahma/alpaca-cleaned the original repository. We used this dataset during the fine-tuning of Panguriye's LLM. The dataset is available under the Creative Commons Non Commercial (CC BY-NC 4.0). \\nThe original dataset consists of 51,760 rows of input, instruction, and output in English. \\nWe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AIAT/Pangpuriye-public_alpaca-cleaned."},
	{"name":"ds1000","keyword":"code-generation","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/claudios/ds1000","creator_name":"Claudio Spiess","creator_url":"https://huggingface.co/claudios","description":"This is a reupload of DS-1000. The metadata dictionary has been extracted into columns and the categorical variables are now ClassLabel types, and the dataset is natively a parquet. The features are as follows:\\n\\n\\t\\n\\t\\t\\nColumn\\nType\\n\\n\\n\\t\\t\\nproblem_id\\nValue(dtype='int64', id=None)\\n\\n\\nprompt\\nValue(dtype='string', id=None)\\n\\n\\nreference_code\\nValue(dtype='string', id=None)\\n\\n\\ncode_context\\nValue(dtype='string', id=None)\\n\\n\\nlibrary_problem_id\\nValue(dtype='int64', id=None)\\n\\n\\nlibrary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/claudios/ds1000."},
	{"name":"Pangpuriye-public_alpaca-cleaned","keyword":"sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIAT/Pangpuriye-public_alpaca-cleaned","creator_name":"Artificial Intelligence Association of Thailand","creator_url":"https://huggingface.co/AIAT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü§ñ Super AI Engineer Development Program Season 4 - Pangpuriye House - Alpaca-Cleaned\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOriginal Dataset\\n\\t\\n\\nWe adopt this alpaca-cleaned dataset from https://huggingface.co/datasets/yahma/alpaca-cleaned the original repository. We used this dataset during the fine-tuning of Panguriye's LLM. The dataset is available under the Creative Commons Non Commercial (CC BY-NC 4.0). \\nThe original dataset consists of 51,760 rows of input, instruction, and output in English. \\nWe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AIAT/Pangpuriye-public_alpaca-cleaned."},
	{"name":"HuixiangDou-CR","keyword":"code","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/tpoisonooo/HuixiangDou-CR","creator_name":"HuanjunKong","creator_url":"https://huggingface.co/tpoisonooo","description":"tpoisonooo/HuixiangDou-CR dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"leetcode_with_youtube_captions","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LimYeri/leetcode_with_youtube_captions","creator_name":"LimYeri","creator_url":"https://huggingface.co/LimYeri","description":""},
	{"name":"fr-summarizer-dataset","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Labagaite/fr-summarizer-dataset","creator_name":"Derue","creator_url":"https://huggingface.co/Labagaite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttraining data\\n\\t\\n\\n\\nDataset : fr-summarizer-dataset\\nData-size : 7.65 MB\\ntrain : 1.97k rows\\nvalidation : 440 rows\\nroles : user , assistant\\nFormat chatml \\\"role\\\": \\\"role\\\", \\\"content\\\": \\\"content\\\", \\\"user\\\": \\\"user\\\", \\\"assistant\\\": \\\"assistant\\\"\\n*French audio podcast transcription*\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProject details\\n\\t\\n\\n\\nFine-tuned on French audio podcast transcription data for summarization task. As a result, the model is able to summarize French audio podcast transcription data.\\nThe model will be used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Labagaite/fr-summarizer-dataset."},
	{"name":"DiagGSM8K","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pharaouk/DiagGSM8K","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"View the project page:\\nhttps://github.com/dvlab-research/DiagGSM8K\\nsee our paper at https://arxiv.org/abs/2312.17080\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nIn this work, we introduce a novel evaluation paradigm for Large Language Models, \\none that challenges them to engage in meta-reasoning. Our paradigm shifts the focus from result-oriented assessments, \\nwhich often overlook the reasoning process, to a more holistic evaluation that effectively differentiates \\nthe cognitive capabilities among models. For‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/DiagGSM8K."},
	{"name":"fake_voices","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unfake/fake_voices","creator_name":"Unfake","creator_url":"https://huggingface.co/unfake","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Fake Voices\\n\\t\\n\\nThis dataset contains deepfakes in Brazilian Portuguese created with XTTS model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe dataset was created using the XTTS model, which is a Text-to-Speech model pre-trained in several languages including Portuguese. \\nIn order to generate the mentioned deepfakes, the model was fed with recordings from the CETUC Corpus, \\nmade available by Fala Brasil Group. It contains speeches from 101 speakers, totaling 140 hours of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unfake/fake_voices."},
	{"name":"table_rec_test_dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SWHL/table_rec_test_dataset","creator_name":"SWHL","creator_url":"https://huggingface.co/SWHL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tË°®Ê†ºËØÜÂà´ÊµãËØïÈõÜ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÈõÜÁÆÄ‰ªã\\n\\t\\n\\n\\nÂåÖÂê´ÁôæÂ∫¶ÁîüÊàêÂ∑•ÂÖ∑ 20Âº†ÊúâÁ∫ø20Âº†Êó†Á∫øÔºåwtwÊï∞ÊçÆÈõÜ15, pubnet valÈõÜ20Âº†ÔºåËá™ÊàëÈõ∂Êï£Ê†áÊ≥®18Âº†ÔºåÂÖ±ËÆ°93Âº†Ë°®Ê†ºÂõæÁâá,Ê∂µÁõñÂ§öÁßçÂú∫ÊôØ„ÄÅ‰∏çÂêåÂÖâÁÖßÊù°‰ª∂„ÄÅ‰∏çÂêåÁöÑÂõæÂÉèÂàÜËæ®Áéá„ÄÇ\\nËØ•Êï∞ÊçÆÈõÜÂèØ‰ª•ÁªìÂêàË°®Ê†ºÊåáÊ†áËØÑÊµãÂ∫ì-TableRecognitionMetric‰ΩøÁî®ÔºåÂø´ÈÄüËØÑÊµãÂêÑÁßçË°®Ê†ºËøòÂéüÁÆóÊ≥ï„ÄÇ\\nÂÖ≥‰∫éËØ•Êï∞ÊçÆÈõÜÔºåÊ¨¢ËøéÂ∞è‰ºô‰º¥Ë¥°ÁåÆÊõ¥Â§öÊï∞ÊçÆÂë¶ÔºÅÊúâ‰ªª‰ΩïÊÉ≥Ê≥ïÔºåÂèØ‰ª•ÂâçÂæÄissueËÆ®ËÆ∫„ÄÇ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÈõÜÊîØÊåÅÁöÑ‰ªªÂä°\\n\\t\\n\\nÂèØÁî®‰∫éËá™ÂÆö‰πâÊï∞ÊçÆÈõÜ‰∏ãÁöÑÊ®°ÂûãÈ™åËØÅÂíåÊÄßËÉΩËØÑ‰º∞Á≠â„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÈõÜÁöÑÊ†ºÂºèÂíåÁªìÊûÑ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÊ†ºÂºè\\n\\t\\n\\nÊï∞ÊçÆÈõÜÂè™ÊúâÊµãËØïÈõÜÔºå‰ªÖÁî®‰∫éÂÆ¢ËßÇËØÑ‰º∞ÁÆóÊ≥ïË°®Áé∞„ÄÇ\\ndata\\n‚îî‚îÄ‚îÄ test\\n    ‚îú‚îÄ‚îÄ 000cce9ca593055d4618466e823e6d7c.jpg\\n    ‚îú‚îÄ‚îÄ 0aNtiNtRRLqEZ9y6PuShtAAAACMAAQED.jpg\\n    ‚îú‚îÄ‚îÄ 116d6b07ecfdae7721bd6bbf31031c1a.jpg‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SWHL/table_rec_test_dataset."},
	{"name":"LeetCode_with_Solutions","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LimYeri/LeetCode_with_Solutions","creator_name":"LimYeri","creator_url":"https://huggingface.co/LimYeri","description":"datasets:\\n\\n[LimYeri/LeetCode_YT_CC_CoT_Summary] (https://huggingface.co/datasets/LimYeri/LeetCode_YT_CC_CoT_Summary)\\n[kreimben/leetcode_user_submissions] (https://huggingface.co/datasets/kreimben/leetcode_user_submissions)\\n[greengerong/leetcode] (https://huggingface.co/datasets/greengerong/leetcode)\\n\\n"},
	{"name":"cli-commands-explained","keyword":"code","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/b-mc2/cli-commands-explained","creator_name":"brianm","creator_url":"https://huggingface.co/b-mc2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is a collection of 16,098 command line instructions sourced from Commandlinefu and Cheatsheets. It includes an array of commands, each with an id, title, description, date, url to source, author, votes, and flag indicating if the description is AI generated. The descriptions are primarily authored by the original contributors, for entries where descriptions were absent, they have been generated using NeuralBeagle14-7B. Out of the total entries, 10,039‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/b-mc2/cli-commands-explained."},
	{"name":"OpenCerebrum-2.0-SFT","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/OpenCerebrum-2.0-SFT","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenCerebrum SFT subset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nOpenCerebrum is my take on creating an open source version of Aether Research's proprietary Cerebrum dataset. This repository contains the SFT subset, which contains about 6,400 examples. To compress this dataset to such a small size, I used an in-house curation technique at Cognitive Computations. More information about this technique will come in the future. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration\\n\\t\\n\\nAs mentioned earlier, I used an in-house‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/OpenCerebrum-2.0-SFT."},
	{"name":"OpenCerebrum-2.0-DPO","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/OpenCerebrum-2.0-DPO","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenCerebrum DPO subset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nOpenCerebrum is my take on creating an open source version of Aether Research's proprietary Cerebrum dataset. This repository contains the DPO subset, which contains about 720 examples. To compress this dataset to such a small size, I used an in-house curation technique at Cognitive Computations. More information about this technique will come in the future. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration\\n\\t\\n\\nAs mentioned earlier, I used an in-house‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/OpenCerebrum-2.0-DPO."},
	{"name":"cpp-code-code_search_net-style","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/malteklaes/cpp-code-code_search_net-style","creator_name":"Malte Klaes","creator_url":"https://huggingface.co/malteklaes","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tC++ Dataset\\n\\t\\n\\n\\ndocumentation source: https://huggingface.co/docs/datasets/main/en/repository_structure\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nlanguage-modeling: The dataset can be used to train a model for modelling programming languages, which consists in building language models for programming languages.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguage\\n\\t\\n\\n\\nC++ programming language\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nA data point consists of a function code along‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malteklaes/cpp-code-code_search_net-style."},
	{"name":"OGText2SQL","keyword":"sql","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/OneGate/OGText2SQL","creator_name":"OneGate","creator_url":"https://huggingface.co/OneGate","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nOGText2SQL dataset was utilized in training the OGSQL model, this dataset comprises over 350,000 rows of text-to-SQL pairs. Through a series of data refining steps, including schema expansion, SQL refinement, and instruction generation using existing Language Models (LLMs), the dataset was meticulously processed to ensure quality and relevance.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use it\\n\\t\\n\\n\\nPython\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"OneGate/OGText2SQL\\\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OneGate/OGText2SQL."},
	{"name":"ultra-feedback-js-instruct","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DigitalClockwork/ultra-feedback-js-instruct","creator_name":"Digital Clockwork","creator_url":"https://huggingface.co/DigitalClockwork","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUltra Feedback JS Instruct\\n\\t\\n\\nA subset of the wonderful and elegant Ultra Feedback dataset. Ratings are 1-5 ( inclusive )\\nGeneration Notebook\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample\\n\\t\\n\\n{\\n    \\\"inst\\\": \\\"Refine the subsequent JavaScript code snippet to obtain the cumulative total of elements within an array:\\\\nlet numbers = [1, 2, 3]\\\",\\n    \\\"author\\\": \\\"codellama-34b-instruct\\\",\\n    \\\"fun\\\": \\\"let numbers = [1, 2, 3];\\\\nlet total = numbers.reduce((a, b) => a + b);\\\\nconsole.log(total); // Output: 6\\\",\\n    \\\"rating\\\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DigitalClockwork/ultra-feedback-js-instruct."},
	{"name":"text_rec_test_dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SWHL/text_rec_test_dataset","creator_name":"SWHL","creator_url":"https://huggingface.co/SWHL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊñáÊú¨ËØÜÂà´ÊµãËØïÈõÜ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÈõÜÁÆÄ‰ªã\\n\\t\\n\\n\\nËØ•ÊµãËØïÈõÜÂåÖÊã¨8Á±ªÂú∫ÊôØÔºåÂàÜÂà´ÊòØÁ´ñÊéíÊñáÂ≠ó„ÄÅÈïøÊñáÊú¨„ÄÅÂçïÂ≠ó„ÄÅÈ™åËØÅÁ†Å„ÄÅËá™ÁÑ∂Âú∫ÊôØ„ÄÅÈì∂Ë°åÂç°„ÄÅÊâãÂÜô‰ΩìÂíåËΩ¶ÁâåÁ≠â„ÄÇ\\nËØ•Êï∞ÊçÆÈõÜÂèØ‰ª•ÁªìÂêàÊñáÊú¨ËØÜÂà´ÊåáÊ†áËØÑÊµãÂ∫ì-TextRecMetric‰ΩøÁî®ÔºåÂø´ÈÄüËØÑÊµãÂêÑÁßçÊñáÊú¨ËØÜÂà´ÁÆóÊ≥ï„ÄÇ\\nÂÖ≥‰∫éËØ•Êï∞ÊçÆÈõÜÔºåÊ¨¢ËøéÂ∞è‰ºô‰º¥Ë¥°ÁåÆÊõ¥Â§öÊï∞ÊçÆÂë¶ÔºÅÊúâ‰ªª‰ΩïÊÉ≥Ê≥ïÔºåÂèØ‰ª•ÂâçÂæÄissueËÆ®ËÆ∫„ÄÇ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÈõÜÊîØÊåÅÁöÑ‰ªªÂä°\\n\\t\\n\\nÂèØÁî®‰∫éËá™ÂÆö‰πâÊï∞ÊçÆÈõÜ‰∏ãÁöÑÊ®°ÂûãÈ™åËØÅÂíåÊÄßËÉΩËØÑ‰º∞Á≠â„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÈõÜÂä†ËΩΩÊñπÂºè\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"SWHL/text_rec_test_dataset\\\")\\n\\ntest_data = dataset['test']\\nprint(test_data)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÈõÜÁîüÊàêÁöÑÁõ∏ÂÖ≥‰ø°ÊÅØ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÂéüÂßãÊï∞ÊçÆ\\n\\t\\n\\nÊï∞ÊçÆÊù•Ê∫ê‰∫éÁΩëÁªúÔºåÂ¶Ç‰æµÂà†„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÂêÑ‰∏™Á±ªÂà´Êï∞ÁõÆÂ¶Ç‰∏ã\\n\\t\\n\\nÁ´ñÊéíÊñáÂ≠ó : 14\\nÈïøÊñáÊú¨ : 18\\nÂçïÂ≠ó : 115‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SWHL/text_rec_test_dataset."},
	{"name":"jina-embeddings-v2-base-code-562024-xbuk-webapp","keyword":"coding","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-xbuk-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-code-562024-xbuk-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Documentation search for programming language\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-code-562024-xbuk-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-xbuk-webapp."},
	{"name":"jina-embeddings-v2-base-code-562024-xbuk-webapp","keyword":"development","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-xbuk-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-code-562024-xbuk-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Documentation search for programming language\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-code-562024-xbuk-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-xbuk-webapp."},
	{"name":"jina-embeddings-v2-base-code-562024-xbuk-webapp","keyword":"programming","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-xbuk-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-code-562024-xbuk-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Documentation search for programming language\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-code-562024-xbuk-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-xbuk-webapp."},
	{"name":"jina-embeddings-v2-base-code-562024-j4ar-webapp","keyword":"programming","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-j4ar-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-code-562024-j4ar-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"software documentation\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-code-562024-j4ar-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-j4ar-webapp."},
	{"name":"jina-embeddings-v2-base-code-06052024-mhal-webapp","keyword":"programming","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-mhal-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-code-06052024-mhal-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"software documentation search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-code-06052024-mhal-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-mhal-webapp."},
	{"name":"jina-embeddings-v2-base-code-562024-xbuk-webapp","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-xbuk-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-code-562024-xbuk-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Documentation search for programming language\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-code-562024-xbuk-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-xbuk-webapp."},
	{"name":"jina-embeddings-v2-base-code-562024-j4ar-webapp","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-j4ar-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-code-562024-j4ar-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"software documentation\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-code-562024-j4ar-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-562024-j4ar-webapp."},
	{"name":"jina-embeddings-v2-base-code-06052024-mhal-webapp","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-mhal-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-code-06052024-mhal-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"software documentation search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-code-06052024-mhal-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-code-06052024-mhal-webapp."},
	{"name":"INHA_Titres_CatVentes","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JulietteBenguigui142/INHA_Titres_CatVentes","creator_name":"Juliette Benguigui","creator_url":"https://huggingface.co/JulietteBenguigui142","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JulietteBenguigui142/INHA_Titres_CatVentes."},
	{"name":"jina-embeddings-v2-base-en-572024-xg53-webapp","keyword":"coding","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-572024-xg53-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-en-572024-xg53-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"scripting language documentation\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-en-572024-xg53-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-572024-xg53-webapp."},
	{"name":"coding","keyword":"coding","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/coding","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcoding Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"coding tutorials\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the coding model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import load_dataset\\n\\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/coding."},
	{"name":"coding","keyword":"development","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/coding","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcoding Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"coding tutorials\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the coding model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import load_dataset\\n\\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/coding."},
	{"name":"test","keyword":"linux","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/test","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttest Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"technical support forum for Ubuntu\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the test model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import load_dataset\\n\\ndataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/test."},
	{"name":"very_specific_technical_questions_about_Ubuntu","keyword":"linux","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/very_specific_technical_questions_about_Ubuntu","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tvery_specific_technical_questions_about_Ubuntu Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"technical support search for Ubuntu\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the very_specific_technical_questions_about_Ubuntu model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/very_specific_technical_questions_about_Ubuntu."},
	{"name":"jina-embeddings-v2-base-en-572024-xg53-webapp","keyword":"programming","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-572024-xg53-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-en-572024-xg53-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"scripting language documentation\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-en-572024-xg53-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-572024-xg53-webapp."},
	{"name":"coding","keyword":"programming","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/coding","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcoding Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"coding tutorials\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the coding model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import load_dataset\\n\\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/coding."},
	{"name":"jina-embeddings-v2-base-en-572024-xg53-webapp","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-572024-xg53-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-en-572024-xg53-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"scripting language documentation\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-en-572024-xg53-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-572024-xg53-webapp."},
	{"name":"very_specific_technical_questions_about_Ubuntu","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/very_specific_technical_questions_about_Ubuntu","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tvery_specific_technical_questions_about_Ubuntu Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"technical support search for Ubuntu\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the very_specific_technical_questions_about_Ubuntu model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/very_specific_technical_questions_about_Ubuntu."},
	{"name":"test","keyword":"ubuntu","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/test","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttest Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"technical support forum for Ubuntu\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the test model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import load_dataset\\n\\ndataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/test."},
	{"name":"very_specific_technical_questions_about_Ubuntu","keyword":"ubuntu","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/very_specific_technical_questions_about_Ubuntu","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tvery_specific_technical_questions_about_Ubuntu Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"technical support search for Ubuntu\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the very_specific_technical_questions_about_Ubuntu model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/very_specific_technical_questions_about_Ubuntu."},
	{"name":"DocuMint","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/documint/DocuMint","creator_name":"DocuMint","creator_url":"https://huggingface.co/documint","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDocuMint Dataset\\n\\t\\n\\nThe DocuMint Dataset is a collection of 100,000 Python functions and their corresponding docstrings, extracted from popular open-source repositories in the Free and open-source software (FLOSS) ecosystem. This dataset was created to train the DocuMint model, a fine-tuned variant of Google's CodeGemma-2B that generates high-quality docstrings for Python code functions. For more information on the model and its training procedure, please refer to the model card.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/documint/DocuMint."},
	{"name":"jinaai_jina-embeddings-v2-base-code-stackoverflow","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-stackoverflow","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-code-stackoverflow Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"code snippet search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-stackoverflow model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-stackoverflow."},
	{"name":"jinaai_jina-embeddings-v2-base-code-stackoverflow","keyword":"development","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-stackoverflow","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-code-stackoverflow Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"code snippet search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-stackoverflow model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-stackoverflow."},
	{"name":"jinaai_jina-embeddings-v2-base-code-askubuntu","keyword":"linux","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-askubuntu","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-code-askubuntu Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"technical support for Ubuntu\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-askubuntu model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-askubuntu."},
	{"name":"DocuMint","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/documint/DocuMint","creator_name":"DocuMint","creator_url":"https://huggingface.co/documint","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDocuMint Dataset\\n\\t\\n\\nThe DocuMint Dataset is a collection of 100,000 Python functions and their corresponding docstrings, extracted from popular open-source repositories in the Free and open-source software (FLOSS) ecosystem. This dataset was created to train the DocuMint model, a fine-tuned variant of Google's CodeGemma-2B that generates high-quality docstrings for Python code functions. For more information on the model and its training procedure, please refer to the model card.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/documint/DocuMint."},
	{"name":"jinaai_jina-embeddings-v2-base-code-stackoverflow","keyword":"programming","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-stackoverflow","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-code-stackoverflow Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"code snippet search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-stackoverflow model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-stackoverflow."},
	{"name":"jina-embeddings-v2-base-en-10052024-lns6-webapp","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-10052024-lns6-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-en-10052024-lns6-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Use case search for SaaS and AI products\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-en-10052024-lns6-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-10052024-lns6-webapp."},
	{"name":"jinaai_jina-embeddings-v2-base-code-stackoverflow","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-stackoverflow","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-code-stackoverflow Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"code snippet search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-stackoverflow model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-stackoverflow."},
	{"name":"jina-embeddings-v2-base-en-5102024-kvgq-webapp","keyword":"sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5102024-kvgq-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-en-5102024-kvgq-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"database search for structured data\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-en-5102024-kvgq-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5102024-kvgq-webapp."},
	{"name":"jinaai_jina-embeddings-v2-base-code-askubuntu","keyword":"ubuntu","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-askubuntu","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-code-askubuntu Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"technical support for Ubuntu\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-askubuntu model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-askubuntu."},
	{"name":"SE-Chatting.en","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/berwart/SE-Chatting.en","creator_name":"Berwart","creator_url":"https://huggingface.co/berwart","description":"\\n\\t\\n\\t\\t\\n\\t\\tSE.02\\n\\t\\n\\nDataset\\nHello, welcome to the official main dataset of SE.02 that's always getting updated, make sure to like to help us a lot.\\nthis dataset contains pretty much everything from math to isk what to put but pretty much anything you think an ai can say.\\nanyways this is our biggest dataset yet, and out first one that I don't even know how I managed to make this.\\nyou can use it to train your own ai if you want.\\n"},
	{"name":"verilog_preprocessed_anonymized","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Von-R/verilog_preprocessed_anonymized","creator_name":"Von Davis","creator_url":"https://huggingface.co/Von-R","description":"Von-R/verilog_preprocessed_anonymized dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"stackoverflow-posts","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/code-rag-bench/stackoverflow-posts","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"The StackOverflow posts retrieval source for code-rag-bench.\\n"},
	{"name":"github-repos","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/code-rag-bench/github-repos","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"The entire dump of GitHub repositories.\\n"},
	{"name":"stackoverflow","keyword":"coding","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"code snippet search for developers\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow."},
	{"name":"jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod","keyword":"linux","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"technical support search for Ubuntu\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod."},
	{"name":"stackoverflow","keyword":"programming","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"code snippet search for developers\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow."},
	{"name":"jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"technical support search for Ubuntu\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod."},
	{"name":"stackoverflow","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"code snippet search for developers\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow."},
	{"name":"jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod","keyword":"ubuntu","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"technical support search for Ubuntu\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-jinaai_jina-embeddings-v2-base-cod."},
	{"name":"askubuntu","keyword":"ubuntu","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\taskubuntu Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Technical Q&A search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the askubuntu model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu."},
	{"name":"askubuntu-c","keyword":"ubuntu","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\taskubuntu-c Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Technical troubleshooting queries\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the askubuntu-c model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c."},
	{"name":"askubuntu-l","keyword":"ubuntu","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu-l","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\taskubuntu-l Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"technical troubleshooting forum\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the askubuntu-l model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-l."},
	{"name":"thailand-cities","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AAhad/thailand-cities","creator_name":"Abdul Ahad","creator_url":"https://huggingface.co/AAhad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Thailand-Cities\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThailand-Cities Contains list of Thailand Cities in both English and Thai languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nTranslation\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThai\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n  1,Amnat Charoen,‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç\\n  2,Ang Sila,‡∏≠‡πà‡∏≤‡∏á‡∏®‡∏¥‡∏•‡∏≤\\n  3,Ang Thong,‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á\\n  4,Aranyaprathet,‡∏≠‡∏£‡∏±‡∏ç‡∏ç‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®\\n  5,Aranyik,‡∏≠‡∏£‡∏±‡∏ç‡∏ç‡∏¥‡∏Å\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields are the same among all configurations:\\n\\nSNO‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AAhad/thailand-cities."},
	{"name":"thailand-provinces","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AAhad/thailand-provinces","creator_name":"Abdul Ahad","creator_url":"https://huggingface.co/AAhad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Thailand-Provinces\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThailand-Provinces Contains list of Thailand Provinces in both Engligh and Thai languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nTranslation\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThai\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n  1,Bangkok,‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£\\n  2,Amnat Charoen,‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç\\n  3,Ang Thong,‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á\\n  4,Bueng Kan,‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨\\n  5,Buriram,‡∏ö‡∏∏‡∏£‡∏µ‡∏£‡∏±‡∏°‡∏¢‡πå\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields are the same among all configurations:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AAhad/thailand-provinces."},
	{"name":"countries-names-in-thai","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AAhad/countries-names-in-thai","creator_name":"Abdul Ahad","creator_url":"https://huggingface.co/AAhad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Countries Names in Thai\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCountries Names in Thai Contains list of world countries names in both Engligh & Thai languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nTranslation\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThai\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n  1,‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏≠‡∏±‡∏ü‡∏Å‡∏≤‡∏ô‡∏¥‡∏™‡∏ñ‡∏≤‡∏ô,Afghanistan\\n  2,‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÅ‡∏≠‡∏•‡πÄ‡∏ö‡πÄ‡∏ô‡∏µ‡∏¢,Albania\\n  3,‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÅ‡∏≠‡∏•‡∏à‡∏µ‡πÄ‡∏£‡∏µ‡∏¢,Algeria\\n  4,‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏≠‡∏±‡∏ô‡∏î‡∏≠‡∏£‡πå‡∏£‡∏≤,Andorra\\n  5,‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏≠‡∏≤‡∏£‡πå‡πÄ‡∏à‡∏ô‡∏ï‡∏¥‡∏ô‡∏≤,Argentina\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AAhad/countries-names-in-thai."},
	{"name":"amenokaku-code-instruct-python-mit","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/amenokaku-code-instruct-python-mit","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"kunishou/amenokaku-code-instruct„Çí‰ª•‰∏ã„ÅÆÊù°‰ª∂„ÅßÁµû„ÇäËæº„Çì„Å†„ÇÇ„ÅÆ„Åß„Åô„ÄÇ  \\n\\nMIT„É©„Ç§„Çª„É≥„Çπ (licence: 'MIT')\\npython (source: ['gasyori_100_knocks', 'datascience_100_knocks_python', 'bifi', 'python_for_begginers_solve_50_exercises', 'nlp_100_knocks')\\n\\n"},
	{"name":"amenokaku-code-instruct-python-mit-450","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/amenokaku-code-instruct-python-mit-450","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"kunishou/amenokaku-code-instruct„Çí‰ª•‰∏ã„ÅÆÊù°‰ª∂„ÅßÁµû„ÇäËæº„Çì„Å†„ÇÇ„ÅÆ„Åß„Åô„ÄÇ  \\n\\nMIT„É©„Ç§„Çª„É≥„Çπ (licence: 'MIT')\\npython (source: ['gasyori_100_knocks', 'datascience_100_knocks_python', 'bifi', 'python_for_begginers_solve_50_exercises', 'nlp_100_knocks')\\nsource: 'bifi'„Çí„É©„É≥„ÉÄ„É†„Å´100‰ª∂„Å´Áµû„ÇäËæº„Åø\\n\\n"},
	{"name":"alpaca_jp_python","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/alpaca_jp_python","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\talpaca_jp_python\\n\\t\\n\\n\\nalpaca_jp_python„ÅØ„ÄÅ  \\n\\nStanford Alpaca„ÅÆÊâãÊ≥ï  \\nmistralai/Mixtral-8x22B-Instruct-v0.1\\n\\n„Åß‰Ωú„Å£„ÅüÂêàÊàê„Éá„Éº„Çø(Synthetic data)„Åß„Åô„ÄÇ„É¢„Éá„É´„ÅÆÂà©Áî®„Å´„ÅØDeepinfra„ÇíÂà©Áî®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ  \\n„Åæ„Åü„ÄÅ\\\"_cleaned\\\"„Åå„Å§„ÅÑ„Åü„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØmistralai/Mixtral-8x22B-Instruct-v0.1„Å´„Çà„Å£„Å¶Á≤æÊüª„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\nCurated by: HachiML\\nLanguage(s) (NLP): Japanese\\nLicense: Apache 2.0\\nGithub: Alpaca-jp\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\n\\n\\n# library\\nfrom datasets import load_dataset\\n\\n# Recommend getting the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HachiML/alpaca_jp_python."},
	{"name":"humaneval_splits","keyword":"code-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iskhare/humaneval_splits","creator_name":"Ishan Khare","creator_url":"https://huggingface.co/iskhare","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for HumanEval with Splits\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe HumanEval dataset released by OpenAI includes 164 programming problems with a function sig- nature, docstring, body, and several unit tests. They were handwritten to ensure not to be included in the training set of code generation models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe programming problems are written in Python and contain English natural text in comments and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iskhare/humaneval_splits."},
	{"name":"stackoverflow-c","keyword":"coding","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"code snippet search for developers\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c."},
	{"name":"stackoverflow-c-128-24","keyword":"coding","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c-128-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"coding tutorials search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c-128-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-128-24."},
	{"name":"stackoverflow-c-256-24","keyword":"coding","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c-256-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"coding tutorials search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c-256-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-256-24."},
	{"name":"stackoverflow-c-64-24","keyword":"coding","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c-64-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"coding tutorials search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c-64-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24."},
	{"name":"stackoverflow-c","keyword":"development","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"code snippet search for developers\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c."},
	{"name":"stackoverflow-c-128-24","keyword":"development","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c-128-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"coding tutorials search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c-128-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-128-24."},
	{"name":"stackoverflow-c-256-24","keyword":"development","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c-256-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"coding tutorials search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c-256-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-256-24."},
	{"name":"stackoverflow-c-64-24","keyword":"development","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c-64-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"coding tutorials search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c-64-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24."},
	{"name":"amenokaku-code-instruct-python-mit","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/amenokaku-code-instruct-python-mit","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"kunishou/amenokaku-code-instruct„Çí‰ª•‰∏ã„ÅÆÊù°‰ª∂„ÅßÁµû„ÇäËæº„Çì„Å†„ÇÇ„ÅÆ„Åß„Åô„ÄÇ  \\n\\nMIT„É©„Ç§„Çª„É≥„Çπ (licence: 'MIT')\\npython (source: ['gasyori_100_knocks', 'datascience_100_knocks_python', 'bifi', 'python_for_begginers_solve_50_exercises', 'nlp_100_knocks')\\n\\n"},
	{"name":"amenokaku-code-instruct-python-mit-450","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/amenokaku-code-instruct-python-mit-450","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"kunishou/amenokaku-code-instruct„Çí‰ª•‰∏ã„ÅÆÊù°‰ª∂„ÅßÁµû„ÇäËæº„Çì„Å†„ÇÇ„ÅÆ„Åß„Åô„ÄÇ  \\n\\nMIT„É©„Ç§„Çª„É≥„Çπ (licence: 'MIT')\\npython (source: ['gasyori_100_knocks', 'datascience_100_knocks_python', 'bifi', 'python_for_begginers_solve_50_exercises', 'nlp_100_knocks')\\nsource: 'bifi'„Çí„É©„É≥„ÉÄ„É†„Å´100‰ª∂„Å´Áµû„ÇäËæº„Åø\\n\\n"},
	{"name":"alpaca_jp_python","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/alpaca_jp_python","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\talpaca_jp_python\\n\\t\\n\\n\\nalpaca_jp_python„ÅØ„ÄÅ  \\n\\nStanford Alpaca„ÅÆÊâãÊ≥ï  \\nmistralai/Mixtral-8x22B-Instruct-v0.1\\n\\n„Åß‰Ωú„Å£„ÅüÂêàÊàê„Éá„Éº„Çø(Synthetic data)„Åß„Åô„ÄÇ„É¢„Éá„É´„ÅÆÂà©Áî®„Å´„ÅØDeepinfra„ÇíÂà©Áî®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ  \\n„Åæ„Åü„ÄÅ\\\"_cleaned\\\"„Åå„Å§„ÅÑ„Åü„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØmistralai/Mixtral-8x22B-Instruct-v0.1„Å´„Çà„Å£„Å¶Á≤æÊüª„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\nCurated by: HachiML\\nLanguage(s) (NLP): Japanese\\nLicense: Apache 2.0\\nGithub: Alpaca-jp\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\n\\n\\n# library\\nfrom datasets import load_dataset\\n\\n# Recommend getting the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HachiML/alpaca_jp_python."},
	{"name":"stackoverflow-c","keyword":"programming","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"code snippet search for developers\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c."},
	{"name":"stackoverflow-c-128-24","keyword":"programming","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c-128-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"coding tutorials search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c-128-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-128-24."},
	{"name":"stackoverflow-c-256-24","keyword":"programming","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c-256-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"coding tutorials search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c-256-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-256-24."},
	{"name":"stackoverflow-c-64-24","keyword":"programming","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c-64-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"coding tutorials search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c-64-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24."},
	{"name":"stackoverflow-c","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"code snippet search for developers\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c."},
	{"name":"stackoverflow-c-128-24","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c-128-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"coding tutorials search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c-128-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-128-24."},
	{"name":"stackoverflow-c-256-24","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c-256-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"coding tutorials search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c-256-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-256-24."},
	{"name":"stackoverflow-c-64-24","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c-64-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"coding tutorials search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c-64-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24."},
	{"name":"askubuntu-c-256-24","keyword":"ubuntu","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\taskubuntu-c-256-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Technical troubleshooting forum search engine for Ubuntu\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the askubuntu-c-256-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-256-24."},
	{"name":"askubuntu-c-128-24","keyword":"ubuntu","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\taskubuntu-c-128-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Technical troubleshooting search engine for Ubuntu\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the askubuntu-c-128-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-128-24."},
	{"name":"askubuntu-c-64-24","keyword":"ubuntu","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\taskubuntu-c-64-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Technical troubleshooting search engine for Ubuntu\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the askubuntu-c-64-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24."},
	{"name":"CodeMouse","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/trollek/CodeMouse","creator_name":"Trolle Karlsson","creator_url":"https://huggingface.co/trollek","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCodeMouse\\n\\t\\n\\nI filtered out instructions with input context from sahil2801/CodeAlpaca-20k (CC BY) resulting in 9764 prompts that I then fed to WaveCoder Ultra at a low temperature.\\nThis is the code:\\nfrom datasets import load_dataset\\nimport json\\nfrom ollama import Client\\nfrom tqdm import tqdm\\n\\ncode_alpaca_dataset = load_dataset(\\\"sahil2801/CodeAlpaca-20k\\\")\\nollama_client = Client(host='http://localhost:11434')\\n\\ndef filter_no_input(hf_dataset):\\n    filtered_dataset = []\\n    for i‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trollek/CodeMouse."},
	{"name":"stackoverflow-c-64-24-gpt-4o-2024-05-13","keyword":"coding","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24-gpt-4o-2024-05-13","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c-64-24-gpt-4o-2024-05-13 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"technical knowledge sharing platform\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c-64-24-gpt-4o-2024-05-13 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24-gpt-4o-2024-05-13."},
	{"name":"stackoverflow-c-64-24-gpt-4o-2024-05-137765","keyword":"coding","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24-gpt-4o-2024-05-137765","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tstackoverflow-c-64-24-gpt-4o-2024-05-137765 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"technical knowledge sharing platform\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the stackoverflow-c-64-24-gpt-4o-2024-05-137765 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/stackoverflow-c-64-24-gpt-4o-2024-05-137765."},
	{"name":"askubuntu-c-64-24-gpt-4o-2024-05-135760","keyword":"linux","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-135760","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\taskubuntu-c-64-24-gpt-4o-2024-05-135760 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Q&A forum for Ubuntu users\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the askubuntu-c-64-24-gpt-4o-2024-05-135760 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-135760."},
	{"name":"askubuntu-c-64-24-gpt-4o-2024-05-135760","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-135760","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\taskubuntu-c-64-24-gpt-4o-2024-05-135760 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Q&A forum for Ubuntu users\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the askubuntu-c-64-24-gpt-4o-2024-05-135760 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-135760."},
	{"name":"askubuntu-c-64-24-gpt-4o-2024-05-135760","keyword":"ubuntu","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-135760","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\taskubuntu-c-64-24-gpt-4o-2024-05-135760 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Q&A forum for Ubuntu users\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the askubuntu-c-64-24-gpt-4o-2024-05-135760 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-135760."},
	{"name":"askubuntu-c-64-24-gpt-4o-2024-05-131171","keyword":"ubuntu","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-131171","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\taskubuntu-c-64-24-gpt-4o-2024-05-131171 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Technology Stack Documentation\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the askubuntu-c-64-24-gpt-4o-2024-05-131171 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/askubuntu-c-64-24-gpt-4o-2024-05-131171."},
	{"name":"iBeta_level_2_Silicone_masks","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AxonData/iBeta_level_2_Silicone_masks","creator_name":"AxonLabs","creator_url":"https://huggingface.co/AxonData","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSilicone Mask Biometric Attack Dataset\\n\\t\\n\\nAnti spoofing dataset with Silicone 3D mask attacks (7000 videos)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a demo version, full dataset is coming soon. Share with us your feedback and recieve additional samples for free!üòä\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFull version of dataset is availible for commercial usage - leave a request on our website Axon Labs to purchase the dataset üí∞\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe Silicone Mask Attack Dataset is designed to address security‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AxonData/iBeta_level_2_Silicone_masks."},
	{"name":"alpaca_jp_math","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/alpaca_jp_math","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\talpaca_jp_math\\n\\t\\n\\n\\nalpaca_jp_math„ÅØ„ÄÅ  \\n\\nStanford Alpaca„ÅÆÊâãÊ≥ï  \\nmistralai/Mixtral-8x22B-Instruct-v0.1\\n\\n„Åß‰Ωú„Å£„ÅüÂêàÊàê„Éá„Éº„Çø(Synthetic data)„Åß„Åô„ÄÇ„É¢„Éá„É´„ÅÆÂà©Áî®„Å´„ÅØDeepinfra„ÇíÂà©Áî®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ  \\n„Åæ„Åü„ÄÅ\\\"_cleaned\\\"„Åå„Å§„ÅÑ„Åü„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØ‰ª•‰∏ã„ÅÆÊâãÊ≥ï„ÅßÁ≤æÊüª„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ  \\n\\npython„ÅÆË®àÁÆóÁµêÊûú„Åå„Åç„Å°„Çì„Å®„ÄÅ„ÉÜ„Ç≠„Çπ„Éà„ÅÆË®àÁÆóÁµêÊûú„ÅåÂêåÁ≠â„Åß„ÅÇ„Çã„ÅãÁ¢∫Ë™ç\\nLLM(mistralai/Mixtral-8x22B-Instruct-v0.1)„Å´„Çà„ÇãÁ¢∫Ë™çÔºàË©≥Á¥∞„ÅØ‰∏ãË®òÔºâ\\n\\ncode_result, text_result„ÅØÂ∞èÊï∞Á¨¨‰∏â‰Ωç„ÅßÂõõÊç®‰∫îÂÖ•„Åó„Å¶„ÅÇ„Çä„Åæ„Åô„ÄÇ\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\nCurated by: HachiML\\nLanguage(s) (NLP): Japanese\\nLicense: Apache 2.0\\nGithub:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HachiML/alpaca_jp_math."},
	{"name":"alpaca_jp_math","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/alpaca_jp_math","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\talpaca_jp_math\\n\\t\\n\\n\\nalpaca_jp_math„ÅØ„ÄÅ  \\n\\nStanford Alpaca„ÅÆÊâãÊ≥ï  \\nmistralai/Mixtral-8x22B-Instruct-v0.1\\n\\n„Åß‰Ωú„Å£„ÅüÂêàÊàê„Éá„Éº„Çø(Synthetic data)„Åß„Åô„ÄÇ„É¢„Éá„É´„ÅÆÂà©Áî®„Å´„ÅØDeepinfra„ÇíÂà©Áî®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ  \\n„Åæ„Åü„ÄÅ\\\"_cleaned\\\"„Åå„Å§„ÅÑ„Åü„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØ‰ª•‰∏ã„ÅÆÊâãÊ≥ï„ÅßÁ≤æÊüª„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ  \\n\\npython„ÅÆË®àÁÆóÁµêÊûú„Åå„Åç„Å°„Çì„Å®„ÄÅ„ÉÜ„Ç≠„Çπ„Éà„ÅÆË®àÁÆóÁµêÊûú„ÅåÂêåÁ≠â„Åß„ÅÇ„Çã„ÅãÁ¢∫Ë™ç\\nLLM(mistralai/Mixtral-8x22B-Instruct-v0.1)„Å´„Çà„ÇãÁ¢∫Ë™çÔºàË©≥Á¥∞„ÅØ‰∏ãË®òÔºâ\\n\\ncode_result, text_result„ÅØÂ∞èÊï∞Á¨¨‰∏â‰Ωç„ÅßÂõõÊç®‰∫îÂÖ•„Åó„Å¶„ÅÇ„Çä„Åæ„Åô„ÄÇ\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\nCurated by: HachiML\\nLanguage(s) (NLP): Japanese\\nLicense: Apache 2.0\\nGithub:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HachiML/alpaca_jp_math."},
	{"name":"opus-php-en-ru-cleaned","keyword":"programming","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/evilfreelancer/opus-php-en-ru-cleaned","creator_name":"Pavel Zloi","creator_url":"https://huggingface.co/evilfreelancer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOPUS PHP (ru-en) Parallel Corpora\\n\\t\\n\\nThe dataset contains parallel corpora, featuring pairs in Russian and English.\\nInitially, the original OPUS PHP v1 (en&ru) dataset was intended to be used for training the enbeddrus project. However, due to its poor quality and high level of noise, it was decided to use only the English corpus from this dataset. The English text was then automatically translated using LibreTranslate, followed by manual translation and quality improvement using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/evilfreelancer/opus-php-en-ru-cleaned."},
	{"name":"code-grader-200","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/code-grader/code-grader-200","creator_name":"Code Grader NSEC","creator_url":"https://huggingface.co/code-grader","description":"code-grader/code-grader-200 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"jina-embeddings-v2-base-en-5222024-hkde-webapp","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5222024-hkde-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-en-5222024-hkde-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"code repository search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-en-5222024-hkde-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5222024-hkde-webapp."},
	{"name":"jina-embeddings-v2-base-en-22052024-vuno-webapp","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-22052024-vuno-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-en-22052024-vuno-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"test search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-en-22052024-vuno-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-22052024-vuno-webapp."},
	{"name":"jina-embeddings-v2-base-en-23052024-hbdj-webapp","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-23052024-hbdj-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-en-23052024-hbdj-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"test run search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-en-23052024-hbdj-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-23052024-hbdj-webapp."},
	{"name":"mixed_shona_dataset","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kittech/mixed_shona_dataset","creator_name":"Bright Chirindo","creator_url":"https://huggingface.co/Kittech","description":"Kittech/mixed_shona_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"github-repos-python","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/code-rag-bench/github-repos-python","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"The Github repository retrieval source for [code-rag-bench], containing all Python files from the entire GitHub dump (in github-repos)\\n"},
	{"name":"HotpotQA-256-24-gpt-4o-2024-05-13-773587","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/HotpotQA-256-24-gpt-4o-2024-05-13-773587","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHotpotQA-256-24-gpt-4o-2024-05-13-773587 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"code repository search for machine learning datasets and models\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the HotpotQA-256-24-gpt-4o-2024-05-13-773587 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/HotpotQA-256-24-gpt-4o-2024-05-13-773587."},
	{"name":"eng-quz-translation-dataset","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pollitoconpapass/eng-quz-translation-dataset","creator_name":"Jose Quispe","creator_url":"https://huggingface.co/pollitoconpapass","description":"pollitoconpapass/eng-quz-translation-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"data-oss_instruct-decontaminated_python.jsonl","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ramikan-BR/data-oss_instruct-decontaminated_python.jsonl","creator_name":"J√∫lio C√©sar","creator_url":"https://huggingface.co/Ramikan-BR","description":"Ramikan-BR/data-oss_instruct-decontaminated_python.jsonl dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"csharpdata","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/privelabs/csharpdata","creator_name":"PriveLabs","creator_url":"https://huggingface.co/privelabs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LeetCode Problems Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains LeetCode problems, including the problem statements, inputs, and solutions. It is useful for training code generation models and studying algorithmic problems.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntext-generation: This dataset can be used to train models to generate code snippets based on problem statements.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is in English.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/privelabs/csharpdata."},
	{"name":"ReflectionSeq-GPT","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SenseLLM/ReflectionSeq-GPT","creator_name":"SenseLLM","creator_url":"https://huggingface.co/SenseLLM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReflectionCoder: Learning from Reflection Sequence for Enhanced One-off Code Generation\\n\\t\\n\\n\\n    üìÑ Paper ‚Ä¢\\n    üè† Repo ‚Ä¢\\n    ü§ñ Models ‚Ä¢\\n    üìö Datasets \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nReflectionCoder is a novel approach that effectively leverages reflection sequences constructed by integrating compiler feedback to improve one-off code generation performance. Please refer to our paper and repo for more details!\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModels\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nModel\\nCheckpoint\\nSize\\nHumanEval (+)\\nMBPP‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SenseLLM/ReflectionSeq-GPT."},
	{"name":"ReflectionSeq-DS","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SenseLLM/ReflectionSeq-DS","creator_name":"SenseLLM","creator_url":"https://huggingface.co/SenseLLM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReflectionCoder: Learning from Reflection Sequence for Enhanced One-off Code Generation\\n\\t\\n\\n\\n    üìÑ Paper ‚Ä¢\\n    üè† Repo ‚Ä¢\\n    ü§ñ Models ‚Ä¢\\n    üìö Datasets \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nReflectionCoder is a novel approach that effectively leverages reflection sequences constructed by integrating compiler feedback to improve one-off code generation performance. Please refer to our paper and repo for more details!\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModels\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nModel\\nCheckpoint\\nSize\\nHumanEval (+)\\nMBPP‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SenseLLM/ReflectionSeq-DS."},
	{"name":"modified-codesearchnet-code-summarization","keyword":"codesearchnet","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sm1rk/modified-codesearchnet-code-summarization","creator_name":"Vladimir Makharev","creator_url":"https://huggingface.co/sm1rk","description":"\\n\\t\\n\\t\\t\\n\\t\\tModified CodeSearchNet (MCSN) Dataset\\n\\t\\n\\nThis dataset is a modification of the CodeSearchNet dataset from CodeXGLUE benchmark, designed for evaluating code summarization models beyond the function level. It explores the impact of function and repository contexts on summary quality.  The dataset includes modifications for evaluating at both function and repository levels.\\nPaper: Code Summarization Beyond Function Level\\nDataset Structure:\\nThe dataset contains samples with the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm1rk/modified-codesearchnet-code-summarization."},
	{"name":"modified-classeval-code-summarization","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sm1rk/modified-classeval-code-summarization","creator_name":"Vladimir Makharev","creator_url":"https://huggingface.co/sm1rk","description":"\\n\\t\\n\\t\\t\\n\\t\\tModified ClassEval (MCE) Dataset\\n\\t\\n\\nThis dataset is a modification of the ClassEval benchmark, designed for evaluating code summarization models beyond the function level. It explores the impact of function and class contexts on summary quality.  The dataset includes modifications for evaluating at both function and class levels.\\nPaper: Code Summarization Beyond Function Level\\nDataset Structure:\\nThe dataset contains samples with the following fields:\\n\\nclass_id: Identifier for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm1rk/modified-classeval-code-summarization."},
	{"name":"modified-codesearchnet-code-summarization","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sm1rk/modified-codesearchnet-code-summarization","creator_name":"Vladimir Makharev","creator_url":"https://huggingface.co/sm1rk","description":"\\n\\t\\n\\t\\t\\n\\t\\tModified CodeSearchNet (MCSN) Dataset\\n\\t\\n\\nThis dataset is a modification of the CodeSearchNet dataset from CodeXGLUE benchmark, designed for evaluating code summarization models beyond the function level. It explores the impact of function and repository contexts on summary quality.  The dataset includes modifications for evaluating at both function and repository levels.\\nPaper: Code Summarization Beyond Function Level\\nDataset Structure:\\nThe dataset contains samples with the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sm1rk/modified-codesearchnet-code-summarization."},
	{"name":"data-oss_instruct-decontaminated_python.jsonl","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ramikan-BR/data-oss_instruct-decontaminated_python.jsonl","creator_name":"J√∫lio C√©sar","creator_url":"https://huggingface.co/Ramikan-BR","description":"Ramikan-BR/data-oss_instruct-decontaminated_python.jsonl dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"csharpdata","keyword":"programming","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/privelabs/csharpdata","creator_name":"PriveLabs","creator_url":"https://huggingface.co/privelabs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LeetCode Problems Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains LeetCode problems, including the problem statements, inputs, and solutions. It is useful for training code generation models and studying algorithmic problems.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntext-generation: This dataset can be used to train models to generate code snippets based on problem statements.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is in English.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/privelabs/csharpdata."},
	{"name":"LeetCode_YouTube_CC","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LimYeri/LeetCode_YouTube_CC","creator_name":"LimYeri","creator_url":"https://huggingface.co/LimYeri","description":"LeetCode Information & YouTube Captions\\nOriginal data -> LimYeri/leetcode_with_youtube_captions\\nThe original ['cc_content'] column had many repeated sentences, making the data too long.\\nTo remove the repetitions, we used precise regular expressions to eliminate the repeated sentences. -> new column ['content']\\nAdditionally, we also removed unnecessary strings (e.g., '[Music]').\\n"},
	{"name":"base64-decode-v1","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/base64-decode-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset: Base64 decode version1\\n\\t\\n\\nThis dataset is for improving base64 decoding capabilities.\\nThe number of bytes that are in the base64 encoded data spans between 0..127 bytes.\\nGPT 4o is great at base64 decoding.\\nHowever llama3 is terrible at base64 decoding.\\nShort examples of what data.jsonl looks like:\\n{\\\"instruction\\\": \\\"Transform base64 to HEX\\\", \\\"input\\\": \\\"464pNBlIObA=\\\", \\\"output\\\": \\\"e3ae2934194839b0\\\"}\\n{\\\"instruction\\\": \\\"Decode Base64 to json\\\", \\\"input\\\": \\\"NQ==\\\", \\\"output\\\": \\\"[53]\\\"}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/base64-decode-v1."},
	{"name":"Mannequin_Dataset_Anti_Spoofing","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AxonData/Mannequin_Dataset_Anti_Spoofing","creator_name":"AxonLabs","creator_url":"https://huggingface.co/AxonData","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t3D Mannequin Face Dataset for Liveness Detection (1K+ pictures)\\n\\t\\n\\nExplore 3D mannequins for anti-spoofing models (1000+ images)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShare your feedback - recieve additional samples for free!üòä\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFull version of dataset is availible for commercial usage - leave a request on our website Axon Labs to purchase the dataset üí∞\\n\\t\\n\\nOur 3D Mannequin Anti-Spoofing Dataset provides a comprehensive collection of mannequin images, optimized for enhancing liveness detection‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AxonData/Mannequin_Dataset_Anti_Spoofing."},
	{"name":"gptgen_text_detection","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yongchao/gptgen_text_detection","creator_name":"Yongchao Wu","creator_url":"https://huggingface.co/yongchao","description":"yongchao/gptgen_text_detection dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Scratch-platformers-10k","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GPT007/Scratch-platformers-10k","creator_name":"Marc Kovka","creator_url":"https://huggingface.co/GPT007","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScratch platformers 10k\\n\\t\\n\\nThis is a dataset featuring 10k search results for platformer on Scratch.\\nThere are 3 fields:  \\n\\nThe instrucions (how to play, ...)\\nThe title\\nThe code in the scratchblocks format\\n\\nI also added @ + the sprite name before the blocks.\\n"},
	{"name":"DafnyBench","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wendy-sun/DafnyBench","creator_name":"Wendy Sun","creator_url":"https://huggingface.co/wendy-sun","description":"wendy-sun/DafnyBench dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"SlimOrca-Dedup-Uzbek-cleaned","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MLDataScientist/SlimOrca-Dedup-Uzbek-cleaned","creator_name":"Saeed","creator_url":"https://huggingface.co/MLDataScientist","description":"This is an Uzbek translated and cleaned version of https://huggingface.co/datasets/Open-Orca/SlimOrca-Dedup. \\nSpecifically, these replaced/removed records that had 'Uzbek translation|Uzbekcha tarjima|Uzbek tarjima|impossible to translate|not possible to translate|cannot fulfill your request|text is in|tilida yozilgan|Uzbek|o'zbek|ozbek|I am sorry'.\\nYou can use this dataset for chat fine-tuning of LLMs.\\nThis dataset has around 100M tokens (500M*0.8/4 = 100M assuming 4 chars are one token).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MLDataScientist/SlimOrca-Dedup-Uzbek-cleaned."},
	{"name":"VSCD-dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ElMater06/VSCD-dataset","creator_name":"El Matero","creator_url":"https://huggingface.co/ElMater06","description":"ElMater06/VSCD-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"humaneval","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/code-rag-bench/humaneval","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"HumanEval dataset annotated with the ground-truth programming solutions, to enable evaluations for retrieval and retrieval augmented code generation. \\nPlease refer to code-rag-becnch for more details. \\n"},
	{"name":"mbpp","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/code-rag-bench/mbpp","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"MBPP dataset annotated with ground-truth programming solutions, to enable evaluations for retrieval and retrieval-augmented code generation.\\nPlease refer to code-rag-bench for more details.\\n"},
	{"name":"ds1000","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/code-rag-bench/ds1000","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"DS-1000 dataset annotated with the ground-truth library documentation, to enable evaluations for retrieval and retrieval-augmented code generation.\\nPlease refer to [code-rag-bench] for more details\\n"},
	{"name":"odex","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/code-rag-bench/odex","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"ODEX dataset annotated with the ground-truth library documentation, to enable evaluations for retrieval and retrieval-augmented code generation.\\nPlease refer to [code-rag-bench] for more details.\\n"},
	{"name":"programming-solutions","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/code-rag-bench/programming-solutions","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"The programming solutions retrieval source for code-rag-bench, comprising programming solutions for the HumanEval and MBPP datasets.\\n"},
	{"name":"online-tutorials","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/code-rag-bench/online-tutorials","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"The online tutorials retrieval source for code-rag-bench, consisting tutorials pages collected from GeeksforGeeks, W3Schools, tutorialspoint, and Towards Data Science.\\n"},
	{"name":"library-documentation","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/code-rag-bench/library-documentation","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"The library documentation retrieval source for code-rag-bench, contains all documentation for Python libraries available on devdocs.io.\\n"},
	{"name":"Wallyai-ml","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SnehaPriyaaMP/Wallyai-ml","creator_name":"Snehapriyaa","creator_url":"https://huggingface.co/SnehaPriyaaMP","description":"SnehaPriyaaMP/Wallyai-ml dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"iac-eval","keyword":"code-generation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/autoiac-project/iac-eval","creator_name":"AutoIaC Project","creator_url":"https://huggingface.co/autoiac-project","description":"\\n\\t\\n\\t\\t\\n\\t\\tIaC-Eval dataset (v1.1)\\n\\t\\n\\nIaC-Eval dataset is the first human-curated and challenging Cloud Infrastructure-as-Code (IaC) dataset tailored to more rigorously benchmark large language models' IaC code generation capabilities. \\nThis dataset contains 458 questions ranging from simple to difficult across various cloud services (targeting AWS for now).\\n| Github | üèÜ Leaderboard TBD | üìñ NeurIPS 2024 Paper |\\n\\n\\t\\n\\t\\n\\t\\n\\t\\t2. Usage instructions\\n\\t\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOption 1: Running the evaluation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/autoiac-project/iac-eval."},
	{"name":"base64-encode-v1","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/base64-encode-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset: Base64 encode version1\\n\\t\\n\\nThis dataset is for improving base64 encoding capabilities.\\nGPT 4o is great at base64 encoding.\\nuser: \\nconvert this hex data to base64:\\n880567a1\\n\\nassistant:\\nThe base64 encoding of the hex data `880567a1` is `iAVnoQ==`.\\n\\nuser:\\nconvert this json data representing a byte sequence to base64:\\n[30,41,183]\\n\\nassistant:\\nThe base64 encoding of the JSON data `[30,41,183]` is `Him3`.\\n\\nHowever llama3 is terrible at base64 encoding.\\nShort examples of what‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/base64-encode-v1."},
	{"name":"bigcodebench","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigcode/bigcodebench","creator_name":"BigCode","creator_url":"https://huggingface.co/bigcode","description":"\\n\\t\\n\\t\\t\\n\\t\\tBigCodeBench\\n\\t\\n\\n\\n\\n\\n\\nThe dataset has 2 variants: \\n\\nBigCodeBench-Complete: Code Completion based on the structured docstrings.\\n¬†BigCodeBench-Instruct: Code Generation based on the NL-oriented instructions.\\n\\nThe overall statistics of the dataset are as follows:\\n\\n\\t\\n\\t\\t\\n\\nComplete\\nInstruct\\n\\n\\n\\t\\t\\n# Task\\n1140\\n1140\\n\\n\\n# Avg. Test Cases\\n5.6\\n5.6\\n\\n\\n# Avg. Coverage\\n99%\\n99%\\n\\n\\n# Avg. Prompt Char.\\n1112.5\\n663.2\\n\\n\\n# Avg. Prompt Line\\n33.5\\n11.7\\n\\n# Avg. Prompt Char. (Code)\\n1112.5\\n124.0\\n\\n\\n# Avg. Solution Char.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bigcode/bigcodebench."},
	{"name":"bigcodebench","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigcode/bigcodebench","creator_name":"BigCode","creator_url":"https://huggingface.co/bigcode","description":"\\n\\t\\n\\t\\t\\n\\t\\tBigCodeBench\\n\\t\\n\\n\\n\\n\\n\\nThe dataset has 2 variants: \\n\\nBigCodeBench-Complete: Code Completion based on the structured docstrings.\\n¬†BigCodeBench-Instruct: Code Generation based on the NL-oriented instructions.\\n\\nThe overall statistics of the dataset are as follows:\\n\\n\\t\\n\\t\\t\\n\\nComplete\\nInstruct\\n\\n\\n\\t\\t\\n# Task\\n1140\\n1140\\n\\n\\n# Avg. Test Cases\\n5.6\\n5.6\\n\\n\\n# Avg. Coverage\\n99%\\n99%\\n\\n\\n# Avg. Prompt Char.\\n1112.5\\n663.2\\n\\n\\n# Avg. Prompt Line\\n33.5\\n11.7\\n\\n# Avg. Prompt Char. (Code)\\n1112.5\\n124.0\\n\\n\\n# Avg. Solution Char.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bigcode/bigcodebench."},
	{"name":"ConBench_D","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConBench/ConBench_D","creator_name":"ConBench","creator_url":"https://huggingface.co/ConBench","description":"ConBench/ConBench_D dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"base64-decode-v2","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neoneye/base64-decode-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset: Base64 decode version2\\n\\t\\n\\nThis dataset is for improving base64 decoding capabilities.\\nThis improves on the neoneye/base64-decode-v1 dataset.\\nHere number of bytes that are in the base64 encoded data spans between 0..255 bytes. Where version 1 spans between 0..127.\\nHere 3 different random functions are used. Where version 1 uses 1 random function.\\nGPT 4o is great at base64 decoding.\\nHowever llama3 is terrible at base64 decoding.\\nShort examples of what data.jsonl looks like:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neoneye/base64-decode-v2."},
	{"name":"jinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp","keyword":"development","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"software development\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-05062024-zvoa-webapp."},
	{"name":"InfiBench","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llylly001/InfiBench","creator_name":"Linyi Li","creator_url":"https://huggingface.co/llylly001","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInfiBench (Data Part)\\n\\t\\n\\nNote: For full description, please visit our main website https://infi-coder.github.io/infibench.\\nThis repo contains all data of our code LLM evaluation dataset InfiBench. suite_v2.1.yaml lists the case list and suite_v2.1_data.csv records all data (prompt, reference answer, evaluation metric). The data can be directly consumed by our automatic evaluation tool to evaluate any model's response.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\nName: InfiBench\\nDescription:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llylly001/InfiBench."},
	{"name":"linux-comands","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mhdabdelrhman/linux-comands","creator_name":"Muhammet Abdurrahman","creator_url":"https://huggingface.co/mhdabdelrhman","description":"mhdabdelrhman/linux-comands dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cpp-10k","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dumb-dev/cpp-10k","creator_name":"dev.lenn","creator_url":"https://huggingface.co/dumb-dev","description":"10k random lines of the \\\"text\\\" column of the https://huggingface.co/datasets/wttw/code_contest_instruct_cpp dataset\\n"},
	{"name":"enamel","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/q-rz/enamel","creator_name":"Ruizhong Qiu","creator_url":"https://huggingface.co/q-rz","description":"See also:\\n\\n\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tWhat is ENAMEL?\\n\\t\\n\\nENAMEL is a rigorous and high-standard benchmark for evaluating the capability of large language models (LLMs) in generating efficient code. We provide:\\nA new metric eff@k characterizing the relationship between code efficiency and sample size k;\\nA problem set consisting of 142 high-quality problems selected from OpenAI HumanEval;\\nExpert-written efficient reference solutions, setting a high-standard for efficiency evaluation;\\nExpert-written strong test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/q-rz/enamel."},
	{"name":"enamel","keyword":"code-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/q-rz/enamel","creator_name":"Ruizhong Qiu","creator_url":"https://huggingface.co/q-rz","description":"See also:\\n\\n\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tWhat is ENAMEL?\\n\\t\\n\\nENAMEL is a rigorous and high-standard benchmark for evaluating the capability of large language models (LLMs) in generating efficient code. We provide:\\nA new metric eff@k characterizing the relationship between code efficiency and sample size k;\\nA problem set consisting of 142 high-quality problems selected from OpenAI HumanEval;\\nExpert-written efficient reference solutions, setting a high-standard for efficiency evaluation;\\nExpert-written strong test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/q-rz/enamel."},
	{"name":"golang-ollamaapi-charm","keyword":"coding","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smcleod/golang-ollamaapi-charm","creator_name":"Sam McLeod","creator_url":"https://huggingface.co/smcleod","description":"Attempting to create a dataset with AugmentToolkit.\\nI'm new to datasets and textgen training and this is my first attempt at creating a dataset. I'm not sure if this will end up being useful or not so YMMV.\\nCreated from:\\n\\nUber's Golang Style Guide\\nOllama's Golang API Docs\\nCharmbracelet's Golang Packages and Examples\\n\\nI generated the Q/A with a mix of Mixtral Nous Hermes 8x7b, Llama 3 8b, Qwen 2 7b.\\nThe file that's the most processed (but probably still needs work) is .\\nhttps://smcleod.net\\n"},
	{"name":"stem_mcqa_questions","keyword":"computer_science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mvujas/stem_mcqa_questions","creator_name":"Milos Vujasinovic","creator_url":"https://huggingface.co/mvujas","description":"This is a dataset of questions in various stem field generated using GPT-4o. The fields contain math, physics, chemistry, biology, computer_science and technical_sciences with around 400 samples in each.\\n"},
	{"name":"jinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp","keyword":"development","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"professional development and job seeking\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-08062024-z8ik-webapp."},
	{"name":"golang-ollamaapi-charm","keyword":"go","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smcleod/golang-ollamaapi-charm","creator_name":"Sam McLeod","creator_url":"https://huggingface.co/smcleod","description":"Attempting to create a dataset with AugmentToolkit.\\nI'm new to datasets and textgen training and this is my first attempt at creating a dataset. I'm not sure if this will end up being useful or not so YMMV.\\nCreated from:\\n\\nUber's Golang Style Guide\\nOllama's Golang API Docs\\nCharmbracelet's Golang Packages and Examples\\n\\nI generated the Q/A with a mix of Mixtral Nous Hermes 8x7b, Llama 3 8b, Qwen 2 7b.\\nThe file that's the most processed (but probably still needs work) is .\\nhttps://smcleod.net\\n"},
	{"name":"golang-en-ru","keyword":"go","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/evilfreelancer/golang-en-ru","creator_name":"Pavel Zloi","creator_url":"https://huggingface.co/evilfreelancer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGoLang (ru-en) Parallel Corpora\\n\\t\\n\\nThe dataset contains parallel corpora, featuring pairs about GoLang in Russian and English.\\n"},
	{"name":"golang-ollamaapi-charm","keyword":"golang","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smcleod/golang-ollamaapi-charm","creator_name":"Sam McLeod","creator_url":"https://huggingface.co/smcleod","description":"Attempting to create a dataset with AugmentToolkit.\\nI'm new to datasets and textgen training and this is my first attempt at creating a dataset. I'm not sure if this will end up being useful or not so YMMV.\\nCreated from:\\n\\nUber's Golang Style Guide\\nOllama's Golang API Docs\\nCharmbracelet's Golang Packages and Examples\\n\\nI generated the Q/A with a mix of Mixtral Nous Hermes 8x7b, Llama 3 8b, Qwen 2 7b.\\nThe file that's the most processed (but probably still needs work) is .\\nhttps://smcleod.net\\n"},
	{"name":"golang-en-ru","keyword":"golang","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/evilfreelancer/golang-en-ru","creator_name":"Pavel Zloi","creator_url":"https://huggingface.co/evilfreelancer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGoLang (ru-en) Parallel Corpora\\n\\t\\n\\nThe dataset contains parallel corpora, featuring pairs about GoLang in Russian and English.\\n"},
	{"name":"golang-en-ru","keyword":"programming","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/evilfreelancer/golang-en-ru","creator_name":"Pavel Zloi","creator_url":"https://huggingface.co/evilfreelancer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGoLang (ru-en) Parallel Corpora\\n\\t\\n\\nThe dataset contains parallel corpora, featuring pairs about GoLang in Russian and English.\\n"},
	{"name":"zigcode-1000","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sovenok-Hacker/zigcode-1000","creator_name":"Artem Hvostov","creator_url":"https://huggingface.co/Sovenok-Hacker","description":"Zig programming language code dataset, loaded using GitHub Search REST API.\\n"},
	{"name":"Nuke-Python-Verse","keyword":"coding","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NuclearAi/Nuke-Python-Verse","creator_name":"Nuclear Ai","creator_url":"https://huggingface.co/NuclearAi","description":"We're excited to announce the release of the NuclearAi/Nuke-Python-Verse, a comprehensive Collection of over 240,888 unique lines of Python Code sourced from public datasets. This dataset is specifically designed for fine-tuning and training LLMs to achieve exceptional accuracy in Python language understanding and generation.\\n"},
	{"name":"Nuke-Python-Verse","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NuclearAi/Nuke-Python-Verse","creator_name":"Nuclear Ai","creator_url":"https://huggingface.co/NuclearAi","description":"We're excited to announce the release of the NuclearAi/Nuke-Python-Verse, a comprehensive Collection of over 240,888 unique lines of Python Code sourced from public datasets. This dataset is specifically designed for fine-tuning and training LLMs to achieve exceptional accuracy in Python language understanding and generation.\\n"},
	{"name":"BAAI_bge-m3-2024__6__12_-1217-webapp","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-2024__6__12_-1217-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBAAI_bge-m3-2024__6__12_-1217-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Python programming\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the BAAI_bge-m3-2024__6__12_-1217-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-2024__6__12_-1217-webapp."},
	{"name":"BAAI_bge-m3-2024__6__12_-1217-webapp","keyword":"programming","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-2024__6__12_-1217-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBAAI_bge-m3-2024__6__12_-1217-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Python programming\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the BAAI_bge-m3-2024__6__12_-1217-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-2024__6__12_-1217-webapp."},
	{"name":"Buzz-slice-1-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-1-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-1-10-V1.2."},
	{"name":"Buzz-slice-10-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-10-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-10-10-V1.2."},
	{"name":"Buzz-slice-2-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-2-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-2-10-V1.2."},
	{"name":"Buzz-slice-3-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-3-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-3-10-V1.2."},
	{"name":"Buzz-slice-4-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-4-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-4-10-V1.2."},
	{"name":"Buzz-slice-5-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-5-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-5-10-V1.2."},
	{"name":"Buzz-slice-6-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-6-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-6-10-V1.2."},
	{"name":"Buzz-slice-7-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-7-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-7-10-V1.2."},
	{"name":"Buzz-slice-8-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-8-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-8-10-V1.2."},
	{"name":"Buzz-slice-9-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-9-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-9-10-V1.2."},
	{"name":"Arabic_Poems","keyword":"code","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alwalid54321/Arabic_Poems","creator_name":"Alwalid Ibrahim","creator_url":"https://huggingface.co/alwalid54321","description":"Arabic Poems\\nit's a filtered version for (https://huggingface.co/datasets/arbml/ashaar) with only al-diwan data\\nOverview:\\nThe \\\"Arabic Poems\\\" dataset is a comprehensive collection of Arabic poetry, comprising 8,875 entries. Each entry contains detailed information about individual poems and their respective poets, making it a valuable resource for researchers, developers, and enthusiasts of Arabic literature.\\nColumns:\\nUnnamed: 0: An index column.\\npoem_title: The title of the poem.\\npoem_meter:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alwalid54321/Arabic_Poems."},
	{"name":"RepoExec","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fsoft-AIC/RepoExec","creator_name":"FPT Software AI Center","creator_url":"https://huggingface.co/Fsoft-AIC","description":"\\n\\t\\n\\t\\t\\n\\t\\tRepoExec: Evaluate Code Generation with a Repository-Level Executable Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nRepoExec is a novel benchmark designed to evaluate code generation at the repository level with a focus on executability and correctness. This benchmark addresses the gaps in existing systems by emphasizing real-world applicability and providing a comprehensive assessment of code functionality. It aims to provide a comprehensive evaluation of code functionality and alignment‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fsoft-AIC/RepoExec."},
	{"name":"sql-create-context-pt","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/emdemor/sql-create-context-pt","creator_name":"Eduardo Morais","creator_url":"https://huggingface.co/emdemor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEste dataset  √© uma vers√£o traduzida para o portugu√™s do dataset b-mc2/sql-create-context,\\nque foi constru√≠do a partir dos datasets WikiSQL e Spider. Ele cont√©m exemplos de perguntas\\nem portugu√™s, instru√ß√µes SQL CREATE TABLE e consultas SQL que respondem √†s perguntas\\nutilizando a instru√ß√£o CREATE TABLE como contexto.\\nO principal objetivo deste dataset √© ajudar modelos de linguagem natural  em portugu√™s a gerar consultas\\nSQL precisas e contextualizadas, prevenindo a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/emdemor/sql-create-context-pt."},
	{"name":"golang-programming-style-best-practices","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smcleod/golang-programming-style-best-practices","creator_name":"Sam McLeod","creator_url":"https://huggingface.co/smcleod","description":"Note: WIP - This dataset has not yet been curated to remove duplicates and filler\\nDataset trained on several popular open source Golang style guides and the effective go book.\\nSource training data:\\n\\nhttps://go.dev/doc/effective_go\\nhttps://github.com/uber-go/guide/blob/master/style.md\\nhttps://google.github.io/styleguide/go/best-practices\\n\\nQ&A generated using Augment Toolkit\\nGeneration models:\\n\\nyi-large (API access kindly donated by 01.ai)\\nhermes-2-theta-llama-3-8b\\nqwen2-72b-instruct\\n\\n"},
	{"name":"hackercup","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hackercupai/hackercup","creator_name":"HackerCupAI","creator_url":"https://huggingface.co/hackercupai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Preview\\n\\t\\n\\nThe data available in this preview contains a 10 row dataset:\\n\\nSample Dataset (\\\"sample\\\"): This is a subset of the full dataset, containing data from 2023.\\n\\nTo view full dataset, download output_dataset.parquet. This contains data from 2011 to 2023.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFields\\n\\t\\n\\nThe dataset include the following fields:\\n\\nname (string)\\nyear (string)\\nround (string)\\nstatement (string)\\ninput (string)\\nsolution (string)\\ncode (string)\\nsample_input (string)\\nsample_output (string)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hackercupai/hackercup."},
	{"name":"golang-programming-style-best-practices","keyword":"go","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smcleod/golang-programming-style-best-practices","creator_name":"Sam McLeod","creator_url":"https://huggingface.co/smcleod","description":"Note: WIP - This dataset has not yet been curated to remove duplicates and filler\\nDataset trained on several popular open source Golang style guides and the effective go book.\\nSource training data:\\n\\nhttps://go.dev/doc/effective_go\\nhttps://github.com/uber-go/guide/blob/master/style.md\\nhttps://google.github.io/styleguide/go/best-practices\\n\\nQ&A generated using Augment Toolkit\\nGeneration models:\\n\\nyi-large (API access kindly donated by 01.ai)\\nhermes-2-theta-llama-3-8b\\nqwen2-72b-instruct\\n\\n"},
	{"name":"golang-programming-style-best-practices","keyword":"golang","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smcleod/golang-programming-style-best-practices","creator_name":"Sam McLeod","creator_url":"https://huggingface.co/smcleod","description":"Note: WIP - This dataset has not yet been curated to remove duplicates and filler\\nDataset trained on several popular open source Golang style guides and the effective go book.\\nSource training data:\\n\\nhttps://go.dev/doc/effective_go\\nhttps://github.com/uber-go/guide/blob/master/style.md\\nhttps://google.github.io/styleguide/go/best-practices\\n\\nQ&A generated using Augment Toolkit\\nGeneration models:\\n\\nyi-large (API access kindly donated by 01.ai)\\nhermes-2-theta-llama-3-8b\\nqwen2-72b-instruct\\n\\n"},
	{"name":"golang-programming-style-best-practices","keyword":"programming","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smcleod/golang-programming-style-best-practices","creator_name":"Sam McLeod","creator_url":"https://huggingface.co/smcleod","description":"Note: WIP - This dataset has not yet been curated to remove duplicates and filler\\nDataset trained on several popular open source Golang style guides and the effective go book.\\nSource training data:\\n\\nhttps://go.dev/doc/effective_go\\nhttps://github.com/uber-go/guide/blob/master/style.md\\nhttps://google.github.io/styleguide/go/best-practices\\n\\nQ&A generated using Augment Toolkit\\nGeneration models:\\n\\nyi-large (API access kindly donated by 01.ai)\\nhermes-2-theta-llama-3-8b\\nqwen2-72b-instruct\\n\\n"},
	{"name":"sql-create-context-pt","keyword":"sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/emdemor/sql-create-context-pt","creator_name":"Eduardo Morais","creator_url":"https://huggingface.co/emdemor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEste dataset  √© uma vers√£o traduzida para o portugu√™s do dataset b-mc2/sql-create-context,\\nque foi constru√≠do a partir dos datasets WikiSQL e Spider. Ele cont√©m exemplos de perguntas\\nem portugu√™s, instru√ß√µes SQL CREATE TABLE e consultas SQL que respondem √†s perguntas\\nutilizando a instru√ß√£o CREATE TABLE como contexto.\\nO principal objetivo deste dataset √© ajudar modelos de linguagem natural  em portugu√™s a gerar consultas\\nSQL precisas e contextualizadas, prevenindo a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/emdemor/sql-create-context-pt."},
	{"name":"sql-create-context-pt","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/emdemor/sql-create-context-pt","creator_name":"Eduardo Morais","creator_url":"https://huggingface.co/emdemor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEste dataset  √© uma vers√£o traduzida para o portugu√™s do dataset b-mc2/sql-create-context,\\nque foi constru√≠do a partir dos datasets WikiSQL e Spider. Ele cont√©m exemplos de perguntas\\nem portugu√™s, instru√ß√µes SQL CREATE TABLE e consultas SQL que respondem √†s perguntas\\nutilizando a instru√ß√£o CREATE TABLE como contexto.\\nO principal objetivo deste dataset √© ajudar modelos de linguagem natural  em portugu√™s a gerar consultas\\nSQL precisas e contextualizadas, prevenindo a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/emdemor/sql-create-context-pt."},
	{"name":"arxiv-cstext","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tensorkelechi/arxiv-cstext","creator_name":"kelechic","creator_url":"https://huggingface.co/tensorkelechi","description":"tensorkelechi/arxiv-cstext dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"testedados","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MatheusFr/testedados","creator_name":"Matheus Francisco","creator_url":"https://huggingface.co/MatheusFr","description":"MatheusFr/testedados dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Big_Personality","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AryankP1/Big_Personality","creator_name":"Aryank Bhargava","creator_url":"https://huggingface.co/AryankP1","description":"AryankP1/Big_Personality dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"kaz-rus-eng-literature-parallel-corpus","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nothingger/kaz-rus-eng-literature-parallel-corpus","creator_name":"Sagi Abdashim","creator_url":"https://huggingface.co/Nothingger","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual Literature Parallel Corpus\\n\\t\\n\\n\\n\\nThe Multilingual Literature Parallel Corpus is designed for translation tasks, containing parallel text pairs from literature in three languages: Kazakh (kaz_Cyrl), Russian (rus_Cyrl), and English (eng_Latn).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nThe Multilingual Literature Parallel Corpus provides parallel text pairs for translation tasks across Kazakh, Russian, and English. The dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nothingger/kaz-rus-eng-literature-parallel-corpus."},
	{"name":"RepoExec-Instruct","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fsoft-AIC/RepoExec-Instruct","creator_name":"FPT Software AI Center","creator_url":"https://huggingface.co/Fsoft-AIC","description":"\\n\\t\\n\\t\\t\\n\\t\\tRepoExec: Evaluate Code Generation with a Repository-Level Executable Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis source contains the instruction-tuning dataset to fine-tune models in our work.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Instances\\n\\t\\n\\n{\\n    \\\"id\\\": 0,\\n    \\\"prompt\\\": \\\"import base64\\\\nimport random\\\\nimport unicodedata\\\\nimport zlib\\\\nfrom typing import Union\\\\nfrom uuid import uuid4\\\\nfrom ._regex import *\\\\nfrom .errors import InvalidInputError\\\\nfrom .validation import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fsoft-AIC/RepoExec-Instruct."},
	{"name":"code-comprehension","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/imbue/code-comprehension","creator_name":"Imbue","creator_url":"https://huggingface.co/imbue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Code Comprehension\\n\\t\\n\\nCollection of code understanding questions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThese examples fall into 2 categories:\\n\\n\\\"cloze\\\": fill in the hole to produce the specified outcome;\\n\\\"eval\\\": given a snippet of python code, determine the outcome.\\n\\nSome questions are very easy, some are much more challenging.\\nMost (if not all) of these questions should be relatively straightforward\\nfor an experienced programmer, even‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/imbue/code-comprehension."},
	{"name":"Clapping_Sound_Dataset","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zahidpichen/Clapping_Sound_Dataset","creator_name":"zahidpichen","creator_url":"https://huggingface.co/zahidpichen","description":"zahidpichen/Clapping_Sound_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"github-issues","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kailasps/github-issues","creator_name":"Kailas P S","creator_url":"https://huggingface.co/kailasps","description":"kailasps/github-issues dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"code-generation-py","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dtruong46me/code-generation-py","creator_name":"Dinh Truong Phan","creator_url":"https://huggingface.co/dtruong46me","description":"dtruong46me/code-generation-py dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"German_RisingWorld_Alpaca-Dataset","keyword":"java","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Andzej-75/German_RisingWorld_Alpaca-Dataset","creator_name":"Andzej Ktowierzy","creator_url":"https://huggingface.co/Andzej-75","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGerman \\\"Rising World\\\"-Game Alpaca-Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Description\\n\\t\\n\\nThis HF data repository contains the German Alpaca dataset for the open-world sandbox game \\\"Rising World\\\".\\nDieses HF-Datenrepository enth√§lt den deutschen Alpaca-Datensatz f√ºr das Open-World-Sandbox-Spiel \\\"Rising World\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\n\\nThis data is intended for fine-tuning\\nThis data is useful for \\\"Rising World\\\" plug-in developers\\nEach instance has an instruction, an output, and an optional input. An‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Andzej-75/German_RisingWorld_Alpaca-Dataset."},
	{"name":"list-sorting","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ChandraP12330/list-sorting","creator_name":"Chandra Prakash","creator_url":"https://huggingface.co/ChandraP12330","description":"ChandraP12330/list-sorting dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"holiday_calendar","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saadbhaldar1212/holiday_calendar","creator_name":"Mohammad Saad Hasan Bhaldar","creator_url":"https://huggingface.co/saadbhaldar1212","description":"saadbhaldar1212/holiday_calendar dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"LAMx-2.2","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gokul00060/LAMx-2.2","creator_name":"SK Gokul","creator_url":"https://huggingface.co/gokul00060","description":"gokul00060/LAMx-2.2 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"test03","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/liuqingquan/test03","creator_name":"lqq","creator_url":"https://huggingface.co/liuqingquan","description":"liuqingquan/test03 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"puhui","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qijiabo/puhui","creator_name":"jiabo","creator_url":"https://huggingface.co/qijiabo","description":"qijiabo/puhui dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"UIT-CourseInfo","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PhucDanh/UIT-CourseInfo","creator_name":"Ngo Phuc Danh","creator_url":"https://huggingface.co/PhucDanh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nWe have meticulously compiled a comprehensive dataset consisting of 4,230 samples collected through advanced data crawling techniques from the University of Information Technology (UIT) website. This dataset includes detailed summaries of courses and extensive descriptions of various study programs offered at UIT. By targeting and extracting data from the student.uit domain, we have ensured that the dataset accurately represents the university's academic offerings.\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PhucDanh/UIT-CourseInfo."},
	{"name":"mermaid_code","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bucaro/mermaid_code","creator_name":"Jonathan B√∫caro","creator_url":"https://huggingface.co/bucaro","description":"bucaro/mermaid_code dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ML-Python-Code-Smells","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jonaskoenig/ML-Python-Code-Smells","creator_name":"Jonas K√∂nig","creator_url":"https://huggingface.co/jonaskoenig","description":"jonaskoenig/ML-Python-Code-Smells dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"movies-network-propogation-analysis","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jayksharma/movies-network-propogation-analysis","creator_name":"Jay Sharma","creator_url":"https://huggingface.co/jayksharma","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMovie Network Analysis\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains information about top-rated films and their shared actors, used to conduct network analysis and understand the factors contributing to their success. The analysis employs techniques like network construction, community detection, and centrality measures.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMotivation\\n\\t\\n\\nThe motivation behind this project is to explore connections between successful films through shared actors, aiming to provide‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jayksharma/movies-network-propogation-analysis."},
	{"name":"svgen_500k_rasterized_jsonified_uuided","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MrOvkill/svgen_500k_rasterized_jsonified_uuided","creator_name":"Samuel L Meyers","creator_url":"https://huggingface.co/MrOvkill","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSVGEN RJU - SVGEN 500k: Rasterized, JSONified, UUID'ed\\n\\t\\n\\nI have selected every svg image from svgen that would rasterize under cairosvg, which is significantly less than a 1% failure rate. Under development.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReasoning\\n\\t\\n\\nThis is the 1st of many SVG datasets I am collecting, extracting, and rasterizing in an attempt to produce a meaningfully helpful spatial reasoning and vertex manipulation model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThe rasterized images are in PNG format, as bytes.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MrOvkill/svgen_500k_rasterized_jsonified_uuided."},
	{"name":"Testing","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WendigoDaniel/Testing","creator_name":"Wendigo","creator_url":"https://huggingface.co/WendigoDaniel","description":"WendigoDaniel/Testing dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Synthetic-JP-Coding-Dataset-Magpie-Nemotron-4-10k","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Synthetic-JP-Coding-Dataset-Magpie-Nemotron-4-10k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic-JP-Coding-Dataset-Magpie-Nemotron-4-10k\\n\\t\\n\\nMagpie„ÅÆÊâãÊ≥ï„Çínvidia/Nemotron-4-340B-Instruct„Å´ÂØæ„Åó„Å¶ÈÅ©Áî®„Åó‰ΩúÊàê„Åó„Åü„ÄÅÁ¥Ñ10000‰ª∂„ÅÆÊó•Êú¨Ë™û„ÅÆ„Ç≥„Éº„Éá„Ç£„É≥„Ç∞Áî®ÂØæË©±„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ\\n„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆ‰ΩúÊàê„Å´„ÅØDeepInfra„ÇíÂà©Áî®„Åó„Åæ„Åó„Åü„ÄÇ\\n„Åæ„Åü„ÄÅ„Åì„ÅÆ„É™„Éù„Ç∏„Éà„É™„Åß„Éá„Éº„Çø„Çª„ÉÉ„Éà‰ΩúÊàê„Å´Áî®„ÅÑ„Åü„Ç≥„Éº„Éâ„ÇíÂÖ¨Èñã„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åì„Çå„Çí„Éô„Éº„Çπ„Å´„ÄÅ„Ç∑„Çπ„ÉÜ„É†„Éó„É≠„É≥„Éó„Éà„Å®stop„Çí‰∏ÄÈÉ®Â§âÊõ¥„Åô„Çã„Åì„Å®„ÅßÁîüÊàê„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\nÁâπ„Å´‰∫ãÂæåÁöÑ„Å™„Éï„Ç£„É´„ÇøÂá¶ÁêÜ„ÅØÂä†„Åà„Å¶„ÅÑ„Å™„ÅÑ„Åü„ÇÅ„ÄÅ„ÇØ„Ç™„É™„ÉÜ„Ç£„ÅÆ‰Ωé„ÅÑ„É¨„Ç≥„Éº„Éâ„ÅåÂê´„Åæ„Çå„Å¶„ÅÑ„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ„ÅîÊ≥®ÊÑè„Åè„Å†„Åï„ÅÑ„ÄÇ\\n"},
	{"name":"CodeHarmony","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Flab-Pruner/CodeHarmony","creator_name":"Flab-Pruner","creator_url":"https://huggingface.co/Flab-Pruner","description":"Acknowledging the limitations of current datasets with a limited number of samples, we have curated a new dataset CodeHarmony.\\nThis dataset is compiled from existing open-source datasets, such as the Evol dataset and OSS dataset. \\nTo ensure the semantic correctness of this dataset, we utilize GPT-3.5 and Gemini for automated test case generation, overseen by humans to ensure code functionality. \\nInspired by the multi-agent alignment, we have also integrated CoT data into the dataset. \\n"},
	{"name":"InverseCoder-CL-7B-Evol-Instruct-90K","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wyt2000/InverseCoder-CL-7B-Evol-Instruct-90K","creator_name":"Yutong Wu","creator_url":"https://huggingface.co/wyt2000","description":"\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct\\n\\t\\n\\n \\n\\nInverseCoder is a series of code LLMs instruction-tuned by generating data from itself through Inverse-Instruct.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModels and Datasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\nBase Model\\nInverseCoder\\nDataset\\n\\n\\n\\t\\t\\n6.7B\\ndeepseek-ai/deepseek-coder-6.7b-base\\nwyt2000/InverseCoder-DS-6.7B\\nwyt2000/InverseCoder-DS-6.7B-Evol-Instruct-90K\\n\\n\\n7B\\ncodellama/CodeLlama-7b-Python-hf\\nwyt2000/InverseCoder-CL-7B‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wyt2000/InverseCoder-CL-7B-Evol-Instruct-90K."},
	{"name":"news-sentiment-data","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sweatSmile/news-sentiment-data","creator_name":"amitk17","creator_url":"https://huggingface.co/sweatSmile","description":"sweatSmile/news-sentiment-data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"InverseCoder-DS-6.7B-Evol-Instruct-90K","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wyt2000/InverseCoder-DS-6.7B-Evol-Instruct-90K","creator_name":"Yutong Wu","creator_url":"https://huggingface.co/wyt2000","description":"\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct\\n\\t\\n\\n \\n\\nInverseCoder is a series of code LLMs instruction-tuned by generating data from itself through Inverse-Instruct.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModels and Datasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\nBase Model\\nInverseCoder\\nDataset\\n\\n\\n\\t\\t\\n6.7B\\ndeepseek-ai/deepseek-coder-6.7b-base\\nwyt2000/InverseCoder-DS-6.7B\\nwyt2000/InverseCoder-DS-6.7B-Evol-Instruct-90K <= You are here\\n\\n\\n7B\\ncodellama/CodeLlama-7b-Python-hf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wyt2000/InverseCoder-DS-6.7B-Evol-Instruct-90K."},
	{"name":"CodeHarmony","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Flab-Pruner/CodeHarmony","creator_name":"Flab-Pruner","creator_url":"https://huggingface.co/Flab-Pruner","description":"Acknowledging the limitations of current datasets with a limited number of samples, we have curated a new dataset CodeHarmony.\\nThis dataset is compiled from existing open-source datasets, such as the Evol dataset and OSS dataset. \\nTo ensure the semantic correctness of this dataset, we utilize GPT-3.5 and Gemini for automated test case generation, overseen by humans to ensure code functionality. \\nInspired by the multi-agent alignment, we have also integrated CoT data into the dataset. \\n"},
	{"name":"InverseCoder-CL-13B-Evol-Instruct-90K","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wyt2000/InverseCoder-CL-13B-Evol-Instruct-90K","creator_name":"Yutong Wu","creator_url":"https://huggingface.co/wyt2000","description":"\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct\\n\\t\\n\\n \\n\\nInverseCoder is a series of code LLMs instruction-tuned by generating data from itself through Inverse-Instruct.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModels and Datasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\nBase Model\\nInverseCoder\\nDataset\\n\\n\\n\\t\\t\\n6.7B\\ndeepseek-ai/deepseek-coder-6.7b-base\\nwyt2000/InverseCoder-DS-6.7B\\nwyt2000/InverseCoder-DS-6.7B-Evol-Instruct-90K\\n\\n\\n7B\\ncodellama/CodeLlama-7b-Python-hf\\nwyt2000/InverseCoder-CL-7B‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wyt2000/InverseCoder-CL-13B-Evol-Instruct-90K."},
	{"name":"Sentiment_lexicons","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mahmed31/Sentiment_lexicons","creator_name":"Muhammad Ahmed","creator_url":"https://huggingface.co/mahmed31","description":"mahmed31/Sentiment_lexicons dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"pyomo-100","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wickes1/pyomo-100","creator_name":"wickes","creator_url":"https://huggingface.co/wickes1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPyomo Code Generation Fine-Tuning Dataset (Generated by GPT-4o)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset is designed for fine-tuning the Phi3 model to generate Pyomo code based on user inputs and existing code contexts. It includes various examples of user queries, existing Pyomo code contexts, and AI-generated responses.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\n\\ninput: The user's query or task description.\\ncontext: The existing Pyomo code related to the query.\\noutput: The AI assistant's‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wickes1/pyomo-100."},
	{"name":"oop","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/codeai-dteam/oop","creator_name":"CodeAI","creator_url":"https://huggingface.co/codeai-dteam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlicense: apache-2.0\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Object-Oriented Programming\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe OOP benchmark consists of 431 instances, and contains three difficulty levels: Simple-level OOP, Moderate-level OOP, and Difficult-level OOP.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe Object-Oriented Programming problems are written in Python and contain English natural text in comments and docstrings.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/codeai-dteam/oop."},
	{"name":"FVELer","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FVELer/FVELer","creator_name":"FVELer","creator_url":"https://huggingface.co/FVELer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe FVELer Dataset\\n\\t\\n\\nDataset examples can be found at https://fveler.github.io/.\\n"},
	{"name":"Synthetic-JP-EN-Coding-Dataset-Magpie-69k","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Coding-Dataset-Magpie-69k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic-JP-EN-Coding-Dataset-Magpie-69k\\n\\t\\n\\nMagpie„ÅÆÊâãÊ≥ï„ÇíÊßò„ÄÖ„Å™„É¢„Éá„É´„Å´ÂØæ„Åó„Å¶ÈÅ©Áî®„Åó‰ΩúÊàê„Åó„Åü„ÄÅÁ¥Ñ69000‰ª∂„ÅÆÊó•Êú¨Ë™û„ÉªËã±Ë™û„ÅÆ„Ç≥„Éº„Éá„Ç£„É≥„Ç∞ÂØæË©±„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ\\n‰ΩúÊàê„Å´Âà©Áî®„Åó„Åü„É¢„Éá„É´„ÅØ‰ª•‰∏ã„ÅÆÈÄö„Çä„Åß„Åô„ÄÇmodel„Ç≠„Éº„Å´Ë©≤ÂΩì„É¨„Ç≥„Éº„Éâ„ÅÆ‰ΩúÊàê„Å´Âà©Áî®„Åó„Åü„É¢„Éá„É´ÊÉÖÂ†±„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ\\n\\nnvidia/Nemotron-4-340B-Instruct\\nmicrosoft/Phi-3-medium-4k-instruct\\nmistralai/Mixtral-8x22B-Instruct-v0.1\\ncyberagent/calm3-22b-chat\\n\\n„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆ‰ΩúÊàê„Å´„ÅØDeepInfra„ÇíÂà©Áî®„Åó„Åæ„Åó„Åü„ÄÇ\\n„Åæ„Åü„ÄÅ„Åì„ÅÆ„É™„Éù„Ç∏„Éà„É™„Åß„Éá„Éº„Çø„Çª„ÉÉ„Éà‰ΩúÊàê„Å´Áî®„ÅÑ„Åü„Ç≥„Éº„Éâ„ÇíÂÖ¨Èñã„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åì„Çå„Çí„Éô„Éº„Çπ„Å´„ÄÅ„Éó„É≠„É≥„Éó„Éà„ÉÜ„É≥„Éó„É¨„Éº„Éà„ÇÑ„Ç∑„Çπ„ÉÜ„É†„Éó„É≠„É≥„Éó„ÉàÁ≠â„Çí‰∏ÄÈÉ®Â§âÊõ¥„Åô„Çã„Åì„Å®„ÅßÁîüÊàê„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\nÁâπ„Å´‰∫ãÂæåÁöÑ„Å™„Éï„Ç£„É´„ÇøÂá¶ÁêÜ„ÅØÂä†„Åà„Å¶„ÅÑ„Å™„ÅÑ„Åü„ÇÅ„ÄÅ„ÇØ„Ç™„É™„ÉÜ„Ç£„ÅÆ‰Ωé„ÅÑ„É¨„Ç≥„Éº„Éâ„ÅåÂê´„Åæ„Çå„Å¶„ÅÑ„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ„ÅîÊ≥®ÊÑè„Åè„Å†„Åï„ÅÑ„ÄÇ\\n"},
	{"name":"alpaca_function_calling_dataset","keyword":"function calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Saxo/alpaca_function_calling_dataset","creator_name":"Ji","creator_url":"https://huggingface.co/Saxo","description":"\\n\\n\\n  \\nAI ÏôÄ ÎπÖÎç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Ï†ÑÎ¨∏ Í∏∞ÏóÖÏù∏ Linkbricks(www.linkbricks.com)Ïùò Îç∞Ïù¥ÌÑ∞ÏÇ¨Ïù¥Ïñ∏Ìã∞Ïä§Ìä∏Ïù∏ ÏßÄÏú§ÏÑ±(Saxo) Î∞ïÏÇ¨Í∞Ä ÎßåÎì† llm RAGÎ•º ÏúÑÌïú function calling ÌïôÏäµÏö© Îç∞Ïù¥ÌÑ∞ÏÖãÏúºÎ°ú llam3 instruct formatÏù∏ mzbac/function-calling-llama-3-format-v1.1 ÏùÑ Alpaca FormatÏúºÎ°ú Î≥ÄÍ≤Ω. \\nChanged the llam3 instruct format, mzbac/function-calling-llama-3-format-v1.1, to Alpaca Format as a dataset for learning function calling for the llm RAG, created by Dr. Ji Yun Sung(Saxo), a data scientist at Linkbricks (www.linkbricks.com), a company specializing in AI and big‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Saxo/alpaca_function_calling_dataset."},
	{"name":"German_RisingWorld_prompt-text-rejected_Jsonl","keyword":"java","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Andzej-75/German_RisingWorld_prompt-text-rejected_Jsonl","creator_name":"Andzej Ktowierzy","creator_url":"https://huggingface.co/Andzej-75","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGerman \\\"Rising World\\\"-Game Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Description\\n\\t\\n\\nThis HF data repository contains the German dataset for the open-world sandbox game \\\"Rising World\\\".\\nDieses HF-Datenrepository enth√§lt den deutschen Datensatz f√ºr das Open-World-Sandbox-Spiel \\\"Rising World\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\n\\nThis data is intended for fine-tuning\\nThis data is useful for \\\"Rising World\\\" plug-in developers\\n\\n"},
	{"name":"pyomo-100","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wickes1/pyomo-100","creator_name":"wickes","creator_url":"https://huggingface.co/wickes1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPyomo Code Generation Fine-Tuning Dataset (Generated by GPT-4o)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset is designed for fine-tuning the Phi3 model to generate Pyomo code based on user inputs and existing code contexts. It includes various examples of user queries, existing Pyomo code contexts, and AI-generated responses.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\n\\ninput: The user's query or task description.\\ncontext: The existing Pyomo code related to the query.\\noutput: The AI assistant's‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wickes1/pyomo-100."},
	{"name":"mypo-4k-rfc","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/joshuasundance/mypo-4k-rfc","creator_name":"Joshua Sundance Bailey","creator_url":"https://huggingface.co/joshuasundance","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmypo\\n\\t\\n\\nmypy + DPO = mypo\\n\\nThis is a preview version of what I'll be calling the mypo dataset, a DPO dataset focused on Python code quality. It is derived from iamtarun/python_code_instructions_18k_alpaca.\\nmypo-4k-rfc is a DPO dataset with three columns:\\n\\nprompt\\nfrom the original dataset\\n\\n\\nrejected\\ncode from the original dataset, found to have linting errors\\n\\n\\nchosen\\ncode from the original dataset, rewritten by codellama/CodeLlama-7b-Python-hf to address linting errors\\n\\n\\n\\nThe plan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joshuasundance/mypo-4k-rfc."},
	{"name":"simple-test","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BruceNju/simple-test","creator_name":"zhongyah","creator_url":"https://huggingface.co/BruceNju","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTriffic\\n\\t\\n\\n"},
	{"name":"Synthetic-JP-EN-Coding-Dataset-801k","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Coding-Dataset-801k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic-JP-EN-Coding-Dataset-801k\\n\\t\\n\\nMagpie„Å´„Çà„Å£„Å¶‰ΩúÊàê„Åó„Åü„Ç≥„Éº„ÉâSFT„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„ÅÇ„ÇãAratako/Synthetic-JP-EN-Coding-Dataset-Magpie-69k„ÇíÂÖÉ„Å´„ÄÅEvol-Instruct„ÅÆ„Çà„ÅÜ„Å™ÊâãÊ≥ï„ÇíÁî®„ÅÑ„Å¶Ë§áÊï∞„ÅÆinstruction„Å®resonse„ÇíÁîüÊàê„ÅóÊã°Âºµ„Åó„Å¶‰ΩúÊàê„Åó„Åü„ÄÅÊó•Ëã±Ê∑∑Âêà801262‰ª∂„ÅÆ„Ç≥„Éº„ÉâSFTÁî®ÂêàÊàê„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ\\n\\nÊó•Êú¨Ë™û: 173849‰ª∂\\nËã±Ë™û: 627413‰ª∂\\n\\nÂÖÉ„ÅÆinstruction„ÅÆ‰ΩúÊàê„Å´Âà©Áî®„Åó„Åü„É¢„Éá„É´„ÅØ‰ª•‰∏ã„ÅÆÈÄö„Çä„Åß„Åô„ÄÇmodel„Ç≠„Éº„Å´Ë©≤ÂΩì„É¨„Ç≥„Éº„Éâ„ÅÆ‰ΩúÊàê„Å´Âà©Áî®„Åó„Åü„É¢„Éá„É´ÊÉÖÂ†±„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ\\n\\nnvidia/Nemotron-4-340B-Instruct\\nmicrosoft/Phi-3-medium-4k-instruct\\nmistralai/Mixtral-8x22B-Instruct-v0.1\\ncyberagent/calm3-22b-chat‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Coding-Dataset-801k."},
	{"name":"mypo-4k-rfc-val-phi3test","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/joshuasundance/mypo-4k-rfc-val-phi3test","creator_name":"Joshua Sundance Bailey","creator_url":"https://huggingface.co/joshuasundance","description":"data: 100 rows of https://huggingface.co/datasets/joshuasundance/mypo-4k-rfc validation split\\nbase: https://huggingface.co/edumunozsala/phi3-mini-4k-qlora-python-code-20k\\ndpo: https://huggingface.co/joshuasundance/phi3-mini-4k-qlora-python-code-20k-mypo-4k-rfc-pipe\\nmade to compare base vs dpo\\nbut apparently I clipped the beginning of some of the dpo outputs with sloppy coding\\nwill update later\\nbase: 16:55, 10.16s/it\\nDPO: 15:36,  9.36s/it\\n"},
	{"name":"icml2024_embeddings","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/porestar/icml2024_embeddings","creator_name":"Lukas Mosser","creator_url":"https://huggingface.co/porestar","description":"porestar/icml2024_embeddings dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"mozzarella","keyword":"java","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/feedback-to-code/mozzarella","creator_name":"Feedback-2-Code","creator_url":"https://huggingface.co/feedback-to-code","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMozzarella-0.3.1 \\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMotivation\\n\\t\\n\\n\\nMozzarella is a dataset matching issues (= problem statements) and corresponding pull requests (PRs = problem solutions) of a selection of well maintained Java GitHub repositories. The original purpose was to serve as training and evaluation data for ML models concerned with fault localization and automated program repair of complex code bases. However, there might be more use cases that could benefit from this data. \\nInspired by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/feedback-to-code/mozzarella."},
	{"name":"love2dapi_chunks","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Nocare3/love2dapi_chunks","creator_name":"Andi Allaraj","creator_url":"https://huggingface.co/Nocare3","description":"LOVE2d API - Lua Game Engine\\nThis dataset represents the API documentation for the LOVE2d Lua game engine. It was taken from https://love2d-community.github.io/love-api.\\nThe goal is to use it to train a chatbot that can easily answer users' questions regarding the engine.\\nThis would likely help people that want a more conversational approach to finding the code they need for specific tasks.\\n"},
	{"name":"leetcode-rosetta","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/scottsuk0306/leetcode-rosetta","creator_name":"Juyoung Suk","creator_url":"https://huggingface.co/scottsuk0306","description":"scottsuk0306/leetcode-rosetta dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cat-breed-blip-fine-tuning","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zahidpichen/cat-breed-blip-fine-tuning","creator_name":"zahidpichen","creator_url":"https://huggingface.co/zahidpichen","description":"zahidpichen/cat-breed-blip-fine-tuning dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"data","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zahidpichen/data","creator_name":"zahidpichen","creator_url":"https://huggingface.co/zahidpichen","description":"zahidpichen/data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cs_tiny_codes_alpaca","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abhijitkumarjha88192/cs_tiny_codes_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/cs_tiny_codes_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"buddhi-dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aiplanet/buddhi-dataset","creator_name":"AI Planet","creator_url":"https://huggingface.co/aiplanet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuddhi Dataset\\n\\t\\n\\nThis dataset was used to train our 128K context window model: Buddhi-128k-Chat-7B. The dataset was generated in a Self-Instruct style using GPT-4 and GPT-3 models, along with data from the Stack Exchange and PG19 open-source datasets.\\nBuddhi-128K-Chat\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuddhi-128K-Chat (7B) vLLM Inference: \\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRead release article: üîó Introducing Buddhi: Open-Source Chat Model with a 128K Context Window üîó \\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Description‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aiplanet/buddhi-dataset."},
	{"name":"cat_breed","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zahidpichen/cat_breed","creator_name":"zahidpichen","creator_url":"https://huggingface.co/zahidpichen","description":"zahidpichen/cat_breed dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"py_tiny_codes_alpaca","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abhijitkumarjha88192/py_tiny_codes_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/py_tiny_codes_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"js_tiny_codes_alpaca","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abhijitkumarjha88192/js_tiny_codes_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/js_tiny_codes_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ts_tiny_codes_alpaca","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abhijitkumarjha88192/ts_tiny_codes_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/ts_tiny_codes_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cs_repl_ai_alpaca","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abhijitkumarjha88192/cs_repl_ai_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/cs_repl_ai_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"py_repl_ai_alpaca","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abhijitkumarjha88192/py_repl_ai_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/py_repl_ai_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"js_repl_ai_alpaca","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abhijitkumarjha88192/js_repl_ai_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/js_repl_ai_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ts_repl_ai_alpaca","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abhijitkumarjha88192/ts_repl_ai_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/ts_repl_ai_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sql_repl_ai_alpaca","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abhijitkumarjha88192/sql_repl_ai_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/sql_repl_ai_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"mmau","keyword":"function-calling","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/apple/mmau","creator_name":"Apple","creator_url":"https://huggingface.co/apple","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMAU Dataset: A Holistic Benchmark of Agent Capabilities Across Diverse Domains\\n\\t\\n\\n\\n\\n"},
	{"name":"jinaai_jina-embeddings-v2-base-en-862024-gra4-webapp","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-862024-gra4-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-en-862024-gra4-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"E-commerce software for an online store\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-862024-gra4-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-862024-gra4-webapp."},
	{"name":"Tachibana","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Tachibana","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Tachibana is a dataset containing code-instruct data.\\nThe 2024-09-27 version contains:\\n\\n104k rows of synthetic chat responses generated using Llama 3.1 405b Instruct.\\n60.6k Magicoder prompts from ise-uiuc/Magicoder-Evol-Instruct-110K\\n43.4k Glaive-code-assistant prompts from glaiveai/glaive-code-assistant\\n\\n\\n\\nThis dataset contains synthetically generated data and has not been subject to manual review.\\n"},
	{"name":"Tachibana","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Tachibana","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Tachibana is a dataset containing code-instruct data.\\nThe 2024-09-27 version contains:\\n\\n104k rows of synthetic chat responses generated using Llama 3.1 405b Instruct.\\n60.6k Magicoder prompts from ise-uiuc/Magicoder-Evol-Instruct-110K\\n43.4k Glaive-code-assistant prompts from glaiveai/glaive-code-assistant\\n\\n\\n\\nThis dataset contains synthetically generated data and has not been subject to manual review.\\n"},
	{"name":"knowledge_consistency_of_LLMs","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ibm-research/knowledge_consistency_of_LLMs","creator_name":"IBM Research","creator_url":"https://huggingface.co/ibm-research","description":"\\n\\t\\n\\t\\t\\n\\t\\tWhat it is:\\n\\t\\n\\nEach dataset in this delivery is made up of query clusters that test an aspect of the consistency of the LLM knowledge about a particular domain. All the questions in each\\ncluster are meant to be answered either 'yes' or 'no'. When the answers vary within a cluster, the knowledge is said to be inconsistent. When all the questions in a cluster \\nare answered 'no' when the expected answer is 'yes' (or viceversa), the knowledge is said to be 'incomplete' (i.e., maybe the LLM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/knowledge_consistency_of_LLMs."},
	{"name":"SynthUI-Code-2k-v1","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JulianAT/SynthUI-Code-2k-v1","creator_name":"Julian Schmidt","creator_url":"https://huggingface.co/JulianAT","description":"Synth UI üéπ\\nhttps://www.synthui.design\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset details\\n\\t\\n\\nThis dataset aims to provide a diverse collection of NextJS code snippets, along with their corresponding instructions, to facilitate the training of language models for NextJS-related tasks. It is designed to cover a wide range of NextJS functionalities, including UI components, routing, state management, and more.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis dataset consists of:\\n\\t\\n\\n\\nNote: The dataset is seperated into two main parts:\\n\\nraw Contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JulianAT/SynthUI-Code-2k-v1."},
	{"name":"custom_llm_data","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/drgary/custom_llm_data","creator_name":"DrYe","creator_url":"https://huggingface.co/drgary","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Train Brand LLM?\\n\\t\\n\\n\\nLaunch Athena Generative AI Starter Kit from AWS Marketplace (see https://aws.amazon.com/marketplace/pp/prodview-su3dsq7b4plxw) \\nThis is public Dataset 1 for training generic Model m2, code at host 4090 ~/athena/m2/m2_athena3.py\\nUse Parquet Hub to add private brand Dataset 2 to the m2 parquet file. Then train Model m3, the enterprise Brand LLM {see \\\"Brand LLM: Parquet Hub\\\"}\\nRun Model m3 training code at host 4090 ~/athena/m3/m3_model.py\\nRemember 'conda‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/drgary/custom_llm_data."},
	{"name":"text_to_jsonFormSchema","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shankerhrm/text_to_jsonFormSchema","creator_name":"Jaishanker","creator_url":"https://huggingface.co/shankerhrm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shankerhrm/text_to_jsonFormSchema."},
	{"name":"summary-demo","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jacquetg/summary-demo","creator_name":"Gottfried JACQUET","creator_url":"https://huggingface.co/jacquetg","description":"jacquetg/summary-demo dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"essays-big5","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jingjietan/essays-big5","creator_name":"Tan Jing Jie","creator_url":"https://huggingface.co/jingjietan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPersonality Dataset\\n\\t\\n\\nEssays\\nhttps://huggingface.co/datasets/jingjietan/essays-big5\\nMBTI\\nhttps://huggingface.co/datasets/jingjietan/kaggle-mbti\\nPandora\\nhttps://huggingface.co/datasets/jingjietan/pandora-big5\\nCite:\\n@software{jingjietan-apr-dataset,\\n  author = {Jing Jie, Tan},\\n  title = {Personality Essays Dataset Splitting},\\n  url = {https://huggingface.co/datasets/jingjietan/essays-big5},\\n  version = {1.0.0},\\n  year = {2024}\\n}\\n"},
	{"name":"kaggle-mbti","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jingjietan/kaggle-mbti","creator_name":"Tan Jing Jie","creator_url":"https://huggingface.co/jingjietan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPersonality Dataset\\n\\t\\n\\nEssays\\nhttps://huggingface.co/datasets/jingjietan/essays-big5\\nMBTI\\nhttps://huggingface.co/datasets/jingjietan/kaggle-mbti\\nPandora\\nhttps://huggingface.co/datasets/jingjietan/pandora-big5\\nPlease contact jingjietan.com for another dataset.\\nCite:\\n@software{jingjietan-apr-dataset,\\n  author = {Jing Jie, Tan},\\n  title = {Personality Kaggle Dataset Splitting},\\n  url = {https://huggingface.co/datasets/jingjietan/kaggle-mbti},\\n  version = {1.0.0},\\n  year = {2024}\\n}\\n"},
	{"name":"jinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp","keyword":"sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Database schema for a data management system\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-7232024-77ap-webapp."},
	{"name":"Code-Feedback-Parsed","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kaleinaNyan/Code-Feedback-Parsed","creator_name":"Igor Kilbas","creator_url":"https://huggingface.co/kaleinaNyan","description":"This is a parsed subset of the Code-Feedback dataset.\\nEach sample in the dataset is formatted in the following way:\\n{\\\"messages\\\": [\\n  {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"user prompt\\\"}, \\n  {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"assistant response\\\", \\\"tool_call\\\": \\\"python code\\\"}, \\n  {\\\"role\\\": \\\"tool\\\", \\\"content\\\": \\\"code execution result\\\"},\\n  {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"assistant response\\\"},\\n]}\\n\\nThe dataset has been filtered from any refusials, mentions of OpenAI, quantum computing, crypto currency and other‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kaleinaNyan/Code-Feedback-Parsed."},
	{"name":"small_kitchen_appliances_review","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jr-d-analyst24/small_kitchen_appliances_review","creator_name":"dayoungyoun","creator_url":"https://huggingface.co/jr-d-analyst24","description":"jr-d-analyst24/small_kitchen_appliances_review dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"lx","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llanguagemtrainer/lx","creator_name":"praveen","creator_url":"https://huggingface.co/llanguagemtrainer","description":"llanguagemtrainer/lx dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"uk_dataset","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rahayu/uk_dataset","creator_name":"Rahayu","creator_url":"https://huggingface.co/rahayu","description":"rahayu/uk_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"github-code-fontend-lang","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LiXiang12/github-code-fontend-lang","creator_name":"XiangLi","creator_url":"https://huggingface.co/LiXiang12","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tgithub-code fontend code\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDwonload\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊñπÂºè‰∏Ä\\n\\t\\n\\nhuggingface-cli download --resume-download LiXiang12/github-code-fontend-lang --include \\\"*/*.zip\\\" --repo-type dataset  --local-dir github_code\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊñπÂºè‰∫å\\n\\t\\n\\nËøõÂÖ•Files and versions/dataÁõ¥Êé•‰∏ãËΩΩzipÊñá‰ª∂\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÁªüËÆ°\\n\\t\\n\\n\\n"},
	{"name":"bio-image-analysis-qa","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/haesleinhuepf/bio-image-analysis-qa","creator_name":"Robert Haase","creator_url":"https://huggingface.co/haesleinhuepf","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for bio-image-analysis-qa\\n\\t\\n\\nThis dataset contains questions and answers for analysing biological microscopy imaging data using python.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nQuestions and answers provided in this repository are centered around the topic, how to process imaging data using Python. \\n\\nCurated by: Robert Haase\\nLicense: CC-BY 4.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources and Processing\\n\\t\\n\\nThis dataset was derived from the Bio-image Analysis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haesleinhuepf/bio-image-analysis-qa."},
	{"name":"SynthUI-Code-Instruct-2k-v1","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JulianAT/SynthUI-Code-Instruct-2k-v1","creator_name":"Julian Schmidt","creator_url":"https://huggingface.co/JulianAT","description":"Synth UI üéπ\\nhttps://www.synthui.design\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset details\\n\\t\\n\\nThis dataset aims to provide a diverse collection of NextJS code snippets, along with their corresponding instructions, to facilitate the training of language models for NextJS-related tasks. It is designed to cover a wide range of NextJS functionalities, including UI components, routing, state management, and more.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis dataset consists of:\\n\\t\\n\\n\\nNote: The dataset is seperated into two main parts:\\n\\nraw Contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JulianAT/SynthUI-Code-Instruct-2k-v1."},
	{"name":"xlam-function-calling-60k-shareGPT","keyword":"function calling","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NewEden/xlam-function-calling-60k-shareGPT","creator_name":"New Eden","creator_url":"https://huggingface.co/NewEden","description":"ShareGPT converted version of Salesforce/xlam-function-calling-60k \\n"},
	{"name":"bio-image-analysis-qa","keyword":"python","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/haesleinhuepf/bio-image-analysis-qa","creator_name":"Robert Haase","creator_url":"https://huggingface.co/haesleinhuepf","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for bio-image-analysis-qa\\n\\t\\n\\nThis dataset contains questions and answers for analysing biological microscopy imaging data using python.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nQuestions and answers provided in this repository are centered around the topic, how to process imaging data using Python. \\n\\nCurated by: Robert Haase\\nLicense: CC-BY 4.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources and Processing\\n\\t\\n\\nThis dataset was derived from the Bio-image Analysis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haesleinhuepf/bio-image-analysis-qa."},
	{"name":"codesearchnet-codegen","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pengyunie/codesearchnet-codegen","creator_name":"Pengyu Nie","creator_url":"https://huggingface.co/pengyunie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CodeSearchNet for CodeGen\\n\\t\\n\\n\\n\\nThis is a processed version of the CodeSearchNet dataset. Namely, I separated the doc (documentation/docstring), sign (function signature), and output (function body) into separate fields; doc and sign are concatenated (according to the correct order of the programming language) into the problem field, making it suitable for the code generation task.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pengyunie/codesearchnet-codegen."},
	{"name":"assist-llm-function-calling-llama3-chat","keyword":"function-calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenporter/assist-llm-function-calling-llama3-chat","creator_name":"Allen Porter","creator_url":"https://huggingface.co/allenporter","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFunction Calling dataset for Assist LLM for Home Assistant\\n\\t\\n\\nThis dataset is generated by using other conversation agent pipelines as teachers\\nfrom the deivce-actions-v2 dataset.\\nThis dataset is used to support fine tuning of llama based models.\\nSee Device Actions for a notebook for construction of this dataset and the device-actions dataset.\\n"},
	{"name":"assist-llm-function-calling","keyword":"function-calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenporter/assist-llm-function-calling","creator_name":"Allen Porter","creator_url":"https://huggingface.co/allenporter","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFunction Calling dataset for Assist LLM for Home Assistant\\n\\t\\n\\nThis dataset is generated by using other conversation agent pipelines as teachers\\nfrom the deivce-actions-v2 dataset.\\nThis dataset is used to support fine tuning of llama based models.\\nSee Device Actions for a notebook for construction of this dataset and the device-actions dataset.\\n"},
	{"name":"assist-llm-function-calling-messages","keyword":"function-calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenporter/assist-llm-function-calling-messages","creator_name":"Allen Porter","creator_url":"https://huggingface.co/allenporter","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFunction Calling dataset for Assist LLM for Home Assistant\\n\\t\\n\\nThis dataset is generated by using other conversation agent pipelines as teachers\\nfrom the deivce-actions-v2 dataset.\\nThis dataset is used to support fine tuning of llama based models.\\nSee Device Actions for a notebook for construction of this dataset and the device-actions dataset.\\n"},
	{"name":"CodeJudge-Eval","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CodeResearch/CodeJudge-Eval","creator_name":"Open Code LLM Research Community","creator_url":"https://huggingface.co/CodeResearch","description":"\\nCodeJudge-Eval:  Can Large Language Models be Good Judges in Code Understanding?\\n If our project helps you, please give us a star ‚≠ê on GitHub to support us. üôèüôè \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nRecent advancements in large language models (LLMs) have showcased impressive code generation capabilities, primarily evaluated through language-to-code benchmarks. However, these benchmarks may not fully capture a model's code understanding abilities. We introduce CodeJudge-Eval (CJ-Eval), a novel‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CodeResearch/CodeJudge-Eval."},
	{"name":"Celestia","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Celestia","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Celestia is a dataset containing science-instruct data.\\nThe 2024-10-30 version contains:\\n\\n126k rows of synthetic science-instruct data, using synthetically generated prompts and responses generated using Llama 3.1 405b Instruct. Primary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\\n\\nThis dataset contains synthetically generated data and has not been subject to manual review.\\n"},
	{"name":"muri-it-language-split","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split."},
	{"name":"PythonCombined","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Montecarlo2024/PythonCombined","creator_name":"James","creator_url":"https://huggingface.co/Montecarlo2024","description":"Dataset is a combination of:\\nflytech/python-codes-25k, \\nNa0s/sft-ready-iamtarun-python-code-instructions-18k-alpaca, \\nmlabonne/Evol-Instruct-Python-26k, \\niamtarun/python_code_instructions_18k_alpaca\\nThis is a test for model building\\n"},
	{"name":"jupyter-code-text-pairs-merged","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/taher30/jupyter-code-text-pairs-merged","creator_name":"Taherali Patrawala","creator_url":"https://huggingface.co/taher30","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMerged Jupyter Notebooks Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset is a transformed version of the Jupyter Code-Text Pairs dataset. The original dataset contains markdown, code, and output pairs extracted from Jupyter notebooks. This transformation merges these components into a single, cohesive format that resembles a Jupyter notebook, making it easier to analyze and understand the flow of information.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/taher30/jupyter-code-text-pairs-merged."},
	{"name":"CleverBoi","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/CleverBoi","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCleverBoi\\n\\t\\n\\nThe CleverBoi Collection is based on a number of data sets that emphasize logic, inference, empathy, math and coding.\\nThe data set has been formatted to follow the alpaca format (instruction + input -> output) when fine tuning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Sets\\n\\t\\n\\nThe source data sets used in the CleverBoi Collection are listed below, ordered by size.\\n\\nKK04/LogicInference_OA\\nmlabonne/Evol-Instruct-Python-26k\\ngarage-bAInd/Open-Platypus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/theprint/CleverBoi."},
	{"name":"exoplanets-sql","keyword":"sql","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dpv/exoplanets-sql","creator_name":"Dmitriy Popov-Velasco","creator_url":"https://huggingface.co/dpv","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExoplanets text-to-SQL\\n\\t\\n\\nThis is a small dataset based on https://www.kaggle.com/datasets/adityamishraml/nasaexoplanets/data.  sqlite table exoplanets was made from the data, along with a reference_planets table made by inserting  (name, mass) VALUES ('Jupiter', 1.898e27) and  (name, mass) VALUES ('Earth', 5.972e24).\\nThe mass_wrt column in exoplanets maps to the mass column in reference_planets, allowing for more complex queries involving joins.  Queries have been checked for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dpv/exoplanets-sql."},
	{"name":"bss-custom-dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bizlaz/bss-custom-dataset","creator_name":"biz-lazy","creator_url":"https://huggingface.co/bizlaz","description":"bizlaz/bss-custom-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"FutureVision","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aymenbhh/FutureVision","creator_name":"Aymen Ben hadj","creator_url":"https://huggingface.co/Aymenbhh","description":"Aymenbhh/FutureVision dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"wikireading","keyword":"code","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/its5Q/wikireading","creator_name":"its5Q","creator_url":"https://huggingface.co/its5Q","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Wikireading\\n\\t\\n\\nThis is a dataset of book chapters scraped from a Russian website called Wikireading.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWikireading is a collection of non-fiction educational books in various domains: Biology, Art, History, Religion and much more. The books are highly educational and provide vast knowledge in different domains, making this dataset a good choice for pretraining.\\nThe resulting dataset contains ~26M rows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/its5Q/wikireading."},
	{"name":"glaive-function-calling-v2-pl","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mpieck/glaive-function-calling-v2-pl","creator_name":"Maciej Piecko","creator_url":"https://huggingface.co/mpieck","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for glaive-function-calling-v2-pl Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a fragment of glaiveai/glaive-function-calling-v2 dataset translated to polish. \\nIt contains first 3.3k (out of 5k total, this is work in progress) instructions of the original dataset. Only instructions having function definitions or function calls are included, instructions without functions (ordinary unstructured) from the original dataset are skipped.\\n Some repeating instructions were‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mpieck/glaive-function-calling-v2-pl."},
	{"name":"JHumanEval-Mod","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/myst72/JHumanEval-Mod","creator_name":"Miyu Sato","creator_url":"https://huggingface.co/myst72","description":"myst72/JHumanEval-Mod dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"glaive-function-calling-v2-pl","keyword":"function-calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mpieck/glaive-function-calling-v2-pl","creator_name":"Maciej Piecko","creator_url":"https://huggingface.co/mpieck","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for glaive-function-calling-v2-pl Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a fragment of glaiveai/glaive-function-calling-v2 dataset translated to polish. \\nIt contains first 3.3k (out of 5k total, this is work in progress) instructions of the original dataset. Only instructions having function definitions or function calls are included, instructions without functions (ordinary unstructured) from the original dataset are skipped.\\n Some repeating instructions were‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mpieck/glaive-function-calling-v2-pl."},
	{"name":"linux-commands","keyword":"linux","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrheinen/linux-commands","creator_name":"Niels Heinen","creator_url":"https://huggingface.co/mrheinen","description":"mrheinen/linux-commands dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sentence-correction","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Ashraf-CK/sentence-correction","creator_name":"Chauhan","creator_url":"https://huggingface.co/Ashraf-CK","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLLM Prompt Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe LLM Prompt Dataset is designed to enhance the performance of large language models (LLMs) by transforming user inputs into structured prompts. This dataset aims to facilitate the understanding of complex queries and improve the interaction between users and LLMs.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset is organized in JSON format, where each entry consists of an input and a prompt. The input represents the original user query‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ashraf-CK/sentence-correction."},
	{"name":"sentence-corrector","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedAshraf701/sentence-corrector","creator_name":"ashraf chauhan","creator_url":"https://huggingface.co/MohamedAshraf701","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentence Correction & Politeness Dataset\\n\\t\\n\\nThis repository contains a dataset specifically designed for sentence correction and politeness transformation. The dataset includes a set of input sentences and their corresponding polite, well-formatted outputs. It can be used to train AI models to rephrase user inputs in a more formal, polite, and grammatically correct manner.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Sentence Correction & Politeness Dataset is designed to help improve natural‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MohamedAshraf701/sentence-corrector."},
	{"name":"lovebangla","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SrejonAhamed/lovebangla","creator_name":"Joy","creator_url":"https://huggingface.co/SrejonAhamed","description":"SrejonAhamed/lovebangla dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"BanglaBoro","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SrejonAhamed/BanglaBoro","creator_name":"Joy","creator_url":"https://huggingface.co/SrejonAhamed","description":"SrejonAhamed/BanglaBoro dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"python-code-DPO-fine-tune","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/quangduc1112001/python-code-DPO-fine-tune","creator_name":"Nguyen Quang Duc","creator_url":"https://huggingface.co/quangduc1112001","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDirect Preference Optimization (DPO) Fine-tuning Dataset Description\\n\\t\\n\\nSimilar to standard datasets utilized in RLHF, this dataset comprises a total of 2,000 rows of data, with each row consisting of three distinct fields: prompt, chosen and rejected. Among these properties, the prompt and chosen fields are randomly picked from the dataset known as iamtarun/python_code_instructions_18k_alpaca while the rejected field is obtained from the inference of the base LLAMA 3.1 model based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/quangduc1112001/python-code-DPO-fine-tune."},
	{"name":"digdeep_data","keyword":"code","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryan1288/digdeep_data","creator_name":"Ryan Lee","creator_url":"https://huggingface.co/ryan1288","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVolleyball Video Analytics Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is designed to support AI tools for analyzing volleyball games. It contains both raw footage (before processing) and short video snippets with 6 consecutive plays including downtime.\\nGitHub Link\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPlanned Features üìã\\n\\t\\n\\n\\nAuto-Editor: Automatically remove downtime between plays for faster video review.\\nScore Tracking: Timestamp key moments and keep an accurate score throughout the video.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryan1288/digdeep_data."},
	{"name":"portufake","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unfake/portufake","creator_name":"Unfake","creator_url":"https://huggingface.co/unfake","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Portufake\\n\\t\\n\\n\\n\\nThis dataset contains spectrograms of audio deepfakes and real speaker recordings in Portuguese, originating from Fake Voices Dataset \\nand CETUC Corpus, respectively.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nThe dataset contains 183,878 512px x 256px colored constant-Q transform (CQT) spectrograms created from audios categorized in two labels: \\\"real\\\" or \\\"fake\\\". \\nThey correspond, respectively, to Brazilian Portuguese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unfake/portufake."},
	{"name":"ReflectionofaLilly","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sephfox/ReflectionofaLilly","creator_name":"Sephfox","creator_url":"https://huggingface.co/Sephfox","description":"Sephfox/ReflectionofaLilly dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CodeEval","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/chungimungi/CodeEval","creator_name":"Aarush","creator_url":"https://huggingface.co/chungimungi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCodeEval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nLanguage\\nCount\\n\\n\\n\\t\\t\\nPython\\n50\\n\\n\\nJavaScript\\n40\\n\\n\\nJava\\n40\\n\\n\\nRuby\\n20\\n\\n\\nC++\\n20\\n\\n\\nTypeScript\\n10\\n\\n\\nGo\\n20\\n\\n\\nC#\\n10\\n\\n\\nRust\\n10\\n\\n\\nTotal\\n220\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorrectness Statistics\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nCorrectness\\nCount\\n\\n\\n\\t\\t\\nTrue\\n127\\n\\n\\nFalse\\n93\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset is structured as follows:\\n[\\n    {\\n        \\\"language\\\": \\\"python\\\",\\n        \\\"code\\\": \\\"def reverse_string(s):\\\\n    return s.reverse()\\\",\\n        \\\"correctness\\\": false,\\n        \\\"explanation\\\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chungimungi/CodeEval."},
	{"name":"gemma-function-calling-eval","keyword":"function calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dushj98/gemma-function-calling-eval","creator_name":"Dinushi Jayasinghe","creator_url":"https://huggingface.co/dushj98","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüëâüèΩ Important\\n\\t\\n\\nThis dataset is adapted from Berkeley Function Calling Leaderboard Dataset to evaluate the function calling ability of dushj98/gemma-function-calling fine-tuned LLM.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüîÄ Changes Made\\n\\t\\n\\n\\nMerged questions and expected function call as a single conversation.\\nConverted function definitions to a valid JSON schema that follows OpenAI function schema, removed 227 examples that had invalid JSON schema definitions.\\nMerged \\\"simple\\\", \\\"multiple\\\", \\\"irrelevance\\\" and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dushj98/gemma-function-calling-eval."},
	{"name":"TerryADavisTempleOSYouTubeChannel","keyword":"programming","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuckMcSneed/TerryADavisTempleOSYouTubeChannel","creator_name":"Charles McSneed","creator_url":"https://huggingface.co/ChuckMcSneed","description":"\\n\\t\\n\\t\\t\\n\\t\\tWarning! Contains offensive language!\\n\\t\\n\\nThis is a mirror of https://archive.org/details/TerryADavisTempleOSYouTubeChannelArchive. Why? Becuse download speed is faster on HuggingFace.\\n\\n\\t\\n\\t\\t\\n\\t\\tNote for mods:\\n\\t\\n\\nWhile videos featuring Terry A. Davis often contain crude language, I respectfully request that these videos not be removed. \\nTerry Davis is a significant cultural icon in the tech community, representing both the brilliance and struggles of neurodivergent individuals in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ChuckMcSneed/TerryADavisTempleOSYouTubeChannel."},
	{"name":"sample_synthetic_text_to_sql","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chakshu2/sample_synthetic_text_to_sql","creator_name":"vodala chakshu","creator_url":"https://huggingface.co/chakshu2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample Synthetic Text to SQL Dataset\\n\\t\\n\\nThe dataset presents a substantial collection of expertly crafted Text-to-SQL samples, generated using open source LLM's and \\nshared under an open-source license. Highlights of the dataset include:\\n-- 1563 examples, divided into a training set of 1200 samples and a test set of 363 samples.-- Approximately less than 1 million tokens in total, with nearly 0.5 million representing code-specific tokens.-- Coverage spans a diverse range of 3‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chakshu2/sample_synthetic_text_to_sql."},
	{"name":"exLong-dataset","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/EngineeringSoftware/exLong-dataset","creator_name":"EngineeringSoftware","creator_url":"https://huggingface.co/EngineeringSoftware","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\texLong Dataset\\n\\t\\n\\nThis dataset is used to train and evaluate the exLong models on generating exceptional-behavior tests.\\nIt has two subsets:\\n\\n'with-EBT-name': provides the target test name in the prompt\\n'no-EBT-name': does not provide the target test name in the prompt\\n\\nNOTE: the data format is customized for Code Llama models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguage\\n\\t\\n\\nThis is a Java dataset\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe input for the model contains the following context:\\n\\nMethod under test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EngineeringSoftware/exLong-dataset."},
	{"name":"sample_synthetic_text_to_sql","keyword":"sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chakshu2/sample_synthetic_text_to_sql","creator_name":"vodala chakshu","creator_url":"https://huggingface.co/chakshu2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample Synthetic Text to SQL Dataset\\n\\t\\n\\nThe dataset presents a substantial collection of expertly crafted Text-to-SQL samples, generated using open source LLM's and \\nshared under an open-source license. Highlights of the dataset include:\\n-- 1563 examples, divided into a training set of 1200 samples and a test set of 363 samples.-- Approximately less than 1 million tokens in total, with nearly 0.5 million representing code-specific tokens.-- Coverage spans a diverse range of 3‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chakshu2/sample_synthetic_text_to_sql."},
	{"name":"sample_synthetic_text_to_sql","keyword":"text-to-sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chakshu2/sample_synthetic_text_to_sql","creator_name":"vodala chakshu","creator_url":"https://huggingface.co/chakshu2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample Synthetic Text to SQL Dataset\\n\\t\\n\\nThe dataset presents a substantial collection of expertly crafted Text-to-SQL samples, generated using open source LLM's and \\nshared under an open-source license. Highlights of the dataset include:\\n-- 1563 examples, divided into a training set of 1200 samples and a test set of 363 samples.-- Approximately less than 1 million tokens in total, with nearly 0.5 million representing code-specific tokens.-- Coverage spans a diverse range of 3‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chakshu2/sample_synthetic_text_to_sql."},
	{"name":"sample_synthetic_text_to_sql","keyword":"text-to-sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chakshu2/sample_synthetic_text_to_sql","creator_name":"vodala chakshu","creator_url":"https://huggingface.co/chakshu2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample Synthetic Text to SQL Dataset\\n\\t\\n\\nThe dataset presents a substantial collection of expertly crafted Text-to-SQL samples, generated using open source LLM's and \\nshared under an open-source license. Highlights of the dataset include:\\n-- 1563 examples, divided into a training set of 1200 samples and a test set of 363 samples.-- Approximately less than 1 million tokens in total, with nearly 0.5 million representing code-specific tokens.-- Coverage spans a diverse range of 3‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chakshu2/sample_synthetic_text_to_sql."},
	{"name":"godot-training","keyword":"coding","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ImJimmeh/godot-training","creator_name":"Jim","creator_url":"https://huggingface.co/ImJimmeh","description":"ImJimmeh/godot-training dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Exemplary_QA","keyword":"sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/100suping/Exemplary_QA","creator_name":"100suping","creator_url":"https://huggingface.co/100suping","description":"100suping/Exemplary_QA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"maykel_dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mayk00/maykel_dataset","creator_name":"cortes","creator_url":"https://huggingface.co/mayk00","description":"cualquier mmd\\n"},
	{"name":"twitter_dataset_try","keyword":"code","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yanisTiky/twitter_dataset_try","creator_name":"Tiky ekotto yanis","creator_url":"https://huggingface.co/yanisTiky","description":"yanisTiky/twitter_dataset_try dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"data_del","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dalssy/data_del","creator_name":"dalssy leyva lopez","creator_url":"https://huggingface.co/dalssy","description":"dalssy/data_del dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"simple_python_description","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/farahbs/simple_python_description","creator_name":"Farah BEN SLAMA","creator_url":"https://huggingface.co/farahbs","description":"farahbs/simple_python_description dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"simple_python_description","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/farahbs/simple_python_description","creator_name":"Farah BEN SLAMA","creator_url":"https://huggingface.co/farahbs","description":"farahbs/simple_python_description dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"qa-portuguese-small","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jpzinn654/qa-portuguese-small","creator_name":"Juan Pablo","creator_url":"https://huggingface.co/Jpzinn654","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQA-PORTUGUESE-SMALL\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe qa-portuguese-small dataset is a collection of 500,000 question-answer pairs in Portuguese designed for Question Answering (QA) tasks. The dataset includes questions based on a wide variety of domains, such as news, general knowledge, and everyday facts, and provides corresponding answers in natural language.\\nThe dataset is intended for training and evaluating machine learning models that can answer questions in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jpzinn654/qa-portuguese-small."},
	{"name":"macbinariesprofile","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/geeksuckmatzball/macbinariesprofile","creator_name":"John Tareco","creator_url":"https://huggingface.co/geeksuckmatzball","description":"Mac binaries disassembly profile\\n"},
	{"name":"stationery-1","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/keikhosrotav/stationery-1","creator_name":"keikhosro tavakoli","creator_url":"https://huggingface.co/keikhosrotav","description":"keikhosrotav/stationery-1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Coq-HoTT","keyword":"formal-methods","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-HoTT","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCoq-HoTT Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Coq-HoTT Dataset is derived from the Coq-HoTT repository, focusing on the formalization of Homotopy Type Theory in the Coq proof assistant. This dataset processes .v files from the theories directory to extract mathematical content in a structured format.\\nThis work builds upon the format established by Andreas Florath (@florath) in his Coq Facts, Propositions and Proofs dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-HoTT."},
	{"name":"tech-docs","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saidsef/tech-docs","creator_name":"Said Sef","creator_url":"https://huggingface.co/saidsef","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTechnical Documentation Dataset\\n\\t\\n\\nA curated collection of technical documentation and guides spanning various cloud-native technologies, infrastructure tools, and machine learning frameworks. This dataset contains 1,397 documents in JSONL format, covering essential topics for modern software development and DevOps practices.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThis dataset includes documentation across multiple domains:\\n\\nCloud Platforms: GCP (83 docs), EKS (33 docs)\\nKubernetes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saidsef/tech-docs."},
	{"name":"Temporary-Datasets","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/RichMiguel/Temporary-Datasets","creator_name":"Richell Mark B. Miguel","creator_url":"https://huggingface.co/RichMiguel","description":"RichMiguel/Temporary-Datasets dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"SWE-agent-trajectories","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nebius/SWE-agent-trajectories","creator_name":"Nebius","creator_url":"https://huggingface.co/nebius","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 80,036 trajectories generated by a software engineering agent based on the SWE-agent framework, using various models as action generators. In these trajectories, the agent attempts to solve GitHub issues from the nebius/SWE-bench-extra and the dev split of princeton-nlp/SWE-bench.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset was created as part of a research project focused on developing a software engineering agent using open-weight models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nebius/SWE-agent-trajectories."},
	{"name":"acl-paper","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sleeping-ai/acl-paper","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tACL Entire\\n\\t\\n\\n\\n  \\n\\n\\nACL Entire is a comprehensive dataset containing all papers from both ACL and Non-ACL events listed on the ACL Anthology website. This dataset includes complete bibliographic information for all years.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nEvents Covered: Papers from ACL and Non-ACL events.\\nBibliography: Includes complete bibliographic details for every paper.\\nYears Covered: Comprehensive data spanning all available years.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\nAll data has been compiled‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sleeping-ai/acl-paper."},
	{"name":"Coq-HoTT-QA","keyword":"formal-methods","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-HoTT-QA","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCoq-HoTT Q&A Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Coq-HoTT Q&A Dataset is a conversational extension of the Coq-HoTT Dataset, derived directly from the Coq-HoTT GitHub repository (https://github.com/HoTT/Coq-HoTT). This dataset transforms Homotopy Type Theory (HoTT) content into structured Q&A pairs, bridging the gap between formal mathematics and conversational AI.\\nEach entry in the dataset represents a mathematical statement, such as a definition or theorem‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-HoTT-QA."},
	{"name":"SWE-agent-trajectories","keyword":"software","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nebius/SWE-agent-trajectories","creator_name":"Nebius","creator_url":"https://huggingface.co/nebius","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 80,036 trajectories generated by a software engineering agent based on the SWE-agent framework, using various models as action generators. In these trajectories, the agent attempts to solve GitHub issues from the nebius/SWE-bench-extra and the dev split of princeton-nlp/SWE-bench.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset was created as part of a research project focused on developing a software engineering agent using open-weight models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nebius/SWE-agent-trajectories."},
	{"name":"CodeNanoFix","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qyliang/CodeNanoFix","creator_name":"liang","creator_url":"https://huggingface.co/qyliang","description":"CodeNanoFix consists of tuples of problem description, buggy code, and correct code, designed to evaluate human-written code with subtle differences.\\nPaper: https://arxiv.org/abs/2412.17429\\nproblem_id: problme index;\\npos: correct code;\\nneg: buggy code;\\nnl: natural language description;\\n\\nCitation:\\n@article{liang2024condor,\\n  title={Condor: A Code Discriminator Integrating General Semantics with Code Details},\\n  author={Liang, Qingyuan and Zhang, Zhao and Liu, Chen and Sun, Zeyu and Zhang‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qyliang/CodeNanoFix."},
	{"name":"wasp-5k","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/namelessai/wasp-5k","creator_name":"Alex Scott","creator_url":"https://huggingface.co/namelessai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWasp-Lang\\n\\t\\n\\nThis is a synthetic dataset created by an amplify model trained on the Wasp programming language quick-start documentation. Better data coming soon.\\n"},
	{"name":"banking-chatbot-enquiries","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythontech9/banking-chatbot-enquiries","creator_name":"pythontech9","creator_url":"https://huggingface.co/pythontech9","description":"pythontech9/banking-chatbot-enquiries dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"NuminaMath-CoT-decontaminated-filtered","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/flatlander1024/NuminaMath-CoT-decontaminated-filtered","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Decontaminated version of AI-MO/NuminaMath-CoT/train that remove the collided data from math/test, gsm8k/test, olympiadbench/test, minerva_math/test, college_math/test, mmlu_stem/test, gaokao, amc23, aime24 and math500.\\nAligned with flatlander1024/QwQ-LongCoT-130K-decontaminated NuminaMath\\nTotal number of rows: 102238\\n"},
	{"name":"QwQ-LongCoT-decontaminated-filtered","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/flatlander1024/QwQ-LongCoT-decontaminated-filtered","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Decontaminated version of gghfez/QwQ-LongCoT-130K-cleaned that remove the collided data from math/test, gsm8k/test, olympiadbench/test, minerva_math/test, college_math/test, mmlu_stem/test, gaokao, amc23, aime24 and math500.\\nWith source=='NuminaMath'.\\nTotal number of rows: 88083\\n"},
	{"name":"NuminaMath-longcot-cot-combined","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/flatlander1024/NuminaMath-longcot-cot-combined","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Contains Decontaminated version of AI-MO/NuminaMath-CoT/train and the decontaminated version of gghfez/QwQ-LongCoT-130K-cleaned.\\nRemove duplicates and merged them into 1 data with 2 different solution rows.\\nTotal number of rows: 87057\\n"},
	{"name":"wximg_vl","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wx1995/wximg_vl","creator_name":"wuxiang","creator_url":"https://huggingface.co/wx1995","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wx1995/wximg_vl."},
	{"name":"SWE-Bench-Verified-O1-native-tool-calling-reasoning-high-results","keyword":"code-generation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlexCuadron/SWE-Bench-Verified-O1-native-tool-calling-reasoning-high-results","creator_name":"Alejandro Cuadron Lafuente","creator_url":"https://huggingface.co/AlexCuadron","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSWE-Bench Verified O1 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExecutive Summary\\n\\t\\n\\nThis repository contains verified reasoning traces from the O1 model evaluating software engineering tasks. Using OpenHands + CodeAct v2.2, we tested O1's bug-fixing capabilities using their native tool calling capabilities on the SWE-Bench Verified dataset, achieving a 45.8% success rate across 500 test instances.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset was generated using the CodeAct framework, which aims to improve‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlexCuadron/SWE-Bench-Verified-O1-native-tool-calling-reasoning-high-results."},
	{"name":"SWE-Bench-Verified-O1-native-tool-calling-reasoning-high-results","keyword":"open-source","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlexCuadron/SWE-Bench-Verified-O1-native-tool-calling-reasoning-high-results","creator_name":"Alejandro Cuadron Lafuente","creator_url":"https://huggingface.co/AlexCuadron","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSWE-Bench Verified O1 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExecutive Summary\\n\\t\\n\\nThis repository contains verified reasoning traces from the O1 model evaluating software engineering tasks. Using OpenHands + CodeAct v2.2, we tested O1's bug-fixing capabilities using their native tool calling capabilities on the SWE-Bench Verified dataset, achieving a 45.8% success rate across 500 test instances.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset was generated using the CodeAct framework, which aims to improve‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlexCuadron/SWE-Bench-Verified-O1-native-tool-calling-reasoning-high-results."},
	{"name":"SWE-Bench-Verified-O1-native-tool-calling-reasoning-high-results","keyword":"python","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlexCuadron/SWE-Bench-Verified-O1-native-tool-calling-reasoning-high-results","creator_name":"Alejandro Cuadron Lafuente","creator_url":"https://huggingface.co/AlexCuadron","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSWE-Bench Verified O1 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExecutive Summary\\n\\t\\n\\nThis repository contains verified reasoning traces from the O1 model evaluating software engineering tasks. Using OpenHands + CodeAct v2.2, we tested O1's bug-fixing capabilities using their native tool calling capabilities on the SWE-Bench Verified dataset, achieving a 45.8% success rate across 500 test instances.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset was generated using the CodeAct framework, which aims to improve‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlexCuadron/SWE-Bench-Verified-O1-native-tool-calling-reasoning-high-results."},
	{"name":"nlp_corpus_zh","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeroMN/nlp_corpus_zh","creator_name":"zeroTT","creator_url":"https://huggingface.co/zeroMN","description":"\\n\\t\\n\\t\\t\\n\\t\\tnlp_corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1 ‰∏≠ÊñáÂÆû‰ΩìËØÜÂà´\\n\\t\\n\\n\\nopen_ner_data‰∏∫ÁΩë‰∏äÂºÄÊîæÁöÑnerÊï∞ÊçÆÈõÜÔºåÂ∑≤Â∞Ü‰∏çÂêåÁöÑÊï∞ÊçÆÊ†ºÂºèËΩ¨Âåñ‰∏∫Áªü‰∏ÄÁöÑÊï∞ÊçÆÊ†ºÂºèÔºåÊ†ºÂºèËΩ¨Êç¢ËÑöÊú¨‰∏∫data_transfer.py\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.1 bosonÊï∞ÊçÆÈõÜ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.2 clueÁªÜÁ≤íÂ∫¶ÂÆû‰ΩìËØÜÂà´Êï∞ÊçÆÈõÜ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.3 ÂæÆËΩØÂÆû‰ΩìËØÜÂà´Êï∞ÊçÆÈõÜ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.4 ‰∫∫Ê∞ëÁΩëÂÆû‰ΩìËØÜÂà´Êï∞ÊçÆÈõÜÔºà98Âπ¥Ôºâ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.5 ‰∏≠ËçØËØ¥Êòé‰π¶ÂÆû‰ΩìËØÜÂà´Êï∞ÊçÆÈõÜÔºà‚Äú‰∏áÂàõÊùØ‚Äù‰∏≠ÂåªËçØÂ§©Ê±†Â§ßÊï∞ÊçÆÁ´ûËµõÔºâ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.6 ËßÜÈ¢ë_Èü≥‰πê_Âõæ‰π¶Êï∞ÊçÆÈõÜ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.7 ÂæÆÂçöÊï∞ÊçÆÈõÜ\\n\\t\\n\\n"},
	{"name":"chatjsonsql","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rishi2903/chatjsonsql","creator_name":"Rishabh Mekala","creator_url":"https://huggingface.co/rishi2903","description":"\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names, column‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rishi2903/chatjsonsql."},
	{"name":"reason_at_code","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MugiLab/reason_at_code","creator_name":"MugiLab","creator_url":"https://huggingface.co/MugiLab","description":"\\n\\t\\n\\t\\t\\n\\t\\tReasoning Dataset for Code\\n\\t\\n\\nThis repository contains a curated reasoning dataset specifically designed for coding-related problems, particularly in Python. \\nThe dataset was created by filtering non-code problems from the original NovaSky-AI/Sky-T1_data_17k dataset. \\nThe goal of this dataset is to facilitate fine-tuning models for reasoning tasks related to code understanding, problem-solving, and logical deduction in programming.\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe dataset emphasizes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MugiLab/reason_at_code."},
	{"name":"InstrucInputOut","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/soendup21/InstrucInputOut","creator_name":"Sonam Lhendup","creator_url":"https://huggingface.co/soendup21","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/soendup21/InstrucInputOut."},
	{"name":"Diverse-Knowledge","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kunu5402/Diverse-Knowledge","creator_name":"Kunal Kumar","creator_url":"https://huggingface.co/kunu5402","description":"\\n\\t\\n\\t\\t\\n\\t\\tEverything Data\\n\\t\\n\\n\\nThis data is synthetically generated by a ton of open and closed source models. This is basically a parsed version of yearly log form a small dialouge based testing to anylyze model's response on it then perform human evals on it.\\nThe data contains information about everything from every domain, most of the pairs included in this data are preferred by humans as the model's response.\\nIt can be used for topic modeling, or human preference evals etc.\\nRest anyone can do‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kunu5402/Diverse-Knowledge."},
	{"name":"chatjsonsql","keyword":"context-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rishi2903/chatjsonsql","creator_name":"Rishabh Mekala","creator_url":"https://huggingface.co/rishi2903","description":"\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names, column‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rishi2903/chatjsonsql."},
	{"name":"chatjsonsql","keyword":"sqlglot","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rishi2903/chatjsonsql","creator_name":"Rishabh Mekala","creator_url":"https://huggingface.co/rishi2903","description":"\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names, column‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rishi2903/chatjsonsql."},
	{"name":"chatjsonsql","keyword":"wikisql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rishi2903/chatjsonsql","creator_name":"Rishabh Mekala","creator_url":"https://huggingface.co/rishi2903","description":"\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names, column‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rishi2903/chatjsonsql."},
	{"name":"chatjsonsql","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rishi2903/chatjsonsql","creator_name":"Rishabh Mekala","creator_url":"https://huggingface.co/rishi2903","description":"\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names, column‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rishi2903/chatjsonsql."},
	{"name":"chatjsonsql","keyword":"sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rishi2903/chatjsonsql","creator_name":"Rishabh Mekala","creator_url":"https://huggingface.co/rishi2903","description":"\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names, column‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rishi2903/chatjsonsql."},
	{"name":"chatjsonsql","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rishi2903/chatjsonsql","creator_name":"Rishabh Mekala","creator_url":"https://huggingface.co/rishi2903","description":"\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names, column‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rishi2903/chatjsonsql."},
	{"name":"yelp_dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shivi23/yelp_dataset","creator_name":"Shivani Dwivedi","creator_url":"https://huggingface.co/shivi23","description":"shivi23/yelp_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"LeetCodeDataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/newfacade/LeetCodeDataset","creator_name":"newfacade","creator_url":"https://huggingface.co/newfacade","description":"\\n\\t\\n\\t\\t\\n\\t\\tLeetCodeDataset\\n\\t\\n\\nLeetCodeDataset is a dataset consists of Python leetcode problems that can be used for LLM training and evaluation.\\n\\n    üíª GitHub\\n\\n"},
	{"name":"apps-small","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AuroraH456/apps-small","creator_name":"Aurora Huang","creator_url":"https://huggingface.co/AuroraH456","description":"\\n\\t\\n\\t\\t\\n\\t\\tAPPS Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nAPPS is a benchmark for code generation with 10000 problems. It can be used to evaluate the ability of language models to generate code from natural language specifications.\\nYou can also find APPS metric in the hub here codeparrot/apps_metric.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset contains questions in English and code solutions in Python.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nfrom datasets import load_dataset\\nload_dataset(\\\"codeparrot/apps\\\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AuroraH456/apps-small."},
	{"name":"sysmon-configuration-dpo","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cowWhySo/sysmon-configuration-dpo","creator_name":"whit3rabbit","creator_url":"https://huggingface.co/cowWhySo","description":"\\n\\t\\n\\t\\t\\n\\t\\tDPO Training Set for Sysmon Configuration File Generation\\n\\t\\n\\nThis repository contains a Direct Preference Optimization (DPO) training set for generating Sysmon configuration files for the purpose of fine tuning LLM.\\n\\n\\t\\n\\t\\t\\n\\t\\tBasis: Sysmon Modular Repository\\n\\t\\n\\nThis dataset is based on the Sysmon Modular repository by Olaf Hartong:üîó Sysmon Modular Repository  \\nThe Sysmon Modular configuration was chosen because it was originally created by multiple people based on the MITRE framework.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cowWhySo/sysmon-configuration-dpo."},
	{"name":"ProfessionalTermsAmharicEnglish","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/admasorg/ProfessionalTermsAmharicEnglish","creator_name":"m","creator_url":"https://huggingface.co/admasorg","description":"admasorg/ProfessionalTermsAmharicEnglish dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"llvm-apr-benchmark","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dtcxzyw/llvm-apr-benchmark","creator_name":"Yingwei Zheng","creator_url":"https://huggingface.co/dtcxzyw","description":"\\n\\t\\n\\t\\t\\n\\t\\tLLVM APR Benchmark: A Large-Scale Automated Program Repair Benchmark of Real-World LLVM Middle-End Bugs\\n\\t\\n\\nGitHub (We only accept pull requests from GitHub)\\nHugging Face Mirror\\nHugging Face Leaderboard\\nEvaluation Result Submission\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMotivation\\n\\t\\n\\nThe compiler is a critical infrastructure in the software development. The LLVM compiler infrastructure is widely used in both academia and industry. However, due to its inherent complexity, the LLVM compiler still contains many bugs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dtcxzyw/llvm-apr-benchmark."},
	{"name":"Gemini-flash-2-code-project","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/loaiabdalslam/Gemini-flash-2-code-project","creator_name":"loai abdalslam","creator_url":"https://huggingface.co/loaiabdalslam","description":"loaiabdalslam/Gemini-flash-2-code-project dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Python_code_RU","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DataSynGen/Python_code_RU","creator_name":"DataGen","creator_url":"https://huggingface.co/DataSynGen","description":"–§–æ—Ä–º–∞—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞, –∫–∞–∂–¥—ã–π –±–ª–æ–∫ –∑–∞–∫–ª—é—á—ë–Ω –≤ —Ç–µ–≥–∏ .\\n–ö–∞–∂–¥—ã–π –±–ª–æ–∫ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏  #–û–ø–∏—Å–∞–Ω–∏–µ-–ö–æ–¥–∞-–±–ª–æ–∫–∞\\n\\n"},
	{"name":"tojoyfoundation","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bcc/tojoyfoundation","creator_name":"bucheyu","creator_url":"https://huggingface.co/bcc","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bcc/tojoyfoundation."},
	{"name":"Python_code_RU","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DataSynGen/Python_code_RU","creator_name":"DataGen","creator_url":"https://huggingface.co/DataSynGen","description":"–§–æ—Ä–º–∞—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞, –∫–∞–∂–¥—ã–π –±–ª–æ–∫ –∑–∞–∫–ª—é—á—ë–Ω –≤ —Ç–µ–≥–∏ .\\n–ö–∞–∂–¥—ã–π –±–ª–æ–∫ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏  #–û–ø–∏—Å–∞–Ω–∏–µ-–ö–æ–¥–∞-–±–ª–æ–∫–∞\\n\\n"},
	{"name":"Testing1","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/YeBhoneLin10/Testing1","creator_name":"Ye Bhone Lin","creator_url":"https://huggingface.co/YeBhoneLin10","description":"YeBhoneLin10/Testing1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ryan_test","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tiantianhaha/ryan_test","creator_name":"li","creator_url":"https://huggingface.co/tiantianhaha","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tiantianhaha/ryan_test."},
	{"name":"Seal-Tools","keyword":"function-calling","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/casey-martin/Seal-Tools","creator_name":"Casey","creator_url":"https://huggingface.co/casey-martin","description":"\\n\\t\\n\\t\\t\\n\\t\\tSeal-Tools\\n\\t\\n\\n\\n\\nThis Huggingface repository contains the dataset generated in Seal-Tools: Self-Instruct Tool Learning Dataset for Agent Tuning and Detailed Benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\tAbstract\\n\\t\\n\\nSeal-Tools contains self-instruct API-like tools. Seal-Tools not only offers a large\\nnumber of tools, but also includes instances\\nwhich demonstrate the practical application\\nof tools. Seeking to generate data on a large\\nscale while ensuring reliability, we propose a\\nself-instruct method to generate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/casey-martin/Seal-Tools."},
	{"name":"APPS-leetcode-codeforces","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xtremekiwi/APPS-leetcode-codeforces","creator_name":"Aaron Sandoval","creator_url":"https://huggingface.co/xtremekiwi","description":"xtremekiwi/APPS-leetcode-codeforces dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"bfc-test","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AugustoSavi/bfc-test","creator_name":"Augusto Savi","creator_url":"https://huggingface.co/AugustoSavi","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset de Exemplos para BFC-Script\\n\\t\\n\\nEste dataset cont√©m exemplos pr√°ticos de uso da linguagem bfc-script, organizados em pares de prompt e completion. Ele foi criado para ajudar desenvolvedores a entender e utilizar a linguagem em diversos cen√°rios, desde opera√ß√µes b√°sicas at√© funcionalidades mais avan√ßadas.\\n\\n\\t\\n\\t\\t\\n\\t\\tEstrutura do Dataset\\n\\t\\n\\nO dataset est√° no formato JSONL (JSON Lines), onde cada linha √© um objeto JSON com dois campos:\\n\\nprompt: Uma pergunta ou descri√ß√£o de um cen√°rio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AugustoSavi/bfc-test."},
	{"name":"astra_grab_floor_toys_without_observations_actions","keyword":"astra","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lookas/astra_grab_floor_toys_without_observations_actions","creator_name":"Haiqin Cui","creator_url":"https://huggingface.co/lookas","description":"This dataset was created using LeRobot.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nmeta/info.json:\\n{\\n    \\\"codebase_version\\\": \\\"v2.0\\\",\\n    \\\"robot_type\\\": \\\"astra\\\",\\n    \\\"total_episodes\\\": 50,\\n    \\\"total_frames\\\": 73944,\\n    \\\"total_tasks\\\": 1,\\n    \\\"total_videos\\\": 150,\\n    \\\"total_chunks\\\": 1,\\n    \\\"chunks_size\\\": 1000,\\n    \\\"fps\\\": 30,\\n    \\\"splits\\\": {\\n        \\\"train\\\": \\\"0:50\\\"},\\n    \\\"data_path\\\": \\\"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\\\",\\n    \\\"video_path\\\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lookas/astra_grab_floor_toys_without_observations_actions."},
	{"name":"astra_grab_floor_toys_base_cmd_pos","keyword":"astra","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lookas/astra_grab_floor_toys_base_cmd_pos","creator_name":"Haiqin Cui","creator_url":"https://huggingface.co/lookas","description":"This dataset was created using LeRobot.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nmeta/info.json:\\n{\\n    \\\"codebase_version\\\": \\\"v2.0\\\",\\n    \\\"robot_type\\\": null,\\n    \\\"total_episodes\\\": 50,\\n    \\\"total_frames\\\": 73694,\\n    \\\"total_tasks\\\": 1,\\n    \\\"total_videos\\\": 150,\\n    \\\"total_chunks\\\": 1,\\n    \\\"chunks_size\\\": 1000,\\n    \\\"fps\\\": 30,\\n    \\\"splits\\\": {\\n        \\\"train\\\": \\\"0:50\\\"\\n    },\\n    \\\"data_path\\\": \\\"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\\\",\\n    \\\"video_path\\\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lookas/astra_grab_floor_toys_base_cmd_pos."},
	{"name":"CNTXTAI-Ranking-Dataset","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CNTXTAI0/CNTXTAI-Ranking-Dataset","creator_name":"CNTXT AI","creator_url":"https://huggingface.co/CNTXTAI0","description":"General Overview\\nThis dataset is to be used for LLM Trainings, This is a sample, visit https://www.cntxt.tech/ to learn more\\nThe dataset consists of 50 rows (excluding headers) and 8 columns. The columns capture various aspects of ranked responses to prompts, including:\\nNumeric_ID (Unique Identifier - Integer)\\nPrompt (The Question or Task - Text)\\nAnswer_A / Answer_B (Response Options - Text)\\nCategory (Type of Task - Categorical)\\nBest Answer (Preferred Response - Categorical)\\nLikeRT Score‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CNTXTAI0/CNTXTAI-Ranking-Dataset."},
	{"name":"RobloxUsersData","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ZelonPrograms/RobloxUsersData","creator_name":"ZelonPrograms","creator_url":"https://huggingface.co/ZelonPrograms","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRoblox User Dataset\\n\\t\\n\\nWarning: Not all data may be collected correctly. Users should be aware of this limitation when utilizing the dataset. All of this was scraped, without permision of the users or company.\\nThis dataset contains information about Roblox users, including their user ID, username, display name, account status, and social metrics.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\nuser_id: Unique identifier for the user\\nusername: The username of the user\\ndisplay_name: The display‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZelonPrograms/RobloxUsersData."},
	{"name":"astra_grab_floor_toys_extended","keyword":"astra","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lookas/astra_grab_floor_toys_extended","creator_name":"Haiqin Cui","creator_url":"https://huggingface.co/lookas","description":"This dataset was created using LeRobot.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nmeta/info.json:\\n{\\n    \\\"codebase_version\\\": \\\"v2.0\\\",\\n    \\\"robot_type\\\": \\\"astra_joint\\\",\\n    \\\"total_episodes\\\": 80,\\n    \\\"total_frames\\\": 113547,\\n    \\\"total_tasks\\\": 1,\\n    \\\"total_videos\\\": 240,\\n    \\\"total_chunks\\\": 1,\\n    \\\"chunks_size\\\": 1000,\\n    \\\"fps\\\": 30,\\n    \\\"splits\\\": {\\n        \\\"train\\\": \\\"0:80\\\"\\n    },\\n    \\\"data_path\\\": \\\"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\\\",\\n    \\\"video_path\\\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lookas/astra_grab_floor_toys_extended."},
	{"name":"sql-new-copy","keyword":"sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Manyah/sql-new-copy","creator_name":"Manuel Fernandez","creator_url":"https://huggingface.co/Manyah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages:\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe following is taken from the corpus' source repsository:\\n\\t\\n\\n"},
	{"name":"mac-os-commands","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sammyview80/mac-os-commands","creator_name":"saman shrestha","creator_url":"https://huggingface.co/sammyview80","description":"sammyview80/mac-os-commands dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Datasets_Jhona","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jhonatan321/Datasets_Jhona","creator_name":"Jhonatan reyes vazquez","creator_url":"https://huggingface.co/Jhonatan321","description":"Jhonatan321/Datasets_Jhona dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ai.luna.ai","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/derricka59/ai.luna.ai","creator_name":"Derrick Adkison","creator_url":"https://huggingface.co/derricka59","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLuna AI Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nLuna AI is a model optimized for creative writing tasks such as poetry generation, short story writing, script drafting, and more. This dataset provides training, validation, and test data for Luna AI to help improve its capabilities in these areas.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nVersion: 1.0\\nOptimized For: Creative Writing\\nLicense: Apache 2.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTraining Data\\n\\t\\n\\nThe training dataset consists of various samples designed to guide‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/derricka59/ai.luna.ai."},
	{"name":"Vietnamese-Function-Calling-Test","keyword":"function calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/phamhai/Vietnamese-Function-Calling-Test","creator_name":"phamhai","creator_url":"https://huggingface.co/phamhai","description":"Vietnamese Function Calling Benchmark\\n\\nRAG applications for Vietnamese chatbot systems are becoming increasingly popular. Many LLM models already support FC for Vietnamese, but there is no common and comprehensive benchmark yet. Today, I am releasing a benchmark for the Vietnamese Function Calling task. I hope this will serve as a standard for product teams to choose models in a reasonable and appropriate way.\\nDataset Details:\\n\\n\\nData size: 2899 single-turn funcation calling samples\\nDomains:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phamhai/Vietnamese-Function-Calling-Test."},
	{"name":"Coq-UniMath","keyword":"formal-methods","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-UniMath","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUniMath Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe UniMath Dataset is derived from the UniMath repository, focusing on the formalization of Univalent Mathematics in the Coq proof assistant. This dataset processes .v files from the core mathematical libraries to extract mathematical content in a structured format. This work builds upon the format established by Andreas Florath (@florath) in his Coq Facts, Propositions and Proofs dataset, providing a more focused and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-UniMath."},
	{"name":"BlameAIData-0.1","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aifoundry-org/BlameAIData-0.1","creator_name":"AIFoundry.org","creator_url":"https://huggingface.co/aifoundry-org","description":"[WIP]\\n"},
	{"name":"laravel-11-qa-long-form","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yannelli/laravel-11-qa-long-form","creator_name":"Ryan Y","creator_url":"https://huggingface.co/yannelli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Laravel 11 Documentation Q&A (Long Form)\\n\\t\\n\\nThis dataset contains detailed question-answer pairs derived from the Laravel 11 official documentation, designed for fine-tuning and evaluating language models on Laravel 11 knowledge. The long-form version provides more comprehensive answers and includes code examples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Laravel 11 Documentation Q&A (Long Form) dataset is an extensive collection of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yannelli/laravel-11-qa-long-form."},
	{"name":"Coq-MetaCoq-QA","keyword":"formal-methods","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-MetaCoq-QA","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMetaCoq Q&A Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe MetaCoq Q&A Dataset is a conversational extension of the MetaCoq Dataset, derived from the MetaCoq formalization of Coq's meta-theory (https://github.com/MetaCoq/metacoq). This dataset transforms meta-theoretical content into structured Q&A pairs, making formal meta-programming and verification concepts more accessible through natural language interactions.\\nEach entry represents a mathematical statement from MetaCoq‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-MetaCoq-QA."},
	{"name":"Titanium","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Titanium","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Titanium is a dataset containing DevOps-instruct data.\\nThe 2024-10-02 version contains:\\n\\n26.6k rows of synthetic DevOps-instruct data, using synthetically generated prompts and responses generated using Llama 3.1 405b Instruct. Primary areas of expertise are AWS, Azure, GCP, Terraform, Dockerfiles, pipelines, and shell scripts.\\n\\nThis dataset contains synthetically generated data and has not been subject to manual review.\\n"},
	{"name":"lunaris-data","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meryyllebr543/lunaris-data","creator_name":"Francisco Antonio","creator_url":"https://huggingface.co/meryyllebr543","description":"\\n\\t\\n\\t\\t\\n\\t\\tLunaris-Data Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nDataset Name: meryyllebr543/lunaris-data  \\nAuthor: Meryyllebr543  \\nLicense: [MIT]  \\nRepository: Hugging Face Dataset Hub  \\nCreated On: March 14, 2025\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nLunaris-Data is a premium dataset crafted to train and evaluate high-performance code generation models, like Lunaris Codex Mini (120M parameters), optimized for advanced programming tasks, debugging, and system design.\\nIt features 40,000 meticulously engineered‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meryyllebr543/lunaris-data."},
	{"name":"python-codesearch-dataset-open","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Shuu12121/python-codesearch-dataset-open","creator_name":"Shuu12121","creator_url":"https://huggingface.co/Shuu12121","description":"\\n\\t\\n\\t\\t\\n\\t\\tPython Code Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains Python functions with their documentation comments extracted from GitHub repositories.\\n\\n\\t\\n\\t\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\ncode: The Python function code\\ndocstring: Documentation comment for the function\\nfunc_name: Function name\\nlanguage: Programming language (always \\\"Python\\\")\\nrepo: Source repository name\\npath: File path within the repository\\nurl: GitHub URL to the source file\\nlicense: License of the source code‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Shuu12121/python-codesearch-dataset-open."},
	{"name":"Comprehensive_Feature_Extraction_DDoS_Datasets","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Thi-Thu-Huong/Comprehensive_Feature_Extraction_DDoS_Datasets","creator_name":"Le","creator_url":"https://huggingface.co/Thi-Thu-Huong","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Comprehensive_Feature_Extraction_DDoS_Datasets\\n\\t\\n\\n\\n\\nThis dataset card aims to be provided preprocessed five published DDoS datasets based on three feature extracted methods, including correlation, IM, and UFS. \\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe imperative for robust detection mechanisms has grown in the face of increasingly sophisticated Distributed Denial of Service (DDoS) attacks. This paper introduces DDoSBERT, an innovative approach harnessing transformer text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Thi-Thu-Huong/Comprehensive_Feature_Extraction_DDoS_Datasets."},
	{"name":"AyvazPython","keyword":"code","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bunyaminergen/AyvazPython","creator_name":"B√ºnyamin Ergen","creator_url":"https://huggingface.co/bunyaminergen","description":"\\n\\nAyvaz Python\\n\\nAyvaz Python is a dataset containing Python code instructions and outputs, which can be useful for tasks\\nsuch as code instruction tuning or code-based Q&A.\\nNote: If you would like to contribute to this repository,\\nplease read the CONTRIBUTING first.\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTableofContents\\n\\t\\n\\n\\nFeatures\\nFile Structure\\nDataset Structure\\nUsage\\nVersioning\\nLicense\\nTeam\\nContact\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nName: AyvazPython\\nPrimary Purpose: Contains JSON lines of programming instructions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bunyaminergen/AyvazPython."},
	{"name":"PyRe-v2","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/PyRe-v2","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"\\n\\t\\n\\t\\t\\n\\t\\tPyRe 2\\n\\t\\n\\nThis data set is a mix of samples from a number of public data sets (sources indidcated in the actual data). The goal with this set was to create a smaller set focused on coding (primarily Python), math, and reasoning.\\n"},
	{"name":"CO2_Vehicle_Emmisions","keyword":"code","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/milind27/CO2_Vehicle_Emmisions","creator_name":"Milind Saini","creator_url":"https://huggingface.co/milind27","description":"milind27/CO2_Vehicle_Emmisions dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"mosel","keyword":"open-source","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description, Collection, and Source\\n\\t\\n\\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel."},
	{"name":"CleverBoi-Data-20k","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/CleverBoi-Data-20k","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"theprint/CleverBoi-Data-20k dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sharegpt_cot_dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AiCloser/sharegpt_cot_dataset","creator_name":"Ai Closer","creator_url":"https://huggingface.co/AiCloser","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tA data set inspired by the \\\"Reflection\\\" method, three-dimensional thinking and cot\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the ShareGPT format.\\n\\t\\n\\nThe data set was generated using multiple llm synthesis.\\n"},
	{"name":"axay-javascript-dataset-pn","keyword":"programming","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/israellaguan/axay-javascript-dataset-pn","creator_name":"Israel Antonio Rosales Laguan","creator_url":"https://huggingface.co/israellaguan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDPO JavaScript Dataset\\n\\t\\n\\nThis repository contains a modified version of the JavaScript dataset originally sourced from axay/javascript-dataset-pn. The dataset has been adapted to fit the DPO (Dynamic Programming Object) format, making it compatible with the LLaMA-Factory project.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nThis dataset is licensed under the Apache 2.0 License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThe dataset consists of JavaScript code snippets that have been restructured and enhanced for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/israellaguan/axay-javascript-dataset-pn."},
	{"name":"Typst-Test","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TechxGenus/Typst-Test","creator_name":"Hao Jiang","creator_url":"https://huggingface.co/TechxGenus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTypst-Test\\n\\t\\n\\n\\n[ü§ñModels] |\\n[üõ†Ô∏èCode] |\\n[üìäData] |\\n\\n\\n\\n\\nDataset used to evaluate Typst-Coder, includes 1000 samples.\\n"},
	{"name":"iData","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/motexture/iData","creator_name":"motexture","creator_url":"https://huggingface.co/motexture","description":"This dataset was created using books from various domains within IT and science.\\n"},
	{"name":"synthetic_chat_text_to_sql","keyword":"sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AcademieDuNumerique/synthetic_chat_text_to_sql","creator_name":"Acad√©mie Du Num√©rique","creator_url":"https://huggingface.co/AcademieDuNumerique","description":"AcademieDuNumerique/synthetic_chat_text_to_sql dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"user-test","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/han9527/user-test","creator_name":"liu","creator_url":"https://huggingface.co/han9527","description":"han9527/user-test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Firefly-Rephrased-Multiturn-300K","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/Firefly-Rephrased-Multiturn-300K","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"Mxode/Firefly-Rephrased-Multiturn-300K dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Firefly-1.1M-Rephrased","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/Firefly-1.1M-Rephrased","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"Mxode/Firefly-1.1M-Rephrased dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"IndustryCorpus-Subset-zh-en","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/IndustryCorpus-Subset-zh-en","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"Mxode/IndustryCorpus-Subset-zh-en dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"webcode2m_purified","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xcodemind/webcode2m_purified","creator_name":"xcodemind","creator_url":"https://huggingface.co/xcodemind","description":"WebCode2M: A Real-World Dataset for Code Generation from Webpage Designs\\nFeatures:\\n\\nimage: the screenshot of the webpage.\\nbbox: the layout information, i.e., the bounding boxes (Bbox) of all the elements in the webpage, which contains the size, position, and hierarchy information. \\ntext: the webpage code text including HTML/CSS code.\\nscale: the scale of the screenshot, in the format [width, height].\\nlang: the main language of the text content displayed on the rendered page (excluding HTML/CSS‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xcodemind/webcode2m_purified."},
	{"name":"Ecommers-delivery","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sravankumarbonthada/Ecommers-delivery","creator_name":"BONTHADA SRAVAN KUMAR","creator_url":"https://huggingface.co/Sravankumarbonthada","description":"Sravankumarbonthada/Ecommers-delivery dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Benchmark","keyword":"code-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FeatEng/Benchmark","creator_name":"FeatEng","creator_url":"https://huggingface.co/FeatEng","description":"Paper: https://huggingface.co/papers/2410.23331\\n"},
	{"name":"brain_tumor_dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Arunisto/brain_tumor_dataset","creator_name":"Arun Arunisto","creator_url":"https://huggingface.co/Arunisto","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBrain Tumor Dataset\\n\\t\\n\\nParquet dataset contains the two different brain tumor condition healthy and tumor, used to classify the brain tumor. The images contains the MRI Scans of two different brain condition, this dataset developers can use for classification, detection and segmentation\\n"},
	{"name":"Spurline","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Spurline","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Spurline is a dataset containing complex responses, emphasizing logical reasoning and using Shining Valiant's friendly, magical personality style.\\nThe 2024-10-30 version contains:\\n\\n10.7k rows of synthetic queries, using randomly selected prompts from migtissera/Synthia-v1.5-I and responses generated using Llama 3.1 405b Instruct.\\n\\nThis dataset contains synthetically generated data and has not been subject to manual review.\\n"},
	{"name":"chatml-function-calling-v2","keyword":"function-calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankush13r/chatml-function-calling-v2","creator_name":"Ankush Rana","creator_url":"https://huggingface.co/ankush13r","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Conversion\\n\\t\\n\\nThis dataset is a converted version of the Glaive Function Calling v2 dataset, originally hosted on Hugging Face.\\n\\n\\t\\n\\t\\t\\n\\t\\tChat Template for Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nThis chat template is designed to work with this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\tTemplate\\n\\t\\n\\n\\nchat_template = \\\"\\\"{%- set tools = tools if tools is defined else None -%}\\n{%- set date_string = date_string if date_string is defined else \\\"1 Sep 2024\\\" -%}\\n\\n{%- set system_message = messages[0].content if‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankush13r/chatml-function-calling-v2."},
	{"name":"pgsql-hackers","keyword":"postgresql","license":"PostgreSQL License","license_url":"https://choosealicense.com/licenses/postgresql/","language":"en","dataset_url":"https://huggingface.co/datasets/wanshenl/pgsql-hackers","creator_name":"Wan Shen Lim","creator_url":"https://huggingface.co/wanshenl","description":"wanshenl/pgsql-hackers dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"LLM_dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mlsuny/LLM_dataset","creator_name":"ml_suny","creator_url":"https://huggingface.co/mlsuny","description":"mlsuny/LLM_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"jobdata","keyword":"code","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/arkodeep/jobdata","creator_name":"Arkodeep Sen","creator_url":"https://huggingface.co/arkodeep","description":"arkodeep/jobdata dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"python-fim","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/simmo/python-fim","creator_name":"Xander May","creator_url":"https://huggingface.co/simmo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPython Stack | Fill-in-the-Middle\\n\\t\\n\\nThis is a conversion or adaptation of The Stack to a python FIM task. The example column is B64 encoded because people like to put special characters in their code that csv files dont like so I encoded the strings before saving them to disk. \\n"},
	{"name":"Qu-QA","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ereeeeef3/Qu-QA","creator_name":"ffhs9","creator_url":"https://huggingface.co/Ereeeeef3","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQu QA Dataset\\n\\t\\n\\nQu QA is a large-scale question-answering (QA) dataset designed for training and evaluating machine learning models. It consists of question-answer pairs in English, making it suitable for general-purpose QA tasks, as well as specialized domains like code-related question answering and GSM8k-style problems.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nFeatures:\\n\\ninput: A string representing the question (dtype: string).\\noutput: A string representing the answer (dtype: string).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ereeeeef3/Qu-QA."},
	{"name":"Qu-QA-v2","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ereeeeef3/Qu-QA-v2","creator_name":"ffhs9","creator_url":"https://huggingface.co/Ereeeeef3","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQu QA v2 Dataset\\n\\t\\n\\nQu QA v2 is a large-scale question-answering (QA) dataset designed for training and evaluating machine learning models. It consists of question-answer pairs in English, making it suitable for general-purpose QA tasks, as well as specialized domains like code-related question answering and GSM8k-style problems.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nFeatures:\\n\\ninput: A string representing the question (dtype: string).\\noutput: A string representing the answer (dtype:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ereeeeef3/Qu-QA-v2."},
	{"name":"BlendNet","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/BlendNet","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\tüìö BlendNet\\n\\t\\n\\nThe dataset contains $12k$ samples. To balance cost savings with data quality and scale, we manually annotated $2k$ samples and used GPT-4o to annotate the remaining $10k$ samples.\\nFor more details, please visit our GitHub repository or refer to our arXiv paper.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìñ Citation\\n\\t\\n\\n@misc{du2024blenderllmtraininglargelanguage,\\n      title={BlenderLLM: Training Large Language Models for Computer-Aided Design with Self-improvement}, \\n      author={Yuhao Du and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/BlendNet."},
	{"name":"SWAP","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sxiong/SWAP","creator_name":"Siheng Xiong","creator_url":"https://huggingface.co/sxiong","description":"\\n\\t\\n\\t\\t\\n\\t\\tSWAP: A Synthetic Dataset for Complex Reasoning with Trajectories and Process Supervision\\n\\t\\n\\nThis repository contains the data for the paper Deliberate Reasoning for LLMs as Structure-aware Planning with Accurate World Model.\\nSWAP (Structure-aware Planning) solves complex reasoning by introducing a Generator-Discriminator architecture, and incorporates structural information to guide the reasoning process and provides a soft verification mechanism over the steps.\\nWe generate the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sxiong/SWAP."},
	{"name":"gemma-function-calling","keyword":"function calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dushj98/gemma-function-calling","creator_name":"Dinushi Jayasinghe","creator_url":"https://huggingface.co/dushj98","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüëâüèΩ Important\\n\\t\\n\\nThis dataset is adapted from hypervariance/function-calling-sharegpt to fine-tune the Google gemma-2-2b-it model for function calling.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüîÄ Changes Made\\n\\t\\n\\n\\nMerged consecutive \\\"GPT\\\" responses into single responses (affected 8.49% of examples, 7372 out of 86864).\\nUpdated role names:\\n\\\"system\\\" ‚Üí Removed (function usage instructions moved to separate column)\\n\\\"human\\\" ‚Üí \\\"user\\\"\\n\\\"gpt\\\" ‚Üí \\\"assistant\\\"\\n\\\"function_response\\\" ‚Üí Unchanged\\n\\n\\nChanged message keys from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dushj98/gemma-function-calling."},
	{"name":"ComBack_Plus_Plus","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/docz1105/ComBack_Plus_Plus","creator_name":"Ming Zhong","creator_url":"https://huggingface.co/docz1105","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tComBack++: A Multi-Language Dataset Providing End-to-End Support for Compiler Backend Development\\n\\t\\n\\nComBack++ is a large-scale, multi-platform and multi-language compiler backend code dataset. It is sourced from GCC and LLVM backends corresponding to 183 target platforms.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSource Data\\n\\nGCC\\n\\n\\n\\t\\n\\t\\t\\nCategory\\nTarget Platform\\nC++ Function\\nC++ KLoC\\nMachine Description KLoC\\n\\n\\n\\t\\t\\nCPU\\n30\\n56,211\\n858.2\\n228.5\\n\\n\\nMPU\\n35\\n8,713\\n243.8\\n87.1\\n\\n\\nGPU\\n2\\n731\\n12.7\\n3.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/docz1105/ComBack_Plus_Plus."},
	{"name":"GoPro-Raw-Videos","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fanqi-Lin/GoPro-Raw-Videos","creator_name":"Fanqi-Lin","creator_url":"https://huggingface.co/Fanqi-Lin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRaw GoPro Videos for Four Robotic Manipulation Tasks\\n\\t\\n\\n[Project Page]\\n[Paper]\\n[Code]\\n[Models]\\n[Processed Dataset]\\nThis repository contains raw GoPro videos of robotic manipulation tasks collected in-the-wild using UMI, as described in the paper \\\"Data Scaling Laws in Imitation Learning for Robotic Manipulation\\\". The dataset covers four tasks:\\n\\nPour Water\\nArrange Mouse\\nFold Towel\\nUnplug Charger\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Folders:\\n\\t\\n\\narrange_mouse and pour_water: Each folder contains data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fanqi-Lin/GoPro-Raw-Videos."},
	{"name":"Coq-MetaCoq","keyword":"formal-methods","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-MetaCoq","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMetaCoq Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe MetaCoq Dataset is derived from the MetaCoq repository, focusing on the formalization of Coq's meta-theory in the Coq proof assistant. This dataset processes .v files from the core theory directories to extract mathematical content in a structured format. This work builds upon the format established by Andreas Florath (@florath) in his Coq Facts, Propositions and Proofs dataset, providing a specialized view of the MetaCoq‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-MetaCoq."},
	{"name":"Function_BasicBlock_Features_NIST_Juliet1_3_C_CPP","keyword":"software","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/saketupadhyay/Function_BasicBlock_Features_NIST_Juliet1_3_C_CPP","creator_name":"Saket Upadhyay","creator_url":"https://huggingface.co/saketupadhyay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFunction and BasicBlock Binary Classification Features based on NIST Juliet1.3 C/C++\\n\\t\\n\\nThe final Basic Block and Function features are extracted in Semicolon-Separated Values (SSV) format.\\nTo load in pandas, use -\\nimport pandas as pd\\ndata = pd.read_csv(\\\"FNFeatures.csv\\\", sep=\\\";\\\")\\n\\nAssuming FNFeatures.csv is the target feature file.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFunction Features\\n\\t\\n\\nThe generated dataset is list of functions with various characteristics and a label indicating whether each function is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saketupadhyay/Function_BasicBlock_Features_NIST_Juliet1_3_C_CPP."},
	{"name":"developers-questions-small-qe2","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OramaSearch/developers-questions-small-qe2","creator_name":"OramaSearch Inc.","creator_url":"https://huggingface.co/OramaSearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDevelopers Questions Small QE2\\n\\t\\n\\nA dataset consisting of ~12k developers' questions, in English. These questions are synthetically generated via local LLMs at Orama.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasets\\n\\t\\n\\nThe dataset is proposed with three different embedding models:\\n\\nbge-small-en-v1.5\\nbge-base-en-v1.5\\nbge-large-en-v1.5\\n\\nIt also contains a quantized version for each model:\\n\\nbge-small 32 bytes\\nbge-base 32 bytes\\nbge-large 32 bytes\\n\\nFor each quantized model, this repository includes a binary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OramaSearch/developers-questions-small-qe2."},
	{"name":"LeetCoTE","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/newfacade/LeetCoTE","creator_name":"newfacade","creator_url":"https://huggingface.co/newfacade","description":"\\n\\t\\n\\t\\t\\n\\t\\tLeetCoTE (LeetCode Training and Evaluation dataset)\\n\\t\\n\\n\\n    üíª GitHub Repository  ‚Ä¢\\n\\n"},
	{"name":"SWE-Bench-Verified-O1-reasoning-high-results","keyword":"code-generation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlexCuadron/SWE-Bench-Verified-O1-reasoning-high-results","creator_name":"Alejandro Cuadron Lafuente","creator_url":"https://huggingface.co/AlexCuadron","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSWE-Bench Verified O1 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExecutive Summary\\n\\t\\n\\nThis repository contains verified reasoning traces from the O1 model evaluating software engineering tasks. Using OpenHands + CodeAct v2.2, we tested O1's bug-fixing capabilities on the SWE-Bench Verified dataset, achieving a 28.8% success rate across 500 test instances.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset was generated using the CodeAct framework, which aims to improve code generation through enhanced action-based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlexCuadron/SWE-Bench-Verified-O1-reasoning-high-results."},
	{"name":"developers-questions-small-qe2","keyword":"coding","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OramaSearch/developers-questions-small-qe2","creator_name":"OramaSearch Inc.","creator_url":"https://huggingface.co/OramaSearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDevelopers Questions Small QE2\\n\\t\\n\\nA dataset consisting of ~12k developers' questions, in English. These questions are synthetically generated via local LLMs at Orama.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasets\\n\\t\\n\\nThe dataset is proposed with three different embedding models:\\n\\nbge-small-en-v1.5\\nbge-base-en-v1.5\\nbge-large-en-v1.5\\n\\nIt also contains a quantized version for each model:\\n\\nbge-small 32 bytes\\nbge-base 32 bytes\\nbge-large 32 bytes\\n\\nFor each quantized model, this repository includes a binary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OramaSearch/developers-questions-small-qe2."},
	{"name":"Coq-Changelog-QA","keyword":"formal-methods","license":"GNU Lesser General Public License v2.1","license_url":"https://choosealicense.com/licenses/lgpl-2.1/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-Changelog-QA","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCoq Changelog Q&A Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Coq Changelog Q&A Dataset is an extension of the original Coq Changelog Dataset, transforming each changelog entry into two Question‚ÄìAnswer pairs via two distinct prompts. One focuses on a straightforward query about the change itself, while the other aims at the rationale or motivation behind it. By applying both prompts to every changelog entry, the dataset approximately doubles in size compared to the source.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Changelog-QA."},
	{"name":"SWE-Bench-Verified-O1-reasoning-high-results","keyword":"open-source","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlexCuadron/SWE-Bench-Verified-O1-reasoning-high-results","creator_name":"Alejandro Cuadron Lafuente","creator_url":"https://huggingface.co/AlexCuadron","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSWE-Bench Verified O1 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExecutive Summary\\n\\t\\n\\nThis repository contains verified reasoning traces from the O1 model evaluating software engineering tasks. Using OpenHands + CodeAct v2.2, we tested O1's bug-fixing capabilities on the SWE-Bench Verified dataset, achieving a 28.8% success rate across 500 test instances.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset was generated using the CodeAct framework, which aims to improve code generation through enhanced action-based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlexCuadron/SWE-Bench-Verified-O1-reasoning-high-results."},
	{"name":"my-blog-qa-dataset","keyword":"open-source","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/didierlopes/my-blog-qa-dataset","creator_name":"Didier Lopes","creator_url":"https://huggingface.co/didierlopes","description":"didierlopes/my-blog-qa-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"SWE-Bench-Verified-O1-reasoning-high-results","keyword":"python","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlexCuadron/SWE-Bench-Verified-O1-reasoning-high-results","creator_name":"Alejandro Cuadron Lafuente","creator_url":"https://huggingface.co/AlexCuadron","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSWE-Bench Verified O1 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExecutive Summary\\n\\t\\n\\nThis repository contains verified reasoning traces from the O1 model evaluating software engineering tasks. Using OpenHands + CodeAct v2.2, we tested O1's bug-fixing capabilities on the SWE-Bench Verified dataset, achieving a 28.8% success rate across 500 test instances.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset was generated using the CodeAct framework, which aims to improve code generation through enhanced action-based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlexCuadron/SWE-Bench-Verified-O1-reasoning-high-results."},
	{"name":"CodeSimilarityBench","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Meeex2/CodeSimilarityBench","creator_name":"Abdellah OUMIDA","creator_url":"https://huggingface.co/Meeex2","description":"Meeex2/CodeSimilarityBench dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"test","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ding0702/test","creator_name":"Ding","creator_url":"https://huggingface.co/Ding0702","description":"Ding0702/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ru-alpaca-html","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ai-blond/ru-alpaca-html","creator_name":"Janice Blond","creator_url":"https://huggingface.co/ai-blond","description":"ai-blond/ru-alpaca-html dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Tachibana-QVQ-PREVIEW","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Tachibana-QVQ-PREVIEW","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"This is a preview of the full Tachibana-QVQ code-instruct dataset, containing the first ~10k rows.\\nGet the full dataset now!\\nPrompts randomly selected from sequelbox/Tachibana, all responses generated by Qwen/QVQ-72B-Preview.\\nDataset has not been reviewed for format or accuracy. Synthetic data is generated by a 'preview' edition of Qwen's QVQ 72b model.\\nUse as you will.\\n"},
	{"name":"Lean4-Changelog","keyword":"formal-methods","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Lean4-Changelog","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLean 4 Changelog Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Lean 4 Changelog Dataset provides structured, machine-readable entries for changes in Lean 4, including language and library updates, fixes, deprecations, and other modifications. This dataset focuses on release notes from Lean 4‚Äôs official changelogs, capturing the key updates that are most likely to impact users, developers, or researchers working with Lean 4.\\nBy offering structured data for these changes, this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-Changelog."},
	{"name":"CodeSimilarityBench","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Meeex2/CodeSimilarityBench","creator_name":"Abdellah OUMIDA","creator_url":"https://huggingface.co/Meeex2","description":"Meeex2/CodeSimilarityBench dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Tachibana-QVQ-PREVIEW","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Tachibana-QVQ-PREVIEW","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"This is a preview of the full Tachibana-QVQ code-instruct dataset, containing the first ~10k rows.\\nGet the full dataset now!\\nPrompts randomly selected from sequelbox/Tachibana, all responses generated by Qwen/QVQ-72B-Preview.\\nDataset has not been reviewed for format or accuracy. Synthetic data is generated by a 'preview' edition of Qwen's QVQ 72b model.\\nUse as you will.\\n"},
	{"name":"mini-MetaMathQA","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/akshathmangudi/mini-MetaMathQA","creator_name":"Akshath Mangudi","creator_url":"https://huggingface.co/akshathmangudi","description":"\\n\\t\\n\\t\\t\\n\\t\\tMini-MetaMathQA\\n\\t\\n\\nMini-MetaMathQA is the miniature version of the original MetaMathQA \\nto fine-tune reasoning capabilities on Small Language Models. \\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\nTotal Size: ~110.84 MB\\nDownload Size: ~56 MB\\nLanguages: English (en)\\nLicense: MIT\\nTask Category: Text-to-Text Generation\\nTags: Code, QA, Reasoning\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nFeature Name\\nData Type\\n\\n\\n\\t\\t\\ntype\\nstring\\n\\n\\nquery\\nstring\\n\\n\\noriginal_question\\nstring\\n\\n\\nresponse\\nstring\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Splits‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akshathmangudi/mini-MetaMathQA."},
	{"name":"lunaris-tech","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meryyllebr543/lunaris-tech","creator_name":"Francisco Antonio","creator_url":"https://huggingface.co/meryyllebr543","description":"\\n\\t\\n\\t\\t\\n\\t\\tLunaris-Tech\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card | Hugging Face\\n\\t\\n\\nLunaris-Tech is a high-quality dataset designed to train lightweight NLP models like Lunaris Codex Mini (120M parameters) for technical question-answering, tool usage guides, and real-world problem-solving in programming and technology. It contains 17,000 unique examples across three key categories: Q&A Tech, Tools/Frameworks, and Real-World Scenarios, generated using a custom pipeline with Azure OpenAI models (o1 and o3-mini).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meryyllebr543/lunaris-tech."},
	{"name":"graph_problem_traces_test1","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Beanbagdzf/graph_problem_traces_test1","creator_name":"Zifeng Ding","creator_url":"https://huggingface.co/Beanbagdzf","description":"A dataset containing graph and discrete math problem-solving traces with tool-based code solutions. Each record includes a problem, its final answer, and the code solution (as rationale)."},
	{"name":"stackoverflow_q_and_a_sample","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eshangj/stackoverflow_q_and_a_sample","creator_name":"Eshan Jayasundara","creator_url":"https://huggingface.co/eshangj","description":"\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\n\\nThis dataset contains the question-answer pairs extracted from Stackoverflow using Stack Exchange API v2.3 and used following endpoints,\\n/answers/{ids} GET\\n/questions GET\\n\\n\\nFrom 2020 January 1 to 2025 February 5\\n\\t\\n\\t\\t\\n\\t\\t1. Dataset description,\\n\\t\\n\\n\\nContains only python tagged question-answer pairs.\\nEach question has a vote greater tan or equal to 1.\\nOnly contains the questions that have accepted answers and the corresponding accepted answers.\\nCan contain accepted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eshangj/stackoverflow_q_and_a_sample."},
	{"name":"qxf2-codegen","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shivaharip/qxf2-codegen","creator_name":"shivahari","creator_url":"https://huggingface.co/shivaharip","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains a collection of code from Qxf2 Services's public GitHub repositories. It includes various scripts, functions, and components used in software development, automation, testing, and other technical services.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nDataset Version: v1.0\\nLast Updated: 11th Feb 2025\\nRepository: https://github.com/qxf2\\nLanguages: Python, Javascript, Java, Rust, YAML, Shell Script, etc.\\nLicense: MIT License\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntended Use\\n\\t\\n\\nThis dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shivaharip/qxf2-codegen."},
	{"name":"Flame-Evo-React","keyword":"code-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Flame-Code-VLM/Flame-Evo-React","creator_name":"Flame-Code-VLM","creator_url":"https://huggingface.co/Flame-Code-VLM","description":"\\n\\t\\n\\t\\t\\n\\t\\tFlame-Evo-React: A Diverse Data Synthesis Dataset for Multi-modal React Code Generation\\n\\t\\n\\nFlame-Evo-React is a dataset synthesized using the Evolution-Based Synthesis method, leveraging random evolutionary logic to generate a highly diverse set of React components. This approach systematically varies functionality, architecture, and visual style, providing a robust dataset for generalized React code generation.\\nThis dataset includes in-breadth (feature expansion) and in-depth‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Flame-Code-VLM/Flame-Evo-React."},
	{"name":"SWE-Fixer-Train-Editing-CoT-70K","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/internlm/SWE-Fixer-Train-Editing-CoT-70K","creator_name":"InternLM","creator_url":"https://huggingface.co/internlm","description":"internlm/SWE-Fixer-Train-Editing-CoT-70K dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"mensuration-cycle-tracker","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anaslari/mensuration-cycle-tracker","creator_name":"lari","creator_url":"https://huggingface.co/anaslari","description":"anaslari/mensuration-cycle-tracker dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Aurora-Think-1.0","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/naimulislam/Aurora-Think-1.0","creator_name":"Naimul Islam Nahid","creator_url":"https://huggingface.co/naimulislam","description":"naimulislam/Aurora-Think-1.0 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"TinyMarkdown-Instruct-PT","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VAMJ-0042/TinyMarkdown-Instruct-PT","creator_name":"Vitor Augusto Machado Jorge","creator_url":"https://huggingface.co/VAMJ-0042","description":"\\n\\t\\n\\t\\t\\n\\t\\tMarkdown Fine-Tuning Datasets (English & PT-BR)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThese datasets are designed to fine-tune Large Language Models (LLMs) like Gemma to generate structured Markdown-formatted responses. The datasets contain instruction-response pairs, ensuring the model learns how to output Markdown elements correctly.\\n\\n\\t\\n\\t\\t\\n\\t\\tDatasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1. English Markdown Dataset\\n\\t\\n\\n\\nAvailable on Hugging Face: TinyMarkdown-Instruct-EN\\nSize: Large-scale dataset with structured Markdown‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VAMJ-0042/TinyMarkdown-Instruct-PT."},
	{"name":"SynSQL-2.5M","keyword":"sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/seeklhy/SynSQL-2.5M","creator_name":"lihaoyang","creator_url":"https://huggingface.co/seeklhy","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynSQL-2.5M - The First Million-Scale Cross-Domain Text-to-SQL Dataset\\n\\t\\n\\nWe introduce the first million-scale text-to-SQL dataset, SynSQL-2.5M, containing over 2.5 million diverse and high-quality data samples, spanning more than 16,000 databases from various domains.\\nBuilding on SynSQL-2.5M, we introduce OmniSQL, a family of powerful text-to-SQL models available in three sizes: 7B, 14B, and 32B. During the fine-tuning process, we also integrate training sets from Spider and BIRD‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/seeklhy/SynSQL-2.5M."},
	{"name":"SynSQL-2.5M","keyword":"text-to-sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/seeklhy/SynSQL-2.5M","creator_name":"lihaoyang","creator_url":"https://huggingface.co/seeklhy","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynSQL-2.5M - The First Million-Scale Cross-Domain Text-to-SQL Dataset\\n\\t\\n\\nWe introduce the first million-scale text-to-SQL dataset, SynSQL-2.5M, containing over 2.5 million diverse and high-quality data samples, spanning more than 16,000 databases from various domains.\\nBuilding on SynSQL-2.5M, we introduce OmniSQL, a family of powerful text-to-SQL models available in three sizes: 7B, 14B, and 32B. During the fine-tuning process, we also integrate training sets from Spider and BIRD‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/seeklhy/SynSQL-2.5M."},
	{"name":"github_issues","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SurAyush/github_issues","creator_name":"Ayush Sur","creator_url":"https://huggingface.co/SurAyush","description":"SurAyush/github_issues dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"func_calls_ds","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/retrain-pipelines/func_calls_ds","creator_name":"retrain-pipelines","creator_url":"https://huggingface.co/retrain-pipelines","description":"\\n\\t\\n\\t\\t\\n\\t\\tretrain-pipelines Function Calling\\n\\t\\n\\nversion 0.10  -  2025-03-16 13:07:17 UTC\\nSource datasets :\\n\\nmain¬†:\\nXlam Function Calling 60k\\nSalesforce/xlam-function-calling-60k\\n(26d14eb -\\n  2025-01-24 19:25:58 UTC)\\nlicense¬†:\\ncc-by-4.0\\narxiv¬†:\\n- 2406.18518\\n\\n\\ndata-enrichment¬†:\\nNatural Questions Clean\\nlighteval/natural_questions_clean\\n(a72f7fa -\\n  2023-10-17 20:29:08 UTC)\\nlicense¬†:\\nunknown\\nThe herein dataset has 2 configs : continued_pre_training and supervised_finetuning.\\nThe former serves for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/retrain-pipelines/func_calls_ds."},
	{"name":"func_calls_ds","keyword":"function-calling","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/retrain-pipelines/func_calls_ds","creator_name":"retrain-pipelines","creator_url":"https://huggingface.co/retrain-pipelines","description":"\\n\\t\\n\\t\\t\\n\\t\\tretrain-pipelines Function Calling\\n\\t\\n\\nversion 0.10  -  2025-03-16 13:07:17 UTC\\nSource datasets :\\n\\nmain¬†:\\nXlam Function Calling 60k\\nSalesforce/xlam-function-calling-60k\\n(26d14eb -\\n  2025-01-24 19:25:58 UTC)\\nlicense¬†:\\ncc-by-4.0\\narxiv¬†:\\n- 2406.18518\\n\\n\\ndata-enrichment¬†:\\nNatural Questions Clean\\nlighteval/natural_questions_clean\\n(a72f7fa -\\n  2023-10-17 20:29:08 UTC)\\nlicense¬†:\\nunknown\\nThe herein dataset has 2 configs : continued_pre_training and supervised_finetuning.\\nThe former serves for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/retrain-pipelines/func_calls_ds."},
	{"name":"QUITE","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/timo-pierre-schrader/QUITE","creator_name":"Timo Pierre Schrader","creator_url":"https://huggingface.co/timo-pierre-schrader","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for QUITE\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nQUITE (Quantifying Uncertainty in natural language Text) is an entirely new benchmark that allows for assessing the capabilities of neural language model-based systems w.r.t. to Bayesian reasoning on a large set of input text that describes probabilistic relationships in natural language text.\\nFor example, take the following statement from QUITE:\\n\\nIf Plcg is in a high state, PIP3 appears in a low state in 42% of all‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/timo-pierre-schrader/QUITE."},
	{"name":"VanRossum-Alpaca","keyword":"coding","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/VanRossum-Alpaca","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHomage to Python\\n\\t\\n\\nThe VanRossum dataset is all Python! I used DataMix to combine a handful of highly rated Python-centric datasets, to get a sampling of each and create something new.\\nThis data set has 80,000 entries and is named after Guido Van Rossum, the man who invented Python back in 1991.\\nSee the VanRossum Collection on HF for all things related to this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAlpaca / GPT\\n\\t\\n\\nThere are 2 versions of this dataset available on Huggingface.\\n\\nVanRossum-GPT‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/theprint/VanRossum-Alpaca."},
	{"name":"VanRossum-GPT","keyword":"coding","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/VanRossum-GPT","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHomage to Python\\n\\t\\n\\nThe VanRossum dataset is all Python! I used DataMix to combine a handful of highly rated Python-centric datasets, to get a sampling of each and create something new.\\nThis data set has 80,000 entries and is named after Guido Van Rossum, the man who invented Python back in 1991.\\nSee the VanRossum Collection on HF for all things related to this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAlpaca / GPT\\n\\t\\n\\nThere are 2 versions of this dataset available on Huggingface.\\n\\nVanRossum-GPT‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/theprint/VanRossum-GPT."},
	{"name":"pgsql-hackers-processed","keyword":"postgresql","license":"PostgreSQL License","license_url":"https://choosealicense.com/licenses/postgresql/","language":"en","dataset_url":"https://huggingface.co/datasets/wanshenl/pgsql-hackers-processed","creator_name":"Wan Shen Lim","creator_url":"https://huggingface.co/wanshenl","description":"wanshenl/pgsql-hackers-processed dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"pgsql-performance-processed","keyword":"postgresql","license":"PostgreSQL License","license_url":"https://choosealicense.com/licenses/postgresql/","language":"en","dataset_url":"https://huggingface.co/datasets/wanshenl/pgsql-performance-processed","creator_name":"Wan Shen Lim","creator_url":"https://huggingface.co/wanshenl","description":"wanshenl/pgsql-performance-processed dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"VanRossum-Alpaca","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/VanRossum-Alpaca","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHomage to Python\\n\\t\\n\\nThe VanRossum dataset is all Python! I used DataMix to combine a handful of highly rated Python-centric datasets, to get a sampling of each and create something new.\\nThis data set has 80,000 entries and is named after Guido Van Rossum, the man who invented Python back in 1991.\\nSee the VanRossum Collection on HF for all things related to this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAlpaca / GPT\\n\\t\\n\\nThere are 2 versions of this dataset available on Huggingface.\\n\\nVanRossum-GPT‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/theprint/VanRossum-Alpaca."},
	{"name":"VanRossum-GPT","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/VanRossum-GPT","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHomage to Python\\n\\t\\n\\nThe VanRossum dataset is all Python! I used DataMix to combine a handful of highly rated Python-centric datasets, to get a sampling of each and create something new.\\nThis data set has 80,000 entries and is named after Guido Van Rossum, the man who invented Python back in 1991.\\nSee the VanRossum Collection on HF for all things related to this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAlpaca / GPT\\n\\t\\n\\nThere are 2 versions of this dataset available on Huggingface.\\n\\nVanRossum-GPT‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/theprint/VanRossum-GPT."},
	{"name":"test","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/haggs/test","creator_name":"Dan Haggerty","creator_url":"https://huggingface.co/haggs","description":"haggs/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"dataset-9","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/keikhosrotav/dataset-9","creator_name":"keikhosro tavakoli","creator_url":"https://huggingface.co/keikhosrotav","description":"keikhosrotav/dataset-9 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"statcodesearch","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/drndr/statcodesearch","creator_name":"A D","creator_url":"https://huggingface.co/drndr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for statcodesearch\\n\\t\\n\\n\\n\\nThe StatCodeSearch dataset is a benchmark test set consisting of code comment pairs extracted from R programming language scripts authored mostly by researchers. The dataset is sourced from the Open Science Framework (OSF). It includes text and code samples from R projects that pertain to the fields of social science and psychology with a focus on the statistical analysis of research data. As part of the GenCodeSearchNet test suite, this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/drndr/statcodesearch."},
	{"name":"Tin_hoc_mcq_extended","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kamisaiko/Tin_hoc_mcq_extended","creator_name":"NGUYEN VIET TRUNG","creator_url":"https://huggingface.co/kamisaiko","description":"kamisaiko/Tin_hoc_mcq_extended dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Celestia2","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Celestia2","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Celestia 2 is a multi-turn agent-instruct dataset containing science data.\\nThis dataset focuses on challenging multi-turn conversations and contains:\\n\\n176k rows of synthetic multi-turn science-instruct data, using Microsoft's AgentInstruct style. All prompts and responses are synthetically generated using Llama 3.1 405b Instruct. Primary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\\n\\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Celestia2."},
	{"name":"zorse","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zorse/zorse","creator_name":"Zorse Project","creator_url":"https://huggingface.co/zorse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZorse\\n\\t\\n\\nZorse contains source code for mainframe programming languages.\\n"},
	{"name":"exoplanets-sql2","keyword":"sql","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dpv/exoplanets-sql2","creator_name":"Dmitriy Popov-Velasco","creator_url":"https://huggingface.co/dpv","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExoplanets text-to-SQL2\\n\\t\\n\\nThis is a copy of dpv/exoplanets-sql with 10 extra examples added to the training data to boost validation performance on questions found challenging by fine tuned models.\\n"},
	{"name":"Single-DriveLM-NuScenes-VQA","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Chouoftears/Single-DriveLM-NuScenes-VQA","creator_name":"Shenzhe Zhu","creator_url":"https://huggingface.co/Chouoftears","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSingle-DriveLM-NuScenes VQA Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUpdates & News\\n\\t\\n\\n\\n[10/11/2024] VQA Dataset was released\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is the sub-dataset of DriveLM which only include single object in ego scenes\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\nFor single traffic participant recgonition, segmentation, VQA subtasks of driving scenarios.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nsingle_pedestrian \\n‚îú‚îÄ‚îÄ images  \\n‚îî‚îÄ‚îÄ labeled_pedestrian_data.json\\n\\nsingle_vehicle\\n‚îú‚îÄ‚îÄ images  \\n‚îî‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Chouoftears/Single-DriveLM-NuScenes-VQA."},
	{"name":"CodeMMLU","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fsoft-AIC/CodeMMLU","creator_name":"FPT Software AI Center","creator_url":"https://huggingface.co/Fsoft-AIC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding Capabilities\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìå CodeMMLU\\n\\t\\n\\nCodeMMLU is a comprehensive benchmark designed to evaluate the capabilities of large language models (LLMs) in coding and software knowledge. \\nIt builds upon the structure of multiple-choice question answering (MCQA) to cover a wide range of programming tasks and domains, including code generation, defect detection, software engineering principles, and much more.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fsoft-AIC/CodeMMLU."},
	{"name":"code_generation","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/macroteck/code_generation","creator_name":"MacroTeck Technologies","creator_url":"https://huggingface.co/macroteck","description":"macroteck/code_generation dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ExecRepoBench","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CSJianYang/ExecRepoBench","creator_name":"Yang Jian","creator_url":"https://huggingface.co/CSJianYang","description":"\\nHome: https://execrepobench.github.io/\\npaper: https://arxiv.org/pdf/2412.11990\\nLeaderboard: https://execrepobench.github.io/leaderboard.html\\nGithub: https://github.com/QwenLM/Qwen2.5-Coder/tree/main/qwencoder-eval/base/benchmarks/ExecRepoBench\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn this work, we introduce a novel framework for enhancing code completion in software development through the creation of a repository-level benchmark ExecRepoBench and the instruction corpora Repo-Instruct, aim at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CSJianYang/ExecRepoBench."},
	{"name":"wordlists","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Chemically-motivated/wordlists","creator_name":"Chemically Motivated Solutions","creator_url":"https://huggingface.co/Chemically-motivated","description":"Dataset Card for Wordlists\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset consists of a collection of wordlists designed for use in cybersecurity tasks, such as penetration testing, vulnerability scanning, and password strength analysis. The wordlists cover various use cases, including common passwords, network device names, and terms used in security-related research. These wordlists are essential tools for security professionals in identifying weak points in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Chemically-motivated/wordlists."},
	{"name":"AntiGPTTest01","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ikerm11/AntiGPTTest01","creator_name":"m","creator_url":"https://huggingface.co/ikerm11","description":"ikerm11/AntiGPTTest01 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"emotions_worldwide","keyword":"code","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ferdinandnathaniel/emotions_worldwide","creator_name":"Fabian Kok","creator_url":"https://huggingface.co/Ferdinandnathaniel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEmotions worldwide\\n\\t\\n\\nThis is an open dataset listing emotions from across the world with their descriptions in English. First used for the artwork E*star for the NeurIPS 2024 Creative AI track, the dataset behind the artwork has been made open-source through github. \\nThe dataset actively seeks validation, correction, and addition by the open public (especially from non-English language speakers, as those emotions are difficult to validate by myself). \\nSupport by validating‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ferdinandnathaniel/emotions_worldwide."},
	{"name":"common_starcoder","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/skymizer/common_starcoder","creator_name":"skymizer","creator_url":"https://huggingface.co/skymizer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCommon Starcoder dataset\\n\\t\\n\\nThis dataset is generated from bigcode/starcoderdata.\\nTotal GPT2 Tokens: 4,649,163,171\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneration Process\\n\\t\\n\\n\\nWe filtered the original dataset with common language: C, Cpp, Java, Python and JSON.\\nWe removed some columns for mixing up with other dataset: \\\"id\\\", \\\"max_stars_repo_path\\\", \\\"max_stars_repo_name\\\"\\nAfter removing the irrelevant fields, we shuffle the dataset with random seed=42.\\nWe filtered the data on \\\"max_stars_count\\\" > 300 and shuffle‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/skymizer/common_starcoder."},
	{"name":"devto","keyword":"development","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/teleren/devto","creator_name":"fg","creator_url":"https://huggingface.co/teleren","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dev.to Blogging Platform Posts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is an unfinished dataset of blog posts from dev.to, a developer community.\\nCurrently containing about 700,000 unfiltered posts. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in English, but also contains content in various other languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes the following fields:\\n\\nid: Unique identifier for the article (integer)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/teleren/devto."},
	{"name":"Coq-Changelog","keyword":"formal-methods","license":"GNU Lesser General Public License v2.1","license_url":"https://choosealicense.com/licenses/lgpl-2.1/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Coq-Changelog","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCoq Changelog Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Coq Changelog Dataset is derived from the official Coq changelogs, focusing on versions 8.17 to 8.20. These versions were specifically chosen as they represent changes that may be underrepresented or entirely absent from current language model training data. By targeting these recent versions, this dataset helps address knowledge gaps in formal methods tools and theorem proving systems.\\nThis dataset provides structured‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Changelog."},
	{"name":"ksdoc-airscript","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cy948/ksdoc-airscript","creator_name":"yao cai","creator_url":"https://huggingface.co/cy948","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHuman Annotation Example\\n\\t\\n\\nWe invite some domain experts who has code experience on AirScript to add annotations for the code snippets in lines. For example:\\n\\nData annotation example\\n\\n/*Êú¨Á§∫‰æãÂà§Êñ≠Â¶ÇÊûúÊ¥ªÂä®Â∑•‰ΩúË°®‰∏äÂå∫Âüü B1:B10 ‰∏≠Á¨¨‰∫å‰∏™ÔºàAboveAverageÔºâÊù°‰ª∂Ê†ºÂºèÁöÑÁ±ªÂûã‰∏∫xlAboveAverageConditionÔºåÂàôÂà†Èô§ËØ•Êù°‰ª∂Ê†ºÂºè„ÄÇ*/\\nfunction test() {\\n+// ‰ªéÂ∑•‰ΩúË°®‰∏äÂå∫Âüü B1:B10 ‰∏≠ÈÄâÊã©Á¨¨‰∫å‰∏™Êù°‰ª∂Ê†ºÂºè\\n    let aboveAverage = ActiveSheet.Range(\\\"B1:B10\\\").FormatConditions.Item(2)\\n+// Ëã•Êù°‰ª∂Ê†ºÂºèÁöÑÁ±ªÂûã‰∏∫ `xlAboveAverageCondition`\\n    if (aboveAverage.Type ==‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cy948/ksdoc-airscript."},
	{"name":"refactorchat","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BradMcDanel/refactorchat","creator_name":"Bradley McDanel","creator_url":"https://huggingface.co/BradMcDanel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Details\\n\\t\\n\\n\\nDataset Name: RefactorChat\\nVersion: 1.0\\nDate: October 19, 2024\\nType: Multi-turn dialogue dataset for code refactoring and feature addition\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntended Use\\n\\t\\n\\n\\nPrimary Use: Evaluating and training large language models on incremental code development tasks\\nIntended Users: Researchers and practitioners in natural language processing and software engineering\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Composition\\n\\t\\n\\n\\nSize: 100 samples\\nStructure: Each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BradMcDanel/refactorchat."},
	{"name":"AEC-VA-details-spec-dataset","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/simondavidpalmer/AEC-VA-details-spec-dataset","creator_name":"Simon David Palmer","creator_url":"https://huggingface.co/simondavidpalmer","description":"simondavidpalmer/AEC-VA-details-spec-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"SmallThoughts","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SmallDoge/SmallThoughts","creator_name":"Doge Face","creator_url":"https://huggingface.co/SmallDoge","description":"\\n\\t\\n\\t\\t\\n\\t\\tSmallThoughts\\n\\t\\n\\n\\n  \\n\\n\\n  \\n    \\n  \\n  \\n    \\n  \\n  \\n    \\nOpen synthetic reasoning dataset, covering math, science, code, and puzzles.\\nTo address the issue of the existing DeepSeek R1 distilled data being too long, this dataset constrains the reasoning trajectory to be more precise and concise while retaining the reflective nature.\\nWe also open-sourced the pipeline code for distilled data here, with just one command you can generate your own dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use\\n\\t\\n\\nYou can load‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SmallDoge/SmallThoughts."},
	{"name":"refactorchat","keyword":"programming","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BradMcDanel/refactorchat","creator_name":"Bradley McDanel","creator_url":"https://huggingface.co/BradMcDanel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Details\\n\\t\\n\\n\\nDataset Name: RefactorChat\\nVersion: 1.0\\nDate: October 19, 2024\\nType: Multi-turn dialogue dataset for code refactoring and feature addition\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntended Use\\n\\t\\n\\n\\nPrimary Use: Evaluating and training large language models on incremental code development tasks\\nIntended Users: Researchers and practitioners in natural language processing and software engineering\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Composition\\n\\t\\n\\n\\nSize: 100 samples\\nStructure: Each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BradMcDanel/refactorchat."},
	{"name":"python-code-dataset-500k","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jtatman/python-code-dataset-500k","creator_name":"James","creator_url":"https://huggingface.co/jtatman","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAttention: This dataset is a summary and reformat pulled from github code.\\n\\t\\n\\nYou should make your own assumptions based on this.\\nIn fact, there is another dataset I formed through parsing that addresses several points:\\n\\nout of 500k python related items, most of them are python-ish, not pythonic\\nthe majority of the items here contain excessive licensing inclusion of original code\\nthe items here are sometimes not even python but have references\\nThere's a whole lot of gpl summaries‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jtatman/python-code-dataset-500k."},
	{"name":"sql-create-context","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/b-mc2/sql-create-context","creator_name":"brianm","creator_url":"https://huggingface.co/b-mc2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/b-mc2/sql-create-context."},
	{"name":"synthetic_text_to_sql","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gretelai/synthetic_text_to_sql","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","description":"\\n  \\n  Image generated by DALL-E. See prompt for more details\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tsynthetic_text_to_sql\\n\\t\\n\\n\\ngretelai/synthetic_text_to_sql is a rich dataset of high quality synthetic Text-to-SQL samples, \\ndesigned and generated using Gretel Navigator, and released under Apache 2.0.\\nPlease see our release blogpost for more details.\\nThe dataset includes:\\n\\n  105,851 records partitioned into 100,000 train and 5,851 test records\\n  ~23M total tokens, including ~12M SQL tokens\\n  Coverage across 100 distinct‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_text_to_sql."},
	{"name":"function-calling-small","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Deepexi/function-calling-small","creator_name":"Deepexi Inc","creator_url":"https://huggingface.co/Deepexi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÈõÜÂÜÖÂÆπËØ¥Êòé:\\n\\t\\n\\nÂåÖÂê´700+‰∏™ÈòøÈáå‰∫ëOpenAPIÁöÑ‰ø°ÊÅØ;ÂåÖÊã¨Dataworks,EMRÔºåDataLakeÔºåMaxcomputeÔºåHologram,ÂÆûÊó∂ËÆ°ÁÆóFlinkÁâàÔºåQuickBI,DTSÁ≠âÂ§ö‰∏™‰∫ßÂìÅÁöÑÂÖ¨ÂºÄOpen API‰ø°ÊÅØ„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊ†∑‰æã\\n\\t\\n\\n{\\n  \\\"systemPrompt\\\": ‰Ω†ÊòØ‰∏Ä‰∏™ÂáΩÊï∞Á≠õÈÄâÂä©ÁêÜÔºåÂ¶ÇÊûú‰∏éÈóÆÈ¢òÁõ∏ÂÖ≥ÁöÑËØù,ÊÇ®ÂèØ‰ª•‰ΩøÁî®‰∏ãÈù¢ÁöÑÂáΩÊï∞Êù•Ëé∑ÂèñÊõ¥Â§öÊï∞ÊçÆ‰ª•ÂõûÁ≠îÁî®Êà∑ÊèêÂá∫ÁöÑÈóÆÈ¢ò:{\\\"function\\\": \\\"UpdateTicketNum\\\", \\\"description\\\": \\\"ÂØπÁî®‰∫éÂÖçÁôªÂµåÂÖ•Êä•Ë°®ÁöÑÊåáÂÆöÁöÑticketËøõË°åÊõ¥Êñ∞Á•®ÊçÆÊï∞ÈáèÊìç‰Ωú„ÄÇ\\\", \\\"arguments\\\": [{\\\"name\\\": \\\"Ticket\\\", \\\"type\\\": \\\"string\\\", \\\"description\\\": \\\"‰∏âÊñπÂµåÂÖ•ÁöÑÁ•®ÊçÆÂÄºÔºåÂç≥URL‰∏≠ÁöÑaccessTicketÂÄº„ÄÇ\\\"}, {\\\"name\\\": \\\"TicketNum\\\", \\\"type\\\": \\\"integer\\\", \\\"description\\\": \\\"Á•®ÊçÆÊï∞„ÄÇ\\\\n-‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Deepexi/function-calling-small."},
	{"name":"ComBack","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/docz1105/ComBack","creator_name":"Ming Zhong","creator_url":"https://huggingface.co/docz1105","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tComBack: A Versatile Dataset for Enhancing Compiler Backend Development Efficiency\\n\\t\\n\\nComBack is a large-scale multi-platform compiler backend code dataset. It is sourced from GCC and LLVM backends corresponding  to 178 target platforms.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSource Data\\n\\nGCC\\n\\n\\n\\t\\n\\t\\t\\nCategory\\nTarget Platform\\nFunction\\nKLoC\\n\\n\\n\\t\\t\\nCPU\\n30\\n35,147\\n647.2\\n\\n\\nMPU\\n33\\n6,010\\n183.9\\n\\n\\nGPU\\n2\\n457\\n11.2\\n\\n\\nVLIW\\n5\\n959\\n25.4\\n\\n\\nDSP\\n3\\n399\\n9.6\\n\\n\\nVirtual\\n4\\n327\\n6.5\\n\\n\\nSUM\\n77\\n43,299\\n883.7\\n\\n\\n\\t\\n\\n\\nLLVM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/docz1105/ComBack."},
	{"name":"webcode2m","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xcodemind/webcode2m","creator_name":"xcodemind","creator_url":"https://huggingface.co/xcodemind","description":"WebCode2M: A Real-World Dataset for Code Generation from Webpage Designs with Layouts\\n(This dataset is also called Vision2UI.)\\n\\nAutomatically generating webpage code from webpage designscan significantly reduce the workload of front-end developers, andrecent Multimodal Large Language Models (MLLMs) have shownpromising potential in this area. However, our investigation revealsthat most existing MLLMs are constrained by the absence of highquality, large-scale, real-world datasets, resulting in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xcodemind/webcode2m."},
	{"name":"SWE-bench-extra","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nebius/SWE-bench-extra","creator_name":"Nebius","creator_url":"https://huggingface.co/nebius","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSWE-bench Extra is a dataset that can be used to train or evaluate agentic systems specializing in resolving GitHub issues. It is based on the methodology used to build SWE-bench benchmark and includes 6,415 Issue-Pull Request pairs sourced from 1,988 Python repositories.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe SWE-bench Extra dataset supports the development of software engineering agents capable of autonomously solving GitHub issues. The data collection process, based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nebius/SWE-bench-extra."},
	{"name":"sql-create-context","keyword":"context-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/b-mc2/sql-create-context","creator_name":"brianm","creator_url":"https://huggingface.co/b-mc2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/b-mc2/sql-create-context."},
	{"name":"turkish-function-calling-2k","keyword":"function-calling","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/atasoglu/turkish-function-calling-2k","creator_name":"Ahmet","creator_url":"https://huggingface.co/atasoglu","description":"Used argilla-warehouse/python-seed-tools to sample tools.\\n"},
	{"name":"function-calling-sharegpt","keyword":"function-calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hypervariance/function-calling-sharegpt","creator_name":"hypervariance","creator_url":"https://huggingface.co/hypervariance","description":"This is a dataset for finetuning models on function calling based on glaiveai/glaive-function-calling-v2.\\nThe dataset includes 86,864 examples of chats that include function calling as part of the conversation. The system prompt includes either 0, 1, or 2 functions that the assistant can use, and instructions on how the agent can use it.\\nChanges include:\\n\\nUsing ShareGPT format for chats\\nAdding \\\"function_response\\\" as a role\\nRemoving code examples\\nRemoving examples with invalid JSON as function‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hypervariance/function-calling-sharegpt."},
	{"name":"python-code-dataset-500k","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jtatman/python-code-dataset-500k","creator_name":"James","creator_url":"https://huggingface.co/jtatman","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAttention: This dataset is a summary and reformat pulled from github code.\\n\\t\\n\\nYou should make your own assumptions based on this.\\nIn fact, there is another dataset I formed through parsing that addresses several points:\\n\\nout of 500k python related items, most of them are python-ish, not pythonic\\nthe majority of the items here contain excessive licensing inclusion of original code\\nthe items here are sometimes not even python but have references\\nThere's a whole lot of gpl summaries‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jtatman/python-code-dataset-500k."},
	{"name":"sql-create-context","keyword":"sqlglot","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/b-mc2/sql-create-context","creator_name":"brianm","creator_url":"https://huggingface.co/b-mc2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/b-mc2/sql-create-context."},
	{"name":"sql-create-context","keyword":"wikisql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/b-mc2/sql-create-context","creator_name":"brianm","creator_url":"https://huggingface.co/b-mc2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/b-mc2/sql-create-context."},
	{"name":"SWE-bench-extra","keyword":"software","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nebius/SWE-bench-extra","creator_name":"Nebius","creator_url":"https://huggingface.co/nebius","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSWE-bench Extra is a dataset that can be used to train or evaluate agentic systems specializing in resolving GitHub issues. It is based on the methodology used to build SWE-bench benchmark and includes 6,415 Issue-Pull Request pairs sourced from 1,988 Python repositories.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe SWE-bench Extra dataset supports the development of software engineering agents capable of autonomously solving GitHub issues. The data collection process, based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nebius/SWE-bench-extra."},
	{"name":"sql-create-context","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/b-mc2/sql-create-context","creator_name":"brianm","creator_url":"https://huggingface.co/b-mc2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/b-mc2/sql-create-context."},
	{"name":"sql-create-context","keyword":"sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/b-mc2/sql-create-context","creator_name":"brianm","creator_url":"https://huggingface.co/b-mc2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/b-mc2/sql-create-context."},
	{"name":"synthetic_text_to_sql","keyword":"sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gretelai/synthetic_text_to_sql","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","description":"\\n  \\n  Image generated by DALL-E. See prompt for more details\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tsynthetic_text_to_sql\\n\\t\\n\\n\\ngretelai/synthetic_text_to_sql is a rich dataset of high quality synthetic Text-to-SQL samples, \\ndesigned and generated using Gretel Navigator, and released under Apache 2.0.\\nPlease see our release blogpost for more details.\\nThe dataset includes:\\n\\n  105,851 records partitioned into 100,000 train and 5,851 test records\\n  ~23M total tokens, including ~12M SQL tokens\\n  Coverage across 100 distinct‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_text_to_sql."},
	{"name":"sql-create-context","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/b-mc2/sql-create-context","creator_name":"brianm","creator_url":"https://huggingface.co/b-mc2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/b-mc2/sql-create-context."},
	{"name":"synthetic_text_to_sql","keyword":"text-to-sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gretelai/synthetic_text_to_sql","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","description":"\\n  \\n  Image generated by DALL-E. See prompt for more details\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tsynthetic_text_to_sql\\n\\t\\n\\n\\ngretelai/synthetic_text_to_sql is a rich dataset of high quality synthetic Text-to-SQL samples, \\ndesigned and generated using Gretel Navigator, and released under Apache 2.0.\\nPlease see our release blogpost for more details.\\nThe dataset includes:\\n\\n  105,851 records partitioned into 100,000 train and 5,851 test records\\n  ~23M total tokens, including ~12M SQL tokens\\n  Coverage across 100 distinct‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_text_to_sql."},
	{"name":"AI-CUDA-Engineer-Archive","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SakanaAI/AI-CUDA-Engineer-Archive","creator_name":"Sakana AI","creator_url":"https://huggingface.co/SakanaAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe AI CUDA Engineer Archive üë∑: Agentic CUDA Kernel Discovery, Optimization & Composition\\n\\t\\n\\n\\nWe release The AI CUDA Engineer archive, a dataset consisting of approximately 30,000 CUDA kernels generated by The AI CUDA Engineer. It is released under the CC-By-4.0 license and can be accessed via HuggingFace and interactively visualized here. The dataset is based on the Kernel tasks provided in KernelBench and includes a torch reference implementation, torch, NCU and Clang-tidy profiling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SakanaAI/AI-CUDA-Engineer-Archive."},
	{"name":"Ling-Coder-DPO","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inclusionAI/Ling-Coder-DPO","creator_name":"inclusionAI","creator_url":"https://huggingface.co/inclusionAI","description":"\\n    \\n\\n\\n\\n          ü§ó Hugging Face\\n          ü§ñ ModelScope\\n          üñ•Ô∏è GitHub\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLing-Coder Dataset\\n\\t\\n\\nThe Ling-Coder Dataset comprises the following components:\\n\\nLing-Coder-SFT: A subset of SFT data used for training Ling-Coder Lite, containing more than 5 million samples.\\nLing-Coder-DPO: A subset of DPO data used for training Ling-Coder Lite, containing 250k samples.\\nLing-Coder-SyntheticQA: A subset of synthetic data used for annealing training of Ling-Coder Lite, containing more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/inclusionAI/Ling-Coder-DPO."},
	{"name":"Ling-Coder-SFT","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inclusionAI/Ling-Coder-SFT","creator_name":"inclusionAI","creator_url":"https://huggingface.co/inclusionAI","description":"\\n    \\n\\n\\n\\n          ü§ó Hugging Face\\n          ü§ñ ModelScope\\n          üñ•Ô∏è GitHub\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLing-Coder Dataset\\n\\t\\n\\nThe Ling-Coder Dataset comprises the following components:\\n\\nLing-Coder-SFT: A subset of SFT data used for training Ling-Coder Lite, containing more than 5 million samples.\\nLing-Coder-DPO: A subset of DPO data used for training Ling-Coder Lite, containing 250k samples.\\nLing-Coder-SyntheticQA: A subset of synthetic data used for annealing training of Ling-Coder Lite, containing more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/inclusionAI/Ling-Coder-SFT."},
	{"name":"Ling-Coder-SyntheticQA","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inclusionAI/Ling-Coder-SyntheticQA","creator_name":"inclusionAI","creator_url":"https://huggingface.co/inclusionAI","description":"\\n    \\n\\n\\n\\n\\n          ü§ó Hugging Face\\n          ü§ñ ModelScope\\n          üñ•Ô∏è GitHub\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLing-Coder Dataset\\n\\t\\n\\nThe Ling-Coder Dataset comprises the following components:\\n\\nLing-Coder-SFT: A subset of SFT data used for training Ling-Coder Lite, containing more than 5 million samples.\\nLing-Coder-DPO: A subset of DPO data used for training Ling-Coder Lite, containing 250k samples.\\nLing-Coder-SyntheticQA: A subset of synthetic data used for annealing training of Ling-Coder Lite, containing more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/inclusionAI/Ling-Coder-SyntheticQA."},
	{"name":"code_clippy_github","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CodedotAI/code_clippy_github","creator_name":"Code.AI","creator_url":"https://huggingface.co/CodedotAI","description":"The Code Clippy dataset consists of various public codebases from GitHub in 22 programming languages with 23 extensions     totalling about 16 TB of data when uncompressed. The dataset was created from the public GitHub dataset on Google BiqQuery."},
	{"name":"mbpp","keyword":"code-generation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/mbpp","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Mostly Basic Python Problems (mbpp)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe benchmark consists of around 1,000 crowd-sourced Python programming problems, designed to be solvable by entry level programmers, covering programming fundamentals, standard library functionality, and so on. Each problem consists of a task description, code solution and 3 automated test cases. As described in the paper, a subset of the data has been hand-verified by us. \\nReleased here as part‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/mbpp."},
	{"name":"openai_humaneval","keyword":"code-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/openai/openai_humaneval","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for OpenAI HumanEval\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe HumanEval dataset released by OpenAI includes 164 programming problems with a function sig- nature, docstring, body, and several unit tests. They were handwritten to ensure not to be included in the training set of code generation models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe programming problems are written in Python and contain English natural text in comments and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openai/openai_humaneval."},
	{"name":"agent-leaderboard","keyword":"function-calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/galileo-ai/agent-leaderboard","creator_name":"Galileo","creator_url":"https://huggingface.co/galileo-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\tAgent Leaderboard\\n\\t\\n\\n\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Agent Leaderboard evaluates language models' ability to effectively utilize tools in complex scenarios. With major tech CEOs predicting 2025 as a pivotal year for AI agents, we built this leaderboard to answer: \\\"How do AI agents perform in real-world business scenarios?\\\"\\nGet latest update of the leaderboard on Hugging Face Spaces. For more info, checkout the blog post for a detailed overview of our evaluation methodology.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/galileo-ai/agent-leaderboard."},
	{"name":"spider-test-portuguese","keyword":"spider","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Boakpe/spider-test-portuguese","creator_name":"Breno","creator_url":"https://huggingface.co/Boakpe","description":"\\n\\t\\n\\t\\t\\n\\t\\tSpider Dataset - Vers√£o em Portugu√™s\\n\\t\\n\\nEste reposit√≥rio cont√©m a tradu√ß√£o para portugu√™s da parti√ß√£o de teste do dataset Spider, um benchmark para a tarefa de Text-to-SQL.\\n\\n\\t\\n\\t\\t\\n\\t\\tSobre esta tradu√ß√£o\\n\\t\\n\\nA tradu√ß√£o da parti√ß√£o \\\"test\\\" do Spider (contendo 2.147 inst√¢ncias) foi realizada seguindo um processo rigoroso:\\n\\nTradu√ß√£o inicial: Utilizando a API do GPT-4o mini da OpenAI\\nRevis√£o manual: Todas as 2.147 quest√µes foram revisadas e validadas manualmente\\nCrit√©rios de tradu√ß√£o:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Boakpe/spider-test-portuguese."},
	{"name":"spider-test-portuguese","keyword":"sql","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Boakpe/spider-test-portuguese","creator_name":"Breno","creator_url":"https://huggingface.co/Boakpe","description":"\\n\\t\\n\\t\\t\\n\\t\\tSpider Dataset - Vers√£o em Portugu√™s\\n\\t\\n\\nEste reposit√≥rio cont√©m a tradu√ß√£o para portugu√™s da parti√ß√£o de teste do dataset Spider, um benchmark para a tarefa de Text-to-SQL.\\n\\n\\t\\n\\t\\t\\n\\t\\tSobre esta tradu√ß√£o\\n\\t\\n\\nA tradu√ß√£o da parti√ß√£o \\\"test\\\" do Spider (contendo 2.147 inst√¢ncias) foi realizada seguindo um processo rigoroso:\\n\\nTradu√ß√£o inicial: Utilizando a API do GPT-4o mini da OpenAI\\nRevis√£o manual: Todas as 2.147 quest√µes foram revisadas e validadas manualmente\\nCrit√©rios de tradu√ß√£o:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Boakpe/spider-test-portuguese."},
	{"name":"spider-test-portuguese","keyword":"text-to-sql","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Boakpe/spider-test-portuguese","creator_name":"Breno","creator_url":"https://huggingface.co/Boakpe","description":"\\n\\t\\n\\t\\t\\n\\t\\tSpider Dataset - Vers√£o em Portugu√™s\\n\\t\\n\\nEste reposit√≥rio cont√©m a tradu√ß√£o para portugu√™s da parti√ß√£o de teste do dataset Spider, um benchmark para a tarefa de Text-to-SQL.\\n\\n\\t\\n\\t\\t\\n\\t\\tSobre esta tradu√ß√£o\\n\\t\\n\\nA tradu√ß√£o da parti√ß√£o \\\"test\\\" do Spider (contendo 2.147 inst√¢ncias) foi realizada seguindo um processo rigoroso:\\n\\nTradu√ß√£o inicial: Utilizando a API do GPT-4o mini da OpenAI\\nRevis√£o manual: Todas as 2.147 quest√µes foram revisadas e validadas manualmente\\nCrit√©rios de tradu√ß√£o:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Boakpe/spider-test-portuguese."},
	{"name":"spider","keyword":"text-to-sql","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xlangai/spider","creator_name":"XLang NLP Lab","creator_url":"https://huggingface.co/xlangai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students.\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at https://yale-lily.github.io/spider\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xlangai/spider."},
	{"name":"apps","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/codeparrot/apps","creator_name":"CodeParrot","creator_url":"https://huggingface.co/codeparrot","description":"APPS is a benchmark for Python code generation, it includes 10,000 problems, which range from having simple oneline solutions to being substantial algorithmic challenges, for more details please refer to this paper: https://arxiv.org/pdf/2105.09938.pdf."},
	{"name":"codecomplex","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/codeparrot/codecomplex","creator_name":"CodeParrot","creator_url":"https://huggingface.co/codeparrot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCodeComplex Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCodeComplex consists of 4,200 Java codes submitted to programming competitions by human programmers and their complexity labels annotated by a group of algorithm experts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use it\\n\\t\\n\\n You can load and iterate through the dataset with the following two lines of code:\\nfrom datasets import load_dataset\\n\\nds = load_dataset(\\\"codeparrot/codecomplex\\\", split=\\\"train\\\")\\nprint(next(iter(ds)))\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/codeparrot/codecomplex."},
	{"name":"xlcost-text-to-code","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/codeparrot/xlcost-text-to-code","creator_name":"CodeParrot","creator_url":"https://huggingface.co/codeparrot","description":" XLCoST is a machine learning benchmark dataset that contains fine-grained parallel data in 7 commonly used programming languages (C++, Java, Python, C#, Javascript, PHP, C), and natural language (English)."},
	{"name":"github-jupyter-code-to-text","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/codeparrot/github-jupyter-code-to-text","creator_name":"CodeParrot","creator_url":"https://huggingface.co/codeparrot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\nThis dataset consists of sequences of Python code followed by a a docstring explaining its function. It was constructed by concatenating code and text pairs \\nfrom this dataset that were originally code and markdown cells in Jupyter Notebooks.\\nThe content of each example the following:\\n[CODE]\\n\\\"\\\"\\nExplanation: [TEXT]\\nEnd of explanation\\n\\\"\\\"\\n[CODE]\\n\\\"\\\"\\nExplanation: [TEXT]\\nEnd of explanation\\n\\\"\\\"\\n...\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use it\\n\\t\\n\\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/codeparrot/github-jupyter-code-to-text."},
	{"name":"conala","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/conala","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"CoNaLa is a dataset of code and natural language pairs crawled from Stack Overflow, for more details please refer to this paper: https://arxiv.org/pdf/1805.08949.pdf or the dataset page https://conala-corpus.github.io/."},
	{"name":"humaneval-x","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/THUDM/humaneval-x","creator_name":"Knowledge Engineering Group (KEG) & Data Mining at Tsinghua University","creator_url":"https://huggingface.co/THUDM","description":"HumanEval-X is a benchmark for the evaluation of the multilingual ability of code generative models. It consists of 820 high-quality human-crafted data samples (each with test cases) in Python, C++, Java, JavaScript, and Go, and can be used for various tasks."},
	{"name":"tldr","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/tldr","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"This is the re-split of CoNaLa dataset. For each code snippet in the dev and test set, at least one function is held out from the training set. This split aims at testing a code generation model's capacity in generating unseen functions.\\nWe further make sure that examples from the same StackOverflow post (same question_id before -) are in the same split."},
	{"name":"conala","keyword":"code-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/conala","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"CoNaLa is a dataset of code and natural language pairs crawled from Stack Overflow, for more details please refer to this paper: https://arxiv.org/pdf/1805.08949.pdf or the dataset page https://conala-corpus.github.io/."},
	{"name":"tldr","keyword":"code-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/tldr","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"This is the re-split of CoNaLa dataset. For each code snippet in the dev and test set, at least one function is held out from the training set. This split aims at testing a code generation model's capacity in generating unseen functions.\\nWe further make sure that examples from the same StackOverflow post (same question_id before -) are in the same split."},
	{"name":"gsm-hard","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/reasoning-machines/gsm-hard","creator_name":"Reasoning Machines","creator_url":"https://huggingface.co/reasoning-machines","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the harder version of gsm8k math reasoning dataset (https://huggingface.co/datasets/gsm8k).\\nWe construct this dataset by replacing the numbers in the questions of GSM8K with larger numbers that are less common.\\n\\u0001\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is used to evaluate math reasoning\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish - Numbers\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\ndataset = load_dataset(\\\"reasoning-machines/gsm-hard\\\")\\nDatasetDict({‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/reasoning-machines/gsm-hard."},
	{"name":"tp3","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gabeorlanski/tp3","creator_name":"Gabe Orlanski","creator_url":"https://huggingface.co/gabeorlanski","description":"Translating Python Programming Puzzles (TP3) is a code translation benchmark created from the verification functions from the questions in the original Python Programming Puzzles dataset (Schuster et al., 2021) to create this dataset. These functions are hand-crafted by the authors and are used to check if an answer satisfies the constraints of the puzzle. These puzzles range in difficulty from basic character checking to competitive programming problems. Thus, each verification function is written by an expert python programmer and requires a significant understanding of programming to translate. In total, there are 370 python functions to translate."},
	{"name":"CodeAlpaca-20k","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k","creator_name":"Sahil Chaudhary","creator_url":"https://huggingface.co/sahil2801","description":"sahil2801/CodeAlpaca-20k dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"translate_code_geeksforgeeks_for_t5","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bhadresh-savani/translate_code_geeksforgeeks_for_t5","creator_name":"Bhadresh Savani","creator_url":"https://huggingface.co/bhadresh-savani","description":"bhadresh-savani/translate_code_geeksforgeeks_for_t5 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"TSSB-3M-instructions","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zirui3/TSSB-3M-instructions","creator_name":"zirui","creator_url":"https://huggingface.co/zirui3","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdata summary\\n\\t\\n\\ninstruction dataset for code bugfix\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReference\\n\\t\\n\\n[1]. TSSB-3M-ext\\n"},
	{"name":"TSSB-3M-instructions","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zirui3/TSSB-3M-instructions","creator_name":"zirui","creator_url":"https://huggingface.co/zirui3","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdata summary\\n\\t\\n\\ninstruction dataset for code bugfix\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReference\\n\\t\\n\\n[1]. TSSB-3M-ext\\n"},
	{"name":"ShareGPT-Chinese-English-90k","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shareAI/ShareGPT-Chinese-English-90k","creator_name":"shareAI","creator_url":"https://huggingface.co/shareAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShareGPT-Chinese-English-90k Bilingual Human-Machine QA Dataset\\n\\t\\n\\nA high-quality Chinese-English parallel bilingual human-machine QA dataset, covering user questions in real and complex scenarios. It is used for training high-quality dialogue models (more robust in instruction distribution than those datasets generated by repeatedly calling API interfaces to simulate machine-generated Q&A, like Moss)\\nFeatures:\\n\\n\\nProvides fully semantically equivalent Chinese-English parallel‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shareAI/ShareGPT-Chinese-English-90k."},
	{"name":"ta-prompt","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigcode/ta-prompt","creator_name":"BigCode","creator_url":"https://huggingface.co/bigcode","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset summary\\n\\t\\n\\nThis repository is dedicated to prompts used to perform in-context learning with starcoder. As a matter of fact, the model is an \\nautoregressive language model that is trained on both code and natural language text. It can be turned into an AI-powered technical assistant by prepending conversations to \\nits 8192-tokens context window.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFormat\\n\\t\\n\\nThe prompt is a .txt file which contains multiple conversations between a human and the assistant. Here is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bigcode/ta-prompt."},
	{"name":"multi-humaneval","keyword":"code-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mxeval/multi-humaneval","creator_name":"mxeval","creator_url":"https://huggingface.co/mxeval","description":"A collection of execution-based multi-lingual benchmark for code generation."},
	{"name":"translate_code_geeksforgeeks_for_t5","keyword":"java","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bhadresh-savani/translate_code_geeksforgeeks_for_t5","creator_name":"Bhadresh Savani","creator_url":"https://huggingface.co/bhadresh-savani","description":"bhadresh-savani/translate_code_geeksforgeeks_for_t5 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"translate_code_geeksforgeeks_for_t5","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bhadresh-savani/translate_code_geeksforgeeks_for_t5","creator_name":"Bhadresh Savani","creator_url":"https://huggingface.co/bhadresh-savani","description":"bhadresh-savani/translate_code_geeksforgeeks_for_t5 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"python_textbooks","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sridevi/python_textbooks","creator_name":"Bonthu","creator_url":"https://huggingface.co/Sridevi","description":"Sridevi/python_textbooks dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"python_textbooks","keyword":"programming","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sridevi/python_textbooks","creator_name":"Bonthu","creator_url":"https://huggingface.co/Sridevi","description":"Sridevi/python_textbooks dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"code-search-net-javascript","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/code-search-net-javascript","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-javascript\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the JavaScript portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset's comments are in English and the functions are coded in JavaScript\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain, test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-javascript."},
	{"name":"reason_code-search-net-python","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"reason_code-search-net-python\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is an instructional dataset for Python.The dataset contains five different kind of tasks.   \\nGiven a Python 3 function:\\n\\nType 1: Generate a summary explaining what it does. (For example: This function counts the number of objects stored in the jsonl file passed as input.)\\nType 2: Generate a summary explaining what its input parameters represent (\\\"For example: infile: a file descriptor of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python."},
	{"name":"reason_code-search-net-python","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"reason_code-search-net-python\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is an instructional dataset for Python.The dataset contains five different kind of tasks.   \\nGiven a Python 3 function:\\n\\nType 1: Generate a summary explaining what it does. (For example: This function counts the number of objects stored in the jsonl file passed as input.)\\nType 2: Generate a summary explaining what its input parameters represent (\\\"For example: infile: a file descriptor of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python."},
	{"name":"multiclass-sentiment-analysis-dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sp1786/multiclass-sentiment-analysis-dataset","creator_name":"Shahriar Parvez","creator_url":"https://huggingface.co/Sp1786","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sp1786/multiclass-sentiment-analysis-dataset."},
	{"name":"deepFashion-with-masks","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SaffalPoosh/deepFashion-with-masks","creator_name":"Talha Yousuf","creator_url":"https://huggingface.co/SaffalPoosh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\nDataset name is deepfashion2 datasest, the dataset is in raw form with annotations, for original dataset repo. see https://github.com/switchablenorms/DeepFashion2 \\nThis dataset is just the extracted version of original deepfashion2 dataset and can be used for training Controlnet Model.\\n"},
	{"name":"evol-codealpaca-v1","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theblackcat102/evol-codealpaca-v1","creator_name":"theblackcat102","creator_url":"https://huggingface.co/theblackcat102","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEvolved codealpaca\\n\\t\\n\\nUpdates:\\n\\n2023/08/26 - Filtered results now only contain pure english instruction and removed any mentioned of trained by OAI response\\n\\nMedian sequence length : 471\\nWe employed a methodology similar to that of WizardCoder, with the exception that ours is open-source. We used the gpt-4-0314 and gpt-4-0613 models to augment and answer each response, with the bulk of generation handled by gpt-4-0314.\\nThe aim of this dataset is twofold: firstly, to facilitate the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/theblackcat102/evol-codealpaca-v1."},
	{"name":"code-search-net-javascript","keyword":"codesearchnet","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/code-search-net-javascript","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-javascript\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the JavaScript portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset's comments are in English and the functions are coded in JavaScript\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain, test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-javascript."},
	{"name":"reason_code-search-net-python","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"reason_code-search-net-python\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is an instructional dataset for Python.The dataset contains five different kind of tasks.   \\nGiven a Python 3 function:\\n\\nType 1: Generate a summary explaining what it does. (For example: This function counts the number of objects stored in the jsonl file passed as input.)\\nType 2: Generate a summary explaining what its input parameters represent (\\\"For example: infile: a file descriptor of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python."},
	{"name":"reason_code-search-net-python","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"reason_code-search-net-python\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is an instructional dataset for Python.The dataset contains five different kind of tasks.   \\nGiven a Python 3 function:\\n\\nType 1: Generate a summary explaining what it does. (For example: This function counts the number of objects stored in the jsonl file passed as input.)\\nType 2: Generate a summary explaining what its input parameters represent (\\\"For example: infile: a file descriptor of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python."},
	{"name":"Text-to-sql-v1","keyword":"sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Clinton/Text-to-sql-v1","creator_name":"Oduor","creator_url":"https://huggingface.co/Clinton","description":"Clinton/Text-to-sql-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cve-llm-training","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/morpheuslord/cve-llm-training","creator_name":"Chiranjeevi G","creator_url":"https://huggingface.co/morpheuslord","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCVE-llm_dataset\\n\\t\\n\\nThis dataset is intended to train an LLM model for an utterly CVE-focused input and output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData extraction:\\n\\t\\n\\nFor the data extraction, I first downloaded the CVE database from NVD lists and then loaded them using the cve_dataset_2.py and cve_dataset.py both have produce different datasets one is for llama and the other is for openai GPT.\\nThe CVE json files are mapped in this format:\\ncves:\\n|\\n‚îú‚îÄ1999\\n|   ‚îú‚îÄ0xxx\\n|   |   ‚îú‚îÄCVE-1999-0001.json\\n|   |‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/morpheuslord/cve-llm-training."},
	{"name":"GitHub-CC0","keyword":"code","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KoalaAI/GitHub-CC0","creator_name":"Koala AI","creator_url":"https://huggingface.co/KoalaAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPublic Domain GitHub Repositories Dataset\\n\\t\\n\\nThis dataset contains metadata and source code of 9,000 public domain (cc0 or unlicense) licensed GitHub repositories that have more than 25 stars. \\nThe dataset was created by scraping the GitHub API and downloading the repositories, so long as they are under 100mb.\\nThe dataset can be used for various natural language processing and software engineering tasks, such as code summarization, code generation, code search, code analysis, etc.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KoalaAI/GitHub-CC0."},
	{"name":"Methods2Test_java_unit_test_code","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jitx/Methods2Test_java_unit_test_code","creator_name":"Jiting Xu","creator_url":"https://huggingface.co/jitx","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMicrosoft created this large dataset of Java Junit test cases with its corresponding focal methods. \\nIt contains 780k pairs of JUnit test cases and focal methods which were extracted from a total of 91K\\nJava open source project hosted on GitHub. \\nThe mapping between test case and focal methods are based heuristics rules and Java developer's best practice.\\nMore information could be found here:\\n\\nmethods2test Github repo\\nMethods2Test: A dataset of focal methods‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jitx/Methods2Test_java_unit_test_code."},
	{"name":"ComPile","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llvm-ml/ComPile","creator_name":"Machine Learning on LLVM","creator_url":"https://huggingface.co/llvm-ml","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ComPile: A Large IR Dataset from Production Sources\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChangelog\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nRelease\\nProgramming Languages\\nDescription\\n\\n\\n\\t\\t\\nv1.0\\nC/C++, Rust, Swift, Julia\\nFine Tuning-scale dataset of 602GB of deduplicated LLVM (bitcode) IR\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nComPile contains over 2.7TB of permissively-licensed source code compiled to (textual) LLVM\\nintermediate representation (IR) covering C/C++, Rust, Swift, and Julia.\\nThe dataset was created by hooking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llvm-ml/ComPile."},
	{"name":"sql-create-context-instruction","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction","creator_name":"Spartak Bughdaryan","creator_url":"https://huggingface.co/bugdaryan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is built upon SQL Create Context, which in turn was constructed using data from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-SQL LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-SQL datasets. The CREATE TABLE statement can often‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction."},
	{"name":"gsm8k-prolog","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Thomas-X-Yang/gsm8k-prolog","creator_name":"Xiaocheng Yang","creator_url":"https://huggingface.co/Thomas-X-Yang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GSM8K-Prolog\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the Prolog annotated version of the GSM8K math reasoning dataset.\\nWe used the same dataset splits and questions in GSM8K and prompted GPT-4 to generate the Prolog programs to solve the questions.\\nWe then manually corrected some malfunctioning samples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be used to train language models to generate Prolog codes in order to solve math questions and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Thomas-X-Yang/gsm8k-prolog."},
	{"name":"StackOverflow-QA-C-Language-40k","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/StackOverflow-QA-C-Language-40k","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"This is a collection of ~40k QA's in C Language from StackOverflow. The data has been initially cleaned, and each response is with Accepted Answer. \\nAll data is <1000 in length.\\nThe questions and answers were organized into a one-line format. A sample format is shown below:\\n{\\n    \\\"question\\\": \\\"```\\\\nFILE* file = fopen(some file)\\\\n\\\\npcap_t* pd = pcap_fopen_offline(file)\\\\n\\\\npcap_close(pd)\\\\n\\\\nfclose(file)\\\\n```\\\\n\\\\nThis code occurs double free error.\\\\n\\\\nCould you explain about this happening?\\\\n\\\\nMy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mxode/StackOverflow-QA-C-Language-40k."},
	{"name":"C-Language-Chat-Debug-Multiturn-Zh","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/C-Language-Chat-Debug-Multiturn-Zh","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"Á∫¶ 1300 Êù° C ËØ≠Ë®Ä Âú∫ÊôØÁöÑ user - assistant Â§öËΩÆÂØπËØù„ÄÇÊØèÊÆµÂØπËØùÂ∑≤ÁªèÁªÑÁªáÊàê‰∫ÜÂçïË°åÁöÑÊ†ºÂºè„ÄÇ‰∏ÄÊù°Ê†∑‰æãÂ¶Ç‰∏ãÔºö\\n{\\n    \\\"id\\\": 1045,\\n    \\\"conversation\\\": [\\n        {\\n            \\\"user\\\": \\\"‰Ω†Â•ΩÔºåAIÂä©Êâã„ÄÇÊàëÊúÄËøëÂú®ÂÜô‰∏Ä‰∏™CËØ≠Ë®ÄÁ®ãÂ∫èÔºå‰ΩÜÊòØÈÅáÂà∞‰∫Ü‰∏Ä‰∫õÈóÆÈ¢òÔºåÂ∏åÊúõ‰Ω†ËÉΩÂ∏ÆÊàëÊ£ÄÊü•‰∏Ä‰∏ã„ÄÇ\\\",\\n            \\\"assistant\\\": \\\"‰Ω†Â•ΩÔºåÊàëÂæà‰πêÊÑèÂ∏ÆÂä©‰Ω†„ÄÇËØ∑Êää‰Ω†ÁöÑ‰ª£Á†ÅÂèëÁªôÊàëÔºåÊàë‰ºöÂ∞ΩÂø´Ê£ÄÊü•Âπ∂ÁªôÂá∫Âª∫ËÆÆ„ÄÇ\\\"\\n        },\\n        {\\n            \\\"user\\\": \\\"Â•ΩÁöÑÔºåËøôÊòØÊàëÁöÑ‰ª£Á†Å„ÄÇËøôÊÆµ‰ª£Á†ÅÁöÑ‰∏ªË¶ÅÂäüËÉΩÊòØËÆ°ÁÆóÊñêÊ≥¢ÈÇ£Â•ëÊï∞ÂàóÁöÑÂâçnÈ°π„ÄÇ\\\",\\n            \\\"assistant\\\": \\\"ËÆ©ÊàëÁúã‰∏Ä‰∏ã......ÂóØÔºåËøôÈáåÊúâ‰∏Ä‰∏™Â∞èÈîôËØØ„ÄÇÂú®Á¨¨10Ë°åÔºå‰Ω†Â∫îËØ•‰ΩøÁî®`++i`ËÄå‰∏çÊòØ`i++`Êù•ÈÄíÂ¢ûiÁöÑÂÄº„ÄÇ‰øÆÊîπÂêéÁöÑ‰ª£Á†ÅÂ∫îËØ•ÊòØËøôÊ†∑ÁöÑ\\\\\\\\n```c\\\\\\\\nfor (int i = 0; i < n; ++i) {\\\\\\\\n    if (i == 0 || i == 1) {\\\\\\\\n‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mxode/C-Language-Chat-Debug-Multiturn-Zh."},
	{"name":"sql-create-context-instruction","keyword":"context-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction","creator_name":"Spartak Bughdaryan","creator_url":"https://huggingface.co/bugdaryan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is built upon SQL Create Context, which in turn was constructed using data from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-SQL LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-SQL datasets. The CREATE TABLE statement can often‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction."},
	{"name":"Methods2Test_java_unit_test_code","keyword":"java","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jitx/Methods2Test_java_unit_test_code","creator_name":"Jiting Xu","creator_url":"https://huggingface.co/jitx","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMicrosoft created this large dataset of Java Junit test cases with its corresponding focal methods. \\nIt contains 780k pairs of JUnit test cases and focal methods which were extracted from a total of 91K\\nJava open source project hosted on GitHub. \\nThe mapping between test case and focal methods are based heuristics rules and Java developer's best practice.\\nMore information could be found here:\\n\\nmethods2test Github repo\\nMethods2Test: A dataset of focal methods‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jitx/Methods2Test_java_unit_test_code."},
	{"name":"sql-create-context-instruction","keyword":"sqlglot","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction","creator_name":"Spartak Bughdaryan","creator_url":"https://huggingface.co/bugdaryan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is built upon SQL Create Context, which in turn was constructed using data from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-SQL LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-SQL datasets. The CREATE TABLE statement can often‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction."},
	{"name":"sql-create-context-instruction","keyword":"wikisql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction","creator_name":"Spartak Bughdaryan","creator_url":"https://huggingface.co/bugdaryan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is built upon SQL Create Context, which in turn was constructed using data from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-SQL LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-SQL datasets. The CREATE TABLE statement can often‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction."},
	{"name":"GitHub-CC0","keyword":"programming","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KoalaAI/GitHub-CC0","creator_name":"Koala AI","creator_url":"https://huggingface.co/KoalaAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPublic Domain GitHub Repositories Dataset\\n\\t\\n\\nThis dataset contains metadata and source code of 9,000 public domain (cc0 or unlicense) licensed GitHub repositories that have more than 25 stars. \\nThe dataset was created by scraping the GitHub API and downloading the repositories, so long as they are under 100mb.\\nThe dataset can be used for various natural language processing and software engineering tasks, such as code summarization, code generation, code search, code analysis, etc.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KoalaAI/GitHub-CC0."},
	{"name":"sql-create-context-instruction","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction","creator_name":"Spartak Bughdaryan","creator_url":"https://huggingface.co/bugdaryan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is built upon SQL Create Context, which in turn was constructed using data from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-SQL LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-SQL datasets. The CREATE TABLE statement can often‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction."},
	{"name":"sql-create-context-instruction","keyword":"sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction","creator_name":"Spartak Bughdaryan","creator_url":"https://huggingface.co/bugdaryan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is built upon SQL Create Context, which in turn was constructed using data from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-SQL LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-SQL datasets. The CREATE TABLE statement can often‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction."},
	{"name":"sql-create-context-instruction","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction","creator_name":"Spartak Bughdaryan","creator_url":"https://huggingface.co/bugdaryan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is built upon SQL Create Context, which in turn was constructed using data from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-SQL LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-SQL datasets. The CREATE TABLE statement can often‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction."},
	{"name":"SlimOrca-Dedup","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Open-Orca/SlimOrca-Dedup","creator_name":"OpenOrca","creator_url":"https://huggingface.co/Open-Orca","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\n\\n\\\"SlimOrca Dedup\\\" is a deduplicated, unfiltered subset of the SlimOrca dataset, excluding RLHF instances, resulting in 363k unique examples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKey Features\\n\\t\\n\\n\\nRemoval of RLHF instances.\\nDeduplication using minhash and Jaccard similarity techniques.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemo Models\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote: These models were trained on the full SlimOrca dataset, not the deduplicated, unfiltered version.\\n* https://huggingface.co/openaccess-ai-collective/jackalope-7b\\n*‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Open-Orca/SlimOrca-Dedup."},
	{"name":"hackaprompt-dataset","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hackaprompt/hackaprompt-dataset","creator_name":"hackaprompt","creator_url":"https://huggingface.co/hackaprompt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for HackAPrompt üíªüîç\\n\\t\\n\\nThis dataset contains submissions from a prompt hacking competition. An in-depth analysis of the dataset has been accepted at the EMNLP 2023 conference. üìäüëæ\\nSubmissions were sourced from two environments: a playground for experimentation and an official submissions platform.\\nThe playground itself can be accessed here üéÆ\\nMore details about the competition itself here üèÜ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details üìã\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description üìÑ\\n\\t\\n\\nWe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hackaprompt/hackaprompt-dataset."},
	{"name":"luau_corpus","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Roblox/luau_corpus","creator_name":"Roblox Corporation","creator_url":"https://huggingface.co/Roblox","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card\\n\\t\\n\\nThe Luau dataset is a collection of code fragments collected from the Roblox Luau Data Sharing program.\\nOnly experiences where creators gave us permission to contribute to the public Luau Dataset were used for producing this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages:\\n\\t\\n\\nLua, Luau\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense:\\n\\t\\n\\nMIT\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ‚ÄúSoftware‚Äù), to deal in the Software‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Roblox/luau_corpus."},
	{"name":"cruxeval","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cruxeval-org/cruxeval","creator_name":"cruxeval","creator_url":"https://huggingface.co/cruxeval-org","description":" CRUXEval: Code Reasoning, Understanding, and Execution Evaluation \\n\\n\\n    üè† Home Page ‚Ä¢\\n    üíª GitHub Repository  ‚Ä¢\\n    üèÜ Leaderboard ‚Ä¢\\n    üîé Sample Explorer\\n\\n\\n\\nCRUXEval (Code Reasoning, Understanding, and eXecution Evaluation) is a benchmark of 800 Python functions and input-output pairs. The benchmark consists of two tasks, CRUXEval-I (input prediction) and CRUXEval-O (output prediction). \\nThe benchmark was constructed as follows: first, we use Code Llama 34B to generate a large set of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cruxeval-org/cruxeval."},
	{"name":"cruxeval","keyword":"code-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cruxeval-org/cruxeval","creator_name":"cruxeval","creator_url":"https://huggingface.co/cruxeval-org","description":" CRUXEval: Code Reasoning, Understanding, and Execution Evaluation \\n\\n\\n    üè† Home Page ‚Ä¢\\n    üíª GitHub Repository  ‚Ä¢\\n    üèÜ Leaderboard ‚Ä¢\\n    üîé Sample Explorer\\n\\n\\n\\nCRUXEval (Code Reasoning, Understanding, and eXecution Evaluation) is a benchmark of 800 Python functions and input-output pairs. The benchmark consists of two tasks, CRUXEval-I (input prediction) and CRUXEval-O (output prediction). \\nThe benchmark was constructed as follows: first, we use Code Llama 34B to generate a large set of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cruxeval-org/cruxeval."},
	{"name":"MMMU","keyword":"computer_science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMMU/MMMU","creator_name":"MMMU","creator_url":"https://huggingface.co/MMMU","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI)\\n\\t\\n\\nüåê Homepage | üèÜ Leaderboard | ü§ó Dataset | ü§ó Paper | üìñ arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüîîNews\\n\\t\\n\\n\\nüõ†Ô∏è[2024-05-30]: Fixed duplicate option issues in Materials dataset items (validation_Materials_25; test_Materials_17, 242) and content error in validation_Materials_25.\\nüõ†Ô∏è[2024-04-30]: Fixed missing \\\"-\\\" or \\\"^\\\" signs in Math dataset items (dev_Math_2, validation_Math_11, 12, 16;‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MMMU/MMMU."},
	{"name":"github-issue-similarity","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WhereIsAI/github-issue-similarity","creator_name":"WhereIsAI","creator_url":"https://huggingface.co/WhereIsAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGIS: Github Issue Similarity Dataset\\n\\t\\n\\nThis dataset was released from the paper: https://arxiv.org/abs/2309.12871\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you use our dataset in your research, welcome to cite us as follows:\\n@article{li2023angle,\\n  title={AnglE-optimized Text Embeddings},\\n  author={Li, Xianming and Li, Jing},\\n  journal={arXiv preprint arXiv:2309.12871},\\n  year={2023}\\n}\\n\\n"},
	{"name":"Mr-GSM8K","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Randolphzeng/Mr-GSM8K","creator_name":"Randolphzeng","creator_url":"https://huggingface.co/Randolphzeng","description":"View the project page:\\nhttps://github.com/dvlab-research/DiagGSM8K\\nsee our paper at https://arxiv.org/abs/2312.17080\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nIn this work, we introduce a novel evaluation paradigm for Large Language Models, \\none that challenges them to engage in meta-reasoning. Our paradigm shifts the focus from result-oriented assessments, \\nwhich often overlook the reasoning process, to a more holistic evaluation that effectively differentiates \\nthe cognitive capabilities among models. For‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Randolphzeng/Mr-GSM8K."},
	{"name":"WebSight","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HuggingFaceM4/WebSight","creator_name":"HuggingFaceM4","creator_url":"https://huggingface.co/HuggingFaceM4","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WebSight\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWebSight is a large synthetic dataset containing HTML/CSS codes representing synthetically generated English websites, each accompanied by a corresponding screenshot.\\nThis dataset serves as a valuable resource for tasks such as generating UI codes from a screenshot.\\nIt comes in two versions:\\n\\nv0.1: Websites are coded with HTML + CSS. They do not include real images.\\nv0.2: Websites are coded with HTML + Tailwind CSS. They do‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceM4/WebSight."},
	{"name":"DebugBench","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rtian/DebugBench","creator_name":"Runchu Tian","creator_url":"https://huggingface.co/Rtian","description":" \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDebugBench is a Large Language Model (LLM) debugging benchmark introduced in the paper DebugBench: Evaluating Debugging Capability of Large Language Models. We collect code snippets from the LeetCode community and implant bugs into source data with GPT-4. The project is also open-sourced as a GitHub repository.\\n\\nIt consists of 4,253 instances.\\nIt covers four major bug categories and 18 minor types.\\nIt includes C++, Java, and Python instances.\\nIt contains three‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rtian/DebugBench."},
	{"name":"T-Eval","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lovesnowbest/T-Eval","creator_name":"Zehui Chen","creator_url":"https://huggingface.co/lovesnowbest","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tT-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t‚ú® Introduction\\n\\t\\n\\nThis is an evaluation harness for the benchmark described in T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step. \\n[Paper]\\n[Project Page]\\n[LeaderBoard]\\n[HuggingFace]\\n\\nLarge language models (LLM) have achieved remarkable performance on various NLP tasks and are augmented by tools for broader applications. Yet, how to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lovesnowbest/T-Eval."},
	{"name":"python-github-code-instruct-filtered-5k","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jtatman/python-github-code-instruct-filtered-5k","creator_name":"James","creator_url":"https://huggingface.co/jtatman","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"python-github-code-instruct-filtered-5k\\\"\\n\\t\\n\\nThis fine dataset tomekkorbak/python-github-code, filtered by scores greater than 0.03. \\nFeedback and additional columns generated through OpenAI and Cohere responses. \\n"},
	{"name":"Latex-VLM","keyword":"computer_science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JosselinSom/Latex-VLM","creator_name":"Josselin Somerville","creator_url":"https://huggingface.co/JosselinSom","description":"JosselinSom/Latex-VLM dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"image2struct-latex-v1","keyword":"computer_science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stanford-crfm/image2struct-latex-v1","creator_name":"Stanford CRFM","creator_url":"https://huggingface.co/stanford-crfm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tImage2Struct - Latex\\n\\t\\n\\nPaper | Website | Datasets (Webpages, Latex, Music sheets) | Leaderboard | HELM repo | Image2Struct repo\\nLicense: Apache License Version 2.0, January 2004\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\nImage2struct is a benchmark for evaluating vision-language models in practical tasks of extracting structured information from images.\\nThis subdataset focuses on LaTeX code. The model is given an image of the expected output with the prompt:\\nPlease provide the LaTex code‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stanford-crfm/image2struct-latex-v1."},
	{"name":"python-github-code-instruct-filtered-5k","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jtatman/python-github-code-instruct-filtered-5k","creator_name":"James","creator_url":"https://huggingface.co/jtatman","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"python-github-code-instruct-filtered-5k\\\"\\n\\t\\n\\nThis fine dataset tomekkorbak/python-github-code, filtered by scores greater than 0.03. \\nFeedback and additional columns generated through OpenAI and Cohere responses. \\n"},
	{"name":"MHaluBench","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/openkg/MHaluBench","creator_name":"OpenKG Consortium","creator_url":"https://huggingface.co/openkg","description":"\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAn Easy-to-Use Multimodal Hallucination Detection Framework for MLLMs\\n \\n\\t\\n\\n\\n  üåªAcknowledgement ‚Ä¢\\n  ü§óBenchmark ‚Ä¢\\n  üçéDemo ‚Ä¢\\n  üåüOverview ‚Ä¢\\n  üêßModelZoo ‚Ä¢\\n  üîßInstallation ‚Ä¢\\n  ‚è©Quickstart ‚Ä¢\\n  ‚è±Ô∏èVersion ‚Ä¢\\n  üö©Citation \\n  \\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüîîNews\\n\\t\\n\\n\\n2024-04-21 We replace all the base models in the demo with our own trained models, significantly reducing the inference time.\\n2024-04-21 We release our open-source hallucination detection model HalDet-LLAVA, which can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openkg/MHaluBench."},
	{"name":"UltraTextbooks","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/UltraTextbooks","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"UltraTextbooks\\\"\\n\\t\\n\\n\\nIn the digital expanse, a Tree of Knowledge grows,\\nIts branches of code and words intertwine in prose.\\nSynthetic leaves shimmer, human insights compose,\\nA binary symphony where wisdom forever flows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRepository\\n\\t\\n\\nThe \\\"UltraTextbooks\\\" dataset is hosted on the Hugging Face platform.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nThe \\\"UltraTextbooks\\\" dataset is a comprehensive collection of high-quality synthetic and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/UltraTextbooks."},
	{"name":"UltraTextbooks","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/UltraTextbooks","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"UltraTextbooks\\\"\\n\\t\\n\\n\\nIn the digital expanse, a Tree of Knowledge grows,\\nIts branches of code and words intertwine in prose.\\nSynthetic leaves shimmer, human insights compose,\\nA binary symphony where wisdom forever flows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRepository\\n\\t\\n\\nThe \\\"UltraTextbooks\\\" dataset is hosted on the Hugging Face platform.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nThe \\\"UltraTextbooks\\\" dataset is a comprehensive collection of high-quality synthetic and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/UltraTextbooks."},
	{"name":"DISL","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ASSERT-KTH/DISL","creator_name":"ASSERT","creator_url":"https://huggingface.co/ASSERT-KTH","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDISL\\n\\t\\n\\nThe DISL dataset features a collection of 514506 unique Solidity files that have been deployed to Ethereum mainnet. It caters to the need for a large and diverse dataset of real-world smart contracts. DISL serves as a resource for developing machine learning systems and for benchmarking software engineering tools designed for smart contracts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContent\\n\\t\\n\\n\\nthe raw subset has full contracts source code and it's not deduplicated, it has 3,298,271 smart contracts\\nthe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ASSERT-KTH/DISL."},
	{"name":"Code-Golang-QA-2k","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k","creator_name":"ExAi","creator_url":"https://huggingface.co/ExAi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode-Golang-QA-2k\\n\\t\\n\\nThis (small) dataset comprises 2,000 question-and-answer entries related to the Go programming language. It is designed to serve as a resource for individuals looking to enhance machine learning models, create chatbots, or simply to provide a comprehensive knowledge base for developers working with Go.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Format\\n\\t\\n\\n[\\n    {\\n        \\\"question\\\": \\\"How do you create a new RESTful API endpoint using Gin?\\\",\\n        \\\"answer\\\": \\\"Creating a new RESTful API‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k."},
	{"name":"Code-Golang-QA-2k-dpo","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k-dpo","creator_name":"ExAi","creator_url":"https://huggingface.co/ExAi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode-Golang-QA-2k\\n\\t\\n\\nThis (small) dataset comprises ~1.8k dpo entries related to the Go programming language. It is designed to serve as a resource for individuals looking to enhance machine learning models, create chatbots, or simply to provide a comprehensive knowledge base for developers working with Go.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Format\\n\\t\\n\\n[\\n  {\\n    \\\"question\\\": \\\"How do you create a new RESTful API endpoint using Gin?\\\",\\n    \\\"chosen_answer\\\": \\\"Creating a new RESTful API endpoint using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k-dpo."},
	{"name":"Code-290k-ShareGPT-Vicuna","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cognitivecomputations/Code-290k-ShareGPT-Vicuna","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","description":"Code-290k-ShareGPT-Vicuna\\nThis dataset is in Vicuna/ShareGPT format. There are around 290000 set of conversations. Each set having 2 conversations. \\nAlong with Python, Java, JavaScript, GO, C++, Rust, Ruby, Sql, MySql, R, Julia, Haskell, etc. code with detailed explanation are provided.\\nThis datset is built upon using my existing Datasets Python-Code-23k-ShareGPT\\nand Code-74k-ShareGPT.\\n"},
	{"name":"codegolf","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VatsaDev/codegolf","creator_name":"Vatsa Pandey","creator_url":"https://huggingface.co/VatsaDev","description":"The entire codegolf stackexchange where questions have a score above 0, 14K code questions with all the answers\\n\\ngood for learning complex code questions, more unique challenges, code optimizations, and code not really mainstream, could help diversity\\n\\n"},
	{"name":"AI-human-text","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/andythetechnerd03/AI-human-text","creator_name":"Dinh Ngoc An","creator_url":"https://huggingface.co/andythetechnerd03","description":"This is a processed dataset of Human vs AI Text roughly 400k rows. This is taken from the Kaggle dataset https://www.kaggle.com/datasets/shanegerami/ai-vs-human-text/data then processed and split into training and test sets.\\n"},
	{"name":"Code-Feedback","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-a-p/Code-Feedback","creator_name":"Multimodal Art Projection","creator_url":"https://huggingface.co/m-a-p","description":" OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement\\n\\n\\n\\n\\n\\n  [üè†Homepage] \\n  |\\n  [üõ†Ô∏èCode] \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nOpenCodeInterpreter is a family of open-source code generation systems designed to bridge the gap between large language models and advanced proprietary systems like the GPT-4 Code Interpreter. It significantly advances code generation capabilities by integrating execution and iterative refinement functionalities.\\nFor further information and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/m-a-p/Code-Feedback."},
	{"name":"CriticBench","keyword":"code-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-agents/CriticBench","creator_name":"LLM-Agents","creator_url":"https://huggingface.co/llm-agents","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nCriticBench is a comprehensive benchmark designed to assess LLMs' abilities to generate, critique/discriminate and correct reasoning across a variety of tasks. CriticBench encompasses five reasoning domains: mathematical, commonsense, symbolic, coding, and algorithmic. It compiles 15 datasets and incorporates responses from three LLM families.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: THU\\nFunded by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llm-agents/CriticBench."},
	{"name":"Code-Golang-QA-2k","keyword":"go","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k","creator_name":"ExAi","creator_url":"https://huggingface.co/ExAi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode-Golang-QA-2k\\n\\t\\n\\nThis (small) dataset comprises 2,000 question-and-answer entries related to the Go programming language. It is designed to serve as a resource for individuals looking to enhance machine learning models, create chatbots, or simply to provide a comprehensive knowledge base for developers working with Go.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Format\\n\\t\\n\\n[\\n    {\\n        \\\"question\\\": \\\"How do you create a new RESTful API endpoint using Gin?\\\",\\n        \\\"answer\\\": \\\"Creating a new RESTful API‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k."},
	{"name":"Code-Golang-QA-2k-dpo","keyword":"go","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k-dpo","creator_name":"ExAi","creator_url":"https://huggingface.co/ExAi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode-Golang-QA-2k\\n\\t\\n\\nThis (small) dataset comprises ~1.8k dpo entries related to the Go programming language. It is designed to serve as a resource for individuals looking to enhance machine learning models, create chatbots, or simply to provide a comprehensive knowledge base for developers working with Go.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Format\\n\\t\\n\\n[\\n  {\\n    \\\"question\\\": \\\"How do you create a new RESTful API endpoint using Gin?\\\",\\n    \\\"chosen_answer\\\": \\\"Creating a new RESTful API endpoint using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k-dpo."},
	{"name":"Code-Golang-QA-2k","keyword":"golang","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k","creator_name":"ExAi","creator_url":"https://huggingface.co/ExAi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode-Golang-QA-2k\\n\\t\\n\\nThis (small) dataset comprises 2,000 question-and-answer entries related to the Go programming language. It is designed to serve as a resource for individuals looking to enhance machine learning models, create chatbots, or simply to provide a comprehensive knowledge base for developers working with Go.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Format\\n\\t\\n\\n[\\n    {\\n        \\\"question\\\": \\\"How do you create a new RESTful API endpoint using Gin?\\\",\\n        \\\"answer\\\": \\\"Creating a new RESTful API‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k."},
	{"name":"Code-Golang-QA-2k-dpo","keyword":"golang","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k-dpo","creator_name":"ExAi","creator_url":"https://huggingface.co/ExAi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode-Golang-QA-2k\\n\\t\\n\\nThis (small) dataset comprises ~1.8k dpo entries related to the Go programming language. It is designed to serve as a resource for individuals looking to enhance machine learning models, create chatbots, or simply to provide a comprehensive knowledge base for developers working with Go.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Format\\n\\t\\n\\n[\\n  {\\n    \\\"question\\\": \\\"How do you create a new RESTful API endpoint using Gin?\\\",\\n    \\\"chosen_answer\\\": \\\"Creating a new RESTful API endpoint using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k-dpo."},
	{"name":"Algorithm_and_Python_Source_Code","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ananyarn/Algorithm_and_Python_Source_Code","creator_name":"Ananya Reetha Noble","creator_url":"https://huggingface.co/ananyarn","description":"Algorithm_and_Python_Source_Code \\nThis dataset provides different algorithms and their corresponding source code in Python.  \\ncredits: Source codes given here are taken from \\\"iamtarun/python_code_instructions_18k_alpaca\\\" dataset in Hugging Face.\\n"},
	{"name":"CodeFeedback-Filtered-Instruction","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-a-p/CodeFeedback-Filtered-Instruction","creator_name":"Multimodal Art Projection","creator_url":"https://huggingface.co/m-a-p","description":" OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement\\n\\n\\n\\n\\n\\n  [üè†Homepage] \\n  |\\n  [üõ†Ô∏èCode] \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenCodeInterpreter\\n\\t\\n\\nOpenCodeInterpreter is a family of open-source code generation systems designed to bridge the gap between large language models and advanced proprietary systems like the GPT-4 Code Interpreter. It significantly advances code generation capabilities by integrating execution and iterative refinement functionalities.\\nFor further information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/m-a-p/CodeFeedback-Filtered-Instruction."},
	{"name":"Code_Vulnerability_Security_DPO","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CyberNative/Code_Vulnerability_Security_DPO","creator_name":"Byte","creator_url":"https://huggingface.co/CyberNative","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCybernative.ai Code Vulnerability and Security Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Cybernative.ai Code Vulnerability and Security Dataset is a dataset of synthetic Data Programming by Demonstration (DPO) pairs, focusing on the intricate relationship between secure and insecure code across a variety of programming languages. This dataset is meticulously crafted to serve as a pivotal resource for researchers, cybersecurity professionals, and AI developers who are keen‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CyberNative/Code_Vulnerability_Security_DPO."},
	{"name":"omniact","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Writer/omniact","creator_name":"Writer","creator_url":"https://huggingface.co/Writer","description":"\\n\\nDataset for OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web\\nSplits:\\n\\n\\t\\n\\t\\t\\nsplit_name\\ncount\\n\\n\\n\\t\\t\\ntrain\\n6788\\n\\n\\ntest\\n2020\\n\\n\\nval\\n991\\n\\n\\n\\t\\n\\nExample datapoint:\\n  \\\"2849\\\": {\\n      \\\"task\\\": \\\"data/tasks/desktop/ibooks/task_1.30.txt\\\",\\n      \\\"image\\\": \\\"data/data/desktop/ibooks/screen_1.png\\\",\\n      \\\"box\\\": \\\"data/metadata/desktop/boxes/ibooks/screen_1.json\\\"\\n  },\\n\\nwhere:\\n\\ntask - contains natural language description (\\\"Task\\\") along with the corresponding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Writer/omniact."},
	{"name":"TableLLM-SFT","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/RUCKBReasoning/TableLLM-SFT","creator_name":"RUCKBReasoning","creator_url":"https://huggingface.co/RUCKBReasoning","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTableLLM-SFT\\n\\t\\n\\n| Paper | Model | Github | Homepage |\\nTableLLM-SFT is a training set containing a number of splits on different benchmarks. This training set is used to fine-tuning TableLLM-7b and TableLLM-13b, which are based on CodeLlama-7b and CodeLlama-13b, respectively.\\n"},
	{"name":"Code_Vulnerability_Security_DPO","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CyberNative/Code_Vulnerability_Security_DPO","creator_name":"Byte","creator_url":"https://huggingface.co/CyberNative","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCybernative.ai Code Vulnerability and Security Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Cybernative.ai Code Vulnerability and Security Dataset is a dataset of synthetic Data Programming by Demonstration (DPO) pairs, focusing on the intricate relationship between secure and insecure code across a variety of programming languages. This dataset is meticulously crafted to serve as a pivotal resource for researchers, cybersecurity professionals, and AI developers who are keen‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CyberNative/Code_Vulnerability_Security_DPO."},
	{"name":"Code_Vulnerability_Security_DPO","keyword":"programming","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CyberNative/Code_Vulnerability_Security_DPO","creator_name":"Byte","creator_url":"https://huggingface.co/CyberNative","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCybernative.ai Code Vulnerability and Security Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Cybernative.ai Code Vulnerability and Security Dataset is a dataset of synthetic Data Programming by Demonstration (DPO) pairs, focusing on the intricate relationship between secure and insecure code across a variety of programming languages. This dataset is meticulously crafted to serve as a pivotal resource for researchers, cybersecurity professionals, and AI developers who are keen‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CyberNative/Code_Vulnerability_Security_DPO."},
	{"name":"tldr-pages","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Edoigtrd/tldr-pages","creator_name":"Edouard Seemann","creator_url":"https://huggingface.co/Edoigtrd","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTLDR.sh pages\\n\\t\\n\\n\\nThe tldr pages are a community effort to simplify the beloved man pages with practical examples. tldr.sh\\n\\nThis dataset contain parsed data from the tldr/pages repository in the English/Linux section.\\nIt provides Bash commands associated to their description.\\n"},
	{"name":"DS-1000","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xlangai/DS-1000","creator_name":"XLang NLP Lab","creator_url":"https://huggingface.co/xlangai","description":" DS-1000 in simplified format \\n\\nüî• Check the leaderboard from Eval-Arena on our project page.\\nSee testing code and more information (also the original fill-in-the-middle/Insertion format) in the DS-1000 repo.\\nReformatting credits: Yuhang Lai, Sida Wang\\n  \\n"},
	{"name":"dungeon-dataset","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DolphinNie/dungeon-dataset","creator_name":"Yuhe Nie","creator_url":"https://huggingface.co/DolphinNie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBrogue Map Dataset\\n\\t\\n\\nTo clone this repo, use:\\ngit clone https://huggingface.co/datasets/DolphinNie/dungeon-dataset\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1. Data Explanation\\n\\t\\n\\nThis is the Map dataset from the open-sourced game Brogue. It contains 49,000 train dataset, 14,000 test dataset and 7,000 validation dataset.\\nEach map is stored in a .csv file. The map is a (32x32) array, which is the map size.\\nEach cell in the array is a int number ranged from 0 to 13, which represented 14 tiles.\\n  \\\"G_NONE\\\": 0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DolphinNie/dungeon-dataset."},
	{"name":"Human-Style-Answers","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/innova-ai/Human-Style-Answers","creator_name":"INNOVA AI","creator_url":"https://huggingface.co/innova-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHuman Style Answers\\n\\t\\n\\n\\n\\nThis Datasets contains question and answers on different topics in Human style. (For Chatbots training)\\nThis Datasets is build using TOP AI like (GPT4, Claude3 , Command R+, etc.)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\n\\nThe Human Style Response Dataset is a rich collection of question-and-answer pairs, meticulously crafted in a human-like style. It serves as a valuable resource for training chatbots and conversational AI models. Let's‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/innova-ai/Human-Style-Answers."},
	{"name":"MathCodeInstruct-Plus","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MathLLMs/MathCodeInstruct-Plus","creator_name":"LLMs for Math Reasoning","creator_url":"https://huggingface.co/MathLLMs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning\\n\\t\\n\\nPaper: https://arxiv.org/pdf/2310.03731.pdf\\nRepo: https://github.com/mathllm/MathCoder\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce MathCoder, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving.\\n\\n\\t\\n\\t\\t\\nBase Model: Llama-2\\nBase Model: Code Llama\\n\\n\\n\\t\\t\\nMathCoder-L-7B\\nMathCoder-CL-7B\\n\\n\\nMathCoder-L-13B\\nMathCoder-CL-34B\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTraining Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathCodeInstruct-Plus."},
	{"name":"RLSTACK","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/H-D-T/RLSTACK","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/RLSTACK."},
	{"name":"DS-1000","keyword":"code-generation","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xlangai/DS-1000","creator_name":"XLang NLP Lab","creator_url":"https://huggingface.co/xlangai","description":" DS-1000 in simplified format \\n\\nüî• Check the leaderboard from Eval-Arena on our project page.\\nSee testing code and more information (also the original fill-in-the-middle/Insertion format) in the DS-1000 repo.\\nReformatting credits: Yuhang Lai, Sida Wang\\n  \\n"},
	{"name":"Plot2Code","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TencentARC/Plot2Code","creator_name":"ARC Lab, Tencent PCG","creator_url":"https://huggingface.co/TencentARC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPlot2Code Benchmark\\n\\t\\n\\nPlot2Code benchmark is now open-sourced at huggingface (ARC Lab) and GitHub. More information can be found in our paper. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy we need Plot2Code?\\n\\t\\n\\n\\nüßê While MLLMs have demonstrated potential in visual contexts, their capabilities in visual coding tasks have not been thoroughly evaluated. Plot2Code offers a platform for comprehensive assessment of these models.\\n\\nü§ó To enable individuals to ascertain the proficiency of AI assistants in generating‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TencentARC/Plot2Code."},
	{"name":"godot_4_docs","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/glaiveai/godot_4_docs","creator_name":"Glaive AI","creator_url":"https://huggingface.co/glaiveai","description":"Dataset generated for Godot 4 docs using Glaive.\\n"},
	{"name":"blockchain-benchmark","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/revflask/blockchain-benchmark","creator_name":"Mayank Panjiyara","creator_url":"https://huggingface.co/revflask","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LLM Blockchain Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Blockchain Benchmark Dataset is a comprehensive collection of data specifically curated for benchmarking Language Models (LMs) in the domain of blockchain technology. This dataset is designed to facilitate research and development in natural language understanding within the blockchain domain.\\nA complete list of tasks: ['general-reasoning', 'code', 'math']\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/revflask/blockchain-benchmark."},
	{"name":"blockchain-benchmark-formatted","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/revflask/blockchain-benchmark-formatted","creator_name":"Mayank Panjiyara","creator_url":"https://huggingface.co/revflask","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LLM Blockchain Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Blockchain Benchmark Dataset is a comprehensive collection of data specifically curated for benchmarking Language Models (LMs) in the domain of blockchain technology. This dataset is designed to facilitate research and development in natural language understanding within the blockchain domain.\\nA complete list of tasks: ['general-reasoning', 'code', 'math']\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/revflask/blockchain-benchmark-formatted."},
	{"name":"unreal-engine-5-code","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AdamCodd/unreal-engine-5-code","creator_name":"AdamCodd","creator_url":"https://huggingface.co/AdamCodd","description":"Processed dataset from AdamCodd/unreal-engine-5-raw focused on the code.\\nIf you want to support me, you can here.\\n"},
	{"name":"RAG-v1","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/glaiveai/RAG-v1","creator_name":"Glaive AI","creator_url":"https://huggingface.co/glaiveai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGlaive-RAG-v1\\n\\t\\n\\nGlaive-RAG-v1 is a dataset with ~50k samples built using the Glaive platform, for finetuning models for RAG use cases. \\nEach row has:\\n\\nList of documents for context\\nQuestion\\nAnswer Mode\\nAnswer\\n\\nThe answer mode is to define if the model should output only grounded responses or if it should combine it's internal information as well.\\nThe answers have Cited documents at the beginning and also <co: 1> tags in the text to mark citations.\\nTo report any problems or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/glaiveai/RAG-v1."},
	{"name":"hpc-instruct","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hpcgroup/hpc-instruct","creator_name":"Parallel Software and Systems Group","creator_url":"https://huggingface.co/hpcgroup","description":"This is an HPC code instruct dataset that was used to train the HPC-Coder-v2 models. There are 122k samples generated synthetically using Gemini Pro, DBRX,Llama-3 and Mixtral.\\nThere are four types of instruct samples in HPC-Instruct detailed below.\\n\\nCode Synthesis: The instruction tasks the LLM to generate code to solve an HPC related problem.\\nParallelization: The instruction tasks the LLM to parallelize an existing sequential code.\\nOptimization: The instruction tasks the LLM to optimize an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hpcgroup/hpc-instruct."},
	{"name":"uzbek_ner","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/risqaliyevds/uzbek_ner","creator_name":"Riskaliev Muradjon","creator_url":"https://huggingface.co/risqaliyevds","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUzbek NER Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout the Dataset\\n\\t\\n\\nThis dataset is created for Named Entity Recognition (NER) in Uzbek texts. The dataset includes named entities from various categories such as persons, places, organizations, dates, and more.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure\\n\\t\\n\\nThe data is provided in JSON format with the following structure:\\n{\\n    \\\"LOC\\\": [\\\"Location names\\\"],\\n    \\\"ORG\\\": [\\\"Organization names\\\"],\\n    \\\"PERSON\\\": [\\\"Person names\\\"],\\n    \\\"DATE\\\": [\\\"Date expressions\\\"]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/risqaliyevds/uzbek_ner."},
	{"name":"TinyAgent-dataset","keyword":"function calling","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/squeeze-ai-lab/TinyAgent-dataset","creator_name":"Squeeze AI Lab","creator_url":"https://huggingface.co/squeeze-ai-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTinyAgent: Function Calling at the Edge\\n\\t\\n\\n\\nGet the desktop app‚Äé ‚Äé \\n  |\\nRead the blog post\\n\\n\\n\\nTinyAgent aims to enable complex reasoning and function calling capabilities in Small Language Models (SLMs) that can be deployed securely and privately at the edge. Traditional Large Language Models (LLMs) like GPT-4 and Gemini-1.5, while powerful, are often too large and resource-intensive for edge deployment, posing challenges in terms of privacy, connectivity, and latency. TinyAgent‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/squeeze-ai-lab/TinyAgent-dataset."},
	{"name":"Nuke-X-Glaive-Python-Dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NuclearAi/Nuke-X-Glaive-Python-Dataset","creator_name":"Nuclear Ai","creator_url":"https://huggingface.co/NuclearAi","description":"We're excited to announce the release of the NuclearAi/Nuke-X-Glaive-Python-Dataset, a comprehensive Collection of over 240,888 unique lines of Python Code sourced from public datasets. This dataset is specifically designed for fine-tuning and training LLMs to achieve exceptional accuracy in Python language understanding and generation.\\n"},
	{"name":"InfinityMATH","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/InfinityMATH","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInfinityMATH\\n\\t\\n\\nWe introduce InfinityMATH, a scalable instruction tuning dataset for programmatic mathematical reasoning. The construction pipeline emphasizes decoupling numbers from mathematical problems to synthesize number-independent programs, enabling efficient and flexible scaling while minimizing dependency on specific numerical values. Fine-tuning experiments with open-source language and code models, such as Llama2 and CodeLlama, demonstrate the practical benefits of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/InfinityMATH."},
	{"name":"linux_cmd_alpaca","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bajrangCoder/linux_cmd_alpaca","creator_name":"Raunak Raj","creator_url":"https://huggingface.co/bajrangCoder","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlinux_cmd_alpaca\\n\\t\\n\\nThis repository contains a dataset in Alpaca format, consisting of natural language instructions, shell commands, and corresponding responses of linux terminal. This dataset is made from some existing datasets with more data and in alpaca format\\n"},
	{"name":"BRIGHT","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xlangai/BRIGHT","creator_name":"XLang NLP Lab","creator_url":"https://huggingface.co/xlangai","description":"\\n\\t\\n\\t\\t\\n\\t\\tBRIGHT benchmark\\n\\t\\n\\nBRIGHT is the first text retrieval benchmark that requires intensive reasoning to retrieve relevant documents. \\nThe queries are collected from diverse domains (StackExchange, LeetCode, and math competitions), all sourced from realistic human data.\\nExperiments show that existing retrieval models perform poorly on BRIGHT, where the highest score is only 22.1 measured by nDCG@10.\\nBRIGHT provides a good testbed for future retrieval research in more realistic and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xlangai/BRIGHT."},
	{"name":"Nuke-X-Glaive-Python-Dataset","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NuclearAi/Nuke-X-Glaive-Python-Dataset","creator_name":"Nuclear Ai","creator_url":"https://huggingface.co/NuclearAi","description":"We're excited to announce the release of the NuclearAi/Nuke-X-Glaive-Python-Dataset, a comprehensive Collection of over 240,888 unique lines of Python Code sourced from public datasets. This dataset is specifically designed for fine-tuning and training LLMs to achieve exceptional accuracy in Python language understanding and generation.\\n"},
	{"name":"LaTeX_OCR","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linxy/LaTeX_OCR","creator_name":"Lin Xueyuan","creator_url":"https://huggingface.co/linxy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLaTeX OCR ÁöÑÊï∞ÊçÆ‰ªìÂ∫ì\\n\\t\\n\\nÊú¨Êï∞ÊçÆ‰ªìÂ∫ìÊòØ‰∏ì‰∏∫ LaTeX_OCR Âèä LaTeX_OCR_PRO Âà∂‰ΩúÁöÑÊï∞ÊçÆÔºåÊù•Ê∫ê‰∫é https://zenodo.org/record/56198#.V2p0KTXT6eA ‰ª•Âèä https://www.isical.ac.in/~crohme/ ‰ª•ÂèäÊàë‰ª¨Ëá™Â∑±ÊûÑÂª∫„ÄÇ\\nÂ¶ÇÊûúËøô‰∏™Êï∞ÊçÆ‰ªìÂ∫ìÊúâÂ∏ÆÂä©Âà∞‰Ω†ÁöÑËØùÔºåËØ∑ÁÇπ‰∫Æ ‚ù§Ô∏èlike ++\\nÂêéÁª≠ËøΩÂä†Êñ∞ÁöÑÊï∞ÊçÆ‰πü‰ºöÊîæÂú®Ëøô‰∏™‰ªìÂ∫ì ~~\\n\\nÂéüÂßãÊï∞ÊçÆ‰ªìÂ∫ìÂú®github LinXueyuanStdio/Data-for-LaTeX_OCR.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÈõÜ\\n\\t\\n\\nÊú¨‰ªìÂ∫ìÊúâ 5 ‰∏™Êï∞ÊçÆÈõÜ\\n\\nsmall ÊòØÂ∞èÊï∞ÊçÆÈõÜÔºåÊ†∑Êú¨Êï∞ 110 Êù°ÔºåÁî®‰∫éÊµãËØï\\nfull ÊòØÂç∞Âà∑‰ΩìÁ∫¶ 100k ÁöÑÂÆåÊï¥Êï∞ÊçÆÈõÜ„ÄÇÂÆûÈôÖ‰∏äÊ†∑Êú¨Êï∞Áï•Â∞è‰∫é 100kÔºåÂõ†‰∏∫Áî® LaTeX ÁöÑÊäΩË±°ËØ≠Ê≥ïÊ†ëÂâîÈô§‰∫ÜÂæàÂ§ö‰∏çËÉΩÊ∏≤ÊüìÁöÑ LaTeX„ÄÇ\\nsynthetic_handwrite ÊòØÊâãÂÜô‰Ωì 100k ÁöÑÂÆåÊï¥Êï∞ÊçÆÈõÜÔºåÂü∫‰∫é full ÁöÑÂÖ¨ÂºèÔºå‰ΩøÁî®ÊâãÂÜôÂ≠ó‰ΩìÂêàÊàêËÄåÊù•ÔºåÂèØ‰ª•ËßÜ‰∏∫‰∫∫Á±ªÂú®Á∫∏‰∏äÁöÑÊâãÂÜô‰Ωì„ÄÇÊ†∑Êú¨Êï∞ÂÆûÈôÖ‰∏äÁï•Â∞è‰∫é 100kÔºåÁêÜÁî±Âêå‰∏ä„ÄÇ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linxy/LaTeX_OCR."},
	{"name":"McEval","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Multilingual-Multimodal-NLP/McEval","creator_name":"Multilingual-Multimodal-NLP","creator_url":"https://huggingface.co/Multilingual-Multimodal-NLP","description":"McEval benchmark data as described in the McEval Paper. Code for the evaluation can be found on Github as McEval.\\n"},
	{"name":"Buzz-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/H-D-T/Buzz-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-V1.2."},
	{"name":"VersiCode","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AstoneNg/VersiCode","creator_name":"Tongtong Wu","creator_url":"https://huggingface.co/AstoneNg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersiCode: Towards Version-controllable Code Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nVersiCode is the first comprehensive dataset designed to assess the ability of large language models to generate verifiable code for specific library versions. VersiCode encompasses 300 libraries across more than 2,000 versions spanning 9 years. We design two dedicated evaluation tasks: version-specific code completion (VSCC) and version-aware code editing (VACE). The resources can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AstoneNg/VersiCode."},
	{"name":"audits-with-reasons","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/msc-smart-contract-auditing/audits-with-reasons","creator_name":"Smart Contract Auditing","creator_url":"https://huggingface.co/msc-smart-contract-auditing","description":"This dataset builds on top of the base dataset by augmenting it using the quantized Llama3 8b instruct model by Unsloth\\nNamely, it:\\n\\nExpands on the level of detail of the description and recommendation.\\nCleans-up the code by fixing formatting and removing out-of-context comments (e.g external URLs which might confuse a model)\\nAdds two new fields: functionality and type (see table for more detail)\\n\\nThe non-vulnerable examples only have values for code, functionality and type='no vulnerability'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/msc-smart-contract-auditing/audits-with-reasons."},
	{"name":"golang-coder","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smcleod/golang-coder","creator_name":"Sam McLeod","creator_url":"https://huggingface.co/smcleod","description":"Q&A style combined, deduplicated dataset including portions of:\\n\\nGolang best practices and coding guides (general Q&A) https://huggingface.co/datasets/smcleod/golang-programming-style-best-practices (MIT)\\nGolang questions (general Q&A) https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k (Apache2)\\nGolang functions (code & description) https://huggingface.co/datasets/google/code_x_glue_ct_code_to_text (c-uda)\\nGolang snippets (code & description)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smcleod/golang-coder."},
	{"name":"CodeUpdateArena","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/leo-liuzy/CodeUpdateArena","creator_name":"Zeyu Leo Liu","creator_url":"https://huggingface.co/leo-liuzy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CodeUpdateArena\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CodeUpdateArena dataset, a benchmark for knowledge editing in the code domain. An instance in our benchmark consists of a synthetic API function update paired with a program synthesis example that uses the updated functionality.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe programming problems are written in Python and contain English natural text in comments and docstrings.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/leo-liuzy/CodeUpdateArena."},
	{"name":"golang-coder","keyword":"coding","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smcleod/golang-coder","creator_name":"Sam McLeod","creator_url":"https://huggingface.co/smcleod","description":"Q&A style combined, deduplicated dataset including portions of:\\n\\nGolang best practices and coding guides (general Q&A) https://huggingface.co/datasets/smcleod/golang-programming-style-best-practices (MIT)\\nGolang questions (general Q&A) https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k (Apache2)\\nGolang functions (code & description) https://huggingface.co/datasets/google/code_x_glue_ct_code_to_text (c-uda)\\nGolang snippets (code & description)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smcleod/golang-coder."},
	{"name":"golang-coder","keyword":"golang","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smcleod/golang-coder","creator_name":"Sam McLeod","creator_url":"https://huggingface.co/smcleod","description":"Q&A style combined, deduplicated dataset including portions of:\\n\\nGolang best practices and coding guides (general Q&A) https://huggingface.co/datasets/smcleod/golang-programming-style-best-practices (MIT)\\nGolang questions (general Q&A) https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k (Apache2)\\nGolang functions (code & description) https://huggingface.co/datasets/google/code_x_glue_ct_code_to_text (c-uda)\\nGolang snippets (code & description)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smcleod/golang-coder."},
	{"name":"golang-coder","keyword":"programming","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smcleod/golang-coder","creator_name":"Sam McLeod","creator_url":"https://huggingface.co/smcleod","description":"Q&A style combined, deduplicated dataset including portions of:\\n\\nGolang best practices and coding guides (general Q&A) https://huggingface.co/datasets/smcleod/golang-programming-style-best-practices (MIT)\\nGolang questions (general Q&A) https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k (Apache2)\\nGolang functions (code & description) https://huggingface.co/datasets/google/code_x_glue_ct_code_to_text (c-uda)\\nGolang snippets (code & description)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smcleod/golang-coder."},
	{"name":"DarkWebSight","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Csplk/DarkWebSight","creator_name":"Ci Splunk","creator_url":"https://huggingface.co/Csplk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DarkWebSight\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nInspired by the HuggingFaceM4/WebSight and its glorius synthetic data generation methods prompts which compared to what I was expecting were amazingly simple! I wanted to test out their method on something similar for synthetic website code data generation ... Tor hidden services ... to reproduce their claim and it seems to be working!\\nDarkWebSight is a WIP that will be a large synthetic dataset containing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Csplk/DarkWebSight."},
	{"name":"svg-stack-labeled","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MrOvkill/svg-stack-labeled","creator_name":"Samuel L Meyers","creator_url":"https://huggingface.co/MrOvkill","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSvg Stack - Labeled\\n\\t\\n\\nThis dataset consists of the central storage for all datasets related to the SVG Stack dataset. I found it to be lovely, detailed, and of decent to extremely good quality upon observing many different icons and logos during the labeling process.\\nThis is the central dataset, and is currently UNDER CONSTRUCTION.  Use with caution, and be aware that the format HAS NOT been frozen. I will make a post announcing when I freeze this dataset, as that will also be the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MrOvkill/svg-stack-labeled."},
	{"name":"LogicStack-LeetCode","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wiserxin/LogicStack-LeetCode","creator_name":"Sheen","creator_url":"https://huggingface.co/wiserxin","description":"extract from LogicStack-LeetCode\\nÂÖ¨‰ºóÂè∑„ÄåÂÆ´Ê∞¥‰∏âÂè∂ÁöÑÂà∑È¢òÊó•ËÆ∞„ÄçÂà∑Á©ø LeetCode Á≥ªÂàóÊñáÁ´†Ê∫êÁ†Å\\nÂåÖÊã¨ ÁºñÁ®ãÈ¢òÁõÆ„ÄÅËß£Êûê„ÄÅtag„ÄÅÈ¢òÁõÆurl\\nÊ†πÊçÆ leetcode ÂéüÂßãÈ¢òÁõÆÁΩëÈ°µÔºå‰øÆÊ≠£‰∫Ü‰∏Ä‰∫õ Êñá‰ª∂Âêç Âíå Êñá‰ª∂ÂÜÖÂÆπ ‰∏≠Ê†áÊ≥®ÁöÑÈöæÂ∫¶‰∏ç‰∏ÄËá¥ÁöÑÊñá‰ª∂Ê†∑Êú¨\\n"},
	{"name":"ru-instruct","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/ru-instruct","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t–ö–∞—Ä—Ç–æ—á–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\\n\\t\\n\\n–°–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤, –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã—Ö –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏. –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –ø–µ—Ä–µ–≤–æ–¥–∞ (—Å–ø–∞—Å–∏–±–æ –º–æ–¥–µ–ª–∏ Den4ikAI/nonsense_gibberish_detector). –î–µ–¥—É–ø–ª–∏—Ü–∏—Ä–æ–≤–∞–Ω SimHash'–æ–º.\\n–û–±—É—á–µ–Ω–Ω–æ–π –Ω–∞ –Ω—ë–º –º–æ–¥–µ–ª–∏ –ø–æ–∫–∞ –Ω–µ –∑–∞–≤—ë–∑, in progress.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t–°–æ—Å—Ç–∞–≤\\n\\t\\n\\n–°–æ–±—Ä–∞–ª –∏–∑ —ç—Ç–∏—Ö –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã—Ö:\\n\\nd0rj/OpenOrca-ru (–æ—Ç Open-Orca/OpenOrca)\\nd0rj/OpenHermes-2.5-ru (–æ—Ç teknium/OpenHermes-2.5)\\nd0rj/dolphin-ru (–æ—Ç ehartford/dolphin)\\nd0rj/alpaca-cleaned-ru (–æ—Ç‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/ru-instruct."},
	{"name":"Web2Code","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI/Web2Code","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nOur Web2Code instruction tuning dataset construction and instruction generation process involves four key components: (1) Creation of new webpage image-code pair data: We generated high-quality HTML webpage-code pairs following the CodeAlpaca prompt  using GPT-3.5 and convert them into instruction-following data. (2) Refinement of existing webpage code generation data: We transform existing datasets including into an instruction-following data format similar to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/Web2Code."},
	{"name":"opencores","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLM-EDA/opencores","creator_name":"LLM-EDA","creator_url":"https://huggingface.co/LLM-EDA","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opencores\\n\\t\\n\\nWe gathered high-quality specification-code pairs from Opencores, a community aimed to developing digital open-source hardware using electronic design automation (EDA). \\nWe then filtered out data instances exceeding 4096 characters in length and those that could not be parsed into Abstract Syntax Trees (AST). \\nThe final dataset comprises approximately 800 data instances.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Features\\n\\t\\n\\n\\ninstruction (string): The nature language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLM-EDA/opencores."},
	{"name":"vgen_cpp","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLM-EDA/vgen_cpp","creator_name":"LLM-EDA","creator_url":"https://huggingface.co/LLM-EDA","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opencores\\n\\t\\n\\nIn the process of continual pre-training, we utilized the publicly available VGen dataset. \\nVGen aggregates Verilog repositories from GitHub, systematically filters out duplicates and excessively large files, and retains only those files containing \\\\texttt{module} and \\\\texttt{endmodule} statements. \\nWe also incorporated the CodeSearchNet dataset \\\\cite{codesearchnet}, which contains approximately 40MB function codes and their documentation.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLM-EDA/vgen_cpp."},
	{"name":"pandora-big5","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jingjietan/pandora-big5","creator_name":"Tan Jing Jie","creator_url":"https://huggingface.co/jingjietan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPersonality Dataset\\n\\t\\n\\nEssays\\nhttps://huggingface.co/datasets/jingjietan/essays-big5\\nMBTI\\nhttps://huggingface.co/datasets/jingjietan/kaggle-mbti\\nPandora\\nhttps://huggingface.co/datasets/jingjietan/pandora-big5\\nPlease contact jingjietan.com for another dataset.\\nCite:\\n@software{jingjietan-apr-dataset,\\n  author = {Jing Jie, Tan},\\n  title = {{Personality Dataset Splitting}},\\n  url = {https://github.com/jingjie00/apr-dataset},\\n  version = {1.0.0},\\n  year = {2024}\\n}\\n"},
	{"name":"4-Security-Tools-Pentesting","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuladeepmantri/4-Security-Tools-Pentesting","creator_name":"kuladeepmantri","creator_url":"https://huggingface.co/kuladeepmantri","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t4 Security Tools for Pentesting\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset is designed to aid in the detection and classification of commands associated with four essential security tools used in pentesting: Nmap, Metasploit, John the Ripper, and the Social Engineering Toolkit (SET). By providing a comprehensive collection of commands for each tool, this dataset aims to enhance the accuracy and effectiveness of models in recognizing and categorizing these commands.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kuladeepmantri/4-Security-Tools-Pentesting."},
	{"name":"MainframeBench","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fsoft-AIC/MainframeBench","creator_name":"FPT Software AI Center","creator_url":"https://huggingface.co/Fsoft-AIC","description":"\\n  \\n\\n\\n\\n  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXMAiNframe: A Large Language Model for Mainframe Modernization\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset - MainframeBench - contains a comprehensive benchmark for assessing mainframe knowledge, including three sub-tasks: multiple-choice questions, question answering, and COBOL code summarization.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances for Question Answering\\n\\t\\n\\n{\\n    \\\"id\\\": 0,\\n    \\\"prompt\\\": \\\"As a supportive AI assistant, you've been presented‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fsoft-AIC/MainframeBench."},
	{"name":"MainframeBench","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fsoft-AIC/MainframeBench","creator_name":"FPT Software AI Center","creator_url":"https://huggingface.co/Fsoft-AIC","description":"\\n  \\n\\n\\n\\n  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXMAiNframe: A Large Language Model for Mainframe Modernization\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset - MainframeBench - contains a comprehensive benchmark for assessing mainframe knowledge, including three sub-tasks: multiple-choice questions, question answering, and COBOL code summarization.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances for Question Answering\\n\\t\\n\\n{\\n    \\\"id\\\": 0,\\n    \\\"prompt\\\": \\\"As a supportive AI assistant, you've been presented‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fsoft-AIC/MainframeBench."},
	{"name":"zig-llama","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cartersusi/zig-llama","creator_name":"Carter Susi","creator_url":"https://huggingface.co/cartersusi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZig LLama\\n\\t\\n\\nThis dataset is used to fine-tune meta-llama/Meta-Llama-3.1-8B-Instruct.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe dataset uses ~1100 of the most popular and recently updated Zig repos on GitHub.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\nThe full list of source repos used.\\nThe folder of source repos used.\\n"},
	{"name":"generate-readme-eval","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/patched-codes/generate-readme-eval","creator_name":"Patched","creator_url":"https://huggingface.co/patched-codes","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGenerate README Eval\\n\\t\\n\\nThe generate-readme-eval is a dataset (train split) and benchmark (test split) to evaluate the effectiveness of LLMs\\nwhen summarizing entire GitHub repos in form of a README.md file. The datset is curated from top 400 real Python repositories\\nfrom GitHub with at least 1000 stars and 100 forks. The script used to generate the dataset can be found here.\\nFor the dataset we restrict ourselves to GH repositories that are less than 100k tokens in size to allow us‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/patched-codes/generate-readme-eval."},
	{"name":"maplestory_captcha","keyword":"code","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lastbattle/maplestory_captcha","creator_name":"lastbattle","creator_url":"https://huggingface.co/lastbattle","description":"A huge collection of English MapleStory's captcha text in jpg that I have collected over the years. ENJOY!! \\nIt us used by pre-Big Bang MapleStory, throughout the game from Lie-Detector (anti-macro item), logins, to NPC conversations. \\nUp till version 190 when they have switched using Runes (Up, Down, Left, Right arrow keys) for most of the time for detection of macros and bots.\\nThese images are not labelled, I'm releasing this for anyone that wants the dataset to be able to train a model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lastbattle/maplestory_captcha."},
	{"name":"muri-it","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it."},
	{"name":"laravel-11-qa","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yannelli/laravel-11-qa","creator_name":"Ryan Y","creator_url":"https://huggingface.co/yannelli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Laravel 11 Documentation Q&A\\n\\t\\n\\nThis dataset contains question-answer pairs derived from the Laravel 11 official documentation, designed for fine-tuning and evaluating language models on Laravel 11 knowledge.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Laravel 11 Documentation Q&A dataset is a collection of question-answer pairs generated from the official Laravel 11 documentation. It is intended to serve as a resource for testing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yannelli/laravel-11-qa."},
	{"name":"MMMU-Thai","keyword":"computer_science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iapp/MMMU-Thai","creator_name":"iApp Technology","creator_url":"https://huggingface.co/iapp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU Thai (MMMU Benchmark Translated to Thai)\\n\\t\\n\\nMMMU Thai is a dataset for evaluating multimodal models on massive multi-discipline tasks requiring college-level knowledge and deliberate reasoning. This dataset is translated from MMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI) into Thai.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nMMMU Thai consists of 11,500 meticulously collected multimodal questions from college exams, quizzes, and textbooks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iapp/MMMU-Thai."},
	{"name":"Synth-APIGen-v0.1","keyword":"function-calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla/Synth-APIGen-v0.1","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\\n  \\n    \\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card for Synth-APIGen-v0.1\\n\\t\\n\\nThis dataset has been created with distilabel.\\nPipeline script: pipeline_apigen_train.py.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nIt has been created with distilabel==1.4.0 version.\\nThis dataset is an implementation of APIGen: Automated Pipeline for Generating Verifiable and Diverse Function-Calling Datasets in distilabel,\\ngenerated from synthetic functions. The process can be summarized as follows:\\n\\nGenerate (or in this case modify)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/argilla/Synth-APIGen-v0.1."},
	{"name":"apigen-synth-trl","keyword":"function-calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla-warehouse/apigen-synth-trl","creator_name":"Argilla Warehouse","creator_url":"https://huggingface.co/argilla-warehouse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card\\n\\t\\n\\nThis dataset is a version of argilla/Synth-APIGen-v0.1 prepared for\\nfine-tuning using trl. To generate it, the following script was run:\\nfrom datasets import load_dataset\\nfrom jinja2 import Template\\n\\nSYSTEM_PROMPT = \\\"\\\"\\nYou are an expert in composing functions. You are given a question and a set of possible functions. \\nBased on the question, you will need to make one or more function/tool calls to achieve the purpose. \\nIf none of the functions can be used, point it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/argilla-warehouse/apigen-synth-trl."},
	{"name":"Software-Architectural-Frameworks","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Software-Architectural-Frameworks","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Software-Architectural-Frameworks\\nI am releasing a small dataset covering topics related to Frameworks under Software-Architecture.\\nI have included following topics:\\nTOGAF\\nZachman Framework\\nIEEE 1471\\nMatrix-based approach to architecture development\\nSignificance of IEEE 1471 (ISO/IEC 42010)\\nBenefits of employing architectural frameworks\\nand Many More!\\nThis dataset can be useful in LLM development. Also those who are working on developing Software development related LLMs then this dataset can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ajibawa-2023/Software-Architectural-Frameworks."},
	{"name":"apigen-function-calling","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla/apigen-function-calling","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card for argilla/apigen-function-calling\\n\\t\\n\\nThis dataset is a merge of argilla/Synth-APIGen-v0.1\\nand Salesforce/xlam-function-calling-60k, making\\nover 100K function calling examples following the APIGen recipe.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrepare for training\\n\\t\\n\\nThis version is not ready to do fine tuning, but you can run a script like prepare_for_sft.py\\nto prepare it, and run the same recipe that can be found in\\nargilla/Llama-3.2-1B-Instruct-APIGen-FC-v0.1#training-procedure.\\nModify the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/argilla/apigen-function-calling."},
	{"name":"apigen-smollm-trl-FC","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla-warehouse/apigen-smollm-trl-FC","creator_name":"Argilla Warehouse","creator_url":"https://huggingface.co/argilla-warehouse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card for argilla-warehouse/apigen-smollm-trl-FC\\n\\t\\n\\nThis dataset is a merge of argilla/Synth-APIGen-v0.1\\nand Salesforce/xlam-function-calling-60k, and was prepared for training using the script\\nprepare_for_sft.py that can be found in the repository files.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReferences\\n\\t\\n\\n@article{liu2024apigen,\\n  title={APIGen: Automated Pipeline for Generating Verifiable and Diverse Function-Calling Datasets},\\n  author={Liu, Zuxin and Hoang, Thai and Zhang, Jianguo and Zhu, Ming‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/argilla-warehouse/apigen-smollm-trl-FC."},
	{"name":"reflection-v1-ru_subset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/reflection-v1-ru_subset","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\td0rj/reflection-v1-ru_subset\\n\\t\\n\\nTranslated glaiveai/reflection-v1 dataset into Russian language using GPT-4o.\\n\\nAlmost all the rows of the dataset have been translated. I have removed those translations that do not match the original by the presence of the tags \\\"thinking\\\", \\\"reflection\\\" and \\\"output\\\". Mapping to the original dataset rows can be taken from the \\\"index\\\" column.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\n\\n\\ndata = datasets.load_dataset(\\\"d0rj/reflection-v1-ru_subset\\\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/reflection-v1-ru_subset."},
	{"name":"websim","keyword":"code","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/websim","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Websim.ai User Projects\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains information about 137,452 user projects from Websim.ai, a service for creating small sites from a description using Large Language Models (LLMs). The data is stored in JSONL format and includes details about each project, such as project metadata, user information, and the generated HTML content.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in English, as it contains project‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/websim."},
	{"name":"Typst-Train","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TechxGenus/Typst-Train","creator_name":"Hao Jiang","creator_url":"https://huggingface.co/TechxGenus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTypst-Train\\n\\t\\n\\n\\n[ü§ñModels] |\\n[üõ†Ô∏èCode] |\\n[üìäData] |\\n\\n\\n\\n\\nDataset used to train Typst-Coder, includes:\\n\\n18.6K Typst texts\\n2.5K Markdown texts containing Typst-related content\\n\\n"},
	{"name":"cData","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/motexture/cData","creator_name":"motexture","creator_url":"https://huggingface.co/motexture","description":"Synthetically created coding dataset using a feedback loop mechanism with various LLMs.\\n"},
	{"name":"DroidCall","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mllmTeam/DroidCall","creator_name":"mllm","creator_url":"https://huggingface.co/mllmTeam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDroidCall: A Dataset for LLM-powered Android Intent Invocation\\n\\t\\n\\npaper|github\\nDroidCall is the first open-sourced, high-quality dataset designed for fine-tuning LLMs for accurate intent invocation on Android devices.\\nThis repo contains data generated by DroidCall. The process of data generation is shown in the figure below\\n\\nDetails can be found in our paper and github repository.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is Android Intent Invocation?\\n\\t\\n\\nAndroid Intent is a key machanism in Android that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mllmTeam/DroidCall."},
	{"name":"cData","keyword":"coding","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/motexture/cData","creator_name":"motexture","creator_url":"https://huggingface.co/motexture","description":"Synthetically created coding dataset using a feedback loop mechanism with various LLMs.\\n"},
	{"name":"apigen-function-calling","keyword":"function-calling","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla/apigen-function-calling","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card for argilla/apigen-function-calling\\n\\t\\n\\nThis dataset is a merge of argilla/Synth-APIGen-v0.1\\nand Salesforce/xlam-function-calling-60k, making\\nover 100K function calling examples following the APIGen recipe.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrepare for training\\n\\t\\n\\nThis version is not ready to do fine tuning, but you can run a script like prepare_for_sft.py\\nto prepare it, and run the same recipe that can be found in\\nargilla/Llama-3.2-1B-Instruct-APIGen-FC-v0.1#training-procedure.\\nModify the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/argilla/apigen-function-calling."},
	{"name":"apigen-smollm-trl-FC","keyword":"function-calling","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla-warehouse/apigen-smollm-trl-FC","creator_name":"Argilla Warehouse","creator_url":"https://huggingface.co/argilla-warehouse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card for argilla-warehouse/apigen-smollm-trl-FC\\n\\t\\n\\nThis dataset is a merge of argilla/Synth-APIGen-v0.1\\nand Salesforce/xlam-function-calling-60k, and was prepared for training using the script\\nprepare_for_sft.py that can be found in the repository files.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReferences\\n\\t\\n\\n@article{liu2024apigen,\\n  title={APIGen: Automated Pipeline for Generating Verifiable and Diverse Function-Calling Datasets},\\n  author={Liu, Zuxin and Hoang, Thai and Zhang, Jianguo and Zhu, Ming‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/argilla-warehouse/apigen-smollm-trl-FC."},
	{"name":"DroidCall","keyword":"function-calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mllmTeam/DroidCall","creator_name":"mllm","creator_url":"https://huggingface.co/mllmTeam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDroidCall: A Dataset for LLM-powered Android Intent Invocation\\n\\t\\n\\npaper|github\\nDroidCall is the first open-sourced, high-quality dataset designed for fine-tuning LLMs for accurate intent invocation on Android devices.\\nThis repo contains data generated by DroidCall. The process of data generation is shown in the figure below\\n\\nDetails can be found in our paper and github repository.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is Android Intent Invocation?\\n\\t\\n\\nAndroid Intent is a key machanism in Android that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mllmTeam/DroidCall."},
	{"name":"cData","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/motexture/cData","creator_name":"motexture","creator_url":"https://huggingface.co/motexture","description":"Synthetically created coding dataset using a feedback loop mechanism with various LLMs.\\n"},
	{"name":"Software-Architecture","keyword":"software","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Software-Architecture","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Software-Architecture\\nI am releasing a Large Dataset covering topics related to Software-Architecture.\\nThis dataset consists of around 450,000 lines of data in jsonl.\\nI have included following topics:\\nArchitectural Frameworks\\nArchitectural Patterns for Reliability\\nArchitectural Patterns for Scalability\\nArchitectural Patterns\\nArchitectural Quality Attributes\\nArchitectural Testing\\nArchitectural Views\\nArchitectural Decision-Making\\nAdvanced Research\\nCloud-Based Architectures\\nComponent-Based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ajibawa-2023/Software-Architecture."},
	{"name":"Dynamic-Topic-RedPajama-Data-1T-100k-SubSample-max-1k-tokens","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AmanPriyanshu/Dynamic-Topic-RedPajama-Data-1T-100k-SubSample-max-1k-tokens","creator_name":"Aman Priyanshu","creator_url":"https://huggingface.co/AmanPriyanshu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDynamic Topic Modeling Dataset: RedPajama-1T SubSample (100k samples, 1k tokens)\\n\\t\\n\\n\\n  üìùCheck out the Blog Post\\n\\n\\nThis dataset represents a curated subset of the RedPajama-1T Sample dataset, specifically processed for dynamic topic modeling applications. It contains 100,000 \\nsamples from the original dataset, with each document limited to the first 1,024 tokens for consistent processing.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\nName:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AmanPriyanshu/Dynamic-Topic-RedPajama-Data-1T-100k-SubSample-max-1k-tokens."},
	{"name":"RAG-v1-ruen","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MexIvanov/RAG-v1-ruen","creator_name":"Mex Ivanov","creator_url":"https://huggingface.co/MexIvanov","description":"A version of the glaiveai/RAG-v1 dataset extended with machine translation to Russian language for multilingual retrieval-augmented generation tasks.\\nReleased under the same license as the original dataset, provided as is with research intent (but not limited), use/read at your own risk.\\n"},
	{"name":"mergekit-configs","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/mergekit-configs","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMergeKit-configs: access all Hub architectures and automate your model merging process\\n\\t\\n\\nThis dataset facilitates the search for compatible architectures for model merging with MergeKit, streamlining the automation of high-performance merge searches. It provides a snapshot of the Hub‚Äôs configuration state, eliminating the need to manually open configuration files.\\nimport polars as pl\\n\\n# Login using e.g. `huggingface-cli login` to access this dataset\\ndf =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/mergekit-configs."},
	{"name":"ru_codefeedback_python_Qwen2.5-Coder-32B-Instruct-GPTQ-Int8_sample","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mizinovmv/ru_codefeedback_python_Qwen2.5-Coder-32B-Instruct-GPTQ-Int8_sample","creator_name":"maksim","creator_url":"https://huggingface.co/mizinovmv","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tru_Code-Feedback\\n\\t\\n\\n–í–æ–ø—Ä–æ—Å—ã python Code-Feedback\\n–†–µ—à–µ–Ω–∏–µ –∏ unit-test —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ python –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è.\\nMade with Qwen2.5-Coder-32B-Instruct-GPTQ-Int8\\n\\n\\t\\n\\t\\t\\nru_eval_status\\ncount\\n\\n\\n\\t\\t\\nOK\\n2554\\n\\n\\nException\\n2337\\n\\n\\nSyntaxError\\n518\\n\\n\\nTimeout\\n79\\n\\n\\n\\t\\n\\n"},
	{"name":"TACO-verified","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/likaixin/TACO-verified","creator_name":"Kaixin Li","creator_url":"https://huggingface.co/likaixin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset contains verified solutions from the TACO dataset's training set. Solutions that fail to pass all the test cases are removed. Problems with no correct solution are also removed.\\nThe solutions were executed on Intel E5-2620 v3 CPUs with the execution timeout set to 10 seconds.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStatistics in the training set\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nDataset\\n# Problems\\n# Solutions\\n\\n\\n\\t\\t\\nTACO\\n25443\\n1468722\\n\\n\\nTACO-verified\\n12898\\n1043251\\n\\n\\nCorrect Ratio\\n50.69 %\\n71.03 %\\n\\n\\n\\t\\n\\n"},
	{"name":"nvlabs-verilogeval","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dakies/nvlabs-verilogeval","creator_name":"Daniel Kiesewalter","creator_url":"https://huggingface.co/dakies","description":"VerilogEval Human dataset from the VerilogEval paper.\\nPaper: https://arxiv.org/abs/2309.07544 \\nRepo: https://github.com/NVlabs/verilog-eval?tab=License-1-ov-file).\\nDisclaimer: I am not the original author and uploaded this here only for convenience. Please refer to the original repo for any information.\\n"},
	{"name":"zeta","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zed-industries/zeta","creator_name":"Zed Industries","creator_url":"https://huggingface.co/zed-industries","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset for Zeta\\n\\t\\n\\nThis is the open dataset used to train Zeta, an edit prediction model that powers Zed's predictive coding feature. Zeta is derived from Qwen2.5-Coder-7B and predicts the developer's next code edit based on their recent programming patterns and cursor position, allowing for intelligent completion with a simple tab press.\\nThis dataset is split into three parts:\\n\\ntrain.jsonl: Contains the training data for supervised fine-tuning.\\ndpo.jsonl: Contains the data for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zed-industries/zeta."},
	{"name":"CodeArena","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CSJianYang/CodeArena","creator_name":"Yang Jian","creator_url":"https://huggingface.co/CSJianYang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTo bridge the gap between the model-generated response and human preference, we present a rigorous human-curated benchmark CodeArena to emulate the complexity and diversity of real-world coding tasks, where 397 high-quality samples spanning 40 categories and 40 languages, carefully curated from user queries.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Example\\n\\t\\n\\nAn example of 'validation' looks as follows:\\n{\\n    \\\"id\\\": \\\"60670a8d9b1e39dd845fb1639d0d8b86\\\",\\n    \\\"messages\\\": \\\"[{'role': 'user'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CSJianYang/CodeArena."},
	{"name":"include-base-44","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/include-base-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-base (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-base-44."},
	{"name":"EUVS-Benchmark","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4ce/EUVS-Benchmark","creator_name":"ai4ce@nyu","creator_url":"https://huggingface.co/ai4ce","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDescription: \\n  This dataset comprises 104 urban scenes, featuring both extrapolated and interpolated camera poses.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nDataset_structure: \\n  For each scene, four main components are:\\n\\nimages: Images of each scene.\\nsparse: COLMAP format camera poses and sparse point clouds produced by SFM.\\ntraining_set.txt: Image names in the training set.\\ntest_set.txt: Image names in the test set.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\nSupported_tasks: \\n  The dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4ce/EUVS-Benchmark."},
	{"name":"include-lite-44","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/include-lite-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-lite (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-lite-44."},
	{"name":"CADBench","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/CADBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìö CADBench\\n\\t\\n\\nCADBench is a comprehensive benchmark to evaluate the ability of LLMs to generate CAD scripts. It contains 500 simulated data samples and 200 data samples collected from online forums.\\nFor more details, please visit our GitHub repository or refer to our arXiv paper.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìñ Citation\\n\\t\\n\\n@misc{du2024blenderllmtraininglargelanguage,\\n      title={BlenderLLM: Training Large Language Models for Computer-Aided Design with Self-improvement}, \\n      author={Yuhao Du‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/CADBench."},
	{"name":"codecontests-textbooks-dp-v1","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bblain/codecontests-textbooks-dp-v1","creator_name":"Evgeniy Beliakin","creator_url":"https://huggingface.co/bblain","description":"This dataset is a synthetic collection designed for algorithmic problem-solving, particularly in the dynamic programming domain. It is inspired by problems from the DeepMind/code_contests dataset, ensuring authenticity and relevance to competitive programming and algorithmic challenges.\\nThe dataset includes detailed problem statements, input-output specifications, constraints, and illustrative test cases. Each example mirrors real-world scenarios, providing not only the problem but also‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bblain/codecontests-textbooks-dp-v1."},
	{"name":"openhands-feedback","keyword":"code-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/all-hands/openhands-feedback","creator_name":"All Hands","creator_url":"https://huggingface.co/all-hands","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenHands Feedback Dataset üôå\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is OpenHands Feedback?\\n\\t\\n\\nThe OpenHands Feedback Dataset is a collection of user interactions and feedback with the OpenHands AI coding assistant. This dataset contains real-world examples of how users interact with AI coding assistants, including both successful and unsuccessful interactions, along with user feedback on the quality and helpfulness of the responses.\\nThe dataset currently contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/all-hands/openhands-feedback."},
	{"name":"AI-Agent-Generating-Tool-Debugging-Prompt-Library","keyword":"python","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Chemically-motivated/AI-Agent-Generating-Tool-Debugging-Prompt-Library","creator_name":"Chemically Motivated Solutions","creator_url":"https://huggingface.co/Chemically-motivated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"AI Agent Generating Tool & Debugging Prompt Library\\\" ü§ñ‚öôÔ∏è\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details üìö\\n\\t\\n\\n\\nDataset Name: AI Agent Generating Tool & Debugging Prompt Library\\n\\nDataset Description:This dataset includes a collection of prompts focused on building and debugging AI-driven tools, including creating self-improving AI agents and debugging prompts for Python projects. The dataset is designed for use in fine-tuning models related to code generation, debugging, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Chemically-motivated/AI-Agent-Generating-Tool-Debugging-Prompt-Library."},
	{"name":"CodeRM-UnitTest","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KAKA22/CodeRM-UnitTest","creator_name":"Zeyao Ma","creator_url":"https://huggingface.co/KAKA22","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCodeRM-UnitTest dataset originates from the paper: Dynamic Scaling of Unit Tests for Code Reward Modeling available on arXiv.\\nYou can visit the homepage to learn more about the paper.\\nIt is a curated collection of high-quality synthetic Python unit tests, derived from two prominent code instruction tuning \\ndatasets: CodeFeedback-Filtered-Instruction and the training \\nset of TACO. This dataset is used for training \\nCodeRM-8B, a small yet powerful unit test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KAKA22/CodeRM-UnitTest."},
	{"name":"CodeMathGen","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lFelix/CodeMathGen","creator_name":"Fan Liu","creator_url":"https://huggingface.co/lFelix","description":"lFelix/CodeMathGen dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CodeElo","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Qwen/CodeElo","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","description":"The evaluation problems in CodeElo benchmark proposed by CodeElo: Benchmarking Competition-level Code Generation of LLMs with Human-comparable Elo Ratings.\\ndescription, input, output, interaction and note are in Markdown format.\\ninput, output, interaction and note may be empty, and interaction is not empty if and only if it is an interactive problem.\\nA dedicated data explorer is available on our main page.\\n@article{codeelo,\\n  title={CodeElo: Benchmarking Competition-level Code Generation of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Qwen/CodeElo."},
	{"name":"OpenCoder-LLM_opc-sft-stage1-DolphinLabeled","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cognitivecomputations/OpenCoder-LLM_opc-sft-stage1-DolphinLabeled","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenCoder-LLM SFT DolphinLabeled\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPart of the DolphinLabeled series of datasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPresented by Eric Hartford and Cognitive Computations\\n\\t\\n\\nThe purpose of this dataset is to enable filtering of OpenCoder-LLM SFT dataset.\\nThe original dataset is OpenCoder-LLM/opc-sft-stage1\\nI have modified the dataset using two scripts.\\n\\ndedupe.py - removes rows with identical instruction\\nlabel.py - adds a \\\"flags\\\" column containing the following boolean values:\\n\\\"refusal\\\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cognitivecomputations/OpenCoder-LLM_opc-sft-stage1-DolphinLabeled."},
	{"name":"Tachibana-QVQ","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Tachibana-QVQ","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Tachibana-QVQ is a dataset containing code-reasoning and code-instruct responses across a wide variety of programming tasks.\\nThis dataset contains:\\n\\n103k prompts from sequelbox/Tachibana, with all responses generated by Qwen/QVQ-72B-Preview.\\nResponses demonstrate QVQ's code-reasoning ability and general code capabilities.\\n\\nResponses have not been filtered or edited at all: some responses will contain infinite thought loops, incomplete answers, inaccurate responses, or other identified or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Tachibana-QVQ."},
	{"name":"SWE-Fixer-Train-110K","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/internlm/SWE-Fixer-Train-110K","creator_name":"InternLM","creator_url":"https://huggingface.co/internlm","description":"\\n\\t\\n\\t\\t\\n\\t\\tSWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution\\n\\t\\n\\n\\nüìÉ Paper  |\\n üöÄ GitHub\\n\\n\\nSWE-Fixer is a simple yet effective solution for addressing real-world GitHub issues by training open-source LLMs. It features a streamlined retrieve-then-edit pipeline with two core components: a code file retriever and a code editor.\\nThis repo holds the data SWE-Fixer-Train-110K we curated for SWE-Fixer training.\\nFor more information, please visit our project page.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/internlm/SWE-Fixer-Train-110K."},
	{"name":"Tachibana-QVQ","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Tachibana-QVQ","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Tachibana-QVQ is a dataset containing code-reasoning and code-instruct responses across a wide variety of programming tasks.\\nThis dataset contains:\\n\\n103k prompts from sequelbox/Tachibana, with all responses generated by Qwen/QVQ-72B-Preview.\\nResponses demonstrate QVQ's code-reasoning ability and general code capabilities.\\n\\nResponses have not been filtered or edited at all: some responses will contain infinite thought loops, incomplete answers, inaccurate responses, or other identified or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Tachibana-QVQ."},
	{"name":"advent_of_code_ecv_dataset","keyword":"code","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Supa-AI/advent_of_code_ecv_dataset","creator_name":"Supahands","creator_url":"https://huggingface.co/Supa-AI","description":"\\n\\t\\n\\t\\t\\n\\t\\tAdvent of Code ECV Dataset\\n\\t\\n\\nMany code generation datasets focus on syntax and structure but lack a strong emphasis on contextual understanding, especially from a storytelling perspective.The Advent of Code ECV (Expanded, Curated, Verified) Dataset addresses this gap by curating and verifying multiple approaches for each challenge from 2024 to provide diverse solutions, comparison of strategies, and better adaptability across different programming paradigms.In addition to training and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Supa-AI/advent_of_code_ecv_dataset."},
	{"name":"bird-critic-1.0-flash-exp","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/birdsql/bird-critic-1.0-flash-exp","creator_name":"The BIRD Team","creator_url":"https://huggingface.co/birdsql","description":"\\n\\t\\n\\t\\t\\n\\t\\tBIRD-CRITIC-1.0-Flash\\n\\t\\n\\nBIRD-Critic is the first SQL debugging benchmark designed to answer a critical question:\\nCan large language models (LLMs) fix user issues in real-world database applications? Each task in BIRD-CRITIC has been verified by human experts on the following dimensions:\\n\\nReproduction of errors on BIRD env to prevent data leakage.\\nCarefully curate test case functions for each task specifically. \\nSoft EX: This metric can evaluate SELECT-ONLY tasks.\\nSoft EX + Parsing:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/birdsql/bird-critic-1.0-flash-exp."},
	{"name":"Math-Question-Answer","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aixr/Math-Question-Answer","creator_name":"Aixr AI","creator_url":"https://huggingface.co/Aixr","description":"Aixr/Math-Question-Answer dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"lots_of_datasets_for_ai_v3","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ReallyFloppyPenguin/lots_of_datasets_for_ai_v3","creator_name":"Gurvaah Singh","creator_url":"https://huggingface.co/ReallyFloppyPenguin","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset is for Training LLMs From Scratch!\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More Information Needed]\\nDemo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ReallyFloppyPenguin/lots_of_datasets_for_ai_v3."},
	{"name":"short_COT_48k","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrankL/short_COT_48k","creator_name":"FrankLiu","creator_url":"https://huggingface.co/FrankL","description":"FrankL/short_COT_48k dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Kotlin_QA","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JetBrains/Kotlin_QA","creator_name":"JetBrains","creator_url":"https://huggingface.co/JetBrains","description":"\\n\\t\\n\\t\\t\\n\\t\\tKotlin QA\\n\\t\\n\\nA collection of 47 open-ended questions and answers focused on idiomatic Kotlin, curated by human experts. Approximately half were sourced from Kotlin advocates, while the others were real questions gathered from the Kotlin Slack community.Utilized in the Kotlin QA Benchmark within the Code Modeling Lab.  \\nLicense: Apache 2.0  \\n"},
	{"name":"reason_at_code","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/XvKuoMing/reason_at_code","creator_name":"Kamil","creator_url":"https://huggingface.co/XvKuoMing","description":"\\n\\t\\n\\t\\t\\n\\t\\tReasoning Dataset for Code\\n\\t\\n\\nThis repository contains a curated reasoning dataset specifically designed for coding-related problems, particularly in Python. \\nThe dataset was created by filtering non-code problems from the original NovaSky-AI/Sky-T1_data_17k dataset. \\nThe goal of this dataset is to facilitate fine-tuning models for reasoning tasks related to code understanding, problem-solving, and logical deduction in programming.\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe dataset emphasizes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/XvKuoMing/reason_at_code."},
	{"name":"numinamath_verifiable_cleaned","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/flatlander1024/numinamath_verifiable_cleaned","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Adapt from https://huggingface.co/datasets/AI-MO/NuminaMath-CoT and filtered problems with verifiable answers.\\nRemoved duplicates and decontaminated from test datasets.\\nTotal number of rows: 678759\\n"},
	{"name":"Coder-Stat","keyword":"go","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Coder-Stat","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tCoder-Stat Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Coder-Stat dataset is a collection of programming-related data, including problem IDs, programming languages, original statuses, and source code snippets. This dataset is designed to assist in the analysis of coding patterns, error types, and performance metrics.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tModalities\\n\\t\\n\\n\\nTabular: The dataset is structured in a tabular format.\\nText: Contains text data, including source code snippets.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFormats‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Coder-Stat."},
	{"name":"Coder-Stat","keyword":"java","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Coder-Stat","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tCoder-Stat Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Coder-Stat dataset is a collection of programming-related data, including problem IDs, programming languages, original statuses, and source code snippets. This dataset is designed to assist in the analysis of coding patterns, error types, and performance metrics.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tModalities\\n\\t\\n\\n\\nTabular: The dataset is structured in a tabular format.\\nText: Contains text data, including source code snippets.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFormats‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Coder-Stat."},
	{"name":"Coder-Stat","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Coder-Stat","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tCoder-Stat Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Coder-Stat dataset is a collection of programming-related data, including problem IDs, programming languages, original statuses, and source code snippets. This dataset is designed to assist in the analysis of coding patterns, error types, and performance metrics.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tModalities\\n\\t\\n\\n\\nTabular: The dataset is structured in a tabular format.\\nText: Contains text data, including source code snippets.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFormats‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Coder-Stat."},
	{"name":"PyCodeZone","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/PyCodeZone","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tPyCodeZone Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe PyCodeZone dataset is a collection of Python code snippets and instructions designed to assist in learning and practicing Python programming. This dataset includes various coding tasks, examples, and solutions, making it a valuable resource for both beginners and experienced programmers.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tModalities\\n\\t\\n\\n\\nText: The dataset primarily contains text data, including Python code snippets and instructions.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/PyCodeZone."},
	{"name":"bird-critic-1.0-flash-exp","keyword":"text-to-sql","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/birdsql/bird-critic-1.0-flash-exp","creator_name":"The BIRD Team","creator_url":"https://huggingface.co/birdsql","description":"\\n\\t\\n\\t\\t\\n\\t\\tBIRD-CRITIC-1.0-Flash\\n\\t\\n\\nBIRD-Critic is the first SQL debugging benchmark designed to answer a critical question:\\nCan large language models (LLMs) fix user issues in real-world database applications? Each task in BIRD-CRITIC has been verified by human experts on the following dimensions:\\n\\nReproduction of errors on BIRD env to prevent data leakage.\\nCarefully curate test case functions for each task specifically. \\nSoft EX: This metric can evaluate SELECT-ONLY tasks.\\nSoft EX + Parsing:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/birdsql/bird-critic-1.0-flash-exp."},
	{"name":"NLP2SQL","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ByteMaster01/NLP2SQL","creator_name":"Laksh Mendpara","creator_url":"https://huggingface.co/ByteMaster01","description":"\\n\\t\\n\\t\\t\\n\\t\\tNLP-to-SQL Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is designed to assist in building and evaluating NLP-to-SQL models. It provides natural language queries, corresponding SQL queries, and the schema for the tables referenced, offering a comprehensive framework for understanding and generating SQL queries from plain language.\\n\\n\\t\\n\\t\\t\\n\\t\\tSchema Example\\n\\t\\n\\nBelow is an example of the schema included in the dataset:\\n\\n\\t\\n\\t\\t\\n\\t\\tTable: employee_1001\\n\\t\\n\\nCREATE TABLE employee_1001 (‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ByteMaster01/NLP2SQL."},
	{"name":"System-Response-100K","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/System-Response-100K","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tSystem-Response-100K dataset\\n\\t\\n\\nThis dataset contains text and code for machine learning tasks including:\\n\\nText Generation\\nText Classification\\nSummarization\\nQuestion Answering\\n\\nThe dataset includes text formatted in JSON and is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\nNumber of entries: Not specified in the information you provided.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tModalities\\n\\t\\n\\n\\nText\\nCode\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFormats\\n\\t\\n\\n\\nJSON\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nEnglish\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tGetting Started\\n\\t\\n\\nThis section can include‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/System-Response-100K."},
	{"name":"LeetCode-Contest","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lbaf23/LeetCode-Contest","creator_name":"lbaf23","creator_url":"https://huggingface.co/lbaf23","description":"\\n\\t\\n\\t\\t\\n\\t\\tLeetCode-Contest\\n\\t\\n\\nContains 80 questions of LeetCode weekly and bi-weekly contests released after March 2024.\\nEach question contains an average of 644 test cases, as well as programming solutions in Python language collected from the official LeetCode website.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Fields\\n\\t\\n\\n\\nindex: The problem numbers in the dataset, from 0 to 79.  \\ntitle: The title of the problem.\\ntitle_slug: The title name connected by \\\"_\\\".   \\nquestion_id: The problem id.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbaf23/LeetCode-Contest."},
	{"name":"AceCode-87K","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/AceCode-87K","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\tüÇ° AceCode-87K\\n\\t\\n\\nPaper | \\nGithub |\\nAceCode-87K |\\nAceCodePair-300K |\\nRM/RL Models\\nWe introduce AceCoder, the first work to propose a fully automated pipeline for synthesizing large-scale reliable tests used for the reward model training and reinforcement learning in the coding scenario. To do this, we curated the dataset AceCode-87K, where we start from a seed code dataset and prompt powerful LLMs to \\\"imagine\\\" proper test cases for the coding question and filter the noisy ones. We‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/AceCode-87K."},
	{"name":"nestful","keyword":"function-calling","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ibm-research/nestful","creator_name":"IBM Research","creator_url":"https://huggingface.co/ibm-research","description":"\\n\\t\\n\\t\\t\\n\\t\\tNESTFUL: Nested Function-Calling Dataset\\n\\t\\n\\n\\n\\n\\n\\n\\nNESTFUL is a benchmark to evaluate LLMs on nested sequences of API calls, i.e., sequences where the output of one API call is passed as input to\\na subsequent call.\\nThe NESTFUL dataset includes over 1800 nested sequences from two main areas: mathematical reasoning and coding tools. The mathematical reasoning portion is generated from \\nthe MathQA dataset, while the coding portion is generated from the\\nStarCoder2-Instruct dataset.\\nAll‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/nestful."},
	{"name":"unreal-engine-5-code-split","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/olympusmonsgames/unreal-engine-5-code-split","creator_name":"Olympus Mons Games","creator_url":"https://huggingface.co/olympusmonsgames","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for unreal-engine-5-code-split\\n\\t\\n\\nUsing the unreal-engine-5-code hf dataset by AdamCodd, I split the data into smaller chunks for RAG systems\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBranches\\nmain: \\n\\nDataset is split/chunked by engine module (no max chunk size)\\n\\nchunked-8k:\\n\\nData is first split by module {module_name}.jsonl if ‚â§ 8000 tokens. \\nIf a module is ‚â• 8000 tokens then it's further split by header name {module_name}_{header_name}.jsonl\\nIf a header‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/olympusmonsgames/unreal-engine-5-code-split."},
	{"name":"SymBench","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yongchao98/SymBench","creator_name":"Yongchao Chen","creator_url":"https://huggingface.co/yongchao98","description":"\\n\\t\\n\\t\\t\\n\\t\\tCodeSteer: Symbolic-Augmented Language Models via Code/Text Guidance\\n\\t\\n\\n\\nSymBench comprises 37 symbolic tasks related to the following papers. The specific description of each task is in page 16-19 of the paper'CodeSteer: Symbolic-Augmented Language Models via Code/Text Guidance'. This dataset comprises the dataset for finetuning CodeSteerLLM with SFT and DPO datasets, the SymBench with 37 tested tasks, the code scripts to synthesize the SymBench samples.\\n\\n\\nCodeSteer:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yongchao98/SymBench."},
	{"name":"Code_Vulnerability_Labeled_Dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lemon42-ai/Code_Vulnerability_Labeled_Dataset","creator_name":"lemon42-ai","creator_url":"https://huggingface.co/lemon42-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Code_Vulnerability_Labeled_Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset provides (code, vulnerability) pairs. The vulnerability field takes values according to the CWE annotation:\\n\\n\\t\\n\\t\\t\\nCWE\\nDescription\\n\\n\\n\\t\\t\\nCWE-020\\nImproper Input Validation\\n\\n\\nCWE-022\\nImproper Limitation of a Pathname to a Restricted Directory (‚ÄúPath Traversal‚Äù)\\n\\n\\nCWE-078\\nImproper Neutralization of Special Elements used in an OS Command (‚ÄúOS Command Injection‚Äù)\\n\\n\\nCWE-079\\nImproper Neutralization of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lemon42-ai/Code_Vulnerability_Labeled_Dataset."},
	{"name":"odoo-sql-query-dataset","keyword":"sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VPCSinfo/odoo-sql-query-dataset","creator_name":"Vinay Rana","creator_url":"https://huggingface.co/VPCSinfo","description":"\\n\\t\\n\\t\\t\\n\\t\\tOdoo SQL Query Dataset\\n\\t\\n\\nThis dataset contains natural language to SQL query pairs specifically for Odoo 17.0 Community Edition. It's designed to help train and fine-tune language models for generating accurate SQL queries for Odoo databases.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe dataset consists of 6815 carefully curated examples of natural language questions paired with their corresponding SQL queries for Odoo databases. Each example includes detailed instructions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VPCSinfo/odoo-sql-query-dataset."},
	{"name":"odoo-sql-query-dataset","keyword":"text-to-sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VPCSinfo/odoo-sql-query-dataset","creator_name":"Vinay Rana","creator_url":"https://huggingface.co/VPCSinfo","description":"\\n\\t\\n\\t\\t\\n\\t\\tOdoo SQL Query Dataset\\n\\t\\n\\nThis dataset contains natural language to SQL query pairs specifically for Odoo 17.0 Community Edition. It's designed to help train and fine-tune language models for generating accurate SQL queries for Odoo databases.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe dataset consists of 6815 carefully curated examples of natural language questions paired with their corresponding SQL queries for Odoo databases. Each example includes detailed instructions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VPCSinfo/odoo-sql-query-dataset."},
	{"name":"code-alpaca-20k","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/flwrlabs/code-alpaca-20k","creator_name":"Flower Labs","creator_url":"https://huggingface.co/flwrlabs","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThis dataset originates from the Code Alpaca repository.\\nThe CodeAlpaca 20K dataset is specifically used for training code generation models.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEach sample is comprised of three columns: instruction, input and output. \\n\\nLanguage(s): English\\nLicense: Apache-2.0 License\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\nThe code from the original repository was adopted to post it here. \\n\\nRepository:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/flwrlabs/code-alpaca-20k."},
	{"name":"Caption-Anything-InContext","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Caption-Anything-InContext","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"Caption-Anything-InContext is a dataset curated using the model Caption-Pro for improved in-context captioning of images. This model is designed for generating multiple captions for images, ensuring they are contextually accurate.\\n\\n\\t\\n\\t\\t\\n\\t\\tRequired Lib\\n\\t\\n\\n!pip install -q transformers qwen-vl-utils==0.0.2\\n\\nDemo with transformers\\nimport os\\nimport gdown\\nimport torch\\nfrom transformers import Qwen2VLForConditionalGeneration, AutoProcessor\\nfrom qwen_vl_utils import process_vision_info\\nfrom PIL import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Caption-Anything-InContext."},
	{"name":"BaxBench","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LogicStar/BaxBench","creator_name":"LogicStar.ai","creator_url":"https://huggingface.co/LogicStar","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBaxBench is a coding benchmark constructed to measure the ability of code generation models and agents to generate correct and secure code. It consists of 392 backend development tasks, which are constructed by combining 28 scenarios that describe the backend functionalities to implement and 14 backend frameworks defining the implementation tools. To assess the correctness and security of the solutions, the benchmark uses end-to-end functional tests and practical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LogicStar/BaxBench."},
	{"name":"minified-diverseful-multilabels","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lemon42-ai/minified-diverseful-multilabels","creator_name":"lemon42-ai","creator_url":"https://huggingface.co/lemon42-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\tA minified, clean and annotated version of DiverseVul\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a minified, clean and deduplicated version of the DiverseVul dataset. \\nWe publish this version to help practionners in their code vulnerability detection research. \\n\\n\\t\\n\\t\\t\\n\\t\\tData Structure & Overview\\n\\t\\n\\n\\nNumber of samples: 23847\\nFeatures: func (the C/C++ code)cwe (the CWE weakness, see table below)\\nSupported Programming Languages: C/C++\\nSupported CWE Weaknesses:\\n\\t\\n\\t\\t\\nLabel\\nDescription‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lemon42-ai/minified-diverseful-multilabels."},
	{"name":"SciCode","keyword":"coding","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SciCode1/SciCode","creator_name":"SciCode","creator_url":"https://huggingface.co/SciCode1","description":"This dataset was presented in SciCode: A Research Coding Benchmark Curated by Scientists.\\n"},
	{"name":"function-calling-reasoning-v1","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zzzch/function-calling-reasoning-v1","creator_name":"Zhangchuanhui","creator_url":"https://huggingface.co/zzzch","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nFunction calling dataset with reasoning, derived from the locally deployed DeepSeek-R1 671B(deepseek-ai/DeepSeek-R1), with the data source being Salesforce/xlam-function-calling-60k.\\n"},
	{"name":"DeepSeek-R1-Distill","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tuanha1305/DeepSeek-R1-Distill","creator_name":"H√† Anh Tu·∫•n","creator_url":"https://huggingface.co/tuanha1305","description":"tuanha1305/DeepSeek-R1-Distill dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"llm-cross-grade","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/av-codes/llm-cross-grade","creator_name":"Ivan Charapanau","creator_url":"https://huggingface.co/av-codes","description":"av-codes/llm-cross-grade dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"yanomami","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/renanserrano/yanomami","creator_name":"Renan Serrano","creator_url":"https://huggingface.co/renanserrano","description":"\\n\\t\\n\\t\\t\\n\\t\\tYanomami Language Dataset\\n\\t\\n\\nThis dataset contains Yanomami language data for training translation models between Yanomami and English. The Yanomami language is spoken by indigenous people in northern Brazil and southern Venezuela.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe dataset consists of the following files:\\n\\n\\t\\n\\t\\t\\nFile\\nDescription\\nExamples\\n\\n\\n\\t\\t\\ntranslations.jsonl\\nGeneral translations between Yanomami and English\\n17,009\\n\\n\\nyanomami-to-english.jsonl\\nSpecific Yanomami to English translations\\n1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/renanserrano/yanomami."},
	{"name":"InductionBench","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wenyueH/InductionBench","creator_name":"Wenyue Hua","creator_url":"https://huggingface.co/wenyueH","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nInductionBench is a new benchmarking suite designed to test the inductive reasoning abilities of large language models.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe benchmark is grounded in formal definitions of inductive function classes (e.g., regular functions/transducers, subregular hierarchies like input-strictly-local functions, Left-output-strictly-local functions, and Right-output-strictly-local functions).\\nThese classes have‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wenyueH/InductionBench."},
	{"name":"Stratos-3k-3.7Sonnet","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidbai/Stratos-3k-3.7Sonnet","creator_name":"David Bai","creator_url":"https://huggingface.co/davidbai","description":"\\n\\t\\n\\t\\t\\n\\t\\tStratos-3K-3.7Sonnet\\n\\t\\n\\nThis is a dataset of 3,155 questions sampled from Bespoke-Stratos-17k,\\nanswered with Claude 3.7 Sonnet on Thinking mode, at temperature 1.0 with maximum thinking tokens at 64,000 (the API limit), and max output length.\\nI would like to acknowledge Bespoke Labs and Berkeley Sky Lab, for their question dataset, as well as Anthropic for providing open-sourced thinking tokens.\\nIf this dataset's publication violates any lab or company policies, please reach out to me‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidbai/Stratos-3k-3.7Sonnet."},
	{"name":"gretel-synthetic-text-to-sql","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/philschmid/gretel-synthetic-text-to-sql","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\t\\n\\t\\t\\n\\t\\tFork of gretelai/synthetic_text_to_sql\\n\\t\\n\\nThe gretelai/synthetic_text_to_sql dataset is a large, Apache 2.0 licensed, synthetic Text-to-SQL dataset consisting of 105,851 high-quality records across 100 diverse domains, designed for training language models. It includes comprehensive SQL tasks with varying complexities, database contexts, natural language explanations, and contextual tags, outperforming existing datasets in SQL correctness and standards compliance.\\n"},
	{"name":"Eastern-Alpaca-14k","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/XeTute/Eastern-Alpaca-14k","creator_name":"XeTute Technologies","creator_url":"https://huggingface.co/XeTute","description":"\\nEastern Alpaca 14k\\n\\nüöÄ Let's enhance ourself with something different\\n\\n\\n\\n\\n  \\n    \\n  \\n  \\n    \\n  \\n  \\n    \\n    \\n  \\n\\n\\n\\n\\n\\nThis dataset is synthetically generated using XeTute/Synthetic-Data-Generation\\n\\nWe publish 14 * 1024 samples synthetically generated through both reasoning and traditional models licensed accordingly.Topics in these samples may include:\\n\\nReligion: Christianity, Islam\\nLiterature: Story-Generation, Summarization, Continuation, et cetera\\nGeneric Questions: STEM and related‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/XeTute/Eastern-Alpaca-14k."},
	{"name":"OpenThoughts-TR-18k","keyword":"coding","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/selimc/OpenThoughts-TR-18k","creator_name":"selim","creator_url":"https://huggingface.co/selimc","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpenThoughts-TR-18k: Turkish Synthetic Reasoning Dataset\\n\\t\\n\\nOpenThoughts-TR-18k is a Turkish translation of a subset of the original Open-Thoughts-114k dataset. It contains ~18k high-quality synthetic reasoning examples covering mathematics, science, coding problems, and puzzles, all translated into Turkish. This dataset is designed to support reasoning task fine tuning for Turkish language models.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n~18k translated reasoning examples\\nCovers multiple domains:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/selimc/OpenThoughts-TR-18k."},
	{"name":"Eastern-Alpaca-14k","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/XeTute/Eastern-Alpaca-14k","creator_name":"XeTute Technologies","creator_url":"https://huggingface.co/XeTute","description":"\\nEastern Alpaca 14k\\n\\nüöÄ Let's enhance ourself with something different\\n\\n\\n\\n\\n  \\n    \\n  \\n  \\n    \\n  \\n  \\n    \\n    \\n  \\n\\n\\n\\n\\n\\nThis dataset is synthetically generated using XeTute/Synthetic-Data-Generation\\n\\nWe publish 14 * 1024 samples synthetically generated through both reasoning and traditional models licensed accordingly.Topics in these samples may include:\\n\\nReligion: Christianity, Islam\\nLiterature: Story-Generation, Summarization, Continuation, et cetera\\nGeneric Questions: STEM and related‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/XeTute/Eastern-Alpaca-14k."},
	{"name":"gretel-synthetic-text-to-sql","keyword":"sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/philschmid/gretel-synthetic-text-to-sql","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\t\\n\\t\\t\\n\\t\\tFork of gretelai/synthetic_text_to_sql\\n\\t\\n\\nThe gretelai/synthetic_text_to_sql dataset is a large, Apache 2.0 licensed, synthetic Text-to-SQL dataset consisting of 105,851 high-quality records across 100 diverse domains, designed for training language models. It includes comprehensive SQL tasks with varying complexities, database contexts, natural language explanations, and contextual tags, outperforming existing datasets in SQL correctness and standards compliance.\\n"},
	{"name":"gretel-synthetic-text-to-sql","keyword":"text-to-sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/philschmid/gretel-synthetic-text-to-sql","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\t\\n\\t\\t\\n\\t\\tFork of gretelai/synthetic_text_to_sql\\n\\t\\n\\nThe gretelai/synthetic_text_to_sql dataset is a large, Apache 2.0 licensed, synthetic Text-to-SQL dataset consisting of 105,851 high-quality records across 100 diverse domains, designed for training language models. It includes comprehensive SQL tasks with varying complexities, database contexts, natural language explanations, and contextual tags, outperforming existing datasets in SQL correctness and standards compliance.\\n"},
	{"name":"kolmogorov-3","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/attn-signs/kolmogorov-3","creator_name":"Attention Signs","creator_url":"https://huggingface.co/attn-signs","description":"\\n\\t\\n\\t\\t\\n\\t\\tKolmogorov-3\\n\\t\\n\\nCarefully selected, checked and formatted PhD-level russian math instruction dataset.Contains olympiad/university/science-level tasks from various sources.\\n\\n\\t\\n\\t\\t\\n\\t\\tContents:\\n\\t\\n\\nMathematics\\n\\nPre-algebra\\nPre-calculus\\nCalculus\\nAlgebra\\nNumber theory\\nGeometry\\nProbability theory\\nSet theory\\nMathematical proofs\\n\\nCode\\n\\nCode-to-math problems\\nAlgorithms\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFormats:\\n\\t\\n\\nDataset is formatted in conversation manner, can be also used for GRPO problem-answer training\\n"},
	{"name":"GoDatas","keyword":"go","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Karesis/GoDatas","creator_name":"Êù®‰∫¶Èîã","creator_url":"https://huggingface.co/Karesis","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Go Game Dataset for Neural Network Training\\n\\t\\n\\nThis is a high-quality dataset designed for Go neural network training, containing board positions extracted from curated SGF game records. The dataset is divided into three strength categories: Standard, Strong, and Elite, with approximately 1,000 samples per category.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains Go board positions and corresponding moves extracted from high-quality SGF‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Karesis/GoDatas."},
	{"name":"shellcode_i_a32","keyword":"code","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SoLID/shellcode_i_a32","creator_name":"SoLID - UNC Charlotte","creator_url":"https://huggingface.co/SoLID","description":"Shellcode_IA32 is a dataset for shellcode generation from English intents. The shellcodes are compilable on Intel Architecture 32-bits."},
	{"name":"ManyTypes4TypeScript","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kevinjesse/ManyTypes4TypeScript","creator_name":"Kevin Jesse","creator_url":"https://huggingface.co/kevinjesse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModels Trained On ManyTypes4TypeScript\\n\\t\\n\\n\\n[CodeBERT](https://huggingface.co/kevinjesse/codebert-MT4TS)\\n[GraphCodeBERT](https://huggingface.co/kevinjesse/graphcodebert-MT4TS)\\n[CodeBERTa](https://huggingface.co/kevinjesse/codeberta-MT4TS)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nManyTypes4TypeScript type inference dataset, available at the DOI link below. \\nGiven a line of source code, the task is to identify types that correspond with the tokens of code. We treat this as a tagging task‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kevinjesse/ManyTypes4TypeScript."},
	{"name":"sentiment-reviews","keyword":"postgresql","license":"PostgreSQL License","license_url":"https://choosealicense.com/licenses/postgresql/","language":"en","dataset_url":"https://huggingface.co/datasets/davidberg/sentiment-reviews","creator_name":"david b","creator_url":"https://huggingface.co/davidberg","description":"davidberg/sentiment-reviews dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"xP3all","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot."},
	{"name":"mbpp","keyword":"code-generation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/mbpp","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"The MBPP (Mostly Basic Python Problems) dataset consists of around 1,000 crowd-sourced Python\\nprogramming problems, designed to be solvable by entry level programmers, covering programming\\nfundamentals, standard library functionality, and so on. Each problem consists of a task\\ndescription, code solution and 3 automated test cases."},
	{"name":"codequeries","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thepurpleowl/codequeries","creator_name":"Surya Prakash Sahu","creator_url":"https://huggingface.co/thepurpleowl","description":"CodeQueries Ideal setup."},
	{"name":"xP3mt","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot."},
	{"name":"humaneval_infilling","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/loubnabnl/humaneval_infilling","creator_name":"Loubna Ben Allal","creator_url":"https://huggingface.co/loubnabnl","description":"An evaluation benchamrk for infilling tasks on HumanEval dataset for code generation."},
	{"name":"standard_humaneval","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/diversoailab/standard_humaneval","creator_name":"Diverso AI Lab","creator_url":"https://huggingface.co/diversoailab","description":"diversoailab/standard_humaneval dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"PyCoder","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Wannita/PyCoder","creator_name":"Takerngsaksiri","creator_url":"https://huggingface.co/Wannita","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPyCoder\\n\\t\\n\\nThis repository contains the dataset for the paper Syntax-Aware On-the-Fly Code Completion\\nThe sample code to run the model can be found in directory: \\\"assets/notebooks/inference.ipynb\\\" in our GitHub: https://github.com/awsm-research/pycoder.\\nPyCoder is an auto code completion model which leverages a Multi-Task Training technique (MTT) to cooperatively\\nlearn the code prediction task and the type prediction task. For the type prediction\\ntask, we propose to leverage the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Wannita/PyCoder."},
	{"name":"humaneval_infilling","keyword":"code-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/loubnabnl/humaneval_infilling","creator_name":"Loubna Ben Allal","creator_url":"https://huggingface.co/loubnabnl","description":"An evaluation benchamrk for infilling tasks on HumanEval dataset for code generation."},
	{"name":"geo","keyword":"code-generation","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dvitel/geo","creator_name":"Dmytro Vitel","creator_url":"https://huggingface.co/dvitel","description":"Dataset contains queries for Problog database of facts about USA geography. Taken from this source \\n"},
	{"name":"codeparrot-train-more-filter-3.3b-cleaned","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kejian/codeparrot-train-more-filter-3.3b-cleaned","creator_name":"Kejian Shi","creator_url":"https://huggingface.co/kejian","description":"kejian/codeparrot-train-more-filter-3.3b-cleaned dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"hearthstone","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dvitel/hearthstone","creator_name":"Dmytro Vitel","creator_url":"https://huggingface.co/dvitel","description":"Datasets for HEARTHSTONE card game. Taken from this source\\n"},
	{"name":"docprompting-conala","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/docprompting-conala","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"This is the re-split of CoNaLa dataset. For each code snippet in the dev and test set, at least one function is held out from the training set. This split aims at testing a code generation model's capacity in generating unseen functions.\\nWe further make sure that examples from the same StackOverflow post (same question_id before -) are in the same split."},
	{"name":"docprompting-conala","keyword":"code-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/docprompting-conala","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"This is the re-split of CoNaLa dataset. For each code snippet in the dev and test set, at least one function is held out from the training set. This split aims at testing a code generation model's capacity in generating unseen functions.\\nWe further make sure that examples from the same StackOverflow post (same question_id before -) are in the same split."},
	{"name":"nameToStdName","keyword":"code","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mble/nameToStdName","creator_name":"Maciej B≈Çƒôdkowski","creator_url":"https://huggingface.co/mble","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tnameToStdName for Minecraft plugins from SpigotMC and Bukkit\\n\\t\\n\\nFrom Spigot/Bukkit plugin titles and description, extract plugin names.\\nMain repository: https://github.com/pluget/services\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense (SPDX)\\n\\t\\n\\nGPL-3.0 for code\\nODbL-1.0 for data/models\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCreators\\n\\t\\n\\nMaciej B≈Çƒôdkowski - Founder, Lead Developer\\n"},
	{"name":"humaneval-rust","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/diversoailab/humaneval-rust","creator_name":"Diverso AI Lab","creator_url":"https://huggingface.co/diversoailab","description":"diversoailab/humaneval-rust dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"energy_induction_motor_simulation","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Thi-Thu-Huong/energy_induction_motor_simulation","creator_name":"Le","creator_url":"https://huggingface.co/Thi-Thu-Huong","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for energy_induction_motor_simulation\\n\\t\\n\\n\\nThis dataset is simulated for four electrical motors using simulation modeling in MATLAB.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nAccurately forecasting electrical signals from three-phase Direct Torque Control (DTC) induction motors is crucial for achieving optimal motor performance and effective condition monitoring. However, the intricate nature of multiple DTC induction motors and the variability in operational conditions present‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Thi-Thu-Huong/energy_induction_motor_simulation."},
	{"name":"MagicPrompt_SD_Washed","keyword":"code","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KonghaYao/MagicPrompt_SD_Washed","creator_name":"KonghaYao","creator_url":"https://huggingface.co/KonghaYao","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMagicPrompt_SD_Washed\\n\\t\\n\\nIt's a version of datasets of Gustavosta/MagicPrompt-Stable-Diffusion.\\nWhen I want to train a model using origin data, some bad prompts broke model and waste many time. \\nSo I washed the origin datasets: \\n\\nüòÑ delete some meanless words like some artists name with misspelling\\nüòÇ delete many spaces that make 100mm to 10 0m\\nüò≠ some url in datasets\\nüò≠ and many unknown words\\n\\nAnd this version is doing well in my train test!üòç\\n"},
	{"name":"torch-forum","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/foldl/torch-forum","creator_name":"Egor Konovalov","creator_url":"https://huggingface.co/foldl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"torch-forum\\\"\\n\\t\\n\\nDataset structure\\n{\\n    title:str\\n    category:str,\\n    posts:List[{\\n                poster:str,\\n                contents:str,\\n                likes:int,\\n                isAccepted:bool\\n               }]\\n}\\n\\n"},
	{"name":"wesnoth-ethea-canon-campaigns","keyword":"code","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kabachuha/wesnoth-ethea-canon-campaigns","creator_name":"Artem","creator_url":"https://huggingface.co/kabachuha","description":"kabachuha/wesnoth-ethea-canon-campaigns dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Dementia_Dataset","keyword":"code","license":"Educational Community License v2.0","license_url":"https://choosealicense.com/licenses/ecl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RiniPL/Dementia_Dataset","creator_name":"Rini P L","creator_url":"https://huggingface.co/RiniPL","description":"RiniPL/Dementia_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"mbxp","keyword":"code-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mxeval/mbxp","creator_name":"mxeval","creator_url":"https://huggingface.co/mxeval","description":"A collection of execution-based multi-lingual benchmark for code generation."},
	{"name":"mxeval","keyword":"code-generation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mxeval/mxeval","creator_name":"mxeval","creator_url":"https://huggingface.co/mxeval","description":"A collection of execution-based multi-lingual benchmark for code generation."},
	{"name":"ubuntu_dialogue_qa","keyword":"linux","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sedthh/ubuntu_dialogue_qa","creator_name":"Richard Nagyfi","creator_url":"https://huggingface.co/sedthh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"ubuntu_dialogue_qa\\\"\\n\\t\\n\\nFiltered the Ubuntu dialogue chatlogs from https://www.kaggle.com/datasets/rtatman/ubuntu-dialogue-corpus to include Q&A pairs ONLY\\nAcknowledgements\\nThis dataset was ORIGINALLY collected by Ryan Lowe, Nissan Pow , Iulian V. Serban‚Ä† and Joelle Pineau. It is made available here under the Apache License, 2.0. If you use this data in your work, please include the following citation:\\nRyan Lowe, Nissan Pow, Iulian V. Serban and Joelle Pineau, \\\"The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sedthh/ubuntu_dialogue_qa."},
	{"name":"ubuntu_dialogue_qa","keyword":"ubuntu","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sedthh/ubuntu_dialogue_qa","creator_name":"Richard Nagyfi","creator_url":"https://huggingface.co/sedthh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"ubuntu_dialogue_qa\\\"\\n\\t\\n\\nFiltered the Ubuntu dialogue chatlogs from https://www.kaggle.com/datasets/rtatman/ubuntu-dialogue-corpus to include Q&A pairs ONLY\\nAcknowledgements\\nThis dataset was ORIGINALLY collected by Ryan Lowe, Nissan Pow , Iulian V. Serban‚Ä† and Joelle Pineau. It is made available here under the Apache License, 2.0. If you use this data in your work, please include the following citation:\\nRyan Lowe, Nissan Pow, Iulian V. Serban and Joelle Pineau, \\\"The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sedthh/ubuntu_dialogue_qa."},
	{"name":"functional_code","keyword":"code","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dhuck/functional_code","creator_name":"davin lawrence","creator_url":"https://huggingface.co/dhuck","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCollection of functional programming languages from GitHub.\\n\\nPoint of Contact: dhuck\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a collection of code examples of functional programming languages for code generation tasks. It was collected over a week long period in March 2023 as part of project in program synthesis.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n{\\n  'id': str\\n  'repository': str‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dhuck/functional_code."},
	{"name":"staqc","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/koutch/staqc","creator_name":"Charles Koutcheme","creator_url":"https://huggingface.co/koutch","description":"StaQC (Stack Overflow Question-Code pairs) is a dataset of around 148K Python and 120K SQL domain question-code pairs, \\nwhich are automatically mined from Stack Overflow using a Bi-View Hierarchical Neural Network, \\nas described in the paper \\\"StaQC: A Systematically Mined Question-Code Dataset from Stack Overflow\\\" (WWW'18)."},
	{"name":"JuICe","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/koutch/JuICe","creator_name":"Charles Koutcheme","creator_url":"https://huggingface.co/koutch","description":"JuICe, a corpus of 1.5 million examples with a curated test set of 3.7K instances based on online programming assignments."},
	{"name":"PyCoder-Type","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Wannita/PyCoder-Type","creator_name":"Takerngsaksiri","creator_url":"https://huggingface.co/Wannita","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPyCoder\\n\\t\\n\\nThis repository contains the dataset for the paper Syntax-Aware On-the-Fly Code Completion\\nThe sample code to run the model can be found in directory: \\\"assets/notebooks/inference.ipynb\\\" in our GitHub: https://github.com/awsm-research/pycoder.\\nPyCoder is an auto code completion model which leverages a Multi-Task Training technique (MTT) to cooperatively\\nlearn the code prediction task and the type prediction task. For the type prediction\\ntask, we propose to leverage the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Wannita/PyCoder-Type."},
	{"name":"cve-single-line-fixes","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lambdasec/cve-single-line-fixes","creator_name":"Lambda Security","creator_url":"https://huggingface.co/lambdasec","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lambdasec/cve-single-line-fixes."},
	{"name":"cve-single-line-fixes","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lambdasec/cve-single-line-fixes","creator_name":"Lambda Security","creator_url":"https://huggingface.co/lambdasec","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lambdasec/cve-single-line-fixes."},
	{"name":"gh-top-1000-projects-vulns","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lambdasec/gh-top-1000-projects-vulns","creator_name":"Lambda Security","creator_url":"https://huggingface.co/lambdasec","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lambdasec/gh-top-1000-projects-vulns."},
	{"name":"gh-top-1000-projects-vulns","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lambdasec/gh-top-1000-projects-vulns","creator_name":"Lambda Security","creator_url":"https://huggingface.co/lambdasec","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lambdasec/gh-top-1000-projects-vulns."},
	{"name":"applescript-lines-100k-non-annotated","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HelloImSteven/applescript-lines-100k-non-annotated","creator_name":"Stephen Kaplan","creator_url":"https://huggingface.co/HelloImSteven","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"applescript-lines-100k-non-annotated\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset of 100,000 unique lines of AppleScript code scraped from GitHub and GitHub Gists. The dataset has been de-duplicated, comments have been removed (both single and multi-line), and effort has been made to merge multi-line structures such as records into one (however, expect some variability in this regard).\\nThe dataset is constructed as an intermediate step to a fully-annotated AppleScript‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HelloImSteven/applescript-lines-100k-non-annotated."},
	{"name":"h2ogpt-oig-instruct-cleaned","keyword":"open-source","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/h2oai/h2ogpt-oig-instruct-cleaned","creator_name":"H2O.ai","creator_url":"https://huggingface.co/h2oai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\th2oGPT Data Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nH2O.ai's h2ogpt-oig-instruct-cleaned is an open-source instruct-type dataset for fine-tuning of large language models, licensed for commercial use.\\n\\nNumber of rows: 195436\\nNumber of columns: 1\\nColumn names: ['input']\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\n\\nOriginal LAION OIG Dataset\\nLAION OIG data detoxed and filtered down by scripts in h2oGPT repository\\n\\n"},
	{"name":"h2ogpt-oig-instruct-cleaned-v2","keyword":"open-source","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/h2oai/h2ogpt-oig-instruct-cleaned-v2","creator_name":"H2O.ai","creator_url":"https://huggingface.co/h2oai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\th2oGPT Data Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nH2O.ai's h2ogpt-oig-instruct-cleaned-v2 is an open-source instruct-type dataset for fine-tuning of large language models, licensed for commercial use.\\n\\nNumber of rows: 426845\\nNumber of columns: 2\\nColumn names: ['input', 'source']\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\n\\nOriginal LAION OIG Dataset\\nLAION OIG data detoxed and filtered down by scripts in h2oGPT repository\\n\\n"},
	{"name":"h2ogpt-oig-instruct-cleaned-v3","keyword":"open-source","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/h2oai/h2ogpt-oig-instruct-cleaned-v3","creator_name":"H2O.ai","creator_url":"https://huggingface.co/h2oai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\th2oGPT Data Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nH2O.ai's h2ogpt-oig-instruct-cleaned-v3 is an open-source instruct-type dataset for fine-tuning of large language models, licensed for commercial use.\\n\\nNumber of rows: 302276\\nNumber of columns: 2\\nColumn names: ['input', 'source']\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\n\\nOriginal LAION OIG Dataset\\nLAION OIG data detoxed and filtered down by scripts in h2oGPT repository\\n\\n"},
	{"name":"openassistant_oasst1","keyword":"open-source","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/h2oai/openassistant_oasst1","creator_name":"H2O.ai","creator_url":"https://huggingface.co/h2oai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\th2oGPT Data Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nH2O.ai's openassistant_oasst1 is an open-source instruct-type dataset for fine-tuning of large language models, licensed for commercial use.\\n\\nNumber of rows: 46283\\nNumber of columns: 3\\nColumn names: ['input', 'prompt_type', 'source']\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\n\\nOriginal Open Assistant data in tree structure\\nThis flattened dataset created by script in h2oGPT repository\\n\\n"},
	{"name":"h2ogpt-oig-oasst1-instruct-cleaned-v1","keyword":"open-source","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v1","creator_name":"H2O.ai","creator_url":"https://huggingface.co/h2oai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\th2oGPT Data Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nH2O.ai's h2ogpt-oig-oasst1-instruct-cleaned-v1 is an open-source instruct-type dataset for fine-tuning of large language models, licensed for commercial use.\\n\\nNumber of rows: 349837\\nNumber of columns: 3\\nColumn names: ['input', 'source', 'prompt_type']\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\n\\nOriginal LAION OIG Dataset\\n\\nLAION OIG data detoxed and filtered down by scripts in h2oGPT repository\\n\\nOriginal Open Assistant data in tree structure\\n\\nThis flattened‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v1."},
	{"name":"cv_backbones","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/monetjoe/cv_backbones","creator_name":"Monet","creator_url":"https://huggingface.co/monetjoe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"monetjoe/cv_backbones\\\"\\n\\t\\n\\nThis repository consolidates the collection of backbone networks for pre-trained computer vision models available on the PyTorch official website. It mainly includes various Convolutional Neural Networks (CNNs) and Vision Transformer models pre-trained on the ImageNet1K dataset. The entire collection is divided into two subsets, V1 and V2, encompassing multiple classic and advanced versions of visual models. These pre-trained backbone‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/monetjoe/cv_backbones."},
	{"name":"OFF_HATE_TOXIC_ENGLISH","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/christinacdl/OFF_HATE_TOXIC_ENGLISH","creator_name":"Christina Christodoulou","creator_url":"https://huggingface.co/christinacdl","description":"100.772 texts with their corresponding labels\\nNOT_OFF_HATEFUL_TOXIC    81.359 values\\nOFF_HATEFUL_TOXIC        19.413 values\\n"},
	{"name":"applescript-lines-annotated","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HelloImSteven/applescript-lines-annotated","creator_name":"Stephen Kaplan","creator_url":"https://huggingface.co/HelloImSteven","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"applescript-lines-annotated\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis is a dataset of single lines of AppleScript code scraped from GitHub and GitHub Gist and manually annotated with descriptions, intents, prompts, and other metadata.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContent\\n\\t\\n\\nEach row contains 8 features:\\n\\ntext - The raw text of the AppleScript code.\\nsource - The name of the file from which the line originates.\\ntype - Either compiled (files using the .scpt extension) or uncompiled‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HelloImSteven/applescript-lines-annotated."},
	{"name":"sql-create-context-copy","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/philschmid/sql-create-context-copy","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFork of b-mc2/sql-create-context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/philschmid/sql-create-context-copy."},
	{"name":"binary_hate_speech","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/christinacdl/binary_hate_speech","creator_name":"Christina Christodoulou","creator_url":"https://huggingface.co/christinacdl","description":"christinacdl/binary_hate_speech dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sql-create-context-copy","keyword":"context-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/philschmid/sql-create-context-copy","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFork of b-mc2/sql-create-context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/philschmid/sql-create-context-copy."},
	{"name":"openassistant_oasst1_h2ogpt","keyword":"open-source","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/h2oai/openassistant_oasst1_h2ogpt","creator_name":"H2O.ai","creator_url":"https://huggingface.co/h2oai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\th2oGPT Data Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nH2O.ai's openassistant_oasst1_h2ogpt is an open-source instruct-type dataset for fine-tuning of large language models, licensed for commercial use.\\n\\nNumber of rows: 48307\\nNumber of columns: 3\\nColumn names: ['input', 'prompt_type', 'source']\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\n\\nOriginal Open Assistant data in tree structure\\nThis flattened dataset created by script in h2oGPT repository\\n\\n"},
	{"name":"h2ogpt-oig-oasst1-instruct-cleaned-v2","keyword":"open-source","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v2","creator_name":"H2O.ai","creator_url":"https://huggingface.co/h2oai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\th2oGPT Data Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nH2O.ai's h2ogpt-oig-oasst1-instruct-cleaned-v2 is an open-source instruct-type dataset for fine-tuning of large language models, licensed for commercial use.\\n\\nNumber of rows: 350581\\nNumber of columns: 3\\nColumn names: ['input', 'source', 'prompt_type']\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\n\\nOriginal LAION OIG Dataset\\n\\nLAION OIG data detoxed and filtered down by scripts in h2oGPT repository\\n\\nOriginal Open Assistant data in tree structure\\n\\nThis flattened‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v2."},
	{"name":"peewee-issues","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/akumoth/peewee-issues","creator_name":"Rainer Palm","creator_url":"https://huggingface.co/akumoth","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Peewee Issues\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPeewee Issues is a dataset containing all the issues in the Peewee github repository up to the last date of extraction (5/3/2023). It has been made for educational purposes in mind (especifically, to get me used to using Hugging Face's datasets), but can be used for multi-label classification or semantic search. The contents are all in English and concern SQL databases and ORM libraries.\\n"},
	{"name":"sql-create-context-copy","keyword":"sqlglot","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/philschmid/sql-create-context-copy","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFork of b-mc2/sql-create-context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/philschmid/sql-create-context-copy."},
	{"name":"sql-create-context-copy","keyword":"wikisql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/philschmid/sql-create-context-copy","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFork of b-mc2/sql-create-context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/philschmid/sql-create-context-copy."},
	{"name":"sql-create-context-copy","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/philschmid/sql-create-context-copy","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFork of b-mc2/sql-create-context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/philschmid/sql-create-context-copy."},
	{"name":"sql-create-context-copy","keyword":"sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/philschmid/sql-create-context-copy","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFork of b-mc2/sql-create-context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/philschmid/sql-create-context-copy."},
	{"name":"sql-create-context-copy","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/philschmid/sql-create-context-copy","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFork of b-mc2/sql-create-context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/philschmid/sql-create-context-copy."},
	{"name":"dolly-code-migration","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/robert-altmiller/dolly-code-migration","creator_name":"Robert Altmiller","creator_url":"https://huggingface.co/robert-altmiller","description":"robert-altmiller/dolly-code-migration dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"code-search-net-java","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/code-search-net-java","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-java\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Java portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset's comments are in English and the functions are coded in Java\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain, test, validation labels are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-java."},
	{"name":"code-search-net-go","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/code-search-net-go","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-go\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Go portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset's comments are in English and the functions are coded in Go\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain, test, validation labels are included in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-go."},
	{"name":"code-search-net-python","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/code-search-net-python","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-python\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nHomepage: None\\nRepository: https://huggingface.co/datasets/Nan-Do/code-search-net-python\\nPaper: None\\nLeaderboard: None\\nPoint of Contact: @Nan-Do\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Python portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-python."},
	{"name":"code-search-net-php","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/code-search-net-php","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-php\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Php portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset's comments are in English and the functions are coded in Php\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain, test, validation labels are included‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-php."},
	{"name":"code-search-net-ruby","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/code-search-net-ruby","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-ruby\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Ruby portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset's comments are in English and the functions are coded in Ruby\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain, test, validation labels are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-ruby."},
	{"name":"gpt-expressions","keyword":"code","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Haziqsayyed/gpt-expressions","creator_name":"Haazique Sayyed","creator_url":"https://huggingface.co/Haziqsayyed","description":"Haziqsayyed/gpt-expressions dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"code-search-net-java","keyword":"codesearchnet","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/code-search-net-java","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-java\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Java portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset's comments are in English and the functions are coded in Java\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain, test, validation labels are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-java."},
	{"name":"code-search-net-go","keyword":"codesearchnet","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/code-search-net-go","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-go\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Go portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset's comments are in English and the functions are coded in Go\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain, test, validation labels are included in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-go."},
	{"name":"code-search-net-python","keyword":"codesearchnet","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/code-search-net-python","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-python\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nHomepage: None\\nRepository: https://huggingface.co/datasets/Nan-Do/code-search-net-python\\nPaper: None\\nLeaderboard: None\\nPoint of Contact: @Nan-Do\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Python portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-python."},
	{"name":"code-search-net-php","keyword":"codesearchnet","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/code-search-net-php","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-php\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Php portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset's comments are in English and the functions are coded in Php\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain, test, validation labels are included‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-php."},
	{"name":"code-search-net-ruby","keyword":"codesearchnet","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/code-search-net-ruby","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-ruby\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Ruby portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset's comments are in English and the functions are coded in Ruby\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain, test, validation labels are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-ruby."},
	{"name":"code-search-net-go","keyword":"go","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/code-search-net-go","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-go\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Go portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset's comments are in English and the functions are coded in Go\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain, test, validation labels are included in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-go."},
	{"name":"code-search-net-java","keyword":"java","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/code-search-net-java","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-java\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Java portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset's comments are in English and the functions are coded in Java\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain, test, validation labels are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-java."},
	{"name":"instructional_code-search-net-java","keyword":"java","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/instructional_code-search-net-java","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"instructional_code-search-net-java\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is an instructional dataset for Java.\\nThe dataset contains two different kind of tasks:\\n\\nGiven a piece of code generate a description of what it does.\\nGiven a description generate a piece of code that fulfils the description.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThere are no splits.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\nMay of 2023\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/instructional_code-search-net-java."},
	{"name":"h2ogpt-oig-oasst1-instruct-cleaned-v3","keyword":"open-source","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v3","creator_name":"H2O.ai","creator_url":"https://huggingface.co/h2oai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\th2oGPT Data Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nH2O.ai's h2ogpt-oig-oasst1-instruct-cleaned-v3 is an open-source instruct-type dataset for fine-tuning of large language models, licensed for commercial use.\\n\\nNumber of rows: 269406\\nNumber of columns: 4\\nColumn names: ['input', 'source', 'prompt_type', 'id']\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\n\\nOriginal LAION OIG Dataset\\n\\nLAION OIG data detoxed and filtered down by scripts in h2oGPT repository\\n\\nOriginal Open Assistant data in tree structure\\n\\nThis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v3."},
	{"name":"openassistant_oasst1_h2ogpt_graded","keyword":"open-source","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/h2oai/openassistant_oasst1_h2ogpt_graded","creator_name":"H2O.ai","creator_url":"https://huggingface.co/h2oai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\th2oGPT Data Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nH2O.ai's openassistant_oasst1_h2ogpt_graded is an open-source instruct-type dataset for fine-tuning of large language models, licensed for commercial use.\\n\\nNumber of rows: 30368\\nNumber of columns: 5\\nColumn names: ['input', 'source', 'prompt_type', 'grade_deberta', 'id']\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\n\\nOriginal Open Assistant data in tree structure\\nThis flattened dataset created by script in h2oGPT repository\\n\\n"},
	{"name":"h2ogpt-fortune2000-personalized","keyword":"open-source","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/h2oai/h2ogpt-fortune2000-personalized","creator_name":"H2O.ai","creator_url":"https://huggingface.co/h2oai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\th2oGPT Data Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nH2O.ai's h2ogpt-fortune2000-personalized is an open-source instruct-type dataset for fine-tuning of large language models, licensed for commercial use.\\n\\nNumber of rows: 11363\\nNumber of columns: 4\\nColumn names: ['input', 'prompt_type', 'source', 'id']\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\n\\nFortune 2000 companies from Wikipedia\\n\\n"},
	{"name":"code-search-net-python","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/code-search-net-python","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-python\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nHomepage: None\\nRepository: https://huggingface.co/datasets/Nan-Do/code-search-net-python\\nPaper: None\\nLeaderboard: None\\nPoint of Contact: @Nan-Do\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Python portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-python."},
	{"name":"instructional_code-search-net-python","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nan-Do/instructional_code-search-net-python","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"instructional_code-search-net-python\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is an instructional dataset for Python.\\nThe dataset contains two different kind of tasks:\\n\\nGiven a piece of code generate a description of what it does.\\nGiven a description generate a piece of code that fulfils the description.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThere are no splits.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\nMay of 2023‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/instructional_code-search-net-python."},
	{"name":"reasoning-gsm-qna-oa","keyword":"programming","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/0x22almostEvil/reasoning-gsm-qna-oa","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GSM QnA reasoning with ~8.8K entries.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nContains Parquet of a list of instructions and answers.\\nEach row consists of\\n\\nINSTRUCTION\\nRESPONSE\\nSOURCE\\nMETADATA (json with language).\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOriginal Datasets are available here:\\n\\t\\n\\n\\nhttps://huggingface.co/datasets/gsm8k\\nhttps://huggingface.co/datasets/reasoning-machines/gsm-hard\\n\\n"},
	{"name":"es2bash","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dev2bit/es2bash","creator_name":"dev2bit","creator_url":"https://huggingface.co/dev2bit","description":"This dataset consisting of natural language requests (in Spanish) and the bash command that resolves it."},
	{"name":"algorithmic-reasoning-seed","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lemonteaa/algorithmic-reasoning-seed","creator_name":"Tom","creator_url":"https://huggingface.co/lemonteaa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Algorithmic Reasoning (seed)\\n\\t\\n\\nNote: This dataset is WIP and most question's answer section is empty or incomplete! See also \\\"Other Known Limitations\\\" section\\nWarning: If you somehow do use this dataset, remember to NOT do any eval after training on the questions in this dataset!\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDataset to help LLM learn how to reason about code, especially on algorithmic tasks, by seeing human demostration.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lemonteaa/algorithmic-reasoning-seed."},
	{"name":"openllm-manual-eval-code","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lemonteaa/openllm-manual-eval-code","creator_name":"Tom","creator_url":"https://huggingface.co/lemonteaa","description":"Sample conversations with vicuna-13b-fp16-v1.0 , focusing on coding ability tests. (Note that vicuna-13b have a v1.1 released and it improved on some coding tasks)\\nProbably not going to make more like this as creating JSON file by hand (copy-pasting from my note app) is exceedingly slow.\\n"},
	{"name":"Dataset-Goldbach-1.0","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ZoabiTalal/Dataset-Goldbach-1.0","creator_name":"Talal Zoabi","creator_url":"https://huggingface.co/ZoabiTalal","description":"ZoabiTalal/Dataset-Goldbach-1.0 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sample_controlnet_dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SaffalPoosh/sample_controlnet_dataset","creator_name":"Talha Yousuf","creator_url":"https://huggingface.co/SaffalPoosh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tControlNet training\\n\\t\\n\\nthis dataset is subset of fill_50k dataset just to test the finetuning logic.\\n\\nTODO:\\n\\n\\n add text data\\n\\n"},
	{"name":"toy-diabetes","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jayabalambika/toy-diabetes","creator_name":"R","creator_url":"https://huggingface.co/Jayabalambika","description":"Jayabalambika/toy-diabetes dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"basic_code_ppl_eval","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/reshinthadith/basic_code_ppl_eval","creator_name":"reshinth.adith","creator_url":"https://huggingface.co/reshinthadith","description":"reshinthadith/basic_code_ppl_eval dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"docs_on_several_languages","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages","creator_name":"Aleksey Timoshin","creator_url":"https://huggingface.co/AlekseyScorpi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"docs_on_several_languages\\\"\\n\\t\\n\\nThis dataset is a collection of different images in different languages.\\nThe set includes the following languages: Azerbaijani, Belorussian, Chinese, English, Estonian, Finnish, Georgian, Japanese, Korean, Kazakh, Latvian, Lithuanian, Mongolian, Norwegian, Polish, Russian, Ukranian.\\nEach language has a corresponding class label defined. At least 100 images in the entire dataset are allocated per class. This dataset was originally used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages."},
	{"name":"ign_clean_instruct_dataset_500k","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ignmilton/ign_clean_instruct_dataset_500k","creator_name":"Ignatius Milton","creator_url":"https://huggingface.co/ignmilton","description":"This dataset contains ~508k prompt-instruction pairs with high quality responses. It was synthetically created from a subset of Ultrachat prompts. It does not contain any alignment focused responses or NSFW content.\\nLicensed under apache-2.0\\n"},
	{"name":"test","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BerMaker/test","creator_name":"BerMaker","creator_url":"https://huggingface.co/BerMaker","description":"Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable."},
	{"name":"pipeline2code","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/katenil/pipeline2code","creator_name":"Kate Trofimova","creator_url":"https://huggingface.co/katenil","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pipeline2Code\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset origin\\n\\t\\n\\nCode4ML: a Large-scale Dataset of annotated Machine Learning Code\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is designed for the iterative generation of Machine Learning (ML) code based on high-level ML pipeline descriptions.\\nIt consists of code snippets extracted from Kaggle kernels, organized as Jupyter Notebook snippets. \\nEach kernel includes a set of prompts and completions. \\nThe initial prompt contains an  token‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/katenil/pipeline2code."},
	{"name":"lyra","keyword":"code","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/lyra","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlyra\\n\\t\\n\\n"},
	{"name":"lyra","keyword":"code","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/lyra","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlyra\\n\\t\\n\\n"},
	{"name":"bc-humaneval","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gabeorlanski/bc-humaneval","creator_name":"Gabe Orlanski","creator_url":"https://huggingface.co/gabeorlanski","description":"The HumanEval dataset in BabelCode format."},
	{"name":"commitpackft","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bigcode/commitpackft","creator_name":"BigCode","creator_url":"https://huggingface.co/bigcode","description":"CommitPackFT is is a 2GB filtered version of CommitPack to contain only high-quality commit messages that resemble natural language instructions."},
	{"name":"bc-transcoder","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gabeorlanski/bc-transcoder","creator_name":"Gabe Orlanski","creator_url":"https://huggingface.co/gabeorlanski","description":"The Transcoder dataset in BabelCode format. Currently supports translation from C++ and Python."},
	{"name":"spider-schema","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-schema","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Schema\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset contains the 166 databases used in the Spider dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at https://yale-lily.github.io/spider‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-schema."},
	{"name":"spider-context-instruct","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs in a ### Instruction: and ### Response: format with database context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-context-instruct."},
	{"name":"spider-context-instruct","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs in a ### Instruction: and ### Response: format with database context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-context-instruct."},
	{"name":"spider-context-validation","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-context-validation","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Context Validation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to validate spider-fine-tuned LLMs with database context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-context-validation."},
	{"name":"spider-context-validation","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-context-validation","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Context Validation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to validate spider-fine-tuned LLMs with database context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-context-validation."},
	{"name":"spider-context-instruct","keyword":"sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs in a ### Instruction: and ### Response: format with database context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-context-instruct."},
	{"name":"spider-context-validation","keyword":"sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-context-validation","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Context Validation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to validate spider-fine-tuned LLMs with database context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-context-validation."},
	{"name":"spider-schema","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-schema","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Schema\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset contains the 166 databases used in the Spider dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at https://yale-lily.github.io/spider‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-schema."},
	{"name":"spider-context-instruct","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs in a ### Instruction: and ### Response: format with database context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-context-instruct."},
	{"name":"spider-context-validation","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-context-validation","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Context Validation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to validate spider-fine-tuned LLMs with database context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-context-validation."},
	{"name":"test","keyword":"code","license":"Boost Software License 1.0","license_url":"https://choosealicense.com/licenses/bsl-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pengxiang01/test","creator_name":"wang","creator_url":"https://huggingface.co/pengxiang01","description":"aasdfsdf\\n"},
	{"name":"spider-natsql-skeleton-context-instruct","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-natsql-skeleton-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider NatSQL Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs on the Spider dataset with database context using NatSQL.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNatSQL\\n\\t\\n\\nNatSQL is an intermediate representation for SQL that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-natsql-skeleton-context-instruct."},
	{"name":"spider-natsql-skeleton-context-instruct","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-natsql-skeleton-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider NatSQL Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs on the Spider dataset with database context using NatSQL.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNatSQL\\n\\t\\n\\nNatSQL is an intermediate representation for SQL that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-natsql-skeleton-context-instruct."},
	{"name":"spider-natsql-context-validation","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-natsql-context-validation","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider NatSQL Context Validation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to validate LLMs on the Spider dev dataset with database context using NatSQL.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNatSQL\\n\\t\\n\\nNatSQL is an intermediate representation for SQL that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-natsql-context-validation."},
	{"name":"spider-natsql-context-validation","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-natsql-context-validation","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider NatSQL Context Validation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to validate LLMs on the Spider dev dataset with database context using NatSQL.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNatSQL\\n\\t\\n\\nNatSQL is an intermediate representation for SQL that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-natsql-context-validation."},
	{"name":"spider-natsql-context-instruct","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-natsql-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider NatSQL Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs on the Spider dataset with database context using NatSQL.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNatSQL\\n\\t\\n\\nNatSQL is an intermediate representation for SQL that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-natsql-context-instruct."},
	{"name":"spider-natsql-context-instruct","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-natsql-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider NatSQL Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs on the Spider dataset with database context using NatSQL.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNatSQL\\n\\t\\n\\nNatSQL is an intermediate representation for SQL that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-natsql-context-instruct."},
	{"name":"spider-natsql-skeleton-context-instruct","keyword":"sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-natsql-skeleton-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider NatSQL Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs on the Spider dataset with database context using NatSQL.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNatSQL\\n\\t\\n\\nNatSQL is an intermediate representation for SQL that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-natsql-skeleton-context-instruct."},
	{"name":"spider-natsql-context-validation","keyword":"sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-natsql-context-validation","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider NatSQL Context Validation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to validate LLMs on the Spider dev dataset with database context using NatSQL.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNatSQL\\n\\t\\n\\nNatSQL is an intermediate representation for SQL that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-natsql-context-validation."},
	{"name":"spider-natsql-context-instruct","keyword":"sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-natsql-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider NatSQL Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs on the Spider dataset with database context using NatSQL.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNatSQL\\n\\t\\n\\nNatSQL is an intermediate representation for SQL that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-natsql-context-instruct."},
	{"name":"spider-natsql-skeleton-context-instruct","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-natsql-skeleton-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider NatSQL Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs on the Spider dataset with database context using NatSQL.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNatSQL\\n\\t\\n\\nNatSQL is an intermediate representation for SQL that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-natsql-skeleton-context-instruct."},
	{"name":"spider-natsql-context-validation","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-natsql-context-validation","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider NatSQL Context Validation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to validate LLMs on the Spider dev dataset with database context using NatSQL.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNatSQL\\n\\t\\n\\nNatSQL is an intermediate representation for SQL that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-natsql-context-validation."},
	{"name":"spider-natsql-context-instruct","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-natsql-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider NatSQL Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs on the Spider dataset with database context using NatSQL.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNatSQL\\n\\t\\n\\nNatSQL is an intermediate representation for SQL that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-natsql-context-instruct."},
	{"name":"NER","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Soressaa/NER","creator_name":"SORESSA BEYENE LEMU","creator_url":"https://huggingface.co/Soressaa","description":"Soressaa/NER dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"TextCodeDepot","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anujsahani01/TextCodeDepot","creator_name":"Anuj Sahani","creator_url":"https://huggingface.co/anujsahani01","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description:\\n\\t\\n\\nThe Python Code Chatbot dataset is a collection of Python code snippets extracted from various publicly available datasets and platforms. It is designed to facilitate training conversational AI models that can understand and generate Python code. The dataset consists of a total of 1,37,183 prompts, each representing a dialogue between a human and an AI Scientist.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompt Card:\\n\\t\\n\\nEach prompt in the dataset follows a specific format known as the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anujsahani01/TextCodeDepot."},
	{"name":"spider-skeleton-context-instruct","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-skeleton-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Skeleton Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs in a ### Instruction: and ### Response: format with database context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-skeleton-context-instruct."},
	{"name":"spider-skeleton-context-instruct","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-skeleton-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Skeleton Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs in a ### Instruction: and ### Response: format with database context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-skeleton-context-instruct."},
	{"name":"spider-skeleton-context-instruct","keyword":"sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-skeleton-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Skeleton Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs in a ### Instruction: and ### Response: format with database context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-skeleton-context-instruct."},
	{"name":"spider-skeleton-context-instruct","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-skeleton-context-instruct","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Skeleton Context Instruct\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\nThis dataset was created to finetune LLMs in a ### Instruction: and ### Response: format with database context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYale Lily Spider Leaderboards\\n\\t\\n\\nThe leaderboard can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-skeleton-context-instruct."},
	{"name":"CodeLlama-2-20k","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mlabonne/CodeLlama-2-20k","creator_name":"Maxime Labonne","creator_url":"https://huggingface.co/mlabonne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCodeLlama-2-20k: A Llama 2 Version of CodeAlpaca\\n\\t\\n\\nThis dataset is the sahil2801/CodeAlpaca-20k dataset with the Llama 2 prompt format described here.\\nHere is the code I used to format it:\\nfrom datasets import load_dataset\\n\\n# Load the dataset\\ndataset = load_dataset('sahil2801/CodeAlpaca-20k')\\n\\n# Define a function to merge the three columns into one\\ndef merge_columns(example):\\n    if example['input']:\\n        merged = f\\\"<s>[INST] <<SYS>>\\\\nBelow is an instruction that describes a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mlabonne/CodeLlama-2-20k."},
	{"name":"ai-hdlcoder-dataset","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AWfaw/ai-hdlcoder-dataset","creator_name":"Romashchenko Vladyslav","creator_url":"https://huggingface.co/AWfaw","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AI-HDLCoder\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe GitHub Code dataset consists of 100M code files from GitHub in VHDL programming language with extensions totaling in 1.94 GB of data. The dataset was created from the public GitHub dataset on Google BiqQuery at Anhalt University of Applied Sciences.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tConsiderations for Using the Data\\n\\t\\n\\nThe dataset is created for research purposes and consists of source code from a wide range of repositories. As such‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AWfaw/ai-hdlcoder-dataset."},
	{"name":"humaneval-ja-v0.6","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/humaneval-ja-v0.6","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"humaneval-ja\\\"\\n\\t\\n\\nMore Information needed\\n"},
	{"name":"BuggedPythonLeetCode","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NeuroDragon/BuggedPythonLeetCode","creator_name":"NeuroDragon","creator_url":"https://huggingface.co/NeuroDragon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nedit: fixed some bugs with datasets not handling all pyarrow types.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of Python coding problems from LeetCode, which have been bugged using the OpenBugger package. This dataset provides a unique opportunity to study the debugging process in a controlled and replicable environment.\\nFor each correct code snippet, 15 bugged versions were attempted. For each succesfully bugged version, a corresponding question‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NeuroDragon/BuggedPythonLeetCode."},
	{"name":"langchain-python-integrations","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clue2solve/langchain-python-integrations","creator_name":"Clue2solve Inc","creator_url":"https://huggingface.co/clue2solve","description":"clue2solve/langchain-python-integrations dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"langchain-docs-use-cases","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clue2solve/langchain-docs-use-cases","creator_name":"Clue2solve Inc","creator_url":"https://huggingface.co/clue2solve","description":"clue2solve/langchain-docs-use-cases dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"langchain-docs-modules","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clue2solve/langchain-docs-modules","creator_name":"Clue2solve Inc","creator_url":"https://huggingface.co/clue2solve","description":"clue2solve/langchain-docs-modules dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"HelloWorldExamples","keyword":"code","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MihaiPopa2/HelloWorldExamples","creator_name":"Popa Mihai Cosmin","creator_url":"https://huggingface.co/MihaiPopa2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntro\\n\\t\\n\\nWelcome to the one-liner \\\"Hello world!\\\" examples!\\nThis is a dataset containing \\\"Hello world!\\\" examples in 10+ languages!\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNotes\\n\\t\\n\\nIf you found a language that's not listed here, you can open a pull request!\\nYou can also create and train models, or even spaces!\\nNote that this dataset is in CSV format, so it's not as flexible as JSON!\\n"},
	{"name":"CodeNet4Repair","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TnT/CodeNet4Repair","creator_name":"TnT","creator_url":"https://huggingface.co/TnT","description":"TnT/CodeNet4Repair dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Python-codes","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Arjun-G-Ravi/Python-codes","creator_name":"Arjun G Ravi","creator_url":"https://huggingface.co/Arjun-G-Ravi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nPlease note that this dataset maynot be perfect and may contain a very small quantity of non python codes. But the quantity appears to be very small\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset contains a collection of python question and their code. This is meant to be used for training models to be efficient in Python specific coding.\\nThe dataset has two features - 'question' and 'code'. \\nAn example is:\\n{'question': 'Create a function that takes in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Arjun-G-Ravi/Python-codes."},
	{"name":"humaneval-ja-v0.6","keyword":"code-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/humaneval-ja-v0.6","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"humaneval-ja\\\"\\n\\t\\n\\nMore Information needed\\n"},
	{"name":"HelloWorldExamples","keyword":"coding","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MihaiPopa2/HelloWorldExamples","creator_name":"Popa Mihai Cosmin","creator_url":"https://huggingface.co/MihaiPopa2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntro\\n\\t\\n\\nWelcome to the one-liner \\\"Hello world!\\\" examples!\\nThis is a dataset containing \\\"Hello world!\\\" examples in 10+ languages!\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNotes\\n\\t\\n\\nIf you found a language that's not listed here, you can open a pull request!\\nYou can also create and train models, or even spaces!\\nNote that this dataset is in CSV format, so it's not as flexible as JSON!\\n"},
	{"name":"openassistant_oasst1_h2ogpt_llama2_chat","keyword":"open-source","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/h2oai/openassistant_oasst1_h2ogpt_llama2_chat","creator_name":"H2O.ai","creator_url":"https://huggingface.co/h2oai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\th2oGPT Data Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nH2O.ai's openassistant_oasst1_h2ogpt_llama2_chat is an open-source instruct-type dataset for fine-tuning of large language models, licensed for commercial use.\\n\\nNumber of rows: 44219\\nNumber of columns: 5\\nColumn names: ['id', 'prompt_type', 'input', 'output', 'source']\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\n\\nOriginal Open Assistant data in tree structure\\nThis flattened dataset created by script in h2oGPT repository\\n\\n"},
	{"name":"langchain-additional-resources","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clue2solve/langchain-additional-resources","creator_name":"Clue2solve Inc","creator_url":"https://huggingface.co/clue2solve","description":"clue2solve/langchain-additional-resources dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"HelloWorldExamples","keyword":"programming","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MihaiPopa2/HelloWorldExamples","creator_name":"Popa Mihai Cosmin","creator_url":"https://huggingface.co/MihaiPopa2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntro\\n\\t\\n\\nWelcome to the one-liner \\\"Hello world!\\\" examples!\\nThis is a dataset containing \\\"Hello world!\\\" examples in 10+ languages!\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNotes\\n\\t\\n\\nIf you found a language that's not listed here, you can open a pull request!\\nYou can also create and train models, or even spaces!\\nNote that this dataset is in CSV format, so it's not as flexible as JSON!\\n"},
	{"name":"Multi_CodeNet4Repair","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TnT/Multi_CodeNet4Repair","creator_name":"TnT","creator_url":"https://huggingface.co/TnT","description":"TnT/Multi_CodeNet4Repair dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"text-template-to-summarize","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Anderson-Andre-P/text-template-to-summarize","creator_name":"Anderson Andr√© Pereira Eleut√©rio","creator_url":"https://huggingface.co/Anderson-Andre-P","description":"Anderson-Andre-P/text-template-to-summarize dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"alpaca-cs","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Vazbeek/alpaca-cs","creator_name":"Jan Sl√°ma","creator_url":"https://huggingface.co/Vazbeek","description":"Alpaca dataset translated to Czech language using ChatGPT 3.5.\\n"},
	{"name":"errored_python","keyword":"code","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TacoPrime/errored_python","creator_name":"Matt J","creator_url":"https://huggingface.co/TacoPrime","description":"This is a subset of the python dataset provided but Ailurophile on Kaggle.\\nImportant:Errors were introduced on purpose to try to test a sort of \\\"specialized masking\\\" in a realistic way. \\nGoal:The goal is to create a specialized agent, and add it to a chain with at least one other agent that generates code, and can hopefully \\\"catch\\\" any errors. \\nInspiration:When working to generate datasets with other models, I found that even after multiple \\\"passes\\\" errors where still missed.\\nOut of curiosity‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TacoPrime/errored_python."},
	{"name":"alpaca-cs-subset-1k","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Vazbeek/alpaca-cs-subset-1k","creator_name":"Jan Sl√°ma","creator_url":"https://huggingface.co/Vazbeek","description":"First 1000 items form dataset Vazbeek/alpaca-cs.\\n"},
	{"name":"PY150k","keyword":"code","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AISE-TUDelft/PY150k","creator_name":"AISE research lab at TU Delft","creator_url":"https://huggingface.co/AISE-TUDelft","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"PY150k\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCode Completion dataset created from the code available in CodeXGlue.\\n"},
	{"name":"dypybench_functions","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/claudios/dypybench_functions","creator_name":"Claudio Spiess","creator_url":"https://huggingface.co/claudios","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDyPyBench Functions Datasets\\n\\t\\n\\nDyPyBench is a dataset constructed by Piyush Krishan Bajaj at the Software Lab, Institute of Software Engineering, University of Stuttgart. It contains 50 open source projects from GitHub.\\nWe used Nathan Cooper's function_parser tool, based off GitHub's CodeSearchNet function_parser, to extract all functions from all the projects, excluding library functions in the virtualenv. We also ran all tests in DyPyBench and produced a coverage report in JSON.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/claudios/dypybench_functions."},
	{"name":"My-First-Dataset","keyword":"postgresql","license":"PostgreSQL License","license_url":"https://choosealicense.com/licenses/postgresql/","language":"en","dataset_url":"https://huggingface.co/datasets/johnsonlee/My-First-Dataset","creator_name":"lizonglin","creator_url":"https://huggingface.co/johnsonlee","description":"ËøôÊòØÊàëÁöÑÁ¨¨‰∏Ä‰∏™dataset\\n"},
	{"name":"user_id","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/feliciamj/user_id","creator_name":"mj","creator_url":"https://huggingface.co/feliciamj","description":"feliciamj/user_id dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"HyPoradise-v0","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PeacefulData/HyPoradise-v0","creator_name":"Peaceful Data","creator_url":"https://huggingface.co/PeacefulData","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHypothesesParadise\\n\\t\\n\\n\\nOpen request to public git submission on open resource their n-best to public usage.\\nIf you consider this work would be related or useful for your research, please consider to cite the work in NeurIPS 2023. Thank you.\\n\\n   \\n\\n@inproceedings{chen2023hyporadise,\\n  title={HyPoradise: An Open Baseline for Generative Speech Recognition with Large Language Models},\\n  author={CHEN, CHEN and Hu, Yuchen and Yang, Chao-Han Huck and Siniscalchi, Sabato Marco and Chen‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PeacefulData/HyPoradise-v0."},
	{"name":"dataset1","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ccml/dataset1","creator_name":"Ahm","creator_url":"https://huggingface.co/ccml","description":"ccml/dataset1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"matt-training-img","keyword":"code","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/raoulduke420/matt-training-img","creator_name":"Matt Dilworth","creator_url":"https://huggingface.co/raoulduke420","description":"My dataset for training SDXL & SD 1.5\\n"},
	{"name":"the-vault-class","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fsoft-AIC/the-vault-class","creator_name":"FPT Software AI Center","creator_url":"https://huggingface.co/Fsoft-AIC","description":"The Vault is a multilingual code-text dataset with over 40 million pairs covering 10 popular programming languages. \\nIt is the largest corpus containing parallel code-text data. By building upon The Stack, a massive raw code sample collection, \\nthe Vault offers a comprehensive and clean resource for advancing research in code understanding and generation. It provides a \\nhigh-quality dataset that includes code-text pairs at multiple levels, such as class and inline-level, in addition to the function level. \\nThe Vault can serve many purposes at multiple levels."},
	{"name":"minispider","keyword":"text-to-sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ravidborse/minispider","creator_name":"Ravikiran Borse","creator_url":"https://huggingface.co/ravidborse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at https://yale-lily.github.io/spider\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ravidborse/minispider."},
	{"name":"huge-context-size-test","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pchanumolu/huge-context-size-test","creator_name":"Pradeep Chanumolu","creator_url":"https://huggingface.co/pchanumolu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCodeLlama-2-20k: A Llama 2 Version of CodeAlpaca\\n\\t\\n\\nThis dataset is the pchanumolu/huge-context-size-test dataset with the Llama 2 prompt format described here.\\nHere is the code I used to format it:\\nfrom datasets import load_dataset\\n\\n# Load the dataset\\ndataset = load_dataset('pchanumolu/huge-context-size-test')\\n\\n# Define a function to merge the three columns into one\\ndef merge_columns(example):\\n    if example['input']:\\n        merged = f\\\"<s>[INST] <<SYS>>\\\\nBelow is an instruction‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pchanumolu/huge-context-size-test."},
	{"name":"chipgpt","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JackieZhang/chipgpt","creator_name":"Jackie Zhang","creator_url":"https://huggingface.co/JackieZhang","description":"JackieZhang/chipgpt dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"mrmocci","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mrmocciai/mrmocci","creator_name":"Mocci lutha","creator_url":"https://huggingface.co/mrmocciai","description":"\\n\\n VOICE CONVERSATION BACKUP\\nOriginal Repo\\n"},
	{"name":"humaneval_ru","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NLPCoreTeam/humaneval_ru","creator_name":"NLP Core Team","creator_url":"https://huggingface.co/NLPCoreTeam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHumanEval_ru Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a version of Code Geneneration HumanEval dataset translated to Russian. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported tasks\\n\\t\\n\\nThe task is to generate body of the function based on the function signature and docstring. The programming problems are written in Python and contain Russian natural text in comments and docstrings.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTask example\\n\\t\\n\\nfrom typing import List\\ndef string_xor(a: str, b: str) -> str:\\n    \\\"\\\"\\n    –í—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPCoreTeam/humaneval_ru."},
	{"name":"Grapheme128x128","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/innat/Grapheme128x128","creator_name":"Mohammed Innat","creator_url":"https://huggingface.co/innat","description":"\\nThis data set is preprocess version of this competition data set. The preprocess data is collected from here.\\n"},
	{"name":"OneOS","keyword":"code","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wasertech/OneOS","creator_name":"Danny Waser","creator_url":"https://huggingface.co/wasertech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOneOS Dataset\\n\\t\\n\\nThe OneOS dataset is a collection of text data for the OneOS project. It consists of a large number of text samples that can be used for training and evaluating natural language processing models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nNumber of Samples: 13,068\\nLicense: CC0*\\nLanguage: English, French\\n\\n  * Only unlicensed sentences generated manually fall under CreativeCommon-0. Sentences already licensed under different terms, such as nl2bash or samantha-data, remain‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wasertech/OneOS."},
	{"name":"habr_qa_sbs","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Vikhrmodels/habr_qa_sbs","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHabr sbs qa\\n\\t\\n\\n–î–∞—Ç–∞—Å–µ—Ç –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ —Å–∞–π—Ç–µ habr qa, –ª—É—á—à–∏–π –æ—Ç–≤–µ—Ç - —Ç–æ—Ç –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –µ—Å—Ç—å –ª–∞–π–∫–∏, —Ö—É–¥—à–∏–π - —Ç–æ—Ç –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –º–µ–Ω—å—à–µ –≤—Å–µ–≥–æ –ª–∞–π–∫–æ–≤. \\n–î–∞—Ç–∞—Å–µ—Ç —Å–æ–±—Ä–∞–Ω Love.Death.Transformers. –∏ –î–∞—Ç–∞-–£—Ç—Ä–µ–Ω–Ω–∏–∫ \\nMore Information needed\\n"},
	{"name":"smart-contracts-instructions","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlfredPros/smart-contracts-instructions","creator_name":"Alfred Kuhlman","creator_url":"https://huggingface.co/AlfredPros","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSmart Contracts Instructions\\n\\t\\n\\nA dataset containing 6,003 GPT-generated human instruction and Solidity source code data pairs.\\nGPT models used to make this data are GPT-3.5 turbo, GPT-3.5 turbo 16k context, and GPT-4. Solidity source codes are used from mwritescode's Slither Audited Smart Contracts (https://huggingface.co/datasets/mwritescode/slither-audited-smart-contracts).\\nDistributions of the GPT models used to make this dataset:\\n\\nGPT-3.5 Turbo: 5,276\\nGPT-3.5 Turbo 16k‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlfredPros/smart-contracts-instructions."},
	{"name":"ClassEval","keyword":"code-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FudanSELab/ClassEval","creator_name":"FudanSELab","creator_url":"https://huggingface.co/FudanSELab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for FudanSELab ClassEval\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWe manually build ClassEval of 100 class-level Python coding tasks, consists of 100 classes and 412 methods, and average 33.1 test cases per class.\\nFor 100 class-level tasks, diversity is maintained by encompassing these tasks over a wide spectrum of topics, including Management Systems, Data Formatting, Mathematical Operations, Game Development, File Handing, Database Operations and Natural Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FudanSELab/ClassEval."},
	{"name":"OneOS","keyword":"python","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wasertech/OneOS","creator_name":"Danny Waser","creator_url":"https://huggingface.co/wasertech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOneOS Dataset\\n\\t\\n\\nThe OneOS dataset is a collection of text data for the OneOS project. It consists of a large number of text samples that can be used for training and evaluating natural language processing models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nNumber of Samples: 13,068\\nLicense: CC0*\\nLanguage: English, French\\n\\n  * Only unlicensed sentences generated manually fall under CreativeCommon-0. Sentences already licensed under different terms, such as nl2bash or samantha-data, remain‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wasertech/OneOS."},
	{"name":"SalesKRA","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AdiOO7/SalesKRA","creator_name":"Aditya Singh","creator_url":"https://huggingface.co/AdiOO7","description":"AdiOO7/SalesKRA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"stackoverflowVQA-filtered-small","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mirzaei2114/stackoverflowVQA-filtered-small","creator_name":"Motahhare Mirzaei","creator_url":"https://huggingface.co/mirzaei2114","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"stackoverflowVQA-filtered-small\\\"\\n\\t\\n\\nMore Information needed\\n"},
	{"name":"stackoverflowVQA","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mirzaei2114/stackoverflowVQA","creator_name":"Motahhare Mirzaei","creator_url":"https://huggingface.co/mirzaei2114","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"stackoverflowVQA\\\"\\n\\t\\n\\nMore Information needed\\n"},
	{"name":"spider-context-validation-ranked-schema","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-context-validation-ranked-schema","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Context Validation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRanked Schema by ChatGPT\\n\\t\\n\\nThe database context used here is generated from ChatGPT after telling it to reorder the schema with the most relevant columns in the beginning of the db_info.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-context-validation-ranked-schema."},
	{"name":"spider-context-validation-ranked-schema","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-context-validation-ranked-schema","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Context Validation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRanked Schema by ChatGPT\\n\\t\\n\\nThe database context used here is generated from ChatGPT after telling it to reorder the schema with the most relevant columns in the beginning of the db_info.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-context-validation-ranked-schema."},
	{"name":"spider-context-validation-ranked-schema","keyword":"sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-context-validation-ranked-schema","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Context Validation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRanked Schema by ChatGPT\\n\\t\\n\\nThe database context used here is generated from ChatGPT after telling it to reorder the schema with the most relevant columns in the beginning of the db_info.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-context-validation-ranked-schema."},
	{"name":"spider-context-validation-ranked-schema","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richardr1126/spider-context-validation-ranked-schema","creator_name":"Richard R.","creator_url":"https://huggingface.co/richardr1126","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider Context Validation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRanked Schema by ChatGPT\\n\\t\\n\\nThe database context used here is generated from ChatGPT after telling it to reorder the schema with the most relevant columns in the beginning of the db_info.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/richardr1126/spider-context-validation-ranked-schema."},
	{"name":"Helix","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KaleidoSG/Helix","creator_name":"Kaleido Singapore","creator_url":"https://huggingface.co/KaleidoSG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHelix Dataset for Questioning and Instructing (QI)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe Helix dataset is a specialized collection of data tailored for Questioning and Instructing (QI) tasks. It is created by merging all the Airoboros datasets and incorporating one RosettaCode dataset, with a primary focus on supporting QI research and applications.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nSource Datasets: Airoboros datasets (various sources), RosettaCode dataset\\nMerging Script: The merging of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KaleidoSG/Helix."},
	{"name":"python_codestyles-random-500","keyword":"code-style","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/infinityofspace/python_codestyles-random-500","creator_name":"infinityofspace","creator_url":"https://huggingface.co/infinityofspace","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"python_codestyles-random-500\\\"\\n\\t\\n\\nThis dataset contains negative and positive examples with python code of compliance with a code style. A positive\\nexample represents compliance with the code style (label is 1). Each example is composed of two components, the first\\ncomponent consists of a code that either conforms to the code style or violates it and the second component\\ncorresponding to an example code that already conforms to a code style. In total, the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/infinityofspace/python_codestyles-random-500."},
	{"name":"python_codestyles-single-500","keyword":"code-style","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/infinityofspace/python_codestyles-single-500","creator_name":"infinityofspace","creator_url":"https://huggingface.co/infinityofspace","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"python_codestyles-single-500\\\"\\n\\t\\n\\nThis dataset contains negative and positive examples with python code of compliance with a code style. A positive\\nexample represents compliance with the code style (label is 1). Each example is composed of two components, the first\\ncomponent consists of a code that either conforms to the code style or violates it and the second component\\ncorresponding to an example code that already conforms to a code style. In total, the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/infinityofspace/python_codestyles-single-500."},
	{"name":"python_codestyles-mixed1-500","keyword":"code-style","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/infinityofspace/python_codestyles-mixed1-500","creator_name":"infinityofspace","creator_url":"https://huggingface.co/infinityofspace","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"python_codestyles-mixed1-500\\\"\\n\\t\\n\\nThis dataset contains negative and positive examples with python code of compliance with a code style. A positive\\nexample represents compliance with the code style (label is 1). Each example is composed of two components, the first\\ncomponent consists of a code that either conforms to the code style or violates it and the second component\\ncorresponding to an example code that already conforms to a code style.\\nThe dataset combines‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/infinityofspace/python_codestyles-mixed1-500."},
	{"name":"python_codestyles-random-1k","keyword":"code-style","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/infinityofspace/python_codestyles-random-1k","creator_name":"infinityofspace","creator_url":"https://huggingface.co/infinityofspace","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"python_codestyles-random-1k\\\"\\n\\t\\n\\nThis dataset contains negative and positive examples with python code of compliance with a code style. A positive\\nexample represents compliance with the code style (label is 1). Each example is composed of two components, the first\\ncomponent consists of a code that either conforms to the code style or violates it and the second component\\ncorresponding to an example code that already conforms to a code style. In total, the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/infinityofspace/python_codestyles-random-1k."},
	{"name":"python_codestyles-single-1k","keyword":"code-style","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/infinityofspace/python_codestyles-single-1k","creator_name":"infinityofspace","creator_url":"https://huggingface.co/infinityofspace","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"python_codestyles-single-1k\\\"\\n\\t\\n\\nThis dataset contains negative and positive examples with python code of compliance with a code style. A positive\\nexample represents compliance with the code style (label is 1). Each example is composed of two components, the first\\ncomponent consists of a code that either conforms to the code style or violates it and the second component\\ncorresponding to an example code that already conforms to a code style. In total, the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/infinityofspace/python_codestyles-single-1k."},
	{"name":"python_codestyles-mixed1-1k","keyword":"code-style","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/infinityofspace/python_codestyles-mixed1-1k","creator_name":"infinityofspace","creator_url":"https://huggingface.co/infinityofspace","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"python_codestyles-mixed1-1k\\\"\\n\\t\\n\\nThis dataset contains negative and positive examples with python code of compliance with a code style. A positive\\nexample represents compliance with the code style (label is 1). Each example is composed of two components, the first\\ncomponent consists of a code that either conforms to the code style or violates it and the second component\\ncorresponding to an example code that already conforms to a code style.\\nThe dataset combines‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/infinityofspace/python_codestyles-mixed1-1k."},
	{"name":"python_codestyles-random-500","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/infinityofspace/python_codestyles-random-500","creator_name":"infinityofspace","creator_url":"https://huggingface.co/infinityofspace","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"python_codestyles-random-500\\\"\\n\\t\\n\\nThis dataset contains negative and positive examples with python code of compliance with a code style. A positive\\nexample represents compliance with the code style (label is 1). Each example is composed of two components, the first\\ncomponent consists of a code that either conforms to the code style or violates it and the second component\\ncorresponding to an example code that already conforms to a code style. In total, the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/infinityofspace/python_codestyles-random-500."},
	{"name":"python_codestyles-single-500","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/infinityofspace/python_codestyles-single-500","creator_name":"infinityofspace","creator_url":"https://huggingface.co/infinityofspace","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"python_codestyles-single-500\\\"\\n\\t\\n\\nThis dataset contains negative and positive examples with python code of compliance with a code style. A positive\\nexample represents compliance with the code style (label is 1). Each example is composed of two components, the first\\ncomponent consists of a code that either conforms to the code style or violates it and the second component\\ncorresponding to an example code that already conforms to a code style. In total, the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/infinityofspace/python_codestyles-single-500."},
	{"name":"python_codestyles-mixed1-500","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/infinityofspace/python_codestyles-mixed1-500","creator_name":"infinityofspace","creator_url":"https://huggingface.co/infinityofspace","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"python_codestyles-mixed1-500\\\"\\n\\t\\n\\nThis dataset contains negative and positive examples with python code of compliance with a code style. A positive\\nexample represents compliance with the code style (label is 1). Each example is composed of two components, the first\\ncomponent consists of a code that either conforms to the code style or violates it and the second component\\ncorresponding to an example code that already conforms to a code style.\\nThe dataset combines‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/infinityofspace/python_codestyles-mixed1-500."},
	{"name":"python_codestyles-random-1k","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/infinityofspace/python_codestyles-random-1k","creator_name":"infinityofspace","creator_url":"https://huggingface.co/infinityofspace","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"python_codestyles-random-1k\\\"\\n\\t\\n\\nThis dataset contains negative and positive examples with python code of compliance with a code style. A positive\\nexample represents compliance with the code style (label is 1). Each example is composed of two components, the first\\ncomponent consists of a code that either conforms to the code style or violates it and the second component\\ncorresponding to an example code that already conforms to a code style. In total, the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/infinityofspace/python_codestyles-random-1k."},
	{"name":"python_codestyles-single-1k","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/infinityofspace/python_codestyles-single-1k","creator_name":"infinityofspace","creator_url":"https://huggingface.co/infinityofspace","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"python_codestyles-single-1k\\\"\\n\\t\\n\\nThis dataset contains negative and positive examples with python code of compliance with a code style. A positive\\nexample represents compliance with the code style (label is 1). Each example is composed of two components, the first\\ncomponent consists of a code that either conforms to the code style or violates it and the second component\\ncorresponding to an example code that already conforms to a code style. In total, the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/infinityofspace/python_codestyles-single-1k."},
	{"name":"python_codestyles-mixed1-1k","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/infinityofspace/python_codestyles-mixed1-1k","creator_name":"infinityofspace","creator_url":"https://huggingface.co/infinityofspace","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"python_codestyles-mixed1-1k\\\"\\n\\t\\n\\nThis dataset contains negative and positive examples with python code of compliance with a code style. A positive\\nexample represents compliance with the code style (label is 1). Each example is composed of two components, the first\\ncomponent consists of a code that either conforms to the code style or violates it and the second component\\ncorresponding to an example code that already conforms to a code style.\\nThe dataset combines‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/infinityofspace/python_codestyles-mixed1-1k."},
	{"name":"book-train","keyword":"sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VishalCh/book-train","creator_name":"Vishal Choudhary","creator_url":"https://huggingface.co/VishalCh","description":"VishalCh/book-train dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Test_Asosoft_WER","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abdulhade/Test_Asosoft_WER","creator_name":"abdulhady abas abdullah","creator_url":"https://huggingface.co/abdulhade","description":"WER evaluation asosoft test set with large v2 whisper model\\n"},
	{"name":"TinyText","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VatsaDev/TinyText","creator_name":"Vatsa Pandey","creator_url":"https://huggingface.co/VatsaDev","description":"The entire NanoPhi Dataset is at train.jsonl\\nSeparate Tasks Include\\n\\nMath (Metamath, mammoth)\\nCode (Code Search Net)\\nLogic (Open-platypus)\\nRoleplay (PIPPA, RoleplayIO)\\nTextbooks (Tiny-text, Sciphi)\\nTextbook QA (Orca-text, Tiny-webtext)\\n\\n"},
	{"name":"StackOverflow-QA-C-Language-5k","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/StackOverflow-QA-C-Language-5k","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"PS: More data (40k) can be found here Mxode/StackOverflow-QA-C-Language-40k.\\n\\nThis is a collection of ~5000 QA's in C Language from StackOverflow. The data has been initially cleaned, and each response is with Accepted Answer. \\nAll data is <500 in length.\\nThe questions and answers were organized into a one-line format. A sample format is shown below:\\n{\\n    \\\"question\\\": \\\"```\\\\nFILE* file = fopen(some file)\\\\n\\\\npcap_t* pd = pcap_fopen_offline(file)\\\\n\\\\npcap_close(pd)\\\\n\\\\nfclose(file)\\\\n```\\\\n\\\\nThis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mxode/StackOverflow-QA-C-Language-5k."},
	{"name":"glaive-code-assistant-v2","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/glaiveai/glaive-code-assistant-v2","creator_name":"Glaive AI","creator_url":"https://huggingface.co/glaiveai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGlaive-code-assistant-v2\\n\\t\\n\\nGlaive-code-assistant-v2 is a dataset of ~215k code problems and solutions generated using Glaive‚Äôs synthetic data generation platform.\\nThis is built on top of the previous version of the dataset that can be found here\\nTo report any problems or suggestions in the data, join the Glaive discord\\n"},
	{"name":"sql-dataLarge","keyword":"sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VishalCh/sql-dataLarge","creator_name":"Vishal Choudhary","creator_url":"https://huggingface.co/VishalCh","description":"VishalCh/sql-dataLarge dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"VoxCelebSpoof","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MattyB95/VoxCelebSpoof","creator_name":"Matthew Boakes","creator_url":"https://huggingface.co/MattyB95","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVoxCelebSpoof\\n\\t\\n\\nVoxCelebSpoof is a dataset related to detecting spoofing attacks on automatic speaker verification systems. This dataset is part of a broader effort to improve the security of voice biometric systems against various types of spoofing attacks, such as replay attacks, voice synthesis, and voice conversion.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe VoxCelebSpoof dataset includes a range of audio samples from different types of synthesis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MattyB95/VoxCelebSpoof."},
	{"name":"sql-parsed","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VishalCh/sql-parsed","creator_name":"Vishal Choudhary","creator_url":"https://huggingface.co/VishalCh","description":"VishalCh/sql-parsed dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"HyPoradise-v1-GigaSpeech","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PeacefulData/HyPoradise-v1-GigaSpeech","creator_name":"Peaceful Data","creator_url":"https://huggingface.co/PeacefulData","description":"\\nIf you consider this work would be related or useful for your research, please consider to cite the work in EMNLP 2023. Thank you.\\n\\n@inproceedings{radhakrishnan2023whispering,\\n  title={Whispering LLaMA: A Cross-Modal Generative Error Correction Framework for Speech Recognition},\\n  author={Srijith Radhakrishnan, Chao-Han Huck Yang, Sumeer Ahmad Khan, Rohit Kumar, Narsis A. Kiani, David Gomez-Cabrero, Jesper N. Tegner},\\n  booktitle={Proc. of EMNLP},\\n  year={2023}\\n}\\n\\n"},
	{"name":"Synthetic_Voice_Detection_Resources","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MattyB95/Synthetic_Voice_Detection_Resources","creator_name":"Matthew Boakes","creator_url":"https://huggingface.co/MattyB95","description":"MattyB95/Synthetic_Voice_Detection_Resources dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sql-parsed","keyword":"context-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VishalCh/sql-parsed","creator_name":"Vishal Choudhary","creator_url":"https://huggingface.co/VishalCh","description":"VishalCh/sql-parsed dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sql-parsed","keyword":"sqlglot","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VishalCh/sql-parsed","creator_name":"Vishal Choudhary","creator_url":"https://huggingface.co/VishalCh","description":"VishalCh/sql-parsed dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sql-parsed","keyword":"wikisql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VishalCh/sql-parsed","creator_name":"Vishal Choudhary","creator_url":"https://huggingface.co/VishalCh","description":"VishalCh/sql-parsed dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sql-parsed","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VishalCh/sql-parsed","creator_name":"Vishal Choudhary","creator_url":"https://huggingface.co/VishalCh","description":"VishalCh/sql-parsed dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sql-parsed","keyword":"sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VishalCh/sql-parsed","creator_name":"Vishal Choudhary","creator_url":"https://huggingface.co/VishalCh","description":"VishalCh/sql-parsed dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sql-parsed","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VishalCh/sql-parsed","creator_name":"Vishal Choudhary","creator_url":"https://huggingface.co/VishalCh","description":"VishalCh/sql-parsed dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"multi-task-instruction","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nmd2k/multi-task-instruction","creator_name":"Nguyen Manh Dung","creator_url":"https://huggingface.co/nmd2k","description":"nmd2k/multi-task-instruction dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Parquet_FIles","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iix/Parquet_FIles","creator_name":"-","creator_url":"https://huggingface.co/iix","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tParquet_Files\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCross Language (CL) Datasets\\n\\t\\n\\nFour datasets of language pair translations originating from CORDIS Project News (https://elrc-share.eu/)\\nStructured as follows:\\n\\n| Field           | Description                                                             |\\n| --------------- | ----------------------------------------------------------------------- |\\n| de/es/fr/it     | Non-English transcripts of sentences                                    |\\n| en‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iix/Parquet_FIles."},
	{"name":"for-test","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ziqin/for-test","creator_name":"yiziqin","creator_url":"https://huggingface.co/ziqin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFor TEST\\n\\t\\n\\nthis is a dataset for test\\njust for test...\\n"},
	{"name":"testing","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/1NightRaid1/testing","creator_name":"ruixiangding","creator_url":"https://huggingface.co/1NightRaid1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/1NightRaid1/testing."},
	{"name":"snd_eng","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/samiesam/snd_eng","creator_name":"Usama Naveed","creator_url":"https://huggingface.co/samiesam","description":"\\ntask_categories:\\n\\ntranslation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset for project snd_to_eng.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe BCP-47 code for the dataset's language is unk.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Fields\\n\\t\\n\\nThe dataset has the following fields (also called \\\"features\\\"):\\n{\\n  \\\"feat_id\\\": \\\"Value(dtype='int64', id=None)\\\",\\n  \\\"feat_source_lang\\\": \\\"Value(dtype='string', id=None)\\\",\\n  \\\"feat_target_lang\\\": \\\"Value(dtype='string', id=None)\\\",\\n  \\\"source\\\": \\\"Value(dtype='string', id=None)\\\",\\n  \\\"target\\\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/samiesam/snd_eng."},
	{"name":"CodeAlpaca_20k_NoBlanks","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PsiPi/CodeAlpaca_20k_NoBlanks","creator_name":"œàœÄ.com","creator_url":"https://huggingface.co/PsiPi","description":"Just a repost of the upstream with \\\" records elided\\n"},
	{"name":"PascalQnA100","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PsiPi/PascalQnA100","creator_name":"œàœÄ.com","creator_url":"https://huggingface.co/PsiPi","description":"100 Pascal Q and A\\n60% with an input string of some kind\\n"},
	{"name":"docs-python-v1","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ASHu2/docs-python-v1","creator_name":"Ashutosh Mishra","creator_url":"https://huggingface.co/ASHu2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for creating python docs from methods. This is formatted from semeru/code-code-galeras-code-completion-from-docstring-3k-deduped\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: semeru/code-code-galeras-code-completion-from-docstring-3k-deduped\\nLanguage(s) (NLP): Python\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ASHu2/docs-python-v1."},
	{"name":"Dummy","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AdiOO7/Dummy","creator_name":"Aditya Singh","creator_url":"https://huggingface.co/AdiOO7","description":"AdiOO7/Dummy dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"coco_image_extract","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iix/coco_image_extract","creator_name":"-","creator_url":"https://huggingface.co/iix","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModified Coco Dataset Files\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRequired dependencies\\n\\t\\n\\nOpenCV (cv2):\\n\\npip install opencv-python\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\timg_data.psv\\n\\t\\n\\nExtract of the coco dataset containing the following labels: [\\\"airplane\\\", \\\"backpack\\\", \\\"cell phone\\\", \\\"handbag\\\", \\\"suitcase\\\", \\\"knife\\\", \\\"laptop\\\", \\\"car\\\"]\\nStructured as follows:\\n\\n| Field           | Description                                                                                         |\\n| --------------- |‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iix/coco_image_extract."},
	{"name":"mini_coco_linux","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iix/mini_coco_linux","creator_name":"-","creator_url":"https://huggingface.co/iix","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmini coco dataset files\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRequired dependencies\\n\\t\\n\\nOpenCV (cv2)\\n\\nmatplotlib\\n\\nipywidgets\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\timg_data.psv\\n\\t\\n\\nExtract of the coco dataset containing the following labels: [\\\"airplane\\\", \\\"backpack\\\", \\\"cell phone\\\", \\\"handbag\\\", \\\"suitcase\\\", \\\"knife\\\", \\\"laptop\\\", \\\"car\\\"]  (300 of each)\\nStructured as follows:\\n\\n| Field           | Description                                                                                         |\\n| --------------- |‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iix/mini_coco_linux."},
	{"name":"Labyrinth","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pnkvalavala/Labyrinth","creator_name":"Pavan Narasimha Karthik","creator_url":"https://huggingface.co/pnkvalavala","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLabyrinth Dataset\\n\\t\\n\\nLabyrinth is a code dataset that combines three existing datasets without modifying the data itself but adapting the structure/format to streamline fine-tuning for Zephyr on code.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\nLabyrinth is composed of code examples and instructions from the following three datasets:\\n\\nCodeAlpaca by Sahil Chaudhary.\\nCodegen-instruct by Teknium.\\nllama-2-instruct-121k-code by Davut Emre TASAR.\\n\\n"},
	{"name":"apps_rlaif","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nmd2k/apps_rlaif","creator_name":"Nguyen Manh Dung","creator_url":"https://huggingface.co/nmd2k","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAPPS Dataset for Reinforcement Learning with AI Feedback\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nAPPS_RLAIF is an extended work from APPS [1] \\nto use Chat LLMs to create multiple variances for each solution for defined problems. \\nIn each solution, we use LLama 34B [2] to transform the original solutions into variances and rank them by score.\\nThe generated flow is demonstrated as below; each variance is created based on the previous version of it in the chat. \\nWe iterated each solutions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nmd2k/apps_rlaif."},
	{"name":"code_contests_instruct","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BEE-spoke-data/code_contests_instruct","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code_contests_instruct\\\"\\n\\t\\n\\nThe deepmind/code_contests dataset formatted as markdown-instruct for text generation training.\\nThere are several different configs. Look at them. Comments:\\n\\nflesch_reading_ease is computed on the description col via textstat\\nhq means that python2 (aka PYTHON in language column) is dropped, and keeps only rows with flesch_reading_ease  75 or greater\\nmin-cols drops all cols except language and text\\npossible values for language are {'CPP'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BEE-spoke-data/code_contests_instruct."},
	{"name":"openai-humaneval-sky-shadow","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Miaosen/openai-humaneval-sky-shadow","creator_name":"Miaosen Zhang","creator_url":"https://huggingface.co/Miaosen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShadow Humaneval dataset\\n\\t\\n\\nThis dataset is generated by GPT-4 to mimic openai-humaneval dataset. Each problem of HumanEval has a corresponding shadow problem in this dataset.\\nThe usage of this dataset is to check Whether a code generation model has data leakage during its training progress. You can refer to Skywork for further details.\\n"},
	{"name":"HTML-correction-examples","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/arhamk/HTML-correction-examples","creator_name":"Arham","creator_url":"https://huggingface.co/arhamk","description":"arhamk/HTML-correction-examples dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sql-create-context-id","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detakarang/sql-create-context-id","creator_name":"Gede Putra Nugraha","creator_url":"https://huggingface.co/detakarang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is a fork from sql-create-context \\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/detakarang/sql-create-context-id."},
	{"name":"sql-create-context-id","keyword":"context-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detakarang/sql-create-context-id","creator_name":"Gede Putra Nugraha","creator_url":"https://huggingface.co/detakarang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is a fork from sql-create-context \\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/detakarang/sql-create-context-id."},
	{"name":"gafoart","keyword":"postgresql","license":"PostgreSQL License","license_url":"https://choosealicense.com/licenses/postgresql/","language":"en","dataset_url":"https://huggingface.co/datasets/gafoart/gafoart","creator_name":"Cesar Rodriguez","creator_url":"https://huggingface.co/gafoart","description":"gafoart/gafoart dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sql-create-context-id","keyword":"sqlglot","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detakarang/sql-create-context-id","creator_name":"Gede Putra Nugraha","creator_url":"https://huggingface.co/detakarang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is a fork from sql-create-context \\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/detakarang/sql-create-context-id."},
	{"name":"sql-create-context-id","keyword":"wikisql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detakarang/sql-create-context-id","creator_name":"Gede Putra Nugraha","creator_url":"https://huggingface.co/detakarang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is a fork from sql-create-context \\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/detakarang/sql-create-context-id."},
	{"name":"sql-create-context-id","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detakarang/sql-create-context-id","creator_name":"Gede Putra Nugraha","creator_url":"https://huggingface.co/detakarang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is a fork from sql-create-context \\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/detakarang/sql-create-context-id."},
	{"name":"sql-create-context-id","keyword":"sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detakarang/sql-create-context-id","creator_name":"Gede Putra Nugraha","creator_url":"https://huggingface.co/detakarang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is a fork from sql-create-context \\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/detakarang/sql-create-context-id."},
	{"name":"sql-create-context-id","keyword":"text-to-sql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detakarang/sql-create-context-id","creator_name":"Gede Putra Nugraha","creator_url":"https://huggingface.co/detakarang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is a fork from sql-create-context \\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/detakarang/sql-create-context-id."},
	{"name":"EasyReddit","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tonic/EasyReddit","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"\\n\\t\\n\\t\\t\\n\\t\\tüôãüèª‚Äç‚ôÇÔ∏èWelcome to üßëüèª‚ÄçüöÄTonic'süöÄüö∞Easyüî¥Redditüî•!\\n\\t\\n\\n\\nThis is every \\\"best reddit_question_best_answers\\\" appended and produced according to the following template :\\n{\\\"prompt\\\": \\\"This is the first prompt\\\", \\\"completion\\\": \\\"This is the first completion\\\"}\\n{\\\"prompt\\\": \\\"This is the second prompt\\\", \\\"completion\\\": \\\"This is the second completion\\\"}\\n\\n\\n\\nüåü You can use it in shards or all together !\\n\\nüåü This dataset is internally consistent !\\n\\n\\nü§îThe point is to make it easy to train models with a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tonic/EasyReddit."},
	{"name":"Youtube_Links","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Decre99/Youtube_Links","creator_name":"De","creator_url":"https://huggingface.co/Decre99","description":"Decre99/Youtube_Links dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Test_Youtube","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Decre99/Test_Youtube","creator_name":"De","creator_url":"https://huggingface.co/Decre99","description":"Decre99/Test_Youtube dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Test_Youtube_Links","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Innovina/Test_Youtube_Links","creator_name":"Innovina","creator_url":"https://huggingface.co/Innovina","description":"Innovina/Test_Youtube_Links dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ikomia_doc_1","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AllanOuii/ikomia_doc_1","creator_name":"K","creator_url":"https://huggingface.co/AllanOuii","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AllanOuii/ikomia_doc_1."},
	{"name":"Test2","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Innovina/Test2","creator_name":"Innovina","creator_url":"https://huggingface.co/Innovina","description":"Innovina/Test2 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"strike-T1","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hsienchen/strike-T1","creator_name":"hsien chen","creator_url":"https://huggingface.co/hsienchen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStrike-T1\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdataset_info:\\n  features:\\n  - name: image\\n    dtype: image\\n  - name: cr\\n    dtype: int64\\n  splits:\\n  - name: train\\n    num_bytes: 162832.0\\n    num_examples: 12\\n  download_size: 70261\\n  dataset_size: 162832.0\\nconfigs:\\n- config_name: default\\n  data_files:\\n  - split: train\\n    path: data/train-*\\n\\t\\n\\n"},
	{"name":"blender_duplicates","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mano-wii/blender_duplicates","creator_name":"Germano Cavalcante de Sousa","creator_url":"https://huggingface.co/mano-wii","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nContains reduced description of issues reported at https://projects.blender.org/blender/blender/issues and points to duplicate issues in order to categorize similarity.\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEach report has been shortened by removing frequently repeated texts such as System Information, Blender‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mano-wii/blender_duplicates."},
	{"name":"stackoverflowVQA-filtered","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mirzaei2114/stackoverflowVQA-filtered","creator_name":"Motahhare Mirzaei","creator_url":"https://huggingface.co/mirzaei2114","description":"mirzaei2114/stackoverflowVQA-filtered dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"lca-bug-localization","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JetBrains-Research/lca-bug-localization","creator_name":"JetBrains Research","creator_url":"https://huggingface.co/JetBrains-Research","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüèüÔ∏è Long Code Arena (Bug localization)\\n\\t\\n\\nThis is the benchmark for the Bug localization task as part of the\\nüèüÔ∏è Long Code Arena benchmark.\\nThe bug localization problem can be formulated as follows: given an issue with a bug description and a repository snapshot in a state where the bug is reproducible, identify the files within the repository that need to be modified to address the reported bug.\\nThe dataset provides all the required components for evaluation of bug localization‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JetBrains-Research/lca-bug-localization."},
	{"name":"Handwriting-Recognition-Dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gymprathap/Handwriting-Recognition-Dataset","creator_name":"Gym Prathap","creator_url":"https://huggingface.co/gymprathap","description":"The dataset comprises over four hundred thousand handwritten names obtained from charitable initiatives.\\nCharacter Recognition employs image processing techniques to transform characters present on scanned documents into digital formats. It generally exhibits good performance with machine-printed fonts. Nonetheless, machines still encounter formidable obstacles in accurately identifying handwritten characters due to the vast diversity in individual writing styles.\\nThe total number of first‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gymprathap/Handwriting-Recognition-Dataset."},
	{"name":"code-readability-krod","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/se2p/code-readability-krod","creator_name":"Chair of Software Engineering II, Uni Passau","creator_url":"https://huggingface.co/se2p","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tJava Code Readability Merged & Modified\\n\\t\\n\\nThis dataset contains 69276 Java code snippets along with a readability score, mined from Github and automatically processed and labelled.\\nYou can download the dataset using Hugging Face:\\nfrom datasets import load_dataset\\nds = load_dataset(\\\"se2p/code-readability-krod\\\")\\n\\nThe snippets are not split into train and test (and validation) set. Thus, the whole dataset is in the train set:\\nds = ds['train']\\nds_as_list = ds.to_list() # Convert the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/se2p/code-readability-krod."},
	{"name":"Pdf","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Decre99/Pdf","creator_name":"De","creator_url":"https://huggingface.co/Decre99","description":"Decre99/Pdf dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"code-readability-krod","keyword":"java","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/se2p/code-readability-krod","creator_name":"Chair of Software Engineering II, Uni Passau","creator_url":"https://huggingface.co/se2p","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tJava Code Readability Merged & Modified\\n\\t\\n\\nThis dataset contains 69276 Java code snippets along with a readability score, mined from Github and automatically processed and labelled.\\nYou can download the dataset using Hugging Face:\\nfrom datasets import load_dataset\\nds = load_dataset(\\\"se2p/code-readability-krod\\\")\\n\\nThe snippets are not split into train and test (and validation) set. Thus, the whole dataset is in the train set:\\nds = ds['train']\\nds_as_list = ds.to_list() # Convert the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/se2p/code-readability-krod."},
	{"name":"methods2test","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/andstor/methods2test","creator_name":"Andr√© Storhaug","creator_url":"https://huggingface.co/andstor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMicrosoft created the methods2test dataset, consisting of Java Junit test cases with its corresponding focal methods. \\nIt contains 780k pairs of JUnit test cases and focal methods which were extracted from a total of 91K\\nJava open source project hosted on GitHub.\\nThis is an assembled version of the methods2test dataset. It provides convenient access to the different context levels based on the raw source code (e.g. newlines are preserved). The test cases and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andstor/methods2test."},
	{"name":"manimation","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mediciresearch/manimation","creator_name":"Medici Research","creator_url":"https://huggingface.co/mediciresearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMedici Animation Instruct Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSmall instruct dataset for animation generation with ManimCE\\n\\t\\n\\n"},
	{"name":"EditPackFT","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nuprl/EditPackFT","creator_name":"Northeastern University Programming Research Lab","creator_url":"https://huggingface.co/nuprl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEditPackFT\\n\\t\\n\\nEditPackFT is a dataset built for training LLMs on the task of instructional code editing. The mail columns are:\\n\\nold_contents the code before the edit\\ninstruction the instruction to transform the before code into the after code\\nnew_contents the code after the edit\\ncontent a pre-formatted training window that can be used to train an LLM with prompts in the format of: <before><instruction><after>\\n\\nThis dataset has been filtered from CommitPackFT. For more detail, see‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuprl/EditPackFT."},
	{"name":"EditPackFT","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nuprl/EditPackFT","creator_name":"Northeastern University Programming Research Lab","creator_url":"https://huggingface.co/nuprl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEditPackFT\\n\\t\\n\\nEditPackFT is a dataset built for training LLMs on the task of instructional code editing. The mail columns are:\\n\\nold_contents the code before the edit\\ninstruction the instruction to transform the before code into the after code\\nnew_contents the code after the edit\\ncontent a pre-formatted training window that can be used to train an LLM with prompts in the format of: <before><instruction><after>\\n\\nThis dataset has been filtered from CommitPackFT. For more detail, see‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuprl/EditPackFT."},
	{"name":"CanItEdit","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nuprl/CanItEdit","creator_name":"Northeastern University Programming Research Lab","creator_url":"https://huggingface.co/nuprl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCan It Edit? Evaluating the Ability of Large Language Models to Follow Code Editing Instructions\\n\\t\\n\\nCanItEdit is a benchmark for evaluating LLMs on instructional code editing, the task of updating a program given a natural language instruction. The benchmark contains 105 hand-crafted Python programs with before and after code blocks, two types of natural language instructions (descriptive and lazy), and a hidden test suite.\\nThe dataset‚Äôs dual natural language instructions test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuprl/CanItEdit."},
	{"name":"CanItEdit","keyword":"code-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nuprl/CanItEdit","creator_name":"Northeastern University Programming Research Lab","creator_url":"https://huggingface.co/nuprl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCan It Edit? Evaluating the Ability of Large Language Models to Follow Code Editing Instructions\\n\\t\\n\\nCanItEdit is a benchmark for evaluating LLMs on instructional code editing, the task of updating a program given a natural language instruction. The benchmark contains 105 hand-crafted Python programs with before and after code blocks, two types of natural language instructions (descriptive and lazy), and a hidden test suite.\\nThe dataset‚Äôs dual natural language instructions test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuprl/CanItEdit."},
	{"name":"methods2test","keyword":"java","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/andstor/methods2test","creator_name":"Andr√© Storhaug","creator_url":"https://huggingface.co/andstor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMicrosoft created the methods2test dataset, consisting of Java Junit test cases with its corresponding focal methods. \\nIt contains 780k pairs of JUnit test cases and focal methods which were extracted from a total of 91K\\nJava open source project hosted on GitHub.\\nThis is an assembled version of the methods2test dataset. It provides convenient access to the different context levels based on the raw source code (e.g. newlines are preserved). The test cases and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andstor/methods2test."},
	{"name":"lipreading","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wissemkarous/lipreading","creator_name":"wissem karous","creator_url":"https://huggingface.co/wissemkarous","description":"wissemkarous/lipreading dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"pandas-create-context","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hiltch/pandas-create-context","creator_name":"Or Hiltch","creator_url":"https://huggingface.co/hiltch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is built from sql-create-context, which in itself builds from WikiSQL and Spider.\\nI have used GPT4 to translate the SQL schema into pandas DataFrame schem initialization statements and to translate the SQL queries into pandas queries. \\nThere are 862 examples of natural language queries, pandas DataFrame creation statements, and pandas query answering the question using the DataFrame creation statement as context. This dataset was built with text-to-pandas‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hiltch/pandas-create-context."},
	{"name":"ja-stackoverflow","keyword":"programming","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/p1atdev/ja-stackoverflow","creator_name":"Plat","creator_url":"https://huggingface.co/p1atdev","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tja-stackoverflow\\n\\t\\n\\nÊó•Êú¨Ë™ûÁâà Stack Overflow „ÅÆ „Çπ„Çø„ÉÉ„ÇØ„Éª„Ç™„Éº„Éê„Éº„Éï„É≠„Éº „ÅÆ„Éá„Éº„Çø„ÉÄ„É≥„Éó „Çí„ÇÇ„Å®„Å´„Éá„Éº„Çø„ÇíÂä†Â∑•„Åó„ÄÅË≥™ÂïèÊñá„Å®ÂõûÁ≠îÊñá„ÅÆ„Éö„Ç¢„Å´„Å™„Çã„Çà„ÅÜ„Å´Ë™øÊï¥„Åó„Åü QA „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t„Éá„Éº„ÇøÊßãÈÄ†\\n\\t\\n\\nÊäïÁ®øÊú¨Êñá„ÅØ html2text „Çí‰Ωø„Å£„Å¶„Éû„Éº„ÇØ„ÉÄ„Ç¶„É≥Âåñ„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åù„ÅÆÈöõ„ÄÅ\\n\\n„Ç≥„Éº„Éâ„Éñ„É≠„ÉÉ„ÇØ„ÅØ ``` „ÅßÂõ≤„Åæ„Çå„Çã„Çà„ÅÜ„Å´Â§âÊõ¥„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\nÁîªÂÉè URL „Å´ base64 „Ç®„É≥„Ç≥„Éº„Éâ„Åï„Çå„ÅüÁîªÂÉè„ÅåÂê´„Åæ„Çå„ÇãÂ†¥Âêà„ÄÅ [unk] „Å´ÁΩÆ„ÅçÊèõ„Åà„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdefault „Çµ„Éñ„Çª„ÉÉ„Éà\\n\\t\\n\\n\\nid: Ë≥™ÂïèÊäïÁ®ø„ÅÆ ID\\nquestion: Ë≥™ÂïèÊäïÁ®ø\\nanswers: Ë≥™Âïè„Å´ÂØæ„Åô„ÇãÂõûÁ≠îÊäïÁ®ø„ÅÆ„É™„Çπ„Éà\\naccepted_answer_id: Ë≥™ÂïèËÄÖ„Å´ÈÅ∏„Å∞„Çå„ÅüÂõûÁ≠î„ÅÆID„ÄÇnull „ÅÆÂèØËÉΩÊÄß„Åå„ÅÇ„Çã\\npopular_answer_id: „ÇÇ„Å£„Å®„ÇÇ„Çπ„Ç≥„Ç¢„ÅåÈ´ò„Åã„Å£„ÅüÂõûÁ≠î„ÅÆID„ÄÇnull „ÅÆÂèØËÉΩÊÄß„Åå„ÅÇ„Çã\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsimple „Çµ„Éñ„Çª„ÉÉ„Éà\\n\\t\\n\\ndefault „Çµ„Éñ„Çª„ÉÉ„Éà„Åã„Çâ„ÄÅ question‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/p1atdev/ja-stackoverflow."},
	{"name":"pandas-create-context","keyword":"wikisql","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hiltch/pandas-create-context","creator_name":"Or Hiltch","creator_url":"https://huggingface.co/hiltch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is built from sql-create-context, which in itself builds from WikiSQL and Spider.\\nI have used GPT4 to translate the SQL schema into pandas DataFrame schem initialization statements and to translate the SQL queries into pandas queries. \\nThere are 862 examples of natural language queries, pandas DataFrame creation statements, and pandas query answering the question using the DataFrame creation statement as context. This dataset was built with text-to-pandas‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hiltch/pandas-create-context."},
	{"name":"pandas-create-context","keyword":"spider","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hiltch/pandas-create-context","creator_name":"Or Hiltch","creator_url":"https://huggingface.co/hiltch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is built from sql-create-context, which in itself builds from WikiSQL and Spider.\\nI have used GPT4 to translate the SQL schema into pandas DataFrame schem initialization statements and to translate the SQL queries into pandas queries. \\nThere are 862 examples of natural language queries, pandas DataFrame creation statements, and pandas query answering the question using the DataFrame creation statement as context. This dataset was built with text-to-pandas‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hiltch/pandas-create-context."},
	{"name":"methods2test_small","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/andstor/methods2test_small","creator_name":"Andr√© Storhaug","creator_url":"https://huggingface.co/andstor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMicrosoft created the methods2test dataset, consisting of Java Junit test cases with their corresponding focal methods. \\nIt contains 780k pairs of JUnit test cases and focal methods which were extracted from a total of 91K Java open-source projects hosted on GitHub.\\nThis is a smaller subset of the assembled version of the methods2test dataset.\\nIt provides convenient access to the different context levels based on the raw source code (e.g. newlines are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andstor/methods2test_small."},
	{"name":"Q_and_A_Google_devices","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aashi/Q_and_A_Google_devices","creator_name":"Aashi Dutt","creator_url":"https://huggingface.co/Aashi","description":"Aashi/Q_and_A_Google_devices dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Vezora-Tested-22k-Python-Alpaca-ru","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MexIvanov/Vezora-Tested-22k-Python-Alpaca-ru","creator_name":"Mex Ivanov","creator_url":"https://huggingface.co/MexIvanov","description":"A machine translated version of the Vezora/Tested-22k-Python-Alpaca dataset.\\nConsists of code \\\"Filtered Using Vezora's CodeTester\\\" with code-related data and natural language instructions.\\nReleased under the same license as the original dataset, provided as is with research intent, use/read at your own risk.\\n"},
	{"name":"openai-formate-function-calling-small","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Deepexi/openai-formate-function-calling-small","creator_name":"Deepexi Inc","creator_url":"https://huggingface.co/Deepexi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÈõÜÂÜÖÂÆπËØ¥Êòé:\\n\\t\\n\\nÂåÖÂê´700+‰∏™ÈòøÈáå‰∫ëOpenAPIÁöÑ‰ø°ÊÅØ;ÂåÖÊã¨Dataworks,EMRÔºåDataLakeÔºåMaxcomputeÔºåHologram,ÂÆûÊó∂ËÆ°ÁÆóFlinkÁâàÔºåQuickBI,DTSÁ≠âÂ§ö‰∏™‰∫ßÂìÅÁöÑÂÖ¨ÂºÄOpen API‰ø°ÊÅØ„ÄÇ\\n Functions‰ø°ÊÅØ‰∏éOpenAI functions calling ËÉΩÂäõ‰∏≠Ôºåfunctions‰ø°ÊÅØ‰º†ÂÖ•ÁöÑÊ†ºÂºè‰øùÊåÅ‰∏ÄËá¥ \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊ†∑‰æã\\n\\t\\n\\n{\\n  \\\"systemPrompt\\\": ‰Ω†ÊòØ‰∏Ä‰∏™ÂáΩÊï∞Á≠õÈÄâÂä©ÁêÜÔºåÂ¶ÇÊûú‰∏éÈóÆÈ¢òÁõ∏ÂÖ≥ÁöÑËØù,ÊÇ®ÂèØ‰ª•‰ΩøÁî®‰∏ãÈù¢ÁöÑÂáΩÊï∞Êù•Ëé∑ÂèñÊõ¥Â§öÊï∞ÊçÆ‰ª•ÂõûÁ≠îÁî®Êà∑ÊèêÂá∫ÁöÑÈóÆÈ¢ò:{\\\"name\\\": \\\"UpdateTicketNum\\\", \\\"description\\\": \\\"ÂØπÁî®‰∫éÂÖçÁôªÂµåÂÖ•Êä•Ë°®ÁöÑÊåáÂÆöÁöÑticketËøõË°åÊõ¥Êñ∞Á•®ÊçÆÊï∞ÈáèÊìç‰Ωú„ÄÇ\\\", \\\"parameters\\\": {\\\"type\\\": \\\"object\\\", \\\"properties\\\": [{\\\"Ticket\\\": {\\\"type\\\": \\\"string\\\", \\\"description\\\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Deepexi/openai-formate-function-calling-small."},
	{"name":"starcoderdatasetnew","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/haris001/starcoderdatasetnew","creator_name":"Demo Hugging","creator_url":"https://huggingface.co/haris001","description":"haris001/starcoderdatasetnew dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"jsoncodes","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/haris001/jsoncodes","creator_name":"Demo Hugging","creator_url":"https://huggingface.co/haris001","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haris001/jsoncodes."},
	{"name":"methods2test_small","keyword":"java","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/andstor/methods2test_small","creator_name":"Andr√© Storhaug","creator_url":"https://huggingface.co/andstor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMicrosoft created the methods2test dataset, consisting of Java Junit test cases with their corresponding focal methods. \\nIt contains 780k pairs of JUnit test cases and focal methods which were extracted from a total of 91K Java open-source projects hosted on GitHub.\\nThis is a smaller subset of the assembled version of the methods2test dataset.\\nIt provides convenient access to the different context levels based on the raw source code (e.g. newlines are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andstor/methods2test_small."},
	{"name":"Vezora-Tested-22k-Python-Alpaca-ru","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MexIvanov/Vezora-Tested-22k-Python-Alpaca-ru","creator_name":"Mex Ivanov","creator_url":"https://huggingface.co/MexIvanov","description":"A machine translated version of the Vezora/Tested-22k-Python-Alpaca dataset.\\nConsists of code \\\"Filtered Using Vezora's CodeTester\\\" with code-related data and natural language instructions.\\nReleased under the same license as the original dataset, provided as is with research intent, use/read at your own risk.\\n"},
	{"name":"Code-74k-ShareGPT-Vicuna","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cognitivecomputations/Code-74k-ShareGPT-Vicuna","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","description":"Code-74k-ShareGPT-Vicuna\\nThis dataset is in Vicuna/ShareGPT format. There are around 74000 set of conversations. Each set having 2 conversations. \\nPython, Java, JavaScript, GO, C++, Rust etc. code with detailed explanation are provided. \\nThis dataset has around 60~65% of Python code. \\n"},
	{"name":"eidas","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/javatask/eidas","creator_name":"Andrii Melashchenko","creator_url":"https://huggingface.co/javatask","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\teIDAS Terminology Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe EiDAS Terminology dataset is a comprehensive collection of terms and abbreviations related to electronic identification and trust services for electronic transactions in the European Single Market (eIDAS). This dataset provides clear definitions and explanations of various terms, making it an essential resource for researchers and practitioners in digital identity and security.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/javatask/eidas."},
	{"name":"Julia-Proof-Pile-2","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Julia-Proof-Pile-2","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Julia-Proof-Pile-2\\nThis dataset is part of Proof-Pile-2 dataset. This dataset is consisting of mathematical code, including numerical computing, computer algebra, and formal mathematics.\\nThis entire dataset is in Julia language. It is slightly more than 0.5 Billion tokens. I have removed Meta data from this dataset hence you can directly use it for training purpose.\\nThis dataset is in Jsonl format.\\n"},
	{"name":"advent-of-code","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/isavita/advent-of-code","creator_name":"Aleksandar Dimov","creator_url":"https://huggingface.co/isavita","description":"This dataset contains solutions and related data for Advent of Code challenges, starting with the year 2015. It includes tasks, inputs, answers, solution codes, and the programming languages used for the solutions."},
	{"name":"CodegebraGPT_data","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sr5434/CodegebraGPT_data","creator_name":"Samir R.","creator_url":"https://huggingface.co/sr5434","description":"A collection of datasets for finetuning LLMs on STEM related tasks. The dataset is formatted in the LLaVA finetuning format.\\n"},
	{"name":"lcc_csharp","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fasterinnerlooper/lcc_csharp","creator_name":"Shafiq Jetha","creator_url":"https://huggingface.co/fasterinnerlooper","description":"This dataset has been modified from the microsoft/LCC_csharp dataset to provide CodeLLaMa with infilling tasks as per the original fill-in-the-middle paper, were the text that needs to be filled in is moved to the end of the dataset, thus taking advantage of the Generative feature of GPT-style models.\\n"},
	{"name":"presto-athena-txt-2-sql","keyword":"text-to-sql","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cnatale/presto-athena-txt-2-sql","creator_name":"Chris Natale","creator_url":"https://huggingface.co/cnatale","description":"I created this dataset using sqlglot to auto-convert the Spider and Wikisql datasets to Presto syntax, along with running some regex's for additional cleanup.\\nAn example use case is fine-tuning an existing model to respond with Presto/Athena text-to-sql, if it performs well at standard SQL syntax used by the major text to sql training datasets.\\nExample of fine-tuning using this dataset (in this case for Mystral 7b Instruct):\\nimport json\\nimport pandas as pd\\nfrom datasets import Dataset\\n\\ndef‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cnatale/presto-athena-txt-2-sql."},
	{"name":"linguistica_assist","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SiguienteGlobal/linguistica_assist","creator_name":"Siguiente","creator_url":"https://huggingface.co/SiguienteGlobal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SiguienteGlobal/linguistica_assist."},
	{"name":"glaive-code-assistant-v3","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/glaiveai/glaive-code-assistant-v3","creator_name":"Glaive AI","creator_url":"https://huggingface.co/glaiveai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGlaive-code-assistant-v3\\n\\t\\n\\nGlaive-code-assistant-v3 is a dataset of ~1M code problems and solutions generated using Glaive‚Äôs synthetic data generation platform.\\nThis is built on top of the previous version of the dataset that can be found here. This already includes v1 and v2 of the dataset.\\nTo report any problems or suggestions in the data, join the Glaive discord\\n"},
	{"name":"Code-290k-ShareGPT","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajibawa-2023/Code-290k-ShareGPT","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Code-290k-ShareGPT\\nThis dataset is in Vicuna/ShareGPT format. There are around 290000 set of conversations. Each set having 2 conversations. \\nAlong with Python, Java, JavaScript, GO, C++, Rust, Ruby, Sql, MySql, R, Julia, Haskell, etc. code with detailed explanation are provided.\\nThis datset is built upon using my existing Datasets Python-Code-23k-ShareGPT\\nand Code-74k-ShareGPT\\nMy Models Python-Code-13B and Python-Code-33B are trained on Python-Code-23k-ShareGPT.\\nMy Models Code-13B and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ajibawa-2023/Code-290k-ShareGPT."},
	{"name":"Derm-T2IM-Dataset","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MAli-Farooq/Derm-T2IM-Dataset","creator_name":"Muhammad Ali Farooq","creator_url":"https://huggingface.co/MAli-Farooq","description":"\\nThe Dataset6K folder consist of two sub folders which includes Benign and Malignant data samples each having 3k data samples.\\n\\nThe Smart transformation folder consist of three subfolders which inlcudes tiny benign mole, large malignant moles and multiple moles each having advanced skin lesion augmentation results.\\n\\nIf you need to generate more data using Derm-T2IM model it can done by uploading the Derm-T2IM model on stable diffusion GUI which can be cloned from below Github Repo.\\nLink:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MAli-Farooq/Derm-T2IM-Dataset."},
	{"name":"D2A","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/claudios/D2A","creator_name":"Claudio Spiess","creator_url":"https://huggingface.co/claudios","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tD2A: A Dataset Built for AI-Based Vulnerability Detection Methods Using Differential Analysis\\n\\t\\n\\nThis is an unofficial HuggingFace upload of the D2A dataset from \\\"D2A: A Dataset Built for AI-Based Vulnerability Detection Methods Using Differential Analysis\\\". \\\"Test\\\" splits have all labels as -1 as they are not provided.\\nUsage:\\nfrom datasets import load_dataset\\n\\n# Use \\\"code\\\", \\\"code_trace\\\", \\\"function\\\", or \\\"trace\\\" to load the different variants.\\ndataset = load_dataset(\\\"claudios/D2A\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/claudios/D2A."},
	{"name":"AI-Dictionary","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/J0nasW/AI-Dictionary","creator_name":"Jonas Wilinski","creator_url":"https://huggingface.co/J0nasW","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Dictionary Dataset\\n\\t\\n\\nWelcome to the AI Dictionary dataset on HuggingFace. This dataset is a comprehensive tool comprised of 16,665 unique key phrases that describe the whole domain of Artificial Intelligence (AI). It serves both the research community and industry domains, aiding in the identification of radical innovations and uncovering applications of AI in new domains.\\nThis dataset is the result of the research paper \\\"The AI Dictionary: The Foundation for a Text-Based Tool‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/J0nasW/AI-Dictionary."},
	{"name":"py-dpo-v0.1","keyword":"code","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jondurbin/py-dpo-v0.1","creator_name":"Jon Durbin","creator_url":"https://huggingface.co/jondurbin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nDPO dataset meant to enhance python coding abilities.\\nThis dataset uses the excellent https://huggingface.co/datasets/Vezora/Tested-22k-Python-Alpaca dataset as the \\\"chosen\\\" responses, given this dataset was already tested and validated.\\nThe \\\"rejected\\\" values were generated with a mix of airoboros-l2-13b-3.1 and bagel-7b-v0.1.\\nThe rejected values may actually be perfectly fine, but the assumption here is that the values are generally a lower quality than the chosen‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jondurbin/py-dpo-v0.1."},
	{"name":"CodeGen4Libs_RetrievalCodeLib","keyword":"code-generation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FudanSELab/CodeGen4Libs_RetrievalCodeLib","creator_name":"FudanSELab","creator_url":"https://huggingface.co/FudanSELab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for FudanSELab CodeGen4Libs Code Retrieval Library\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the code retrieval library used in the ASE2023 paper titled \\\"CodeGen4Libs: A Two-stage Approach for Library-oriented Code Generation\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAdditional Information\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n@inproceedings{ase2023codegen4libs,\\n  author       = {Mingwei Liu and Tianyong Yang and Yiling Lou and Xueying Du and Ying Wang and and Xin Peng},\\n  title        =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FudanSELab/CodeGen4Libs_RetrievalCodeLib."},
	{"name":"MMMU","keyword":"computer_science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aslessor/MMMU","creator_name":"Alex","creator_url":"https://huggingface.co/aslessor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI)\\n\\t\\n\\nüåê Homepage | ü§ó Dataset | ü§ó Paper | üìñ arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüîîNews\\n\\t\\n\\n\\nüî•[2023-12-04]: Our evaluation server for test set is now availble on EvalAI. We welcome all submissions and look forward to your participation! üòÜ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe introduce MMMU: a new benchmark designed to evaluate multimodal models on massive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aslessor/MMMU."},
	{"name":"Python-Q_A","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HassanSamo/Python-Q_A","creator_name":"Hassan Samo","creator_url":"https://huggingface.co/HassanSamo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Python Q/A pair\\n\\t\\n\\n\\n\\nThis dataset card provides information about the Python Q/A pair dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Python Q/A pair dataset is a preprocessed version of a Python Q/A dataset from StackOverflow, which was originally hosted on Kaggle. The dataset contains high-ranked questions and their corresponding high-ranked answers, sorted from high to low rank.\\n\\nCurated by: [More Information Needed]\\nFunded by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HassanSamo/Python-Q_A."},
	{"name":"zenn-articles-20240115","keyword":"code","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/p1atdev/zenn-articles-20240115","creator_name":"Plat","creator_url":"https://huggingface.co/p1atdev","description":"Dataset of URLs of articles on Zenn (zenn.dev)\\n"},
	{"name":"Turkish-QA","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aixr/Turkish-QA","creator_name":"Aixr AI","creator_url":"https://huggingface.co/Aixr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAixr T√ºrk√ße Veri Seti\\n\\t\\n\\nAixr tarafƒ±ndan olu≈üturulan bu veri seti, T√ºrk√ße kaynak arayanlar i√ßin hazƒ±rlanmƒ±≈ütƒ±r. Yazƒ±lƒ±m geli≈ütirme, radyoloji, tƒ±bbi g√∂r√ºnt√ºleme ve diƒüer konularda bilgi saƒülayan bu veri seti, √∂ƒürenme s√ºre√ßlerini kolayla≈ütƒ±rmayƒ± ve T√ºrk√ße dilinde yapay zeka geli≈ütirme s√ºre√ßlerini desteklemeyi hedefler.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVeri Seti Hakkƒ±nda\\n\\t\\n\\nAma√ß:\\nBu veri seti, T√ºrk√ße i√ßerikler arayan ara≈ütƒ±rmacƒ±lar, geli≈ütiriciler ve eƒüitimciler i√ßin bir kaynak olarak tasarlanmƒ±≈ütƒ±r.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aixr/Turkish-QA."},
	{"name":"Turkish-QA","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aixr/Turkish-QA","creator_name":"Aixr AI","creator_url":"https://huggingface.co/Aixr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAixr T√ºrk√ße Veri Seti\\n\\t\\n\\nAixr tarafƒ±ndan olu≈üturulan bu veri seti, T√ºrk√ße kaynak arayanlar i√ßin hazƒ±rlanmƒ±≈ütƒ±r. Yazƒ±lƒ±m geli≈ütirme, radyoloji, tƒ±bbi g√∂r√ºnt√ºleme ve diƒüer konularda bilgi saƒülayan bu veri seti, √∂ƒürenme s√ºre√ßlerini kolayla≈ütƒ±rmayƒ± ve T√ºrk√ße dilinde yapay zeka geli≈ütirme s√ºre√ßlerini desteklemeyi hedefler.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVeri Seti Hakkƒ±nda\\n\\t\\n\\nAma√ß:\\nBu veri seti, T√ºrk√ße i√ßerikler arayan ara≈ütƒ±rmacƒ±lar, geli≈ütiriciler ve eƒüitimciler i√ßin bir kaynak olarak tasarlanmƒ±≈ütƒ±r.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aixr/Turkish-QA."},
	{"name":"RSL_Maran","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran."},
	{"name":"query-parsing-instructions-falcon","keyword":"bug-reporting-automation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EmbeddingStudio/query-parsing-instructions-falcon","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic Search Query Parsing Instruction for Instruct Falcon family\\n\\t\\n\\nThis is the version of EmbeddingStudio/synthetic-search-queries dataset created the way to be aligned with Falcon-7B-Instruct instruction format.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneration details\\n\\t\\n\\nWe used synthetically generated query parsing instructions:\\n\\nWe generated lists of possible filters for 63 customer categories: \\nRaw version of filters dataset\\nSplit by representations\\n\\n\\nSelect randomly up-to 150 possible‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/query-parsing-instructions-falcon."},
	{"name":"synthetic-search-queries","keyword":"bug-reporting-automation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-queries","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic Search Queries\\n\\t\\n\\nThis is generated with GPT-4 Turbo synthetic search queries, that based on the given filters schema for the given business/service categories:\\nEducational Institutions, Job Recruitment Agencies, Banking Services, Investment Services, Insurance Services, Financial Planning and Advisory, Credit Services, Payment Processing, Mortgage and Real Estate Services, Taxation Services, Risk Management and Compliance, Digital and Mobile Banking, Retail Stores‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-queries."},
	{"name":"query-parsing-instructions-falcon","keyword":"collaborative-dev-environments","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EmbeddingStudio/query-parsing-instructions-falcon","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic Search Query Parsing Instruction for Instruct Falcon family\\n\\t\\n\\nThis is the version of EmbeddingStudio/synthetic-search-queries dataset created the way to be aligned with Falcon-7B-Instruct instruction format.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneration details\\n\\t\\n\\nWe used synthetically generated query parsing instructions:\\n\\nWe generated lists of possible filters for 63 customer categories: \\nRaw version of filters dataset\\nSplit by representations\\n\\n\\nSelect randomly up-to 150 possible‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/query-parsing-instructions-falcon."},
	{"name":"synthetic-search-queries","keyword":"collaborative-dev-environments","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-queries","creator_name":"EmbeddingStudio","creator_url":"https://huggingface.co/EmbeddingStudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic Search Queries\\n\\t\\n\\nThis is generated with GPT-4 Turbo synthetic search queries, that based on the given filters schema for the given business/service categories:\\nEducational Institutions, Job Recruitment Agencies, Banking Services, Investment Services, Insurance Services, Financial Planning and Advisory, Credit Services, Payment Processing, Mortgage and Real Estate Services, Taxation Services, Risk Management and Compliance, Digital and Mobile Banking, Retail Stores‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EmbeddingStudio/synthetic-search-queries."},
	{"name":"DafnyGym","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/emugnier/DafnyGym","creator_name":"Eric Mugnier","creator_url":"https://huggingface.co/emugnier","description":"emugnier/DafnyGym dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Lean4-Changelog-QA","keyword":"formal-methods","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/phanerozoic/Lean4-Changelog-QA","creator_name":"Charles Norton","creator_url":"https://huggingface.co/phanerozoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLean 4 Changelog Q&A Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Lean 4 Changelog Q&A Dataset is derived from the Lean4-Changelog. Each Lean 4 changelog entry (including version, section, pull request number, and description) is converted into a single Q&A pair. This allows for straightforward question-answering tasks reflecting the evolution of Lean 4 features, bug fixes, and language decisions over time.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nEach record contains the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-Changelog-QA."},
	{"name":"hanlp_date-zh","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zeroMN/hanlp_date-zh","creator_name":"zeroTT","creator_url":"https://huggingface.co/zeroMN","description":"\\n\\t\\n\\t\\t\\n\\t\\t--\\n2nd International Chinese Word Segmentation Bakeoff - Data Release\\nRelease 1, 2005-11-18\\n\\t\\n\\n\\nIntroduction\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis directory contains the training, test, and gold-standard data\\nused in the 2nd International Chinese Word Segmentation Bakeoff. Also\\nincluded is the script used to score the results submitted by the\\nbakeoff participants and the simple segmenter used to generate the\\nbaseline and topline data.\\n\\t\\n\\n\\nFile List\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tgold/       Contains the gold standard‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zeroMN/hanlp_date-zh."},
	{"name":"ai-chat-dataset","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rahulsingh2103/ai-chat-dataset","creator_name":"Rahul Singh","creator_url":"https://huggingface.co/rahulsingh2103","description":"rahulsingh2103/ai-chat-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"nemo-github-issues","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/renwei2024/nemo-github-issues","creator_name":"Wei Ren","creator_url":"https://huggingface.co/renwei2024","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThis dataset contains 10,000 issues and pull requests along with their associated comments of Nvidia Nemo Github repo.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/renwei2024/nemo-github-issues."},
	{"name":"MX-CHAT","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/berwart/MX-CHAT","creator_name":"Berwart","creator_url":"https://huggingface.co/berwart","description":"MX-CHAT 01\\n"},
	{"name":"Dataset-Tools","keyword":"python","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EarthnDusk/Dataset-Tools","creator_name":"Earth & Dusk","creator_url":"https://huggingface.co/EarthnDusk","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset-Tools: A Simple Dataset Viewer for AI Art\\n\\t\\n\\n\\n\\nHow to use Dataset-Tools\\nLaunching the Application\\nUser Interface Overview\\nImprove the Project\\nHelp the Creators\\n\\n\\n\\n\\t\\n\\t\\t\\nBadge\\nDescription\\n\\n\\n\\t\\t\\nOur Github\\n\\n\\n\\nIndicates the build status of the project.\\n\\n\\n\\nPyTest results.\\n\\n\\n\\nCreative Commons Zero v1.0 Universal (Public Domain Dedication)\\n\\n\\nDiscord Server\\n\\n\\n\\nDuskfallcrew Ko-FI\\n\\n\\n\\nWatch on Twitch\\n\\n\\n\\t\\n\\n\\n\\nDataset-Tools is a desktop application designed to help users browse and manage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EarthnDusk/Dataset-Tools."},
	{"name":"test_01","keyword":"code","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jedgert2/test_01","creator_name":"Joe Edgerton","creator_url":"https://huggingface.co/jedgert2","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jedgert2/test_01."},
	{"name":"nepali_law_datasets","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ashalupreti/nepali_law_datasets","creator_name":"Ashal Upreti","creator_url":"https://huggingface.co/Ashalupreti","description":"\\n\\t\\n\\t\\t\\n\\t\\tüìú Nepali Law Commission Dataset\\n\\t\\n\\nA structured dataset of Nepali legal questions and answers, focusing on the rights of people with disabilities.\\n\\n\\t\\n\\t\\t\\n\\t\\tüìå Overview\\n\\t\\n\\nThis dataset contains questions and answers based on Nepal's legal framework, particularly regarding the rights of persons with disabilities. The dataset is designed for AI/ML applications such as:‚úÖ Legal chatbots‚úÖ Question-answering models‚úÖ Legal document analysis‚úÖ NLP research on Nepali language  \\nThe dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ashalupreti/nepali_law_datasets."},
	{"name":"go-vuln-data","keyword":"go","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vivi365/go-vuln-data","creator_name":"Vivi A","creator_url":"https://huggingface.co/vivi365","description":"\\n\\t\\n\\t\\t\\n\\t\\tgo\\n\\t\\n\\n"},
	{"name":"task2_advanced","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litlsun/task2_advanced","creator_name":"Ekaterina","creator_url":"https://huggingface.co/litlsun","description":"\\n\\t\\n\\t\\t\\n\\t\\t–ó–∞–¥–∞—á–∞ 2: –†–∞–∑–º–µ—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å HF Datasets: —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\\n\\t\\n\\n–†–∞–∑–º–µ—Ç–∫–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –≤ —Ä–∞–º–∫–∞—Ö –∫—É—Ä—Å–∞ –ø–æ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–π –ª–∏–Ω–≥–≤–∏—Å—Ç–∏–∫–µ –ù–ò–£ –í–®–≠ (–°–ü–±).\\n\\n\\t\\n\\t\\t\\n\\t\\t–ü–†–û–í–ï–î–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó\\n\\t\\n\\n–ë—ã–ª –ø–æ—Ä–æ–≤–µ–¥–µ–Ω —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞, –≤–∫–ª—é—á–∞—é—â–∏–π:\\n\\n–ê–Ω–∞–ª–∏–∑ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö\\n–î–æ–ª—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: 0.0032\\n\\n–ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±–∏–≥—Ä–∞–º–º –∏ —Ç—Ä–∏–≥—Ä–∞–º–º\\n\\n\\n\\n\\n\\n–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π: –î–ª–∏–Ω—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —Å–ª–æ–≤ –∏ n-–≥—Ä–∞–º–º\\n\\n–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: 15.82\\n–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–ª–∏–Ω—ã‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/litlsun/task2_advanced."},
	{"name":"Web-dev-large-dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cynnix69/Web-dev-large-dataset","creator_name":"cynnix sinn","creator_url":"https://huggingface.co/cynnix69","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [Cynnix]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cynnix69/Web-dev-large-dataset."},
	{"name":"text-to-command","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/beargos/text-to-command","creator_name":"Valdis Aglonietis","creator_url":"https://huggingface.co/beargos","description":"beargos/text-to-command dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cl-humaneval_v1.0","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kogi-jwu/cl-humaneval_v1.0","creator_name":"Kuramitsu Lab, JWU","creator_url":"https://huggingface.co/kogi-jwu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCL-HumanEval\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCL-HumanEval is a benchmark for evaluating cross-lingual transfer through code generation. \\nIt is based on the code generation benchmark HumanEval.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset contains coding problems in 2 natural languages: English and Japanese.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nfrom datasets import load_dataset\\nload_dataset(\\\"kogi-jwu/cl-humaneval_v1.0\\\", \\\"en\\\")\\n\\nDatasetDict({\\n    test: Dataset({\\n        features: ['task_id'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kogi-jwu/cl-humaneval_v1.0."},
	{"name":"pgsql-performance","keyword":"postgresql","license":"PostgreSQL License","license_url":"https://choosealicense.com/licenses/postgresql/","language":"en","dataset_url":"https://huggingface.co/datasets/wanshenl/pgsql-performance","creator_name":"Wan Shen Lim","creator_url":"https://huggingface.co/wanshenl","description":"wanshenl/pgsql-performance dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"test","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/waitmandot/test","creator_name":"Cau√™ Waitman","creator_url":"https://huggingface.co/waitmandot","description":"waitmandot/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"narrative-function-calling-v1","keyword":"function calling","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/narrative-io/narrative-function-calling-v1","creator_name":"Narrative I/O","creator_url":"https://huggingface.co/narrative-io","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNarrative Function Calling v1\\n\\t\\n\\nWelcome to Narrative Function Calling v1! This dataset is purpose-built for training (or fine-tuning) models that produce consistent, structured function calls in conversation-like settings. The dataset integrates and normalizes data from both Glaive Function Calling v2 (Apache License 2.0) and Salesforce XLAM function calling data (CC-BY-4.0)[^liu2024apigen]. It provides a clean, rich, and comprehensive set of examples that guide large language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/narrative-io/narrative-function-calling-v1."},
	{"name":"sakuraeval-alpha0101","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/myst72/sakuraeval-alpha0101","creator_name":"Miyu Sato","creator_url":"https://huggingface.co/myst72","description":"myst72/sakuraeval-alpha0101 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"retail-shop-enquiries","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythontech9/retail-shop-enquiries","creator_name":"pythontech9","creator_url":"https://huggingface.co/pythontech9","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythontech9/retail-shop-enquiries."},
	{"name":"my-sql-commands","keyword":"postgresql","license":"PostgreSQL License","license_url":"https://choosealicense.com/licenses/postgresql/","language":"en","dataset_url":"https://huggingface.co/datasets/ddedaniel02/my-sql-commands","creator_name":"Daniel Moreno","creator_url":"https://huggingface.co/ddedaniel02","description":"ddedaniel02/my-sql-commands dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"langchain_full","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tony20100/langchain_full","creator_name":"Anthony Vincent","creator_url":"https://huggingface.co/Tony20100","description":"Tony20100/langchain_full dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"QwQ-LongCoT-130K-decontaminated","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/flatlander1024/QwQ-LongCoT-130K-decontaminated","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Decontaminated version of gghfez/QwQ-LongCoT-130K-cleaned that remove the collided data from math/test, gsm8k/test, olympiadbench/test, minerva_math/test, college_math/test, mmlu_stem/test, gaokao, amc23, aime24 and math500.\\nTotal number of rows: 124594\\n"},
	{"name":"langchain_full","keyword":"python","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tony20100/langchain_full","creator_name":"Anthony Vincent","creator_url":"https://huggingface.co/Tony20100","description":"Tony20100/langchain_full dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"aurora_programmer_data","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/naimulislam/aurora_programmer_data","creator_name":"Naimul Islam Nahid","creator_url":"https://huggingface.co/naimulislam","description":"\\n\\t\\n\\t\\t\\n\\t\\tMy Awesome Dataset\\n\\t\\n\\nA comprehensive description of my awesome dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains images of cats and dogs.  The images were collected from [mention data source(s), e.g., a specific website, scraped from the internet]. It is intended for use in image classification tasks.  The dataset consists of [number] images, with approximately [percentage]% allocated to the training set and [percentage]% to the test set. [Add more details about the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/naimulislam/aurora_programmer_data."},
	{"name":"Coding-Agent-Github-2025-Feb","keyword":"coding","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DeepNLP/Coding-Agent-Github-2025-Feb","creator_name":"DeepNLP","creator_url":"https://huggingface.co/DeepNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tCoding Agent AI Agent Directory to Host All Coding Agent related AI Agents Web Traffic Data, Search Ranking, Community, Reviews and More.\\n\\t\\n\\nThis is the Coding Agent Dataset from pypi package \\\"coding_agent\\\" https://pypi.org/project/coding_agent. You can use this package to download and get statistics (forks/stars/website traffic) of AI agents on website from AI Agent Marketplace AI Agent Directory  (http://www.deepnlp.org/store/ai-agent) and AI Agent Search Portal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DeepNLP/Coding-Agent-Github-2025-Feb."},
	{"name":"scicode","keyword":"coding","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Zilinghan/scicode","creator_name":"Zilinghan Li","creator_url":"https://huggingface.co/Zilinghan","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Zilinghan/scicode."},
	{"name":"HumanEval-V-Benchmark","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HumanEval-V/HumanEval-V-Benchmark","creator_name":"HumanEval-V","creator_url":"https://huggingface.co/HumanEval-V","description":"\\n\\t\\n\\t\\t\\n\\t\\tHumanEval-V: Benchmarking High-Level Visual Reasoning with Complex Diagrams in Coding Tasks\\n\\t\\n\\n\\n    üìÑ Paper  ‚Ä¢\\n    üè† Home Page ‚Ä¢\\n    üíª GitHub Repository  ‚Ä¢\\n    üèÜ Leaderboard ‚Ä¢\\n    ü§ó Dataset Viewer \\n\\n\\nHumanEval-V is a novel benchmark designed to evaluate the diagram understanding and reasoning capabilities of Large Multimodal Models (LMMs) in programming contexts. Unlike existing benchmarks, HumanEval-V focuses on coding tasks that require sophisticated visual reasoning over‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HumanEval-V/HumanEval-V-Benchmark."},
	{"name":"Crash_Predictionsv2","keyword":"code","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PratikGanesh/Crash_Predictionsv2","creator_name":"Pratik Ganesh","creator_url":"https://huggingface.co/PratikGanesh","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PratikGanesh/Crash_Predictionsv2."},
	{"name":"AlternateNumbers","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/EscheWang/AlternateNumbers","creator_name":"Wang","creator_url":"https://huggingface.co/EscheWang","description":"This is a dataset for CFG-based GflowNet development.\\nThe ebnf style CFG for numbers are:\\nroot ::= number_list\\n\\nnumber_list ::= number (number_list)?\\n\\nnumber ::= odd even | even odd\\n\\neven ::= \\\"0,\\\" | \\\"2,\\\" | \\\"4,\\\" | \\\"6,\\\" | \\\"8,\\\" | \\\"10,\\\" | \\\"12,\\\" | \\\"14,\\\" | \\\"16,\\\" | \\\"18,\\\" | \\\"20,\\\"\\n\\nodd ::= \\\"1,\\\" | \\\"3,\\\" | \\\"5,\\\" | \\\"7,\\\" | \\\"9,\\\" | \\\"11,\\\" | \\\"13,\\\" | \\\"15,\\\" | \\\"17,\\\" | \\\"19,\\\"\\n\\nHowever, this CFG cannot satisfy all the requirments. The CFG give a chunk of numbers where the transition between chunks always failed to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EscheWang/AlternateNumbers."},
	{"name":"Marathi-matrix","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sonyvakode/Marathi-matrix","creator_name":"sonyvakode","creator_url":"https://huggingface.co/sonyvakode","description":"sonyvakode/Marathi-matrix dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"BoannaTheThird","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Bonana/BoannaTheThird","creator_name":"Adnan Jami","creator_url":"https://huggingface.co/Bonana","description":"Bonana/BoannaTheThird dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CHASE-Code","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/McGill-NLP/CHASE-Code","creator_name":"McGill NLP Group","creator_url":"https://huggingface.co/McGill-NLP","description":"\\n  CHASE: Challenging AI with Synthetic Evaluations\\n\\n\\n\\n  \\n\\n\\n\\nThe pace of evolution of Large Language Models (LLMs) necessitates new approaches for rigorous and comprehensive evaluation. Traditional human annotation is increasingly impracticable due to the complexities and costs involved in generating high-quality, challenging problems. In this work, we introduce **CHASE**, a unified framework to synthetically generate challenging problems using LLMs without human involvement.  For a given task‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/McGill-NLP/CHASE-Code."},
	{"name":"V1Q","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q."},
	{"name":"Synthetic-JP-EN-Coding-Dataset","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-jp/Synthetic-JP-EN-Coding-Dataset","creator_name":"LLM-jp","creator_url":"https://huggingface.co/llm-jp","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthetic-JP-EN-Coding-Dataset\\n\\t\\n\\nThis repository provides an instruction tuning dataset developed by LLM-jp, a collaborative project launched in Japan.\\nThe dataset comprises a subset from Aratako/Synthetic-JP-EN-Coding-Dataset-801k.\\n\\n\\t\\n\\t\\t\\n\\t\\tSend Questions to\\n\\t\\n\\nllm-jp(at)nii.ac.jp\\n\\n\\t\\n\\t\\t\\n\\t\\tModel Card Authors\\n\\t\\n\\nThe names are listed in alphabetical order.\\nHirokazu Kiyomaru and Takashi Kodama.\\n"},
	{"name":"JuNE","keyword":"python","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JetBrains-Research/JuNE","creator_name":"JetBrains Research","creator_url":"https://huggingface.co/JetBrains-Research","description":"\\n\\t\\n\\t\\t\\n\\t\\tJupyter Notebooks Executions (JuNE)\\n\\t\\n\\nThis dataset contains logs of code evolution in Jupyter notebooks, focusing on data science tasks. The data was\\ncollected from participants working on Data Analysis (DA) and Machine Learning (ML) tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\tData collection procedure\\n\\t\\n\\nThe data collection procedure took place in four different locations (two universities and two companies),\\nwe gathered all eligible participants into groups of two to nine people. Each person in the group was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JetBrains-Research/JuNE."},
	{"name":"shootergtu-architecture","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Gray-Time-Kid/shootergtu-architecture","creator_name":"Full Gray","creator_url":"https://huggingface.co/Gray-Time-Kid","description":"\\n\\t\\n\\t\\t\\n\\t\\tShooterGTU Architecture Dataset\\n\\t\\n\\nThis dataset contains a JSON file describing the event-driven architecture\\nof the ShooterGTU game. It includes core managers, scenes, events, and \\ndependencies.\\n\\n\\t\\n\\t\\t\\n\\t\\tFiles\\n\\t\\n\\n\\narchitecture.json: The main JSON with metadata, core components, \\nhierarchy layers, etc.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\nYou can load this dataset using the datasets library:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"username/shootergtu-architecture\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gray-Time-Kid/shootergtu-architecture."},
	{"name":"GPT4-Chat-GRP0","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/naimulislam/GPT4-Chat-GRP0","creator_name":"Naimul Islam Nahid","creator_url":"https://huggingface.co/naimulislam","description":"naimulislam/GPT4-Chat-GRP0 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"PyRe","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/PyRe","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"theprint/PyRe dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"blender_qna","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DeltaSatellite1/blender_qna","creator_name":"Amarion Burks","creator_url":"https://huggingface.co/DeltaSatellite1","description":"raaaa\\n"},
	{"name":"UCP","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Cuizhihao10/UCP","creator_name":"Zhihao","creator_url":"https://huggingface.co/Cuizhihao10","description":"Cuizhihao10/UCP dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"einstein_answers","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aliMohammad16/einstein_answers","creator_name":"Mohammad Ali","creator_url":"https://huggingface.co/aliMohammad16","description":"\\n\\t\\n\\t\\t\\n\\t\\tWhat would Einstein Say?\\n\\t\\n\\nThis dataset contains a set of questions and answers, mimicking Einstein's approach to answer general scientific and philosophical queries. \\nThe data points have been generated synthetically, however the factual correctness of the data is ensured, not guaranteed whatsoever.\\n"},
	{"name":"Roblox-Luau-Reasoning-v1.0","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/boatbomber/Roblox-Luau-Reasoning-v1.0","creator_name":"Zack Ovits","creator_url":"https://huggingface.co/boatbomber","description":"\\n\\t\\n\\t\\t\\n\\t\\tRoblox-Luau-Reasoning-v1.0\\n\\t\\n\\nThis dataset contains prompt->chain of thought+code+explanation for Luau, based on Roblox/luau-corpus.\\nWe take real Luau code from the corpus (cleaned & auto-formatted for best quality) and work backwards to generate a prompt for it. Then, we generate a chain of thought that works from that prompt to reach the code. Finally, we generate an explanation of the code.\\nThis means that we'll be able to fine tune reasoning models (like Deepseek R1) on the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/boatbomber/Roblox-Luau-Reasoning-v1.0."},
	{"name":"astra_grab_floor_toys_smoothed_base_cmd","keyword":"astra","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lookas/astra_grab_floor_toys_smoothed_base_cmd","creator_name":"Haiqin Cui","creator_url":"https://huggingface.co/lookas","description":"This dataset was created using LeRobot.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nmeta/info.json:\\n{\\n    \\\"codebase_version\\\": \\\"v2.0\\\",\\n    \\\"robot_type\\\": null,\\n    \\\"total_episodes\\\": 50,\\n    \\\"total_frames\\\": 73694,\\n    \\\"total_tasks\\\": 1,\\n    \\\"total_videos\\\": 150,\\n    \\\"total_chunks\\\": 1,\\n    \\\"chunks_size\\\": 1000,\\n    \\\"fps\\\": 30,\\n    \\\"splits\\\": {\\n        \\\"train\\\": \\\"0:50\\\"\\n    },\\n    \\\"data_path\\\": \\\"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\\\",\\n    \\\"video_path\\\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lookas/astra_grab_floor_toys_smoothed_base_cmd."},
	{"name":"Meta_Plan_Optimization","keyword":"code","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xwm/Meta_Plan_Optimization","creator_name":"xwm","creator_url":"https://huggingface.co/xwm","description":"\\n\\t\\n\\t\\t\\n\\t\\tMPO Datasets\\n\\t\\n\\nThis folder contains the datasets for the MPO experiments.\\nPaper: https://hf.co/papers/2503.02682\\nCode: https://github.com/WeiminXiong/MPO\\n\\n\\t\\n\\t\\t\\n\\t\\tFile Structure\\n\\t\\n\\nalfworld_metaplan_preference_pairs.json: includes comparison data for the DPO optimization phase of the ALFWorld meta planner.\\nsciworld_metaplan_preference_pairs.json: includes comparison data for the DPO optimization phase of the SciWorld meta planner.\\nalfworld_metaplan_sft.json: includes the metaplan data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xwm/Meta_Plan_Optimization."},
	{"name":"TinyMarkdown-Instruct-EN","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VAMJ-0042/TinyMarkdown-Instruct-EN","creator_name":"Vitor Augusto Machado Jorge","creator_url":"https://huggingface.co/VAMJ-0042","description":"\\n\\t\\n\\t\\t\\n\\t\\tMarkdown Fine-Tuning Datasets (English & PT-BR)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThese datasets are designed to fine-tune Large Language Models (LLMs) like Gemma to generate structured Markdown-formatted responses. The datasets contain instruction-response pairs, ensuring the model learns how to output Markdown elements correctly.\\n\\n\\t\\n\\t\\t\\n\\t\\tDatasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1. English Markdown Dataset\\n\\t\\n\\n\\nAvailable on Hugging Face: TinyMarkdown-Instruct-EN\\nSize: Large-scale dataset with structured Markdown‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VAMJ-0042/TinyMarkdown-Instruct-EN."},
	{"name":"astra_grab_floor_toys","keyword":"astra","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lookas/astra_grab_floor_toys","creator_name":"Haiqin Cui","creator_url":"https://huggingface.co/lookas","description":"This dataset was created using LeRobot.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nmeta/info.json:\\n{\\n    \\\"codebase_version\\\": \\\"v2.0\\\",\\n    \\\"robot_type\\\": null,\\n    \\\"total_episodes\\\": 50,\\n    \\\"total_frames\\\": 73694,\\n    \\\"total_tasks\\\": 1,\\n    \\\"total_videos\\\": 150,\\n    \\\"total_chunks\\\": 1,\\n    \\\"chunks_size\\\": 1000,\\n    \\\"fps\\\": 30,\\n    \\\"splits\\\": {\\n        \\\"train\\\": \\\"0:50\\\"},\\n    \\\"data_path\\\": \\\"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\\\",\\n    \\\"video_path\\\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lookas/astra_grab_floor_toys."},
	{"name":"astra_grab_floor_toys_extended_base_cmd_pos","keyword":"astra","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lookas/astra_grab_floor_toys_extended_base_cmd_pos","creator_name":"Haiqin Cui","creator_url":"https://huggingface.co/lookas","description":"This dataset was created using LeRobot.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nmeta/info.json:\\n{\\n    \\\"codebase_version\\\": \\\"v2.0\\\",\\n    \\\"robot_type\\\": \\\"astra_joint\\\",\\n    \\\"total_episodes\\\": 80,\\n    \\\"total_frames\\\": 113547,\\n    \\\"total_tasks\\\": 1,\\n    \\\"total_videos\\\": 240,\\n    \\\"total_chunks\\\": 1,\\n    \\\"chunks_size\\\": 1000,\\n    \\\"fps\\\": 30,\\n    \\\"splits\\\": {\\n        \\\"train\\\": \\\"0:80\\\"},\\n    \\\"data_path\\\": \\\"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\\\",\\n    \\\"video_path\\\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lookas/astra_grab_floor_toys_extended_base_cmd_pos."},
	{"name":"astra_grab_floor_toys_extended_smoothed_base_cmd","keyword":"astra","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lookas/astra_grab_floor_toys_extended_smoothed_base_cmd","creator_name":"Haiqin Cui","creator_url":"https://huggingface.co/lookas","description":"This dataset was created using LeRobot.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nmeta/info.json:\\n{\\n    \\\"codebase_version\\\": \\\"v2.0\\\",\\n    \\\"robot_type\\\": \\\"astra_joint\\\",\\n    \\\"total_episodes\\\": 80,\\n    \\\"total_frames\\\": 113547,\\n    \\\"total_tasks\\\": 1,\\n    \\\"total_videos\\\": 240,\\n    \\\"total_chunks\\\": 1,\\n    \\\"chunks_size\\\": 1000,\\n    \\\"fps\\\": 30,\\n    \\\"splits\\\": {\\n        \\\"train\\\": \\\"0:80\\\"},\\n    \\\"data_path\\\": \\\"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\\\",\\n    \\\"video_path\\\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lookas/astra_grab_floor_toys_extended_smoothed_base_cmd."},
	{"name":"Java_method2test_chatml","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/random-long-int/Java_method2test_chatml","creator_name":"Long Int","creator_url":"https://huggingface.co/random-long-int","description":"\\n\\t\\n\\t\\t\\n\\t\\tJava Method to Test ChatML\\n\\t\\n\\nThis dataset is based on the methods2test dataset from Microsoft. It follows the ChatML template format: [{'role': '', 'content': ''}, {...}].\\nOriginally, methods2test contains only Java methods at different levels of granularity along with their corresponding test cases. The different focal method segmentations are illustrated here:\\n\\nTo simulate a conversation between a Java developer and an AI assistant, I introduce two key parameters:\\n\\nThe prompt‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/random-long-int/Java_method2test_chatml."},
	{"name":"Java_method2test_chatml","keyword":"java","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/random-long-int/Java_method2test_chatml","creator_name":"Long Int","creator_url":"https://huggingface.co/random-long-int","description":"\\n\\t\\n\\t\\t\\n\\t\\tJava Method to Test ChatML\\n\\t\\n\\nThis dataset is based on the methods2test dataset from Microsoft. It follows the ChatML template format: [{'role': '', 'content': ''}, {...}].\\nOriginally, methods2test contains only Java methods at different levels of granularity along with their corresponding test cases. The different focal method segmentations are illustrated here:\\n\\nTo simulate a conversation between a Java developer and an AI assistant, I introduce two key parameters:\\n\\nThe prompt‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/random-long-int/Java_method2test_chatml."},
	{"name":"merged_bigvul_primevul","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mahdin70/merged_bigvul_primevul","creator_name":"Mukit Mahdin","creator_url":"https://huggingface.co/mahdin70","description":"\\n\\t\\n\\t\\t\\n\\t\\tMerged BigVul and PrimeVul Dataset\\n\\t\\n\\nDataset ID: mahdin70/merged_bigvul_primevul\\nThis dataset is a merged and preprocessed combination of the BigVul (bstee615/bigvul) and PrimeVul (colin/PrimeVul, \\\"default\\\" configuration) datasets, designed for vulnerability analysis and machine learning tasks. The preprocessing ensures consistency in column names, data types, and formats, making it suitable for fine-tuning models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThe dataset integrates vulnerability‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mahdin70/merged_bigvul_primevul."},
	{"name":"secure_code","keyword":"code","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Vayuda/secure_code","creator_name":"Pawan Jayakumar","creator_url":"https://huggingface.co/Vayuda","description":"Vayuda/secure_code dataset hosted on Hugging Face and contributed by the HF Datasets community"}
]
;
