var data_for_code = 
[
	{"name":"c-to-rust","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/yijunyu/c-to-rust","creator_name":"Yu","creator_url":"https://huggingface.co/yijunyu","description":"yijunyu/c-to-rust dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Nepali","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/SunilC/Nepali","creator_name":"Sunil Chaudhary","creator_url":"https://huggingface.co/SunilC","description":"SunilC/Nepali dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cubert_ETHPy150Open","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/claudios/cubert_ETHPy150Open","creator_name":"Claudio Spiess","creator_url":"https://huggingface.co/claudios","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuBERT ETH150 Open Benchmarks\\n\\t\\n\\nThis is an unofficial HuggingFace upload of the CuBERT ETH150 Open Benchmarks. This dataset was released along with Learning and Evaluating Contextual Embedding of Source Code.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBenchmarks and Fine-Tuned Models\\n\\t\\n\\nHere we describe the 6 Python benchmarks we created. All 6 benchmarks were derived from ETH Py150 Open. All examples are stored as sharded text files. Each text line corresponds to a separate example encoded as a JSON object.… See the full description on the dataset page: https://huggingface.co/datasets/claudios/cubert_ETHPy150Open."},
	{"name":"oxford-pets-subset","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/tomfern/oxford-pets-subset","creator_name":"Fernandez","creator_url":"https://huggingface.co/tomfern","description":"tomfern/oxford-pets-subset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"relative-positioning","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/LlameUser/relative-positioning","creator_name":"Antoine Angert","creator_url":"https://huggingface.co/LlameUser","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThis dataset aims to teach LLMs relative positioning (e.g. above, left from, below, etc.), \\nwhich in my findings most LLMs, even SOTA where not able to produce under all circumstances.\\nWill be pushing a fine-tuned mixtral-7x8B with this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nContains Data for relative positioning on a grid(256, 256).\\nAssumes Origin [0, 0] is in the bottom left.\\nTwo Objects (Object 1, Object 2) are… See the full description on the dataset page: https://huggingface.co/datasets/LlameUser/relative-positioning."},
	{"name":"FrontendCookbook","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Tensoic/FrontendCookbook","creator_name":"Tensoic AI","creator_url":"https://huggingface.co/Tensoic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset features a curated collection of questions and answers synthesized to cover key topics in Frontend development. Topics include HTML. CSS, JS, React JS, Next JS in a circullum manner.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCaution\\n\\t\\n\\nThis dataset was generated using Bard, please note that some content may not be entirely precise or reflect expert consensus. \\nUsers are encouraged to verify information independently for scholarly or critical purposes.\\n"},
	{"name":"bitaudit_verification_dataset","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/3it/bitaudit_verification_dataset","creator_name":"Franklin","creator_url":"https://huggingface.co/3it","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/3it/bitaudit_verification_dataset."},
	{"name":"WebSightDescribed","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/haidark1/WebSightDescribed","creator_name":"Haidar Khan","creator_url":"https://huggingface.co/haidark1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WebSightDescribed\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWebSightDescribed is a subset of WebSight v0.1, augmenting the dataset with \\nsynthetically generated natural language descriptions of the websites.\\nThis dataset serves as a valuable resource for the task of generating html code from a natural language description.\\n\\n  Details for WebSightDescribed\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nAn example of a sample appears as follows:\\n{\\n    'image': PIL.Image,\\n    'id': int… See the full description on the dataset page: https://huggingface.co/datasets/haidark1/WebSightDescribed."},
	{"name":"code-review","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/VatsaDev/code-review","creator_name":"Vatsa Pandey","creator_url":"https://huggingface.co/VatsaDev","description":"A Scrape of the codereview stack exchange, good for high quality code\\n"},
	{"name":"openeval","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NTUYG/openeval","creator_name":"Yang Guang","creator_url":"https://huggingface.co/NTUYG","description":"NTUYG/openeval dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"slimorca-dedup-chatml","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Radiantloom/slimorca-dedup-chatml","creator_name":"Radiantloom AI","creator_url":"https://huggingface.co/Radiantloom","description":"This is a chatml formatted version of original SlimOrca-Dedup dataset with few modifications to the system prompts.\\n"},
	{"name":"OpenHermes-2.5-Code-290k","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ajibawa-2023/OpenHermes-2.5-Code-290k","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"OpenHermes-2.5-Code-290k\\nThis dataset is amalgamation of two datasets. I have used OpenHermes-2.5 a super quality dataset made avaliable by teknium.\\nOther datset is my own Code-290k-ShareGPT.\\nThis dataset is in Vicuna/ShareGPT format. There are around 1.29 million set of conversations. \\nI have cleaned the dataset provided by Teknium and removed metadata such as \\\"source\\\" & \\\"category\\\" etc.\\nThis dataset has primarily synthetically generated instruction and chat samples.\\nThis dataset is very… See the full description on the dataset page: https://huggingface.co/datasets/ajibawa-2023/OpenHermes-2.5-Code-290k."},
	{"name":"DABench","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/infiagent/DABench","creator_name":"InfiAgent","creator_url":"https://huggingface.co/infiagent","description":"infiagent/DABench dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Github-PR-BOT","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/SIT-RiSE/Github-PR-BOT","creator_name":"Research in software engineering","creator_url":"https://huggingface.co/SIT-RiSE","description":"\\n  \\n\\n\\ngithub-bot-pr\\n\\nThe PR data for the GitHub Bot PR investigation Study.\\nThe PR Dataset contains three subsets:\\n\\nApache official projects\\nMicrosoft 200 most starred projects\\nGithub 200 most starred java projects\\n\\nThe time frame:\\nMay 1st 2022 -- May 1st 2023\\n"},
	{"name":"general-v-online-llm","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/RealEmmettS/general-v-online-llm","creator_name":"Emmett Shaughnessy","creator_url":"https://huggingface.co/RealEmmettS","description":"RealEmmettS/general-v-online-llm dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ChatML-SlimOrca-Dedup","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Felladrin/ChatML-SlimOrca-Dedup","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"Open-Orca/SlimOrca-Dedup in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"Open-Orca/SlimOrca-Dedup\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = []\\n\\n    conversations = columns[\\\"conversations\\\"]\\n\\n    for i in range(len(conversations)):\\n        message =… See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-SlimOrca-Dedup."},
	{"name":"MMCode","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/likaixin/MMCode","creator_name":"Kaixin Li","creator_url":"https://huggingface.co/likaixin","description":"\\n    \\n    MMCode\\n\\n\\nMMCode Github Repo \\n\\nNote: Please find the files directly via the \\\"Files and versions\\\" panel. Preview is not available. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMMCode is a multi-modal code generation dataset designed to evaluate the problem-solving skills of code language models in visually rich contexts (i.e. images). \\nIt contains 3,548 questions paired with 6,620 images, derived from real-world programming challenges across 10 code competition websites, with Python solutions… See the full description on the dataset page: https://huggingface.co/datasets/likaixin/MMCode."},
	{"name":"SentiMP-En","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rbnuria/SentiMP-En","creator_name":"Nuria Rodríguez Barroso","creator_url":"https://huggingface.co/rbnuria","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentiMP-En Dataset\\n\\t\\n\\nThe SentiMP-En Dataset is an english sentiment analysis dataset based on tweets written by members of parliament in United Kingdom in 2021.  It has been developed collaboratively by the Andalusian Research Institute in Data Science and Computational Intelligence (DaSCI) research  group from the University of Granada, the SINAI research group from the University of Jaén and the Cardiff NLP research group from the University of Cardiff.… See the full description on the dataset page: https://huggingface.co/datasets/rbnuria/SentiMP-En."},
	{"name":"LLM-EvaluationHub","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/strikoder/LLM-EvaluationHub","creator_name":"Mohamad Alamin Yassin","creator_url":"https://huggingface.co/strikoder","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLLM-EvaluationHub: Enhanced Dataset for Large Language Model Assessment\\n\\t\\n\\nThis repository, LLM-EvaluationHub, presents an enhanced dataset tailored for the evaluation and assessment of Large Language Models (LLMs). It builds upon the dataset originally provided by SafetyBench (THU-COAI), incorporating significant modifications and additions to address specific research objectives. Below is a summary of the key differences and enhancements:\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKey Modifications… See the full description on the dataset page: https://huggingface.co/datasets/strikoder/LLM-EvaluationHub."},
	{"name":"Prompts","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/UserIscool/Prompts","creator_name":"John Leo","creator_url":"https://huggingface.co/UserIscool","description":"UserIscool/Prompts dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"test","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ErikQQY/test","creator_name":"QingyuQu","creator_url":"https://huggingface.co/ErikQQY","description":"ErikQQY/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"AIEC-140K","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AgoraX/AIEC-140K","creator_name":"Agora","creator_url":"https://huggingface.co/AgoraX","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAgoraX/AIEC-140K Dataset\\n\\t\\n\\n===============================\\nExcited to Announce AgoraX/AIEC-140K!\\nAn all-new dataset with super high High Quality AI Engineering Code Tokens totaling 140k samples!\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nThe AgoraX/AIEC-140K dataset is a collection of AI engineering code tokens from top research labs such as OpenAI, Nvidia, Google, Lucidrains, and others. These tokens have been scraped from various repositories on GitHub, providing a valuable resource for… See the full description on the dataset page: https://huggingface.co/datasets/AgoraX/AIEC-140K."},
	{"name":"SentiMP-Sp","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rbnuria/SentiMP-Sp","creator_name":"Nuria Rodríguez Barroso","creator_url":"https://huggingface.co/rbnuria","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentiMP-Sp Dataset\\n\\t\\n\\nThe SentiMP-Sp Dataset is a spanish sentiment analysis dataset based on tweets written by members of parliament in Spain in 2021.  It has been developed collaboratively by the Andalusian Research Institute in Data Science and Computational Intelligence (DaSCI) research  group from the University of Granada, the SINAI research group from the University of Jaén and the Cardiff NLP research group from the University of Cardiff.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset details… See the full description on the dataset page: https://huggingface.co/datasets/rbnuria/SentiMP-Sp."},
	{"name":"SentiMP-Gr","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rbnuria/SentiMP-Gr","creator_name":"Nuria Rodríguez Barroso","creator_url":"https://huggingface.co/rbnuria","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentiMP-Gr Dataset\\n\\t\\n\\nThe SentiMP-Gr Dataset is a greek sentiment analysis dataset based on tweets written by members of parliament in United Kingdom in 2021.  It has been developed collaboratively by the Andalusian Research Institute in Data Science and Computational Intelligence (DaSCI) research  group from the University of Granada, the SINAI research group from the University of Jaén and the Cardiff NLP research group from the University of Cardiff.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/rbnuria/SentiMP-Gr."},
	{"name":"data_set_test","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/sg69291/data_set_test","creator_name":"Shubham Gupta","creator_url":"https://huggingface.co/sg69291","description":"This is README file.\\n"},
	{"name":"kittech_shona_dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Kittech/kittech_shona_dataset","creator_name":"Bright Chirindo","creator_url":"https://huggingface.co/Kittech","description":"Kittech/kittech_shona_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Capybara","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AISE-TUDelft/Capybara","creator_name":"AISE research lab at TU Delft","creator_url":"https://huggingface.co/AISE-TUDelft","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Capybara\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDataset used to train BinT5. Please refer to the paper for more information. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n@inproceedings{alkaswan2023extending,\\n  title={Extending Source Code Pre-Trained Language Models to Summarise Decompiled Binaries},\\n  author={Al-Kaswan, Ali and Ahmed, Toufique and Izadi, Maliheh and Sawant, Anand Ashok and Devanbu, Premkumar and van Deursen, Arie},\\n  booktitle={2023 IEEE International… See the full description on the dataset page: https://huggingface.co/datasets/AISE-TUDelft/Capybara."},
	{"name":"hercules-v2.0","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Locutusque/hercules-v2.0","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Hercules-v2.0\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nDataset Name: Hercules-v2.0\\nVersion: 2.0\\nDate of Release: February 2, 2024\\nSize: 1,307,174\\nData Sources: \\nHercules-v2.0 is an enriched instruction dataset derived from OpenHermes-2.5, aimed at enhancing its diversity and scope. The dataset amalgamates contributions from various data sources, with a strong emphasis on Biology, Physics, Medicine, Math, Computer Science, Instruction Following, Function Calling, and Roleplay. The data… See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/hercules-v2.0."},
	{"name":"Evol-Instruct-Code-80k-v1","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Sharathhebbar24/Evol-Instruct-Code-80k-v1","creator_name":"Sharath S Hebbar","creator_url":"https://huggingface.co/Sharathhebbar24","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEvol-Instruct-Code-80k-v1\\n\\t\\n\\nThis is a cleansed version of nickrosh/Evol-Instruct-Code-80k-v1\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"Sharathhebbar24/Evol-Instruct-Code-80k-v1\\\", split=\\\"train\\\")\\n\\n"},
	{"name":"sql-create-context","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Sharathhebbar24/sql-create-context","creator_name":"Sharath S Hebbar","creator_url":"https://huggingface.co/Sharathhebbar24","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSQL Code\\n\\t\\n\\nThis is a cleansed version of b-mc2/sql-create-context\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"Sharathhebbar24/sql-create-context\\\", split=\\\"train\\\")\\n\\n"},
	{"name":"Purr-Data_example_source_codes","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ParZiVal04/Purr-Data_example_source_codes","creator_name":"amrutk","creator_url":"https://huggingface.co/ParZiVal04","description":"Purr-Data Patch Source Code Dataset:\\n\\nThis dataset is designed for training language models to generate source code for Purr-Data patches. It focuses specifically on patches that output a particular message when a \\\"bang\\\" object is clicked.\\n\\nDataset Creation:\\n\\nThe dataset was created with the goal of evaluating the ability of large language models like Google's 2B GEMMA to be fine-tuned for Purr-Data source code generation.\\n\\nDataset Characteristics:\\n\\nContent: Each data point consists of two… See the full description on the dataset page: https://huggingface.co/datasets/ParZiVal04/Purr-Data_example_source_codes."},
	{"name":"hcad_imdb","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Siki-77/hcad_imdb","creator_name":"Qiu Siki","creator_url":"https://huggingface.co/Siki-77","description":"Siki-77/hcad_imdb dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"synthetic-introduction-extraction","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/angelmmiguel/synthetic-introduction-extraction","creator_name":"Angel M De Miguel","creator_url":"https://huggingface.co/angelmmiguel","description":"angelmmiguel/synthetic-introduction-extraction dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ZharfaTech-Open-Platypus-Persian-Farsi","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ZharfaTech/ZharfaTech-Open-Platypus-Persian-Farsi","creator_name":"ZharfaTech","creator_url":"https://huggingface.co/ZharfaTech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPersian Open-Platypus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout ZharfaTech\\n\\t\\n\\nZharfaTech is a pioneer in developing Language Learning Models (LLMs) tailored for the Persian language, aiming to empower over 100 million Persian speakers worldwide. Our mission encompasses bridging the digital divide in LLM-related services like content generation, customer relationship systems, and more, with a dual approach of fostering open-source collaboration and delivering high-value, specialized closed-source… See the full description on the dataset page: https://huggingface.co/datasets/ZharfaTech/ZharfaTech-Open-Platypus-Persian-Farsi."},
	{"name":"Nadi_Indic466k_Instruct","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct","creator_name":"Convai Innovations","creator_url":"https://huggingface.co/convaiinnovations","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNadi_Indic466K_Instruct Dataset\\n\\t\\n\\nThe Nadi_Indic466K_Instruct dataset is the world's first coding dataset with 18 Indian language support, 466k rows and 142 Million total tokens. This dataset can be used by developers to build Indian coding language models (LLMs) for various programming languages.\\nQ-LoRA based SFT/PPO/DPO fine-tuning can be done on the dataset in LLAMA-2 or Mistral or any opens-soure LLM for text generation.\\nThe dataset was carefully curated such that the coding… See the full description on the dataset page: https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct."},
	{"name":"codeconv-fortran-to-rust","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/devesh5/codeconv-fortran-to-rust","creator_name":"Devesh Surve","creator_url":"https://huggingface.co/devesh5","description":"devesh5/codeconv-fortran-to-rust dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"vacancies_prompts","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AlekseyScorpi/vacancies_prompts","creator_name":"Aleksey Timoshin","creator_url":"https://huggingface.co/AlekseyScorpi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout this dataset\\n\\t\\n\\nThis dataset was originally based on dataset from HH.ru company https://www.kaggle.com/datasets/vyacheslavpanteleev1/hhru-it-vacancies-from-20211025-to-20211202.\\nThis data is parsed from hh.ru for Moscow and Saint Petersburg (from 2021-10-25 to 2021-12-02).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCreate prompt and description\\n\\t\\n\\nTo create a dataset prompts, fields such as: employer, name, experience, schedule, keys are used. For description just used description field.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe… See the full description on the dataset page: https://huggingface.co/datasets/AlekseyScorpi/vacancies_prompts."},
	{"name":"tapilot-crossing","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/patrickNLP/tapilot-crossing","creator_name":"Malou Lab","creator_url":"https://huggingface.co/patrickNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTapilot-Crossing is the first benchmark to evaluate LLM agents on interactive data analysis. It includes 1024 user-machine interactions with 1176 user intents, spanning four practical scenarios: \\n\\n\\nNormal, where all questions and user requirements are explicit, requiring no actions from agents;\\n\\n\\n\\nAction, where agents must respond to diverse user feedback or instructions;\\n\\n\\n\\nPrivate, which examines the true semantic parsing capability of agents when encountering… See the full description on the dataset page: https://huggingface.co/datasets/patrickNLP/tapilot-crossing."},
	{"name":"MMOS","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/cyzhh/MMOS","creator_name":"Yezeng Chen","creator_url":"https://huggingface.co/cyzhh","description":"ArXiv | Models | Data | Code | \\nYou can download the dataset as follows\\nfrom datasets import load_dataset\\nds = load_dataset(\\\"cyzhh/MMOS\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema\\n\\t\\n\\nEach dataset row has the following structure\\n{\\n  \\\"idx\\\": ..., # problem id\\n  \\\"prompt\\\": ..., # problem \\n  \\\"completion\\\": ... # reasoning path with python\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nWe do not alter the license of any of the underlying data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nFor the MMOS, cite \\n@misc{chen2024empirical,\\n      title={An Empirical Study… See the full description on the dataset page: https://huggingface.co/datasets/cyzhh/MMOS."},
	{"name":"datasets-github-issues","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jamesLeeeeeee/datasets-github-issues","creator_name":"jk.lee","creator_url":"https://huggingface.co/jamesLeeeeeee","description":"jamesLeeeeeee/datasets-github-issues dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"SLTrans","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/UKPLab/SLTrans","creator_name":"Ubiquitous Knowledge Processing Lab","creator_url":"https://huggingface.co/UKPLab","description":"The dataset consists of source code and LLVM IR pairs generated from accepted and de-duped programming contest solutions. The dataset is divided into language configs and mode splits. The language can be one of C, C++, D, Fortran, Go, Haskell, Nim, Objective-C, Python, Rust and Swift, indicating the source files' languages. The mode split indicates the compilation mode, which can be wither Size_Optimized or Perf_Optimized.\\nOnce you have submitted an access request which has been approved… See the full description on the dataset page: https://huggingface.co/datasets/UKPLab/SLTrans."},
	{"name":"pokedex","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/smartire/pokedex","creator_name":"Stefano Martire","creator_url":"https://huggingface.co/smartire","description":"Regional pokedex from the Pokemon games.\\nPokedex available at the moment:\\n\\nPaldea (utilised in https://medium.com/@virtualmartire/i-built-an-algorithm-that-finds-the-optimal-pokemon-team-01ea152824a9).\\n\\n"},
	{"name":"attackdex-paldea","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/smartire/attackdex-paldea","creator_name":"Stefano Martire","creator_url":"https://huggingface.co/smartire","description":"Single pokemon datasets containing all the attacks (from levelling or TMs) learnable by the relative monster. All the data refer to the Paldea region and they come from the project discussed in https://medium.com/@virtualmartire/i-built-an-algorithm-that-finds-the-optimal-pokemon-team-01ea152824a9.\\n"},
	{"name":"slimorca-dedup-chatml-100k","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/philschmid/slimorca-dedup-chatml-100k","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCopy of Open-Orca/SlimOrca-Dedup in ChatML format downsample to 100k\\n\\t\\n\\n\\n\\\"SlimOrca Dedup\\\" is a deduplicated, unfiltered subset of the SlimOrca dataset, excluding RLHF instances, resulting in 363k unique examples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKey Features\\n\\t\\n\\n\\nRemoval of RLHF instances.\\nDeduplication using minhash and Jaccard similarity techniques.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemo Models\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote: These models were trained on the full SlimOrca dataset, not the deduplicated, unfiltered version.\\n*… See the full description on the dataset page: https://huggingface.co/datasets/philschmid/slimorca-dedup-chatml-100k."},
	{"name":"slimorca-dedup-chatml","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/philschmid/slimorca-dedup-chatml","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCopy of Open-Orca/SlimOrca-Dedup in ChatML format\\n\\t\\n\\n\\n\\\"SlimOrca Dedup\\\" is a deduplicated, unfiltered subset of the SlimOrca dataset, excluding RLHF instances, resulting in 363k unique examples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKey Features\\n\\t\\n\\n\\nRemoval of RLHF instances.\\nDeduplication using minhash and Jaccard similarity techniques.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemo Models\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote: These models were trained on the full SlimOrca dataset, not the deduplicated, unfiltered version.\\n*… See the full description on the dataset page: https://huggingface.co/datasets/philschmid/slimorca-dedup-chatml."},
	{"name":"qdrant_doc","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/atitaarora/qdrant_doc","creator_name":"Atita","creator_url":"https://huggingface.co/atitaarora","description":"atitaarora/qdrant_doc dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Malicious_code_classification","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Er1111c/Malicious_code_classification","creator_name":"Lee","creator_url":"https://huggingface.co/Er1111c","description":""},
	{"name":"Handwritten-Latex-Datasets","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Shijiang/Handwritten-Latex-Datasets","creator_name":"Wang","creator_url":"https://huggingface.co/Shijiang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\nThis data set includes common handwritten formulas in junior high schools and high schools, and is labeled in Latex format. Can be used to train models that recognize common numbers, fractions, and sets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset source\\n\\t\\n\\nCollected in various junior high schools and high schools, handwritten by students.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThe label is stored at json folder and scanned hand-writted pictures are stored at pic folder.\\nScan the qr code of the picture to get… See the full description on the dataset page: https://huggingface.co/datasets/Shijiang/Handwritten-Latex-Datasets."},
	{"name":"CoderAPI_Dataset","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/IslamMesabah/CoderAPI_Dataset","creator_name":"Islam Mesabah","creator_url":"https://huggingface.co/IslamMesabah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLarge Language Models for instructed and effective code generation using Documentation of APIs\\n\\t\\n\\nThis thesis explores the effective utilization of Large Language Models, specifically the Instruct CodeT5+ 16 Billion model, for the generation of multi-line, ready-to-execute code in Python. Departing from conventional reliance solely on pre-trained LLM knowledge, we employ API documentation to enhance the correctness of generated code for both seen and unseen APIs in the LLM… See the full description on the dataset page: https://huggingface.co/datasets/IslamMesabah/CoderAPI_Dataset."},
	{"name":"colors_2_train","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/molchomen/colors_2_train","creator_name":"Molcho","creator_url":"https://huggingface.co/molchomen","description":"molchomen/colors_2_train dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"socratic-debugging-benchmark","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/taisazero/socratic-debugging-benchmark","creator_name":"Erfan Al-Hossami","creator_url":"https://huggingface.co/taisazero","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSocratic Debugging Benchmark\\n\\t\\n\\n\\n  \\n\\n\\nThe repository contains the dataset for the Socratic Debugging Benchmark accompanying the papers \\\"Socratic Questioning of Novice Debuggers: A Benchmark Dataset and Preliminary Evaluations\\\" in proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Application at ACL 2023 and \\\"Can Language Models Employ the Socratic Method? Experiments with Code Debugging\\\" in the proceedings of SIGCSE'24.\\nThe dataset is also hosted on… See the full description on the dataset page: https://huggingface.co/datasets/taisazero/socratic-debugging-benchmark."},
	{"name":"ObscuraX","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ObscuraCoder/ObscuraX","creator_name":"Obscura Coder","creator_url":"https://huggingface.co/ObscuraCoder","description":"ObscuraCoder/ObscuraX dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Wos","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/gtceu/Wos","creator_name":"gt","creator_url":"https://huggingface.co/gtceu","description":"gtceu/Wos dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"JetCopper-10B","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sudy-super/JetCopper-10B","creator_name":"Sudy","creator_url":"https://huggingface.co/sudy-super","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tJetCopper-10B\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nJetCopper-10B was created by extracting a portion of the data after cleaning, filtering, and deduplicating the following datasets.\\n\\nThe japanese subset of C4\\nThe japanese subset of CC-100\\nThe japanese subset of OSCAR-2301\\nThe japanese subset of HPLT Datasets v1.2\\nwiki40b-ja\\n\\nThis dataset was used to pre-train Contrail-200m-64k when we participated in LOCAL AI HACKATHON #000.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe number of tokens (Using tokenizer of calm2-chat)… See the full description on the dataset page: https://huggingface.co/datasets/sudy-super/JetCopper-10B."},
	{"name":"MiFirma-Ejemplo","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/devdroide/MiFirma-Ejemplo","creator_name":"devdroide","creator_url":"https://huggingface.co/devdroide","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMi Firma - Preguntas y respuestas\\n\\t\\n\\nEste colección contiene preguntas y respuestas de una aplicación web ficticia que se encarga de firmar documentos\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContenido\\n\\t\\n\\nTiene preguntas y repuestas con un contexto dado, como de:\\n\\nInformación de la aplicación\\nPerfiles\\nProductos que cubre\\nQuienes pueden firmar\\nErrores que comunes de la aplicación\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsos\\n\\t\\n\\nLa colección tiene como objetivo ampliar la disponibilidad de datos conversacionales para la investigación en IA… See the full description on the dataset page: https://huggingface.co/datasets/devdroide/MiFirma-Ejemplo."},
	{"name":"vacancies_prompts_en","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AlekseyScorpi/vacancies_prompts_en","creator_name":"Aleksey Timoshin","creator_url":"https://huggingface.co/AlekseyScorpi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout this dataset\\n\\t\\n\\nThis dataset is just a translation of the following dataset https://huggingface.co/datasets/AlekseyScorpi/vacancies_prompts . The translation was carried out using googletrans.\\n"},
	{"name":"Worldsim","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/VatsaDev/Worldsim","creator_name":"Vatsa Pandey","creator_url":"https://huggingface.co/VatsaDev","description":"Bunch of worldsim text?\\n"},
	{"name":"pecc","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/PatrickHaller/pecc","creator_name":"Patrick Haller","creator_url":"https://huggingface.co/PatrickHaller","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\nCurated by: Patrick Haller\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository:… See the full description on the dataset page: https://huggingface.co/datasets/PatrickHaller/pecc."},
	{"name":"EvoEval_difficult","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/evoeval/EvoEval_difficult","creator_name":"EvoEval","creator_url":"https://huggingface.co/evoeval","description":"evoeval/EvoEval_difficult dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"OpenCerebrum-SFT","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Locutusque/OpenCerebrum-SFT","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenCerebrum SFT subset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nOpenCerebrum is my take on creating an open source version of Aether Research's proprietary Cerebrum dataset. This repository contains the SFT subset, which contains about 1,200,00 examples. Unfortunately, I was unsure about how I would compress this dataset to just 5,000 examples like in the original Cerebrum dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration\\n\\t\\n\\nThis dataset was curated using a simple and logical rationale. The goal was to use… See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/OpenCerebrum-SFT."},
	{"name":"EvoEval_creative","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/evoeval/EvoEval_creative","creator_name":"EvoEval","creator_url":"https://huggingface.co/evoeval","description":"evoeval/EvoEval_creative dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"EvoEval_combine","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/evoeval/EvoEval_combine","creator_name":"EvoEval","creator_url":"https://huggingface.co/evoeval","description":"evoeval/EvoEval_combine dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"EvoEval_subtle","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/evoeval/EvoEval_subtle","creator_name":"EvoEval","creator_url":"https://huggingface.co/evoeval","description":"evoeval/EvoEval_subtle dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"EvoEval_tool_use","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/evoeval/EvoEval_tool_use","creator_name":"EvoEval","creator_url":"https://huggingface.co/evoeval","description":"evoeval/EvoEval_tool_use dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"harry_potter_conversational","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/krinal/harry_potter_conversational","creator_name":"Krinal Joshi","creator_url":"https://huggingface.co/krinal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset: Harry potter conversational text corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThis corpus contains conversational data in text format\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\n\\ntext classification\\ntoken classification\\nquestion answering\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguage\\n\\t\\n\\nen\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\napache 2.0\\n"},
	{"name":"aiysha-diction","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/rofyray/aiysha-diction","creator_name":"Rofy Ray","creator_url":"https://huggingface.co/rofyray","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAIySha: yShade.AI AI Agent\\n\\t\\n\\nThis is the base dataset for customizing the diction of the bot backed by llama-2-7b-chat model.\\nThe dataset needs to be reformatted to fit the prompt template for the chat model in order to use for fine tuning purposes.\\nThe goal of the dataset is to train the model to be specialized as a beauty advisor.\\n"},
	{"name":"aiysha-diction-500","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/rofyray/aiysha-diction-500","creator_name":"Rofy Ray","creator_url":"https://huggingface.co/rofyray","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAIySha: yShade.AI AI Agent\\n\\t\\n\\nThis is the formatted dataset for customizing the diction of the bot backed by llama-2-7b-chat model.\\nThe dataset fits the prompt template for the chat model and is ready to be used for fine tuning purposes.\\nThe goal of the dataset is to train the model to be specialized as a beauty advisor.\\n"},
	{"name":"CodeAlpaca-20K-Python","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/graycatHCO3/CodeAlpaca-20K-Python","creator_name":"graycat","creator_url":"https://huggingface.co/graycatHCO3","description":"graycatHCO3/CodeAlpaca-20K-Python dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"raw_data","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SilvioLima/raw_data","creator_name":"Silvio  Lima","creator_url":"https://huggingface.co/SilvioLima","description":"\\n"},
	{"name":"text-to-neo4j-cypher-chinese","keyword":"code","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/Doraemon-AI/text-to-neo4j-cypher-chinese","creator_name":"AnitaSherry","creator_url":"https://huggingface.co/Doraemon-AI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t动机\\n\\t\\n\\n随着信息量的不断增加和技术的进步，我们的社会正在逐渐形成一个庞大而复杂的网络。随着大数据时代的到来，半结构化和非结构化的数据格式越来越多。 ，传统关系型数据库难以有效处理这些数据，而图数据库能够更灵活地存储和查询此类类型的数据，Neo4j就是其中最流行的产品之一\\n但是 Neo4j 的查询语言 Cypher 可以实现对图的高效查询。Cypher 的复杂操作和语法对用户的学习成本要求同样高。因此，本文提出并定义了一种类似Text-to-SQL的新任务Text-to-Neo4j-Cypher\\nText-to-Neo4j-Cypher是一种新的语义解析任务，即将用户的自然语言查询转化为为Neo4j-Cypherquery，以帮助降低用户的学习和使用成本，提升图数据库与用户的交互程度\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t亮点\\n\\t\\n\\n1、提出并正式定义了 Text-to-Neo4j-Cypher 任务，该任务的目的是将用户自然语言查询自动转化为 Neo4j-Cypher 查询，降低图数据库与用户交互的学习和使用成本\\n2、对参考文献中的数据进行了改进，以适应LLM的训练… See the full description on the dataset page: https://huggingface.co/datasets/Doraemon-AI/text-to-neo4j-cypher-chinese."},
	{"name":"Code-Feedback-decontamination","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Leon-Leee/Code-Feedback-decontamination","creator_name":"Leon Lee","creator_url":"https://huggingface.co/Leon-Leee","description":"A decontaminated version of m-a-p/Code-Feedback. \\nThe excluded (28) files are \\\"contaminated\\\" with only two code segments: \\n\\nsimple GCD function: while b: a, b = b, a % b return a\\nsum_to_n solution: return sum(range(n + 1))\\n\\nAnd reformated to sharegpt.\\nDecontamination is done in the same way as Magicoder (ie., bigcode decontamination process), which uses a substring-match-finding method to find overlaps between a target dataset and the following standard benchmarks:\\n\\nHumanEval\\nMBPP… See the full description on the dataset page: https://huggingface.co/datasets/Leon-Leee/Code-Feedback-decontamination."},
	{"name":"Xerxes-Instruct-700K","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Instinct-AI/Xerxes-Instruct-700K","creator_name":"Instinct-AI","creator_url":"https://huggingface.co/Instinct-AI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Xerxes-Instruct-700K\\\"\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nXerxes, named after a Persian King renowned for his wisdom and strategic prowess, is an amalgamation of four distinct datasets. This dataset has been curated to cater to the burgeoning needs of natural language processing tasks, particularly in the domain of conversation modeling and comprehension.\\nThe dataset encompasses conversations sourced from a variety of sources, ranging from generative models to… See the full description on the dataset page: https://huggingface.co/datasets/Instinct-AI/Xerxes-Instruct-700K."},
	{"name":"WizardLM_evol_instruct_V2_only_code","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Leon-Leee/WizardLM_evol_instruct_V2_only_code","creator_name":"Leon Lee","creator_url":"https://huggingface.co/Leon-Leee","description":"filtered from (WizardLM/WizardLM_evol_instruct_V2_196k)[https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k] using \\\"```\\\"\\n"},
	{"name":"ptbr-deita-8k","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/botbot-ai/ptbr-deita-8k","creator_name":"BotBot","creator_url":"https://huggingface.co/botbot-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\tPTBR Deita 8k\\n\\t\\n\\nPortuguese translation of the Deita 8k dataset. \\n"},
	{"name":"urv_test","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/elmambru/urv_test","creator_name":"Albert Garcia Bernat","creator_url":"https://huggingface.co/elmambru","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/elmambru/urv_test."},
	{"name":"glaive-code-assistant-v3","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/pharaouk/glaive-code-assistant-v3","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGlaive-code-assistant-v2\\n\\t\\n\\nGlaive-code-assistant-v2 is a dataset of ~1M code problems and solutions generated using Glaive’s synthetic data generation platform.\\nThis is built on top of the previous version of the dataset that can be found here. This already includes v1 and v2 of the dataset.\\nTo report any problems or suggestions in the data, join the Glaive discord\\n"},
	{"name":"glaive-code-assistant-v2","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/pharaouk/glaive-code-assistant-v2","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGlaive-code-assistant-v2\\n\\t\\n\\nGlaive-code-assistant-v2 is a dataset of ~215k code problems and solutions generated using Glaive’s synthetic data generation platform.\\nThis is built on top of the previous version of the dataset that can be found here\\nTo report any problems or suggestions in the data, join the Glaive discord\\n"},
	{"name":"wangwei","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/guilty1987/wangwei","creator_name":"FAN","creator_url":"https://huggingface.co/guilty1987","description":"guilty1987/wangwei dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CodeEditSearch","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/cassanof/CodeEditSearch","creator_name":"Federico Cassano","creator_url":"https://huggingface.co/cassanof","description":"This is a dataset built from CommitPackFT, providing ~1500 commits with diffs for several programming languages:\\n\\nPython\\nJavaScript\\nTypeScript\\nGo\\nRuby\\nJava\\nPHP\\nC\\nC++\\nRust\\nSwift\\nScala\\nBash\\n\\nThe goal of this dataset is to evaluate the ability of models to retrieve a diff given its instruction.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode To Produce Dataset\\n\\t\\n\\nBelow is the code to reproduce this dataset:\\nimport datasets\\nfrom tqdm import tqdm\\nimport difflib\\n\\n\\noutrepo = \\\"cassanof/CodeEditSearch\\\"\\nLANGS = [\\\"python\\\"… See the full description on the dataset page: https://huggingface.co/datasets/cassanof/CodeEditSearch."},
	{"name":"spam_ham_spanish","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/softecapps/spam_ham_spanish","creator_name":"softecapps","creator_url":"https://huggingface.co/softecapps","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAnálisis de Dataset de Mensajes de Texto\\n\\t\\n\\nEste dataset contiene un total de 1000 mensajes de texto en español, junto con una etiqueta que indica si el mensaje es considerado \\\"spam\\\" o \\\"ham\\\" (legítimo).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tComposición del Dataset\\n\\t\\n\\nEl dataset está compuesto por dos columnas:\\nMensaje: Contiene el texto del mensaje.\\nEtiqueta: Indica si el mensaje es \\\"spam\\\" o \\\"ham\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPotenciales Usos\\n\\t\\n\\nEste dataset puede ser utilizado para entrenar modelos de Machine Learning con… See the full description on the dataset page: https://huggingface.co/datasets/softecapps/spam_ham_spanish."},
	{"name":"alpaca-cleaned-gpt4-turbo","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mylesgoose/alpaca-cleaned-gpt4-turbo","creator_name":"myles bruce","creator_url":"https://huggingface.co/mylesgoose","description":"I downloaded the dataset from Alpaca at https://huggingface.co/datasets/yahma/alpaca-cleaned and processed it using a script to convert the text to hashes. I removed any duplicate hashes along with their corresponding input and output columns. Subsequently, I utilized the GPT-4 Turbo API to feed each message, instruction, and input to the model for generating responses.\\nHere are the outputs generated by the GPT-4 Turbo model. The information in the input column and instruction column should be… See the full description on the dataset page: https://huggingface.co/datasets/mylesgoose/alpaca-cleaned-gpt4-turbo."},
	{"name":"sql-create-context-thai","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/saksornr/sql-create-context-thai","creator_name":"Saksorn Ruangtanusak","creator_url":"https://huggingface.co/saksornr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from sql-create-context.\\n@misc{b-mc2_2023_sql-create-context,\\n  title   = {sql-create-context Dataset},\\n  author  = {b-mc2}, \\n  year    = {2023},\\n  url     = {https://huggingface.co/datasets/b-mc2/sql-create-context},\\n  note    = {This dataset was created by modifying data from the following sources: \\\\cite{zhongSeq2SQL2017, yu2018spider}.},\\n}\\n\\n"},
	{"name":"MathCodeInstruct","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/MathLLMs/MathCodeInstruct","creator_name":"LLMs for Math Reasoning","creator_url":"https://huggingface.co/MathLLMs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning\\n\\t\\n\\nPaper: https://arxiv.org/pdf/2310.03731.pdf\\nRepo: https://github.com/mathllm/MathCoder\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce MathCoder, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving.\\n\\n\\t\\n\\t\\t\\nBase Model: Llama-2\\nBase Model: Code Llama\\n\\n\\n\\t\\t\\nMathCoder-L-7B\\nMathCoder-CL-7B\\n\\n\\nMathCoder-L-13B\\nMathCoder-CL-34B\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTraining Data… See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathCodeInstruct."},
	{"name":"BanglaEnglishMixedAsrDataset","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/akhikhan123/BanglaEnglishMixedAsrDataset","creator_name":"Fatema Tuz Zohra Akhi","creator_url":"https://huggingface.co/akhikhan123","description":"akhikhan123/BanglaEnglishMixedAsrDataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ds1000","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/claudios/ds1000","creator_name":"Claudio Spiess","creator_url":"https://huggingface.co/claudios","description":"This is a reupload of DS-1000. The metadata dictionary has been extracted into columns and the categorical variables are now ClassLabel types, and the dataset is natively a parquet. The features are as follows:\\n\\n\\t\\n\\t\\t\\nColumn\\nType\\n\\n\\n\\t\\t\\nproblem_id\\nValue(dtype='int64', id=None)\\n\\n\\nprompt\\nValue(dtype='string', id=None)\\n\\n\\nreference_code\\nValue(dtype='string', id=None)\\n\\n\\ncode_context\\nValue(dtype='string', id=None)\\n\\n\\nlibrary_problem_id\\nValue(dtype='int64', id=None)\\n\\n\\nlibrary… See the full description on the dataset page: https://huggingface.co/datasets/claudios/ds1000."},
	{"name":"synthetic-text2cypher-gpt4turbo","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/tomasonjo/synthetic-text2cypher-gpt4turbo","creator_name":"Tomaž Bratanič","creator_url":"https://huggingface.co/tomasonjo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic dataset created with GPT-4-Turbo\\n\\t\\n\\nSynthetic dataset of text2cypher over 16 different graph schemas.\\nBoth questions and cypher queries were generated using GPT-4-turbo.\\nThe demo database is available at:\\nURI: neo4j+s://demo.neo4jlabs.com\\nusername: name of the database, for example 'movies'\\npassword: name of the database, for example 'movies'\\ndatabase: name of the database, for example 'movies'\\n\\nNotebooks:\\n\\ngenerate_text2cypher_questions.ipynb: Generate questions and… See the full description on the dataset page: https://huggingface.co/datasets/tomasonjo/synthetic-text2cypher-gpt4turbo."},
	{"name":"verilog-wavedrom","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/vkenbeek/verilog-wavedrom","creator_name":"Vincent","creator_url":"https://huggingface.co/vkenbeek","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVerilog Wavedrom\\n\\t\\n\\n\\n\\nA combination of verilog modules and their correspondig timing diagrams generated by wavedrom.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\nA collection of wavedrom timing diagrams in PNG format representing verilog modules.\\nThe Verilog modules were copied from shailja/Verilog_GitHub.The timing diagrams were generated by first generating testbenches for the individual verilog modules through the Verilog Testbench Generator from EDA Utils VlogTBGen.The resulting… See the full description on the dataset page: https://huggingface.co/datasets/vkenbeek/verilog-wavedrom."},
	{"name":"Select-Stack","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/H-D-T/Select-Stack","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to… See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Select-Stack."},
	{"name":"unstacked","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/H-D-T/unstacked","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to… See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/unstacked."},
	{"name":"Pangpuriye-public_alpaca-cleaned","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/AIAT/Pangpuriye-public_alpaca-cleaned","creator_name":"Artificial Intelligence Association of Thailand","creator_url":"https://huggingface.co/AIAT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🤖 Super AI Engineer Development Program Season 4 - Pangpuriye House - Alpaca-Cleaned\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOriginal Dataset\\n\\t\\n\\nWe adopt this alpaca-cleaned dataset from https://huggingface.co/datasets/yahma/alpaca-cleaned the original repository. We used this dataset during the fine-tuning of Panguriye's LLM. The dataset is available under the Creative Commons Non Commercial (CC BY-NC 4.0). \\nThe original dataset consists of 51,760 rows of input, instruction, and output in English. \\nWe… See the full description on the dataset page: https://huggingface.co/datasets/AIAT/Pangpuriye-public_alpaca-cleaned."},
	{"name":"HuixiangDou-CR","keyword":"code","license":"BSD 3-Clause \"New\" or \"Revised\" License","language":"en","url":"https://huggingface.co/datasets/tpoisonooo/HuixiangDou-CR","creator_name":"HuanjunKong","creator_url":"https://huggingface.co/tpoisonooo","description":"tpoisonooo/HuixiangDou-CR dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"leetcode_with_youtube_captions","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/LimYeri/leetcode_with_youtube_captions","creator_name":"LimYeri","creator_url":"https://huggingface.co/LimYeri","description":""},
	{"name":"fr-summarizer-dataset","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Labagaite/fr-summarizer-dataset","creator_name":"Derue","creator_url":"https://huggingface.co/Labagaite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttraining data\\n\\t\\n\\n\\nDataset : fr-summarizer-dataset\\nData-size : 7.65 MB\\ntrain : 1.97k rows\\nvalidation : 440 rows\\nroles : user , assistant\\nFormat chatml \\\"role\\\": \\\"role\\\", \\\"content\\\": \\\"content\\\", \\\"user\\\": \\\"user\\\", \\\"assistant\\\": \\\"assistant\\\"\\n*French audio podcast transcription*\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProject details\\n\\t\\n\\n\\nFine-tuned on French audio podcast transcription data for summarization task. As a result, the model is able to summarize French audio podcast transcription data.\\nThe model will be used… See the full description on the dataset page: https://huggingface.co/datasets/Labagaite/fr-summarizer-dataset."},
	{"name":"DiagGSM8K","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/pharaouk/DiagGSM8K","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"View the project page:\\nhttps://github.com/dvlab-research/DiagGSM8K\\nsee our paper at https://arxiv.org/abs/2312.17080\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nIn this work, we introduce a novel evaluation paradigm for Large Language Models, \\none that challenges them to engage in meta-reasoning. Our paradigm shifts the focus from result-oriented assessments, \\nwhich often overlook the reasoning process, to a more holistic evaluation that effectively differentiates \\nthe cognitive capabilities among models. For… See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/DiagGSM8K."},
	{"name":"fake_voices","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/unfake/fake_voices","creator_name":"Unfake","creator_url":"https://huggingface.co/unfake","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Fake Voices\\n\\t\\n\\nThis dataset contains deepfakes in Brazilian Portuguese created with XTTS model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe dataset was created using the XTTS model, which is a Text-to-Speech model pre-trained in several languages including Portuguese. \\nIn order to generate the mentioned deepfakes, the model was fed with recordings from the CETUC Corpus, \\nmade available by Fala Brasil Group. It contains speeches from 101 speakers, totaling 140 hours of… See the full description on the dataset page: https://huggingface.co/datasets/unfake/fake_voices."},
	{"name":"table_rec_test_dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SWHL/table_rec_test_dataset","creator_name":"SWHL","creator_url":"https://huggingface.co/SWHL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t表格识别测试集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集简介\\n\\t\\n\\n\\n包含百度生成工具 20张有线20张无线，wtw数据集15, pubnet val集20张，自我零散标注18张，共计93张表格图片,涵盖多种场景、不同光照条件、不同的图像分辨率。\\n该数据集可以结合表格指标评测库-TableRecognitionMetric使用，快速评测各种表格还原算法。\\n关于该数据集，欢迎小伙伴贡献更多数据呦！有任何想法，可以前往issue讨论。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集支持的任务\\n\\t\\n\\n可用于自定义数据集下的模型验证和性能评估等。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集的格式和结构\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据格式\\n\\t\\n\\n数据集只有测试集，仅用于客观评估算法表现。\\ndata\\n└── test\\n    ├── 000cce9ca593055d4618466e823e6d7c.jpg\\n    ├── 0aNtiNtRRLqEZ9y6PuShtAAAACMAAQED.jpg\\n    ├── 116d6b07ecfdae7721bd6bbf31031c1a.jpg… See the full description on the dataset page: https://huggingface.co/datasets/SWHL/table_rec_test_dataset."},
	{"name":"LeetCode_with_Solutions","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/LimYeri/LeetCode_with_Solutions","creator_name":"LimYeri","creator_url":"https://huggingface.co/LimYeri","description":"datasets:\\n\\n[LimYeri/LeetCode_YT_CC_CoT_Summary] (https://huggingface.co/datasets/LimYeri/LeetCode_YT_CC_CoT_Summary)\\n[kreimben/leetcode_user_submissions] (https://huggingface.co/datasets/kreimben/leetcode_user_submissions)\\n[greengerong/leetcode] (https://huggingface.co/datasets/greengerong/leetcode)\\n\\n"},
	{"name":"cli-commands-explained","keyword":"code","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/b-mc2/cli-commands-explained","creator_name":"brianm","creator_url":"https://huggingface.co/b-mc2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is a collection of 16,098 command line instructions sourced from Commandlinefu and Cheatsheets. It includes an array of commands, each with an id, title, description, date, url to source, author, votes, and flag indicating if the description is AI generated. The descriptions are primarily authored by the original contributors, for entries where descriptions were absent, they have been generated using NeuralBeagle14-7B. Out of the total entries, 10,039… See the full description on the dataset page: https://huggingface.co/datasets/b-mc2/cli-commands-explained."},
	{"name":"OpenCerebrum-2.0-SFT","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Locutusque/OpenCerebrum-2.0-SFT","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenCerebrum SFT subset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nOpenCerebrum is my take on creating an open source version of Aether Research's proprietary Cerebrum dataset. This repository contains the SFT subset, which contains about 6,400 examples. To compress this dataset to such a small size, I used an in-house curation technique at Cognitive Computations. More information about this technique will come in the future. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration\\n\\t\\n\\nAs mentioned earlier, I used an in-house… See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/OpenCerebrum-2.0-SFT."},
	{"name":"OpenCerebrum-2.0-DPO","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Locutusque/OpenCerebrum-2.0-DPO","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenCerebrum DPO subset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nOpenCerebrum is my take on creating an open source version of Aether Research's proprietary Cerebrum dataset. This repository contains the DPO subset, which contains about 720 examples. To compress this dataset to such a small size, I used an in-house curation technique at Cognitive Computations. More information about this technique will come in the future. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration\\n\\t\\n\\nAs mentioned earlier, I used an in-house… See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/OpenCerebrum-2.0-DPO."},
	{"name":"cpp-code-code_search_net-style","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/malteklaes/cpp-code-code_search_net-style","creator_name":"Malte Klaes","creator_url":"https://huggingface.co/malteklaes","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tC++ Dataset\\n\\t\\n\\n\\ndocumentation source: https://huggingface.co/docs/datasets/main/en/repository_structure\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nlanguage-modeling: The dataset can be used to train a model for modelling programming languages, which consists in building language models for programming languages.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguage\\n\\t\\n\\n\\nC++ programming language\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nA data point consists of a function code along… See the full description on the dataset page: https://huggingface.co/datasets/malteklaes/cpp-code-code_search_net-style."},
	{"name":"ultra-feedback-js-instruct","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/DigitalClockwork/ultra-feedback-js-instruct","creator_name":"Digital Clockwork","creator_url":"https://huggingface.co/DigitalClockwork","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUltra Feedback JS Instruct\\n\\t\\n\\nA subset of the wonderful and elegant Ultra Feedback dataset. Ratings are 1-5 ( inclusive )\\nGeneration Notebook\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample\\n\\t\\n\\n{\\n    \\\"inst\\\": \\\"Refine the subsequent JavaScript code snippet to obtain the cumulative total of elements within an array:\\\\nlet numbers = [1, 2, 3]\\\",\\n    \\\"author\\\": \\\"codellama-34b-instruct\\\",\\n    \\\"fun\\\": \\\"let numbers = [1, 2, 3];\\\\nlet total = numbers.reduce((a, b) => a + b);\\\\nconsole.log(total); // Output: 6\\\",\\n    \\\"rating\\\":… See the full description on the dataset page: https://huggingface.co/datasets/DigitalClockwork/ultra-feedback-js-instruct."},
	{"name":"text_rec_test_dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SWHL/text_rec_test_dataset","creator_name":"SWHL","creator_url":"https://huggingface.co/SWHL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t文本识别测试集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集简介\\n\\t\\n\\n\\n该测试集包括8类场景，分别是竖排文字、长文本、单字、验证码、自然场景、银行卡、手写体和车牌等。\\n该数据集可以结合文本识别指标评测库-TextRecMetric使用，快速评测各种文本识别算法。\\n关于该数据集，欢迎小伙伴贡献更多数据呦！有任何想法，可以前往issue讨论。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集支持的任务\\n\\t\\n\\n可用于自定义数据集下的模型验证和性能评估等。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集加载方式\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"SWHL/text_rec_test_dataset\\\")\\n\\ntest_data = dataset['test']\\nprint(test_data)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集生成的相关信息\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t原始数据\\n\\t\\n\\n数据来源于网络，如侵删。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t各个类别数目如下\\n\\t\\n\\n竖排文字 : 14\\n长文本 : 18\\n单字 : 115… See the full description on the dataset page: https://huggingface.co/datasets/SWHL/text_rec_test_dataset."},
	{"name":"INHA_Titres_CatVentes","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/JulietteBenguigui142/INHA_Titres_CatVentes","creator_name":"Juliette Benguigui","creator_url":"https://huggingface.co/JulietteBenguigui142","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/JulietteBenguigui142/INHA_Titres_CatVentes."},
	{"name":"DocuMint","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/documint/DocuMint","creator_name":"DocuMint","creator_url":"https://huggingface.co/documint","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDocuMint Dataset\\n\\t\\n\\nThe DocuMint Dataset is a collection of 100,000 Python functions and their corresponding docstrings, extracted from popular open-source repositories in the Free and open-source software (FLOSS) ecosystem. This dataset was created to train the DocuMint model, a fine-tuned variant of Google's CodeGemma-2B that generates high-quality docstrings for Python code functions. For more information on the model and its training procedure, please refer to the model card.… See the full description on the dataset page: https://huggingface.co/datasets/documint/DocuMint."},
	{"name":"jinaai_jina-embeddings-v2-base-code-stackoverflow","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-stackoverflow","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-code-stackoverflow Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"code snippet search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-code-stackoverflow model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-code-stackoverflow."},
	{"name":"SE-Chatting.en","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/berwart/SE-Chatting.en","creator_name":"Berwart","creator_url":"https://huggingface.co/berwart","description":"\\n\\t\\n\\t\\t\\n\\t\\tSE.02\\n\\t\\n\\nDataset\\nHello, welcome to the official main dataset of SE.02 that's always getting updated, make sure to like to help us a lot.\\nthis dataset contains pretty much everything from math to isk what to put but pretty much anything you think an ai can say.\\nanyways this is our biggest dataset yet, and out first one that I don't even know how I managed to make this.\\nyou can use it to train your own ai if you want.\\n"},
	{"name":"verilog_preprocessed_anonymized","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Von-R/verilog_preprocessed_anonymized","creator_name":"Von Davis","creator_url":"https://huggingface.co/Von-R","description":"Von-R/verilog_preprocessed_anonymized dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"stackoverflow-posts","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/code-rag-bench/stackoverflow-posts","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"The StackOverflow posts retrieval source for code-rag-bench.\\n"},
	{"name":"github-repos","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/code-rag-bench/github-repos","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"The entire dump of GitHub repositories.\\n"},
	{"name":"thailand-cities","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AAhad/thailand-cities","creator_name":"Abdul Ahad","creator_url":"https://huggingface.co/AAhad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Thailand-Cities\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThailand-Cities Contains list of Thailand Cities in both English and Thai languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nTranslation\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThai\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n  1,Amnat Charoen,อำนาจเจริญ\\n  2,Ang Sila,อ่างศิลา\\n  3,Ang Thong,อ่างทอง\\n  4,Aranyaprathet,อรัญญประเทศ\\n  5,Aranyik,อรัญญิก\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields are the same among all configurations:\\n\\nSNO… See the full description on the dataset page: https://huggingface.co/datasets/AAhad/thailand-cities."},
	{"name":"thailand-provinces","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AAhad/thailand-provinces","creator_name":"Abdul Ahad","creator_url":"https://huggingface.co/AAhad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Thailand-Provinces\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThailand-Provinces Contains list of Thailand Provinces in both Engligh and Thai languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nTranslation\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThai\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n  1,Bangkok,กรุงเทพมหานคร\\n  2,Amnat Charoen,อำนาจเจริญ\\n  3,Ang Thong,อ่างทอง\\n  4,Bueng Kan,บึงกาฬ\\n  5,Buriram,บุรีรัมย์\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields are the same among all configurations:… See the full description on the dataset page: https://huggingface.co/datasets/AAhad/thailand-provinces."},
	{"name":"countries-names-in-thai","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AAhad/countries-names-in-thai","creator_name":"Abdul Ahad","creator_url":"https://huggingface.co/AAhad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Countries Names in Thai\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCountries Names in Thai Contains list of world countries names in both Engligh & Thai languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nTranslation\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThai\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n  1,ประเทศอัฟกานิสถาน,Afghanistan\\n  2,ประเทศแอลเบเนีย,Albania\\n  3,ประเทศแอลจีเรีย,Algeria\\n  4,ประเทศอันดอร์รา,Andorra\\n  5,ประเทศอาร์เจนตินา,Argentina\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields… See the full description on the dataset page: https://huggingface.co/datasets/AAhad/countries-names-in-thai."},
	{"name":"amenokaku-code-instruct-python-mit","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/HachiML/amenokaku-code-instruct-python-mit","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"kunishou/amenokaku-code-instructを以下の条件で絞り込んだものです。  \\n\\nMITライセンス (licence: 'MIT')\\npython (source: ['gasyori_100_knocks', 'datascience_100_knocks_python', 'bifi', 'python_for_begginers_solve_50_exercises', 'nlp_100_knocks')\\n\\n"},
	{"name":"amenokaku-code-instruct-python-mit-450","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/HachiML/amenokaku-code-instruct-python-mit-450","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"kunishou/amenokaku-code-instructを以下の条件で絞り込んだものです。  \\n\\nMITライセンス (licence: 'MIT')\\npython (source: ['gasyori_100_knocks', 'datascience_100_knocks_python', 'bifi', 'python_for_begginers_solve_50_exercises', 'nlp_100_knocks')\\nsource: 'bifi'をランダムに100件に絞り込み\\n\\n"},
	{"name":"alpaca_jp_python","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HachiML/alpaca_jp_python","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\talpaca_jp_python\\n\\t\\n\\n\\nalpaca_jp_pythonは、  \\n\\nStanford Alpacaの手法  \\nmistralai/Mixtral-8x22B-Instruct-v0.1\\n\\nで作った合成データ(Synthetic data)です。モデルの利用にはDeepinfraを利用しています。  \\nまた、\\\"_cleaned\\\"がついたデータセットはmistralai/Mixtral-8x22B-Instruct-v0.1によって精査されています。  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\nCurated by: HachiML\\nLanguage(s) (NLP): Japanese\\nLicense: Apache 2.0\\nGithub: Alpaca-jp\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\n\\n\\n# library\\nfrom datasets import load_dataset\\n\\n# Recommend getting the… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/alpaca_jp_python."},
	{"name":"CodeMouse","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/trollek/CodeMouse","creator_name":"Trolle Karlsson","creator_url":"https://huggingface.co/trollek","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCodeMouse\\n\\t\\n\\nI filtered out instructions with input context from sahil2801/CodeAlpaca-20k (CC BY) resulting in 9764 prompts that I then fed to WaveCoder Ultra at a low temperature.\\nThis is the code:\\nfrom datasets import load_dataset\\nimport json\\nfrom ollama import Client\\nfrom tqdm import tqdm\\n\\ncode_alpaca_dataset = load_dataset(\\\"sahil2801/CodeAlpaca-20k\\\")\\nollama_client = Client(host='http://localhost:11434')\\n\\ndef filter_no_input(hf_dataset):\\n    filtered_dataset = []\\n    for i… See the full description on the dataset page: https://huggingface.co/datasets/trollek/CodeMouse."},
	{"name":"iBeta_level_2_Silicone_masks","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/AxonData/iBeta_level_2_Silicone_masks","creator_name":"AxonLabs","creator_url":"https://huggingface.co/AxonData","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSilicone Mask Biometric Attack Dataset\\n\\t\\n\\nAnti spoofing dataset with Silicone 3D mask attacks (7000 videos)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a demo version, full dataset is coming soon. Share with us your feedback and recieve additional samples for free!😊\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFull version of dataset is availible for commercial usage - leave a request on our website Axon Labs to purchase the dataset 💰\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe Silicone Mask Attack Dataset is designed to address security… See the full description on the dataset page: https://huggingface.co/datasets/AxonData/iBeta_level_2_Silicone_masks."},
	{"name":"alpaca_jp_math","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HachiML/alpaca_jp_math","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\talpaca_jp_math\\n\\t\\n\\n\\nalpaca_jp_mathは、  \\n\\nStanford Alpacaの手法  \\nmistralai/Mixtral-8x22B-Instruct-v0.1\\n\\nで作った合成データ(Synthetic data)です。モデルの利用にはDeepinfraを利用しています。  \\nまた、\\\"_cleaned\\\"がついたデータセットは以下の手法で精査されています。  \\n\\npythonの計算結果がきちんと、テキストの計算結果が同等であるか確認\\nLLM(mistralai/Mixtral-8x22B-Instruct-v0.1)による確認（詳細は下記）\\n\\ncode_result, text_resultは小数第三位で四捨五入してあります。\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\nCurated by: HachiML\\nLanguage(s) (NLP): Japanese\\nLicense: Apache 2.0\\nGithub:… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/alpaca_jp_math."},
	{"name":"code-grader-200","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/code-grader/code-grader-200","creator_name":"Code Grader NSEC","creator_url":"https://huggingface.co/code-grader","description":"code-grader/code-grader-200 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"jina-embeddings-v2-base-en-5222024-hkde-webapp","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5222024-hkde-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-en-5222024-hkde-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"code repository search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-en-5222024-hkde-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5222024-hkde-webapp."},
	{"name":"mixed_shona_dataset","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Kittech/mixed_shona_dataset","creator_name":"Bright Chirindo","creator_url":"https://huggingface.co/Kittech","description":"Kittech/mixed_shona_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"github-repos-python","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/code-rag-bench/github-repos-python","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"The Github repository retrieval source for [code-rag-bench], containing all Python files from the entire GitHub dump (in github-repos)\\n"},
	{"name":"eng-quz-translation-dataset","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/pollitoconpapass/eng-quz-translation-dataset","creator_name":"Jose Quispe","creator_url":"https://huggingface.co/pollitoconpapass","description":"pollitoconpapass/eng-quz-translation-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"data-oss_instruct-decontaminated_python.jsonl","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Ramikan-BR/data-oss_instruct-decontaminated_python.jsonl","creator_name":"Júlio César","creator_url":"https://huggingface.co/Ramikan-BR","description":"Ramikan-BR/data-oss_instruct-decontaminated_python.jsonl dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"csharpdata","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/privelabs/csharpdata","creator_name":"PriveLabs","creator_url":"https://huggingface.co/privelabs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LeetCode Problems Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains LeetCode problems, including the problem statements, inputs, and solutions. It is useful for training code generation models and studying algorithmic problems.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntext-generation: This dataset can be used to train models to generate code snippets based on problem statements.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is in English.… See the full description on the dataset page: https://huggingface.co/datasets/privelabs/csharpdata."},
	{"name":"ReflectionSeq-GPT","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SenseLLM/ReflectionSeq-GPT","creator_name":"SenseLLM","creator_url":"https://huggingface.co/SenseLLM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReflectionCoder: Learning from Reflection Sequence for Enhanced One-off Code Generation\\n\\t\\n\\n\\n    📄 Paper •\\n    🏠 Repo •\\n    🤖 Models •\\n    📚 Datasets \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nReflectionCoder is a novel approach that effectively leverages reflection sequences constructed by integrating compiler feedback to improve one-off code generation performance. Please refer to our paper and repo for more details!\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModels\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nModel\\nCheckpoint\\nSize\\nHumanEval (+)\\nMBPP… See the full description on the dataset page: https://huggingface.co/datasets/SenseLLM/ReflectionSeq-GPT."},
	{"name":"ReflectionSeq-DS","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SenseLLM/ReflectionSeq-DS","creator_name":"SenseLLM","creator_url":"https://huggingface.co/SenseLLM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReflectionCoder: Learning from Reflection Sequence for Enhanced One-off Code Generation\\n\\t\\n\\n\\n    📄 Paper •\\n    🏠 Repo •\\n    🤖 Models •\\n    📚 Datasets \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nReflectionCoder is a novel approach that effectively leverages reflection sequences constructed by integrating compiler feedback to improve one-off code generation performance. Please refer to our paper and repo for more details!\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModels\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nModel\\nCheckpoint\\nSize\\nHumanEval (+)\\nMBPP… See the full description on the dataset page: https://huggingface.co/datasets/SenseLLM/ReflectionSeq-DS."},
	{"name":"LeetCode_YouTube_CC","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/LimYeri/LeetCode_YouTube_CC","creator_name":"LimYeri","creator_url":"https://huggingface.co/LimYeri","description":"LeetCode Information & YouTube Captions\\nOriginal data -> LimYeri/leetcode_with_youtube_captions\\nThe original ['cc_content'] column had many repeated sentences, making the data too long.\\nTo remove the repetitions, we used precise regular expressions to eliminate the repeated sentences. -> new column ['content']\\nAdditionally, we also removed unnecessary strings (e.g., '[Music]').\\n"},
	{"name":"base64-decode-v1","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/neoneye/base64-decode-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset: Base64 decode version1\\n\\t\\n\\nThis dataset is for improving base64 decoding capabilities.\\nThe number of bytes that are in the base64 encoded data spans between 0..127 bytes.\\nGPT 4o is great at base64 decoding.\\nHowever llama3 is terrible at base64 decoding.\\nShort examples of what data.jsonl looks like:\\n{\\\"instruction\\\": \\\"Transform base64 to HEX\\\", \\\"input\\\": \\\"464pNBlIObA=\\\", \\\"output\\\": \\\"e3ae2934194839b0\\\"}\\n{\\\"instruction\\\": \\\"Decode Base64 to json\\\", \\\"input\\\": \\\"NQ==\\\", \\\"output\\\": \\\"[53]\\\"}… See the full description on the dataset page: https://huggingface.co/datasets/neoneye/base64-decode-v1."},
	{"name":"Mannequin_Dataset_Anti_Spoofing","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/AxonData/Mannequin_Dataset_Anti_Spoofing","creator_name":"AxonLabs","creator_url":"https://huggingface.co/AxonData","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t3D Mannequin Face Dataset for Liveness Detection (1K+ pictures)\\n\\t\\n\\nExplore 3D mannequins for anti-spoofing models (1000+ images)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShare your feedback - recieve additional samples for free!😊\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFull version of dataset is availible for commercial usage - leave a request on our website Axon Labs to purchase the dataset 💰\\n\\t\\n\\nOur 3D Mannequin Anti-Spoofing Dataset provides a comprehensive collection of mannequin images, optimized for enhancing liveness detection… See the full description on the dataset page: https://huggingface.co/datasets/AxonData/Mannequin_Dataset_Anti_Spoofing."},
	{"name":"gptgen_text_detection","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/yongchao/gptgen_text_detection","creator_name":"Yongchao Wu","creator_url":"https://huggingface.co/yongchao","description":"yongchao/gptgen_text_detection dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Scratch-platformers-10k","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/GPT007/Scratch-platformers-10k","creator_name":"Marc Kovka","creator_url":"https://huggingface.co/GPT007","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScratch platformers 10k\\n\\t\\n\\nThis is a dataset featuring 10k search results for platformer on Scratch.\\nThere are 3 fields:  \\n\\nThe instrucions (how to play, ...)\\nThe title\\nThe code in the scratchblocks format\\n\\nI also added @ + the sprite name before the blocks.\\n"},
	{"name":"DafnyBench","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/wendy-sun/DafnyBench","creator_name":"Wendy Sun","creator_url":"https://huggingface.co/wendy-sun","description":"wendy-sun/DafnyBench dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"SlimOrca-Dedup-Uzbek-cleaned","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MLDataScientist/SlimOrca-Dedup-Uzbek-cleaned","creator_name":"Saeed","creator_url":"https://huggingface.co/MLDataScientist","description":"This is an Uzbek translated and cleaned version of https://huggingface.co/datasets/Open-Orca/SlimOrca-Dedup. \\nSpecifically, these replaced/removed records that had 'Uzbek translation|Uzbekcha tarjima|Uzbek tarjima|impossible to translate|not possible to translate|cannot fulfill your request|text is in|tilida yozilgan|Uzbek|o'zbek|ozbek|I am sorry'.\\nYou can use this dataset for chat fine-tuning of LLMs.\\nThis dataset has around 100M tokens (500M*0.8/4 = 100M assuming 4 chars are one token).… See the full description on the dataset page: https://huggingface.co/datasets/MLDataScientist/SlimOrca-Dedup-Uzbek-cleaned."},
	{"name":"VSCD-dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ElMater06/VSCD-dataset","creator_name":"El Matero","creator_url":"https://huggingface.co/ElMater06","description":"ElMater06/VSCD-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"humaneval","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/code-rag-bench/humaneval","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"HumanEval dataset annotated with the ground-truth programming solutions, to enable evaluations for retrieval and retrieval augmented code generation. \\nPlease refer to code-rag-becnch for more details. \\n"},
	{"name":"mbpp","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/code-rag-bench/mbpp","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"MBPP dataset annotated with ground-truth programming solutions, to enable evaluations for retrieval and retrieval-augmented code generation.\\nPlease refer to code-rag-bench for more details.\\n"},
	{"name":"ds1000","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/code-rag-bench/ds1000","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"DS-1000 dataset annotated with the ground-truth library documentation, to enable evaluations for retrieval and retrieval-augmented code generation.\\nPlease refer to [code-rag-bench] for more details\\n"},
	{"name":"odex","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/code-rag-bench/odex","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"ODEX dataset annotated with the ground-truth library documentation, to enable evaluations for retrieval and retrieval-augmented code generation.\\nPlease refer to [code-rag-bench] for more details.\\n"},
	{"name":"programming-solutions","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/code-rag-bench/programming-solutions","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"The programming solutions retrieval source for code-rag-bench, comprising programming solutions for the HumanEval and MBPP datasets.\\n"},
	{"name":"online-tutorials","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/code-rag-bench/online-tutorials","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"The online tutorials retrieval source for code-rag-bench, consisting tutorials pages collected from GeeksforGeeks, W3Schools, tutorialspoint, and Towards Data Science.\\n"},
	{"name":"library-documentation","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/code-rag-bench/library-documentation","creator_name":"CodeRAG-Bench","creator_url":"https://huggingface.co/code-rag-bench","description":"The library documentation retrieval source for code-rag-bench, contains all documentation for Python libraries available on devdocs.io.\\n"},
	{"name":"Wallyai-ml","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SnehaPriyaaMP/Wallyai-ml","creator_name":"Snehapriyaa","creator_url":"https://huggingface.co/SnehaPriyaaMP","description":"SnehaPriyaaMP/Wallyai-ml dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"base64-encode-v1","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/neoneye/base64-encode-v1","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset: Base64 encode version1\\n\\t\\n\\nThis dataset is for improving base64 encoding capabilities.\\nGPT 4o is great at base64 encoding.\\nuser: \\nconvert this hex data to base64:\\n880567a1\\n\\nassistant:\\nThe base64 encoding of the hex data `880567a1` is `iAVnoQ==`.\\n\\nuser:\\nconvert this json data representing a byte sequence to base64:\\n[30,41,183]\\n\\nassistant:\\nThe base64 encoding of the JSON data `[30,41,183]` is `Him3`.\\n\\nHowever llama3 is terrible at base64 encoding.\\nShort examples of what… See the full description on the dataset page: https://huggingface.co/datasets/neoneye/base64-encode-v1."},
	{"name":"bigcodebench","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bigcode/bigcodebench","creator_name":"BigCode","creator_url":"https://huggingface.co/bigcode","description":"\\n\\t\\n\\t\\t\\n\\t\\tBigCodeBench\\n\\t\\n\\n\\n\\n\\n\\nThe dataset has 2 variants: \\n\\nBigCodeBench-Complete: Code Completion based on the structured docstrings.\\n BigCodeBench-Instruct: Code Generation based on the NL-oriented instructions.\\n\\nThe overall statistics of the dataset are as follows:\\n\\n\\t\\n\\t\\t\\n\\nComplete\\nInstruct\\n\\n\\n\\t\\t\\n# Task\\n1140\\n1140\\n\\n\\n# Avg. Test Cases\\n5.6\\n5.6\\n\\n\\n# Avg. Coverage\\n99%\\n99%\\n\\n\\n# Avg. Prompt Char.\\n1112.5\\n663.2\\n\\n\\n# Avg. Prompt Line\\n33.5\\n11.7\\n\\n# Avg. Prompt Char. (Code)\\n1112.5\\n124.0\\n\\n\\n# Avg. Solution Char.… See the full description on the dataset page: https://huggingface.co/datasets/bigcode/bigcodebench."},
	{"name":"bigcodebench","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bigcode/bigcodebench","creator_name":"BigCode","creator_url":"https://huggingface.co/bigcode","description":"\\n\\t\\n\\t\\t\\n\\t\\tBigCodeBench\\n\\t\\n\\n\\n\\n\\n\\nThe dataset has 2 variants: \\n\\nBigCodeBench-Complete: Code Completion based on the structured docstrings.\\n BigCodeBench-Instruct: Code Generation based on the NL-oriented instructions.\\n\\nThe overall statistics of the dataset are as follows:\\n\\n\\t\\n\\t\\t\\n\\nComplete\\nInstruct\\n\\n\\n\\t\\t\\n# Task\\n1140\\n1140\\n\\n\\n# Avg. Test Cases\\n5.6\\n5.6\\n\\n\\n# Avg. Coverage\\n99%\\n99%\\n\\n\\n# Avg. Prompt Char.\\n1112.5\\n663.2\\n\\n\\n# Avg. Prompt Line\\n33.5\\n11.7\\n\\n# Avg. Prompt Char. (Code)\\n1112.5\\n124.0\\n\\n\\n# Avg. Solution Char.… See the full description on the dataset page: https://huggingface.co/datasets/bigcode/bigcodebench."},
	{"name":"ConBench_D","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ConBench/ConBench_D","creator_name":"ConBench","creator_url":"https://huggingface.co/ConBench","description":"ConBench/ConBench_D dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"base64-decode-v2","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/neoneye/base64-decode-v2","creator_name":"Simon Strandgaard","creator_url":"https://huggingface.co/neoneye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset: Base64 decode version2\\n\\t\\n\\nThis dataset is for improving base64 decoding capabilities.\\nThis improves on the neoneye/base64-decode-v1 dataset.\\nHere number of bytes that are in the base64 encoded data spans between 0..255 bytes. Where version 1 spans between 0..127.\\nHere 3 different random functions are used. Where version 1 uses 1 random function.\\nGPT 4o is great at base64 decoding.\\nHowever llama3 is terrible at base64 decoding.\\nShort examples of what data.jsonl looks like:… See the full description on the dataset page: https://huggingface.co/datasets/neoneye/base64-decode-v2."},
	{"name":"InfiBench","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/llylly001/InfiBench","creator_name":"Linyi Li","creator_url":"https://huggingface.co/llylly001","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInfiBench (Data Part)\\n\\t\\n\\nNote: For full description, please visit our main website https://infi-coder.github.io/infibench.\\nThis repo contains all data of our code LLM evaluation dataset InfiBench. suite_v2.1.yaml lists the case list and suite_v2.1_data.csv records all data (prompt, reference answer, evaluation metric). The data can be directly consumed by our automatic evaluation tool to evaluate any model's response.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\nName: InfiBench\\nDescription:… See the full description on the dataset page: https://huggingface.co/datasets/llylly001/InfiBench."},
	{"name":"linux-comands","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/mhdabdelrhman/linux-comands","creator_name":"Muhammet Abdurrahman","creator_url":"https://huggingface.co/mhdabdelrhman","description":"mhdabdelrhman/linux-comands dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cpp-10k","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dumb-dev/cpp-10k","creator_name":"dev.lenn","creator_url":"https://huggingface.co/dumb-dev","description":"10k random lines of the \\\"text\\\" column of the https://huggingface.co/datasets/wttw/code_contest_instruct_cpp dataset\\n"},
	{"name":"enamel","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/q-rz/enamel","creator_name":"Ruizhong Qiu","creator_url":"https://huggingface.co/q-rz","description":"See also:\\n\\n\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tWhat is ENAMEL?\\n\\t\\n\\nENAMEL is a rigorous and high-standard benchmark for evaluating the capability of large language models (LLMs) in generating efficient code. We provide:\\nA new metric eff@k characterizing the relationship between code efficiency and sample size k;\\nA problem set consisting of 142 high-quality problems selected from OpenAI HumanEval;\\nExpert-written efficient reference solutions, setting a high-standard for efficiency evaluation;\\nExpert-written strong test… See the full description on the dataset page: https://huggingface.co/datasets/q-rz/enamel."},
	{"name":"zigcode-1000","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Sovenok-Hacker/zigcode-1000","creator_name":"Artem Hvostov","creator_url":"https://huggingface.co/Sovenok-Hacker","description":"Zig programming language code dataset, loaded using GitHub Search REST API.\\n"},
	{"name":"Buzz-slice-1-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-1-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to… See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-1-10-V1.2."},
	{"name":"Buzz-slice-10-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-10-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to… See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-10-10-V1.2."},
	{"name":"Buzz-slice-2-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-2-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to… See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-2-10-V1.2."},
	{"name":"Buzz-slice-3-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-3-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to… See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-3-10-V1.2."},
	{"name":"Buzz-slice-4-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-4-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to… See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-4-10-V1.2."},
	{"name":"Buzz-slice-5-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-5-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to… See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-5-10-V1.2."},
	{"name":"Buzz-slice-6-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-6-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to… See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-6-10-V1.2."},
	{"name":"Buzz-slice-7-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-7-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to… See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-7-10-V1.2."},
	{"name":"Buzz-slice-8-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-8-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to… See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-8-10-V1.2."},
	{"name":"Buzz-slice-9-10-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/H-D-T/Buzz-slice-9-10-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to… See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-slice-9-10-V1.2."},
	{"name":"Arabic_Poems","keyword":"code","license":"GNU General Public License v2.0","language":"en","url":"https://huggingface.co/datasets/alwalid54321/Arabic_Poems","creator_name":"Alwalid Ibrahim","creator_url":"https://huggingface.co/alwalid54321","description":"Arabic Poems\\nit's a filtered version for (https://huggingface.co/datasets/arbml/ashaar) with only al-diwan data\\nOverview:\\nThe \\\"Arabic Poems\\\" dataset is a comprehensive collection of Arabic poetry, comprising 8,875 entries. Each entry contains detailed information about individual poems and their respective poets, making it a valuable resource for researchers, developers, and enthusiasts of Arabic literature.\\nColumns:\\nUnnamed: 0: An index column.\\npoem_title: The title of the poem.\\npoem_meter:… See the full description on the dataset page: https://huggingface.co/datasets/alwalid54321/Arabic_Poems."},
	{"name":"RepoExec","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Fsoft-AIC/RepoExec","creator_name":"FPT Software AI Center","creator_url":"https://huggingface.co/Fsoft-AIC","description":"\\n\\t\\n\\t\\t\\n\\t\\tRepoExec: Evaluate Code Generation with a Repository-Level Executable Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nRepoExec is a novel benchmark designed to evaluate code generation at the repository level with a focus on executability and correctness. This benchmark addresses the gaps in existing systems by emphasizing real-world applicability and providing a comprehensive assessment of code functionality. It aims to provide a comprehensive evaluation of code functionality and alignment… See the full description on the dataset page: https://huggingface.co/datasets/Fsoft-AIC/RepoExec."},
	{"name":"sql-create-context-pt","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/emdemor/sql-create-context-pt","creator_name":"Eduardo Morais","creator_url":"https://huggingface.co/emdemor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEste dataset  é uma versão traduzida para o português do dataset b-mc2/sql-create-context,\\nque foi construído a partir dos datasets WikiSQL e Spider. Ele contém exemplos de perguntas\\nem português, instruções SQL CREATE TABLE e consultas SQL que respondem às perguntas\\nutilizando a instrução CREATE TABLE como contexto.\\nO principal objetivo deste dataset é ajudar modelos de linguagem natural  em português a gerar consultas\\nSQL precisas e contextualizadas, prevenindo a… See the full description on the dataset page: https://huggingface.co/datasets/emdemor/sql-create-context-pt."},
	{"name":"golang-programming-style-best-practices","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/smcleod/golang-programming-style-best-practices","creator_name":"Sam McLeod","creator_url":"https://huggingface.co/smcleod","description":"Note: WIP - This dataset has not yet been curated to remove duplicates and filler\\nDataset trained on several popular open source Golang style guides and the effective go book.\\nSource training data:\\n\\nhttps://go.dev/doc/effective_go\\nhttps://github.com/uber-go/guide/blob/master/style.md\\nhttps://google.github.io/styleguide/go/best-practices\\n\\nQ&A generated using Augment Toolkit\\nGeneration models:\\n\\nyi-large (API access kindly donated by 01.ai)\\nhermes-2-theta-llama-3-8b\\nqwen2-72b-instruct\\n\\n"},
	{"name":"hackercup","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/hackercupai/hackercup","creator_name":"HackerCupAI","creator_url":"https://huggingface.co/hackercupai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Preview\\n\\t\\n\\nThe data available in this preview contains a 10 row dataset:\\n\\nSample Dataset (\\\"sample\\\"): This is a subset of the full dataset, containing data from 2023.\\n\\nTo view full dataset, download output_dataset.parquet. This contains data from 2011 to 2023.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFields\\n\\t\\n\\nThe dataset include the following fields:\\n\\nname (string)\\nyear (string)\\nround (string)\\nstatement (string)\\ninput (string)\\nsolution (string)\\ncode (string)\\nsample_input (string)\\nsample_output (string)… See the full description on the dataset page: https://huggingface.co/datasets/hackercupai/hackercup."},
	{"name":"arxiv-cstext","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/tensorkelechi/arxiv-cstext","creator_name":"kelechic","creator_url":"https://huggingface.co/tensorkelechi","description":"tensorkelechi/arxiv-cstext dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"testedados","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/MatheusFr/testedados","creator_name":"Matheus Francisco","creator_url":"https://huggingface.co/MatheusFr","description":"MatheusFr/testedados dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Big_Personality","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AryankP1/Big_Personality","creator_name":"Aryank Bhargava","creator_url":"https://huggingface.co/AryankP1","description":"AryankP1/Big_Personality dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"kaz-rus-eng-literature-parallel-corpus","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Nothingger/kaz-rus-eng-literature-parallel-corpus","creator_name":"Sagi Abdashim","creator_url":"https://huggingface.co/Nothingger","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual Literature Parallel Corpus\\n\\t\\n\\n\\n\\nThe Multilingual Literature Parallel Corpus is designed for translation tasks, containing parallel text pairs from literature in three languages: Kazakh (kaz_Cyrl), Russian (rus_Cyrl), and English (eng_Latn).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nThe Multilingual Literature Parallel Corpus provides parallel text pairs for translation tasks across Kazakh, Russian, and English. The dataset is… See the full description on the dataset page: https://huggingface.co/datasets/Nothingger/kaz-rus-eng-literature-parallel-corpus."},
	{"name":"RepoExec-Instruct","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Fsoft-AIC/RepoExec-Instruct","creator_name":"FPT Software AI Center","creator_url":"https://huggingface.co/Fsoft-AIC","description":"\\n\\t\\n\\t\\t\\n\\t\\tRepoExec: Evaluate Code Generation with a Repository-Level Executable Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis source contains the instruction-tuning dataset to fine-tune models in our work.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Instances\\n\\t\\n\\n{\\n    \\\"id\\\": 0,\\n    \\\"prompt\\\": \\\"import base64\\\\nimport random\\\\nimport unicodedata\\\\nimport zlib\\\\nfrom typing import Union\\\\nfrom uuid import uuid4\\\\nfrom ._regex import *\\\\nfrom .errors import InvalidInputError\\\\nfrom .validation import… See the full description on the dataset page: https://huggingface.co/datasets/Fsoft-AIC/RepoExec-Instruct."},
	{"name":"Clapping_Sound_Dataset","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zahidpichen/Clapping_Sound_Dataset","creator_name":"zahidpichen","creator_url":"https://huggingface.co/zahidpichen","description":"zahidpichen/Clapping_Sound_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"github-issues","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kailasps/github-issues","creator_name":"Kailas P S","creator_url":"https://huggingface.co/kailasps","description":"kailasps/github-issues dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"code-generation-py","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/dtruong46me/code-generation-py","creator_name":"Dinh Truong Phan","creator_url":"https://huggingface.co/dtruong46me","description":"dtruong46me/code-generation-py dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"list-sorting","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ChandraP12330/list-sorting","creator_name":"Chandra Prakash","creator_url":"https://huggingface.co/ChandraP12330","description":"ChandraP12330/list-sorting dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"holiday_calendar","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/saadbhaldar1212/holiday_calendar","creator_name":"Mohammad Saad Hasan Bhaldar","creator_url":"https://huggingface.co/saadbhaldar1212","description":"saadbhaldar1212/holiday_calendar dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"LAMx-2.2","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/gokul00060/LAMx-2.2","creator_name":"SK Gokul","creator_url":"https://huggingface.co/gokul00060","description":"gokul00060/LAMx-2.2 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"test03","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/liuqingquan/test03","creator_name":"lqq","creator_url":"https://huggingface.co/liuqingquan","description":"liuqingquan/test03 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"puhui","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/qijiabo/puhui","creator_name":"jiabo","creator_url":"https://huggingface.co/qijiabo","description":"qijiabo/puhui dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"UIT-CourseInfo","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/PhucDanh/UIT-CourseInfo","creator_name":"Ngo Phuc Danh","creator_url":"https://huggingface.co/PhucDanh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nWe have meticulously compiled a comprehensive dataset consisting of 4,230 samples collected through advanced data crawling techniques from the University of Information Technology (UIT) website. This dataset includes detailed summaries of courses and extensive descriptions of various study programs offered at UIT. By targeting and extracting data from the student.uit domain, we have ensured that the dataset accurately represents the university's academic offerings.\\nThe… See the full description on the dataset page: https://huggingface.co/datasets/PhucDanh/UIT-CourseInfo."},
	{"name":"mermaid_code","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bucaro/mermaid_code","creator_name":"Jonathan Búcaro","creator_url":"https://huggingface.co/bucaro","description":"bucaro/mermaid_code dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"svgen_500k_rasterized_jsonified_uuided","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MrOvkill/svgen_500k_rasterized_jsonified_uuided","creator_name":"Samuel L Meyers","creator_url":"https://huggingface.co/MrOvkill","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSVGEN RJU - SVGEN 500k: Rasterized, JSONified, UUID'ed\\n\\t\\n\\nI have selected every svg image from svgen that would rasterize under cairosvg, which is significantly less than a 1% failure rate. Under development.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReasoning\\n\\t\\n\\nThis is the 1st of many SVG datasets I am collecting, extracting, and rasterizing in an attempt to produce a meaningfully helpful spatial reasoning and vertex manipulation model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThe rasterized images are in PNG format, as bytes.… See the full description on the dataset page: https://huggingface.co/datasets/MrOvkill/svgen_500k_rasterized_jsonified_uuided."},
	{"name":"Testing","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/WendigoDaniel/Testing","creator_name":"Wendigo","creator_url":"https://huggingface.co/WendigoDaniel","description":"WendigoDaniel/Testing dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Synthetic-JP-Coding-Dataset-Magpie-Nemotron-4-10k","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Aratako/Synthetic-JP-Coding-Dataset-Magpie-Nemotron-4-10k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic-JP-Coding-Dataset-Magpie-Nemotron-4-10k\\n\\t\\n\\nMagpieの手法をnvidia/Nemotron-4-340B-Instructに対して適用し作成した、約10000件の日本語のコーディング用対話データセットです。\\nデータセットの作成にはDeepInfraを利用しました。\\nまた、このリポジトリでデータセット作成に用いたコードを公開しています。これをベースに、システムプロンプトとstopを一部変更することで生成しています。\\n特に事後的なフィルタ処理は加えていないため、クオリティの低いレコードが含まれている可能性があります。ご注意ください。\\n"},
	{"name":"CodeHarmony","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Flab-Pruner/CodeHarmony","creator_name":"Flab-Pruner","creator_url":"https://huggingface.co/Flab-Pruner","description":"Acknowledging the limitations of current datasets with a limited number of samples, we have curated a new dataset CodeHarmony.\\nThis dataset is compiled from existing open-source datasets, such as the Evol dataset and OSS dataset. \\nTo ensure the semantic correctness of this dataset, we utilize GPT-3.5 and Gemini for automated test case generation, overseen by humans to ensure code functionality. \\nInspired by the multi-agent alignment, we have also integrated CoT data into the dataset. \\n"},
	{"name":"InverseCoder-CL-7B-Evol-Instruct-90K","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/wyt2000/InverseCoder-CL-7B-Evol-Instruct-90K","creator_name":"Yutong Wu","creator_url":"https://huggingface.co/wyt2000","description":"\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct\\n\\t\\n\\n \\n\\nInverseCoder is a series of code LLMs instruction-tuned by generating data from itself through Inverse-Instruct.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModels and Datasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\nBase Model\\nInverseCoder\\nDataset\\n\\n\\n\\t\\t\\n6.7B\\ndeepseek-ai/deepseek-coder-6.7b-base\\nwyt2000/InverseCoder-DS-6.7B\\nwyt2000/InverseCoder-DS-6.7B-Evol-Instruct-90K\\n\\n\\n7B\\ncodellama/CodeLlama-7b-Python-hf\\nwyt2000/InverseCoder-CL-7B… See the full description on the dataset page: https://huggingface.co/datasets/wyt2000/InverseCoder-CL-7B-Evol-Instruct-90K."},
	{"name":"news-sentiment-data","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sweatSmile/news-sentiment-data","creator_name":"amitk17","creator_url":"https://huggingface.co/sweatSmile","description":"sweatSmile/news-sentiment-data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"InverseCoder-DS-6.7B-Evol-Instruct-90K","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/wyt2000/InverseCoder-DS-6.7B-Evol-Instruct-90K","creator_name":"Yutong Wu","creator_url":"https://huggingface.co/wyt2000","description":"\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct\\n\\t\\n\\n \\n\\nInverseCoder is a series of code LLMs instruction-tuned by generating data from itself through Inverse-Instruct.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModels and Datasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\nBase Model\\nInverseCoder\\nDataset\\n\\n\\n\\t\\t\\n6.7B\\ndeepseek-ai/deepseek-coder-6.7b-base\\nwyt2000/InverseCoder-DS-6.7B\\nwyt2000/InverseCoder-DS-6.7B-Evol-Instruct-90K <= You are here\\n\\n\\n7B\\ncodellama/CodeLlama-7b-Python-hf… See the full description on the dataset page: https://huggingface.co/datasets/wyt2000/InverseCoder-DS-6.7B-Evol-Instruct-90K."},
	{"name":"InverseCoder-CL-13B-Evol-Instruct-90K","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/wyt2000/InverseCoder-CL-13B-Evol-Instruct-90K","creator_name":"Yutong Wu","creator_url":"https://huggingface.co/wyt2000","description":"\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct\\n\\t\\n\\n \\n\\nInverseCoder is a series of code LLMs instruction-tuned by generating data from itself through Inverse-Instruct.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModels and Datasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\nBase Model\\nInverseCoder\\nDataset\\n\\n\\n\\t\\t\\n6.7B\\ndeepseek-ai/deepseek-coder-6.7b-base\\nwyt2000/InverseCoder-DS-6.7B\\nwyt2000/InverseCoder-DS-6.7B-Evol-Instruct-90K\\n\\n\\n7B\\ncodellama/CodeLlama-7b-Python-hf\\nwyt2000/InverseCoder-CL-7B… See the full description on the dataset page: https://huggingface.co/datasets/wyt2000/InverseCoder-CL-13B-Evol-Instruct-90K."},
	{"name":"Sentiment_lexicons","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mahmed31/Sentiment_lexicons","creator_name":"Muhammad Ahmed","creator_url":"https://huggingface.co/mahmed31","description":"mahmed31/Sentiment_lexicons dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"pyomo-100","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/wickes1/pyomo-100","creator_name":"wickes","creator_url":"https://huggingface.co/wickes1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPyomo Code Generation Fine-Tuning Dataset (Generated by GPT-4o)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset is designed for fine-tuning the Phi3 model to generate Pyomo code based on user inputs and existing code contexts. It includes various examples of user queries, existing Pyomo code contexts, and AI-generated responses.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\n\\ninput: The user's query or task description.\\ncontext: The existing Pyomo code related to the query.\\noutput: The AI assistant's… See the full description on the dataset page: https://huggingface.co/datasets/wickes1/pyomo-100."},
	{"name":"oop","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/codeai-dteam/oop","creator_name":"CodeAI","creator_url":"https://huggingface.co/codeai-dteam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlicense: apache-2.0\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Object-Oriented Programming\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe OOP benchmark consists of 431 instances, and contains three difficulty levels: Simple-level OOP, Moderate-level OOP, and Difficult-level OOP.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe Object-Oriented Programming problems are written in Python and contain English natural text in comments and docstrings.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure… See the full description on the dataset page: https://huggingface.co/datasets/codeai-dteam/oop."},
	{"name":"FVELer","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/FVELer/FVELer","creator_name":"FVELer","creator_url":"https://huggingface.co/FVELer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe FVELer Dataset\\n\\t\\n\\nDataset examples can be found at https://fveler.github.io/.\\n"},
	{"name":"Synthetic-JP-EN-Coding-Dataset-Magpie-69k","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Coding-Dataset-Magpie-69k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic-JP-EN-Coding-Dataset-Magpie-69k\\n\\t\\n\\nMagpieの手法を様々なモデルに対して適用し作成した、約69000件の日本語・英語のコーディング対話データセットです。\\n作成に利用したモデルは以下の通りです。modelキーに該当レコードの作成に利用したモデル情報があります。\\n\\nnvidia/Nemotron-4-340B-Instruct\\nmicrosoft/Phi-3-medium-4k-instruct\\nmistralai/Mixtral-8x22B-Instruct-v0.1\\ncyberagent/calm3-22b-chat\\n\\nデータセットの作成にはDeepInfraを利用しました。\\nまた、このリポジトリでデータセット作成に用いたコードを公開しています。これをベースに、プロンプトテンプレートやシステムプロンプト等を一部変更することで生成しています。\\n特に事後的なフィルタ処理は加えていないため、クオリティの低いレコードが含まれている可能性があります。ご注意ください。\\n"},
	{"name":"simple-test","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/BruceNju/simple-test","creator_name":"zhongyah","creator_url":"https://huggingface.co/BruceNju","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTriffic\\n\\t\\n\\n"},
	{"name":"Synthetic-JP-EN-Coding-Dataset-801k","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Coding-Dataset-801k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic-JP-EN-Coding-Dataset-801k\\n\\t\\n\\nMagpieによって作成したコードSFTデータセットであるAratako/Synthetic-JP-EN-Coding-Dataset-Magpie-69kを元に、Evol-Instructのような手法を用いて複数のinstructionとresonseを生成し拡張して作成した、日英混合801262件のコードSFT用合成データセットです。\\n\\n日本語: 173849件\\n英語: 627413件\\n\\n元のinstructionの作成に利用したモデルは以下の通りです。modelキーに該当レコードの作成に利用したモデル情報があります。\\n\\nnvidia/Nemotron-4-340B-Instruct\\nmicrosoft/Phi-3-medium-4k-instruct\\nmistralai/Mixtral-8x22B-Instruct-v0.1\\ncyberagent/calm3-22b-chat… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Coding-Dataset-801k."},
	{"name":"icml2024_embeddings","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/porestar/icml2024_embeddings","creator_name":"Lukas Mosser","creator_url":"https://huggingface.co/porestar","description":"porestar/icml2024_embeddings dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"love2dapi_chunks","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Nocare3/love2dapi_chunks","creator_name":"Andi Allaraj","creator_url":"https://huggingface.co/Nocare3","description":"LOVE2d API - Lua Game Engine\\nThis dataset represents the API documentation for the LOVE2d Lua game engine. It was taken from https://love2d-community.github.io/love-api.\\nThe goal is to use it to train a chatbot that can easily answer users' questions regarding the engine.\\nThis would likely help people that want a more conversational approach to finding the code they need for specific tasks.\\n"},
	{"name":"leetcode-rosetta","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/scottsuk0306/leetcode-rosetta","creator_name":"Juyoung Suk","creator_url":"https://huggingface.co/scottsuk0306","description":"scottsuk0306/leetcode-rosetta dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cat-breed-blip-fine-tuning","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zahidpichen/cat-breed-blip-fine-tuning","creator_name":"zahidpichen","creator_url":"https://huggingface.co/zahidpichen","description":"zahidpichen/cat-breed-blip-fine-tuning dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"data","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zahidpichen/data","creator_name":"zahidpichen","creator_url":"https://huggingface.co/zahidpichen","description":"zahidpichen/data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cs_tiny_codes_alpaca","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/abhijitkumarjha88192/cs_tiny_codes_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/cs_tiny_codes_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"buddhi-dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/aiplanet/buddhi-dataset","creator_name":"AI Planet","creator_url":"https://huggingface.co/aiplanet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuddhi Dataset\\n\\t\\n\\nThis dataset was used to train our 128K context window model: Buddhi-128k-Chat-7B. The dataset was generated in a Self-Instruct style using GPT-4 and GPT-3 models, along with data from the Stack Exchange and PG19 open-source datasets.\\nBuddhi-128K-Chat\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuddhi-128K-Chat (7B) vLLM Inference: \\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRead release article: 🔗 Introducing Buddhi: Open-Source Chat Model with a 128K Context Window 🔗 \\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Description… See the full description on the dataset page: https://huggingface.co/datasets/aiplanet/buddhi-dataset."},
	{"name":"cat_breed","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zahidpichen/cat_breed","creator_name":"zahidpichen","creator_url":"https://huggingface.co/zahidpichen","description":"zahidpichen/cat_breed dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"py_tiny_codes_alpaca","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/abhijitkumarjha88192/py_tiny_codes_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/py_tiny_codes_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"js_tiny_codes_alpaca","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/abhijitkumarjha88192/js_tiny_codes_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/js_tiny_codes_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ts_tiny_codes_alpaca","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/abhijitkumarjha88192/ts_tiny_codes_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/ts_tiny_codes_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cs_repl_ai_alpaca","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/abhijitkumarjha88192/cs_repl_ai_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/cs_repl_ai_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"py_repl_ai_alpaca","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/abhijitkumarjha88192/py_repl_ai_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/py_repl_ai_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"js_repl_ai_alpaca","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/abhijitkumarjha88192/js_repl_ai_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/js_repl_ai_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ts_repl_ai_alpaca","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/abhijitkumarjha88192/ts_repl_ai_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/ts_repl_ai_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sql_repl_ai_alpaca","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/abhijitkumarjha88192/sql_repl_ai_alpaca","creator_name":"Abhijit","creator_url":"https://huggingface.co/abhijitkumarjha88192","description":"abhijitkumarjha88192/sql_repl_ai_alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Tachibana","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sequelbox/Tachibana","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Tachibana is a dataset containing code-instruct data.\\nThe 2024-09-27 version contains:\\n\\n104k rows of synthetic chat responses generated using Llama 3.1 405b Instruct.\\n60.6k Magicoder prompts from ise-uiuc/Magicoder-Evol-Instruct-110K\\n43.4k Glaive-code-assistant prompts from glaiveai/glaive-code-assistant\\n\\n\\n\\nThis dataset contains synthetically generated data and has not been subject to manual review.\\n"},
	{"name":"SynthUI-Code-2k-v1","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/JulianAT/SynthUI-Code-2k-v1","creator_name":"Julian Schmidt","creator_url":"https://huggingface.co/JulianAT","description":"Synth UI 🎹\\nhttps://www.synthui.design\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset details\\n\\t\\n\\nThis dataset aims to provide a diverse collection of NextJS code snippets, along with their corresponding instructions, to facilitate the training of language models for NextJS-related tasks. It is designed to cover a wide range of NextJS functionalities, including UI components, routing, state management, and more.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis dataset consists of:\\n\\t\\n\\n\\nNote: The dataset is seperated into two main parts:\\n\\nraw Contains… See the full description on the dataset page: https://huggingface.co/datasets/JulianAT/SynthUI-Code-2k-v1."},
	{"name":"custom_llm_data","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/drgary/custom_llm_data","creator_name":"DrYe","creator_url":"https://huggingface.co/drgary","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Train Brand LLM?\\n\\t\\n\\n\\nLaunch Athena Generative AI Starter Kit from AWS Marketplace (see https://aws.amazon.com/marketplace/pp/prodview-su3dsq7b4plxw) \\nThis is public Dataset 1 for training generic Model m2, code at host 4090 ~/athena/m2/m2_athena3.py\\nUse Parquet Hub to add private brand Dataset 2 to the m2 parquet file. Then train Model m3, the enterprise Brand LLM {see \\\"Brand LLM: Parquet Hub\\\"}\\nRun Model m3 training code at host 4090 ~/athena/m3/m3_model.py\\nRemember 'conda… See the full description on the dataset page: https://huggingface.co/datasets/drgary/custom_llm_data."},
	{"name":"text_to_jsonFormSchema","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/shankerhrm/text_to_jsonFormSchema","creator_name":"Jaishanker","creator_url":"https://huggingface.co/shankerhrm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/shankerhrm/text_to_jsonFormSchema."},
	{"name":"summary-demo","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jacquetg/summary-demo","creator_name":"Gottfried JACQUET","creator_url":"https://huggingface.co/jacquetg","description":"jacquetg/summary-demo dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"essays-big5","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jingjietan/essays-big5","creator_name":"Tan Jing Jie","creator_url":"https://huggingface.co/jingjietan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPersonality Dataset\\n\\t\\n\\nEssays\\nhttps://huggingface.co/datasets/jingjietan/essays-big5\\nMBTI\\nhttps://huggingface.co/datasets/jingjietan/kaggle-mbti\\nPandora\\nhttps://huggingface.co/datasets/jingjietan/pandora-big5\\nCite:\\n@software{jingjietan-apr-dataset,\\n  author = {Jing Jie, Tan},\\n  title = {Personality Essays Dataset Splitting},\\n  url = {https://huggingface.co/datasets/jingjietan/essays-big5},\\n  version = {1.0.0},\\n  year = {2024}\\n}\\n"},
	{"name":"kaggle-mbti","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jingjietan/kaggle-mbti","creator_name":"Tan Jing Jie","creator_url":"https://huggingface.co/jingjietan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPersonality Dataset\\n\\t\\n\\nEssays\\nhttps://huggingface.co/datasets/jingjietan/essays-big5\\nMBTI\\nhttps://huggingface.co/datasets/jingjietan/kaggle-mbti\\nPandora\\nhttps://huggingface.co/datasets/jingjietan/pandora-big5\\nPlease contact jingjietan.com for another dataset.\\nCite:\\n@software{jingjietan-apr-dataset,\\n  author = {Jing Jie, Tan},\\n  title = {Personality Kaggle Dataset Splitting},\\n  url = {https://huggingface.co/datasets/jingjietan/kaggle-mbti},\\n  version = {1.0.0},\\n  year = {2024}\\n}\\n"},
	{"name":"Code-Feedback-Parsed","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kaleinaNyan/Code-Feedback-Parsed","creator_name":"Igor Kilbas","creator_url":"https://huggingface.co/kaleinaNyan","description":"This is a parsed subset of the Code-Feedback dataset.\\nEach sample in the dataset is formatted in the following way:\\n{\\\"messages\\\": [\\n  {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"user prompt\\\"}, \\n  {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"assistant response\\\", \\\"tool_call\\\": \\\"python code\\\"}, \\n  {\\\"role\\\": \\\"tool\\\", \\\"content\\\": \\\"code execution result\\\"},\\n  {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"assistant response\\\"},\\n]}\\n\\nThe dataset has been filtered from any refusials, mentions of OpenAI, quantum computing, crypto currency and other… See the full description on the dataset page: https://huggingface.co/datasets/kaleinaNyan/Code-Feedback-Parsed."},
	{"name":"small_kitchen_appliances_review","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jr-d-analyst24/small_kitchen_appliances_review","creator_name":"dayoungyoun","creator_url":"https://huggingface.co/jr-d-analyst24","description":"jr-d-analyst24/small_kitchen_appliances_review dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"lx","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/llanguagemtrainer/lx","creator_name":"praveen","creator_url":"https://huggingface.co/llanguagemtrainer","description":"llanguagemtrainer/lx dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"uk_dataset","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/rahayu/uk_dataset","creator_name":"Rahayu","creator_url":"https://huggingface.co/rahayu","description":"rahayu/uk_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"github-code-fontend-lang","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/LiXiang12/github-code-fontend-lang","creator_name":"XiangLi","creator_url":"https://huggingface.co/LiXiang12","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tgithub-code fontend code\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDwonload\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t方式一\\n\\t\\n\\nhuggingface-cli download --resume-download LiXiang12/github-code-fontend-lang --include \\\"*/*.zip\\\" --repo-type dataset  --local-dir github_code\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t方式二\\n\\t\\n\\n进入Files and versions/data直接下载zip文件\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据统计\\n\\t\\n\\n\\n"},
	{"name":"bio-image-analysis-qa","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/haesleinhuepf/bio-image-analysis-qa","creator_name":"Robert Haase","creator_url":"https://huggingface.co/haesleinhuepf","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for bio-image-analysis-qa\\n\\t\\n\\nThis dataset contains questions and answers for analysing biological microscopy imaging data using python.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nQuestions and answers provided in this repository are centered around the topic, how to process imaging data using Python. \\n\\nCurated by: Robert Haase\\nLicense: CC-BY 4.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources and Processing\\n\\t\\n\\nThis dataset was derived from the Bio-image Analysis… See the full description on the dataset page: https://huggingface.co/datasets/haesleinhuepf/bio-image-analysis-qa."},
	{"name":"SynthUI-Code-Instruct-2k-v1","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/JulianAT/SynthUI-Code-Instruct-2k-v1","creator_name":"Julian Schmidt","creator_url":"https://huggingface.co/JulianAT","description":"Synth UI 🎹\\nhttps://www.synthui.design\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset details\\n\\t\\n\\nThis dataset aims to provide a diverse collection of NextJS code snippets, along with their corresponding instructions, to facilitate the training of language models for NextJS-related tasks. It is designed to cover a wide range of NextJS functionalities, including UI components, routing, state management, and more.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis dataset consists of:\\n\\t\\n\\n\\nNote: The dataset is seperated into two main parts:\\n\\nraw Contains… See the full description on the dataset page: https://huggingface.co/datasets/JulianAT/SynthUI-Code-Instruct-2k-v1."},
	{"name":"codesearchnet-codegen","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/pengyunie/codesearchnet-codegen","creator_name":"Pengyu Nie","creator_url":"https://huggingface.co/pengyunie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CodeSearchNet for CodeGen\\n\\t\\n\\n\\n\\nThis is a processed version of the CodeSearchNet dataset. Namely, I separated the doc (documentation/docstring), sign (function signature), and output (function body) into separate fields; doc and sign are concatenated (according to the correct order of the programming language) into the problem field, making it suitable for the code generation task.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by:… See the full description on the dataset page: https://huggingface.co/datasets/pengyunie/codesearchnet-codegen."},
	{"name":"CodeJudge-Eval","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CodeResearch/CodeJudge-Eval","creator_name":"Open Code LLM Research Community","creator_url":"https://huggingface.co/CodeResearch","description":"\\nCodeJudge-Eval:  Can Large Language Models be Good Judges in Code Understanding?\\n If our project helps you, please give us a star ⭐ on GitHub to support us. 🙏🙏 \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nRecent advancements in large language models (LLMs) have showcased impressive code generation capabilities, primarily evaluated through language-to-code benchmarks. However, these benchmarks may not fully capture a model's code understanding abilities. We introduce CodeJudge-Eval (CJ-Eval), a novel… See the full description on the dataset page: https://huggingface.co/datasets/CodeResearch/CodeJudge-Eval."},
	{"name":"Celestia","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sequelbox/Celestia","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Celestia is a dataset containing science-instruct data.\\nThe 2024-10-30 version contains:\\n\\n126k rows of synthetic science-instruct data, using synthetically generated prompts and responses generated using Llama 3.1 405b Instruct. Primary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\\n\\nThis dataset contains synthetically generated data and has not been subject to manual review.\\n"},
	{"name":"muri-it-language-split","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic… See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split."},
	{"name":"PythonCombined","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Montecarlo2024/PythonCombined","creator_name":"James","creator_url":"https://huggingface.co/Montecarlo2024","description":"Dataset is a combination of:\\nflytech/python-codes-25k, \\nNa0s/sft-ready-iamtarun-python-code-instructions-18k-alpaca, \\nmlabonne/Evol-Instruct-Python-26k, \\niamtarun/python_code_instructions_18k_alpaca\\nThis is a test for model building\\n"},
	{"name":"bss-custom-dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bizlaz/bss-custom-dataset","creator_name":"biz-lazy","creator_url":"https://huggingface.co/bizlaz","description":"bizlaz/bss-custom-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"FutureVision","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Aymenbhh/FutureVision","creator_name":"Aymen Ben hadj","creator_url":"https://huggingface.co/Aymenbhh","description":"Aymenbhh/FutureVision dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"wikireading","keyword":"code","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/its5Q/wikireading","creator_name":"its5Q","creator_url":"https://huggingface.co/its5Q","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Wikireading\\n\\t\\n\\nThis is a dataset of book chapters scraped from a Russian website called Wikireading.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWikireading is a collection of non-fiction educational books in various domains: Biology, Art, History, Religion and much more. The books are highly educational and provide vast knowledge in different domains, making this dataset a good choice for pretraining.\\nThe resulting dataset contains ~26M rows… See the full description on the dataset page: https://huggingface.co/datasets/its5Q/wikireading."},
	{"name":"glaive-function-calling-v2-pl","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/mpieck/glaive-function-calling-v2-pl","creator_name":"Maciej Piecko","creator_url":"https://huggingface.co/mpieck","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for glaive-function-calling-v2-pl Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a fragment of glaiveai/glaive-function-calling-v2 dataset translated to polish. \\nIt contains first 3.3k (out of 5k total, this is work in progress) instructions of the original dataset. Only instructions having function definitions or function calls are included, instructions without functions (ordinary unstructured) from the original dataset are skipped.\\n Some repeating instructions were… See the full description on the dataset page: https://huggingface.co/datasets/mpieck/glaive-function-calling-v2-pl."},
	{"name":"JHumanEval-Mod","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/myst72/JHumanEval-Mod","creator_name":"Miyu Sato","creator_url":"https://huggingface.co/myst72","description":"myst72/JHumanEval-Mod dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sentence-correction","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Ashraf-CK/sentence-correction","creator_name":"Chauhan","creator_url":"https://huggingface.co/Ashraf-CK","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLLM Prompt Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe LLM Prompt Dataset is designed to enhance the performance of large language models (LLMs) by transforming user inputs into structured prompts. This dataset aims to facilitate the understanding of complex queries and improve the interaction between users and LLMs.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset is organized in JSON format, where each entry consists of an input and a prompt. The input represents the original user query… See the full description on the dataset page: https://huggingface.co/datasets/Ashraf-CK/sentence-correction."},
	{"name":"sentence-corrector","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/MohamedAshraf701/sentence-corrector","creator_name":"ashraf chauhan","creator_url":"https://huggingface.co/MohamedAshraf701","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentence Correction & Politeness Dataset\\n\\t\\n\\nThis repository contains a dataset specifically designed for sentence correction and politeness transformation. The dataset includes a set of input sentences and their corresponding polite, well-formatted outputs. It can be used to train AI models to rephrase user inputs in a more formal, polite, and grammatically correct manner.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Sentence Correction & Politeness Dataset is designed to help improve natural… See the full description on the dataset page: https://huggingface.co/datasets/MohamedAshraf701/sentence-corrector."},
	{"name":"lovebangla","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/SrejonAhamed/lovebangla","creator_name":"Joy","creator_url":"https://huggingface.co/SrejonAhamed","description":"SrejonAhamed/lovebangla dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"BanglaBoro","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/SrejonAhamed/BanglaBoro","creator_name":"Joy","creator_url":"https://huggingface.co/SrejonAhamed","description":"SrejonAhamed/BanglaBoro dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"python-code-DPO-fine-tune","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/quangduc1112001/python-code-DPO-fine-tune","creator_name":"Nguyen Quang Duc","creator_url":"https://huggingface.co/quangduc1112001","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDirect Preference Optimization (DPO) Fine-tuning Dataset Description\\n\\t\\n\\nSimilar to standard datasets utilized in RLHF, this dataset comprises a total of 2,000 rows of data, with each row consisting of three distinct fields: prompt, chosen and rejected. Among these properties, the prompt and chosen fields are randomly picked from the dataset known as iamtarun/python_code_instructions_18k_alpaca while the rejected field is obtained from the inference of the base LLAMA 3.1 model based… See the full description on the dataset page: https://huggingface.co/datasets/quangduc1112001/python-code-DPO-fine-tune."},
	{"name":"digdeep_data","keyword":"code","license":"GNU Affero General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/ryan1288/digdeep_data","creator_name":"Ryan Lee","creator_url":"https://huggingface.co/ryan1288","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVolleyball Video Analytics Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is designed to support AI tools for analyzing volleyball games. It contains both raw footage (before processing) and short video snippets with 6 consecutive plays including downtime.\\nGitHub Link\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPlanned Features 📋\\n\\t\\n\\n\\nAuto-Editor: Automatically remove downtime between plays for faster video review.\\nScore Tracking: Timestamp key moments and keep an accurate score throughout the video.… See the full description on the dataset page: https://huggingface.co/datasets/ryan1288/digdeep_data."},
	{"name":"portufake","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/unfake/portufake","creator_name":"Unfake","creator_url":"https://huggingface.co/unfake","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Portufake\\n\\t\\n\\n\\n\\nThis dataset contains spectrograms of audio deepfakes and real speaker recordings in Portuguese, originating from Fake Voices Dataset \\nand CETUC Corpus, respectively.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nThe dataset contains 183,878 512px x 256px colored constant-Q transform (CQT) spectrograms created from audios categorized in two labels: \\\"real\\\" or \\\"fake\\\". \\nThey correspond, respectively, to Brazilian Portuguese… See the full description on the dataset page: https://huggingface.co/datasets/unfake/portufake."},
	{"name":"ReflectionofaLilly","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Sephfox/ReflectionofaLilly","creator_name":"Sephfox","creator_url":"https://huggingface.co/Sephfox","description":"Sephfox/ReflectionofaLilly dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CodeEval","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/chungimungi/CodeEval","creator_name":"Aarush","creator_url":"https://huggingface.co/chungimungi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCodeEval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nLanguage\\nCount\\n\\n\\n\\t\\t\\nPython\\n50\\n\\n\\nJavaScript\\n40\\n\\n\\nJava\\n40\\n\\n\\nRuby\\n20\\n\\n\\nC++\\n20\\n\\n\\nTypeScript\\n10\\n\\n\\nGo\\n20\\n\\n\\nC#\\n10\\n\\n\\nRust\\n10\\n\\n\\nTotal\\n220\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorrectness Statistics\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nCorrectness\\nCount\\n\\n\\n\\t\\t\\nTrue\\n127\\n\\n\\nFalse\\n93\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset is structured as follows:\\n[\\n    {\\n        \\\"language\\\": \\\"python\\\",\\n        \\\"code\\\": \\\"def reverse_string(s):\\\\n    return s.reverse()\\\",\\n        \\\"correctness\\\": false,\\n        \\\"explanation\\\":… See the full description on the dataset page: https://huggingface.co/datasets/chungimungi/CodeEval."},
	{"name":"sample_synthetic_text_to_sql","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/chakshu2/sample_synthetic_text_to_sql","creator_name":"vodala chakshu","creator_url":"https://huggingface.co/chakshu2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample Synthetic Text to SQL Dataset\\n\\t\\n\\nThe dataset presents a substantial collection of expertly crafted Text-to-SQL samples, generated using open source LLM's and \\nshared under an open-source license. Highlights of the dataset include:\\n-- 1563 examples, divided into a training set of 1200 samples and a test set of 363 samples.-- Approximately less than 1 million tokens in total, with nearly 0.5 million representing code-specific tokens.-- Coverage spans a diverse range of 3… See the full description on the dataset page: https://huggingface.co/datasets/chakshu2/sample_synthetic_text_to_sql."},
	{"name":"exLong-dataset","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/EngineeringSoftware/exLong-dataset","creator_name":"EngineeringSoftware","creator_url":"https://huggingface.co/EngineeringSoftware","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\texLong Dataset\\n\\t\\n\\nThis dataset is used to train and evaluate the exLong models on generating exceptional-behavior tests.\\nIt has two subsets:\\n\\n'with-EBT-name': provides the target test name in the prompt\\n'no-EBT-name': does not provide the target test name in the prompt\\n\\nNOTE: the data format is customized for Code Llama models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguage\\n\\t\\n\\nThis is a Java dataset\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe input for the model contains the following context:\\n\\nMethod under test… See the full description on the dataset page: https://huggingface.co/datasets/EngineeringSoftware/exLong-dataset."},
	{"name":"maykel_dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/mayk00/maykel_dataset","creator_name":"cortes","creator_url":"https://huggingface.co/mayk00","description":"cualquier mmd\\n"},
	{"name":"twitter_dataset_try","keyword":"code","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/yanisTiky/twitter_dataset_try","creator_name":"Tiky ekotto yanis","creator_url":"https://huggingface.co/yanisTiky","description":"yanisTiky/twitter_dataset_try dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"data_del","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dalssy/data_del","creator_name":"dalssy leyva lopez","creator_url":"https://huggingface.co/dalssy","description":"dalssy/data_del dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"simple_python_description","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/farahbs/simple_python_description","creator_name":"Farah BEN SLAMA","creator_url":"https://huggingface.co/farahbs","description":"farahbs/simple_python_description dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"qa-portuguese-small","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Jpzinn654/qa-portuguese-small","creator_name":"Juan Pablo","creator_url":"https://huggingface.co/Jpzinn654","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQA-PORTUGUESE-SMALL\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe qa-portuguese-small dataset is a collection of 500,000 question-answer pairs in Portuguese designed for Question Answering (QA) tasks. The dataset includes questions based on a wide variety of domains, such as news, general knowledge, and everyday facts, and provides corresponding answers in natural language.\\nThe dataset is intended for training and evaluating machine learning models that can answer questions in… See the full description on the dataset page: https://huggingface.co/datasets/Jpzinn654/qa-portuguese-small."},
	{"name":"macbinariesprofile","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/geeksuckmatzball/macbinariesprofile","creator_name":"John Tareco","creator_url":"https://huggingface.co/geeksuckmatzball","description":"Mac binaries disassembly profile\\n"},
	{"name":"stationery-1","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/keikhosrotav/stationery-1","creator_name":"keikhosro tavakoli","creator_url":"https://huggingface.co/keikhosrotav","description":"keikhosrotav/stationery-1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"tech-docs","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/saidsef/tech-docs","creator_name":"Said Sef","creator_url":"https://huggingface.co/saidsef","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTechnical Documentation Dataset\\n\\t\\n\\nA curated collection of technical documentation and guides spanning various cloud-native technologies, infrastructure tools, and machine learning frameworks. This dataset contains 1,397 documents in JSONL format, covering essential topics for modern software development and DevOps practices.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThis dataset includes documentation across multiple domains:\\n\\nCloud Platforms: GCP (83 docs), EKS (33 docs)\\nKubernetes… See the full description on the dataset page: https://huggingface.co/datasets/saidsef/tech-docs."},
	{"name":"Temporary-Datasets","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/RichMiguel/Temporary-Datasets","creator_name":"Richell Mark B. Miguel","creator_url":"https://huggingface.co/RichMiguel","description":"RichMiguel/Temporary-Datasets dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"SWE-agent-trajectories","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/nebius/SWE-agent-trajectories","creator_name":"Nebius","creator_url":"https://huggingface.co/nebius","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 80,036 trajectories generated by a software engineering agent based on the SWE-agent framework, using various models as action generators. In these trajectories, the agent attempts to solve GitHub issues from the nebius/SWE-bench-extra and the dev split of princeton-nlp/SWE-bench.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset was created as part of a research project focused on developing a software engineering agent using open-weight models… See the full description on the dataset page: https://huggingface.co/datasets/nebius/SWE-agent-trajectories."},
	{"name":"acl-paper","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/sleeping-ai/acl-paper","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tACL Entire\\n\\t\\n\\n\\n  \\n\\n\\nACL Entire is a comprehensive dataset containing all papers from both ACL and Non-ACL events listed on the ACL Anthology website. This dataset includes complete bibliographic information for all years.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nEvents Covered: Papers from ACL and Non-ACL events.\\nBibliography: Includes complete bibliographic details for every paper.\\nYears Covered: Comprehensive data spanning all available years.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\nAll data has been compiled… See the full description on the dataset page: https://huggingface.co/datasets/sleeping-ai/acl-paper."},
	{"name":"CodeNanoFix","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/qyliang/CodeNanoFix","creator_name":"liang","creator_url":"https://huggingface.co/qyliang","description":"CodeNanoFix consists of tuples of problem description, buggy code, and correct code, designed to evaluate human-written code with subtle differences.\\nPaper: https://arxiv.org/abs/2412.17429\\nproblem_id: problme index;\\npos: correct code;\\nneg: buggy code;\\nnl: natural language description;\\n\\nCitation:\\n@article{liang2024condor,\\n  title={Condor: A Code Discriminator Integrating General Semantics with Code Details},\\n  author={Liang, Qingyuan and Zhang, Zhao and Liu, Chen and Sun, Zeyu and Zhang… See the full description on the dataset page: https://huggingface.co/datasets/qyliang/CodeNanoFix."},
	{"name":"wasp-5k","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/namelessai/wasp-5k","creator_name":"Alex Scott","creator_url":"https://huggingface.co/namelessai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWasp-Lang\\n\\t\\n\\nThis is a synthetic dataset created by an amplify model trained on the Wasp programming language quick-start documentation. Better data coming soon.\\n"},
	{"name":"banking-chatbot-enquiries","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/pythontech9/banking-chatbot-enquiries","creator_name":"pythontech9","creator_url":"https://huggingface.co/pythontech9","description":"pythontech9/banking-chatbot-enquiries dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"NuminaMath-CoT-decontaminated-filtered","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/flatlander1024/NuminaMath-CoT-decontaminated-filtered","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Decontaminated version of AI-MO/NuminaMath-CoT/train that remove the collided data from math/test, gsm8k/test, olympiadbench/test, minerva_math/test, college_math/test, mmlu_stem/test, gaokao, amc23, aime24 and math500.\\nAligned with flatlander1024/QwQ-LongCoT-130K-decontaminated NuminaMath\\nTotal number of rows: 102238\\n"},
	{"name":"QwQ-LongCoT-decontaminated-filtered","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/flatlander1024/QwQ-LongCoT-decontaminated-filtered","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Decontaminated version of gghfez/QwQ-LongCoT-130K-cleaned that remove the collided data from math/test, gsm8k/test, olympiadbench/test, minerva_math/test, college_math/test, mmlu_stem/test, gaokao, amc23, aime24 and math500.\\nWith source=='NuminaMath'.\\nTotal number of rows: 88083\\n"},
	{"name":"NuminaMath-longcot-cot-combined","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/flatlander1024/NuminaMath-longcot-cot-combined","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Contains Decontaminated version of AI-MO/NuminaMath-CoT/train and the decontaminated version of gghfez/QwQ-LongCoT-130K-cleaned.\\nRemove duplicates and merged them into 1 data with 2 different solution rows.\\nTotal number of rows: 87057\\n"},
	{"name":"wximg_vl","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/wx1995/wximg_vl","creator_name":"wuxiang","creator_url":"https://huggingface.co/wx1995","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/wx1995/wximg_vl."},
	{"name":"nlp_corpus_zh","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zeroMN/nlp_corpus_zh","creator_name":"zeroTT","creator_url":"https://huggingface.co/zeroMN","description":"\\n\\t\\n\\t\\t\\n\\t\\tnlp_corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1 中文实体识别\\n\\t\\n\\n\\nopen_ner_data为网上开放的ner数据集，已将不同的数据格式转化为统一的数据格式，格式转换脚本为data_transfer.py\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.1 boson数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.2 clue细粒度实体识别数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.3 微软实体识别数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.4 人民网实体识别数据集（98年）\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.5 中药说明书实体识别数据集（“万创杯”中医药天池大数据竞赛）\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.6 视频_音乐_图书数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.7 微博数据集\\n\\t\\n\\n"},
	{"name":"chatjsonsql","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/rishi2903/chatjsonsql","creator_name":"Rishabh Mekala","creator_url":"https://huggingface.co/rishi2903","description":"\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names, column… See the full description on the dataset page: https://huggingface.co/datasets/rishi2903/chatjsonsql."},
	{"name":"reason_at_code","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MugiLab/reason_at_code","creator_name":"MugiLab","creator_url":"https://huggingface.co/MugiLab","description":"\\n\\t\\n\\t\\t\\n\\t\\tReasoning Dataset for Code\\n\\t\\n\\nThis repository contains a curated reasoning dataset specifically designed for coding-related problems, particularly in Python. \\nThe dataset was created by filtering non-code problems from the original NovaSky-AI/Sky-T1_data_17k dataset. \\nThe goal of this dataset is to facilitate fine-tuning models for reasoning tasks related to code understanding, problem-solving, and logical deduction in programming.\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe dataset emphasizes… See the full description on the dataset page: https://huggingface.co/datasets/MugiLab/reason_at_code."},
	{"name":"InstrucInputOut","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/soendup21/InstrucInputOut","creator_name":"Sonam Lhendup","creator_url":"https://huggingface.co/soendup21","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/soendup21/InstrucInputOut."},
	{"name":"Diverse-Knowledge","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kunu5402/Diverse-Knowledge","creator_name":"Kunal Kumar","creator_url":"https://huggingface.co/kunu5402","description":"\\n\\t\\n\\t\\t\\n\\t\\tEverything Data\\n\\t\\n\\n\\nThis data is synthetically generated by a ton of open and closed source models. This is basically a parsed version of yearly log form a small dialouge based testing to anylyze model's response on it then perform human evals on it.\\nThe data contains information about everything from every domain, most of the pairs included in this data are preferred by humans as the model's response.\\nIt can be used for topic modeling, or human preference evals etc.\\nRest anyone can do… See the full description on the dataset page: https://huggingface.co/datasets/kunu5402/Diverse-Knowledge."},
	{"name":"yelp_dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/shivi23/yelp_dataset","creator_name":"Shivani Dwivedi","creator_url":"https://huggingface.co/shivi23","description":"shivi23/yelp_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"LeetCodeDataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/newfacade/LeetCodeDataset","creator_name":"newfacade","creator_url":"https://huggingface.co/newfacade","description":"\\n\\t\\n\\t\\t\\n\\t\\tLeetCodeDataset\\n\\t\\n\\nLeetCodeDataset is a dataset consists of Python leetcode problems that can be used for LLM training and evaluation.\\n\\n    💻 GitHub\\n\\n"},
	{"name":"apps-small","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AuroraH456/apps-small","creator_name":"Aurora Huang","creator_url":"https://huggingface.co/AuroraH456","description":"\\n\\t\\n\\t\\t\\n\\t\\tAPPS Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nAPPS is a benchmark for code generation with 10000 problems. It can be used to evaluate the ability of language models to generate code from natural language specifications.\\nYou can also find APPS metric in the hub here codeparrot/apps_metric.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset contains questions in English and code solutions in Python.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nfrom datasets import load_dataset\\nload_dataset(\\\"codeparrot/apps\\\")… See the full description on the dataset page: https://huggingface.co/datasets/AuroraH456/apps-small."},
	{"name":"sysmon-configuration-dpo","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/cowWhySo/sysmon-configuration-dpo","creator_name":"whit3rabbit","creator_url":"https://huggingface.co/cowWhySo","description":"\\n\\t\\n\\t\\t\\n\\t\\tDPO Training Set for Sysmon Configuration File Generation\\n\\t\\n\\nThis repository contains a Direct Preference Optimization (DPO) training set for generating Sysmon configuration files for the purpose of fine tuning LLM.\\n\\n\\t\\n\\t\\t\\n\\t\\tBasis: Sysmon Modular Repository\\n\\t\\n\\nThis dataset is based on the Sysmon Modular repository by Olaf Hartong:🔗 Sysmon Modular Repository  \\nThe Sysmon Modular configuration was chosen because it was originally created by multiple people based on the MITRE framework.… See the full description on the dataset page: https://huggingface.co/datasets/cowWhySo/sysmon-configuration-dpo."},
	{"name":"ProfessionalTermsAmharicEnglish","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/admasorg/ProfessionalTermsAmharicEnglish","creator_name":"m","creator_url":"https://huggingface.co/admasorg","description":"admasorg/ProfessionalTermsAmharicEnglish dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"llvm-apr-benchmark","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dtcxzyw/llvm-apr-benchmark","creator_name":"Yingwei Zheng","creator_url":"https://huggingface.co/dtcxzyw","description":"\\n\\t\\n\\t\\t\\n\\t\\tLLVM APR Benchmark: A Large-Scale Automated Program Repair Benchmark of Real-World LLVM Middle-End Bugs\\n\\t\\n\\nGitHub (We only accept pull requests from GitHub)\\nHugging Face Mirror\\nHugging Face Leaderboard\\nEvaluation Result Submission\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMotivation\\n\\t\\n\\nThe compiler is a critical infrastructure in the software development. The LLVM compiler infrastructure is widely used in both academia and industry. However, due to its inherent complexity, the LLVM compiler still contains many bugs… See the full description on the dataset page: https://huggingface.co/datasets/dtcxzyw/llvm-apr-benchmark."},
	{"name":"Gemini-flash-2-code-project","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/loaiabdalslam/Gemini-flash-2-code-project","creator_name":"loai abdalslam","creator_url":"https://huggingface.co/loaiabdalslam","description":"loaiabdalslam/Gemini-flash-2-code-project dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Python_code_RU","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/DataSynGen/Python_code_RU","creator_name":"DataGen","creator_url":"https://huggingface.co/DataSynGen","description":"Формат датасета, каждый блок заключён в теги .\\nКаждый блок содержит комментарии  #Описание-Кода-блока\\n\\n"},
	{"name":"tojoyfoundation","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bcc/tojoyfoundation","creator_name":"bucheyu","creator_url":"https://huggingface.co/bcc","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/bcc/tojoyfoundation."},
	{"name":"Testing1","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/YeBhoneLin10/Testing1","creator_name":"Ye Bhone Lin","creator_url":"https://huggingface.co/YeBhoneLin10","description":"YeBhoneLin10/Testing1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ryan_test","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/tiantianhaha/ryan_test","creator_name":"li","creator_url":"https://huggingface.co/tiantianhaha","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/tiantianhaha/ryan_test."},
	{"name":"APPS-leetcode-codeforces","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/xtremekiwi/APPS-leetcode-codeforces","creator_name":"Aaron Sandoval","creator_url":"https://huggingface.co/xtremekiwi","description":"xtremekiwi/APPS-leetcode-codeforces dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"bfc-test","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AugustoSavi/bfc-test","creator_name":"Augusto Savi","creator_url":"https://huggingface.co/AugustoSavi","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset de Exemplos para BFC-Script\\n\\t\\n\\nEste dataset contém exemplos práticos de uso da linguagem bfc-script, organizados em pares de prompt e completion. Ele foi criado para ajudar desenvolvedores a entender e utilizar a linguagem em diversos cenários, desde operações básicas até funcionalidades mais avançadas.\\n\\n\\t\\n\\t\\t\\n\\t\\tEstrutura do Dataset\\n\\t\\n\\nO dataset está no formato JSONL (JSON Lines), onde cada linha é um objeto JSON com dois campos:\\n\\nprompt: Uma pergunta ou descrição de um cenário… See the full description on the dataset page: https://huggingface.co/datasets/AugustoSavi/bfc-test."},
	{"name":"CNTXTAI-Ranking-Dataset","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CNTXTAI0/CNTXTAI-Ranking-Dataset","creator_name":"CNTXT AI","creator_url":"https://huggingface.co/CNTXTAI0","description":"General Overview\\nThis dataset is to be used for LLM Trainings, This is a sample, visit https://www.cntxt.tech/ to learn more\\nThe dataset consists of 50 rows (excluding headers) and 8 columns. The columns capture various aspects of ranked responses to prompts, including:\\nNumeric_ID (Unique Identifier - Integer)\\nPrompt (The Question or Task - Text)\\nAnswer_A / Answer_B (Response Options - Text)\\nCategory (Type of Task - Categorical)\\nBest Answer (Preferred Response - Categorical)\\nLikeRT Score… See the full description on the dataset page: https://huggingface.co/datasets/CNTXTAI0/CNTXTAI-Ranking-Dataset."},
	{"name":"RobloxUsersData","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ZelonPrograms/RobloxUsersData","creator_name":"ZelonPrograms","creator_url":"https://huggingface.co/ZelonPrograms","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRoblox User Dataset\\n\\t\\n\\nWarning: Not all data may be collected correctly. Users should be aware of this limitation when utilizing the dataset. All of this was scraped, without permision of the users or company.\\nThis dataset contains information about Roblox users, including their user ID, username, display name, account status, and social metrics.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\nuser_id: Unique identifier for the user\\nusername: The username of the user\\ndisplay_name: The display… See the full description on the dataset page: https://huggingface.co/datasets/ZelonPrograms/RobloxUsersData."},
	{"name":"mac-os-commands","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/sammyview80/mac-os-commands","creator_name":"saman shrestha","creator_url":"https://huggingface.co/sammyview80","description":"sammyview80/mac-os-commands dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Datasets_Jhona","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Jhonatan321/Datasets_Jhona","creator_name":"Jhonatan reyes vazquez","creator_url":"https://huggingface.co/Jhonatan321","description":"Jhonatan321/Datasets_Jhona dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ai.luna.ai","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/derricka59/ai.luna.ai","creator_name":"Derrick Adkison","creator_url":"https://huggingface.co/derricka59","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLuna AI Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nLuna AI is a model optimized for creative writing tasks such as poetry generation, short story writing, script drafting, and more. This dataset provides training, validation, and test data for Luna AI to help improve its capabilities in these areas.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nVersion: 1.0\\nOptimized For: Creative Writing\\nLicense: Apache 2.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTraining Data\\n\\t\\n\\nThe training dataset consists of various samples designed to guide… See the full description on the dataset page: https://huggingface.co/datasets/derricka59/ai.luna.ai."},
	{"name":"BlameAIData-0.1","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/aifoundry-org/BlameAIData-0.1","creator_name":"AIFoundry.org","creator_url":"https://huggingface.co/aifoundry-org","description":"[WIP]\\n"},
	{"name":"laravel-11-qa-long-form","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/yannelli/laravel-11-qa-long-form","creator_name":"Ryan Y","creator_url":"https://huggingface.co/yannelli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Laravel 11 Documentation Q&A (Long Form)\\n\\t\\n\\nThis dataset contains detailed question-answer pairs derived from the Laravel 11 official documentation, designed for fine-tuning and evaluating language models on Laravel 11 knowledge. The long-form version provides more comprehensive answers and includes code examples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Laravel 11 Documentation Q&A (Long Form) dataset is an extensive collection of… See the full description on the dataset page: https://huggingface.co/datasets/yannelli/laravel-11-qa-long-form."},
	{"name":"lunaris-data","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/meryyllebr543/lunaris-data","creator_name":"Francisco Antonio","creator_url":"https://huggingface.co/meryyllebr543","description":"\\n\\t\\n\\t\\t\\n\\t\\tLunaris-Data Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nDataset Name: meryyllebr543/lunaris-data  \\nAuthor: Meryyllebr543  \\nLicense: [MIT]  \\nRepository: Hugging Face Dataset Hub  \\nCreated On: March 14, 2025\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nLunaris-Data is a premium dataset crafted to train and evaluate high-performance code generation models, like Lunaris Codex Mini (120M parameters), optimized for advanced programming tasks, debugging, and system design.\\nIt features 40,000 meticulously engineered… See the full description on the dataset page: https://huggingface.co/datasets/meryyllebr543/lunaris-data."},
	{"name":"python-codesearch-dataset-open","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Shuu12121/python-codesearch-dataset-open","creator_name":"Shuu12121","creator_url":"https://huggingface.co/Shuu12121","description":"\\n\\t\\n\\t\\t\\n\\t\\tPython Code Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains Python functions with their documentation comments extracted from GitHub repositories.\\n\\n\\t\\n\\t\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\ncode: The Python function code\\ndocstring: Documentation comment for the function\\nfunc_name: Function name\\nlanguage: Programming language (always \\\"Python\\\")\\nrepo: Source repository name\\npath: File path within the repository\\nurl: GitHub URL to the source file\\nlicense: License of the source code… See the full description on the dataset page: https://huggingface.co/datasets/Shuu12121/python-codesearch-dataset-open."},
	{"name":"Comprehensive_Feature_Extraction_DDoS_Datasets","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Thi-Thu-Huong/Comprehensive_Feature_Extraction_DDoS_Datasets","creator_name":"Le","creator_url":"https://huggingface.co/Thi-Thu-Huong","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Comprehensive_Feature_Extraction_DDoS_Datasets\\n\\t\\n\\n\\n\\nThis dataset card aims to be provided preprocessed five published DDoS datasets based on three feature extracted methods, including correlation, IM, and UFS. \\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe imperative for robust detection mechanisms has grown in the face of increasingly sophisticated Distributed Denial of Service (DDoS) attacks. This paper introduces DDoSBERT, an innovative approach harnessing transformer text… See the full description on the dataset page: https://huggingface.co/datasets/Thi-Thu-Huong/Comprehensive_Feature_Extraction_DDoS_Datasets."},
	{"name":"AyvazPython","keyword":"code","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/bunyaminergen/AyvazPython","creator_name":"Bünyamin Ergen","creator_url":"https://huggingface.co/bunyaminergen","description":"\\n\\nAyvaz Python\\n\\nAyvaz Python is a dataset containing Python code instructions and outputs, which can be useful for tasks\\nsuch as code instruction tuning or code-based Q&A.\\nNote: If you would like to contribute to this repository,\\nplease read the CONTRIBUTING first.\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTableofContents\\n\\t\\n\\n\\nFeatures\\nFile Structure\\nDataset Structure\\nUsage\\nVersioning\\nLicense\\nTeam\\nContact\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nName: AyvazPython\\nPrimary Purpose: Contains JSON lines of programming instructions… See the full description on the dataset page: https://huggingface.co/datasets/bunyaminergen/AyvazPython."},
	{"name":"PyRe-v2","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/theprint/PyRe-v2","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"\\n\\t\\n\\t\\t\\n\\t\\tPyRe 2\\n\\t\\n\\nThis data set is a mix of samples from a number of public data sets (sources indidcated in the actual data). The goal with this set was to create a smaller set focused on coding (primarily Python), math, and reasoning.\\n"},
	{"name":"CO2_Vehicle_Emmisions","keyword":"code","license":"\"Do What The F*ck You Want To Public License\"","language":"en","url":"https://huggingface.co/datasets/milind27/CO2_Vehicle_Emmisions","creator_name":"Milind Saini","creator_url":"https://huggingface.co/milind27","description":"milind27/CO2_Vehicle_Emmisions dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sharegpt_cot_dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AiCloser/sharegpt_cot_dataset","creator_name":"Ai Closer","creator_url":"https://huggingface.co/AiCloser","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tA data set inspired by the \\\"Reflection\\\" method, three-dimensional thinking and cot\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the ShareGPT format.\\n\\t\\n\\nThe data set was generated using multiple llm synthesis.\\n"},
	{"name":"Typst-Test","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/TechxGenus/Typst-Test","creator_name":"Hao Jiang","creator_url":"https://huggingface.co/TechxGenus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTypst-Test\\n\\t\\n\\n\\n[🤖Models] |\\n[🛠️Code] |\\n[📊Data] |\\n\\n\\n\\n\\nDataset used to evaluate Typst-Coder, includes 1000 samples.\\n"},
	{"name":"iData","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/motexture/iData","creator_name":"motexture","creator_url":"https://huggingface.co/motexture","description":"This dataset was created using books from various domains within IT and science.\\n"},
	{"name":"user-test","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/han9527/user-test","creator_name":"liu","creator_url":"https://huggingface.co/han9527","description":"han9527/user-test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Firefly-Rephrased-Multiturn-300K","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Mxode/Firefly-Rephrased-Multiturn-300K","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"Mxode/Firefly-Rephrased-Multiturn-300K dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Firefly-1.1M-Rephrased","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Mxode/Firefly-1.1M-Rephrased","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"Mxode/Firefly-1.1M-Rephrased dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"IndustryCorpus-Subset-zh-en","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Mxode/IndustryCorpus-Subset-zh-en","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"Mxode/IndustryCorpus-Subset-zh-en dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"webcode2m_purified","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/xcodemind/webcode2m_purified","creator_name":"xcodemind","creator_url":"https://huggingface.co/xcodemind","description":"WebCode2M: A Real-World Dataset for Code Generation from Webpage Designs\\nFeatures:\\n\\nimage: the screenshot of the webpage.\\nbbox: the layout information, i.e., the bounding boxes (Bbox) of all the elements in the webpage, which contains the size, position, and hierarchy information. \\ntext: the webpage code text including HTML/CSS code.\\nscale: the scale of the screenshot, in the format [width, height].\\nlang: the main language of the text content displayed on the rendered page (excluding HTML/CSS… See the full description on the dataset page: https://huggingface.co/datasets/xcodemind/webcode2m_purified."},
	{"name":"Ecommers-delivery","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Sravankumarbonthada/Ecommers-delivery","creator_name":"BONTHADA SRAVAN KUMAR","creator_url":"https://huggingface.co/Sravankumarbonthada","description":"Sravankumarbonthada/Ecommers-delivery dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"brain_tumor_dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Arunisto/brain_tumor_dataset","creator_name":"Arun Arunisto","creator_url":"https://huggingface.co/Arunisto","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBrain Tumor Dataset\\n\\t\\n\\nParquet dataset contains the two different brain tumor condition healthy and tumor, used to classify the brain tumor. The images contains the MRI Scans of two different brain condition, this dataset developers can use for classification, detection and segmentation\\n"},
	{"name":"Spurline","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sequelbox/Spurline","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Spurline is a dataset containing complex responses, emphasizing logical reasoning and using Shining Valiant's friendly, magical personality style.\\nThe 2024-10-30 version contains:\\n\\n10.7k rows of synthetic queries, using randomly selected prompts from migtissera/Synthia-v1.5-I and responses generated using Llama 3.1 405b Instruct.\\n\\nThis dataset contains synthetically generated data and has not been subject to manual review.\\n"},
	{"name":"LLM_dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/mlsuny/LLM_dataset","creator_name":"ml_suny","creator_url":"https://huggingface.co/mlsuny","description":"mlsuny/LLM_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"jobdata","keyword":"code","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/arkodeep/jobdata","creator_name":"Arkodeep Sen","creator_url":"https://huggingface.co/arkodeep","description":"arkodeep/jobdata dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"python-fim","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/simmo/python-fim","creator_name":"Xander May","creator_url":"https://huggingface.co/simmo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPython Stack | Fill-in-the-Middle\\n\\t\\n\\nThis is a conversion or adaptation of The Stack to a python FIM task. The example column is B64 encoded because people like to put special characters in their code that csv files dont like so I encoded the strings before saving them to disk. \\n"},
	{"name":"Qu-QA","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Ereeeeef3/Qu-QA","creator_name":"ffhs9","creator_url":"https://huggingface.co/Ereeeeef3","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQu QA Dataset\\n\\t\\n\\nQu QA is a large-scale question-answering (QA) dataset designed for training and evaluating machine learning models. It consists of question-answer pairs in English, making it suitable for general-purpose QA tasks, as well as specialized domains like code-related question answering and GSM8k-style problems.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nFeatures:\\n\\ninput: A string representing the question (dtype: string).\\noutput: A string representing the answer (dtype: string).… See the full description on the dataset page: https://huggingface.co/datasets/Ereeeeef3/Qu-QA."},
	{"name":"Qu-QA-v2","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Ereeeeef3/Qu-QA-v2","creator_name":"ffhs9","creator_url":"https://huggingface.co/Ereeeeef3","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQu QA v2 Dataset\\n\\t\\n\\nQu QA v2 is a large-scale question-answering (QA) dataset designed for training and evaluating machine learning models. It consists of question-answer pairs in English, making it suitable for general-purpose QA tasks, as well as specialized domains like code-related question answering and GSM8k-style problems.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nFeatures:\\n\\ninput: A string representing the question (dtype: string).\\noutput: A string representing the answer (dtype:… See the full description on the dataset page: https://huggingface.co/datasets/Ereeeeef3/Qu-QA-v2."},
	{"name":"BlendNet","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/BlendNet","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\t📚 BlendNet\\n\\t\\n\\nThe dataset contains $12k$ samples. To balance cost savings with data quality and scale, we manually annotated $2k$ samples and used GPT-4o to annotate the remaining $10k$ samples.\\nFor more details, please visit our GitHub repository or refer to our arXiv paper.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📖 Citation\\n\\t\\n\\n@misc{du2024blenderllmtraininglargelanguage,\\n      title={BlenderLLM: Training Large Language Models for Computer-Aided Design with Self-improvement}, \\n      author={Yuhao Du and… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/BlendNet."},
	{"name":"SWAP","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/sxiong/SWAP","creator_name":"Siheng Xiong","creator_url":"https://huggingface.co/sxiong","description":"\\n\\t\\n\\t\\t\\n\\t\\tSWAP: A Synthetic Dataset for Complex Reasoning with Trajectories and Process Supervision\\n\\t\\n\\nThis repository contains the data for the paper Deliberate Reasoning for LLMs as Structure-aware Planning with Accurate World Model.\\nSWAP (Structure-aware Planning) solves complex reasoning by introducing a Generator-Discriminator architecture, and incorporates structural information to guide the reasoning process and provides a soft verification mechanism over the steps.\\nWe generate the… See the full description on the dataset page: https://huggingface.co/datasets/sxiong/SWAP."},
	{"name":"ComBack_Plus_Plus","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/docz1105/ComBack_Plus_Plus","creator_name":"Ming Zhong","creator_url":"https://huggingface.co/docz1105","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tComBack++: A Multi-Language Dataset Providing End-to-End Support for Compiler Backend Development\\n\\t\\n\\nComBack++ is a large-scale, multi-platform and multi-language compiler backend code dataset. It is sourced from GCC and LLVM backends corresponding to 183 target platforms.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSource Data\\n\\nGCC\\n\\n\\n\\t\\n\\t\\t\\nCategory\\nTarget Platform\\nC++ Function\\nC++ KLoC\\nMachine Description KLoC\\n\\n\\n\\t\\t\\nCPU\\n30\\n56,211\\n858.2\\n228.5\\n\\n\\nMPU\\n35\\n8,713\\n243.8\\n87.1\\n\\n\\nGPU\\n2\\n731\\n12.7\\n3.0… See the full description on the dataset page: https://huggingface.co/datasets/docz1105/ComBack_Plus_Plus."},
	{"name":"GoPro-Raw-Videos","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Fanqi-Lin/GoPro-Raw-Videos","creator_name":"Fanqi-Lin","creator_url":"https://huggingface.co/Fanqi-Lin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRaw GoPro Videos for Four Robotic Manipulation Tasks\\n\\t\\n\\n[Project Page]\\n[Paper]\\n[Code]\\n[Models]\\n[Processed Dataset]\\nThis repository contains raw GoPro videos of robotic manipulation tasks collected in-the-wild using UMI, as described in the paper \\\"Data Scaling Laws in Imitation Learning for Robotic Manipulation\\\". The dataset covers four tasks:\\n\\nPour Water\\nArrange Mouse\\nFold Towel\\nUnplug Charger\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Folders:\\n\\t\\n\\narrange_mouse and pour_water: Each folder contains data… See the full description on the dataset page: https://huggingface.co/datasets/Fanqi-Lin/GoPro-Raw-Videos."},
	{"name":"developers-questions-small-qe2","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/OramaSearch/developers-questions-small-qe2","creator_name":"OramaSearch Inc.","creator_url":"https://huggingface.co/OramaSearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDevelopers Questions Small QE2\\n\\t\\n\\nA dataset consisting of ~12k developers' questions, in English. These questions are synthetically generated via local LLMs at Orama.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasets\\n\\t\\n\\nThe dataset is proposed with three different embedding models:\\n\\nbge-small-en-v1.5\\nbge-base-en-v1.5\\nbge-large-en-v1.5\\n\\nIt also contains a quantized version for each model:\\n\\nbge-small 32 bytes\\nbge-base 32 bytes\\nbge-large 32 bytes\\n\\nFor each quantized model, this repository includes a binary… See the full description on the dataset page: https://huggingface.co/datasets/OramaSearch/developers-questions-small-qe2."},
	{"name":"LeetCoTE","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/newfacade/LeetCoTE","creator_name":"newfacade","creator_url":"https://huggingface.co/newfacade","description":"\\n\\t\\n\\t\\t\\n\\t\\tLeetCoTE (LeetCode Training and Evaluation dataset)\\n\\t\\n\\n\\n    💻 GitHub Repository  •\\n\\n"},
	{"name":"CodeSimilarityBench","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Meeex2/CodeSimilarityBench","creator_name":"Abdellah OUMIDA","creator_url":"https://huggingface.co/Meeex2","description":"Meeex2/CodeSimilarityBench dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"test","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Ding0702/test","creator_name":"Ding","creator_url":"https://huggingface.co/Ding0702","description":"Ding0702/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ru-alpaca-html","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ai-blond/ru-alpaca-html","creator_name":"Janice Blond","creator_url":"https://huggingface.co/ai-blond","description":"ai-blond/ru-alpaca-html dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Tachibana-QVQ-PREVIEW","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sequelbox/Tachibana-QVQ-PREVIEW","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"This is a preview of the full Tachibana-QVQ code-instruct dataset, containing the first ~10k rows.\\nGet the full dataset now!\\nPrompts randomly selected from sequelbox/Tachibana, all responses generated by Qwen/QVQ-72B-Preview.\\nDataset has not been reviewed for format or accuracy. Synthetic data is generated by a 'preview' edition of Qwen's QVQ 72b model.\\nUse as you will.\\n"},
	{"name":"mini-MetaMathQA","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/akshathmangudi/mini-MetaMathQA","creator_name":"Akshath Mangudi","creator_url":"https://huggingface.co/akshathmangudi","description":"\\n\\t\\n\\t\\t\\n\\t\\tMini-MetaMathQA\\n\\t\\n\\nMini-MetaMathQA is the miniature version of the original MetaMathQA \\nto fine-tune reasoning capabilities on Small Language Models. \\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\nTotal Size: ~110.84 MB\\nDownload Size: ~56 MB\\nLanguages: English (en)\\nLicense: MIT\\nTask Category: Text-to-Text Generation\\nTags: Code, QA, Reasoning\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nFeature Name\\nData Type\\n\\n\\n\\t\\t\\ntype\\nstring\\n\\n\\nquery\\nstring\\n\\n\\noriginal_question\\nstring\\n\\n\\nresponse\\nstring\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Splits… See the full description on the dataset page: https://huggingface.co/datasets/akshathmangudi/mini-MetaMathQA."},
	{"name":"lunaris-tech","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/meryyllebr543/lunaris-tech","creator_name":"Francisco Antonio","creator_url":"https://huggingface.co/meryyllebr543","description":"\\n\\t\\n\\t\\t\\n\\t\\tLunaris-Tech\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card | Hugging Face\\n\\t\\n\\nLunaris-Tech is a high-quality dataset designed to train lightweight NLP models like Lunaris Codex Mini (120M parameters) for technical question-answering, tool usage guides, and real-world problem-solving in programming and technology. It contains 17,000 unique examples across three key categories: Q&A Tech, Tools/Frameworks, and Real-World Scenarios, generated using a custom pipeline with Azure OpenAI models (o1 and o3-mini).… See the full description on the dataset page: https://huggingface.co/datasets/meryyllebr543/lunaris-tech."},
	{"name":"graph_problem_traces_test1","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Beanbagdzf/graph_problem_traces_test1","creator_name":"Zifeng Ding","creator_url":"https://huggingface.co/Beanbagdzf","description":"A dataset containing graph and discrete math problem-solving traces with tool-based code solutions. Each record includes a problem, its final answer, and the code solution (as rationale)."},
	{"name":"qxf2-codegen","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/shivaharip/qxf2-codegen","creator_name":"shivahari","creator_url":"https://huggingface.co/shivaharip","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains a collection of code from Qxf2 Services's public GitHub repositories. It includes various scripts, functions, and components used in software development, automation, testing, and other technical services.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nDataset Version: v1.0\\nLast Updated: 11th Feb 2025\\nRepository: https://github.com/qxf2\\nLanguages: Python, Javascript, Java, Rust, YAML, Shell Script, etc.\\nLicense: MIT License\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntended Use\\n\\t\\n\\nThis dataset is… See the full description on the dataset page: https://huggingface.co/datasets/shivaharip/qxf2-codegen."},
	{"name":"SWE-Fixer-Train-Editing-CoT-70K","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/internlm/SWE-Fixer-Train-Editing-CoT-70K","creator_name":"InternLM","creator_url":"https://huggingface.co/internlm","description":"internlm/SWE-Fixer-Train-Editing-CoT-70K dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"mensuration-cycle-tracker","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/anaslari/mensuration-cycle-tracker","creator_name":"lari","creator_url":"https://huggingface.co/anaslari","description":"anaslari/mensuration-cycle-tracker dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Aurora-Think-1.0","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/naimulislam/Aurora-Think-1.0","creator_name":"Naimul Islam Nahid","creator_url":"https://huggingface.co/naimulislam","description":"naimulislam/Aurora-Think-1.0 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"TinyMarkdown-Instruct-PT","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/VAMJ-0042/TinyMarkdown-Instruct-PT","creator_name":"Vitor Augusto Machado Jorge","creator_url":"https://huggingface.co/VAMJ-0042","description":"\\n\\t\\n\\t\\t\\n\\t\\tMarkdown Fine-Tuning Datasets (English & PT-BR)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThese datasets are designed to fine-tune Large Language Models (LLMs) like Gemma to generate structured Markdown-formatted responses. The datasets contain instruction-response pairs, ensuring the model learns how to output Markdown elements correctly.\\n\\n\\t\\n\\t\\t\\n\\t\\tDatasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1. English Markdown Dataset\\n\\t\\n\\n\\nAvailable on Hugging Face: TinyMarkdown-Instruct-EN\\nSize: Large-scale dataset with structured Markdown… See the full description on the dataset page: https://huggingface.co/datasets/VAMJ-0042/TinyMarkdown-Instruct-PT."},
	{"name":"github_issues","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/SurAyush/github_issues","creator_name":"Ayush Sur","creator_url":"https://huggingface.co/SurAyush","description":"SurAyush/github_issues dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"func_calls_ds","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/retrain-pipelines/func_calls_ds","creator_name":"retrain-pipelines","creator_url":"https://huggingface.co/retrain-pipelines","description":"\\n\\t\\n\\t\\t\\n\\t\\tretrain-pipelines Function Calling\\n\\t\\n\\nversion 0.10  -  2025-03-16 13:07:17 UTC\\nSource datasets :\\n\\nmain :\\nXlam Function Calling 60k\\nSalesforce/xlam-function-calling-60k\\n(26d14eb -\\n  2025-01-24 19:25:58 UTC)\\nlicense :\\ncc-by-4.0\\narxiv :\\n- 2406.18518\\n\\n\\ndata-enrichment :\\nNatural Questions Clean\\nlighteval/natural_questions_clean\\n(a72f7fa -\\n  2023-10-17 20:29:08 UTC)\\nlicense :\\nunknown\\nThe herein dataset has 2 configs : continued_pre_training and supervised_finetuning.\\nThe former serves for… See the full description on the dataset page: https://huggingface.co/datasets/retrain-pipelines/func_calls_ds."},
	{"name":"QUITE","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/timo-pierre-schrader/QUITE","creator_name":"Timo Pierre Schrader","creator_url":"https://huggingface.co/timo-pierre-schrader","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for QUITE\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nQUITE (Quantifying Uncertainty in natural language Text) is an entirely new benchmark that allows for assessing the capabilities of neural language model-based systems w.r.t. to Bayesian reasoning on a large set of input text that describes probabilistic relationships in natural language text.\\nFor example, take the following statement from QUITE:\\n\\nIf Plcg is in a high state, PIP3 appears in a low state in 42% of all… See the full description on the dataset page: https://huggingface.co/datasets/timo-pierre-schrader/QUITE."},
	{"name":"test","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/haggs/test","creator_name":"Dan Haggerty","creator_url":"https://huggingface.co/haggs","description":"haggs/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"dataset-9","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/keikhosrotav/dataset-9","creator_name":"keikhosro tavakoli","creator_url":"https://huggingface.co/keikhosrotav","description":"keikhosrotav/dataset-9 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"statcodesearch","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/drndr/statcodesearch","creator_name":"A D","creator_url":"https://huggingface.co/drndr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for statcodesearch\\n\\t\\n\\n\\n\\nThe StatCodeSearch dataset is a benchmark test set consisting of code comment pairs extracted from R programming language scripts authored mostly by researchers. The dataset is sourced from the Open Science Framework (OSF). It includes text and code samples from R projects that pertain to the fields of social science and psychology with a focus on the statistical analysis of research data. As part of the GenCodeSearchNet test suite, this dataset… See the full description on the dataset page: https://huggingface.co/datasets/drndr/statcodesearch."},
	{"name":"Tin_hoc_mcq_extended","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kamisaiko/Tin_hoc_mcq_extended","creator_name":"NGUYEN VIET TRUNG","creator_url":"https://huggingface.co/kamisaiko","description":"kamisaiko/Tin_hoc_mcq_extended dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Celestia2","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sequelbox/Celestia2","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Celestia 2 is a multi-turn agent-instruct dataset containing science data.\\nThis dataset focuses on challenging multi-turn conversations and contains:\\n\\n176k rows of synthetic multi-turn science-instruct data, using Microsoft's AgentInstruct style. All prompts and responses are synthetically generated using Llama 3.1 405b Instruct. Primary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\\n\\nThis dataset… See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Celestia2."},
	{"name":"zorse","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zorse/zorse","creator_name":"Zorse Project","creator_url":"https://huggingface.co/zorse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZorse\\n\\t\\n\\nZorse contains source code for mainframe programming languages.\\n"},
	{"name":"Single-DriveLM-NuScenes-VQA","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Chouoftears/Single-DriveLM-NuScenes-VQA","creator_name":"Shenzhe Zhu","creator_url":"https://huggingface.co/Chouoftears","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSingle-DriveLM-NuScenes VQA Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUpdates & News\\n\\t\\n\\n\\n[10/11/2024] VQA Dataset was released\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is the sub-dataset of DriveLM which only include single object in ego scenes\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\nFor single traffic participant recgonition, segmentation, VQA subtasks of driving scenarios.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nsingle_pedestrian \\n├── images  \\n└── labeled_pedestrian_data.json\\n\\nsingle_vehicle\\n├── images  \\n└──… See the full description on the dataset page: https://huggingface.co/datasets/Chouoftears/Single-DriveLM-NuScenes-VQA."},
	{"name":"CodeMMLU","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Fsoft-AIC/CodeMMLU","creator_name":"FPT Software AI Center","creator_url":"https://huggingface.co/Fsoft-AIC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding Capabilities\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📌 CodeMMLU\\n\\t\\n\\nCodeMMLU is a comprehensive benchmark designed to evaluate the capabilities of large language models (LLMs) in coding and software knowledge. \\nIt builds upon the structure of multiple-choice question answering (MCQA) to cover a wide range of programming tasks and domains, including code generation, defect detection, software engineering principles, and much more.… See the full description on the dataset page: https://huggingface.co/datasets/Fsoft-AIC/CodeMMLU."},
	{"name":"code_generation","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/macroteck/code_generation","creator_name":"MacroTeck Technologies","creator_url":"https://huggingface.co/macroteck","description":"macroteck/code_generation dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ExecRepoBench","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CSJianYang/ExecRepoBench","creator_name":"Yang Jian","creator_url":"https://huggingface.co/CSJianYang","description":"\\nHome: https://execrepobench.github.io/\\npaper: https://arxiv.org/pdf/2412.11990\\nLeaderboard: https://execrepobench.github.io/leaderboard.html\\nGithub: https://github.com/QwenLM/Qwen2.5-Coder/tree/main/qwencoder-eval/base/benchmarks/ExecRepoBench\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn this work, we introduce a novel framework for enhancing code completion in software development through the creation of a repository-level benchmark ExecRepoBench and the instruction corpora Repo-Instruct, aim at… See the full description on the dataset page: https://huggingface.co/datasets/CSJianYang/ExecRepoBench."},
	{"name":"wordlists","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Chemically-motivated/wordlists","creator_name":"Chemically Motivated Solutions","creator_url":"https://huggingface.co/Chemically-motivated","description":"Dataset Card for Wordlists\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset consists of a collection of wordlists designed for use in cybersecurity tasks, such as penetration testing, vulnerability scanning, and password strength analysis. The wordlists cover various use cases, including common passwords, network device names, and terms used in security-related research. These wordlists are essential tools for security professionals in identifying weak points in… See the full description on the dataset page: https://huggingface.co/datasets/Chemically-motivated/wordlists."},
	{"name":"AntiGPTTest01","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ikerm11/AntiGPTTest01","creator_name":"m","creator_url":"https://huggingface.co/ikerm11","description":"ikerm11/AntiGPTTest01 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"emotions_worldwide","keyword":"code","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/Ferdinandnathaniel/emotions_worldwide","creator_name":"Fabian Kok","creator_url":"https://huggingface.co/Ferdinandnathaniel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEmotions worldwide\\n\\t\\n\\nThis is an open dataset listing emotions from across the world with their descriptions in English. First used for the artwork E*star for the NeurIPS 2024 Creative AI track, the dataset behind the artwork has been made open-source through github. \\nThe dataset actively seeks validation, correction, and addition by the open public (especially from non-English language speakers, as those emotions are difficult to validate by myself). \\nSupport by validating… See the full description on the dataset page: https://huggingface.co/datasets/Ferdinandnathaniel/emotions_worldwide."},
	{"name":"common_starcoder","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/skymizer/common_starcoder","creator_name":"skymizer","creator_url":"https://huggingface.co/skymizer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCommon Starcoder dataset\\n\\t\\n\\nThis dataset is generated from bigcode/starcoderdata.\\nTotal GPT2 Tokens: 4,649,163,171\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneration Process\\n\\t\\n\\n\\nWe filtered the original dataset with common language: C, Cpp, Java, Python and JSON.\\nWe removed some columns for mixing up with other dataset: \\\"id\\\", \\\"max_stars_repo_path\\\", \\\"max_stars_repo_name\\\"\\nAfter removing the irrelevant fields, we shuffle the dataset with random seed=42.\\nWe filtered the data on \\\"max_stars_count\\\" > 300 and shuffle… See the full description on the dataset page: https://huggingface.co/datasets/skymizer/common_starcoder."},
	{"name":"ksdoc-airscript","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/cy948/ksdoc-airscript","creator_name":"yao cai","creator_url":"https://huggingface.co/cy948","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHuman Annotation Example\\n\\t\\n\\nWe invite some domain experts who has code experience on AirScript to add annotations for the code snippets in lines. For example:\\n\\nData annotation example\\n\\n/*本示例判断如果活动工作表上区域 B1:B10 中第二个（AboveAverage）条件格式的类型为xlAboveAverageCondition，则删除该条件格式。*/\\nfunction test() {\\n+// 从工作表上区域 B1:B10 中选择第二个条件格式\\n    let aboveAverage = ActiveSheet.Range(\\\"B1:B10\\\").FormatConditions.Item(2)\\n+// 若条件格式的类型为 `xlAboveAverageCondition`\\n    if (aboveAverage.Type ==… See the full description on the dataset page: https://huggingface.co/datasets/cy948/ksdoc-airscript."},
	{"name":"refactorchat","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/BradMcDanel/refactorchat","creator_name":"Bradley McDanel","creator_url":"https://huggingface.co/BradMcDanel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Details\\n\\t\\n\\n\\nDataset Name: RefactorChat\\nVersion: 1.0\\nDate: October 19, 2024\\nType: Multi-turn dialogue dataset for code refactoring and feature addition\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntended Use\\n\\t\\n\\n\\nPrimary Use: Evaluating and training large language models on incremental code development tasks\\nIntended Users: Researchers and practitioners in natural language processing and software engineering\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Composition\\n\\t\\n\\n\\nSize: 100 samples\\nStructure: Each… See the full description on the dataset page: https://huggingface.co/datasets/BradMcDanel/refactorchat."},
	{"name":"AEC-VA-details-spec-dataset","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/simondavidpalmer/AEC-VA-details-spec-dataset","creator_name":"Simon David Palmer","creator_url":"https://huggingface.co/simondavidpalmer","description":"simondavidpalmer/AEC-VA-details-spec-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"SmallThoughts","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SmallDoge/SmallThoughts","creator_name":"Doge Face","creator_url":"https://huggingface.co/SmallDoge","description":"\\n\\t\\n\\t\\t\\n\\t\\tSmallThoughts\\n\\t\\n\\n\\n  \\n\\n\\n  \\n    \\n  \\n  \\n    \\n  \\n  \\n    \\nOpen synthetic reasoning dataset, covering math, science, code, and puzzles.\\nTo address the issue of the existing DeepSeek R1 distilled data being too long, this dataset constrains the reasoning trajectory to be more precise and concise while retaining the reflective nature.\\nWe also open-sourced the pipeline code for distilled data here, with just one command you can generate your own dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use\\n\\t\\n\\nYou can load… See the full description on the dataset page: https://huggingface.co/datasets/SmallDoge/SmallThoughts."},
	{"name":"python-code-dataset-500k","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jtatman/python-code-dataset-500k","creator_name":"James","creator_url":"https://huggingface.co/jtatman","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAttention: This dataset is a summary and reformat pulled from github code.\\n\\t\\n\\nYou should make your own assumptions based on this.\\nIn fact, there is another dataset I formed through parsing that addresses several points:\\n\\nout of 500k python related items, most of them are python-ish, not pythonic\\nthe majority of the items here contain excessive licensing inclusion of original code\\nthe items here are sometimes not even python but have references\\nThere's a whole lot of gpl summaries… See the full description on the dataset page: https://huggingface.co/datasets/jtatman/python-code-dataset-500k."},
	{"name":"sql-create-context","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/b-mc2/sql-create-context","creator_name":"brianm","creator_url":"https://huggingface.co/b-mc2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted from different DBMS and provides table names… See the full description on the dataset page: https://huggingface.co/datasets/b-mc2/sql-create-context."},
	{"name":"synthetic_text_to_sql","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/gretelai/synthetic_text_to_sql","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","description":"\\n  \\n  Image generated by DALL-E. See prompt for more details\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tsynthetic_text_to_sql\\n\\t\\n\\n\\ngretelai/synthetic_text_to_sql is a rich dataset of high quality synthetic Text-to-SQL samples, \\ndesigned and generated using Gretel Navigator, and released under Apache 2.0.\\nPlease see our release blogpost for more details.\\nThe dataset includes:\\n\\n  105,851 records partitioned into 100,000 train and 5,851 test records\\n  ~23M total tokens, including ~12M SQL tokens\\n  Coverage across 100 distinct… See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_text_to_sql."},
	{"name":"function-calling-small","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Deepexi/function-calling-small","creator_name":"Deepexi Inc","creator_url":"https://huggingface.co/Deepexi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集内容说明:\\n\\t\\n\\n包含700+个阿里云OpenAPI的信息;包括Dataworks,EMR，DataLake，Maxcompute，Hologram,实时计算Flink版，QuickBI,DTS等多个产品的公开Open API信息。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t样例\\n\\t\\n\\n{\\n  \\\"systemPrompt\\\": 你是一个函数筛选助理，如果与问题相关的话,您可以使用下面的函数来获取更多数据以回答用户提出的问题:{\\\"function\\\": \\\"UpdateTicketNum\\\", \\\"description\\\": \\\"对用于免登嵌入报表的指定的ticket进行更新票据数量操作。\\\", \\\"arguments\\\": [{\\\"name\\\": \\\"Ticket\\\", \\\"type\\\": \\\"string\\\", \\\"description\\\": \\\"三方嵌入的票据值，即URL中的accessTicket值。\\\"}, {\\\"name\\\": \\\"TicketNum\\\", \\\"type\\\": \\\"integer\\\", \\\"description\\\": \\\"票据数。\\\\n-… See the full description on the dataset page: https://huggingface.co/datasets/Deepexi/function-calling-small."},
	{"name":"ComBack","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/docz1105/ComBack","creator_name":"Ming Zhong","creator_url":"https://huggingface.co/docz1105","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tComBack: A Versatile Dataset for Enhancing Compiler Backend Development Efficiency\\n\\t\\n\\nComBack is a large-scale multi-platform compiler backend code dataset. It is sourced from GCC and LLVM backends corresponding  to 178 target platforms.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSource Data\\n\\nGCC\\n\\n\\n\\t\\n\\t\\t\\nCategory\\nTarget Platform\\nFunction\\nKLoC\\n\\n\\n\\t\\t\\nCPU\\n30\\n35,147\\n647.2\\n\\n\\nMPU\\n33\\n6,010\\n183.9\\n\\n\\nGPU\\n2\\n457\\n11.2\\n\\n\\nVLIW\\n5\\n959\\n25.4\\n\\n\\nDSP\\n3\\n399\\n9.6\\n\\n\\nVirtual\\n4\\n327\\n6.5\\n\\n\\nSUM\\n77\\n43,299\\n883.7\\n\\n\\n\\t\\n\\n\\nLLVM… See the full description on the dataset page: https://huggingface.co/datasets/docz1105/ComBack."},
	{"name":"webcode2m","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/xcodemind/webcode2m","creator_name":"xcodemind","creator_url":"https://huggingface.co/xcodemind","description":"WebCode2M: A Real-World Dataset for Code Generation from Webpage Designs with Layouts\\n(This dataset is also called Vision2UI.)\\n\\nAutomatically generating webpage code from webpage designscan significantly reduce the workload of front-end developers, andrecent Multimodal Large Language Models (MLLMs) have shownpromising potential in this area. However, our investigation revealsthat most existing MLLMs are constrained by the absence of highquality, large-scale, real-world datasets, resulting in… See the full description on the dataset page: https://huggingface.co/datasets/xcodemind/webcode2m."},
	{"name":"SWE-bench-extra","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/nebius/SWE-bench-extra","creator_name":"Nebius","creator_url":"https://huggingface.co/nebius","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSWE-bench Extra is a dataset that can be used to train or evaluate agentic systems specializing in resolving GitHub issues. It is based on the methodology used to build SWE-bench benchmark and includes 6,415 Issue-Pull Request pairs sourced from 1,988 Python repositories.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe SWE-bench Extra dataset supports the development of software engineering agents capable of autonomously solving GitHub issues. The data collection process, based… See the full description on the dataset page: https://huggingface.co/datasets/nebius/SWE-bench-extra."},
	{"name":"AI-CUDA-Engineer-Archive","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/SakanaAI/AI-CUDA-Engineer-Archive","creator_name":"Sakana AI","creator_url":"https://huggingface.co/SakanaAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe AI CUDA Engineer Archive 👷: Agentic CUDA Kernel Discovery, Optimization & Composition\\n\\t\\n\\n\\nWe release The AI CUDA Engineer archive, a dataset consisting of approximately 30,000 CUDA kernels generated by The AI CUDA Engineer. It is released under the CC-By-4.0 license and can be accessed via HuggingFace and interactively visualized here. The dataset is based on the Kernel tasks provided in KernelBench and includes a torch reference implementation, torch, NCU and Clang-tidy profiling… See the full description on the dataset page: https://huggingface.co/datasets/SakanaAI/AI-CUDA-Engineer-Archive."},
	{"name":"Ling-Coder-DPO","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/inclusionAI/Ling-Coder-DPO","creator_name":"inclusionAI","creator_url":"https://huggingface.co/inclusionAI","description":"\\n    \\n\\n\\n\\n          🤗 Hugging Face\\n          🤖 ModelScope\\n          🖥️ GitHub\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLing-Coder Dataset\\n\\t\\n\\nThe Ling-Coder Dataset comprises the following components:\\n\\nLing-Coder-SFT: A subset of SFT data used for training Ling-Coder Lite, containing more than 5 million samples.\\nLing-Coder-DPO: A subset of DPO data used for training Ling-Coder Lite, containing 250k samples.\\nLing-Coder-SyntheticQA: A subset of synthetic data used for annealing training of Ling-Coder Lite, containing more… See the full description on the dataset page: https://huggingface.co/datasets/inclusionAI/Ling-Coder-DPO."},
	{"name":"Ling-Coder-SFT","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/inclusionAI/Ling-Coder-SFT","creator_name":"inclusionAI","creator_url":"https://huggingface.co/inclusionAI","description":"\\n    \\n\\n\\n\\n          🤗 Hugging Face\\n          🤖 ModelScope\\n          🖥️ GitHub\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLing-Coder Dataset\\n\\t\\n\\nThe Ling-Coder Dataset comprises the following components:\\n\\nLing-Coder-SFT: A subset of SFT data used for training Ling-Coder Lite, containing more than 5 million samples.\\nLing-Coder-DPO: A subset of DPO data used for training Ling-Coder Lite, containing 250k samples.\\nLing-Coder-SyntheticQA: A subset of synthetic data used for annealing training of Ling-Coder Lite, containing more… See the full description on the dataset page: https://huggingface.co/datasets/inclusionAI/Ling-Coder-SFT."},
	{"name":"Ling-Coder-SyntheticQA","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/inclusionAI/Ling-Coder-SyntheticQA","creator_name":"inclusionAI","creator_url":"https://huggingface.co/inclusionAI","description":"\\n    \\n\\n\\n\\n\\n          🤗 Hugging Face\\n          🤖 ModelScope\\n          🖥️ GitHub\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLing-Coder Dataset\\n\\t\\n\\nThe Ling-Coder Dataset comprises the following components:\\n\\nLing-Coder-SFT: A subset of SFT data used for training Ling-Coder Lite, containing more than 5 million samples.\\nLing-Coder-DPO: A subset of DPO data used for training Ling-Coder Lite, containing 250k samples.\\nLing-Coder-SyntheticQA: A subset of synthetic data used for annealing training of Ling-Coder Lite, containing more… See the full description on the dataset page: https://huggingface.co/datasets/inclusionAI/Ling-Coder-SyntheticQA."},
	{"name":"code_clippy_github","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CodedotAI/code_clippy_github","creator_name":"Code.AI","creator_url":"https://huggingface.co/CodedotAI","description":"The Code Clippy dataset consists of various public codebases from GitHub in 22 programming languages with 23 extensions     totalling about 16 TB of data when uncompressed. The dataset was created from the public GitHub dataset on Google BiqQuery."},
	{"name":"apps","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/codeparrot/apps","creator_name":"CodeParrot","creator_url":"https://huggingface.co/codeparrot","description":"APPS is a benchmark for Python code generation, it includes 10,000 problems, which range from having simple oneline solutions to being substantial algorithmic challenges, for more details please refer to this paper: https://arxiv.org/pdf/2105.09938.pdf."},
	{"name":"codecomplex","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/codeparrot/codecomplex","creator_name":"CodeParrot","creator_url":"https://huggingface.co/codeparrot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCodeComplex Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCodeComplex consists of 4,200 Java codes submitted to programming competitions by human programmers and their complexity labels annotated by a group of algorithm experts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use it\\n\\t\\n\\n You can load and iterate through the dataset with the following two lines of code:\\nfrom datasets import load_dataset\\n\\nds = load_dataset(\\\"codeparrot/codecomplex\\\", split=\\\"train\\\")\\nprint(next(iter(ds)))\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure… See the full description on the dataset page: https://huggingface.co/datasets/codeparrot/codecomplex."},
	{"name":"xlcost-text-to-code","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/codeparrot/xlcost-text-to-code","creator_name":"CodeParrot","creator_url":"https://huggingface.co/codeparrot","description":" XLCoST is a machine learning benchmark dataset that contains fine-grained parallel data in 7 commonly used programming languages (C++, Java, Python, C#, Javascript, PHP, C), and natural language (English)."},
	{"name":"github-jupyter-code-to-text","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/codeparrot/github-jupyter-code-to-text","creator_name":"CodeParrot","creator_url":"https://huggingface.co/codeparrot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\nThis dataset consists of sequences of Python code followed by a a docstring explaining its function. It was constructed by concatenating code and text pairs \\nfrom this dataset that were originally code and markdown cells in Jupyter Notebooks.\\nThe content of each example the following:\\n[CODE]\\n\\\"\\\"\\nExplanation: [TEXT]\\nEnd of explanation\\n\\\"\\\"\\n[CODE]\\n\\\"\\\"\\nExplanation: [TEXT]\\nEnd of explanation\\n\\\"\\\"\\n...\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use it\\n\\t\\n\\nfrom datasets import load_dataset… See the full description on the dataset page: https://huggingface.co/datasets/codeparrot/github-jupyter-code-to-text."},
	{"name":"conala","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/neulab/conala","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"CoNaLa is a dataset of code and natural language pairs crawled from Stack Overflow, for more details please refer to this paper: https://arxiv.org/pdf/1805.08949.pdf or the dataset page https://conala-corpus.github.io/."},
	{"name":"humaneval-x","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/THUDM/humaneval-x","creator_name":"Knowledge Engineering Group (KEG) & Data Mining at Tsinghua University","creator_url":"https://huggingface.co/THUDM","description":"HumanEval-X is a benchmark for the evaluation of the multilingual ability of code generative models. It consists of 820 high-quality human-crafted data samples (each with test cases) in Python, C++, Java, JavaScript, and Go, and can be used for various tasks."},
	{"name":"tldr","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/neulab/tldr","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"This is the re-split of CoNaLa dataset. For each code snippet in the dev and test set, at least one function is held out from the training set. This split aims at testing a code generation model's capacity in generating unseen functions.\\nWe further make sure that examples from the same StackOverflow post (same question_id before -) are in the same split."},
	{"name":"gsm-hard","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/reasoning-machines/gsm-hard","creator_name":"Reasoning Machines","creator_url":"https://huggingface.co/reasoning-machines","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the harder version of gsm8k math reasoning dataset (https://huggingface.co/datasets/gsm8k).\\nWe construct this dataset by replacing the numbers in the questions of GSM8K with larger numbers that are less common.\\n\\u0001\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is used to evaluate math reasoning\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish - Numbers\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\ndataset = load_dataset(\\\"reasoning-machines/gsm-hard\\\")\\nDatasetDict({… See the full description on the dataset page: https://huggingface.co/datasets/reasoning-machines/gsm-hard."},
	{"name":"tp3","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/gabeorlanski/tp3","creator_name":"Gabe Orlanski","creator_url":"https://huggingface.co/gabeorlanski","description":"Translating Python Programming Puzzles (TP3) is a code translation benchmark created from the verification functions from the questions in the original Python Programming Puzzles dataset (Schuster et al., 2021) to create this dataset. These functions are hand-crafted by the authors and are used to check if an answer satisfies the constraints of the puzzle. These puzzles range in difficulty from basic character checking to competitive programming problems. Thus, each verification function is written by an expert python programmer and requires a significant understanding of programming to translate. In total, there are 370 python functions to translate."},
	{"name":"CodeAlpaca-20k","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k","creator_name":"Sahil Chaudhary","creator_url":"https://huggingface.co/sahil2801","description":"sahil2801/CodeAlpaca-20k dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"translate_code_geeksforgeeks_for_t5","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bhadresh-savani/translate_code_geeksforgeeks_for_t5","creator_name":"Bhadresh Savani","creator_url":"https://huggingface.co/bhadresh-savani","description":"bhadresh-savani/translate_code_geeksforgeeks_for_t5 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"TSSB-3M-instructions","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/zirui3/TSSB-3M-instructions","creator_name":"zirui","creator_url":"https://huggingface.co/zirui3","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdata summary\\n\\t\\n\\ninstruction dataset for code bugfix\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReference\\n\\t\\n\\n[1]. TSSB-3M-ext\\n"},
	{"name":"TSSB-3M-instructions","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/zirui3/TSSB-3M-instructions","creator_name":"zirui","creator_url":"https://huggingface.co/zirui3","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdata summary\\n\\t\\n\\ninstruction dataset for code bugfix\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReference\\n\\t\\n\\n[1]. TSSB-3M-ext\\n"},
	{"name":"ShareGPT-Chinese-English-90k","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/shareAI/ShareGPT-Chinese-English-90k","creator_name":"shareAI","creator_url":"https://huggingface.co/shareAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShareGPT-Chinese-English-90k Bilingual Human-Machine QA Dataset\\n\\t\\n\\nA high-quality Chinese-English parallel bilingual human-machine QA dataset, covering user questions in real and complex scenarios. It is used for training high-quality dialogue models (more robust in instruction distribution than those datasets generated by repeatedly calling API interfaces to simulate machine-generated Q&A, like Moss)\\nFeatures:\\n\\n\\nProvides fully semantically equivalent Chinese-English parallel… See the full description on the dataset page: https://huggingface.co/datasets/shareAI/ShareGPT-Chinese-English-90k."},
	{"name":"ta-prompt","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bigcode/ta-prompt","creator_name":"BigCode","creator_url":"https://huggingface.co/bigcode","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset summary\\n\\t\\n\\nThis repository is dedicated to prompts used to perform in-context learning with starcoder. As a matter of fact, the model is an \\nautoregressive language model that is trained on both code and natural language text. It can be turned into an AI-powered technical assistant by prepending conversations to \\nits 8192-tokens context window.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFormat\\n\\t\\n\\nThe prompt is a .txt file which contains multiple conversations between a human and the assistant. Here is… See the full description on the dataset page: https://huggingface.co/datasets/bigcode/ta-prompt."},
	{"name":"code-search-net-javascript","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-javascript","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-javascript\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the JavaScript portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset's comments are in English and the functions are coded in JavaScript\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain, test… See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-javascript."},
	{"name":"reason_code-search-net-python","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"reason_code-search-net-python\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is an instructional dataset for Python.The dataset contains five different kind of tasks.   \\nGiven a Python 3 function:\\n\\nType 1: Generate a summary explaining what it does. (For example: This function counts the number of objects stored in the jsonl file passed as input.)\\nType 2: Generate a summary explaining what its input parameters represent (\\\"For example: infile: a file descriptor of… See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python."},
	{"name":"reason_code-search-net-python","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"reason_code-search-net-python\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is an instructional dataset for Python.The dataset contains five different kind of tasks.   \\nGiven a Python 3 function:\\n\\nType 1: Generate a summary explaining what it does. (For example: This function counts the number of objects stored in the jsonl file passed as input.)\\nType 2: Generate a summary explaining what its input parameters represent (\\\"For example: infile: a file descriptor of… See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python."},
	{"name":"multiclass-sentiment-analysis-dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Sp1786/multiclass-sentiment-analysis-dataset","creator_name":"Shahriar Parvez","creator_url":"https://huggingface.co/Sp1786","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information… See the full description on the dataset page: https://huggingface.co/datasets/Sp1786/multiclass-sentiment-analysis-dataset."},
	{"name":"deepFashion-with-masks","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SaffalPoosh/deepFashion-with-masks","creator_name":"Talha Yousuf","creator_url":"https://huggingface.co/SaffalPoosh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\nDataset name is deepfashion2 datasest, the dataset is in raw form with annotations, for original dataset repo. see https://github.com/switchablenorms/DeepFashion2 \\nThis dataset is just the extracted version of original deepfashion2 dataset and can be used for training Controlnet Model.\\n"},
	{"name":"evol-codealpaca-v1","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/theblackcat102/evol-codealpaca-v1","creator_name":"theblackcat102","creator_url":"https://huggingface.co/theblackcat102","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEvolved codealpaca\\n\\t\\n\\nUpdates:\\n\\n2023/08/26 - Filtered results now only contain pure english instruction and removed any mentioned of trained by OAI response\\n\\nMedian sequence length : 471\\nWe employed a methodology similar to that of WizardCoder, with the exception that ours is open-source. We used the gpt-4-0314 and gpt-4-0613 models to augment and answer each response, with the bulk of generation handled by gpt-4-0314.\\nThe aim of this dataset is twofold: firstly, to facilitate the… See the full description on the dataset page: https://huggingface.co/datasets/theblackcat102/evol-codealpaca-v1."},
	{"name":"cve-llm-training","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/morpheuslord/cve-llm-training","creator_name":"Chiranjeevi G","creator_url":"https://huggingface.co/morpheuslord","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCVE-llm_dataset\\n\\t\\n\\nThis dataset is intended to train an LLM model for an utterly CVE-focused input and output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData extraction:\\n\\t\\n\\nFor the data extraction, I first downloaded the CVE database from NVD lists and then loaded them using the cve_dataset_2.py and cve_dataset.py both have produce different datasets one is for llama and the other is for openai GPT.\\nThe CVE json files are mapped in this format:\\ncves:\\n|\\n├─1999\\n|   ├─0xxx\\n|   |   ├─CVE-1999-0001.json\\n|   |… See the full description on the dataset page: https://huggingface.co/datasets/morpheuslord/cve-llm-training."},
	{"name":"GitHub-CC0","keyword":"code","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/KoalaAI/GitHub-CC0","creator_name":"Koala AI","creator_url":"https://huggingface.co/KoalaAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPublic Domain GitHub Repositories Dataset\\n\\t\\n\\nThis dataset contains metadata and source code of 9,000 public domain (cc0 or unlicense) licensed GitHub repositories that have more than 25 stars. \\nThe dataset was created by scraping the GitHub API and downloading the repositories, so long as they are under 100mb.\\nThe dataset can be used for various natural language processing and software engineering tasks, such as code summarization, code generation, code search, code analysis, etc.… See the full description on the dataset page: https://huggingface.co/datasets/KoalaAI/GitHub-CC0."},
	{"name":"Methods2Test_java_unit_test_code","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jitx/Methods2Test_java_unit_test_code","creator_name":"Jiting Xu","creator_url":"https://huggingface.co/jitx","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMicrosoft created this large dataset of Java Junit test cases with its corresponding focal methods. \\nIt contains 780k pairs of JUnit test cases and focal methods which were extracted from a total of 91K\\nJava open source project hosted on GitHub. \\nThe mapping between test case and focal methods are based heuristics rules and Java developer's best practice.\\nMore information could be found here:\\n\\nmethods2test Github repo\\nMethods2Test: A dataset of focal methods… See the full description on the dataset page: https://huggingface.co/datasets/jitx/Methods2Test_java_unit_test_code."},
	{"name":"ComPile","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/llvm-ml/ComPile","creator_name":"Machine Learning on LLVM","creator_url":"https://huggingface.co/llvm-ml","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ComPile: A Large IR Dataset from Production Sources\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChangelog\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nRelease\\nProgramming Languages\\nDescription\\n\\n\\n\\t\\t\\nv1.0\\nC/C++, Rust, Swift, Julia\\nFine Tuning-scale dataset of 602GB of deduplicated LLVM (bitcode) IR\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nComPile contains over 2.7TB of permissively-licensed source code compiled to (textual) LLVM\\nintermediate representation (IR) covering C/C++, Rust, Swift, and Julia.\\nThe dataset was created by hooking… See the full description on the dataset page: https://huggingface.co/datasets/llvm-ml/ComPile."},
	{"name":"sql-create-context-instruction","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction","creator_name":"Spartak Bughdaryan","creator_url":"https://huggingface.co/bugdaryan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is built upon SQL Create Context, which in turn was constructed using data from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-SQL LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-SQL datasets. The CREATE TABLE statement can often… See the full description on the dataset page: https://huggingface.co/datasets/bugdaryan/sql-create-context-instruction."},
	{"name":"gsm8k-prolog","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Thomas-X-Yang/gsm8k-prolog","creator_name":"Xiaocheng Yang","creator_url":"https://huggingface.co/Thomas-X-Yang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GSM8K-Prolog\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the Prolog annotated version of the GSM8K math reasoning dataset.\\nWe used the same dataset splits and questions in GSM8K and prompted GPT-4 to generate the Prolog programs to solve the questions.\\nWe then manually corrected some malfunctioning samples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be used to train language models to generate Prolog codes in order to solve math questions and… See the full description on the dataset page: https://huggingface.co/datasets/Thomas-X-Yang/gsm8k-prolog."},
	{"name":"StackOverflow-QA-C-Language-40k","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Mxode/StackOverflow-QA-C-Language-40k","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"This is a collection of ~40k QA's in C Language from StackOverflow. The data has been initially cleaned, and each response is with Accepted Answer. \\nAll data is <1000 in length.\\nThe questions and answers were organized into a one-line format. A sample format is shown below:\\n{\\n    \\\"question\\\": \\\"```\\\\nFILE* file = fopen(some file)\\\\n\\\\npcap_t* pd = pcap_fopen_offline(file)\\\\n\\\\npcap_close(pd)\\\\n\\\\nfclose(file)\\\\n```\\\\n\\\\nThis code occurs double free error.\\\\n\\\\nCould you explain about this happening?\\\\n\\\\nMy… See the full description on the dataset page: https://huggingface.co/datasets/Mxode/StackOverflow-QA-C-Language-40k."},
	{"name":"C-Language-Chat-Debug-Multiturn-Zh","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Mxode/C-Language-Chat-Debug-Multiturn-Zh","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"约 1300 条 C 语言 场景的 user - assistant 多轮对话。每段对话已经组织成了单行的格式。一条样例如下：\\n{\\n    \\\"id\\\": 1045,\\n    \\\"conversation\\\": [\\n        {\\n            \\\"user\\\": \\\"你好，AI助手。我最近在写一个C语言程序，但是遇到了一些问题，希望你能帮我检查一下。\\\",\\n            \\\"assistant\\\": \\\"你好，我很乐意帮助你。请把你的代码发给我，我会尽快检查并给出建议。\\\"\\n        },\\n        {\\n            \\\"user\\\": \\\"好的，这是我的代码。这段代码的主要功能是计算斐波那契数列的前n项。\\\",\\n            \\\"assistant\\\": \\\"让我看一下......嗯，这里有一个小错误。在第10行，你应该使用`++i`而不是`i++`来递增i的值。修改后的代码应该是这样的\\\\\\\\n```c\\\\\\\\nfor (int i = 0; i < n; ++i) {\\\\\\\\n    if (i == 0 || i == 1) {\\\\\\\\n… See the full description on the dataset page: https://huggingface.co/datasets/Mxode/C-Language-Chat-Debug-Multiturn-Zh."},
	{"name":"SlimOrca-Dedup","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Open-Orca/SlimOrca-Dedup","creator_name":"OpenOrca","creator_url":"https://huggingface.co/Open-Orca","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\n\\n\\\"SlimOrca Dedup\\\" is a deduplicated, unfiltered subset of the SlimOrca dataset, excluding RLHF instances, resulting in 363k unique examples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKey Features\\n\\t\\n\\n\\nRemoval of RLHF instances.\\nDeduplication using minhash and Jaccard similarity techniques.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemo Models\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote: These models were trained on the full SlimOrca dataset, not the deduplicated, unfiltered version.\\n* https://huggingface.co/openaccess-ai-collective/jackalope-7b\\n*… See the full description on the dataset page: https://huggingface.co/datasets/Open-Orca/SlimOrca-Dedup."},
	{"name":"hackaprompt-dataset","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hackaprompt/hackaprompt-dataset","creator_name":"hackaprompt","creator_url":"https://huggingface.co/hackaprompt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for HackAPrompt 💻🔍\\n\\t\\n\\nThis dataset contains submissions from a prompt hacking competition. An in-depth analysis of the dataset has been accepted at the EMNLP 2023 conference. 📊👾\\nSubmissions were sourced from two environments: a playground for experimentation and an official submissions platform.\\nThe playground itself can be accessed here 🎮\\nMore details about the competition itself here 🏆\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details 📋\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description 📄\\n\\t\\n\\nWe… See the full description on the dataset page: https://huggingface.co/datasets/hackaprompt/hackaprompt-dataset."},
	{"name":"luau_corpus","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Roblox/luau_corpus","creator_name":"Roblox Corporation","creator_url":"https://huggingface.co/Roblox","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card\\n\\t\\n\\nThe Luau dataset is a collection of code fragments collected from the Roblox Luau Data Sharing program.\\nOnly experiences where creators gave us permission to contribute to the public Luau Dataset were used for producing this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages:\\n\\t\\n\\nLua, Luau\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense:\\n\\t\\n\\nMIT\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software… See the full description on the dataset page: https://huggingface.co/datasets/Roblox/luau_corpus."},
	{"name":"cruxeval","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/cruxeval-org/cruxeval","creator_name":"cruxeval","creator_url":"https://huggingface.co/cruxeval-org","description":" CRUXEval: Code Reasoning, Understanding, and Execution Evaluation \\n\\n\\n    🏠 Home Page •\\n    💻 GitHub Repository  •\\n    🏆 Leaderboard •\\n    🔎 Sample Explorer\\n\\n\\n\\nCRUXEval (Code Reasoning, Understanding, and eXecution Evaluation) is a benchmark of 800 Python functions and input-output pairs. The benchmark consists of two tasks, CRUXEval-I (input prediction) and CRUXEval-O (output prediction). \\nThe benchmark was constructed as follows: first, we use Code Llama 34B to generate a large set of… See the full description on the dataset page: https://huggingface.co/datasets/cruxeval-org/cruxeval."},
	{"name":"github-issue-similarity","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/WhereIsAI/github-issue-similarity","creator_name":"WhereIsAI","creator_url":"https://huggingface.co/WhereIsAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGIS: Github Issue Similarity Dataset\\n\\t\\n\\nThis dataset was released from the paper: https://arxiv.org/abs/2309.12871\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you use our dataset in your research, welcome to cite us as follows:\\n@article{li2023angle,\\n  title={AnglE-optimized Text Embeddings},\\n  author={Li, Xianming and Li, Jing},\\n  journal={arXiv preprint arXiv:2309.12871},\\n  year={2023}\\n}\\n\\n"},
	{"name":"Mr-GSM8K","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Randolphzeng/Mr-GSM8K","creator_name":"Randolphzeng","creator_url":"https://huggingface.co/Randolphzeng","description":"View the project page:\\nhttps://github.com/dvlab-research/DiagGSM8K\\nsee our paper at https://arxiv.org/abs/2312.17080\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nIn this work, we introduce a novel evaluation paradigm for Large Language Models, \\none that challenges them to engage in meta-reasoning. Our paradigm shifts the focus from result-oriented assessments, \\nwhich often overlook the reasoning process, to a more holistic evaluation that effectively differentiates \\nthe cognitive capabilities among models. For… See the full description on the dataset page: https://huggingface.co/datasets/Randolphzeng/Mr-GSM8K."},
	{"name":"WebSight","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/HuggingFaceM4/WebSight","creator_name":"HuggingFaceM4","creator_url":"https://huggingface.co/HuggingFaceM4","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WebSight\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWebSight is a large synthetic dataset containing HTML/CSS codes representing synthetically generated English websites, each accompanied by a corresponding screenshot.\\nThis dataset serves as a valuable resource for tasks such as generating UI codes from a screenshot.\\nIt comes in two versions:\\n\\nv0.1: Websites are coded with HTML + CSS. They do not include real images.\\nv0.2: Websites are coded with HTML + Tailwind CSS. They do… See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceM4/WebSight."},
	{"name":"DebugBench","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Rtian/DebugBench","creator_name":"Runchu Tian","creator_url":"https://huggingface.co/Rtian","description":" \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDebugBench is a Large Language Model (LLM) debugging benchmark introduced in the paper DebugBench: Evaluating Debugging Capability of Large Language Models. We collect code snippets from the LeetCode community and implant bugs into source data with GPT-4. The project is also open-sourced as a GitHub repository.\\n\\nIt consists of 4,253 instances.\\nIt covers four major bug categories and 18 minor types.\\nIt includes C++, Java, and Python instances.\\nIt contains three… See the full description on the dataset page: https://huggingface.co/datasets/Rtian/DebugBench."},
	{"name":"T-Eval","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lovesnowbest/T-Eval","creator_name":"Zehui Chen","creator_url":"https://huggingface.co/lovesnowbest","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tT-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t✨ Introduction\\n\\t\\n\\nThis is an evaluation harness for the benchmark described in T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step. \\n[Paper]\\n[Project Page]\\n[LeaderBoard]\\n[HuggingFace]\\n\\nLarge language models (LLM) have achieved remarkable performance on various NLP tasks and are augmented by tools for broader applications. Yet, how to… See the full description on the dataset page: https://huggingface.co/datasets/lovesnowbest/T-Eval."},
	{"name":"python-github-code-instruct-filtered-5k","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jtatman/python-github-code-instruct-filtered-5k","creator_name":"James","creator_url":"https://huggingface.co/jtatman","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"python-github-code-instruct-filtered-5k\\\"\\n\\t\\n\\nThis fine dataset tomekkorbak/python-github-code, filtered by scores greater than 0.03. \\nFeedback and additional columns generated through OpenAI and Cohere responses. \\n"},
	{"name":"MHaluBench","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/openkg/MHaluBench","creator_name":"OpenKG Consortium","creator_url":"https://huggingface.co/openkg","description":"\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAn Easy-to-Use Multimodal Hallucination Detection Framework for MLLMs\\n \\n\\t\\n\\n\\n  🌻Acknowledgement •\\n  🤗Benchmark •\\n  🍎Demo •\\n  🌟Overview •\\n  🐧ModelZoo •\\n  🔧Installation •\\n  ⏩Quickstart •\\n  ⏱️Version •\\n  🚩Citation \\n  \\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🔔News\\n\\t\\n\\n\\n2024-04-21 We replace all the base models in the demo with our own trained models, significantly reducing the inference time.\\n2024-04-21 We release our open-source hallucination detection model HalDet-LLAVA, which can be… See the full description on the dataset page: https://huggingface.co/datasets/openkg/MHaluBench."},
	{"name":"UltraTextbooks","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Locutusque/UltraTextbooks","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"UltraTextbooks\\\"\\n\\t\\n\\n\\nIn the digital expanse, a Tree of Knowledge grows,\\nIts branches of code and words intertwine in prose.\\nSynthetic leaves shimmer, human insights compose,\\nA binary symphony where wisdom forever flows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRepository\\n\\t\\n\\nThe \\\"UltraTextbooks\\\" dataset is hosted on the Hugging Face platform.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nThe \\\"UltraTextbooks\\\" dataset is a comprehensive collection of high-quality synthetic and… See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/UltraTextbooks."},
	{"name":"UltraTextbooks","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Locutusque/UltraTextbooks","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"UltraTextbooks\\\"\\n\\t\\n\\n\\nIn the digital expanse, a Tree of Knowledge grows,\\nIts branches of code and words intertwine in prose.\\nSynthetic leaves shimmer, human insights compose,\\nA binary symphony where wisdom forever flows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRepository\\n\\t\\n\\nThe \\\"UltraTextbooks\\\" dataset is hosted on the Hugging Face platform.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nThe \\\"UltraTextbooks\\\" dataset is a comprehensive collection of high-quality synthetic and… See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/UltraTextbooks."},
	{"name":"DISL","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ASSERT-KTH/DISL","creator_name":"ASSERT","creator_url":"https://huggingface.co/ASSERT-KTH","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDISL\\n\\t\\n\\nThe DISL dataset features a collection of 514506 unique Solidity files that have been deployed to Ethereum mainnet. It caters to the need for a large and diverse dataset of real-world smart contracts. DISL serves as a resource for developing machine learning systems and for benchmarking software engineering tools designed for smart contracts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContent\\n\\t\\n\\n\\nthe raw subset has full contracts source code and it's not deduplicated, it has 3,298,271 smart contracts\\nthe… See the full description on the dataset page: https://huggingface.co/datasets/ASSERT-KTH/DISL."},
	{"name":"Code-Golang-QA-2k","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k","creator_name":"ExAi","creator_url":"https://huggingface.co/ExAi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode-Golang-QA-2k\\n\\t\\n\\nThis (small) dataset comprises 2,000 question-and-answer entries related to the Go programming language. It is designed to serve as a resource for individuals looking to enhance machine learning models, create chatbots, or simply to provide a comprehensive knowledge base for developers working with Go.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Format\\n\\t\\n\\n[\\n    {\\n        \\\"question\\\": \\\"How do you create a new RESTful API endpoint using Gin?\\\",\\n        \\\"answer\\\": \\\"Creating a new RESTful API… See the full description on the dataset page: https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k."},
	{"name":"Code-Golang-QA-2k-dpo","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k-dpo","creator_name":"ExAi","creator_url":"https://huggingface.co/ExAi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode-Golang-QA-2k\\n\\t\\n\\nThis (small) dataset comprises ~1.8k dpo entries related to the Go programming language. It is designed to serve as a resource for individuals looking to enhance machine learning models, create chatbots, or simply to provide a comprehensive knowledge base for developers working with Go.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Format\\n\\t\\n\\n[\\n  {\\n    \\\"question\\\": \\\"How do you create a new RESTful API endpoint using Gin?\\\",\\n    \\\"chosen_answer\\\": \\\"Creating a new RESTful API endpoint using the… See the full description on the dataset page: https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k-dpo."},
	{"name":"Code-290k-ShareGPT-Vicuna","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/cognitivecomputations/Code-290k-ShareGPT-Vicuna","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","description":"Code-290k-ShareGPT-Vicuna\\nThis dataset is in Vicuna/ShareGPT format. There are around 290000 set of conversations. Each set having 2 conversations. \\nAlong with Python, Java, JavaScript, GO, C++, Rust, Ruby, Sql, MySql, R, Julia, Haskell, etc. code with detailed explanation are provided.\\nThis datset is built upon using my existing Datasets Python-Code-23k-ShareGPT\\nand Code-74k-ShareGPT.\\n"},
	{"name":"codegolf","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/VatsaDev/codegolf","creator_name":"Vatsa Pandey","creator_url":"https://huggingface.co/VatsaDev","description":"The entire codegolf stackexchange where questions have a score above 0, 14K code questions with all the answers\\n\\ngood for learning complex code questions, more unique challenges, code optimizations, and code not really mainstream, could help diversity\\n\\n"},
	{"name":"AI-human-text","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/andythetechnerd03/AI-human-text","creator_name":"Dinh Ngoc An","creator_url":"https://huggingface.co/andythetechnerd03","description":"This is a processed dataset of Human vs AI Text roughly 400k rows. This is taken from the Kaggle dataset https://www.kaggle.com/datasets/shanegerami/ai-vs-human-text/data then processed and split into training and test sets.\\n"},
	{"name":"Code-Feedback","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/m-a-p/Code-Feedback","creator_name":"Multimodal Art Projection","creator_url":"https://huggingface.co/m-a-p","description":" OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement\\n\\n\\n\\n\\n\\n  [🏠Homepage] \\n  |\\n  [🛠️Code] \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nOpenCodeInterpreter is a family of open-source code generation systems designed to bridge the gap between large language models and advanced proprietary systems like the GPT-4 Code Interpreter. It significantly advances code generation capabilities by integrating execution and iterative refinement functionalities.\\nFor further information and… See the full description on the dataset page: https://huggingface.co/datasets/m-a-p/Code-Feedback."},
	{"name":"CodeFeedback-Filtered-Instruction","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/m-a-p/CodeFeedback-Filtered-Instruction","creator_name":"Multimodal Art Projection","creator_url":"https://huggingface.co/m-a-p","description":" OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement\\n\\n\\n\\n\\n\\n  [🏠Homepage] \\n  |\\n  [🛠️Code] \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenCodeInterpreter\\n\\t\\n\\nOpenCodeInterpreter is a family of open-source code generation systems designed to bridge the gap between large language models and advanced proprietary systems like the GPT-4 Code Interpreter. It significantly advances code generation capabilities by integrating execution and iterative refinement functionalities.\\nFor further information… See the full description on the dataset page: https://huggingface.co/datasets/m-a-p/CodeFeedback-Filtered-Instruction."},
	{"name":"Code_Vulnerability_Security_DPO","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CyberNative/Code_Vulnerability_Security_DPO","creator_name":"Byte","creator_url":"https://huggingface.co/CyberNative","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCybernative.ai Code Vulnerability and Security Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Cybernative.ai Code Vulnerability and Security Dataset is a dataset of synthetic Data Programming by Demonstration (DPO) pairs, focusing on the intricate relationship between secure and insecure code across a variety of programming languages. This dataset is meticulously crafted to serve as a pivotal resource for researchers, cybersecurity professionals, and AI developers who are keen… See the full description on the dataset page: https://huggingface.co/datasets/CyberNative/Code_Vulnerability_Security_DPO."},
	{"name":"omniact","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Writer/omniact","creator_name":"Writer","creator_url":"https://huggingface.co/Writer","description":"\\n\\nDataset for OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web\\nSplits:\\n\\n\\t\\n\\t\\t\\nsplit_name\\ncount\\n\\n\\n\\t\\t\\ntrain\\n6788\\n\\n\\ntest\\n2020\\n\\n\\nval\\n991\\n\\n\\n\\t\\n\\nExample datapoint:\\n  \\\"2849\\\": {\\n      \\\"task\\\": \\\"data/tasks/desktop/ibooks/task_1.30.txt\\\",\\n      \\\"image\\\": \\\"data/data/desktop/ibooks/screen_1.png\\\",\\n      \\\"box\\\": \\\"data/metadata/desktop/boxes/ibooks/screen_1.json\\\"\\n  },\\n\\nwhere:\\n\\ntask - contains natural language description (\\\"Task\\\") along with the corresponding… See the full description on the dataset page: https://huggingface.co/datasets/Writer/omniact."},
	{"name":"TableLLM-SFT","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/RUCKBReasoning/TableLLM-SFT","creator_name":"RUCKBReasoning","creator_url":"https://huggingface.co/RUCKBReasoning","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTableLLM-SFT\\n\\t\\n\\n| Paper | Model | Github | Homepage |\\nTableLLM-SFT is a training set containing a number of splits on different benchmarks. This training set is used to fine-tuning TableLLM-7b and TableLLM-13b, which are based on CodeLlama-7b and CodeLlama-13b, respectively.\\n"},
	{"name":"tldr-pages","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Edoigtrd/tldr-pages","creator_name":"Edouard Seemann","creator_url":"https://huggingface.co/Edoigtrd","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTLDR.sh pages\\n\\t\\n\\n\\nThe tldr pages are a community effort to simplify the beloved man pages with practical examples. tldr.sh\\n\\nThis dataset contain parsed data from the tldr/pages repository in the English/Linux section.\\nIt provides Bash commands associated to their description.\\n"},
	{"name":"DS-1000","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/xlangai/DS-1000","creator_name":"XLang NLP Lab","creator_url":"https://huggingface.co/xlangai","description":" DS-1000 in simplified format \\n\\n🔥 Check the leaderboard from Eval-Arena on our project page.\\nSee testing code and more information (also the original fill-in-the-middle/Insertion format) in the DS-1000 repo.\\nReformatting credits: Yuhang Lai, Sida Wang\\n  \\n"},
	{"name":"dungeon-dataset","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/DolphinNie/dungeon-dataset","creator_name":"Yuhe Nie","creator_url":"https://huggingface.co/DolphinNie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBrogue Map Dataset\\n\\t\\n\\nTo clone this repo, use:\\ngit clone https://huggingface.co/datasets/DolphinNie/dungeon-dataset\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1. Data Explanation\\n\\t\\n\\nThis is the Map dataset from the open-sourced game Brogue. It contains 49,000 train dataset, 14,000 test dataset and 7,000 validation dataset.\\nEach map is stored in a .csv file. The map is a (32x32) array, which is the map size.\\nEach cell in the array is a int number ranged from 0 to 13, which represented 14 tiles.\\n  \\\"G_NONE\\\": 0… See the full description on the dataset page: https://huggingface.co/datasets/DolphinNie/dungeon-dataset."},
	{"name":"Human-Style-Answers","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/innova-ai/Human-Style-Answers","creator_name":"INNOVA AI","creator_url":"https://huggingface.co/innova-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHuman Style Answers\\n\\t\\n\\n\\n\\nThis Datasets contains question and answers on different topics in Human style. (For Chatbots training)\\nThis Datasets is build using TOP AI like (GPT4, Claude3 , Command R+, etc.)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\n\\nThe Human Style Response Dataset is a rich collection of question-and-answer pairs, meticulously crafted in a human-like style. It serves as a valuable resource for training chatbots and conversational AI models. Let's… See the full description on the dataset page: https://huggingface.co/datasets/innova-ai/Human-Style-Answers."},
	{"name":"MathCodeInstruct-Plus","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/MathLLMs/MathCodeInstruct-Plus","creator_name":"LLMs for Math Reasoning","creator_url":"https://huggingface.co/MathLLMs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning\\n\\t\\n\\nPaper: https://arxiv.org/pdf/2310.03731.pdf\\nRepo: https://github.com/mathllm/MathCoder\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce MathCoder, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving.\\n\\n\\t\\n\\t\\t\\nBase Model: Llama-2\\nBase Model: Code Llama\\n\\n\\n\\t\\t\\nMathCoder-L-7B\\nMathCoder-CL-7B\\n\\n\\nMathCoder-L-13B\\nMathCoder-CL-34B\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTraining Data… See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathCodeInstruct-Plus."},
	{"name":"RLSTACK","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/H-D-T/RLSTACK","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to… See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/RLSTACK."},
	{"name":"Plot2Code","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/TencentARC/Plot2Code","creator_name":"ARC Lab, Tencent PCG","creator_url":"https://huggingface.co/TencentARC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPlot2Code Benchmark\\n\\t\\n\\nPlot2Code benchmark is now open-sourced at huggingface (ARC Lab) and GitHub. More information can be found in our paper. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy we need Plot2Code?\\n\\t\\n\\n\\n🧐 While MLLMs have demonstrated potential in visual contexts, their capabilities in visual coding tasks have not been thoroughly evaluated. Plot2Code offers a platform for comprehensive assessment of these models.\\n\\n🤗 To enable individuals to ascertain the proficiency of AI assistants in generating… See the full description on the dataset page: https://huggingface.co/datasets/TencentARC/Plot2Code."},
	{"name":"godot_4_docs","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/glaiveai/godot_4_docs","creator_name":"Glaive AI","creator_url":"https://huggingface.co/glaiveai","description":"Dataset generated for Godot 4 docs using Glaive.\\n"},
	{"name":"blockchain-benchmark","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/revflask/blockchain-benchmark","creator_name":"Mayank Panjiyara","creator_url":"https://huggingface.co/revflask","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LLM Blockchain Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Blockchain Benchmark Dataset is a comprehensive collection of data specifically curated for benchmarking Language Models (LMs) in the domain of blockchain technology. This dataset is designed to facilitate research and development in natural language understanding within the blockchain domain.\\nA complete list of tasks: ['general-reasoning', 'code', 'math']\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards… See the full description on the dataset page: https://huggingface.co/datasets/revflask/blockchain-benchmark."},
	{"name":"blockchain-benchmark-formatted","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/revflask/blockchain-benchmark-formatted","creator_name":"Mayank Panjiyara","creator_url":"https://huggingface.co/revflask","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LLM Blockchain Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Blockchain Benchmark Dataset is a comprehensive collection of data specifically curated for benchmarking Language Models (LMs) in the domain of blockchain technology. This dataset is designed to facilitate research and development in natural language understanding within the blockchain domain.\\nA complete list of tasks: ['general-reasoning', 'code', 'math']\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards… See the full description on the dataset page: https://huggingface.co/datasets/revflask/blockchain-benchmark-formatted."},
	{"name":"unreal-engine-5-code","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AdamCodd/unreal-engine-5-code","creator_name":"AdamCodd","creator_url":"https://huggingface.co/AdamCodd","description":"Processed dataset from AdamCodd/unreal-engine-5-raw focused on the code.\\nIf you want to support me, you can here.\\n"},
	{"name":"RAG-v1","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/glaiveai/RAG-v1","creator_name":"Glaive AI","creator_url":"https://huggingface.co/glaiveai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGlaive-RAG-v1\\n\\t\\n\\nGlaive-RAG-v1 is a dataset with ~50k samples built using the Glaive platform, for finetuning models for RAG use cases. \\nEach row has:\\n\\nList of documents for context\\nQuestion\\nAnswer Mode\\nAnswer\\n\\nThe answer mode is to define if the model should output only grounded responses or if it should combine it's internal information as well.\\nThe answers have Cited documents at the beginning and also <co: 1> tags in the text to mark citations.\\nTo report any problems or… See the full description on the dataset page: https://huggingface.co/datasets/glaiveai/RAG-v1."},
	{"name":"hpc-instruct","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hpcgroup/hpc-instruct","creator_name":"Parallel Software and Systems Group","creator_url":"https://huggingface.co/hpcgroup","description":"This is an HPC code instruct dataset that was used to train the HPC-Coder-v2 models. There are 122k samples generated synthetically using Gemini Pro, DBRX,Llama-3 and Mixtral.\\nThere are four types of instruct samples in HPC-Instruct detailed below.\\n\\nCode Synthesis: The instruction tasks the LLM to generate code to solve an HPC related problem.\\nParallelization: The instruction tasks the LLM to parallelize an existing sequential code.\\nOptimization: The instruction tasks the LLM to optimize an… See the full description on the dataset page: https://huggingface.co/datasets/hpcgroup/hpc-instruct."},
	{"name":"uzbek_ner","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/risqaliyevds/uzbek_ner","creator_name":"Riskaliev Muradjon","creator_url":"https://huggingface.co/risqaliyevds","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUzbek NER Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout the Dataset\\n\\t\\n\\nThis dataset is created for Named Entity Recognition (NER) in Uzbek texts. The dataset includes named entities from various categories such as persons, places, organizations, dates, and more.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure\\n\\t\\n\\nThe data is provided in JSON format with the following structure:\\n{\\n    \\\"LOC\\\": [\\\"Location names\\\"],\\n    \\\"ORG\\\": [\\\"Organization names\\\"],\\n    \\\"PERSON\\\": [\\\"Person names\\\"],\\n    \\\"DATE\\\": [\\\"Date expressions\\\"]… See the full description on the dataset page: https://huggingface.co/datasets/risqaliyevds/uzbek_ner."},
	{"name":"Nuke-X-Glaive-Python-Dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NuclearAi/Nuke-X-Glaive-Python-Dataset","creator_name":"Nuclear Ai","creator_url":"https://huggingface.co/NuclearAi","description":"We're excited to announce the release of the NuclearAi/Nuke-X-Glaive-Python-Dataset, a comprehensive Collection of over 240,888 unique lines of Python Code sourced from public datasets. This dataset is specifically designed for fine-tuning and training LLMs to achieve exceptional accuracy in Python language understanding and generation.\\n"},
	{"name":"InfinityMATH","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/BAAI/InfinityMATH","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInfinityMATH\\n\\t\\n\\nWe introduce InfinityMATH, a scalable instruction tuning dataset for programmatic mathematical reasoning. The construction pipeline emphasizes decoupling numbers from mathematical problems to synthesize number-independent programs, enabling efficient and flexible scaling while minimizing dependency on specific numerical values. Fine-tuning experiments with open-source language and code models, such as Llama2 and CodeLlama, demonstrate the practical benefits of… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/InfinityMATH."},
	{"name":"linux_cmd_alpaca","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bajrangCoder/linux_cmd_alpaca","creator_name":"Raunak Raj","creator_url":"https://huggingface.co/bajrangCoder","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlinux_cmd_alpaca\\n\\t\\n\\nThis repository contains a dataset in Alpaca format, consisting of natural language instructions, shell commands, and corresponding responses of linux terminal. This dataset is made from some existing datasets with more data and in alpaca format\\n"},
	{"name":"BRIGHT","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/xlangai/BRIGHT","creator_name":"XLang NLP Lab","creator_url":"https://huggingface.co/xlangai","description":"\\n\\t\\n\\t\\t\\n\\t\\tBRIGHT benchmark\\n\\t\\n\\nBRIGHT is the first text retrieval benchmark that requires intensive reasoning to retrieve relevant documents. \\nThe queries are collected from diverse domains (StackExchange, LeetCode, and math competitions), all sourced from realistic human data.\\nExperiments show that existing retrieval models perform poorly on BRIGHT, where the highest score is only 22.1 measured by nDCG@10.\\nBRIGHT provides a good testbed for future retrieval research in more realistic and… See the full description on the dataset page: https://huggingface.co/datasets/xlangai/BRIGHT."},
	{"name":"LaTeX_OCR","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/linxy/LaTeX_OCR","creator_name":"Lin Xueyuan","creator_url":"https://huggingface.co/linxy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLaTeX OCR 的数据仓库\\n\\t\\n\\n本数据仓库是专为 LaTeX_OCR 及 LaTeX_OCR_PRO 制作的数据，来源于 https://zenodo.org/record/56198#.V2p0KTXT6eA 以及 https://www.isical.ac.in/~crohme/ 以及我们自己构建。\\n如果这个数据仓库有帮助到你的话，请点亮 ❤️like ++\\n后续追加新的数据也会放在这个仓库 ~~\\n\\n原始数据仓库在github LinXueyuanStdio/Data-for-LaTeX_OCR.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集\\n\\t\\n\\n本仓库有 5 个数据集\\n\\nsmall 是小数据集，样本数 110 条，用于测试\\nfull 是印刷体约 100k 的完整数据集。实际上样本数略小于 100k，因为用 LaTeX 的抽象语法树剔除了很多不能渲染的 LaTeX。\\nsynthetic_handwrite 是手写体 100k 的完整数据集，基于 full 的公式，使用手写字体合成而来，可以视为人类在纸上的手写体。样本数实际上略小于 100k，理由同上。… See the full description on the dataset page: https://huggingface.co/datasets/linxy/LaTeX_OCR."},
	{"name":"McEval","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Multilingual-Multimodal-NLP/McEval","creator_name":"Multilingual-Multimodal-NLP","creator_url":"https://huggingface.co/Multilingual-Multimodal-NLP","description":"McEval benchmark data as described in the McEval Paper. Code for the evaluation can be found on Github as McEval.\\n"},
	{"name":"Buzz-V1.2","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/H-D-T/Buzz-V1.2","creator_name":"Hive-Digital-Technologies","creator_url":"https://huggingface.co/H-D-T","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBuzz: Advancing Efficiency through Iterative Fine-Tuning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n\\nAlignment Lab AI is pleased to introduce our latest research efforts with:\\n\\nBuzz, a highly curated pretraining scale assistant dataset, unifying RL and SFT, developed in collaboration with Hive Digital Technologies. \\nThe Buzz model, Dataset, and Code are to be released to build a toolkit that aims to demonstrate the potential for reuse and optimization of existing pretrained language models to… See the full description on the dataset page: https://huggingface.co/datasets/H-D-T/Buzz-V1.2."},
	{"name":"VersiCode","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AstoneNg/VersiCode","creator_name":"Tongtong Wu","creator_url":"https://huggingface.co/AstoneNg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersiCode: Towards Version-controllable Code Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nVersiCode is the first comprehensive dataset designed to assess the ability of large language models to generate verifiable code for specific library versions. VersiCode encompasses 300 libraries across more than 2,000 versions spanning 9 years. We design two dedicated evaluation tasks: version-specific code completion (VSCC) and version-aware code editing (VACE). The resources can be… See the full description on the dataset page: https://huggingface.co/datasets/AstoneNg/VersiCode."},
	{"name":"audits-with-reasons","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/msc-smart-contract-auditing/audits-with-reasons","creator_name":"Smart Contract Auditing","creator_url":"https://huggingface.co/msc-smart-contract-auditing","description":"This dataset builds on top of the base dataset by augmenting it using the quantized Llama3 8b instruct model by Unsloth\\nNamely, it:\\n\\nExpands on the level of detail of the description and recommendation.\\nCleans-up the code by fixing formatting and removing out-of-context comments (e.g external URLs which might confuse a model)\\nAdds two new fields: functionality and type (see table for more detail)\\n\\nThe non-vulnerable examples only have values for code, functionality and type='no vulnerability'… See the full description on the dataset page: https://huggingface.co/datasets/msc-smart-contract-auditing/audits-with-reasons."},
	{"name":"golang-coder","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/smcleod/golang-coder","creator_name":"Sam McLeod","creator_url":"https://huggingface.co/smcleod","description":"Q&A style combined, deduplicated dataset including portions of:\\n\\nGolang best practices and coding guides (general Q&A) https://huggingface.co/datasets/smcleod/golang-programming-style-best-practices (MIT)\\nGolang questions (general Q&A) https://huggingface.co/datasets/ExAi/Code-Golang-QA-2k (Apache2)\\nGolang functions (code & description) https://huggingface.co/datasets/google/code_x_glue_ct_code_to_text (c-uda)\\nGolang snippets (code & description)… See the full description on the dataset page: https://huggingface.co/datasets/smcleod/golang-coder."},
	{"name":"CodeUpdateArena","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/leo-liuzy/CodeUpdateArena","creator_name":"Zeyu Leo Liu","creator_url":"https://huggingface.co/leo-liuzy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CodeUpdateArena\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CodeUpdateArena dataset, a benchmark for knowledge editing in the code domain. An instance in our benchmark consists of a synthetic API function update paired with a program synthesis example that uses the updated functionality.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe programming problems are written in Python and contain English natural text in comments and docstrings.… See the full description on the dataset page: https://huggingface.co/datasets/leo-liuzy/CodeUpdateArena."},
	{"name":"DarkWebSight","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Csplk/DarkWebSight","creator_name":"Ci Splunk","creator_url":"https://huggingface.co/Csplk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DarkWebSight\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nInspired by the HuggingFaceM4/WebSight and its glorius synthetic data generation methods prompts which compared to what I was expecting were amazingly simple! I wanted to test out their method on something similar for synthetic website code data generation ... Tor hidden services ... to reproduce their claim and it seems to be working!\\nDarkWebSight is a WIP that will be a large synthetic dataset containing… See the full description on the dataset page: https://huggingface.co/datasets/Csplk/DarkWebSight."},
	{"name":"svg-stack-labeled","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MrOvkill/svg-stack-labeled","creator_name":"Samuel L Meyers","creator_url":"https://huggingface.co/MrOvkill","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSvg Stack - Labeled\\n\\t\\n\\nThis dataset consists of the central storage for all datasets related to the SVG Stack dataset. I found it to be lovely, detailed, and of decent to extremely good quality upon observing many different icons and logos during the labeling process.\\nThis is the central dataset, and is currently UNDER CONSTRUCTION.  Use with caution, and be aware that the format HAS NOT been frozen. I will make a post announcing when I freeze this dataset, as that will also be the… See the full description on the dataset page: https://huggingface.co/datasets/MrOvkill/svg-stack-labeled."},
	{"name":"LogicStack-LeetCode","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/wiserxin/LogicStack-LeetCode","creator_name":"Sheen","creator_url":"https://huggingface.co/wiserxin","description":"extract from LogicStack-LeetCode\\n公众号「宫水三叶的刷题日记」刷穿 LeetCode 系列文章源码\\n包括 编程题目、解析、tag、题目url\\n根据 leetcode 原始题目网页，修正了一些 文件名 和 文件内容 中标注的难度不一致的文件样本\\n"},
	{"name":"ru-instruct","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/d0rj/ru-instruct","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tКарточка датасета\\n\\t\\n\\nСкомбинирован из нескольких популярных датасетов, переведённых автоматически. Отфильтрован на предмет артефактов перевода (спасибо модели Den4ikAI/nonsense_gibberish_detector). Дедуплицирован SimHash'ом.\\nОбученной на нём модели пока не завёз, in progress.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tСостав\\n\\t\\n\\nСобрал из этих переведённых:\\n\\nd0rj/OpenOrca-ru (от Open-Orca/OpenOrca)\\nd0rj/OpenHermes-2.5-ru (от teknium/OpenHermes-2.5)\\nd0rj/dolphin-ru (от ehartford/dolphin)\\nd0rj/alpaca-cleaned-ru (от… See the full description on the dataset page: https://huggingface.co/datasets/d0rj/ru-instruct."},
	{"name":"Web2Code","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MBZUAI/Web2Code","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nOur Web2Code instruction tuning dataset construction and instruction generation process involves four key components: (1) Creation of new webpage image-code pair data: We generated high-quality HTML webpage-code pairs following the CodeAlpaca prompt  using GPT-3.5 and convert them into instruction-following data. (2) Refinement of existing webpage code generation data: We transform existing datasets including into an instruction-following data format similar to… See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/Web2Code."},
	{"name":"opencores","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/LLM-EDA/opencores","creator_name":"LLM-EDA","creator_url":"https://huggingface.co/LLM-EDA","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opencores\\n\\t\\n\\nWe gathered high-quality specification-code pairs from Opencores, a community aimed to developing digital open-source hardware using electronic design automation (EDA). \\nWe then filtered out data instances exceeding 4096 characters in length and those that could not be parsed into Abstract Syntax Trees (AST). \\nThe final dataset comprises approximately 800 data instances.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Features\\n\\t\\n\\n\\ninstruction (string): The nature language… See the full description on the dataset page: https://huggingface.co/datasets/LLM-EDA/opencores."},
	{"name":"vgen_cpp","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/LLM-EDA/vgen_cpp","creator_name":"LLM-EDA","creator_url":"https://huggingface.co/LLM-EDA","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opencores\\n\\t\\n\\nIn the process of continual pre-training, we utilized the publicly available VGen dataset. \\nVGen aggregates Verilog repositories from GitHub, systematically filters out duplicates and excessively large files, and retains only those files containing \\\\texttt{module} and \\\\texttt{endmodule} statements. \\nWe also incorporated the CodeSearchNet dataset \\\\cite{codesearchnet}, which contains approximately 40MB function codes and their documentation.… See the full description on the dataset page: https://huggingface.co/datasets/LLM-EDA/vgen_cpp."},
	{"name":"pandora-big5","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jingjietan/pandora-big5","creator_name":"Tan Jing Jie","creator_url":"https://huggingface.co/jingjietan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPersonality Dataset\\n\\t\\n\\nEssays\\nhttps://huggingface.co/datasets/jingjietan/essays-big5\\nMBTI\\nhttps://huggingface.co/datasets/jingjietan/kaggle-mbti\\nPandora\\nhttps://huggingface.co/datasets/jingjietan/pandora-big5\\nPlease contact jingjietan.com for another dataset.\\nCite:\\n@software{jingjietan-apr-dataset,\\n  author = {Jing Jie, Tan},\\n  title = {{Personality Dataset Splitting}},\\n  url = {https://github.com/jingjie00/apr-dataset},\\n  version = {1.0.0},\\n  year = {2024}\\n}\\n"},
	{"name":"4-Security-Tools-Pentesting","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kuladeepmantri/4-Security-Tools-Pentesting","creator_name":"kuladeepmantri","creator_url":"https://huggingface.co/kuladeepmantri","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t4 Security Tools for Pentesting\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset is designed to aid in the detection and classification of commands associated with four essential security tools used in pentesting: Nmap, Metasploit, John the Ripper, and the Social Engineering Toolkit (SET). By providing a comprehensive collection of commands for each tool, this dataset aims to enhance the accuracy and effectiveness of models in recognizing and categorizing these commands.… See the full description on the dataset page: https://huggingface.co/datasets/kuladeepmantri/4-Security-Tools-Pentesting."},
	{"name":"MainframeBench","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Fsoft-AIC/MainframeBench","creator_name":"FPT Software AI Center","creator_url":"https://huggingface.co/Fsoft-AIC","description":"\\n  \\n\\n\\n\\n  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXMAiNframe: A Large Language Model for Mainframe Modernization\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset - MainframeBench - contains a comprehensive benchmark for assessing mainframe knowledge, including three sub-tasks: multiple-choice questions, question answering, and COBOL code summarization.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances for Question Answering\\n\\t\\n\\n{\\n    \\\"id\\\": 0,\\n    \\\"prompt\\\": \\\"As a supportive AI assistant, you've been presented… See the full description on the dataset page: https://huggingface.co/datasets/Fsoft-AIC/MainframeBench."},
	{"name":"MainframeBench","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Fsoft-AIC/MainframeBench","creator_name":"FPT Software AI Center","creator_url":"https://huggingface.co/Fsoft-AIC","description":"\\n  \\n\\n\\n\\n  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXMAiNframe: A Large Language Model for Mainframe Modernization\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset - MainframeBench - contains a comprehensive benchmark for assessing mainframe knowledge, including three sub-tasks: multiple-choice questions, question answering, and COBOL code summarization.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances for Question Answering\\n\\t\\n\\n{\\n    \\\"id\\\": 0,\\n    \\\"prompt\\\": \\\"As a supportive AI assistant, you've been presented… See the full description on the dataset page: https://huggingface.co/datasets/Fsoft-AIC/MainframeBench."},
	{"name":"zig-llama","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/cartersusi/zig-llama","creator_name":"Carter Susi","creator_url":"https://huggingface.co/cartersusi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZig LLama\\n\\t\\n\\nThis dataset is used to fine-tune meta-llama/Meta-Llama-3.1-8B-Instruct.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe dataset uses ~1100 of the most popular and recently updated Zig repos on GitHub.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\nThe full list of source repos used.\\nThe folder of source repos used.\\n"},
	{"name":"generate-readme-eval","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/patched-codes/generate-readme-eval","creator_name":"Patched","creator_url":"https://huggingface.co/patched-codes","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGenerate README Eval\\n\\t\\n\\nThe generate-readme-eval is a dataset (train split) and benchmark (test split) to evaluate the effectiveness of LLMs\\nwhen summarizing entire GitHub repos in form of a README.md file. The datset is curated from top 400 real Python repositories\\nfrom GitHub with at least 1000 stars and 100 forks. The script used to generate the dataset can be found here.\\nFor the dataset we restrict ourselves to GH repositories that are less than 100k tokens in size to allow us… See the full description on the dataset page: https://huggingface.co/datasets/patched-codes/generate-readme-eval."},
	{"name":"maplestory_captcha","keyword":"code","license":"Mozilla Public License 2.0","language":"en","url":"https://huggingface.co/datasets/lastbattle/maplestory_captcha","creator_name":"lastbattle","creator_url":"https://huggingface.co/lastbattle","description":"A huge collection of English MapleStory's captcha text in jpg that I have collected over the years. ENJOY!! \\nIt us used by pre-Big Bang MapleStory, throughout the game from Lie-Detector (anti-macro item), logins, to NPC conversations. \\nUp till version 190 when they have switched using Runes (Up, Down, Left, Right arrow keys) for most of the time for detection of macros and bots.\\nThese images are not labelled, I'm releasing this for anyone that wants the dataset to be able to train a model… See the full description on the dataset page: https://huggingface.co/datasets/lastbattle/maplestory_captcha."},
	{"name":"muri-it","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic… See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it."},
	{"name":"laravel-11-qa","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/yannelli/laravel-11-qa","creator_name":"Ryan Y","creator_url":"https://huggingface.co/yannelli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Laravel 11 Documentation Q&A\\n\\t\\n\\nThis dataset contains question-answer pairs derived from the Laravel 11 official documentation, designed for fine-tuning and evaluating language models on Laravel 11 knowledge.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Laravel 11 Documentation Q&A dataset is a collection of question-answer pairs generated from the official Laravel 11 documentation. It is intended to serve as a resource for testing… See the full description on the dataset page: https://huggingface.co/datasets/yannelli/laravel-11-qa."},
	{"name":"apigen-function-calling","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/argilla/apigen-function-calling","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card for argilla/apigen-function-calling\\n\\t\\n\\nThis dataset is a merge of argilla/Synth-APIGen-v0.1\\nand Salesforce/xlam-function-calling-60k, making\\nover 100K function calling examples following the APIGen recipe.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrepare for training\\n\\t\\n\\nThis version is not ready to do fine tuning, but you can run a script like prepare_for_sft.py\\nto prepare it, and run the same recipe that can be found in\\nargilla/Llama-3.2-1B-Instruct-APIGen-FC-v0.1#training-procedure.\\nModify the… See the full description on the dataset page: https://huggingface.co/datasets/argilla/apigen-function-calling."},
	{"name":"apigen-smollm-trl-FC","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/argilla-warehouse/apigen-smollm-trl-FC","creator_name":"Argilla Warehouse","creator_url":"https://huggingface.co/argilla-warehouse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card for argilla-warehouse/apigen-smollm-trl-FC\\n\\t\\n\\nThis dataset is a merge of argilla/Synth-APIGen-v0.1\\nand Salesforce/xlam-function-calling-60k, and was prepared for training using the script\\nprepare_for_sft.py that can be found in the repository files.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReferences\\n\\t\\n\\n@article{liu2024apigen,\\n  title={APIGen: Automated Pipeline for Generating Verifiable and Diverse Function-Calling Datasets},\\n  author={Liu, Zuxin and Hoang, Thai and Zhang, Jianguo and Zhu, Ming… See the full description on the dataset page: https://huggingface.co/datasets/argilla-warehouse/apigen-smollm-trl-FC."},
	{"name":"reflection-v1-ru_subset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/d0rj/reflection-v1-ru_subset","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\td0rj/reflection-v1-ru_subset\\n\\t\\n\\nTranslated glaiveai/reflection-v1 dataset into Russian language using GPT-4o.\\n\\nAlmost all the rows of the dataset have been translated. I have removed those translations that do not match the original by the presence of the tags \\\"thinking\\\", \\\"reflection\\\" and \\\"output\\\". Mapping to the original dataset rows can be taken from the \\\"index\\\" column.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\n\\n\\ndata = datasets.load_dataset(\\\"d0rj/reflection-v1-ru_subset\\\")… See the full description on the dataset page: https://huggingface.co/datasets/d0rj/reflection-v1-ru_subset."},
	{"name":"websim","keyword":"code","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/nyuuzyou/websim","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Websim.ai User Projects\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains information about 137,452 user projects from Websim.ai, a service for creating small sites from a description using Large Language Models (LLMs). The data is stored in JSONL format and includes details about each project, such as project metadata, user information, and the generated HTML content.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in English, as it contains project… See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/websim."},
	{"name":"Typst-Train","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/TechxGenus/Typst-Train","creator_name":"Hao Jiang","creator_url":"https://huggingface.co/TechxGenus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTypst-Train\\n\\t\\n\\n\\n[🤖Models] |\\n[🛠️Code] |\\n[📊Data] |\\n\\n\\n\\n\\nDataset used to train Typst-Coder, includes:\\n\\n18.6K Typst texts\\n2.5K Markdown texts containing Typst-related content\\n\\n"},
	{"name":"cData","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/motexture/cData","creator_name":"motexture","creator_url":"https://huggingface.co/motexture","description":"Synthetically created coding dataset using a feedback loop mechanism with various LLMs.\\n"},
	{"name":"DroidCall","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/mllmTeam/DroidCall","creator_name":"mllm","creator_url":"https://huggingface.co/mllmTeam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDroidCall: A Dataset for LLM-powered Android Intent Invocation\\n\\t\\n\\npaper|github\\nDroidCall is the first open-sourced, high-quality dataset designed for fine-tuning LLMs for accurate intent invocation on Android devices.\\nThis repo contains data generated by DroidCall. The process of data generation is shown in the figure below\\n\\nDetails can be found in our paper and github repository.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is Android Intent Invocation?\\n\\t\\n\\nAndroid Intent is a key machanism in Android that… See the full description on the dataset page: https://huggingface.co/datasets/mllmTeam/DroidCall."},
	{"name":"Dynamic-Topic-RedPajama-Data-1T-100k-SubSample-max-1k-tokens","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AmanPriyanshu/Dynamic-Topic-RedPajama-Data-1T-100k-SubSample-max-1k-tokens","creator_name":"Aman Priyanshu","creator_url":"https://huggingface.co/AmanPriyanshu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDynamic Topic Modeling Dataset: RedPajama-1T SubSample (100k samples, 1k tokens)\\n\\t\\n\\n\\n  📝Check out the Blog Post\\n\\n\\nThis dataset represents a curated subset of the RedPajama-1T Sample dataset, specifically processed for dynamic topic modeling applications. It contains 100,000 \\nsamples from the original dataset, with each document limited to the first 1,024 tokens for consistent processing.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\nName:… See the full description on the dataset page: https://huggingface.co/datasets/AmanPriyanshu/Dynamic-Topic-RedPajama-Data-1T-100k-SubSample-max-1k-tokens."},
	{"name":"RAG-v1-ruen","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/MexIvanov/RAG-v1-ruen","creator_name":"Mex Ivanov","creator_url":"https://huggingface.co/MexIvanov","description":"A version of the glaiveai/RAG-v1 dataset extended with machine translation to Russian language for multilingual retrieval-augmented generation tasks.\\nReleased under the same license as the original dataset, provided as is with research intent (but not limited), use/read at your own risk.\\n"},
	{"name":"mergekit-configs","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/mergekit-configs","creator_name":"Louis Brulé Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMergeKit-configs: access all Hub architectures and automate your model merging process\\n\\t\\n\\nThis dataset facilitates the search for compatible architectures for model merging with MergeKit, streamlining the automation of high-performance merge searches. It provides a snapshot of the Hub’s configuration state, eliminating the need to manually open configuration files.\\nimport polars as pl\\n\\n# Login using e.g. `huggingface-cli login` to access this dataset\\ndf =… See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/mergekit-configs."},
	{"name":"ru_codefeedback_python_Qwen2.5-Coder-32B-Instruct-GPTQ-Int8_sample","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/mizinovmv/ru_codefeedback_python_Qwen2.5-Coder-32B-Instruct-GPTQ-Int8_sample","creator_name":"maksim","creator_url":"https://huggingface.co/mizinovmv","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tru_Code-Feedback\\n\\t\\n\\nВопросы python Code-Feedback\\nРешение и unit-test с результатами python исполнения.\\nMade with Qwen2.5-Coder-32B-Instruct-GPTQ-Int8\\n\\n\\t\\n\\t\\t\\nru_eval_status\\ncount\\n\\n\\n\\t\\t\\nOK\\n2554\\n\\n\\nException\\n2337\\n\\n\\nSyntaxError\\n518\\n\\n\\nTimeout\\n79\\n\\n\\n\\t\\n\\n"},
	{"name":"TACO-verified","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/likaixin/TACO-verified","creator_name":"Kaixin Li","creator_url":"https://huggingface.co/likaixin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset contains verified solutions from the TACO dataset's training set. Solutions that fail to pass all the test cases are removed. Problems with no correct solution are also removed.\\nThe solutions were executed on Intel E5-2620 v3 CPUs with the execution timeout set to 10 seconds.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStatistics in the training set\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nDataset\\n# Problems\\n# Solutions\\n\\n\\n\\t\\t\\nTACO\\n25443\\n1468722\\n\\n\\nTACO-verified\\n12898\\n1043251\\n\\n\\nCorrect Ratio\\n50.69 %\\n71.03 %\\n\\n\\n\\t\\n\\n"},
	{"name":"nvlabs-verilogeval","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/dakies/nvlabs-verilogeval","creator_name":"Daniel Kiesewalter","creator_url":"https://huggingface.co/dakies","description":"VerilogEval Human dataset from the VerilogEval paper.\\nPaper: https://arxiv.org/abs/2309.07544 \\nRepo: https://github.com/NVlabs/verilog-eval?tab=License-1-ov-file).\\nDisclaimer: I am not the original author and uploaded this here only for convenience. Please refer to the original repo for any information.\\n"},
	{"name":"zeta","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zed-industries/zeta","creator_name":"Zed Industries","creator_url":"https://huggingface.co/zed-industries","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset for Zeta\\n\\t\\n\\nThis is the open dataset used to train Zeta, an edit prediction model that powers Zed's predictive coding feature. Zeta is derived from Qwen2.5-Coder-7B and predicts the developer's next code edit based on their recent programming patterns and cursor position, allowing for intelligent completion with a simple tab press.\\nThis dataset is split into three parts:\\n\\ntrain.jsonl: Contains the training data for supervised fine-tuning.\\ndpo.jsonl: Contains the data for the… See the full description on the dataset page: https://huggingface.co/datasets/zed-industries/zeta."},
	{"name":"CodeArena","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CSJianYang/CodeArena","creator_name":"Yang Jian","creator_url":"https://huggingface.co/CSJianYang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTo bridge the gap between the model-generated response and human preference, we present a rigorous human-curated benchmark CodeArena to emulate the complexity and diversity of real-world coding tasks, where 397 high-quality samples spanning 40 categories and 40 languages, carefully curated from user queries.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Example\\n\\t\\n\\nAn example of 'validation' looks as follows:\\n{\\n    \\\"id\\\": \\\"60670a8d9b1e39dd845fb1639d0d8b86\\\",\\n    \\\"messages\\\": \\\"[{'role': 'user'… See the full description on the dataset page: https://huggingface.co/datasets/CSJianYang/CodeArena."},
	{"name":"include-base-44","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/include-base-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-base (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-base-44."},
	{"name":"EUVS-Benchmark","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ai4ce/EUVS-Benchmark","creator_name":"ai4ce@nyu","creator_url":"https://huggingface.co/ai4ce","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDescription: \\n  This dataset comprises 104 urban scenes, featuring both extrapolated and interpolated camera poses.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nDataset_structure: \\n  For each scene, four main components are:\\n\\nimages: Images of each scene.\\nsparse: COLMAP format camera poses and sparse point clouds produced by SFM.\\ntraining_set.txt: Image names in the training set.\\ntest_set.txt: Image names in the test set.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\nSupported_tasks: \\n  The dataset… See the full description on the dataset page: https://huggingface.co/datasets/ai4ce/EUVS-Benchmark."},
	{"name":"include-lite-44","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/include-lite-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-lite (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-lite-44."},
	{"name":"CADBench","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/CADBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📚 CADBench\\n\\t\\n\\nCADBench is a comprehensive benchmark to evaluate the ability of LLMs to generate CAD scripts. It contains 500 simulated data samples and 200 data samples collected from online forums.\\nFor more details, please visit our GitHub repository or refer to our arXiv paper.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📖 Citation\\n\\t\\n\\n@misc{du2024blenderllmtraininglargelanguage,\\n      title={BlenderLLM: Training Large Language Models for Computer-Aided Design with Self-improvement}, \\n      author={Yuhao Du… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/CADBench."},
	{"name":"codecontests-textbooks-dp-v1","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bblain/codecontests-textbooks-dp-v1","creator_name":"Evgeniy Beliakin","creator_url":"https://huggingface.co/bblain","description":"This dataset is a synthetic collection designed for algorithmic problem-solving, particularly in the dynamic programming domain. It is inspired by problems from the DeepMind/code_contests dataset, ensuring authenticity and relevance to competitive programming and algorithmic challenges.\\nThe dataset includes detailed problem statements, input-output specifications, constraints, and illustrative test cases. Each example mirrors real-world scenarios, providing not only the problem but also… See the full description on the dataset page: https://huggingface.co/datasets/bblain/codecontests-textbooks-dp-v1."},
	{"name":"CodeRM-UnitTest","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/KAKA22/CodeRM-UnitTest","creator_name":"Zeyao Ma","creator_url":"https://huggingface.co/KAKA22","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCodeRM-UnitTest dataset originates from the paper: Dynamic Scaling of Unit Tests for Code Reward Modeling available on arXiv.\\nYou can visit the homepage to learn more about the paper.\\nIt is a curated collection of high-quality synthetic Python unit tests, derived from two prominent code instruction tuning \\ndatasets: CodeFeedback-Filtered-Instruction and the training \\nset of TACO. This dataset is used for training \\nCodeRM-8B, a small yet powerful unit test… See the full description on the dataset page: https://huggingface.co/datasets/KAKA22/CodeRM-UnitTest."},
	{"name":"CodeMathGen","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lFelix/CodeMathGen","creator_name":"Fan Liu","creator_url":"https://huggingface.co/lFelix","description":"lFelix/CodeMathGen dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CodeElo","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Qwen/CodeElo","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","description":"The evaluation problems in CodeElo benchmark proposed by CodeElo: Benchmarking Competition-level Code Generation of LLMs with Human-comparable Elo Ratings.\\ndescription, input, output, interaction and note are in Markdown format.\\ninput, output, interaction and note may be empty, and interaction is not empty if and only if it is an interactive problem.\\nA dedicated data explorer is available on our main page.\\n@article{codeelo,\\n  title={CodeElo: Benchmarking Competition-level Code Generation of… See the full description on the dataset page: https://huggingface.co/datasets/Qwen/CodeElo."},
	{"name":"OpenCoder-LLM_opc-sft-stage1-DolphinLabeled","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/cognitivecomputations/OpenCoder-LLM_opc-sft-stage1-DolphinLabeled","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenCoder-LLM SFT DolphinLabeled\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPart of the DolphinLabeled series of datasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPresented by Eric Hartford and Cognitive Computations\\n\\t\\n\\nThe purpose of this dataset is to enable filtering of OpenCoder-LLM SFT dataset.\\nThe original dataset is OpenCoder-LLM/opc-sft-stage1\\nI have modified the dataset using two scripts.\\n\\ndedupe.py - removes rows with identical instruction\\nlabel.py - adds a \\\"flags\\\" column containing the following boolean values:\\n\\\"refusal\\\":… See the full description on the dataset page: https://huggingface.co/datasets/cognitivecomputations/OpenCoder-LLM_opc-sft-stage1-DolphinLabeled."},
	{"name":"Tachibana-QVQ","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sequelbox/Tachibana-QVQ","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Tachibana-QVQ is a dataset containing code-reasoning and code-instruct responses across a wide variety of programming tasks.\\nThis dataset contains:\\n\\n103k prompts from sequelbox/Tachibana, with all responses generated by Qwen/QVQ-72B-Preview.\\nResponses demonstrate QVQ's code-reasoning ability and general code capabilities.\\n\\nResponses have not been filtered or edited at all: some responses will contain infinite thought loops, incomplete answers, inaccurate responses, or other identified or… See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Tachibana-QVQ."},
	{"name":"SWE-Fixer-Train-110K","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/internlm/SWE-Fixer-Train-110K","creator_name":"InternLM","creator_url":"https://huggingface.co/internlm","description":"\\n\\t\\n\\t\\t\\n\\t\\tSWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution\\n\\t\\n\\n\\n📃 Paper  |\\n 🚀 GitHub\\n\\n\\nSWE-Fixer is a simple yet effective solution for addressing real-world GitHub issues by training open-source LLMs. It features a streamlined retrieve-then-edit pipeline with two core components: a code file retriever and a code editor.\\nThis repo holds the data SWE-Fixer-Train-110K we curated for SWE-Fixer training.\\nFor more information, please visit our project page.… See the full description on the dataset page: https://huggingface.co/datasets/internlm/SWE-Fixer-Train-110K."},
	{"name":"advent_of_code_ecv_dataset","keyword":"code","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Supa-AI/advent_of_code_ecv_dataset","creator_name":"Supahands","creator_url":"https://huggingface.co/Supa-AI","description":"\\n\\t\\n\\t\\t\\n\\t\\tAdvent of Code ECV Dataset\\n\\t\\n\\nMany code generation datasets focus on syntax and structure but lack a strong emphasis on contextual understanding, especially from a storytelling perspective.The Advent of Code ECV (Expanded, Curated, Verified) Dataset addresses this gap by curating and verifying multiple approaches for each challenge from 2024 to provide diverse solutions, comparison of strategies, and better adaptability across different programming paradigms.In addition to training and… See the full description on the dataset page: https://huggingface.co/datasets/Supa-AI/advent_of_code_ecv_dataset."},
	{"name":"bird-critic-1.0-flash-exp","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/birdsql/bird-critic-1.0-flash-exp","creator_name":"The BIRD Team","creator_url":"https://huggingface.co/birdsql","description":"\\n\\t\\n\\t\\t\\n\\t\\tBIRD-CRITIC-1.0-Flash\\n\\t\\n\\nBIRD-Critic is the first SQL debugging benchmark designed to answer a critical question:\\nCan large language models (LLMs) fix user issues in real-world database applications? Each task in BIRD-CRITIC has been verified by human experts on the following dimensions:\\n\\nReproduction of errors on BIRD env to prevent data leakage.\\nCarefully curate test case functions for each task specifically. \\nSoft EX: This metric can evaluate SELECT-ONLY tasks.\\nSoft EX + Parsing:… See the full description on the dataset page: https://huggingface.co/datasets/birdsql/bird-critic-1.0-flash-exp."},
	{"name":"Math-Question-Answer","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Aixr/Math-Question-Answer","creator_name":"Aixr AI","creator_url":"https://huggingface.co/Aixr","description":"Aixr/Math-Question-Answer dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"lots_of_datasets_for_ai_v3","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ReallyFloppyPenguin/lots_of_datasets_for_ai_v3","creator_name":"Gurvaah Singh","creator_url":"https://huggingface.co/ReallyFloppyPenguin","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset is for Training LLMs From Scratch!\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More Information Needed]\\nDemo… See the full description on the dataset page: https://huggingface.co/datasets/ReallyFloppyPenguin/lots_of_datasets_for_ai_v3."},
	{"name":"short_COT_48k","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FrankL/short_COT_48k","creator_name":"FrankLiu","creator_url":"https://huggingface.co/FrankL","description":"FrankL/short_COT_48k dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Kotlin_QA","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/JetBrains/Kotlin_QA","creator_name":"JetBrains","creator_url":"https://huggingface.co/JetBrains","description":"\\n\\t\\n\\t\\t\\n\\t\\tKotlin QA\\n\\t\\n\\nA collection of 47 open-ended questions and answers focused on idiomatic Kotlin, curated by human experts. Approximately half were sourced from Kotlin advocates, while the others were real questions gathered from the Kotlin Slack community.Utilized in the Kotlin QA Benchmark within the Code Modeling Lab.  \\nLicense: Apache 2.0  \\n"},
	{"name":"reason_at_code","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/XvKuoMing/reason_at_code","creator_name":"Kamil","creator_url":"https://huggingface.co/XvKuoMing","description":"\\n\\t\\n\\t\\t\\n\\t\\tReasoning Dataset for Code\\n\\t\\n\\nThis repository contains a curated reasoning dataset specifically designed for coding-related problems, particularly in Python. \\nThe dataset was created by filtering non-code problems from the original NovaSky-AI/Sky-T1_data_17k dataset. \\nThe goal of this dataset is to facilitate fine-tuning models for reasoning tasks related to code understanding, problem-solving, and logical deduction in programming.\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe dataset emphasizes… See the full description on the dataset page: https://huggingface.co/datasets/XvKuoMing/reason_at_code."},
	{"name":"numinamath_verifiable_cleaned","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/flatlander1024/numinamath_verifiable_cleaned","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Adapt from https://huggingface.co/datasets/AI-MO/NuminaMath-CoT and filtered problems with verifiable answers.\\nRemoved duplicates and decontaminated from test datasets.\\nTotal number of rows: 678759\\n"},
	{"name":"NLP2SQL","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ByteMaster01/NLP2SQL","creator_name":"Laksh Mendpara","creator_url":"https://huggingface.co/ByteMaster01","description":"\\n\\t\\n\\t\\t\\n\\t\\tNLP-to-SQL Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is designed to assist in building and evaluating NLP-to-SQL models. It provides natural language queries, corresponding SQL queries, and the schema for the tables referenced, offering a comprehensive framework for understanding and generating SQL queries from plain language.\\n\\n\\t\\n\\t\\t\\n\\t\\tSchema Example\\n\\t\\n\\nBelow is an example of the schema included in the dataset:\\n\\n\\t\\n\\t\\t\\n\\t\\tTable: employee_1001\\n\\t\\n\\nCREATE TABLE employee_1001 (… See the full description on the dataset page: https://huggingface.co/datasets/ByteMaster01/NLP2SQL."},
	{"name":"System-Response-100K","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/prithivMLmods/System-Response-100K","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tSystem-Response-100K dataset\\n\\t\\n\\nThis dataset contains text and code for machine learning tasks including:\\n\\nText Generation\\nText Classification\\nSummarization\\nQuestion Answering\\n\\nThe dataset includes text formatted in JSON and is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\nNumber of entries: Not specified in the information you provided.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tModalities\\n\\t\\n\\n\\nText\\nCode\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFormats\\n\\t\\n\\n\\nJSON\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nEnglish\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tGetting Started\\n\\t\\n\\nThis section can include… See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/System-Response-100K."},
	{"name":"LeetCode-Contest","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lbaf23/LeetCode-Contest","creator_name":"lbaf23","creator_url":"https://huggingface.co/lbaf23","description":"\\n\\t\\n\\t\\t\\n\\t\\tLeetCode-Contest\\n\\t\\n\\nContains 80 questions of LeetCode weekly and bi-weekly contests released after March 2024.\\nEach question contains an average of 644 test cases, as well as programming solutions in Python language collected from the official LeetCode website.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Fields\\n\\t\\n\\n\\nindex: The problem numbers in the dataset, from 0 to 79.  \\ntitle: The title of the problem.\\ntitle_slug: The title name connected by \\\"_\\\".   \\nquestion_id: The problem id.… See the full description on the dataset page: https://huggingface.co/datasets/lbaf23/LeetCode-Contest."},
	{"name":"AceCode-87K","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/TIGER-Lab/AceCode-87K","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\t🂡 AceCode-87K\\n\\t\\n\\nPaper | \\nGithub |\\nAceCode-87K |\\nAceCodePair-300K |\\nRM/RL Models\\nWe introduce AceCoder, the first work to propose a fully automated pipeline for synthesizing large-scale reliable tests used for the reward model training and reinforcement learning in the coding scenario. To do this, we curated the dataset AceCode-87K, where we start from a seed code dataset and prompt powerful LLMs to \\\"imagine\\\" proper test cases for the coding question and filter the noisy ones. We… See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/AceCode-87K."},
	{"name":"unreal-engine-5-code-split","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/olympusmonsgames/unreal-engine-5-code-split","creator_name":"Olympus Mons Games","creator_url":"https://huggingface.co/olympusmonsgames","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for unreal-engine-5-code-split\\n\\t\\n\\nUsing the unreal-engine-5-code hf dataset by AdamCodd, I split the data into smaller chunks for RAG systems\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBranches\\nmain: \\n\\nDataset is split/chunked by engine module (no max chunk size)\\n\\nchunked-8k:\\n\\nData is first split by module {module_name}.jsonl if ≤ 8000 tokens. \\nIf a module is ≥ 8000 tokens then it's further split by header name {module_name}_{header_name}.jsonl\\nIf a header… See the full description on the dataset page: https://huggingface.co/datasets/olympusmonsgames/unreal-engine-5-code-split."},
	{"name":"SymBench","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/yongchao98/SymBench","creator_name":"Yongchao Chen","creator_url":"https://huggingface.co/yongchao98","description":"\\n\\t\\n\\t\\t\\n\\t\\tCodeSteer: Symbolic-Augmented Language Models via Code/Text Guidance\\n\\t\\n\\n\\nSymBench comprises 37 symbolic tasks related to the following papers. The specific description of each task is in page 16-19 of the paper'CodeSteer: Symbolic-Augmented Language Models via Code/Text Guidance'. This dataset comprises the dataset for finetuning CodeSteerLLM with SFT and DPO datasets, the SymBench with 37 tested tasks, the code scripts to synthesize the SymBench samples.\\n\\n\\nCodeSteer:… See the full description on the dataset page: https://huggingface.co/datasets/yongchao98/SymBench."},
	{"name":"Code_Vulnerability_Labeled_Dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lemon42-ai/Code_Vulnerability_Labeled_Dataset","creator_name":"lemon42-ai","creator_url":"https://huggingface.co/lemon42-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Code_Vulnerability_Labeled_Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset provides (code, vulnerability) pairs. The vulnerability field takes values according to the CWE annotation:\\n\\n\\t\\n\\t\\t\\nCWE\\nDescription\\n\\n\\n\\t\\t\\nCWE-020\\nImproper Input Validation\\n\\n\\nCWE-022\\nImproper Limitation of a Pathname to a Restricted Directory (“Path Traversal”)\\n\\n\\nCWE-078\\nImproper Neutralization of Special Elements used in an OS Command (“OS Command Injection”)\\n\\n\\nCWE-079\\nImproper Neutralization of… See the full description on the dataset page: https://huggingface.co/datasets/lemon42-ai/Code_Vulnerability_Labeled_Dataset."},
	{"name":"code-alpaca-20k","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/flwrlabs/code-alpaca-20k","creator_name":"Flower Labs","creator_url":"https://huggingface.co/flwrlabs","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThis dataset originates from the Code Alpaca repository.\\nThe CodeAlpaca 20K dataset is specifically used for training code generation models.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEach sample is comprised of three columns: instruction, input and output. \\n\\nLanguage(s): English\\nLicense: Apache-2.0 License\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\nThe code from the original repository was adopted to post it here. \\n\\nRepository:… See the full description on the dataset page: https://huggingface.co/datasets/flwrlabs/code-alpaca-20k."},
	{"name":"Caption-Anything-InContext","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/prithivMLmods/Caption-Anything-InContext","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"Caption-Anything-InContext is a dataset curated using the model Caption-Pro for improved in-context captioning of images. This model is designed for generating multiple captions for images, ensuring they are contextually accurate.\\n\\n\\t\\n\\t\\t\\n\\t\\tRequired Lib\\n\\t\\n\\n!pip install -q transformers qwen-vl-utils==0.0.2\\n\\nDemo with transformers\\nimport os\\nimport gdown\\nimport torch\\nfrom transformers import Qwen2VLForConditionalGeneration, AutoProcessor\\nfrom qwen_vl_utils import process_vision_info\\nfrom PIL import… See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Caption-Anything-InContext."},
	{"name":"BaxBench","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/LogicStar/BaxBench","creator_name":"LogicStar.ai","creator_url":"https://huggingface.co/LogicStar","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBaxBench is a coding benchmark constructed to measure the ability of code generation models and agents to generate correct and secure code. It consists of 392 backend development tasks, which are constructed by combining 28 scenarios that describe the backend functionalities to implement and 14 backend frameworks defining the implementation tools. To assess the correctness and security of the solutions, the benchmark uses end-to-end functional tests and practical… See the full description on the dataset page: https://huggingface.co/datasets/LogicStar/BaxBench."},
	{"name":"minified-diverseful-multilabels","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lemon42-ai/minified-diverseful-multilabels","creator_name":"lemon42-ai","creator_url":"https://huggingface.co/lemon42-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\tA minified, clean and annotated version of DiverseVul\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a minified, clean and deduplicated version of the DiverseVul dataset. \\nWe publish this version to help practionners in their code vulnerability detection research. \\n\\n\\t\\n\\t\\t\\n\\t\\tData Structure & Overview\\n\\t\\n\\n\\nNumber of samples: 23847\\nFeatures: func (the C/C++ code)cwe (the CWE weakness, see table below)\\nSupported Programming Languages: C/C++\\nSupported CWE Weaknesses:\\n\\t\\n\\t\\t\\nLabel\\nDescription… See the full description on the dataset page: https://huggingface.co/datasets/lemon42-ai/minified-diverseful-multilabels."},
	{"name":"function-calling-reasoning-v1","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zzzch/function-calling-reasoning-v1","creator_name":"Zhangchuanhui","creator_url":"https://huggingface.co/zzzch","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nFunction calling dataset with reasoning, derived from the locally deployed DeepSeek-R1 671B(deepseek-ai/DeepSeek-R1), with the data source being Salesforce/xlam-function-calling-60k.\\n"},
	{"name":"DeepSeek-R1-Distill","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/tuanha1305/DeepSeek-R1-Distill","creator_name":"Hà Anh Tuấn","creator_url":"https://huggingface.co/tuanha1305","description":"tuanha1305/DeepSeek-R1-Distill dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"llm-cross-grade","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/av-codes/llm-cross-grade","creator_name":"Ivan Charapanau","creator_url":"https://huggingface.co/av-codes","description":"av-codes/llm-cross-grade dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"yanomami","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/renanserrano/yanomami","creator_name":"Renan Serrano","creator_url":"https://huggingface.co/renanserrano","description":"\\n\\t\\n\\t\\t\\n\\t\\tYanomami Language Dataset\\n\\t\\n\\nThis dataset contains Yanomami language data for training translation models between Yanomami and English. The Yanomami language is spoken by indigenous people in northern Brazil and southern Venezuela.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe dataset consists of the following files:\\n\\n\\t\\n\\t\\t\\nFile\\nDescription\\nExamples\\n\\n\\n\\t\\t\\ntranslations.jsonl\\nGeneral translations between Yanomami and English\\n17,009\\n\\n\\nyanomami-to-english.jsonl\\nSpecific Yanomami to English translations\\n1… See the full description on the dataset page: https://huggingface.co/datasets/renanserrano/yanomami."},
	{"name":"InductionBench","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/wenyueH/InductionBench","creator_name":"Wenyue Hua","creator_url":"https://huggingface.co/wenyueH","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nInductionBench is a new benchmarking suite designed to test the inductive reasoning abilities of large language models.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe benchmark is grounded in formal definitions of inductive function classes (e.g., regular functions/transducers, subregular hierarchies like input-strictly-local functions, Left-output-strictly-local functions, and Right-output-strictly-local functions).\\nThese classes have… See the full description on the dataset page: https://huggingface.co/datasets/wenyueH/InductionBench."},
	{"name":"Stratos-3k-3.7Sonnet","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/davidbai/Stratos-3k-3.7Sonnet","creator_name":"David Bai","creator_url":"https://huggingface.co/davidbai","description":"\\n\\t\\n\\t\\t\\n\\t\\tStratos-3K-3.7Sonnet\\n\\t\\n\\nThis is a dataset of 3,155 questions sampled from Bespoke-Stratos-17k,\\nanswered with Claude 3.7 Sonnet on Thinking mode, at temperature 1.0 with maximum thinking tokens at 64,000 (the API limit), and max output length.\\nI would like to acknowledge Bespoke Labs and Berkeley Sky Lab, for their question dataset, as well as Anthropic for providing open-sourced thinking tokens.\\nIf this dataset's publication violates any lab or company policies, please reach out to me… See the full description on the dataset page: https://huggingface.co/datasets/davidbai/Stratos-3k-3.7Sonnet."},
	{"name":"gretel-synthetic-text-to-sql","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/philschmid/gretel-synthetic-text-to-sql","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\t\\n\\t\\t\\n\\t\\tFork of gretelai/synthetic_text_to_sql\\n\\t\\n\\nThe gretelai/synthetic_text_to_sql dataset is a large, Apache 2.0 licensed, synthetic Text-to-SQL dataset consisting of 105,851 high-quality records across 100 diverse domains, designed for training language models. It includes comprehensive SQL tasks with varying complexities, database contexts, natural language explanations, and contextual tags, outperforming existing datasets in SQL correctness and standards compliance.\\n"},
	{"name":"Eastern-Alpaca-14k","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/XeTute/Eastern-Alpaca-14k","creator_name":"XeTute Technologies","creator_url":"https://huggingface.co/XeTute","description":"\\nEastern Alpaca 14k\\n\\n🚀 Let's enhance ourself with something different\\n\\n\\n\\n\\n  \\n    \\n  \\n  \\n    \\n  \\n  \\n    \\n    \\n  \\n\\n\\n\\n\\n\\nThis dataset is synthetically generated using XeTute/Synthetic-Data-Generation\\n\\nWe publish 14 * 1024 samples synthetically generated through both reasoning and traditional models licensed accordingly.Topics in these samples may include:\\n\\nReligion: Christianity, Islam\\nLiterature: Story-Generation, Summarization, Continuation, et cetera\\nGeneric Questions: STEM and related… See the full description on the dataset page: https://huggingface.co/datasets/XeTute/Eastern-Alpaca-14k."},
	{"name":"kolmogorov-3","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/attn-signs/kolmogorov-3","creator_name":"Attention Signs","creator_url":"https://huggingface.co/attn-signs","description":"\\n\\t\\n\\t\\t\\n\\t\\tKolmogorov-3\\n\\t\\n\\nCarefully selected, checked and formatted PhD-level russian math instruction dataset.Contains olympiad/university/science-level tasks from various sources.\\n\\n\\t\\n\\t\\t\\n\\t\\tContents:\\n\\t\\n\\nMathematics\\n\\nPre-algebra\\nPre-calculus\\nCalculus\\nAlgebra\\nNumber theory\\nGeometry\\nProbability theory\\nSet theory\\nMathematical proofs\\n\\nCode\\n\\nCode-to-math problems\\nAlgorithms\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFormats:\\n\\t\\n\\nDataset is formatted in conversation manner, can be also used for GRPO problem-answer training\\n"},
	{"name":"shellcode_i_a32","keyword":"code","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/SoLID/shellcode_i_a32","creator_name":"SoLID - UNC Charlotte","creator_url":"https://huggingface.co/SoLID","description":"Shellcode_IA32 is a dataset for shellcode generation from English intents. The shellcodes are compilable on Intel Architecture 32-bits."},
	{"name":"ManyTypes4TypeScript","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/kevinjesse/ManyTypes4TypeScript","creator_name":"Kevin Jesse","creator_url":"https://huggingface.co/kevinjesse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModels Trained On ManyTypes4TypeScript\\n\\t\\n\\n\\n[CodeBERT](https://huggingface.co/kevinjesse/codebert-MT4TS)\\n[GraphCodeBERT](https://huggingface.co/kevinjesse/graphcodebert-MT4TS)\\n[CodeBERTa](https://huggingface.co/kevinjesse/codeberta-MT4TS)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nManyTypes4TypeScript type inference dataset, available at the DOI link below. \\nGiven a line of source code, the task is to identify types that correspond with the tokens of code. We treat this as a tagging task… See the full description on the dataset page: https://huggingface.co/datasets/kevinjesse/ManyTypes4TypeScript."},
	{"name":"xP3all","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot."},
	{"name":"codequeries","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/thepurpleowl/codequeries","creator_name":"Surya Prakash Sahu","creator_url":"https://huggingface.co/thepurpleowl","description":"CodeQueries Ideal setup."},
	{"name":"xP3mt","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot."},
	{"name":"humaneval_infilling","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/loubnabnl/humaneval_infilling","creator_name":"Loubna Ben Allal","creator_url":"https://huggingface.co/loubnabnl","description":"An evaluation benchamrk for infilling tasks on HumanEval dataset for code generation."},
	{"name":"standard_humaneval","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/diversoailab/standard_humaneval","creator_name":"Diverso AI Lab","creator_url":"https://huggingface.co/diversoailab","description":"diversoailab/standard_humaneval dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"PyCoder","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Wannita/PyCoder","creator_name":"Takerngsaksiri","creator_url":"https://huggingface.co/Wannita","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPyCoder\\n\\t\\n\\nThis repository contains the dataset for the paper Syntax-Aware On-the-Fly Code Completion\\nThe sample code to run the model can be found in directory: \\\"assets/notebooks/inference.ipynb\\\" in our GitHub: https://github.com/awsm-research/pycoder.\\nPyCoder is an auto code completion model which leverages a Multi-Task Training technique (MTT) to cooperatively\\nlearn the code prediction task and the type prediction task. For the type prediction\\ntask, we propose to leverage the… See the full description on the dataset page: https://huggingface.co/datasets/Wannita/PyCoder."},
	{"name":"docprompting-conala","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/neulab/docprompting-conala","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"This is the re-split of CoNaLa dataset. For each code snippet in the dev and test set, at least one function is held out from the training set. This split aims at testing a code generation model's capacity in generating unseen functions.\\nWe further make sure that examples from the same StackOverflow post (same question_id before -) are in the same split."},
	{"name":"nameToStdName","keyword":"code","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/mble/nameToStdName","creator_name":"Maciej Błędkowski","creator_url":"https://huggingface.co/mble","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tnameToStdName for Minecraft plugins from SpigotMC and Bukkit\\n\\t\\n\\nFrom Spigot/Bukkit plugin titles and description, extract plugin names.\\nMain repository: https://github.com/pluget/services\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense (SPDX)\\n\\t\\n\\nGPL-3.0 for code\\nODbL-1.0 for data/models\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCreators\\n\\t\\n\\nMaciej Błędkowski - Founder, Lead Developer\\n"},
	{"name":"humaneval-rust","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/diversoailab/humaneval-rust","creator_name":"Diverso AI Lab","creator_url":"https://huggingface.co/diversoailab","description":"diversoailab/humaneval-rust dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"energy_induction_motor_simulation","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Thi-Thu-Huong/energy_induction_motor_simulation","creator_name":"Le","creator_url":"https://huggingface.co/Thi-Thu-Huong","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for energy_induction_motor_simulation\\n\\t\\n\\n\\nThis dataset is simulated for four electrical motors using simulation modeling in MATLAB.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nAccurately forecasting electrical signals from three-phase Direct Torque Control (DTC) induction motors is crucial for achieving optimal motor performance and effective condition monitoring. However, the intricate nature of multiple DTC induction motors and the variability in operational conditions present… See the full description on the dataset page: https://huggingface.co/datasets/Thi-Thu-Huong/energy_induction_motor_simulation."},
	{"name":"MagicPrompt_SD_Washed","keyword":"code","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/KonghaYao/MagicPrompt_SD_Washed","creator_name":"KonghaYao","creator_url":"https://huggingface.co/KonghaYao","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMagicPrompt_SD_Washed\\n\\t\\n\\nIt's a version of datasets of Gustavosta/MagicPrompt-Stable-Diffusion.\\nWhen I want to train a model using origin data, some bad prompts broke model and waste many time. \\nSo I washed the origin datasets: \\n\\n😄 delete some meanless words like some artists name with misspelling\\n😂 delete many spaces that make 100mm to 10 0m\\n😭 some url in datasets\\n😭 and many unknown words\\n\\nAnd this version is doing well in my train test!😍\\n"},
	{"name":"torch-forum","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/foldl/torch-forum","creator_name":"Egor Konovalov","creator_url":"https://huggingface.co/foldl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"torch-forum\\\"\\n\\t\\n\\nDataset structure\\n{\\n    title:str\\n    category:str,\\n    posts:List[{\\n                poster:str,\\n                contents:str,\\n                likes:int,\\n                isAccepted:bool\\n               }]\\n}\\n\\n"},
	{"name":"wesnoth-ethea-canon-campaigns","keyword":"code","license":"GNU General Public License v2.0","language":"en","url":"https://huggingface.co/datasets/kabachuha/wesnoth-ethea-canon-campaigns","creator_name":"Artem","creator_url":"https://huggingface.co/kabachuha","description":"kabachuha/wesnoth-ethea-canon-campaigns dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Dementia_Dataset","keyword":"code","license":"Educational Community License v2.0","language":"en","url":"https://huggingface.co/datasets/RiniPL/Dementia_Dataset","creator_name":"Rini P L","creator_url":"https://huggingface.co/RiniPL","description":"RiniPL/Dementia_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"functional_code","keyword":"code","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/dhuck/functional_code","creator_name":"davin lawrence","creator_url":"https://huggingface.co/dhuck","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCollection of functional programming languages from GitHub.\\n\\nPoint of Contact: dhuck\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a collection of code examples of functional programming languages for code generation tasks. It was collected over a week long period in March 2023 as part of project in program synthesis.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n{\\n  'id': str\\n  'repository': str… See the full description on the dataset page: https://huggingface.co/datasets/dhuck/functional_code."},
	{"name":"staqc","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/koutch/staqc","creator_name":"Charles Koutcheme","creator_url":"https://huggingface.co/koutch","description":"StaQC (Stack Overflow Question-Code pairs) is a dataset of around 148K Python and 120K SQL domain question-code pairs, \\nwhich are automatically mined from Stack Overflow using a Bi-View Hierarchical Neural Network, \\nas described in the paper \\\"StaQC: A Systematically Mined Question-Code Dataset from Stack Overflow\\\" (WWW'18)."},
	{"name":"JuICe","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/koutch/JuICe","creator_name":"Charles Koutcheme","creator_url":"https://huggingface.co/koutch","description":"JuICe, a corpus of 1.5 million examples with a curated test set of 3.7K instances based on online programming assignments."},
	{"name":"PyCoder-Type","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Wannita/PyCoder-Type","creator_name":"Takerngsaksiri","creator_url":"https://huggingface.co/Wannita","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPyCoder\\n\\t\\n\\nThis repository contains the dataset for the paper Syntax-Aware On-the-Fly Code Completion\\nThe sample code to run the model can be found in directory: \\\"assets/notebooks/inference.ipynb\\\" in our GitHub: https://github.com/awsm-research/pycoder.\\nPyCoder is an auto code completion model which leverages a Multi-Task Training technique (MTT) to cooperatively\\nlearn the code prediction task and the type prediction task. For the type prediction\\ntask, we propose to leverage the… See the full description on the dataset page: https://huggingface.co/datasets/Wannita/PyCoder-Type."},
	{"name":"cve-single-line-fixes","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lambdasec/cve-single-line-fixes","creator_name":"Lambda Security","creator_url":"https://huggingface.co/lambdasec","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information… See the full description on the dataset page: https://huggingface.co/datasets/lambdasec/cve-single-line-fixes."},
	{"name":"cve-single-line-fixes","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lambdasec/cve-single-line-fixes","creator_name":"Lambda Security","creator_url":"https://huggingface.co/lambdasec","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information… See the full description on the dataset page: https://huggingface.co/datasets/lambdasec/cve-single-line-fixes."},
	{"name":"gh-top-1000-projects-vulns","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lambdasec/gh-top-1000-projects-vulns","creator_name":"Lambda Security","creator_url":"https://huggingface.co/lambdasec","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information… See the full description on the dataset page: https://huggingface.co/datasets/lambdasec/gh-top-1000-projects-vulns."},
	{"name":"gh-top-1000-projects-vulns","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lambdasec/gh-top-1000-projects-vulns","creator_name":"Lambda Security","creator_url":"https://huggingface.co/lambdasec","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information… See the full description on the dataset page: https://huggingface.co/datasets/lambdasec/gh-top-1000-projects-vulns."},
	{"name":"applescript-lines-100k-non-annotated","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/HelloImSteven/applescript-lines-100k-non-annotated","creator_name":"Stephen Kaplan","creator_url":"https://huggingface.co/HelloImSteven","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"applescript-lines-100k-non-annotated\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset of 100,000 unique lines of AppleScript code scraped from GitHub and GitHub Gists. The dataset has been de-duplicated, comments have been removed (both single and multi-line), and effort has been made to merge multi-line structures such as records into one (however, expect some variability in this regard).\\nThe dataset is constructed as an intermediate step to a fully-annotated AppleScript… See the full description on the dataset page: https://huggingface.co/datasets/HelloImSteven/applescript-lines-100k-non-annotated."},
	{"name":"cv_backbones","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/monetjoe/cv_backbones","creator_name":"Monet","creator_url":"https://huggingface.co/monetjoe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"monetjoe/cv_backbones\\\"\\n\\t\\n\\nThis repository consolidates the collection of backbone networks for pre-trained computer vision models available on the PyTorch official website. It mainly includes various Convolutional Neural Networks (CNNs) and Vision Transformer models pre-trained on the ImageNet1K dataset. The entire collection is divided into two subsets, V1 and V2, encompassing multiple classic and advanced versions of visual models. These pre-trained backbone… See the full description on the dataset page: https://huggingface.co/datasets/monetjoe/cv_backbones."},
	{"name":"OFF_HATE_TOXIC_ENGLISH","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/christinacdl/OFF_HATE_TOXIC_ENGLISH","creator_name":"Christina Christodoulou","creator_url":"https://huggingface.co/christinacdl","description":"100.772 texts with their corresponding labels\\nNOT_OFF_HATEFUL_TOXIC    81.359 values\\nOFF_HATEFUL_TOXIC        19.413 values\\n"},
	{"name":"applescript-lines-annotated","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/HelloImSteven/applescript-lines-annotated","creator_name":"Stephen Kaplan","creator_url":"https://huggingface.co/HelloImSteven","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"applescript-lines-annotated\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis is a dataset of single lines of AppleScript code scraped from GitHub and GitHub Gist and manually annotated with descriptions, intents, prompts, and other metadata.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContent\\n\\t\\n\\nEach row contains 8 features:\\n\\ntext - The raw text of the AppleScript code.\\nsource - The name of the file from which the line originates.\\ntype - Either compiled (files using the .scpt extension) or uncompiled… See the full description on the dataset page: https://huggingface.co/datasets/HelloImSteven/applescript-lines-annotated."},
	{"name":"sql-create-context-copy","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/philschmid/sql-create-context-copy","creator_name":"Philipp Schmid","creator_url":"https://huggingface.co/philschmid","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFork of b-mc2/sql-create-context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted… See the full description on the dataset page: https://huggingface.co/datasets/philschmid/sql-create-context-copy."},
	{"name":"binary_hate_speech","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/christinacdl/binary_hate_speech","creator_name":"Christina Christodoulou","creator_url":"https://huggingface.co/christinacdl","description":"christinacdl/binary_hate_speech dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"dolly-code-migration","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/robert-altmiller/dolly-code-migration","creator_name":"Robert Altmiller","creator_url":"https://huggingface.co/robert-altmiller","description":"robert-altmiller/dolly-code-migration dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"code-search-net-java","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-java","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-java\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Java portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset's comments are in English and the functions are coded in Java\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain, test, validation labels are… See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-java."},
	{"name":"code-search-net-go","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-go","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-go\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Go portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset's comments are in English and the functions are coded in Go\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain, test, validation labels are included in… See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-go."},
	{"name":"code-search-net-python","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-python","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-python\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nHomepage: None\\nRepository: https://huggingface.co/datasets/Nan-Do/code-search-net-python\\nPaper: None\\nLeaderboard: None\\nPoint of Contact: @Nan-Do\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Python portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what… See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-python."},
	{"name":"code-search-net-php","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-php","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-php\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Php portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset's comments are in English and the functions are coded in Php\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain, test, validation labels are included… See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-php."},
	{"name":"code-search-net-ruby","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Nan-Do/code-search-net-ruby","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code-search-net-ruby\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the Ruby portion of the CodeSarchNet annotated with a summary column.The code-search-net dataset includes open source functions that include comments found at GitHub.The summary is a short description of what the function does.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset's comments are in English and the functions are coded in Ruby\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain, test, validation labels are… See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/code-search-net-ruby."},
	{"name":"gpt-expressions","keyword":"code","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/Haziqsayyed/gpt-expressions","creator_name":"Haazique Sayyed","creator_url":"https://huggingface.co/Haziqsayyed","description":"Haziqsayyed/gpt-expressions dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"es2bash","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dev2bit/es2bash","creator_name":"dev2bit","creator_url":"https://huggingface.co/dev2bit","description":"This dataset consisting of natural language requests (in Spanish) and the bash command that resolves it."},
	{"name":"algorithmic-reasoning-seed","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lemonteaa/algorithmic-reasoning-seed","creator_name":"Tom","creator_url":"https://huggingface.co/lemonteaa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Algorithmic Reasoning (seed)\\n\\t\\n\\nNote: This dataset is WIP and most question's answer section is empty or incomplete! See also \\\"Other Known Limitations\\\" section\\nWarning: If you somehow do use this dataset, remember to NOT do any eval after training on the questions in this dataset!\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDataset to help LLM learn how to reason about code, especially on algorithmic tasks, by seeing human demostration.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and… See the full description on the dataset page: https://huggingface.co/datasets/lemonteaa/algorithmic-reasoning-seed."},
	{"name":"openllm-manual-eval-code","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lemonteaa/openllm-manual-eval-code","creator_name":"Tom","creator_url":"https://huggingface.co/lemonteaa","description":"Sample conversations with vicuna-13b-fp16-v1.0 , focusing on coding ability tests. (Note that vicuna-13b have a v1.1 released and it improved on some coding tasks)\\nProbably not going to make more like this as creating JSON file by hand (copy-pasting from my note app) is exceedingly slow.\\n"},
	{"name":"Dataset-Goldbach-1.0","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ZoabiTalal/Dataset-Goldbach-1.0","creator_name":"Talal Zoabi","creator_url":"https://huggingface.co/ZoabiTalal","description":"ZoabiTalal/Dataset-Goldbach-1.0 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sample_controlnet_dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SaffalPoosh/sample_controlnet_dataset","creator_name":"Talha Yousuf","creator_url":"https://huggingface.co/SaffalPoosh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tControlNet training\\n\\t\\n\\nthis dataset is subset of fill_50k dataset just to test the finetuning logic.\\n\\nTODO:\\n\\n\\n add text data\\n\\n"},
	{"name":"toy-diabetes","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Jayabalambika/toy-diabetes","creator_name":"R","creator_url":"https://huggingface.co/Jayabalambika","description":"Jayabalambika/toy-diabetes dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"basic_code_ppl_eval","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/reshinthadith/basic_code_ppl_eval","creator_name":"reshinth.adith","creator_url":"https://huggingface.co/reshinthadith","description":"reshinthadith/basic_code_ppl_eval dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"docs_on_several_languages","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages","creator_name":"Aleksey Timoshin","creator_url":"https://huggingface.co/AlekseyScorpi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"docs_on_several_languages\\\"\\n\\t\\n\\nThis dataset is a collection of different images in different languages.\\nThe set includes the following languages: Azerbaijani, Belorussian, Chinese, English, Estonian, Finnish, Georgian, Japanese, Korean, Kazakh, Latvian, Lithuanian, Mongolian, Norwegian, Polish, Russian, Ukranian.\\nEach language has a corresponding class label defined. At least 100 images in the entire dataset are allocated per class. This dataset was originally used… See the full description on the dataset page: https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages."},
	{"name":"ign_clean_instruct_dataset_500k","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ignmilton/ign_clean_instruct_dataset_500k","creator_name":"Ignatius Milton","creator_url":"https://huggingface.co/ignmilton","description":"This dataset contains ~508k prompt-instruction pairs with high quality responses. It was synthetically created from a subset of Ultrachat prompts. It does not contain any alignment focused responses or NSFW content.\\nLicensed under apache-2.0\\n"},
	{"name":"test","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/BerMaker/test","creator_name":"BerMaker","creator_url":"https://huggingface.co/BerMaker","description":"Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable."},
	{"name":"pipeline2code","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/katenil/pipeline2code","creator_name":"Kate Trofimova","creator_url":"https://huggingface.co/katenil","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pipeline2Code\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset origin\\n\\t\\n\\nCode4ML: a Large-scale Dataset of annotated Machine Learning Code\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is designed for the iterative generation of Machine Learning (ML) code based on high-level ML pipeline descriptions.\\nIt consists of code snippets extracted from Kaggle kernels, organized as Jupyter Notebook snippets. \\nEach kernel includes a set of prompts and completions. \\nThe initial prompt contains an  token… See the full description on the dataset page: https://huggingface.co/datasets/katenil/pipeline2code."},
	{"name":"lyra","keyword":"code","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/d0rj/lyra","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlyra\\n\\t\\n\\n"},
	{"name":"lyra","keyword":"code","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/d0rj/lyra","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlyra\\n\\t\\n\\n"},
	{"name":"bc-humaneval","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/gabeorlanski/bc-humaneval","creator_name":"Gabe Orlanski","creator_url":"https://huggingface.co/gabeorlanski","description":"The HumanEval dataset in BabelCode format."},
	{"name":"commitpackft","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bigcode/commitpackft","creator_name":"BigCode","creator_url":"https://huggingface.co/bigcode","description":"CommitPackFT is is a 2GB filtered version of CommitPack to contain only high-quality commit messages that resemble natural language instructions."},
	{"name":"bc-transcoder","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/gabeorlanski/bc-transcoder","creator_name":"Gabe Orlanski","creator_url":"https://huggingface.co/gabeorlanski","description":"The Transcoder dataset in BabelCode format. Currently supports translation from C++ and Python."},
	{"name":"test","keyword":"code","license":"Boost Software License 1.0","language":"en","url":"https://huggingface.co/datasets/pengxiang01/test","creator_name":"wang","creator_url":"https://huggingface.co/pengxiang01","description":"aasdfsdf\\n"},
	{"name":"NER","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Soressaa/NER","creator_name":"SORESSA BEYENE LEMU","creator_url":"https://huggingface.co/Soressaa","description":"Soressaa/NER dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CodeLlama-2-20k","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mlabonne/CodeLlama-2-20k","creator_name":"Maxime Labonne","creator_url":"https://huggingface.co/mlabonne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCodeLlama-2-20k: A Llama 2 Version of CodeAlpaca\\n\\t\\n\\nThis dataset is the sahil2801/CodeAlpaca-20k dataset with the Llama 2 prompt format described here.\\nHere is the code I used to format it:\\nfrom datasets import load_dataset\\n\\n# Load the dataset\\ndataset = load_dataset('sahil2801/CodeAlpaca-20k')\\n\\n# Define a function to merge the three columns into one\\ndef merge_columns(example):\\n    if example['input']:\\n        merged = f\\\"<s>[INST] <<SYS>>\\\\nBelow is an instruction that describes a… See the full description on the dataset page: https://huggingface.co/datasets/mlabonne/CodeLlama-2-20k."},
	{"name":"ai-hdlcoder-dataset","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AWfaw/ai-hdlcoder-dataset","creator_name":"Romashchenko Vladyslav","creator_url":"https://huggingface.co/AWfaw","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AI-HDLCoder\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe GitHub Code dataset consists of 100M code files from GitHub in VHDL programming language with extensions totaling in 1.94 GB of data. The dataset was created from the public GitHub dataset on Google BiqQuery at Anhalt University of Applied Sciences.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tConsiderations for Using the Data\\n\\t\\n\\nThe dataset is created for research purposes and consists of source code from a wide range of repositories. As such… See the full description on the dataset page: https://huggingface.co/datasets/AWfaw/ai-hdlcoder-dataset."},
	{"name":"humaneval-ja-v0.6","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/HachiML/humaneval-ja-v0.6","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"humaneval-ja\\\"\\n\\t\\n\\nMore Information needed\\n"},
	{"name":"BuggedPythonLeetCode","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NeuroDragon/BuggedPythonLeetCode","creator_name":"NeuroDragon","creator_url":"https://huggingface.co/NeuroDragon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nedit: fixed some bugs with datasets not handling all pyarrow types.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of Python coding problems from LeetCode, which have been bugged using the OpenBugger package. This dataset provides a unique opportunity to study the debugging process in a controlled and replicable environment.\\nFor each correct code snippet, 15 bugged versions were attempted. For each succesfully bugged version, a corresponding question… See the full description on the dataset page: https://huggingface.co/datasets/NeuroDragon/BuggedPythonLeetCode."},
	{"name":"langchain-python-integrations","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/clue2solve/langchain-python-integrations","creator_name":"Clue2solve Inc","creator_url":"https://huggingface.co/clue2solve","description":"clue2solve/langchain-python-integrations dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"langchain-docs-use-cases","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/clue2solve/langchain-docs-use-cases","creator_name":"Clue2solve Inc","creator_url":"https://huggingface.co/clue2solve","description":"clue2solve/langchain-docs-use-cases dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"langchain-docs-modules","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/clue2solve/langchain-docs-modules","creator_name":"Clue2solve Inc","creator_url":"https://huggingface.co/clue2solve","description":"clue2solve/langchain-docs-modules dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"HelloWorldExamples","keyword":"code","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/MihaiPopa2/HelloWorldExamples","creator_name":"Popa Mihai Cosmin","creator_url":"https://huggingface.co/MihaiPopa2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntro\\n\\t\\n\\nWelcome to the one-liner \\\"Hello world!\\\" examples!\\nThis is a dataset containing \\\"Hello world!\\\" examples in 10+ languages!\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNotes\\n\\t\\n\\nIf you found a language that's not listed here, you can open a pull request!\\nYou can also create and train models, or even spaces!\\nNote that this dataset is in CSV format, so it's not as flexible as JSON!\\n"},
	{"name":"CodeNet4Repair","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/TnT/CodeNet4Repair","creator_name":"TnT","creator_url":"https://huggingface.co/TnT","description":"TnT/CodeNet4Repair dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Python-codes","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Arjun-G-Ravi/Python-codes","creator_name":"Arjun G Ravi","creator_url":"https://huggingface.co/Arjun-G-Ravi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nPlease note that this dataset maynot be perfect and may contain a very small quantity of non python codes. But the quantity appears to be very small\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset contains a collection of python question and their code. This is meant to be used for training models to be efficient in Python specific coding.\\nThe dataset has two features - 'question' and 'code'. \\nAn example is:\\n{'question': 'Create a function that takes in… See the full description on the dataset page: https://huggingface.co/datasets/Arjun-G-Ravi/Python-codes."},
	{"name":"Multi_CodeNet4Repair","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/TnT/Multi_CodeNet4Repair","creator_name":"TnT","creator_url":"https://huggingface.co/TnT","description":"TnT/Multi_CodeNet4Repair dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"text-template-to-summarize","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Anderson-Andre-P/text-template-to-summarize","creator_name":"Anderson André Pereira Eleutério","creator_url":"https://huggingface.co/Anderson-Andre-P","description":"Anderson-Andre-P/text-template-to-summarize dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"alpaca-cs","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Vazbeek/alpaca-cs","creator_name":"Jan Sláma","creator_url":"https://huggingface.co/Vazbeek","description":"Alpaca dataset translated to Czech language using ChatGPT 3.5.\\n"},
	{"name":"errored_python","keyword":"code","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/TacoPrime/errored_python","creator_name":"Matt J","creator_url":"https://huggingface.co/TacoPrime","description":"This is a subset of the python dataset provided but Ailurophile on Kaggle.\\nImportant:Errors were introduced on purpose to try to test a sort of \\\"specialized masking\\\" in a realistic way. \\nGoal:The goal is to create a specialized agent, and add it to a chain with at least one other agent that generates code, and can hopefully \\\"catch\\\" any errors. \\nInspiration:When working to generate datasets with other models, I found that even after multiple \\\"passes\\\" errors where still missed.\\nOut of curiosity… See the full description on the dataset page: https://huggingface.co/datasets/TacoPrime/errored_python."},
	{"name":"alpaca-cs-subset-1k","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Vazbeek/alpaca-cs-subset-1k","creator_name":"Jan Sláma","creator_url":"https://huggingface.co/Vazbeek","description":"First 1000 items form dataset Vazbeek/alpaca-cs.\\n"},
	{"name":"PY150k","keyword":"code","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/AISE-TUDelft/PY150k","creator_name":"AISE research lab at TU Delft","creator_url":"https://huggingface.co/AISE-TUDelft","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"PY150k\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCode Completion dataset created from the code available in CodeXGlue.\\n"},
	{"name":"dypybench_functions","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/claudios/dypybench_functions","creator_name":"Claudio Spiess","creator_url":"https://huggingface.co/claudios","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDyPyBench Functions Datasets\\n\\t\\n\\nDyPyBench is a dataset constructed by Piyush Krishan Bajaj at the Software Lab, Institute of Software Engineering, University of Stuttgart. It contains 50 open source projects from GitHub.\\nWe used Nathan Cooper's function_parser tool, based off GitHub's CodeSearchNet function_parser, to extract all functions from all the projects, excluding library functions in the virtualenv. We also ran all tests in DyPyBench and produced a coverage report in JSON.… See the full description on the dataset page: https://huggingface.co/datasets/claudios/dypybench_functions."},
	{"name":"user_id","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/feliciamj/user_id","creator_name":"mj","creator_url":"https://huggingface.co/feliciamj","description":"feliciamj/user_id dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"HyPoradise-v0","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/PeacefulData/HyPoradise-v0","creator_name":"Peaceful Data","creator_url":"https://huggingface.co/PeacefulData","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHypothesesParadise\\n\\t\\n\\n\\nOpen request to public git submission on open resource their n-best to public usage.\\nIf you consider this work would be related or useful for your research, please consider to cite the work in NeurIPS 2023. Thank you.\\n\\n   \\n\\n@inproceedings{chen2023hyporadise,\\n  title={HyPoradise: An Open Baseline for Generative Speech Recognition with Large Language Models},\\n  author={CHEN, CHEN and Hu, Yuchen and Yang, Chao-Han Huck and Siniscalchi, Sabato Marco and Chen… See the full description on the dataset page: https://huggingface.co/datasets/PeacefulData/HyPoradise-v0."},
	{"name":"dataset1","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ccml/dataset1","creator_name":"Ahm","creator_url":"https://huggingface.co/ccml","description":"ccml/dataset1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"matt-training-img","keyword":"code","license":"Artistic License 2.0","language":"en","url":"https://huggingface.co/datasets/raoulduke420/matt-training-img","creator_name":"Matt Dilworth","creator_url":"https://huggingface.co/raoulduke420","description":"My dataset for training SDXL & SD 1.5\\n"},
	{"name":"the-vault-class","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Fsoft-AIC/the-vault-class","creator_name":"FPT Software AI Center","creator_url":"https://huggingface.co/Fsoft-AIC","description":"The Vault is a multilingual code-text dataset with over 40 million pairs covering 10 popular programming languages. \\nIt is the largest corpus containing parallel code-text data. By building upon The Stack, a massive raw code sample collection, \\nthe Vault offers a comprehensive and clean resource for advancing research in code understanding and generation. It provides a \\nhigh-quality dataset that includes code-text pairs at multiple levels, such as class and inline-level, in addition to the function level. \\nThe Vault can serve many purposes at multiple levels."},
	{"name":"huge-context-size-test","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/pchanumolu/huge-context-size-test","creator_name":"Pradeep Chanumolu","creator_url":"https://huggingface.co/pchanumolu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCodeLlama-2-20k: A Llama 2 Version of CodeAlpaca\\n\\t\\n\\nThis dataset is the pchanumolu/huge-context-size-test dataset with the Llama 2 prompt format described here.\\nHere is the code I used to format it:\\nfrom datasets import load_dataset\\n\\n# Load the dataset\\ndataset = load_dataset('pchanumolu/huge-context-size-test')\\n\\n# Define a function to merge the three columns into one\\ndef merge_columns(example):\\n    if example['input']:\\n        merged = f\\\"<s>[INST] <<SYS>>\\\\nBelow is an instruction… See the full description on the dataset page: https://huggingface.co/datasets/pchanumolu/huge-context-size-test."},
	{"name":"chipgpt","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/JackieZhang/chipgpt","creator_name":"Jackie Zhang","creator_url":"https://huggingface.co/JackieZhang","description":"JackieZhang/chipgpt dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"mrmocci","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mrmocciai/mrmocci","creator_name":"Mocci lutha","creator_url":"https://huggingface.co/mrmocciai","description":"\\n\\n VOICE CONVERSATION BACKUP\\nOriginal Repo\\n"},
	{"name":"humaneval_ru","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/NLPCoreTeam/humaneval_ru","creator_name":"NLP Core Team","creator_url":"https://huggingface.co/NLPCoreTeam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHumanEval_ru Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a version of Code Geneneration HumanEval dataset translated to Russian. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported tasks\\n\\t\\n\\nThe task is to generate body of the function based on the function signature and docstring. The programming problems are written in Python and contain Russian natural text in comments and docstrings.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTask example\\n\\t\\n\\nfrom typing import List\\ndef string_xor(a: str, b: str) -> str:\\n    \\\"\\\"\\n    Входными данными… See the full description on the dataset page: https://huggingface.co/datasets/NLPCoreTeam/humaneval_ru."},
	{"name":"Grapheme128x128","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/innat/Grapheme128x128","creator_name":"Mohammed Innat","creator_url":"https://huggingface.co/innat","description":"\\nThis data set is preprocess version of this competition data set. The preprocess data is collected from here.\\n"},
	{"name":"OneOS","keyword":"code","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/wasertech/OneOS","creator_name":"Danny Waser","creator_url":"https://huggingface.co/wasertech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOneOS Dataset\\n\\t\\n\\nThe OneOS dataset is a collection of text data for the OneOS project. It consists of a large number of text samples that can be used for training and evaluating natural language processing models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nNumber of Samples: 13,068\\nLicense: CC0*\\nLanguage: English, French\\n\\n  * Only unlicensed sentences generated manually fall under CreativeCommon-0. Sentences already licensed under different terms, such as nl2bash or samantha-data, remain… See the full description on the dataset page: https://huggingface.co/datasets/wasertech/OneOS."},
	{"name":"habr_qa_sbs","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Vikhrmodels/habr_qa_sbs","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHabr sbs qa\\n\\t\\n\\nДатасет основан на сайте habr qa, лучший ответ - тот на котором есть лайки, худший - тот на котором меньше всего лайков. \\nДатасет собран Love.Death.Transformers. и Дата-Утренник \\nMore Information needed\\n"},
	{"name":"smart-contracts-instructions","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AlfredPros/smart-contracts-instructions","creator_name":"Alfred Kuhlman","creator_url":"https://huggingface.co/AlfredPros","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSmart Contracts Instructions\\n\\t\\n\\nA dataset containing 6,003 GPT-generated human instruction and Solidity source code data pairs.\\nGPT models used to make this data are GPT-3.5 turbo, GPT-3.5 turbo 16k context, and GPT-4. Solidity source codes are used from mwritescode's Slither Audited Smart Contracts (https://huggingface.co/datasets/mwritescode/slither-audited-smart-contracts).\\nDistributions of the GPT models used to make this dataset:\\n\\nGPT-3.5 Turbo: 5,276\\nGPT-3.5 Turbo 16k… See the full description on the dataset page: https://huggingface.co/datasets/AlfredPros/smart-contracts-instructions."},
	{"name":"SalesKRA","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AdiOO7/SalesKRA","creator_name":"Aditya Singh","creator_url":"https://huggingface.co/AdiOO7","description":"AdiOO7/SalesKRA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"stackoverflowVQA-filtered-small","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mirzaei2114/stackoverflowVQA-filtered-small","creator_name":"Motahhare Mirzaei","creator_url":"https://huggingface.co/mirzaei2114","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"stackoverflowVQA-filtered-small\\\"\\n\\t\\n\\nMore Information needed\\n"},
	{"name":"stackoverflowVQA","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mirzaei2114/stackoverflowVQA","creator_name":"Motahhare Mirzaei","creator_url":"https://huggingface.co/mirzaei2114","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"stackoverflowVQA\\\"\\n\\t\\n\\nMore Information needed\\n"},
	{"name":"Helix","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/KaleidoSG/Helix","creator_name":"Kaleido Singapore","creator_url":"https://huggingface.co/KaleidoSG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHelix Dataset for Questioning and Instructing (QI)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe Helix dataset is a specialized collection of data tailored for Questioning and Instructing (QI) tasks. It is created by merging all the Airoboros datasets and incorporating one RosettaCode dataset, with a primary focus on supporting QI research and applications.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nSource Datasets: Airoboros datasets (various sources), RosettaCode dataset\\nMerging Script: The merging of… See the full description on the dataset page: https://huggingface.co/datasets/KaleidoSG/Helix."},
	{"name":"Test_Asosoft_WER","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/abdulhade/Test_Asosoft_WER","creator_name":"abdulhady abas abdullah","creator_url":"https://huggingface.co/abdulhade","description":"WER evaluation asosoft test set with large v2 whisper model\\n"},
	{"name":"TinyText","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/VatsaDev/TinyText","creator_name":"Vatsa Pandey","creator_url":"https://huggingface.co/VatsaDev","description":"The entire NanoPhi Dataset is at train.jsonl\\nSeparate Tasks Include\\n\\nMath (Metamath, mammoth)\\nCode (Code Search Net)\\nLogic (Open-platypus)\\nRoleplay (PIPPA, RoleplayIO)\\nTextbooks (Tiny-text, Sciphi)\\nTextbook QA (Orca-text, Tiny-webtext)\\n\\n"},
	{"name":"StackOverflow-QA-C-Language-5k","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Mxode/StackOverflow-QA-C-Language-5k","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"PS: More data (40k) can be found here Mxode/StackOverflow-QA-C-Language-40k.\\n\\nThis is a collection of ~5000 QA's in C Language from StackOverflow. The data has been initially cleaned, and each response is with Accepted Answer. \\nAll data is <500 in length.\\nThe questions and answers were organized into a one-line format. A sample format is shown below:\\n{\\n    \\\"question\\\": \\\"```\\\\nFILE* file = fopen(some file)\\\\n\\\\npcap_t* pd = pcap_fopen_offline(file)\\\\n\\\\npcap_close(pd)\\\\n\\\\nfclose(file)\\\\n```\\\\n\\\\nThis… See the full description on the dataset page: https://huggingface.co/datasets/Mxode/StackOverflow-QA-C-Language-5k."},
	{"name":"glaive-code-assistant-v2","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/glaiveai/glaive-code-assistant-v2","creator_name":"Glaive AI","creator_url":"https://huggingface.co/glaiveai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGlaive-code-assistant-v2\\n\\t\\n\\nGlaive-code-assistant-v2 is a dataset of ~215k code problems and solutions generated using Glaive’s synthetic data generation platform.\\nThis is built on top of the previous version of the dataset that can be found here\\nTo report any problems or suggestions in the data, join the Glaive discord\\n"},
	{"name":"VoxCelebSpoof","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MattyB95/VoxCelebSpoof","creator_name":"Matthew Boakes","creator_url":"https://huggingface.co/MattyB95","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVoxCelebSpoof\\n\\t\\n\\nVoxCelebSpoof is a dataset related to detecting spoofing attacks on automatic speaker verification systems. This dataset is part of a broader effort to improve the security of voice biometric systems against various types of spoofing attacks, such as replay attacks, voice synthesis, and voice conversion.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe VoxCelebSpoof dataset includes a range of audio samples from different types of synthesis… See the full description on the dataset page: https://huggingface.co/datasets/MattyB95/VoxCelebSpoof."},
	{"name":"sql-parsed","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/VishalCh/sql-parsed","creator_name":"Vishal Choudhary","creator_url":"https://huggingface.co/VishalCh","description":"VishalCh/sql-parsed dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"HyPoradise-v1-GigaSpeech","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/PeacefulData/HyPoradise-v1-GigaSpeech","creator_name":"Peaceful Data","creator_url":"https://huggingface.co/PeacefulData","description":"\\nIf you consider this work would be related or useful for your research, please consider to cite the work in EMNLP 2023. Thank you.\\n\\n@inproceedings{radhakrishnan2023whispering,\\n  title={Whispering LLaMA: A Cross-Modal Generative Error Correction Framework for Speech Recognition},\\n  author={Srijith Radhakrishnan, Chao-Han Huck Yang, Sumeer Ahmad Khan, Rohit Kumar, Narsis A. Kiani, David Gomez-Cabrero, Jesper N. Tegner},\\n  booktitle={Proc. of EMNLP},\\n  year={2023}\\n}\\n\\n"},
	{"name":"Synthetic_Voice_Detection_Resources","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MattyB95/Synthetic_Voice_Detection_Resources","creator_name":"Matthew Boakes","creator_url":"https://huggingface.co/MattyB95","description":"MattyB95/Synthetic_Voice_Detection_Resources dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"multi-task-instruction","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nmd2k/multi-task-instruction","creator_name":"Nguyen Manh Dung","creator_url":"https://huggingface.co/nmd2k","description":"nmd2k/multi-task-instruction dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Parquet_FIles","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/iix/Parquet_FIles","creator_name":"-","creator_url":"https://huggingface.co/iix","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tParquet_Files\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCross Language (CL) Datasets\\n\\t\\n\\nFour datasets of language pair translations originating from CORDIS Project News (https://elrc-share.eu/)\\nStructured as follows:\\n\\n| Field           | Description                                                             |\\n| --------------- | ----------------------------------------------------------------------- |\\n| de/es/fr/it     | Non-English transcripts of sentences                                    |\\n| en… See the full description on the dataset page: https://huggingface.co/datasets/iix/Parquet_FIles."},
	{"name":"for-test","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ziqin/for-test","creator_name":"yiziqin","creator_url":"https://huggingface.co/ziqin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFor TEST\\n\\t\\n\\nthis is a dataset for test\\njust for test...\\n"},
	{"name":"testing","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/1NightRaid1/testing","creator_name":"ruixiangding","creator_url":"https://huggingface.co/1NightRaid1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/1NightRaid1/testing."},
	{"name":"snd_eng","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/samiesam/snd_eng","creator_name":"Usama Naveed","creator_url":"https://huggingface.co/samiesam","description":"\\ntask_categories:\\n\\ntranslation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset for project snd_to_eng.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe BCP-47 code for the dataset's language is unk.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Fields\\n\\t\\n\\nThe dataset has the following fields (also called \\\"features\\\"):\\n{\\n  \\\"feat_id\\\": \\\"Value(dtype='int64', id=None)\\\",\\n  \\\"feat_source_lang\\\": \\\"Value(dtype='string', id=None)\\\",\\n  \\\"feat_target_lang\\\": \\\"Value(dtype='string', id=None)\\\",\\n  \\\"source\\\": \\\"Value(dtype='string', id=None)\\\",\\n  \\\"target\\\":… See the full description on the dataset page: https://huggingface.co/datasets/samiesam/snd_eng."},
	{"name":"CodeAlpaca_20k_NoBlanks","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PsiPi/CodeAlpaca_20k_NoBlanks","creator_name":"ψπ.com","creator_url":"https://huggingface.co/PsiPi","description":"Just a repost of the upstream with \\\" records elided\\n"},
	{"name":"PascalQnA100","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PsiPi/PascalQnA100","creator_name":"ψπ.com","creator_url":"https://huggingface.co/PsiPi","description":"100 Pascal Q and A\\n60% with an input string of some kind\\n"},
	{"name":"docs-python-v1","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ASHu2/docs-python-v1","creator_name":"Ashutosh Mishra","creator_url":"https://huggingface.co/ASHu2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for creating python docs from methods. This is formatted from semeru/code-code-galeras-code-completion-from-docstring-3k-deduped\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: semeru/code-code-galeras-code-completion-from-docstring-3k-deduped\\nLanguage(s) (NLP): Python\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository:… See the full description on the dataset page: https://huggingface.co/datasets/ASHu2/docs-python-v1."},
	{"name":"Dummy","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AdiOO7/Dummy","creator_name":"Aditya Singh","creator_url":"https://huggingface.co/AdiOO7","description":"AdiOO7/Dummy dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"coco_image_extract","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/iix/coco_image_extract","creator_name":"-","creator_url":"https://huggingface.co/iix","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModified Coco Dataset Files\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRequired dependencies\\n\\t\\n\\nOpenCV (cv2):\\n\\npip install opencv-python\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\timg_data.psv\\n\\t\\n\\nExtract of the coco dataset containing the following labels: [\\\"airplane\\\", \\\"backpack\\\", \\\"cell phone\\\", \\\"handbag\\\", \\\"suitcase\\\", \\\"knife\\\", \\\"laptop\\\", \\\"car\\\"]\\nStructured as follows:\\n\\n| Field           | Description                                                                                         |\\n| --------------- |… See the full description on the dataset page: https://huggingface.co/datasets/iix/coco_image_extract."},
	{"name":"mini_coco_linux","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/iix/mini_coco_linux","creator_name":"-","creator_url":"https://huggingface.co/iix","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmini coco dataset files\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRequired dependencies\\n\\t\\n\\nOpenCV (cv2)\\n\\nmatplotlib\\n\\nipywidgets\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\timg_data.psv\\n\\t\\n\\nExtract of the coco dataset containing the following labels: [\\\"airplane\\\", \\\"backpack\\\", \\\"cell phone\\\", \\\"handbag\\\", \\\"suitcase\\\", \\\"knife\\\", \\\"laptop\\\", \\\"car\\\"]  (300 of each)\\nStructured as follows:\\n\\n| Field           | Description                                                                                         |\\n| --------------- |… See the full description on the dataset page: https://huggingface.co/datasets/iix/mini_coco_linux."},
	{"name":"Labyrinth","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/pnkvalavala/Labyrinth","creator_name":"Pavan Narasimha Karthik","creator_url":"https://huggingface.co/pnkvalavala","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLabyrinth Dataset\\n\\t\\n\\nLabyrinth is a code dataset that combines three existing datasets without modifying the data itself but adapting the structure/format to streamline fine-tuning for Zephyr on code.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\nLabyrinth is composed of code examples and instructions from the following three datasets:\\n\\nCodeAlpaca by Sahil Chaudhary.\\nCodegen-instruct by Teknium.\\nllama-2-instruct-121k-code by Davut Emre TASAR.\\n\\n"},
	{"name":"apps_rlaif","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nmd2k/apps_rlaif","creator_name":"Nguyen Manh Dung","creator_url":"https://huggingface.co/nmd2k","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAPPS Dataset for Reinforcement Learning with AI Feedback\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nAPPS_RLAIF is an extended work from APPS [1] \\nto use Chat LLMs to create multiple variances for each solution for defined problems. \\nIn each solution, we use LLama 34B [2] to transform the original solutions into variances and rank them by score.\\nThe generated flow is demonstrated as below; each variance is created based on the previous version of it in the chat. \\nWe iterated each solutions… See the full description on the dataset page: https://huggingface.co/datasets/nmd2k/apps_rlaif."},
	{"name":"code_contests_instruct","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/BEE-spoke-data/code_contests_instruct","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"code_contests_instruct\\\"\\n\\t\\n\\nThe deepmind/code_contests dataset formatted as markdown-instruct for text generation training.\\nThere are several different configs. Look at them. Comments:\\n\\nflesch_reading_ease is computed on the description col via textstat\\nhq means that python2 (aka PYTHON in language column) is dropped, and keeps only rows with flesch_reading_ease  75 or greater\\nmin-cols drops all cols except language and text\\npossible values for language are {'CPP'… See the full description on the dataset page: https://huggingface.co/datasets/BEE-spoke-data/code_contests_instruct."},
	{"name":"openai-humaneval-sky-shadow","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Miaosen/openai-humaneval-sky-shadow","creator_name":"Miaosen Zhang","creator_url":"https://huggingface.co/Miaosen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShadow Humaneval dataset\\n\\t\\n\\nThis dataset is generated by GPT-4 to mimic openai-humaneval dataset. Each problem of HumanEval has a corresponding shadow problem in this dataset.\\nThe usage of this dataset is to check Whether a code generation model has data leakage during its training progress. You can refer to Skywork for further details.\\n"},
	{"name":"HTML-correction-examples","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/arhamk/HTML-correction-examples","creator_name":"Arham","creator_url":"https://huggingface.co/arhamk","description":"arhamk/HTML-correction-examples dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sql-create-context-id","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/detakarang/sql-create-context-id","creator_name":"Gede Putra Nugraha","creator_url":"https://huggingface.co/detakarang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is a fork from sql-create-context \\nThis dataset builds from WikiSQL and Spider.\\nThere are 78,577 examples of natural language queries, SQL CREATE TABLE statements, and SQL Query answering the question using the CREATE statement as context. This dataset was built with text-to-sql LLMs in mind, intending to prevent hallucination of column and table names often seen when trained on text-to-sql datasets. The CREATE TABLE statement can often be copy and pasted… See the full description on the dataset page: https://huggingface.co/datasets/detakarang/sql-create-context-id."},
	{"name":"EasyReddit","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Tonic/EasyReddit","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"\\n\\t\\n\\t\\t\\n\\t\\t🙋🏻‍♂️Welcome to 🧑🏻‍🚀Tonic's🚀🚰Easy🔴Reddit🔥!\\n\\t\\n\\n\\nThis is every \\\"best reddit_question_best_answers\\\" appended and produced according to the following template :\\n{\\\"prompt\\\": \\\"This is the first prompt\\\", \\\"completion\\\": \\\"This is the first completion\\\"}\\n{\\\"prompt\\\": \\\"This is the second prompt\\\", \\\"completion\\\": \\\"This is the second completion\\\"}\\n\\n\\n\\n🌟 You can use it in shards or all together !\\n\\n🌟 This dataset is internally consistent !\\n\\n\\n🤔The point is to make it easy to train models with a… See the full description on the dataset page: https://huggingface.co/datasets/Tonic/EasyReddit."},
	{"name":"Youtube_Links","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Decre99/Youtube_Links","creator_name":"De","creator_url":"https://huggingface.co/Decre99","description":"Decre99/Youtube_Links dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Test_Youtube","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Decre99/Test_Youtube","creator_name":"De","creator_url":"https://huggingface.co/Decre99","description":"Decre99/Test_Youtube dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Test_Youtube_Links","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Innovina/Test_Youtube_Links","creator_name":"Innovina","creator_url":"https://huggingface.co/Innovina","description":"Innovina/Test_Youtube_Links dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ikomia_doc_1","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AllanOuii/ikomia_doc_1","creator_name":"K","creator_url":"https://huggingface.co/AllanOuii","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/AllanOuii/ikomia_doc_1."},
	{"name":"Test2","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Innovina/Test2","creator_name":"Innovina","creator_url":"https://huggingface.co/Innovina","description":"Innovina/Test2 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"strike-T1","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hsienchen/strike-T1","creator_name":"hsien chen","creator_url":"https://huggingface.co/hsienchen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStrike-T1\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdataset_info:\\n  features:\\n  - name: image\\n    dtype: image\\n  - name: cr\\n    dtype: int64\\n  splits:\\n  - name: train\\n    num_bytes: 162832.0\\n    num_examples: 12\\n  download_size: 70261\\n  dataset_size: 162832.0\\nconfigs:\\n- config_name: default\\n  data_files:\\n  - split: train\\n    path: data/train-*\\n\\t\\n\\n"},
	{"name":"blender_duplicates","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/mano-wii/blender_duplicates","creator_name":"Germano Cavalcante de Sousa","creator_url":"https://huggingface.co/mano-wii","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nContains reduced description of issues reported at https://projects.blender.org/blender/blender/issues and points to duplicate issues in order to categorize similarity.\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEach report has been shortened by removing frequently repeated texts such as System Information, Blender… See the full description on the dataset page: https://huggingface.co/datasets/mano-wii/blender_duplicates."},
	{"name":"stackoverflowVQA-filtered","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mirzaei2114/stackoverflowVQA-filtered","creator_name":"Motahhare Mirzaei","creator_url":"https://huggingface.co/mirzaei2114","description":"mirzaei2114/stackoverflowVQA-filtered dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"lca-bug-localization","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/JetBrains-Research/lca-bug-localization","creator_name":"JetBrains Research","creator_url":"https://huggingface.co/JetBrains-Research","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🏟️ Long Code Arena (Bug localization)\\n\\t\\n\\nThis is the benchmark for the Bug localization task as part of the\\n🏟️ Long Code Arena benchmark.\\nThe bug localization problem can be formulated as follows: given an issue with a bug description and a repository snapshot in a state where the bug is reproducible, identify the files within the repository that need to be modified to address the reported bug.\\nThe dataset provides all the required components for evaluation of bug localization… See the full description on the dataset page: https://huggingface.co/datasets/JetBrains-Research/lca-bug-localization."},
	{"name":"Handwriting-Recognition-Dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/gymprathap/Handwriting-Recognition-Dataset","creator_name":"Gym Prathap","creator_url":"https://huggingface.co/gymprathap","description":"The dataset comprises over four hundred thousand handwritten names obtained from charitable initiatives.\\nCharacter Recognition employs image processing techniques to transform characters present on scanned documents into digital formats. It generally exhibits good performance with machine-printed fonts. Nonetheless, machines still encounter formidable obstacles in accurately identifying handwritten characters due to the vast diversity in individual writing styles.\\nThe total number of first… See the full description on the dataset page: https://huggingface.co/datasets/gymprathap/Handwriting-Recognition-Dataset."},
	{"name":"code-readability-krod","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/se2p/code-readability-krod","creator_name":"Chair of Software Engineering II, Uni Passau","creator_url":"https://huggingface.co/se2p","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tJava Code Readability Merged & Modified\\n\\t\\n\\nThis dataset contains 69276 Java code snippets along with a readability score, mined from Github and automatically processed and labelled.\\nYou can download the dataset using Hugging Face:\\nfrom datasets import load_dataset\\nds = load_dataset(\\\"se2p/code-readability-krod\\\")\\n\\nThe snippets are not split into train and test (and validation) set. Thus, the whole dataset is in the train set:\\nds = ds['train']\\nds_as_list = ds.to_list() # Convert the… See the full description on the dataset page: https://huggingface.co/datasets/se2p/code-readability-krod."},
	{"name":"Pdf","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Decre99/Pdf","creator_name":"De","creator_url":"https://huggingface.co/Decre99","description":"Decre99/Pdf dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"methods2test","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/andstor/methods2test","creator_name":"André Storhaug","creator_url":"https://huggingface.co/andstor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMicrosoft created the methods2test dataset, consisting of Java Junit test cases with its corresponding focal methods. \\nIt contains 780k pairs of JUnit test cases and focal methods which were extracted from a total of 91K\\nJava open source project hosted on GitHub.\\nThis is an assembled version of the methods2test dataset. It provides convenient access to the different context levels based on the raw source code (e.g. newlines are preserved). The test cases and… See the full description on the dataset page: https://huggingface.co/datasets/andstor/methods2test."},
	{"name":"manimation","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mediciresearch/manimation","creator_name":"Medici Research","creator_url":"https://huggingface.co/mediciresearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMedici Animation Instruct Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSmall instruct dataset for animation generation with ManimCE\\n\\t\\n\\n"},
	{"name":"EditPackFT","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nuprl/EditPackFT","creator_name":"Northeastern University Programming Research Lab","creator_url":"https://huggingface.co/nuprl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEditPackFT\\n\\t\\n\\nEditPackFT is a dataset built for training LLMs on the task of instructional code editing. The mail columns are:\\n\\nold_contents the code before the edit\\ninstruction the instruction to transform the before code into the after code\\nnew_contents the code after the edit\\ncontent a pre-formatted training window that can be used to train an LLM with prompts in the format of: <before><instruction><after>\\n\\nThis dataset has been filtered from CommitPackFT. For more detail, see… See the full description on the dataset page: https://huggingface.co/datasets/nuprl/EditPackFT."},
	{"name":"EditPackFT","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nuprl/EditPackFT","creator_name":"Northeastern University Programming Research Lab","creator_url":"https://huggingface.co/nuprl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEditPackFT\\n\\t\\n\\nEditPackFT is a dataset built for training LLMs on the task of instructional code editing. The mail columns are:\\n\\nold_contents the code before the edit\\ninstruction the instruction to transform the before code into the after code\\nnew_contents the code after the edit\\ncontent a pre-formatted training window that can be used to train an LLM with prompts in the format of: <before><instruction><after>\\n\\nThis dataset has been filtered from CommitPackFT. For more detail, see… See the full description on the dataset page: https://huggingface.co/datasets/nuprl/EditPackFT."},
	{"name":"CanItEdit","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nuprl/CanItEdit","creator_name":"Northeastern University Programming Research Lab","creator_url":"https://huggingface.co/nuprl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCan It Edit? Evaluating the Ability of Large Language Models to Follow Code Editing Instructions\\n\\t\\n\\nCanItEdit is a benchmark for evaluating LLMs on instructional code editing, the task of updating a program given a natural language instruction. The benchmark contains 105 hand-crafted Python programs with before and after code blocks, two types of natural language instructions (descriptive and lazy), and a hidden test suite.\\nThe dataset’s dual natural language instructions test… See the full description on the dataset page: https://huggingface.co/datasets/nuprl/CanItEdit."},
	{"name":"lipreading","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/wissemkarous/lipreading","creator_name":"wissem karous","creator_url":"https://huggingface.co/wissemkarous","description":"wissemkarous/lipreading dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"pandas-create-context","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/hiltch/pandas-create-context","creator_name":"Or Hiltch","creator_url":"https://huggingface.co/hiltch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is built from sql-create-context, which in itself builds from WikiSQL and Spider.\\nI have used GPT4 to translate the SQL schema into pandas DataFrame schem initialization statements and to translate the SQL queries into pandas queries. \\nThere are 862 examples of natural language queries, pandas DataFrame creation statements, and pandas query answering the question using the DataFrame creation statement as context. This dataset was built with text-to-pandas… See the full description on the dataset page: https://huggingface.co/datasets/hiltch/pandas-create-context."},
	{"name":"methods2test_small","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/andstor/methods2test_small","creator_name":"André Storhaug","creator_url":"https://huggingface.co/andstor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMicrosoft created the methods2test dataset, consisting of Java Junit test cases with their corresponding focal methods. \\nIt contains 780k pairs of JUnit test cases and focal methods which were extracted from a total of 91K Java open-source projects hosted on GitHub.\\nThis is a smaller subset of the assembled version of the methods2test dataset.\\nIt provides convenient access to the different context levels based on the raw source code (e.g. newlines are… See the full description on the dataset page: https://huggingface.co/datasets/andstor/methods2test_small."},
	{"name":"Q_and_A_Google_devices","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Aashi/Q_and_A_Google_devices","creator_name":"Aashi Dutt","creator_url":"https://huggingface.co/Aashi","description":"Aashi/Q_and_A_Google_devices dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Vezora-Tested-22k-Python-Alpaca-ru","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/MexIvanov/Vezora-Tested-22k-Python-Alpaca-ru","creator_name":"Mex Ivanov","creator_url":"https://huggingface.co/MexIvanov","description":"A machine translated version of the Vezora/Tested-22k-Python-Alpaca dataset.\\nConsists of code \\\"Filtered Using Vezora's CodeTester\\\" with code-related data and natural language instructions.\\nReleased under the same license as the original dataset, provided as is with research intent, use/read at your own risk.\\n"},
	{"name":"openai-formate-function-calling-small","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Deepexi/openai-formate-function-calling-small","creator_name":"Deepexi Inc","creator_url":"https://huggingface.co/Deepexi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集内容说明:\\n\\t\\n\\n包含700+个阿里云OpenAPI的信息;包括Dataworks,EMR，DataLake，Maxcompute，Hologram,实时计算Flink版，QuickBI,DTS等多个产品的公开Open API信息。\\n Functions信息与OpenAI functions calling 能力中，functions信息传入的格式保持一致 \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t样例\\n\\t\\n\\n{\\n  \\\"systemPrompt\\\": 你是一个函数筛选助理，如果与问题相关的话,您可以使用下面的函数来获取更多数据以回答用户提出的问题:{\\\"name\\\": \\\"UpdateTicketNum\\\", \\\"description\\\": \\\"对用于免登嵌入报表的指定的ticket进行更新票据数量操作。\\\", \\\"parameters\\\": {\\\"type\\\": \\\"object\\\", \\\"properties\\\": [{\\\"Ticket\\\": {\\\"type\\\": \\\"string\\\", \\\"description\\\":… See the full description on the dataset page: https://huggingface.co/datasets/Deepexi/openai-formate-function-calling-small."},
	{"name":"starcoderdatasetnew","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/haris001/starcoderdatasetnew","creator_name":"Demo Hugging","creator_url":"https://huggingface.co/haris001","description":"haris001/starcoderdatasetnew dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"jsoncodes","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/haris001/jsoncodes","creator_name":"Demo Hugging","creator_url":"https://huggingface.co/haris001","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/haris001/jsoncodes."},
	{"name":"Code-74k-ShareGPT-Vicuna","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/cognitivecomputations/Code-74k-ShareGPT-Vicuna","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","description":"Code-74k-ShareGPT-Vicuna\\nThis dataset is in Vicuna/ShareGPT format. There are around 74000 set of conversations. Each set having 2 conversations. \\nPython, Java, JavaScript, GO, C++, Rust etc. code with detailed explanation are provided. \\nThis dataset has around 60~65% of Python code. \\n"},
	{"name":"eidas","keyword":"code","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/javatask/eidas","creator_name":"Andrii Melashchenko","creator_url":"https://huggingface.co/javatask","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\teIDAS Terminology Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe EiDAS Terminology dataset is a comprehensive collection of terms and abbreviations related to electronic identification and trust services for electronic transactions in the European Single Market (eIDAS). This dataset provides clear definitions and explanations of various terms, making it an essential resource for researchers and practitioners in digital identity and security.… See the full description on the dataset page: https://huggingface.co/datasets/javatask/eidas."},
	{"name":"Julia-Proof-Pile-2","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ajibawa-2023/Julia-Proof-Pile-2","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Julia-Proof-Pile-2\\nThis dataset is part of Proof-Pile-2 dataset. This dataset is consisting of mathematical code, including numerical computing, computer algebra, and formal mathematics.\\nThis entire dataset is in Julia language. It is slightly more than 0.5 Billion tokens. I have removed Meta data from this dataset hence you can directly use it for training purpose.\\nThis dataset is in Jsonl format.\\n"},
	{"name":"advent-of-code","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/isavita/advent-of-code","creator_name":"Aleksandar Dimov","creator_url":"https://huggingface.co/isavita","description":"This dataset contains solutions and related data for Advent of Code challenges, starting with the year 2015. It includes tasks, inputs, answers, solution codes, and the programming languages used for the solutions."},
	{"name":"CodegebraGPT_data","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/sr5434/CodegebraGPT_data","creator_name":"Samir R.","creator_url":"https://huggingface.co/sr5434","description":"A collection of datasets for finetuning LLMs on STEM related tasks. The dataset is formatted in the LLaVA finetuning format.\\n"},
	{"name":"lcc_csharp","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/fasterinnerlooper/lcc_csharp","creator_name":"Shafiq Jetha","creator_url":"https://huggingface.co/fasterinnerlooper","description":"This dataset has been modified from the microsoft/LCC_csharp dataset to provide CodeLLaMa with infilling tasks as per the original fill-in-the-middle paper, were the text that needs to be filled in is moved to the end of the dataset, thus taking advantage of the Generative feature of GPT-style models.\\n"},
	{"name":"linguistica_assist","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SiguienteGlobal/linguistica_assist","creator_name":"Siguiente","creator_url":"https://huggingface.co/SiguienteGlobal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/SiguienteGlobal/linguistica_assist."},
	{"name":"glaive-code-assistant-v3","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/glaiveai/glaive-code-assistant-v3","creator_name":"Glaive AI","creator_url":"https://huggingface.co/glaiveai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGlaive-code-assistant-v3\\n\\t\\n\\nGlaive-code-assistant-v3 is a dataset of ~1M code problems and solutions generated using Glaive’s synthetic data generation platform.\\nThis is built on top of the previous version of the dataset that can be found here. This already includes v1 and v2 of the dataset.\\nTo report any problems or suggestions in the data, join the Glaive discord\\n"},
	{"name":"Code-290k-ShareGPT","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ajibawa-2023/Code-290k-ShareGPT","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","description":"Code-290k-ShareGPT\\nThis dataset is in Vicuna/ShareGPT format. There are around 290000 set of conversations. Each set having 2 conversations. \\nAlong with Python, Java, JavaScript, GO, C++, Rust, Ruby, Sql, MySql, R, Julia, Haskell, etc. code with detailed explanation are provided.\\nThis datset is built upon using my existing Datasets Python-Code-23k-ShareGPT\\nand Code-74k-ShareGPT\\nMy Models Python-Code-13B and Python-Code-33B are trained on Python-Code-23k-ShareGPT.\\nMy Models Code-13B and… See the full description on the dataset page: https://huggingface.co/datasets/ajibawa-2023/Code-290k-ShareGPT."},
	{"name":"Derm-T2IM-Dataset","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MAli-Farooq/Derm-T2IM-Dataset","creator_name":"Muhammad Ali Farooq","creator_url":"https://huggingface.co/MAli-Farooq","description":"\\nThe Dataset6K folder consist of two sub folders which includes Benign and Malignant data samples each having 3k data samples.\\n\\nThe Smart transformation folder consist of three subfolders which inlcudes tiny benign mole, large malignant moles and multiple moles each having advanced skin lesion augmentation results.\\n\\nIf you need to generate more data using Derm-T2IM model it can done by uploading the Derm-T2IM model on stable diffusion GUI which can be cloned from below Github Repo.\\nLink:… See the full description on the dataset page: https://huggingface.co/datasets/MAli-Farooq/Derm-T2IM-Dataset."},
	{"name":"D2A","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/claudios/D2A","creator_name":"Claudio Spiess","creator_url":"https://huggingface.co/claudios","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tD2A: A Dataset Built for AI-Based Vulnerability Detection Methods Using Differential Analysis\\n\\t\\n\\nThis is an unofficial HuggingFace upload of the D2A dataset from \\\"D2A: A Dataset Built for AI-Based Vulnerability Detection Methods Using Differential Analysis\\\". \\\"Test\\\" splits have all labels as -1 as they are not provided.\\nUsage:\\nfrom datasets import load_dataset\\n\\n# Use \\\"code\\\", \\\"code_trace\\\", \\\"function\\\", or \\\"trace\\\" to load the different variants.\\ndataset = load_dataset(\\\"claudios/D2A\\\"… See the full description on the dataset page: https://huggingface.co/datasets/claudios/D2A."},
	{"name":"AI-Dictionary","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/J0nasW/AI-Dictionary","creator_name":"Jonas Wilinski","creator_url":"https://huggingface.co/J0nasW","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Dictionary Dataset\\n\\t\\n\\nWelcome to the AI Dictionary dataset on HuggingFace. This dataset is a comprehensive tool comprised of 16,665 unique key phrases that describe the whole domain of Artificial Intelligence (AI). It serves both the research community and industry domains, aiding in the identification of radical innovations and uncovering applications of AI in new domains.\\nThis dataset is the result of the research paper \\\"The AI Dictionary: The Foundation for a Text-Based Tool… See the full description on the dataset page: https://huggingface.co/datasets/J0nasW/AI-Dictionary."},
	{"name":"py-dpo-v0.1","keyword":"code","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/jondurbin/py-dpo-v0.1","creator_name":"Jon Durbin","creator_url":"https://huggingface.co/jondurbin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nDPO dataset meant to enhance python coding abilities.\\nThis dataset uses the excellent https://huggingface.co/datasets/Vezora/Tested-22k-Python-Alpaca dataset as the \\\"chosen\\\" responses, given this dataset was already tested and validated.\\nThe \\\"rejected\\\" values were generated with a mix of airoboros-l2-13b-3.1 and bagel-7b-v0.1.\\nThe rejected values may actually be perfectly fine, but the assumption here is that the values are generally a lower quality than the chosen… See the full description on the dataset page: https://huggingface.co/datasets/jondurbin/py-dpo-v0.1."},
	{"name":"zenn-articles-20240115","keyword":"code","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/p1atdev/zenn-articles-20240115","creator_name":"Plat","creator_url":"https://huggingface.co/p1atdev","description":"Dataset of URLs of articles on Zenn (zenn.dev)\\n"},
	{"name":"Turkish-QA","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Aixr/Turkish-QA","creator_name":"Aixr AI","creator_url":"https://huggingface.co/Aixr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAixr Türkçe Veri Seti\\n\\t\\n\\nAixr tarafından oluşturulan bu veri seti, Türkçe kaynak arayanlar için hazırlanmıştır. Yazılım geliştirme, radyoloji, tıbbi görüntüleme ve diğer konularda bilgi sağlayan bu veri seti, öğrenme süreçlerini kolaylaştırmayı ve Türkçe dilinde yapay zeka geliştirme süreçlerini desteklemeyi hedefler.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVeri Seti Hakkında\\n\\t\\n\\nAmaç:\\nBu veri seti, Türkçe içerikler arayan araştırmacılar, geliştiriciler ve eğitimciler için bir kaynak olarak tasarlanmıştır.… See the full description on the dataset page: https://huggingface.co/datasets/Aixr/Turkish-QA."},
	{"name":"Turkish-QA","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Aixr/Turkish-QA","creator_name":"Aixr AI","creator_url":"https://huggingface.co/Aixr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAixr Türkçe Veri Seti\\n\\t\\n\\nAixr tarafından oluşturulan bu veri seti, Türkçe kaynak arayanlar için hazırlanmıştır. Yazılım geliştirme, radyoloji, tıbbi görüntüleme ve diğer konularda bilgi sağlayan bu veri seti, öğrenme süreçlerini kolaylaştırmayı ve Türkçe dilinde yapay zeka geliştirme süreçlerini desteklemeyi hedefler.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVeri Seti Hakkında\\n\\t\\n\\nAmaç:\\nBu veri seti, Türkçe içerikler arayan araştırmacılar, geliştiriciler ve eğitimciler için bir kaynak olarak tasarlanmıştır.… See the full description on the dataset page: https://huggingface.co/datasets/Aixr/Turkish-QA."},
	{"name":"RSL_Maran","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran."},
	{"name":"DafnyGym","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/emugnier/DafnyGym","creator_name":"Eric Mugnier","creator_url":"https://huggingface.co/emugnier","description":"emugnier/DafnyGym dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"hanlp_date-zh","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zeroMN/hanlp_date-zh","creator_name":"zeroTT","creator_url":"https://huggingface.co/zeroMN","description":"\\n\\t\\n\\t\\t\\n\\t\\t--\\n2nd International Chinese Word Segmentation Bakeoff - Data Release\\nRelease 1, 2005-11-18\\n\\t\\n\\n\\nIntroduction\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis directory contains the training, test, and gold-standard data\\nused in the 2nd International Chinese Word Segmentation Bakeoff. Also\\nincluded is the script used to score the results submitted by the\\nbakeoff participants and the simple segmenter used to generate the\\nbaseline and topline data.\\n\\t\\n\\n\\nFile List\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tgold/       Contains the gold standard… See the full description on the dataset page: https://huggingface.co/datasets/zeroMN/hanlp_date-zh."},
	{"name":"ai-chat-dataset","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/rahulsingh2103/ai-chat-dataset","creator_name":"Rahul Singh","creator_url":"https://huggingface.co/rahulsingh2103","description":"rahulsingh2103/ai-chat-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"nemo-github-issues","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/renwei2024/nemo-github-issues","creator_name":"Wei Ren","creator_url":"https://huggingface.co/renwei2024","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThis dataset contains 10,000 issues and pull requests along with their associated comments of Nvidia Nemo Github repo.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/renwei2024/nemo-github-issues."},
	{"name":"MX-CHAT","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/berwart/MX-CHAT","creator_name":"Berwart","creator_url":"https://huggingface.co/berwart","description":"MX-CHAT 01\\n"},
	{"name":"test_01","keyword":"code","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jedgert2/test_01","creator_name":"Joe Edgerton","creator_url":"https://huggingface.co/jedgert2","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/jedgert2/test_01."},
	{"name":"nepali_law_datasets","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Ashalupreti/nepali_law_datasets","creator_name":"Ashal Upreti","creator_url":"https://huggingface.co/Ashalupreti","description":"\\n\\t\\n\\t\\t\\n\\t\\t📜 Nepali Law Commission Dataset\\n\\t\\n\\nA structured dataset of Nepali legal questions and answers, focusing on the rights of people with disabilities.\\n\\n\\t\\n\\t\\t\\n\\t\\t📌 Overview\\n\\t\\n\\nThis dataset contains questions and answers based on Nepal's legal framework, particularly regarding the rights of persons with disabilities. The dataset is designed for AI/ML applications such as:✅ Legal chatbots✅ Question-answering models✅ Legal document analysis✅ NLP research on Nepali language  \\nThe dataset is… See the full description on the dataset page: https://huggingface.co/datasets/Ashalupreti/nepali_law_datasets."},
	{"name":"task2_advanced","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/litlsun/task2_advanced","creator_name":"Ekaterina","creator_url":"https://huggingface.co/litlsun","description":"\\n\\t\\n\\t\\t\\n\\t\\tЗадача 2: Разметка датасета с HF Datasets: статистический анализ и визуализация\\n\\t\\n\\nРазметка представленного датасета выполнена в рамках курса по компьютерной лингвистике НИУ ВШЭ (СПб).\\n\\n\\t\\n\\t\\t\\n\\t\\tПРОВЕДЕННЫЙ АНАЛИЗ\\n\\t\\n\\nБыл пороведен статистический анализ текста, включающий:\\n\\nАнализ уникальности данных\\nДоля уникальных слов: 0.0032\\n\\nЧастотный анализ биграмм и триграмм\\n\\n\\n\\n\\n\\nАнализ распределений: Длины предложений, слов и n-грамм\\n\\nСредняя длина предложения: 15.82\\nСтандартное отклонение длины… See the full description on the dataset page: https://huggingface.co/datasets/litlsun/task2_advanced."},
	{"name":"Web-dev-large-dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/cynnix69/Web-dev-large-dataset","creator_name":"cynnix sinn","creator_url":"https://huggingface.co/cynnix69","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [Cynnix]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper… See the full description on the dataset page: https://huggingface.co/datasets/cynnix69/Web-dev-large-dataset."},
	{"name":"text-to-command","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/beargos/text-to-command","creator_name":"Valdis Aglonietis","creator_url":"https://huggingface.co/beargos","description":"beargos/text-to-command dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cl-humaneval_v1.0","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kogi-jwu/cl-humaneval_v1.0","creator_name":"Kuramitsu Lab, JWU","creator_url":"https://huggingface.co/kogi-jwu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCL-HumanEval\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCL-HumanEval is a benchmark for evaluating cross-lingual transfer through code generation. \\nIt is based on the code generation benchmark HumanEval.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset contains coding problems in 2 natural languages: English and Japanese.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nfrom datasets import load_dataset\\nload_dataset(\\\"kogi-jwu/cl-humaneval_v1.0\\\", \\\"en\\\")\\n\\nDatasetDict({\\n    test: Dataset({\\n        features: ['task_id'… See the full description on the dataset page: https://huggingface.co/datasets/kogi-jwu/cl-humaneval_v1.0."},
	{"name":"test","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/waitmandot/test","creator_name":"Cauê Waitman","creator_url":"https://huggingface.co/waitmandot","description":"waitmandot/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sakuraeval-alpha0101","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/myst72/sakuraeval-alpha0101","creator_name":"Miyu Sato","creator_url":"https://huggingface.co/myst72","description":"myst72/sakuraeval-alpha0101 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"retail-shop-enquiries","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/pythontech9/retail-shop-enquiries","creator_name":"pythontech9","creator_url":"https://huggingface.co/pythontech9","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/pythontech9/retail-shop-enquiries."},
	{"name":"langchain_full","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Tony20100/langchain_full","creator_name":"Anthony Vincent","creator_url":"https://huggingface.co/Tony20100","description":"Tony20100/langchain_full dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"QwQ-LongCoT-130K-decontaminated","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/flatlander1024/QwQ-LongCoT-130K-decontaminated","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Decontaminated version of gghfez/QwQ-LongCoT-130K-cleaned that remove the collided data from math/test, gsm8k/test, olympiadbench/test, minerva_math/test, college_math/test, mmlu_stem/test, gaokao, amc23, aime24 and math500.\\nTotal number of rows: 124594\\n"},
	{"name":"aurora_programmer_data","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/naimulislam/aurora_programmer_data","creator_name":"Naimul Islam Nahid","creator_url":"https://huggingface.co/naimulislam","description":"\\n\\t\\n\\t\\t\\n\\t\\tMy Awesome Dataset\\n\\t\\n\\nA comprehensive description of my awesome dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains images of cats and dogs.  The images were collected from [mention data source(s), e.g., a specific website, scraped from the internet]. It is intended for use in image classification tasks.  The dataset consists of [number] images, with approximately [percentage]% allocated to the training set and [percentage]% to the test set. [Add more details about the… See the full description on the dataset page: https://huggingface.co/datasets/naimulislam/aurora_programmer_data."},
	{"name":"HumanEval-V-Benchmark","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HumanEval-V/HumanEval-V-Benchmark","creator_name":"HumanEval-V","creator_url":"https://huggingface.co/HumanEval-V","description":"\\n\\t\\n\\t\\t\\n\\t\\tHumanEval-V: Benchmarking High-Level Visual Reasoning with Complex Diagrams in Coding Tasks\\n\\t\\n\\n\\n    📄 Paper  •\\n    🏠 Home Page •\\n    💻 GitHub Repository  •\\n    🏆 Leaderboard •\\n    🤗 Dataset Viewer \\n\\n\\nHumanEval-V is a novel benchmark designed to evaluate the diagram understanding and reasoning capabilities of Large Multimodal Models (LMMs) in programming contexts. Unlike existing benchmarks, HumanEval-V focuses on coding tasks that require sophisticated visual reasoning over… See the full description on the dataset page: https://huggingface.co/datasets/HumanEval-V/HumanEval-V-Benchmark."},
	{"name":"Crash_Predictionsv2","keyword":"code","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/PratikGanesh/Crash_Predictionsv2","creator_name":"Pratik Ganesh","creator_url":"https://huggingface.co/PratikGanesh","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/PratikGanesh/Crash_Predictionsv2."},
	{"name":"AlternateNumbers","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/EscheWang/AlternateNumbers","creator_name":"Wang","creator_url":"https://huggingface.co/EscheWang","description":"This is a dataset for CFG-based GflowNet development.\\nThe ebnf style CFG for numbers are:\\nroot ::= number_list\\n\\nnumber_list ::= number (number_list)?\\n\\nnumber ::= odd even | even odd\\n\\neven ::= \\\"0,\\\" | \\\"2,\\\" | \\\"4,\\\" | \\\"6,\\\" | \\\"8,\\\" | \\\"10,\\\" | \\\"12,\\\" | \\\"14,\\\" | \\\"16,\\\" | \\\"18,\\\" | \\\"20,\\\"\\n\\nodd ::= \\\"1,\\\" | \\\"3,\\\" | \\\"5,\\\" | \\\"7,\\\" | \\\"9,\\\" | \\\"11,\\\" | \\\"13,\\\" | \\\"15,\\\" | \\\"17,\\\" | \\\"19,\\\"\\n\\nHowever, this CFG cannot satisfy all the requirments. The CFG give a chunk of numbers where the transition between chunks always failed to… See the full description on the dataset page: https://huggingface.co/datasets/EscheWang/AlternateNumbers."},
	{"name":"Marathi-matrix","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sonyvakode/Marathi-matrix","creator_name":"sonyvakode","creator_url":"https://huggingface.co/sonyvakode","description":"sonyvakode/Marathi-matrix dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"BoannaTheThird","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Bonana/BoannaTheThird","creator_name":"Adnan Jami","creator_url":"https://huggingface.co/Bonana","description":"Bonana/BoannaTheThird dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CHASE-Code","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/McGill-NLP/CHASE-Code","creator_name":"McGill NLP Group","creator_url":"https://huggingface.co/McGill-NLP","description":"\\n  CHASE: Challenging AI with Synthetic Evaluations\\n\\n\\n\\n  \\n\\n\\n\\nThe pace of evolution of Large Language Models (LLMs) necessitates new approaches for rigorous and comprehensive evaluation. Traditional human annotation is increasingly impracticable due to the complexities and costs involved in generating high-quality, challenging problems. In this work, we introduce **CHASE**, a unified framework to synthetically generate challenging problems using LLMs without human involvement.  For a given task… See the full description on the dataset page: https://huggingface.co/datasets/McGill-NLP/CHASE-Code."},
	{"name":"V1Q","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate… See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q."},
	{"name":"Synthetic-JP-EN-Coding-Dataset","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/llm-jp/Synthetic-JP-EN-Coding-Dataset","creator_name":"LLM-jp","creator_url":"https://huggingface.co/llm-jp","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthetic-JP-EN-Coding-Dataset\\n\\t\\n\\nThis repository provides an instruction tuning dataset developed by LLM-jp, a collaborative project launched in Japan.\\nThe dataset comprises a subset from Aratako/Synthetic-JP-EN-Coding-Dataset-801k.\\n\\n\\t\\n\\t\\t\\n\\t\\tSend Questions to\\n\\t\\n\\nllm-jp(at)nii.ac.jp\\n\\n\\t\\n\\t\\t\\n\\t\\tModel Card Authors\\n\\t\\n\\nThe names are listed in alphabetical order.\\nHirokazu Kiyomaru and Takashi Kodama.\\n"},
	{"name":"shootergtu-architecture","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Gray-Time-Kid/shootergtu-architecture","creator_name":"Full Gray","creator_url":"https://huggingface.co/Gray-Time-Kid","description":"\\n\\t\\n\\t\\t\\n\\t\\tShooterGTU Architecture Dataset\\n\\t\\n\\nThis dataset contains a JSON file describing the event-driven architecture\\nof the ShooterGTU game. It includes core managers, scenes, events, and \\ndependencies.\\n\\n\\t\\n\\t\\t\\n\\t\\tFiles\\n\\t\\n\\n\\narchitecture.json: The main JSON with metadata, core components, \\nhierarchy layers, etc.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\nYou can load this dataset using the datasets library:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"username/shootergtu-architecture\\\"… See the full description on the dataset page: https://huggingface.co/datasets/Gray-Time-Kid/shootergtu-architecture."},
	{"name":"GPT4-Chat-GRP0","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/naimulislam/GPT4-Chat-GRP0","creator_name":"Naimul Islam Nahid","creator_url":"https://huggingface.co/naimulislam","description":"naimulislam/GPT4-Chat-GRP0 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"PyRe","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/theprint/PyRe","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"theprint/PyRe dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"blender_qna","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/DeltaSatellite1/blender_qna","creator_name":"Amarion Burks","creator_url":"https://huggingface.co/DeltaSatellite1","description":"raaaa\\n"},
	{"name":"UCP","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Cuizhihao10/UCP","creator_name":"Zhihao","creator_url":"https://huggingface.co/Cuizhihao10","description":"Cuizhihao10/UCP dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"einstein_answers","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/aliMohammad16/einstein_answers","creator_name":"Mohammad Ali","creator_url":"https://huggingface.co/aliMohammad16","description":"\\n\\t\\n\\t\\t\\n\\t\\tWhat would Einstein Say?\\n\\t\\n\\nThis dataset contains a set of questions and answers, mimicking Einstein's approach to answer general scientific and philosophical queries. \\nThe data points have been generated synthetically, however the factual correctness of the data is ensured, not guaranteed whatsoever.\\n"},
	{"name":"Roblox-Luau-Reasoning-v1.0","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/boatbomber/Roblox-Luau-Reasoning-v1.0","creator_name":"Zack Ovits","creator_url":"https://huggingface.co/boatbomber","description":"\\n\\t\\n\\t\\t\\n\\t\\tRoblox-Luau-Reasoning-v1.0\\n\\t\\n\\nThis dataset contains prompt->chain of thought+code+explanation for Luau, based on Roblox/luau-corpus.\\nWe take real Luau code from the corpus (cleaned & auto-formatted for best quality) and work backwards to generate a prompt for it. Then, we generate a chain of thought that works from that prompt to reach the code. Finally, we generate an explanation of the code.\\nThis means that we'll be able to fine tune reasoning models (like Deepseek R1) on the dataset… See the full description on the dataset page: https://huggingface.co/datasets/boatbomber/Roblox-Luau-Reasoning-v1.0."},
	{"name":"Meta_Plan_Optimization","keyword":"code","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/xwm/Meta_Plan_Optimization","creator_name":"xwm","creator_url":"https://huggingface.co/xwm","description":"\\n\\t\\n\\t\\t\\n\\t\\tMPO Datasets\\n\\t\\n\\nThis folder contains the datasets for the MPO experiments.\\nPaper: https://hf.co/papers/2503.02682\\nCode: https://github.com/WeiminXiong/MPO\\n\\n\\t\\n\\t\\t\\n\\t\\tFile Structure\\n\\t\\n\\nalfworld_metaplan_preference_pairs.json: includes comparison data for the DPO optimization phase of the ALFWorld meta planner.\\nsciworld_metaplan_preference_pairs.json: includes comparison data for the DPO optimization phase of the SciWorld meta planner.\\nalfworld_metaplan_sft.json: includes the metaplan data… See the full description on the dataset page: https://huggingface.co/datasets/xwm/Meta_Plan_Optimization."},
	{"name":"TinyMarkdown-Instruct-EN","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/VAMJ-0042/TinyMarkdown-Instruct-EN","creator_name":"Vitor Augusto Machado Jorge","creator_url":"https://huggingface.co/VAMJ-0042","description":"\\n\\t\\n\\t\\t\\n\\t\\tMarkdown Fine-Tuning Datasets (English & PT-BR)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThese datasets are designed to fine-tune Large Language Models (LLMs) like Gemma to generate structured Markdown-formatted responses. The datasets contain instruction-response pairs, ensuring the model learns how to output Markdown elements correctly.\\n\\n\\t\\n\\t\\t\\n\\t\\tDatasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1. English Markdown Dataset\\n\\t\\n\\n\\nAvailable on Hugging Face: TinyMarkdown-Instruct-EN\\nSize: Large-scale dataset with structured Markdown… See the full description on the dataset page: https://huggingface.co/datasets/VAMJ-0042/TinyMarkdown-Instruct-EN."},
	{"name":"Java_method2test_chatml","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/random-long-int/Java_method2test_chatml","creator_name":"Long Int","creator_url":"https://huggingface.co/random-long-int","description":"\\n\\t\\n\\t\\t\\n\\t\\tJava Method to Test ChatML\\n\\t\\n\\nThis dataset is based on the methods2test dataset from Microsoft. It follows the ChatML template format: [{'role': '', 'content': ''}, {...}].\\nOriginally, methods2test contains only Java methods at different levels of granularity along with their corresponding test cases. The different focal method segmentations are illustrated here:\\n\\nTo simulate a conversation between a Java developer and an AI assistant, I introduce two key parameters:\\n\\nThe prompt… See the full description on the dataset page: https://huggingface.co/datasets/random-long-int/Java_method2test_chatml."},
	{"name":"merged_bigvul_primevul","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mahdin70/merged_bigvul_primevul","creator_name":"Mukit Mahdin","creator_url":"https://huggingface.co/mahdin70","description":"\\n\\t\\n\\t\\t\\n\\t\\tMerged BigVul and PrimeVul Dataset\\n\\t\\n\\nDataset ID: mahdin70/merged_bigvul_primevul\\nThis dataset is a merged and preprocessed combination of the BigVul (bstee615/bigvul) and PrimeVul (colin/PrimeVul, \\\"default\\\" configuration) datasets, designed for vulnerability analysis and machine learning tasks. The preprocessing ensures consistency in column names, data types, and formats, making it suitable for fine-tuning models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThe dataset integrates vulnerability… See the full description on the dataset page: https://huggingface.co/datasets/mahdin70/merged_bigvul_primevul."},
	{"name":"secure_code","keyword":"code","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Vayuda/secure_code","creator_name":"Pawan Jayakumar","creator_url":"https://huggingface.co/Vayuda","description":"Vayuda/secure_code dataset hosted on Hugging Face and contributed by the HF Datasets community"}
]
;
