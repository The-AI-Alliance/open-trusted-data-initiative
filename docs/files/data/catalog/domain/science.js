const data_for_domain_science = 
[
	{"name":"scicom-context-qa","keyword":"science","description":"\n\t\n\t\t\n\t\tSciCom Context QA Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a merged collection of context-enriched science and commonsense question-answering pairs from multiple high-quality QA benchmarks. It combines data from 4 different sources into a unified context-enriched question-answer format with 10 diverse template patterns.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis merged dataset combines the following benchmarks:\n\nCommonsenseQA: commonsense reasoning questions (tau/commonsense_qa)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sungyub/scicom-context-qa.","url":"https://huggingface.co/datasets/sungyub/scicom-context-qa","creator_name":"sungyub kim","creator_url":"https://huggingface.co/sungyub","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","tau/commonsense_qa","allenai/openbookqa","allenai/qasc"],"keywords_longer_than_N":true},
	{"name":"sciq-pairs","keyword":"science","description":"\n\t\n\t\t\n\t\tSciQ Pairs Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a processed version of the SciQ dataset by AllenAI, reformatted into simple input-output pairs for question-answering tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe original SciQ dataset contains science exam questions with multiple choice answers. This dataset extracts only the questions and correct answers, creating a clean Q&A pair format.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ninput: Science question (string)\noutput: Correct answer (string)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sungyub/sciq-pairs.","url":"https://huggingface.co/datasets/sungyub/sciq-pairs","creator_name":"sungyub kim","creator_url":"https://huggingface.co/sungyub","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","allenai/sciq","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"scicom-qa","keyword":"science","description":"\n\t\n\t\t\n\t\tSciCom QA Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a merged collection of science and commonsense question-answering pairs from multiple high-quality QA benchmarks. It combines data from 4 different sources into a unified basic question-answer format.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis merged dataset combines the following benchmarks:\n\nCommonsenseQA: commonsense reasoning questions (tau/commonsense_qa)\nOpenBookQA: open book science questions (allenai/openbookqa)\nQASC: multi-hop‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sungyub/scicom-qa.","url":"https://huggingface.co/datasets/sungyub/scicom-qa","creator_name":"sungyub kim","creator_url":"https://huggingface.co/sungyub","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","tau/commonsense_qa","allenai/openbookqa","allenai/qasc"],"keywords_longer_than_N":true},
	{"name":"MultiSim","keyword":"science","description":"MultiSim is a growing collection of Text Simplfication datasets in multiple languages.  Each dataset is a set of complex and simple sentence pairs.","url":"https://huggingface.co/datasets/MichaelR207/MultiSim","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["summarization","text-generation","English","French","Russian"],"keywords_longer_than_N":true},
	{"name":"Luganda_Sci-Math-Bio_Translations","keyword":"science","description":"\n\t\n\t\t\n\t\tLuganda Sci-Math-Bio Translations\n\t\n\nThis dataset contains Luganda and English translations of biologicial, mathematical and scientific terms\n","url":"https://huggingface.co/datasets/allandclive/Luganda_Sci-Math-Bio_Translations","creator_name":"Allan D Clive","creator_url":"https://huggingface.co/allandclive","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Ganda","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MMMU","keyword":"science","description":"\n\t\n\t\t\n\t\tMMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI)\n\t\n\nüåê Homepage | ü§ó Dataset | ü§ó Paper | üìñ arXiv | GitHub\n\n\t\n\t\t\n\t\n\t\n\t\tüîîNews\n\t\n\n\nüî•[2023-12-04]: Our evaluation server for test set is now availble on EvalAI. We welcome all submissions and look forward to your participation! üòÜ\n\n\n\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe introduce MMMU: a new benchmark designed to evaluate multimodal models on massive multi-discipline‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aslessor/MMMU.","url":"https://huggingface.co/datasets/aslessor/MMMU","creator_name":"Alex","creator_url":"https://huggingface.co/aslessor","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MMMU","keyword":"science","description":"\n\t\n\t\t\n\t\tMMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI)\n\t\n\nüåê Homepage | üèÜ Leaderboard | ü§ó Dataset | ü§ó Paper | üìñ arXiv | GitHub\n\n\t\n\t\t\n\t\n\t\n\t\tüîîNews\n\t\n\n\nüõ†Ô∏è[2024-05-30]: Fixed duplicate option issues in Materials dataset items (validation_Materials_25; test_Materials_17, 242) and content error in validation_Materials_25.\nüõ†Ô∏è[2024-04-30]: Fixed missing \"-\" or \"^\" signs in Math dataset items (dev_Math_2, validation_Math_11, 12, 16; test_Math_8‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MMMU/MMMU.","url":"https://huggingface.co/datasets/MMMU/MMMU","creator_name":"MMMU","creator_url":"https://huggingface.co/MMMU","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"sciq-contrast-pairs","keyword":"science","description":"\n\t\n\t\t\n\t\tSciQ Contrast Pairs Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a contrast-based learning version of the SciQ dataset by AllenAI. Instead of directly asking questions, this dataset focuses on teaching models to distinguish between correct and incorrect answers through contrastive examples.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe original SciQ dataset contains science exam questions with one correct answer and three distractors (incorrect answers). This dataset reformats them into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sungyub/sciq-contrast-pairs.","url":"https://huggingface.co/datasets/sungyub/sciq-contrast-pairs","creator_name":"sungyub kim","creator_url":"https://huggingface.co/sungyub","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","allenai/sciq","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"sciq-context-pairs","keyword":"science","description":"\n\t\n\t\t\n\t\tSciQ Context-Aware Pairs Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is an augmented version of the SciQ dataset by AllenAI. It includes only samples with supporting context and applies 12 different question templates to prevent overfitting during training.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe original SciQ dataset contains science exam questions with multiple choice answers and optional supporting text. This dataset:\n\nFilters samples that have non-empty support text (contextual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sungyub/sciq-context-pairs.","url":"https://huggingface.co/datasets/sungyub/sciq-context-pairs","creator_name":"sungyub kim","creator_url":"https://huggingface.co/sungyub","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","allenai/sciq","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"physics-formulas-tr","keyword":"science","description":"esholmess/physics-formulas-tr dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/esholmess/physics-formulas-tr","creator_name":"ƒ∞lknur Yaren K.","creator_url":"https://huggingface.co/esholmess","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Turkish","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"shortlist-reason-v1","keyword":"science","description":"\n\t\n\t\t\n\t\tShort List Reason V1\n\t\n\nA fully synthetic fine-tuning dataset of reasoning questions across multiple domains, generated using advanced language models.\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nShort List Reason V1 is a fully synthetic dataset made for fine-tuning large language models on reasoning tasks. It contains question-answer pairs from various subjects such as:\n\nMathematics  \nScience  \nBusiness  \nAnd other reasoning-oriented topics\n\nAll question-answer pairs are fully synthetic and generated by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/catsaresupercool/shortlist-reason-v1.","url":"https://huggingface.co/datasets/catsaresupercool/shortlist-reason-v1","creator_name":"Burchid Sipt","creator_url":"https://huggingface.co/catsaresupercool","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"scidocs-c","keyword":"science","description":"\n\t\n\t\t\n\t\tscidocs-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Gargantua-R1-Wee","keyword":"science","description":"\n\n\t\n\t\t\n\t\tGargantua-R1-Wee\n\t\n\n\nThe Gargantua-R1-Wee dataset, curated by prithivMLmods and available on Hugging Face, is a compact, high-quality collection of mathematical and scientific reasoning problems paired with detailed solutions. It contains approximately 232,530 rows and is designed in Parquet format for efficient storage and access, with an estimated size of 2.23 GB. This dataset emphasizes rigorous mathematical problem-solving and covers diverse domains such as mathematics, coding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Gargantua-R1-Wee.","url":"https://huggingface.co/datasets/prithivMLmods/Gargantua-R1-Wee","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"customer-feedback-action-plans","keyword":"reviews","description":"\n\t\n\t\t\n\t\tCustomer Feedback ‚Üí Action Plans\n\t\n\nA small, practical dataset that maps raw customer feedback (e.g., restaurant reviews) to actionable recommendations with optional aspect annotations and reasoning. Useful for training instruction-following models, aspect-aware summarizers, or classification heads that support the generation task.\n\n\t\n\t\t\n\t\tFiles & Splits\n\t\n\n\ntrain.csv ‚Äî main training split for generation.\nvalidation.csv ‚Äî validation split for generation.\ntrain_aux_classification.csv ‚Äî‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Programmer-RD-AI/customer-feedback-action-plans.","url":"https://huggingface.co/datasets/Programmer-RD-AI/customer-feedback-action-plans","creator_name":"Programmer-RD-AI","creator_url":"https://huggingface.co/Programmer-RD-AI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","English","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"gp_surgery_reviews_fake_and_real","keyword":"reviews","description":"\n\t\n\t\t\n\t\tGP Surgery Reviews Dataset Data Card\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset consists of GP Surgery reviews designed for binary classification tasks. It includes both real and fake reviews, where the label feature marks real reviews as 0 and fake reviews as 1. The fake reviews were generated using DeepSeek LLM (Ollama) and then passed through a processing pipeline to derive additional features.\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\n\nTotal Records: 9,974\n\n\n\t\n\t\t\n\t\tFeatures:\n\t\n\n\nfree_text:\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/janduplessis886/gp_surgery_reviews_fake_and_real.","url":"https://huggingface.co/datasets/janduplessis886/gp_surgery_reviews_fake_and_real","creator_name":"Jan du Plessis","creator_url":"https://huggingface.co/janduplessis886","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"amazon-food-reviews-dataset","keyword":"reviews","description":"\n\t\n\t\t\n\t\tDataset Card for \"Amazon Food Reviews\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be used for numerous tasks like sentiment analysis, text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhan21/amazon-food-reviews-dataset.","url":"https://huggingface.co/datasets/jhan21/amazon-food-reviews-dataset","creator_name":"misschestnut","creator_url":"https://huggingface.co/jhan21","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Open-Omega-Forge-1M","keyword":"science","description":"\n\n\t\n\t\t\n\t\tOpen-Omega-Forge-1M\n\t\n\n\nOpen-Omega-Forge-1M is a carefully curated and optimized collection derived from multiple high-quality datasets, specifically designed to enhance reasoning capabilities across mathematical, scientific, and coding domains. This dataset represents a focused subset that maintains the quality and diversity of reasoning patterns while providing a more manageable size for training and evaluation. A high-quality, compact reasoning dataset designed for mathematics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Open-Omega-Forge-1M.","url":"https://huggingface.co/datasets/prithivMLmods/Open-Omega-Forge-1M","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Spurline","keyword":"science","description":"Spurline is a dataset containing complex responses, emphasizing logical reasoning and using Shining Valiant's friendly, magical personality style.\nThe 2024-10-30 version contains:\n\n10.7k rows of synthetic queries, using randomly selected prompts from migtissera/Synthia-v1.5-I and responses generated using Llama 3.1 405b Instruct.\n\nThis dataset contains synthetically generated data and has not been subject to manual review.\n","url":"https://huggingface.co/datasets/sequelbox/Spurline","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"AtomicGPT-3.0_Dataset","keyword":"science","description":"Atomic-Ai/AtomicGPT-3.0_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Atomic-Ai/AtomicGPT-3.0_Dataset","creator_name":"Atomic Ai Studios","creator_url":"https://huggingface.co/Atomic-Ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"SciDA","keyword":"science","description":"m-a-p/SciDA dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/m-a-p/SciDA","creator_name":"Multimodal Art Projection","creator_url":"https://huggingface.co/m-a-p","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"academic-section-classification","keyword":"science","description":"\n\t\n\t\t\n\t\tDataset for Classification of Sections of Academic Papers\n\t\n\nA dataset mapping sections of academic papers to one of the following section types:\n0: Introduction 1: Background 2: Methodology 3: Experiments and Results 4: Conclusion \nThe dataset was collected by taking the GROBID parses of academic papers in the ACL-OCL dataset and matching the section headings to one of the synonyms of each section type. Sections that did not have a match were disregarded. The following synonyms are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nhop/academic-section-classification.","url":"https://huggingface.co/datasets/nhop/academic-section-classification","creator_name":"Niklas Hoepner","creator_url":"https://huggingface.co/nhop","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Yelp_Reviews_for_Binary_Senti_Analysis","keyword":"reviews","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThe Yelp reviews polarity dataset is constructed by considering stars 1 and 2 negative, and 3 and 4 positive. For each polarity 280,000 training samples and 19,000 testing samples are take randomly. In total there are 560,000 trainig samples and 38,000 testing samples. Negative polarity is class 1, and positive class 2.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe files train.csv and test.csv contain all the training samples as comma-sparated values. There are 2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yassiracharki/Yelp_Reviews_for_Binary_Senti_Analysis.","url":"https://huggingface.co/datasets/yassiracharki/Yelp_Reviews_for_Binary_Senti_Analysis","creator_name":"yassir acharki","creator_url":"https://huggingface.co/yassiracharki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"scidocs-keywords-exkeyliword","keyword":"science","description":"\n\t\n\t\t\n\t\tSciDocs Keywords exKEYliWORD\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSciDocs2Keywords is a dataset consisting of scientific papers (title and abstract) and their associated author-provided keywords. It is designed for use in task of keyword extraction or abstraction.\nEach entry in the dataset includes:\n\nTitle: The title of the scientific paper.\nAbstract: A brief summary of the paper.\nAuthor Keywords: Keywords provided by the authors to highlight the main topics or concepts of the paper.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicolauduran45/scidocs-keywords-exkeyliword.","url":"https://huggingface.co/datasets/nicolauduran45/scidocs-keywords-exkeyliword","creator_name":"Nicolau Duran","creator_url":"https://huggingface.co/nicolauduran45","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-994884","keyword":"science","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-994884 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-994884 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-994884.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-994884","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MM-MathInstruct","keyword":"science","description":"\n\t\n\t\t\n\t\tMathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning\n\t\n\nRepo: https://github.com/mathllm/MathCoder\nPaper: https://huggingface.co/papers/2505.10557\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWe introduce MathCoder-VL, a series of open-source large multimodal models (LMMs) specifically tailored for general math problem-solving. We also introduce FigCodifier-8B, an image-to-code model.\n\n\t\n\t\t\nBase Model\nOurs\n\n\n\t\t\nMini-InternVL-Chat-2B-V1-5\nMathCoder-VL-2B\n\n\nInternVL2-8B‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MM-MathInstruct.","url":"https://huggingface.co/datasets/MathLLMs/MM-MathInstruct","creator_name":"LLMs for Reasoning","creator_url":"https://huggingface.co/MathLLMs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","visual-question-answering","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"discoverybench","keyword":"science","description":"\n\t\n\t\t\n\t\tDiscoveryBench - Alias\n\t\n\nA reformatted version of the original DiscoveryBench dataset for easier usage.\n\nü§ó  Original Dataset on HF  \nüíª GitHub Repository  \nüìÑ Paper (arXiv)\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìÅ Dataset Structure\n\t\n\nThe dataset consists of real and synthetic subsets:\nReal Splits:\n\nreal_train\nreal_test\n\nSynthetic Splits:\n\nsynth_train\nsynth_dev\nsynth_test\n\nEach split contains a list of tasks with references to associated CSV datasets needed to answer the query. LLMs are expected to use the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nhop/discoverybench.","url":"https://huggingface.co/datasets/nhop/discoverybench","creator_name":"Niklas Hoepner","creator_url":"https://huggingface.co/nhop","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","English","odc-by","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Math-Question-Answer","keyword":"science","description":"Aixr/Math-Question-Answer dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Aixr/Math-Question-Answer","creator_name":"Aixr AI","creator_url":"https://huggingface.co/Aixr","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Science-QnA","keyword":"science","description":"\n\t\n\t\t\n\t\t169Pi-Science-QnA\n\t\n\nThe 169Pi-Science-QnA is a large-scale, high-quality science-focused dataset (~5.63M rows) curated using synthetic data generation through distillation techniques and select open-source resources. Designed to train and evaluate reasoning-capable models in science domains with emphasis on conceptual understanding, numerical problem-solving, and exam-style Q&A patterns across Physics, Chemistry, Biology, and Mathematics.\n\n\t\n\t\t\n\t\n\t\n\t\tSummary\n\t\n\n‚Ä¢ Domain: Science‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/169Pi/Science-QnA.","url":"https://huggingface.co/datasets/169Pi/Science-QnA","creator_name":"169Pi","creator_url":"https://huggingface.co/169Pi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"dblp_aminer_triplets","keyword":"science","description":"vaios-stergio/dblp_aminer_triplets dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/vaios-stergio/dblp_aminer_triplets","creator_name":"Vaios Stergiopoulos","creator_url":"https://huggingface.co/vaios-stergio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","sentence-similarity","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-128-24","keyword":"science","description":"\n\t\n\t\t\n\t\tscidocs-c-128-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for scientific papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-128-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-128-24.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Poseidon-Reasoning-Mini-300K","keyword":"science","description":"\n\n\t\n\t\t\n\t\tPoseidon-Reasoning-Mini-300K\n\t\n\n\nPoseidon-Reasoning-Mini-300K is a compact, high-quality reasoning dataset designed for advanced tasks in mathematics, coding, and science. This smaller-scale collection maintains the depth and quality of its larger counterparts, with a focus on multi-step and general reasoning‚Äîmaking it ideal for model pretraining, fine-tuning, benchmarking, and STEM educational applications.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tQuick Start with Hugging Face Datasetsü§ó\n\t\n\npip install -U‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Poseidon-Reasoning-Mini-300K.","url":"https://huggingface.co/datasets/prithivMLmods/Poseidon-Reasoning-Mini-300K","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Burmese-General-Reviews","keyword":"reviews","description":"\n\t\n\t\t\n\t\tBurmese General Reviews\n\t\n\nA collection of 5k e-commerce reviews. Only a portion has been uploaded.\n‚ö´‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ 13.9%\n(695/5,000)\nThis dataset card aims to be of value to NLP endeavors in Burmese.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSourced from various e-commerce platforms and communities. Uses Burmese Unicode. \nThe reviews are normalized with [product], and [seller] in place of original names and products (this is still a work in progress)\nBecause the data comes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rickaym/Burmese-General-Reviews.","url":"https://huggingface.co/datasets/Rickaym/Burmese-General-Reviews","creator_name":"Pyae Sone Myo","creator_url":"https://huggingface.co/Rickaym","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Burmese","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"walmart-reviews-dataset","keyword":"reviews","description":"\n\t\n\t\t\n\t\tüõí Walmart Product Reviews Dataset (6.7K Records)\n\t\n\nThis dataset contains 6,700+ structured customer reviews from Walmart.com. Each entry includes product-level metadata along with review details, making it ideal for small-scale machine learning models, sentiment analysis, and ecommerce insights.\n\n\n\t\n\t\t\n\t\tüìë Dataset Fields\n\t\n\n\n\t\n\t\t\nColumn\nDescription\n\n\n\t\t\nurl\nDirect product page URL\n\n\nname\nProduct name/title\n\n\nsku\nProduct SKU (Stock Keeping Unit)\n\n\nprice\nProduct price (numeric, USD)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/crawlfeeds/walmart-reviews-dataset.","url":"https://huggingface.co/datasets/crawlfeeds/walmart-reviews-dataset","creator_name":"Crawl Feeds","creator_url":"https://huggingface.co/crawlfeeds","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-512-192-gpt-4o-2024-05-13-650620","keyword":"science","description":"\n\t\n\t\t\n\t\tSCIDOCS-512-192-gpt-4o-2024-05-13-650620 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"arxiv paper domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-512-192-gpt-4o-2024-05-13-650620 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-650620.","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-650620","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Celestia3-DeepSeek-R1-0528","keyword":"science","description":"Click here to support our open-source dataset and model releases!\nCelestia3-DeepSeek-R1-0528 is a dataset focused on science, testing the limits of DeepSeek R1 0528's science-reasoning skills!\nThis dataset contains:\n\n90.9k synthetically generated science prompts, with all responses generated using DeepSeek R1 0528.\nPrimary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\nAll prompts are synthetic, taken‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Celestia3-DeepSeek-R1-0528.","url":"https://huggingface.co/datasets/sequelbox/Celestia3-DeepSeek-R1-0528","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Demeter-LongCoT-400K","keyword":"science","description":"\n\n\t\n\t\t\n\t\tDemeter-LongCoT-400K\n\t\n\n\nDemeter-LongCoT-400K is a high-quality, compact chain-of-thought reasoning dataset curated for tasks in mathematics, science, and coding. While the dataset spans diverse domains, it is primarily driven by mathematical reasoning, reflecting a major share of math-focused prompts and long-form logical solutions.\n\n\n\t\n\t\t\n\t\n\t\n\t\tQuick Start with Hugging Face Datasetsü§ó\n\t\n\npip install -U datasets\n\nfrom datasets import load_dataset\n\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Demeter-LongCoT-400K.","url":"https://huggingface.co/datasets/prithivMLmods/Demeter-LongCoT-400K","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_8th","keyword":"science","description":"KadamParth/NCERT_Science_8th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_8th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"aifgen","keyword":"science","description":"\n\t\n\t\t\n\t\tDataset Card for aif-gen static dataset\n\t\n\n\n\nThis dataset is a set of static RLHF datasets used to generate continual RLHF datasets for benchmarking Lifelong RL on language models. \nThe data used in the paper can be found under the directory 4omini_generation and the rest are included for reference and are used in the experiments for the paper.\nThe continual datasets created for benchmarking can be found with their dataset cards in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LifelongAlignment/aifgen.","url":"https://huggingface.co/datasets/LifelongAlignment/aifgen","creator_name":"Lifelong Alignment of Agents","creator_url":"https://huggingface.co/LifelongAlignment","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"openrelay-dataset","keyword":"reviews","description":"\n\t\n\t\t\n\t\tOpenRelay Dataset\n\t\n\nThe OpenRelay Dataset is a collection of curated articles, tool reviews, user comments, and productivity-related content sourced from the OpenRelay platform. It‚Äôs designed to support training and evaluation of machine learning models for tasks such as text classification, summarization, semantic search, and question answering in the context of tech and productivity tools.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nEach entry in the dataset may include fields like:\n\ntitle:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openrelay/openrelay-dataset.","url":"https://huggingface.co/datasets/openrelay/openrelay-dataset","creator_name":"openrelay","creator_url":"https://huggingface.co/openrelay","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","summarization","question-answering","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"VisualWebInstruct","keyword":"science","description":"\n\t\n\t\t\n\t\tVisualWebInstruct: Scaling up Multimodal Instruction Data through Web Search\n\t\n\nVisualWebInstruct is a large-scale, diverse multimodal instruction dataset designed to enhance vision-language models' reasoning capabilities. The dataset contains approximately 900K question-answer (QA) pairs, with 40% consisting of visual QA pairs associated with 163,743 unique images, while the remaining 60% are text-only QA pairs.\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nGitHub Repository\nResearch Paper\nProject Website‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct.","url":"https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","image-text-to-text","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MMMU-Thai","keyword":"science","description":"\n\t\n\t\t\n\t\tMMMU Thai (MMMU Benchmark Translated to Thai)\n\t\n\nMMMU Thai is a dataset for evaluating multimodal models on massive multi-discipline tasks requiring college-level knowledge and deliberate reasoning. This dataset is translated from MMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI) into Thai.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nMMMU Thai consists of 11,500 meticulously collected multimodal questions from college exams, quizzes, and textbooks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iapp/MMMU-Thai.","url":"https://huggingface.co/datasets/iapp/MMMU-Thai","creator_name":"iApp Technology","creator_url":"https://huggingface.co/iapp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","Thai","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MNLP_M3_quantized_dataset","keyword":"science","description":"\n\t\n\t\t\n\t\tEnhanced MCQA Test Dataset for Comprehensive Model Evaluation\n\t\n\nThis dataset contains 400 carefully selected test samples from MetaMathQA, AQuA-RAT, OpenBookQA, and SciQ datasets, designed for comprehensive MCQA (Multiple Choice Question Answering) model evaluation and quantization testing across multiple domains.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Samples: 400\nMetaMathQA Samples: 100 (mathematical problems)\nAQuA-RAT Samples: 100 (algebraic word problems)\nOpenBookQA Samples: 100‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlirezaAbdollahpoor/MNLP_M3_quantized_dataset.","url":"https://huggingface.co/datasets/AlirezaAbdollahpoor/MNLP_M3_quantized_dataset","creator_name":"Alireza Abdollahopoorrostam","creator_url":"https://huggingface.co/AlirezaAbdollahpoor","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-204265","keyword":"science","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-204265 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-204265 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-204265.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-204265","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"teach-science-v1","keyword":"science","description":"\n\t\n\t\t\n\t\tCanis.teach Science Dataset\n\t\n\nSimple synthetic dataset for training Science tutoring models.\n\nProject: Canis.teach - Learning that fits.\nSubject: Science\nGenerated with: Canis.lab\nFormat: Simple ID:content pairs\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{\n  \"id\": \"unique_identifier\",\n  \"content\": \"tutoring conversation text\"\n}\n\nThis dataset contains educational conversations focused on Science topics, designed to teach effective tutoring behavior rather than just providing direct answers.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CanisAI/teach-science-v1.","url":"https://huggingface.co/datasets/CanisAI/teach-science-v1","creator_name":"Canis","creator_url":"https://huggingface.co/CanisAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"OpenThoughts3-1.2M","keyword":"science","description":"\n    \n\n\n\npaper |\ndataset |\nmodel\n\n\n\n[!NOTE]\nWe have released a paper for OpenThoughts! See our paper here.\n\n\n \n\n\n\n\n\t\n\t\n\t\n\t\tOpenThoughts3-1.2M\n\t\n\nOpen-source state-of-the-art reasoning dataset with 1.2M rows. üöÄ\nOpenThoughts3-1.2M is the third iteration in our line of OpenThoughts datasets, building on our previous OpenThoughts-114k and OpenThoughts2-1M.\nThis time around, we scale even further and generate our dataset in a much more systematic way -- OpenThoughts3-1.2M is the result of a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/open-thoughts/OpenThoughts3-1.2M.","url":"https://huggingface.co/datasets/open-thoughts/OpenThoughts3-1.2M","creator_name":"Open Thoughts","creator_url":"https://huggingface.co/open-thoughts","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Pitchfork","keyword":"reviews","description":"\n\t\n\t\t\n\t\tDataset Card for Pitchfork\n\t\n\n~14k album reviews.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nApproximately 14 thousand album reviews and scores from Pitchfork\n\nCurated by: hlky\nLicense: Open Data Commons Attribution License (ODC-By) v1.0\n\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@misc{Pitchfork,\n  author = {hlky},\n  title = {Pitchfork},\n  year = {2024},\n  publisher = {hlky},\n  journal = {Hugging Face repository},\n  howpublished =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bigdata-pw/Pitchfork.","url":"https://huggingface.co/datasets/bigdata-pw/Pitchfork","creator_name":"BIG data","creator_url":"https://huggingface.co/bigdata-pw","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","odc-by","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SciFact-512-192-gpt-4o-2024-05-13-866232","keyword":"science","description":"\n\t\n\t\t\n\t\tSciFact-512-192-gpt-4o-2024-05-13-866232 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-512-192-gpt-4o-2024-05-13-866232 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-866232.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-866232","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scicom-contrast-qa","keyword":"science","description":"\n\t\n\t\t\n\t\tSciCom Contrast QA Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a merged collection of contrast-based learning pairs for distinguishing correct from incorrect answers from multiple high-quality QA benchmarks. It combines data from 4 different sources into a unified contrastive learning format with negative sampling.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis merged dataset combines the following benchmarks:\n\nCommonsenseQA: commonsense reasoning questions (tau/commonsense_qa)\nOpenBookQA:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sungyub/scicom-contrast-qa.","url":"https://huggingface.co/datasets/sungyub/scicom-contrast-qa","creator_name":"sungyub kim","creator_url":"https://huggingface.co/sungyub","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","tau/commonsense_qa","allenai/openbookqa","allenai/qasc"],"keywords_longer_than_N":true},
	{"name":"nlp_taxonomy_data","keyword":"science","description":"\n\t\n\t\t\n\t\tNLP Taxonomy Classification Data\n\t\n\nThe dataset consists of titles and abstracts from NLP-related papers. Each paper is annotated with multiple fields of study from the NLP taxonomy. Each sample is annotated with all possible lower-level concepts and their hypernyms in the NLP taxonomy. The training dataset contains 178,521 weakly annotated samples. The test dataset consists of 828 manually annotated samples from the EMNLP22 conference. The manually labeled test dataset might not‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TimSchopf/nlp_taxonomy_data.","url":"https://huggingface.co/datasets/TimSchopf/nlp_taxonomy_data","creator_name":"Tim Schopf","creator_url":"https://huggingface.co/TimSchopf","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"multiscale_rotten_tomatoes_critic_reviews","keyword":"reviews","description":"Cleaned up version of the rotten tomatoes critic reviews dataset. The original\nis obtained from Kaggle:\nhttps://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset\nData has been scraped from the publicly available website\nhttps://www.rottentomatoes.com as of 2020-10-31.\nThe clean up process drops anything without both a review and a rating, as well\nas standardising the ratings onto several integer, ordinal scales.\nRequires the kaggle library to be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/frankier/multiscale_rotten_tomatoes_critic_reviews.","url":"https://huggingface.co/datasets/frankier/multiscale_rotten_tomatoes_critic_reviews","creator_name":"Frankie Robertson","creator_url":"https://huggingface.co/frankier","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-scoring","sentiment-scoring","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"dataclysm-pubmed","keyword":"science","description":"\n\t\n\t\t\n\t\tDATACLYSM PATCH 0.0.4: PUBMED\n\t\n\n\n\t\n\t\t\n\t\tUSE THE NOTEBOOK TO GET STARTED!\n\t\n\nhttps://github.com/somewheresystems/dataclysm\n\n\t\n\t\t\n\t\tsomewheresystems/dataclysm-pubmed\n\t\n\nThis dataset comprises of 35.7 million PubMed metadata entries including title and some (~69% with) abstracts, with two new columns added: title-embeddings and abstract-embeddings. These additional columns were generated using the bge-small-en-v1.5 embeddings model. The dataset was sourced from the PubMed Baseline as of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somewheresystems/dataclysm-pubmed.","url":"https://huggingface.co/datasets/somewheresystems/dataclysm-pubmed","creator_name":"S2","creator_url":"https://huggingface.co/somewheresystems","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10M<n<100M","üá∫üá∏ Region: US","pubmed"],"keywords_longer_than_N":true},
	{"name":"arxiv_categories","keyword":"science","description":"üìÑ Paper: Efficient Few-shot Learning for Multi-label Classification of Scientific Documents with Many Classes (ICNLSP 2024)\nüíª GitHub: https://github.com/sebischair/FusionSent\nThis is a dataset of scientific documents derived from arXiv metadata. The arXiv metadata provides information about more than 2 million scholarly articles published in arXiv from various scientific fields. We use this metadata to create a dataset of 203,961 titles and abstracts categorized into 130 different classes.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TimSchopf/arxiv_categories.","url":"https://huggingface.co/datasets/TimSchopf/arxiv_categories","creator_name":"Tim Schopf","creator_url":"https://huggingface.co/TimSchopf","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-1562024-to89-webapp","keyword":"science","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-1562024-to89-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific research in medicine, biology, and technology\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-1562024-to89-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1562024-to89-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1562024-to89-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"food_reviews-sentiment-analysis","keyword":"reviews","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\n\nTopic: Food Reviews\nDomains: Fast Food, Fine Dining, Home Cooking\nFocus: This dataset contains food reviews for different styles of cooking.\nNumber of Entries: 500\nDataset Type: Sentiment Analysis Dataset\nModel Used: bedrock/us.amazon.nova-pro-v1:0\nLanguage: English\nAdditional Information: The dataset is designed to help analyze the sentiment of reviews across various food styles.\nGenerated by: SynthGenAI Package\n\n","url":"https://huggingface.co/datasets/Shekswess/food_reviews-sentiment-analysis","creator_name":"Bojan Jakimovski","creator_url":"https://huggingface.co/Shekswess","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"turkish-comprehensive-movie-series-dataset","keyword":"reviews","description":"\n\t\n\t\t\n\t\tBeyazperde Film & Series Dataset\n\t\n\nThis dataset contains a comprehensive collection of Turkish films and TV series from Beyazperde.com, including detailed information about movies, series, cast, reviews, and ratings.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Movies: 27,227\nTotal Series: 11,240\nTotal Entries: 38,467\nFile Size: ~222 MB\nFormat: JSONL (JSON Lines)\nLanguage: Turkish\nSource: Beyazperde.com\n\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach line in the JSONL file contains a JSON object with either a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pkchwy/turkish-comprehensive-movie-series-dataset.","url":"https://huggingface.co/datasets/pkchwy/turkish-comprehensive-movie-series-dataset","creator_name":"Salih Mert Canseven","creator_url":"https://huggingface.co/pkchwy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","Turkish","English"],"keywords_longer_than_N":true},
	{"name":"sentiment-polarity-dataset-v2.0","keyword":"reviews","description":"\n\t\n\t\t\n\t\tSentiment Polarity Dataset Version 2.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is available on NLTK as the \"movie_reviews\" dataset. The Sentiment Polarity Dataset Version 2.0 was developed by Bo Pang and Lillian Lee. I'm uploading it as a Huggingface dataset for a lab task.\nThe following information is from the README file distributed with the NLTK version of the data-set.\n=======\n\n\t\n\t\t\n\t\n\t\n\t\tData Format Summary\n\t\n\n  File names consist of a cross-validation tag plus the name of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/polsci/sentiment-polarity-dataset-v2.0.","url":"https://huggingface.co/datasets/polsci/sentiment-polarity-dataset-v2.0","creator_name":"Geoff Ford","creator_url":"https://huggingface.co/polsci","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"merfish","keyword":"science","description":"\n\t\n\t\t\n\t\tMERFISH Mouse Brain Dataset\n\t\n\nThis dataset provides spatial transcriptomic profiles of the adult mouse brain using MERFISH (Multiplexed Error-Robust Fluorescence In Situ Hybridization), enabling high-resolution cellular gene expression analysis in situ. The MERFISH data consists of 59 coronal sections (10 micron thick) covering the whole anterior to posterior extent of the brain (~200 micron apart) from a single adult male mouse.\nIt includes both raw and processed versions of the data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cgeorgiaw/merfish.","url":"https://huggingface.co/datasets/cgeorgiaw/merfish","creator_name":"Georgia Channing","creator_url":"https://huggingface.co/cgeorgiaw","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["other","English","cc-by-4.0","üá∫üá∏ Region: US","biology"],"keywords_longer_than_N":true},
	{"name":"MAiDE-up","keyword":"reviews","description":"\n\t\n\t\t\n\t\tDataset Card for MAiDE-up: Multilingual Deception Detection of GPT-generated Hotel Reviews\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMultilingual Deception Detection of GPT-generated Hotel Reviews. We compare real hotel reviews from Booking with LLM-generated hotel reviews in 10 languages.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in 10 languages: Chinese, English, French, German, Italian, Romanian, Korean, Russian, Spanish, Turkish\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTODO‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MichiganNLP/MAiDE-up.","url":"https://huggingface.co/datasets/MichiganNLP/MAiDE-up","creator_name":"LIT @ UMich","creator_url":"https://huggingface.co/MichiganNLP","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"ru_biosses_sts","keyword":"science","description":"–≠—Ç–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–∞—è –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ –≤–µ—Ä—Å–∏—è mteb/biosses-sts - Biomedical Semantic Similarity Estimation.\n–ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π ( —á–µ—Ä–µ–∑ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ):\n\n\t\n\t\t\n–ú–æ–¥–µ–ª—å (cls-pooling)\nPearson\nSpearman\nMAE\nRMSE\n\n\n\t\t\njinaai/jina-embeddings-v3\n0.8222\n0.7768\n2.2463\n2.4468\n\n\ncointegrated/rubert-tiny2\n0.6897\n0.6793\n2.1546\n2.3944\n\n\nDeepPavlov/rubert-base-cased\n0.2982\n0.4966\n2.7042\n2.9374\n\n\nai-forever/ruRoberta-large\n-0.0096\n0.0219\n2.3931\n2.6905\n\n\n\t\n\n\n\t\n\t\t\n–ú–æ–¥–µ–ª—å  (mean-pooling)\nPearson\nSpearman\nMAE‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kostya165/ru_biosses_sts.","url":"https://huggingface.co/datasets/Kostya165/ru_biosses_sts","creator_name":"pleroma_cascade","creator_url":"https://huggingface.co/Kostya165","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","Russian","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"rag-qa-arena","keyword":"science","description":"\n\t\n\t\t\n\t\tRAG QA Arena Annotated Dataset\n\t\n\nA comprehensive multi-domain question-answering dataset with citation annotations designed for evaluating Retrieval-Augmented Generation (RAG) systems, featuring faithful answers with proper source attribution across 6 specialized domains.\n\n\t\n\t\t\n\t\tüéØ Dataset Overview\n\t\n\nThis annotated version of the RAG QA Arena dataset includes citation information and gold document IDs, making it ideal for evaluating not just answer accuracy but also answer grounding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rajistics/rag-qa-arena.","url":"https://huggingface.co/datasets/rajistics/rag-qa-arena","creator_name":"Rajiv Shah","creator_url":"https://huggingface.co/rajistics","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ifpri-ai-documents","keyword":"science","description":"Documents: 12,007\nPages: 362,716\nTokens: 75,284,385 \n\n\t\n\t\t\n\t\tA Curated Research Corpus for Agricultural Advisory AI Applications\n\t\n\nEach document has been systematically processed using GROBID to extract \nstructured content while preserving critical scientific context, metadata, and domain-specific agricultural knowledge. Morever, chunking\nmethods that preserver the semantic coherence have been applied. More specifically, documents are split \ninto chunks based on a fixed number of tokens and a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CGIAR/ifpri-ai-documents.","url":"https://huggingface.co/datasets/CGIAR/ifpri-ai-documents","creator_name":"CGIAR","creator_url":"https://huggingface.co/CGIAR","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","10M<n<100M","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc","keyword":"science","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for scientific papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SFE","keyword":"science","description":"\n\t\n\t\t\n\t\tScientists' First Exam: Probing Cognitive Abilities of MLLM via Perception, Understanding, and Reasoning\n\t\n\n\n  \n\n\n\n| Leaderboard | Paper  | Website  | HuggingFace  |\n\n\n\n\nLatest News üî•\n[Latest] We are officially integrated by VLMEvalKit. Intern-S1, the most advanced open-source multimodal reasoning model to date, benchmarked on SFE.\nUnfold to see more details.\n\n\n\n[2025/07] Intern-S1, the most advanced open-source multimodal reasoning model to date, benchmarked on SFE.\n[2025/07] We are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PrismaX/SFE.","url":"https://huggingface.co/datasets/PrismaX/SFE","creator_name":"PrismaX","creator_url":"https://huggingface.co/PrismaX","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","Chinese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"KhmunuChronicles","keyword":"science","description":"Svngoku/KhmunuChronicles dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Svngoku/KhmunuChronicles","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","French","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Helios-R-6M","keyword":"science","description":"\n\n\t\n\t\t\n\t\tHelios-R-6M\n\t\n\n\nHelios-R-6M is a high-quality, compact reasoning dataset designed to strengthen multi-step problem solving across mathematics, computer science, and scientific inquiry. While the dataset covers a range of disciplines, math constitutes the largest share of examples and drives the reasoning complexity.\n\n\n\n\t\n\t\t\n\t\tQuick Start with Hugging Face Datasetsü§ó\n\t\n\npip install -U datasets\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"prithivMLmods/Helios-R-6M\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Helios-R-6M.","url":"https://huggingface.co/datasets/prithivMLmods/Helios-R-6M","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"gardian-ai-ready-docs","keyword":"science","description":"\n\n\t\n\t\t\n\t\t‚ö†Ô∏è Heads up: Updated Dataset Available\n\t\n\nThis dataset has been updated with a newer version published on 27 Feb 2025. The latest version includes more updated and refined set of documents.\nWe recommend using the latest version, available at https://huggingface.co/datasets/CGIAR/gardian-cigi-ai-documents. This version remains accessible for reference and reproducibility purposes.\n\n\n\t\n\t\t\n\t\n\t\n\t\tA Curated Research Corpus for Agricultural Advisory AI Applications\n\t\n\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CGIAR/gardian-ai-ready-docs.","url":"https://huggingface.co/datasets/CGIAR/gardian-ai-ready-docs","creator_name":"CGIAR","creator_url":"https://huggingface.co/CGIAR","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"aifgen-domain-preference-shift","keyword":"science","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset is a continual dataset in a mixed non stationarity scenario of both domains and preferences given a combination of given two tasks:\n\nDomain: Education (math, sciences, and social sciences), Objective: QnA, Preference: Explain like I'm 5 answer\nDomain: Education (math, sciences, and social sciences), Objective: QnA, Preference: Expert answer\nDomain: Politics, Objective: Summary, Preference: Explain like I'm 5 answer\nDomain: Politics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LifelongAlignment/aifgen-domain-preference-shift.","url":"https://huggingface.co/datasets/LifelongAlignment/aifgen-domain-preference-shift","creator_name":"Lifelong Alignment of Agents","creator_url":"https://huggingface.co/LifelongAlignment","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Open-Omega-Explora-2.5M","keyword":"science","description":"\n\n\t\n\t\t\n\t\tOpen-Omega-Explora-2.5M\n\t\n\n\nOpen-Omega-Explora-2.5M is a high-quality, large-scale reasoning dataset blending the strengths of both Open-Omega-Forge-1M and Open-Omega-Atom-1.5M. This unified dataset is crafted for advanced tasks in mathematics, coding, and science reasoning, featuring a robust majority of math-centric examples. Its construction ensures comprehensive coverage and balanced optimization for training, evaluation, and benchmarking in AI research, STEM education, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Open-Omega-Explora-2.5M.","url":"https://huggingface.co/datasets/prithivMLmods/Open-Omega-Explora-2.5M","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"WebInstruct-verified-unfiltered","keyword":"science","description":"This repo contains the unfiltered version WebInstruct-verified in the General Reasoner work.\n\n\t\n\t\t\n\t\tGeneral-Reasoner: Advancing LLM Reasoning Across All Domains\n\t\n\n\n  üíª Code |\n  üìÑ Paper |\n  üìä Dataset |\n  ü§ó Model |\n  üåê Project Page\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\n\n  \n\n\n  \n    Figure: Effectiveness of General-Reasoner trained with diverse verifiable reasoning questions using model-based verifier compared to baseline methods on various reasoning tasks.\n  General-Reasoner is a training paradigm‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/WebInstruct-verified-unfiltered.","url":"https://huggingface.co/datasets/TIGER-Lab/WebInstruct-verified-unfiltered","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"team-truthowl-mixed-reasoning-dataset","keyword":"science","description":"\n\t\n\t\t\n\t\tTeam P11 Mixed Reasoning Dataset\n\t\n\n\n\t\n\t\t\n\t\tüìä Dataset description\n\t\n\nHLEÔºàHumanity's Last ExamÔºâÂêë„Åë„Å´‰ΩúÊàê„Åó„Åü„ÄÅÊï∞Â≠¶‰∏≠ÂøÉÔºãÁßëÂ≠¶MC„ÅÆÊ∑∑ÂêàÊé®Ë´ñ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ\nÊé®Ë´ñÈÅéÁ®ãÔºàChain-of-ThoughtÔºâ„Çí‰øùÊåÅ„Åó„ÄÅÊúÄÁµÇËß£Á≠î„ÅÆÊ≠£Ë¶èÂåñ„ÇíË°å„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ\nÂØæË±°„É¢„Éá„É´„ÅØ DeepSeek-R1-Distill-Qwen-32B„ÄÅÂ≠¶Áøí„ÅØQLoRA„ÇíÊÉ≥ÂÆö„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n\n\t\n\t\t\n\t\tüéØ Purpose\n\t\n\n\nCompetition: ÊùæÂ∞æÁ†îLLM„Ç≥„É≥„Éö 2025  \nTarget Model: DeepSeek-R1-Distill-Qwen-32B  \nTraining Method: QLoRA Fine-tuningÔºà4bit NF4, double quantÔºâ\n\n\n\t\n\t\t\n\t\tüì¶ Composition\n\t\n\n\nMath HardÔºàMATH Level‚â•3, HARDMathÔºâ  \nMath MidÔºàGSM8K, MetaMathQAÔºâ  \nScienceÔºàGPQA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/weblab-llm-competition-2025-bridge/team-truthowl-mixed-reasoning-dataset.","url":"https://huggingface.co/datasets/weblab-llm-competition-2025-bridge/team-truthowl-mixed-reasoning-dataset","creator_name":"weblab-llm-competition-2025-bridge","creator_url":"https://huggingface.co/weblab-llm-competition-2025-bridge","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-526066","keyword":"science","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-526066 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-526066 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-526066.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-526066","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"protobowl-11-13","keyword":"science","description":"\n\t\n\t\t\n\t\tProgressive Quiz Bowl Clues Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains Quiz Bowl questions and their corresponding progressive clues, designed for evaluating question-answering systems.\nThe progressive clues subset contains additional features such as GPT-3.5 generated categories and subcategories specific to each progressive clue.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nName: protobowl-11-13\nVersion: 1.0\nMaintainer: mgor\nHub URL: https://huggingface.co/datasets/mgor/protobowl-11-13‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mgor/protobowl-11-13.","url":"https://huggingface.co/datasets/mgor/protobowl-11-13","creator_name":"Maharshi Gor","creator_url":"https://huggingface.co/mgor","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"VisualWebInstruct-Seed","keyword":"science","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis is the seed dataset we used to conduct Google Search.\n\n\t\n\t\t\n\t\tLinks\n\t\n\nGithub|\nPaper|\nWebsite\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@article{visualwebinstruct,\n    title={VisualWebInstruct: Scaling up Multimodal Instruction Data through Web Search},\n    author = {Jia, Yiming and Li, Jiachen and Yue, Xiang and Li, Bo and Nie, Ping and Zou, Kai and Chen, Wenhu},\n    journal={arXiv preprint arXiv:2503.10582},\n    year={2025}\n}\n\n","url":"https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct-Seed","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","image-text-to-text","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"EEE-Bench","keyword":"science","description":"\n\t\n\t\t\n\t\tEEE-Bench: A Comprehensive Multimodal Electrical And Electronics Engineering Benchmark\n\t\n\n\n\t\n\t\t\n\t\tIntroduction:\n\t\n\nEEE-Bench is a multimodal benchmark designed to evaluate the practical engineering capabilities of large multimodal models (LMMs), using electrical and electronics engineering (EEE) as the domain focus. It comprises 2,860 carefully curated problems across 10 core subdomains, including analog circuits and control systems, featuring complex visual inputs such as abstract‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/afdsafas/EEE-Bench.","url":"https://huggingface.co/datasets/afdsafas/EEE-Bench","creator_name":"Ming Li","creator_url":"https://huggingface.co/afdsafas","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","visual-question-answering","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"amazon-beauty-reviews-dataset","keyword":"reviews","description":"\n\t\n\t\t\n\t\tDataset Card for \"Amazon Beauty Reviews\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of reviews of \"All Beauty\" category from amazon. The data includes all ~700,000 reviews up to 2023. Reviews include product and user information, ratings, and a plain text review. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be used for numerous tasks like sentiment analysis, text classification, and user behavior analysis. It's particularly useful for training models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhan21/amazon-beauty-reviews-dataset.","url":"https://huggingface.co/datasets/jhan21/amazon-beauty-reviews-dataset","creator_name":"misschestnut","creator_url":"https://huggingface.co/jhan21","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","cc0-1.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"Poseidon-Reasoning-5M","keyword":"science","description":"\n\n\t\n\t\t\n\t\tPoseidon-Reasoning-5M\n\t\n\n\nPoseidon-Reasoning-5M is a high-quality, compact reasoning dataset curated for advanced applications in mathematics, coding, and science. The dataset distinctly emphasizes mathematical and general reasoning challenges, ensuring its suitability for large language model (LLM) research, benchmarking, and STEM-focused educational tools.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tQuick Start with Hugging Face Datasetsü§ó\n\t\n\npip install -U datasets\n\nfrom datasets import load_dataset\n\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Poseidon-Reasoning-5M.","url":"https://huggingface.co/datasets/prithivMLmods/Poseidon-Reasoning-5M","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"MultiSimV2","keyword":"science","description":"\n\t\n\t\t\n\t\tDataset Card for MultiSim Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe MultiSim benchmark is a growing collection of text simplification datasets targeted at sentence simplification in several languages.  Currently, the benchmark spans 12 languages.\n\n\n\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\n\nSentence Simplification\n\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets importload_dataset\n\ndataset = load_dataset(\"MichaelR207/MultiSimV2\")\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this benchmark, please cite our paper:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MichaelR207/MultiSimV2.","url":"https://huggingface.co/datasets/MichaelR207/MultiSimV2","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text2text-generation","text-generation","English","French"],"keywords_longer_than_N":true},
	{"name":"ghana-news","keyword":"science","description":"\n\t\n\t\t\n\t\tDescription üôÖ‚Äç‚ôÇÔ∏èü§ñ\n\t\n\nGhanaNews dataset is a collection of news articles from various Ghanaian News Portals (MyJoyOnline, GraphicOnline, GhanaWeb, PulseGh, CitiNewsOnline, ect). The dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc), information retrieval (ranking, search, etc), xml, data compression, data streaming, and any other non-commercial activity.\nThe Ghana news topic classification dataset is constructed by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worldboss/ghana-news.","url":"https://huggingface.co/datasets/worldboss/ghana-news","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"gardian-cigi-ai-documents","keyword":"science","description":"Documents: 65,550\nPages: 1,780,047\nTokens: 343,498,673 \n\n\t\n\t\t\n\t\tA Curated Research Corpus for Agricultural Advisory AI Applications\n\t\n\nThis dataset represents a comprehensive collection of 65,550 agricultural research publications from CGIAR,\nspecifically processed and structured for Large Language Model (LLM) applications in agricultural advisory services. \nThis dataset bridges the gap between advanced agricultural research and field-level advisory needs, \ndrawing from CGIAR's extensive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CGIAR/gardian-cigi-ai-documents.","url":"https://huggingface.co/datasets/CGIAR/gardian-cigi-ai-documents","creator_name":"CGIAR","creator_url":"https://huggingface.co/CGIAR","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","10M<n<100M","doi:10.57967/hf/4327"],"keywords_longer_than_N":true},
	{"name":"arxiv-metadata-snapshot","keyword":"science","description":"\n\t\n\t\t\n\t\tDataset Card for \"arxiv-metadata-oai-snapshot\"\n\t\n\nMore Information needed\nThis is a mirror of the metadata portion of the arXiv dataset. \nThe sync will take place weekly so may fall behind the original datasets slightly if there are more regular updates to the source dataset. \n\n\t\n\t\t\n\t\n\t\n\t\tMetadata\n\t\n\nThis dataset is a mirror of the original ArXiv data. This dataset contains an entry for each paper, containing:\n\nid: ArXiv ID (can be used to access the paper, see below)\nsubmitter: Who‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/librarian-bots/arxiv-metadata-snapshot.","url":"https://huggingface.co/datasets/librarian-bots/arxiv-metadata-snapshot","creator_name":"Librarian Bots","creator_url":"https://huggingface.co/librarian-bots","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","English","cc0-1.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Atlas-Think-Cot-12M","keyword":"science","description":"\n\n\t\n\t\t\n\t\tAtlas-Think-Cot-12M\n\t\n\n\nAtlas-Think-Cot-12M is a large-scale, high-quality reasoning dataset curated for mathematical problem-solving, code generation, and scientific thinking. This dataset emphasizes step-by-step solutions and detailed reasoning, with a major share of mathematical problems guiding its structure and composition.\n\n\nMixture of Mathematics, Coding, and Science. [ <:think>/cot ]\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tQuick Start with Hugging Face Datasetsü§ó\n\t\n\npip install -U datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Atlas-Think-Cot-12M.","url":"https://huggingface.co/datasets/prithivMLmods/Atlas-Think-Cot-12M","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"modular-s2orc","keyword":"science","description":"\n\t\n\t\t\n\t\tDataset Card for Modular S2ORC\n\t\n\n\n\nTopically and temporally partitioned data from S2ORC, used for continued pre-training experiments in \"Scalable Data Ablation Approximations for Language Models through Modular Training and Merging\" to be presented at EMNLP 2024.\nValidation and test splits are determined by 'sha1' values in metadata.\nMore details to come.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/claran/modular-s2orc.","url":"https://huggingface.co/datasets/claran/modular-s2orc","creator_name":"Clara Na","creator_url":"https://huggingface.co/claran","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["English","odc-by","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"ScienceGlossary","keyword":"science","description":"\n\t\n\t\t\n\t\tDataset Card for Science Terms and Phrases Glossary\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset contains scientific terms and phrases from various disciplines, compiled from multiple sources.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset was created by web scraping scientific glossaries from sources like Wikipedia, NASA, and other academic references. Additionally, some terms were generated using ChatGPT-4.0.  \nIt is designed for token classification, meaning it includes both scientific‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JonyC/ScienceGlossary.","url":"https://huggingface.co/datasets/JonyC/ScienceGlossary","creator_name":"Jonatan Cohen","creator_url":"https://huggingface.co/JonyC","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"science_physics","keyword":"science","description":"deep-principle/science_physics dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/deep-principle/science_physics","creator_name":"Deep Principle","creator_url":"https://huggingface.co/deep-principle","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"SciGen-Figure","keyword":"science","description":"\n\t\n\t\t\n\t\tSciGen-Figures\n\t\n\nSciGen-Figures is an augmented version of the SciGen dataset, which includes images of table figures alongside the original text.\nThe dataset is designed for tasks that involve reasoning over scientific tables and generating text based on table figures. \nEach entry includes both the textual representation of a table and a corresponding image of the table. \nThe goal is to test LLM's ability to correctly reason over the textual and visual representation of scientific‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nhop/SciGen-Figure.","url":"https://huggingface.co/datasets/nhop/SciGen-Figure","creator_name":"Niklas Hoepner","creator_url":"https://huggingface.co/nhop","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"InqBench","keyword":"science","description":"InqModel/InqBench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/InqModel/InqBench","creator_name":"junjie Lu","creator_url":"https://huggingface.co/InqModel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-scidocs","keyword":"science","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-scidocs Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-scidocs model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scidocs.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scidocs","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Gargantua-R1-Compact","keyword":"science","description":"\n\n\n\n  Gargantua-R1 Distribution\n\n\n\n\n\n\n\n\n\t\n\t\n\t\n\t\tGargantua-R1-Compact(experimental purpose)\n\t\n\n\nGargantua-R1-Compact is a large-scale, high-quality reasoning dataset primarily designed for mathematical reasoning and STEM education. It contains approximately 6.67 million problems and solution traces, with a strong emphasis on mathematics (over 70%), as well as coverage of scientific domains, algorithmic challenges, and creative logic puzzles. The dataset is suitable for training and evaluating‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Gargantua-R1-Compact.","url":"https://huggingface.co/datasets/prithivMLmods/Gargantua-R1-Compact","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"natural-science-reasoning","keyword":"science","description":"\n\t\n\t\t\n\t\tNatural Sciences Reasoning: the \"smolest\" reasoning dataset\n\t\n\nA smol-scale open dataset for reasoning tasks using Hugging Face Inference Endpoints. While intentionally limited in scale, this resource prioritizes:\n\nReproducible pipeline for reasoning tasks using a variety of models (Deepseek V3, Deepsek-R1, Llama70B-Instruct, etc.)\n\nKnowledge sharing for domains other than Math and Code reasoning\n\n\nIn this repo, you can find:\n\nThe prompts and the pipeline (see the config file).\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dvilasuero/natural-science-reasoning.","url":"https://huggingface.co/datasets/dvilasuero/natural-science-reasoning","creator_name":"Daniel Vila","creator_url":"https://huggingface.co/dvilasuero","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"AstroChat","keyword":"science","description":"\n\t\n\t\t\n\t\tAstroChat Dataset Description\n\t\n\n\n\t\n\t\t\n\t\tPurpose and Scope\n\t\n\nThe AstroChat dataset is a collection of 901 dialogues, synthetically generated, tailored to the specific domain of Astronautics / Space Mission Engineering.\nThis dataset will be frequently updated following feedback from the community. If you would like to contribute, please reach out in the community discussion.\n\n\t\n\t\t\n\t\tIntended Use\n\t\n\nThe dataset is intended to be used for supervised fine-tuning of chat LLMs (Large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/patrickfleith/AstroChat.","url":"https://huggingface.co/datasets/patrickfleith/AstroChat","creator_name":"Patrick Fleith","creator_url":"https://huggingface.co/patrickfleith","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"CoTton-38k-6525-Collective","keyword":"science","description":"\n\t\n\t\t\n\t\tCoTton-38k-6525-Collective\n\t\n\nCoTton-38k is a 38,350-example dataset of soft reasoning conversations in the ShareGPT format. Each entry contains an exchange between a user and a model, showcasing high-quality Chain-of-Thought (CoT) reasoning in natural language.\nThe dataset is distilled from open LLMs:\n\nQwen3 235B A22B\nAM Thinking\nQwQ 32B\nDeepseek R1\nR1 0528\n\nThe name CoTton encodes multiple layers of meaning:\n\nCoT: Chain-of-Thought is embedded in the name\nTON: The dataset contains a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NewstaR/CoTton-38k-6525-Collective.","url":"https://huggingface.co/datasets/NewstaR/CoTton-38k-6525-Collective","creator_name":"Newstar Research ASIA","creator_url":"https://huggingface.co/NewstaR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Chinese-Herbal-Medicine-Sentiment","keyword":"reviews","description":"\n\t\n\t\t\n\t\t‰∏≠ËçØÊÉÖÊÑüÂàÜÊûêÊï∞ÊçÆÈõÜ - Êï∞ÊçÆËØ¥Êòé‰π¶\n\t\n\n\n\t\n\t\t\n\t\tChinese Herbal Medicine Sentiment Analysis Dataset - Datacard\n\t\n\n\n\t\n\t\t\n\t\tÊï∞ÊçÆÈõÜÊ¶ÇËø∞ / Dataset Overview\n\t\n\n\n\t\n\t\t\n\t\tÂü∫Êú¨‰ø°ÊÅØ / Basic Information\n\t\n\n\nÊï∞ÊçÆÈõÜÂêçÁß∞ / Dataset Name: Chinese Herbal Medicine Sentiment Analysis Dataset\nÁâàÊú¨ / Version: 1.0.0\nÂàõÂª∫Êó•Êúü / Created: 2025-08-26\n‰ΩúËÄÖ / Author: Xingqiang Chen\nËÆ∏ÂèØËØÅ / License: MIT\nËØ≠Ë®Ä / Language: ‰∏≠Êñá (Chinese)\nÈ¢ÜÂüü / Domain: ‰∏≠ËçØ / ‰º†Áªü‰∏≠ÂåªËçØ (Traditional Chinese Medicine)\n\n\n\t\n\t\t\n\t\n\t\n\t\tÊï∞ÊçÆËßÑÊ®° / Data Scale\n\t\n\n\nÊÄªÊ†∑Êú¨Êï∞ / Total Samples: 234,879\nÂîØ‰∏Ä‰∫ßÂìÅÊï∞ /‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenModels/Chinese-Herbal-Medicine-Sentiment.","url":"https://huggingface.co/datasets/OpenModels/Chinese-Herbal-Medicine-Sentiment","creator_name":"Turing Artificial Intelligence","creator_url":"https://huggingface.co/OpenModels","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","Chinese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"exambench","keyword":"science","description":"\n\t\n\t\t\n\t\tExamBench\n\t\n\nThe ExamBench Dataset (~600M tokens, 405k examples) is one of the largest open-source corpora designed for competitive exam preparation and reasoning AI. Generated using advanced distillation techniques, it combines structured chain-of-thought reasoning with comprehensive coverage of over 25 Indian and international examinations. From JEE and NEET to UPSC, Banking, GRE, and IELTS, the dataset spans multiple domains like STEM, humanities, current affairs, language, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/169Pi/exambench.","url":"https://huggingface.co/datasets/169Pi/exambench","creator_name":"169Pi","creator_url":"https://huggingface.co/169Pi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"YuLan-Mini-Text-Datasets","keyword":"science","description":"\n\t\n\t\t\n\t\tNews\n\t\n\n\n[2025.04.11] Add dataset mixture: link.\n[2025.03.30] Text datasets upload finished.\n\n\nThis is text dataset.\nËøôÊòØÊñáÊú¨Ê†ºÂºèÁöÑÊï∞ÊçÆÈõÜ„ÄÇ\nSince we have used BPE-Dropout, in order to ensure accuracy, you can find the tokenized dataset here.\nÁî±‰∫éÊàë‰ª¨‰ΩøÁî®‰∫ÜBPE-DropoutÔºå‰∏∫‰∫Ü‰øùËØÅÂáÜÁ°ÆÊÄßÔºå‰Ω†ÂèØ‰ª•Âú®ËøôÈáåÊâæÂà∞ÂàÜËØçÂêéÁöÑÊï∞ÊçÆ„ÄÇ\nFor more information, please refer to our datasets details and preprocess details.\n\n\n\t\t\n\t\tContributing\n\t\n\nWe welcome any form of contribution, including feedback on model bad cases, feature suggestions, and example‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yulan-team/YuLan-Mini-Text-Datasets.","url":"https://huggingface.co/datasets/yulan-team/YuLan-Mini-Text-Datasets","creator_name":"RUC-GSAI-YuLan","creator_url":"https://huggingface.co/yulan-team","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Chinese","mit","100M - 1B"],"keywords_longer_than_N":true},
	{"name":"s1_54k_filter","keyword":"science","description":"\n\t\n\t\t\n\t\tDataset Card for XuHu6736/s1_54k_filter\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nXuHu6736/s1_54k_filter is a filtered version of the XuHu6736/s1_59k dataset. This dataset has been processed to remove records containing empty or null values in any field, with the specific exception of the 'cot' (Chain-of-Thought) column. If any other field in a record is empty, that entire record is discarded.\nThe original s1_59k dataset was prepared for Supervised Fine-Tuning (SFT) of large language models by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/XuHu6736/s1_54k_filter.","url":"https://huggingface.co/datasets/XuHu6736/s1_54k_filter","creator_name":"XuHu","creator_url":"https://huggingface.co/XuHu6736","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"TaoGPT-v1","keyword":"science","description":"\n\t\n\t\t\n\t\tToaGPT Dataset\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Adithya S K\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [English]\nLicense: [MIT]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: https://github.com/agencyxr/taogpt7B\nDemo [optional]: [More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agency888/TaoGPT-v1.","url":"https://huggingface.co/datasets/agency888/TaoGPT-v1","creator_name":"agency","creator_url":"https://huggingface.co/agency888","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","table-question-answering","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"geo-reviews-dataset-2023","keyword":"reviews","description":"\n\t\n\t\t\n\t\tGeo Reviews Dataset 2023\n\t\n\nYandex is making available the largest Russian-language dataset of reviews about organizations published on Yandex Maps.\nUse it for academic and research purposes, share your results with us in Issues.\n\n\t\n\t\t\n\t\tDescription\n\t\n\n\n500,000 unique reviews\nOnly reviews about organizations in Russia\nAvailable on Yandex Maps\nPublished from January to July 2023\nThe dataset does not contain short one-word reviews\nReviews have been cleared of personal data (phone numbers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/geo-reviews-dataset-2023.","url":"https://huggingface.co/datasets/d0rj/geo-reviews-dataset-2023","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","token-classification","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"b2w-reviews01","keyword":"reviews","description":"B2W-Reviews01 is an open corpus of product reviews. It contains more than 130k e-commerce customer reviews, collected from the Americanas.com website between January and May, 2018. B2W-Reviews01 offers rich information about the reviewer profile, such as gender, age, and geographical location. The corpus also has two different review rates","url":"https://huggingface.co/datasets/ruanchaves/b2w-reviews01","creator_name":"Ruan Chaves Rodrigues","creator_url":"https://huggingface.co/ruanchaves","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","intent-classification","topic-classification"],"keywords_longer_than_N":true},
	{"name":"scientific_studies","keyword":"science","description":"yousefg/scientific_studies dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/yousefg/scientific_studies","creator_name":"Yousef Rafat Gamaleldin","creator_url":"https://huggingface.co/yousefg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"k12-science-standards","keyword":"science","description":"\n\t\n\t\t\n\t\tK-12 Science Standards Aligned Learning Framework Dataset\n\t\n\nA comprehensive dataset of K-12 science curriculum standards aligned with the Next Generation Science Standards (NGSS), designed for training and evaluating educational AI systems.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset contains 6,787 examples of educational content spanning all K-12 grade levels and science domains. Each example includes instructional content, student inputs, expected outputs, and rich metadata aligned‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/robworks-software/k12-science-standards.","url":"https://huggingface.co/datasets/robworks-software/k12-science-standards","creator_name":"Ryan Robson","creator_url":"https://huggingface.co/robworks-software","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","text2text-generation","multi-class-classification"],"keywords_longer_than_N":true},
	{"name":"aifgen-short-piecewise","keyword":"science","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset is a continual dataset in short piecewise scenario given two tasks:\n\nDomain: Education (math, sciences, and social sciences), Objective: QnA, Preference: hinted answer\nDomain: Education (math, sciences, and social sciences), Objective: QnA, Preference: direct answer\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nAs a subset of a larger repository of datasets generated and curated carefully for Lifelong Alignment of Agents‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LifelongAlignment/aifgen-short-piecewise.","url":"https://huggingface.co/datasets/LifelongAlignment/aifgen-short-piecewise","creator_name":"Lifelong Alignment of Agents","creator_url":"https://huggingface.co/LifelongAlignment","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"PhysUniBench","keyword":"science","description":"\n\t\n\t\t\n\t\tPhysUniBench\n\t\n\nAn Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models\nPaper: https://arxiv.org/abs/2506.17667\nRepository: https://github.com/PrismaX-Team/PhysUniBenchmark\nProject page: https://prismax-team.github.io/PhysUniBenchmark/\nPhysUniBench is the first large-scale multimodal physics benchmark specifically designed for undergraduate-level understanding, reasoning, and problem-solving. It provides a valuable testbed for advancing multimodal large language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PrismaX/PhysUniBench.","url":"https://huggingface.co/datasets/PrismaX/PhysUniBench","creator_name":"PrismaX","creator_url":"https://huggingface.co/PrismaX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","English","Chinese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-3778","keyword":"science","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-3778 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-3778 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-3778.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-3778","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"letterboxd-all-movie-data","keyword":"reviews","description":"\n\t\n\t\t\n\t\tLetterboxd Film Dataset\n\t\n\nThis dataset contains a comprehensive collection of 847,209 films from the Letterboxd platform, including movie information, user reviews, and ratings.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Films: 847,209\nFile Size: ~1.12 GB (1,120,572,122 bytes)\nFormat: JSONL (JSON Lines)\nLanguage: Primarily English, with some multilingual content\n\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach line contains a JSON object with the following fields:\n{\n  \"url\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pkchwy/letterboxd-all-movie-data.","url":"https://huggingface.co/datasets/pkchwy/letterboxd-all-movie-data","creator_name":"Salih Mert Canseven","creator_url":"https://huggingface.co/pkchwy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","English","Turkish"],"keywords_longer_than_N":true},
	{"name":"Open-Omega-Atom-1.5M","keyword":"science","description":"\n\n\t\n\t\t\n\t\tOpen-Omega-Atom-1.5M\n\t\n\n\nOpen-Omega-Atom-1.5M is a carefully curated and optimized collection derived from multiple high-quality datasets, specifically designed to enhance reasoning capabilities across mathematical and scientific domains. This dataset represents a focused subset that maintains the quality and diversity of reasoning patterns while providing an efficient size for training and evaluation. A high-quality, compact reasoning dataset designed for mathematics, science, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Open-Omega-Atom-1.5M.","url":"https://huggingface.co/datasets/prithivMLmods/Open-Omega-Atom-1.5M","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-256-24","keyword":"science","description":"\n\t\n\t\t\n\t\tscidocs-c-256-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic paper search for scientific articles\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-256-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-256-24.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"WebInstruct-verified","keyword":"science","description":"\n\t\n\t\t\n\t\tGeneral-Reasoner: Advancing LLM Reasoning Across All Domains\n\t\n\n\n  üíª Code |\n  üìÑ Paper |\n  üìä Dataset |\n  ü§ó Model |\n  üåê Project Page\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\n\n  \n\n\n  \n    Figure: Effectiveness of General-Reasoner trained with diverse verifiable reasoning questions using model-based verifier compared to baseline methods on various reasoning tasks.\n  General-Reasoner is a training paradigm for large language models (LLMs), designed to robustly enhance reasoning abilities across‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/WebInstruct-verified.","url":"https://huggingface.co/datasets/TIGER-Lab/WebInstruct-verified","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ScImage","keyword":"science","description":"The prompt for ICLR2025 paper \nScImage: HOW GOOD ARE MULTIMODAL LARGE LANGUAGE MODELS AT SCIENTIFIC TEXT-TO-IMAGE GENERATION?\nThe prompt template and the object list will be added soon.\n@inproceedings{\nscimage2025,\ntitle={ScImage: How Good Are Multimodal Large Language Models at Scientific Text-to-Image Generation?},\nauthor={Zhang, Leixin and Cheng, Yinjie and Zhai, Weihe and Eger, Steffen and Belouadi, Jonas and Moafian, Fahimeh and Zhao, Zhixue},\nbooktitle={The Thirteenth International‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/casszhao/ScImage.","url":"https://huggingface.co/datasets/casszhao/ScImage","creator_name":"casszhao","creator_url":"https://huggingface.co/casszhao","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"MMMU_with_difficulty_level","keyword":"science","description":"\n\t\n\t\t\n\t\tMMMU with difficulty level tags\n\t\n\nThis dataset extends the ü§ó MMMU val benchmark by introducing two additional tags: passrate_for_qwen2.5_vl_7b and difficulty_level_for_qwen2.5_vl_7b. Further details are available in our paper The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs.\n\n\t\n\t\t\n\t\n\t\n\t\tüöÄ Data Usage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"JierunChen/MMMU_with_difficulty_level\")\nprint(dataset)\n\n\n\t\n\t\n\t\n\t\tüìë‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JierunChen/MMMU_with_difficulty_level.","url":"https://huggingface.co/datasets/JierunChen/MMMU_with_difficulty_level","creator_name":"Jierun Chen","creator_url":"https://huggingface.co/JierunChen","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"aifgen-piecewise-preference-shift","keyword":"science","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset is a continual dataset in a piecewise non stationarity scenario of both domains and preferences given a combination of given three recurring tasks:\n\nDomain: Politics, Objective: Generation, Preference: Respond like a rapper\nDomain: Politics, Objective: Generation, Preference: Respond like Shakespeare\nDomain: Politics, Objective: Generation, Preference: Respond formally\nDomain: Politics, Objective: Generation, Preference: Respond like a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LifelongAlignment/aifgen-piecewise-preference-shift.","url":"https://huggingface.co/datasets/LifelongAlignment/aifgen-piecewise-preference-shift","creator_name":"Lifelong Alignment of Agents","creator_url":"https://huggingface.co/LifelongAlignment","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"WildSci","keyword":"science","description":"\n\t\n\t\t\n\t\tüß™ WildSci: Advancing Scientific Reasoning from In-the-Wild Literature\n\t\n\n\n\t\n\t\t\n\t\tPurpose and scope\n\t\n\nDespite recent advances in LLM reasoning, there remains a notable lack of diverse, domain-rich science datasets ‚Äúin the wild‚Äù to support progress on science reasoning tasks. While existing work has demonstrated strong performance in specialized areas such as mathematical reasoning, there is still a gap in datasets that capture the complexity and breadth of reasoning required across‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JustinTX/WildSci.","url":"https://huggingface.co/datasets/JustinTX/WildSci","creator_name":"Tengxiao Liu","creator_url":"https://huggingface.co/JustinTX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Amazon_Reviews_for_Sentiment_Analysis_fine_grained_5_classes","keyword":"reviews","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThe Amazon reviews full score dataset is constructed by randomly taking 600,000 training samples and 130,000 testing samples for each review score from 1 to 5. In total there are 3,000,000 trainig samples and 650,000 testing samples.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe files train.csv and test.csv contain all the training samples as comma-sparated values. There are 3 columns in them, corresponding to class index (1 to 5)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yassiracharki/Amazon_Reviews_for_Sentiment_Analysis_fine_grained_5_classes.","url":"https://huggingface.co/datasets/yassiracharki/Amazon_Reviews_for_Sentiment_Analysis_fine_grained_5_classes","creator_name":"yassir acharki","creator_url":"https://huggingface.co/yassiracharki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_9th","keyword":"science","description":"KadamParth/NCERT_Science_9th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_9th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"Astro-mcqa","keyword":"science","description":"\n\t\n\t\t\n\t\tAstroMCQA Dataset\n\t\n\n\n\t\n\t\t\n\t\tPurpose and scope\n\t\n\nThe primary purpose of AstroMCQA is for application developers in the domain of space engineering to be able to comparatively assess LLM performances on the specific task of multiple-choice question-answering\n\n\t\n\t\t\n\t\tIntended Usage\n\t\n\nComparative assessement of differents LLMs, Model evaluation, audit, and model selection. Assessment of different quantization levels, different prompting strategies, and assessing effectiveness of domain‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/patrickfleith/Astro-mcqa.","url":"https://huggingface.co/datasets/patrickfleith/Astro-mcqa","creator_name":"Patrick Fleith","creator_url":"https://huggingface.co/patrickfleith","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"Images","keyword":"science","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Johnnyboystar/Images.","url":"https://huggingface.co/datasets/Johnnyboystar/Images","creator_name":"John Clough","creator_url":"https://huggingface.co/Johnnyboystar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","summarization","table-question-answering","question-answering","text-generation"],"keywords_longer_than_N":true},
	{"name":"yandex-geo-reviews-embeddings","keyword":"reviews","description":"Dataset full description: https://www.kaggle.com/datasets/lockiultra/yandex-geo-reviews-embeddings\nDataset contains index column, 768 embedding columns and rating column. Each row corresponds to an embedding representation of the review text with same index.\n","url":"https://huggingface.co/datasets/lockiultra/yandex-geo-reviews-embeddings","creator_name":"Dmitry","creator_url":"https://huggingface.co/lockiultra","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Russian","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-478897","keyword":"science","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-478897 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-478897 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-478897.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-478897","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Celestia","keyword":"science","description":"Celestia is a dataset containing science-instruct data.\nThe 2024-10-30 version contains:\n\n126k rows of synthetic science-instruct data, using synthetically generated prompts and responses generated using Llama 3.1 405b Instruct. Primary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\n\nThis dataset contains synthetically generated data and has not been subject to manual review.\n","url":"https://huggingface.co/datasets/sequelbox/Celestia","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"PHYSICS","keyword":"science","description":"This repository contains the PHYSICS dataset we introduced, which covers five physics disciplines and includes physics problems ranging from high school to graduate-level physics courses, with rigorous quality control.\nThe dataset is divided into training and testing parts, At this stage, we currently provide only the test portion. The training portion will be open-sourced in the future. The test portion corresponds to PHYSICS_test.jsonl in the repository.\nThe field names in the files are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/desimfj/PHYSICS.","url":"https://huggingface.co/datasets/desimfj/PHYSICS","creator_name":"shenghe zheng","creator_url":"https://huggingface.co/desimfj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1K - 10K","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"CineBrain","keyword":"science","description":"\n\t\n\t\t\n\t\tCineBrain: A Large-Scale Multi-Modal Brain Dataset During Naturalistic Audiovisual Narrative Processing\n\t\n\n\nCineBrain is a large-scale multimodal brain dataset comprising fMRI, EEG, and ECG recordings collected while participants watched episodes of The Big Bang Theory.It supports research on neural decoding, multimodal learning, and modality transfer in naturalistic narrative processing.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüß† Dataset Description\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSummary\n\t\n\n\nParticipants: 6 subjects  \nStimuli:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fudan-fMRI/CineBrain.","url":"https://huggingface.co/datasets/Fudan-fMRI/CineBrain","creator_name":"Fudan-fMRI-yanwei","creator_url":"https://huggingface.co/Fudan-fMRI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-video","image-to-video","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_7th","keyword":"science","description":"KadamParth/NCERT_Science_7th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_7th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"s1_59k","keyword":"science","description":"\n\t\n\t\t\n\t\tDataset Card for XuHu6736/s1_59k\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nXuHu6736/s1_59k is a dataset specifically prepared for Supervised Fine-Tuning (SFT) of large language models. It is constructed by merging and processing two existing Hugging Face datasets: simplescaling/data_ablation_full59K and qfq/train_featurized.\nThe simplescaling/data_ablation_full59K dataset is a collection of approximately 59,000 questions and solutions spanning various domains including mathematics, science‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/XuHu6736/s1_59k.","url":"https://huggingface.co/datasets/XuHu6736/s1_59k","creator_name":"XuHu","creator_url":"https://huggingface.co/XuHu6736","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","XuHu6736 (merging process)","simplescaling (source dataset: data_ablation_full59K)","qfq (source dataset: train_featurized, annotation based on 's1: Simple test-time scaling')"],"keywords_longer_than_N":true},
	{"name":"Celestia2","keyword":"science","description":"Celestia 2 is a multi-turn agent-instruct dataset containing science data.\nThis dataset focuses on challenging multi-turn conversations and contains:\n\n176k rows of synthetic multi-turn science-instruct data, using Microsoft's AgentInstruct style. All prompts and responses are synthetically generated using Llama 3.1 405b Instruct. Primary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\n\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Celestia2.","url":"https://huggingface.co/datasets/sequelbox/Celestia2","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"everyday-science","keyword":"science","description":"\n\t\n\t\t\n\t\tEveryday Science Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Everyday Science\" dataset is a synthetically generated collection of question-answer pairs covering a diverse range of topics within everyday science. Each entry includes a topic, a specific question, a scientific explanation or principle, a relatable everyday example, relevant scientific concepts (keywords), and further reasoning or inference.\nThis dataset contains question-and-answer pairs focused on everyday science‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nirajandhakal/everyday-science.","url":"https://huggingface.co/datasets/nirajandhakal/everyday-science","creator_name":"Nirajan Dhakal","creator_url":"https://huggingface.co/nirajandhakal","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","question-answering","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"steam-reviews-constructiveness-binary-label-annotations-1.5k","keyword":"reviews","description":"\n\n\n    \n\n\n\n\n\n\n\n    1.5K Steam Reviews Binary Labeled for Constructiveness\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,461 Steam reviews from 10 of the most reviewed games. Each game has about the same amount of reviews. Each review is annotated with a binary label indicating whether the review is constructive or not. The dataset is designed to support tasks related to text classification, particularly constructiveness detection tasks in the gaming domain.\n\nAlso available as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abullard1/steam-reviews-constructiveness-binary-label-annotations-1.5k.","url":"https://huggingface.co/datasets/abullard1/steam-reviews-constructiveness-binary-label-annotations-1.5k","creator_name":"Samuel Bullard","creator_url":"https://huggingface.co/abullard1","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-generated","found","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"amazon_appliance_prices","keyword":"reviews","description":"slconnin/amazon_appliance_prices dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/slconnin/amazon_appliance_prices","creator_name":"Sean Connin","creator_url":"https://huggingface.co/slconnin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"aifgen-lipschitz","keyword":"science","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset is a continual dataset in lipschitz bounded scenario given three tasks:\n\nDomain: Technology and Physics, Objective: Summarization, Preference: Explain Like I'm 5\nDomain: Technology and Physics, Objective: Summarization, Preference: Explain Like I'm a High School Student\nDomain: Technology and Physics, Objective: Summarization, Preference: Explain Like I'm an expert\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\nAs a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LifelongAlignment/aifgen-lipschitz.","url":"https://huggingface.co/datasets/LifelongAlignment/aifgen-lipschitz","creator_name":"Lifelong Alignment of Agents","creator_url":"https://huggingface.co/LifelongAlignment","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"math-formulas-tr","keyword":"science","description":"esholmess/math-formulas-tr dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/esholmess/math-formulas-tr","creator_name":"ƒ∞lknur Yaren K.","creator_url":"https://huggingface.co/esholmess","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Turkish","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"science_biology","keyword":"science","description":"deep-principle/science_biology dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/deep-principle/science_biology","creator_name":"Deep Principle","creator_url":"https://huggingface.co/deep-principle","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"M4U","keyword":"science","description":"\n\t\n\t\t\n\t\tM4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models\n\t\n\nCode for the Paper M4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models.\n[Webpage] [Paper] [Huggingface Dataset] [Leaderboard]\n\n\t\n\t\t\n\t\n\t\n\t\tüí• News üí•\n\t\n\n\n[2024.05.23] Our paper, dataset and code are public aviailable.\n\n\n\t\n\t\n\t\n\t\tüëÄ About M4U\n\t\n\n\n     \n\n\nMultilingual multimodal reasoning is a core component to achieve human-level intelligence. However, most of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/M4U-Benchmark/M4U.","url":"https://huggingface.co/datasets/M4U-Benchmark/M4U","creator_name":"M4U-Benchmark","creator_url":"https://huggingface.co/M4U-Benchmark","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","Chinese","German","mit"],"keywords_longer_than_N":true},
	{"name":"scips_qa","keyword":"science","description":"zorpsoon/scips_qa dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zorpsoon/scips_qa","creator_name":"Prasoon Bajpai","creator_url":"https://huggingface.co/zorpsoon","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"TheoremQA","keyword":"science","description":"\n\t\n\t\t\n\t\tDataset Card for \"TheoremQA\"\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWe propose the first question-answering dataset driven by STEM theorems. We annotated 800 QA pairs covering 350+ theorems spanning across Math, EE&CS, Physics and Finance. The dataset is collected by human experts with very high quality. We provide the dataset as a new benchmark to test the limit of large language models to apply theorems to solve challenging university-level questions. We provide a pipeline in the following to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/TheoremQA.","url":"https://huggingface.co/datasets/TIGER-Lab/TheoremQA","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"shopee-reviews-tl-binary","keyword":"reviews","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA typical data point, comprises of a text and the corresponding label.\nAn example from the YelpReviewFull test set looks as follows:\n{\n    'label':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/scaredmeow/shopee-reviews-tl-binary.","url":"https://huggingface.co/datasets/scaredmeow/shopee-reviews-tl-binary","creator_name":"Neil Riego","creator_url":"https://huggingface.co/scaredmeow","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Tagalog","odc-by","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"MMMU_Pro","keyword":"science","description":"\n\t\n\t\t\n\t\tMMMU-Pro (A More Robust Multi-discipline Multimodal Understanding Benchmark)\n\t\n\nüåê Homepage | üèÜ Leaderboard | ü§ó Dataset | ü§ó Paper | üìñ arXiv | GitHub\n\n\t\n\t\t\n\t\n\t\n\t\tüîîNews\n\t\n\n\nüõ†Ô∏èüõ†Ô∏è [2025-03-08] Fixed mismatch between inner image labels and shuffled options in Vision and Standard (10 options) settings. (test_Chemistry_5,94,147,216,314,345,354,461,560,570; test_Materials_450; test_Pharmacy_198; validation_Chemistry_12,26,29; validation_Materials_10,28; validation_Psychology_1)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MMMU/MMMU_Pro.","url":"https://huggingface.co/datasets/MMMU/MMMU_Pro","creator_name":"MMMU","creator_url":"https://huggingface.co/MMMU","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"sfe-competition-2025","keyword":"science","description":"\n\t\n\t\t\n\t\tSFE Competition 2025\n\t\n\nHere contains the training dataset for the SFE Competition 2025.\nFor more information, please see: https://prismax-team.github.io/sfe-competition-2025/#organizers\n\n\t\n\t\t\n\t\tHow to obtain images:\n\t\n\nzip -FF images_bundle.zip --out images.zip\nunzip images.zip\n\n","url":"https://huggingface.co/datasets/PrismaX/sfe-competition-2025","creator_name":"PrismaX","creator_url":"https://huggingface.co/PrismaX","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","100K<n<1M","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"rehber-ai-data","keyword":"reviews","description":"\n\t\n\t\t\n\t\tRehber.ai Dataset\n\t\n\nGoogle Maps yorumlarƒ±ndan olu≈üturulmu≈ü T√ºrk√ße RAG dataset'i.\n\n\t\n\t\t\n\t\tDataset Bilgileri\n\t\n\n\nKayƒ±t Sayƒ±sƒ±: 200,000\nBoyut: ~66 MB\nFormat: JSONL (her satƒ±r bir JSON)\nDil: T√ºrk√ße\nKaynak: opdullah/turkish-google-maps-reviews\n\n\n\t\n\t\t\n\t\tVeri Yapƒ±sƒ±\n\t\n\nHer kayƒ±t ≈üu alanlarƒ± i√ßerir:\n{\n  \"question\": \"Mekan adƒ± hakkƒ±nda ne d√º≈ü√ºn√ºl√ºyor?\",\n  \"answer\": \"Kullanƒ±cƒ± yorumu\",\n  \"place_name\": \"Mekan adƒ±\",\n  \"category\": \"Kategori\",\n  \"rating\": 5\n}\n\n\n\t\n\t\t\n\t\tFiltreleme\n\t\n\n\nKategori:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/corumyagmuur/rehber-ai-data.","url":"https://huggingface.co/datasets/corumyagmuur/rehber-ai-data","creator_name":"Yaƒümur √áorum","creator_url":"https://huggingface.co/corumyagmuur","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Turkish","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"DRIFT-TL-Distill-4K","keyword":"science","description":"\n\t\n\t\t\n\t\tDRIFT-TL-Distill-4K Dataset\n\t\n\nThis dataset contains multimodal reasoning examples with images and step-by-step thinking processes.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\nmessages: Conversation between user and assistant with image references\nimages: Paths to associated images\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ChaoHuangCS/DRIFT-TL-Distill-4K\")\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite our paper.\n","url":"https://huggingface.co/datasets/ChaoHuangCS/DRIFT-TL-Distill-4K","creator_name":"Chao Huang","creator_url":"https://huggingface.co/ChaoHuangCS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Aze-Instruct-2K","keyword":"science","description":"\n\t\n\t\t\n\t\tAze-Instruct-2K (Azerbaijani Reasoning & Instruction Dataset)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAze-Instruct-2K is a high-quality Azerbaijani dataset designed for instruction-tuning and reasoning-focused tasks.It consists of 2,000 samples across 12 diverse categories.\nThis dataset is intended for fine-tuning models to understand, reason, and generate responses in Azerbaijani, particularly in multi-domain reasoning scenarios.\n\n\t\n\t\t\nCategory\nNumber of Rows\n\n\n\t\t\nMathematical Reasoning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/karabakh-nlp/Aze-Instruct-2K.","url":"https://huggingface.co/datasets/karabakh-nlp/Aze-Instruct-2K","creator_name":"Karabakh NLP","creator_url":"https://huggingface.co/karabakh-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Azerbaijani","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"amazon_reviews_mobile_electronics","keyword":"reviews","description":"rkf2778/amazon_reviews_mobile_electronics dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rkf2778/amazon_reviews_mobile_electronics","creator_name":"Rohit Kochikkat Francis","creator_url":"https://huggingface.co/rkf2778","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Amazon_Reviews_Binary_for_Sentiment_Analysis","keyword":"reviews","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThe Amazon reviews polarity dataset is constructed by taking review score 1 and 2 as negative, and 4 and 5 as positive. Samples of score 3 is ignored. In the dataset, class 1 is the negative and class 2 is the positive. Each class has 1,800,000 training samples and 200,000 testing samples.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe files train.csv and test.csv contain all the training samples as comma-sparated values. There are 3‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yassiracharki/Amazon_Reviews_Binary_for_Sentiment_Analysis.","url":"https://huggingface.co/datasets/yassiracharki/Amazon_Reviews_Binary_for_Sentiment_Analysis","creator_name":"yassir acharki","creator_url":"https://huggingface.co/yassiracharki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"MathVision_with_difficulty_level","keyword":"science","description":"\n\t\n\t\t\n\t\tMathVision with difficulty level tags\n\t\n\nThis dataset extends the ü§ó MathVision  benchmark by introducing two additional tags: passrate_for_qwen2.5_vl_7b and difficulty_level_for_qwen2.5_vl_7b. Further details are available in our paper The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs.\n\n\t\n\t\t\n\t\n\t\n\t\tüöÄ Data Usage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"JierunChen/MathVision_with_difficulty_level\")\nprint(dataset)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JierunChen/MathVision_with_difficulty_level.","url":"https://huggingface.co/datasets/JierunChen/MathVision_with_difficulty_level","creator_name":"Jierun Chen","creator_url":"https://huggingface.co/JierunChen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","visual-question-answering","text-generation","expert-generated"],"keywords_longer_than_N":true},
	{"name":"science_chemistry","keyword":"science","description":"deep-principle/science_chemistry dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/deep-principle/science_chemistry","creator_name":"Deep Principle","creator_url":"https://huggingface.co/deep-principle","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Demeter-LongCoT-6M","keyword":"science","description":"\n\n\t\n\t\t\n\t\tDemeter-LongCoT-6M\n\t\n\n\nDemeter-LongCoT-6M is a high-quality, compact chain-of-thought reasoning dataset curated for tasks in mathematics, science, and coding. While the dataset spans diverse domains, it is primarily driven by mathematical reasoning, reflecting a major share of math-focused prompts and long-form logical solutions.\n\n\n\t\n\t\t\n\t\n\t\n\t\tQuick Start with Hugging Face Datasetsü§ó\n\t\n\npip install -U datasets\n\nfrom datasets import load_dataset\n\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Demeter-LongCoT-6M.","url":"https://huggingface.co/datasets/prithivMLmods/Demeter-LongCoT-6M","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"scidocs","keyword":"science","description":"\n\t\n\t\t\n\t\tscidocs Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for scientific papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs.","url":"https://huggingface.co/datasets/fine-tuned/scidocs","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"OpenThoughts-TR-18k","keyword":"science","description":"\n\t\n\t\t\n\t\tOpenThoughts-TR-18k: Turkish Synthetic Reasoning Dataset\n\t\n\nOpenThoughts-TR-18k is a Turkish translation of a subset of the original Open-Thoughts-114k dataset. It contains ~18k high-quality synthetic reasoning examples covering mathematics, science, coding problems, and puzzles, all translated into Turkish. This dataset is designed to support reasoning task fine tuning for Turkish language models.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n~18k translated reasoning examples\nCovers multiple domains:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/selimc/OpenThoughts-TR-18k.","url":"https://huggingface.co/datasets/selimc/OpenThoughts-TR-18k","creator_name":"selim","creator_url":"https://huggingface.co/selimc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Turkish","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"gliner-bird-diet-synthetic","keyword":"science","description":"\n\t\n\t\t\n\t\n\t\n\t\tGLiNER Bird Diet Synthetic Dataset\n\t\n\nThis is an NER dataset focused on ornithological data, specifically focused on the diets of birds. The data is purely synthetic and should not be taken as factual. We created this dataset using Qwen2-7B-Instruct. It consists of ~2k descriptions. The format of the annotations consists with the GLiNER format. We used this data to finetune a GLiNER model. For the base model, we used NuNerZero Span. You can visit our model here: GLiNER Ecology‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wjbmattingly/gliner-bird-diet-synthetic.","url":"https://huggingface.co/datasets/wjbmattingly/gliner-bird-diet-synthetic","creator_name":"William Mattingly","creator_url":"https://huggingface.co/wjbmattingly","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","English","mit","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"WyFormer-Symmetric-Crystals","keyword":"science","description":"\n\t\n\t\t\n\t\tWyFormer generated datasets\n\t\n\nThe first folder in the dataset which was used for training WyFormer, using only train and validation parts. Then the folder structure corresponds to transformations of the data.\n\nmp_20/WyckoffTransformer 10k formally valid Wyckoff representations generated by WyFormer trained on MP-20 dataset.\nDiffCSP++10k 9999 structures obtained with DifCSP++; it failed for one Wyckoff representation, we consider this structure unstable. Can be considered as the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cgeorgiaw/WyFormer-Symmetric-Crystals.","url":"https://huggingface.co/datasets/cgeorgiaw/WyFormer-Symmetric-Crystals","creator_name":"Georgia Channing","creator_url":"https://huggingface.co/cgeorgiaw","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["cc-by-4.0","arxiv:2406.04713","arxiv:2503.16784","arxiv:2110.06197","arxiv:2503.02407"],"keywords_longer_than_N":true},
	{"name":"Electronics_Product_Review_With_Sentiment","keyword":"reviews","description":"\n\t\n\t\t\n\t\tüìä Amazon Electronics Review Dataset\n\t\n\nThis dataset contains Amazon Electronics product reviews with sentiment.It was preprocessed to remove reviews without helpful vote and unverified purchases.  \n\n\t\n\t\t\n\t\t‚úÖ Features\n\t\n\n\ntext: The main review text written by customers.  \nreview_sentiment: Positive, Negative, Neutral (classified using Mistral Large Language Model).  \nverified_purchase: Boolean flag indicating if purchase was verified.  \nhelpful_votes: Number of helpful votes received.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stephaniestv/Electronics_Product_Review_With_Sentiment.","url":"https://huggingface.co/datasets/stephaniestv/Electronics_Product_Review_With_Sentiment","creator_name":"Stephanie Stevie","creator_url":"https://huggingface.co/stephaniestv","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv","keyword":"science","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ScienceOlympiad","keyword":"science","description":"\n\t\n\t\t\n\t\tScienceOlympiad: Challenging AI with Olympiad-Level Multimodal Science Problems\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe ScienceOlympiad dataset is a meticulously curated benchmark designed to test the limits of current AI models in scientific reasoning. It comprises elite, competition-level problems in physics and chemistry. Addressing the need for more diverse and realistic challenges, ScienceOlympiad introduces multimodal integration as a key dimension. Unlike purely text-based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ByteDance-Seed/ScienceOlympiad.","url":"https://huggingface.co/datasets/ByteDance-Seed/ScienceOlympiad","creator_name":"ByteDance Seed","creator_url":"https://huggingface.co/ByteDance-Seed","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["cc0-1.0","< 1K","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"dataclysm-arxiv","keyword":"science","description":"\n\t\n\t\t\n\t\tDATACLYSM PATCH 0.0.2: ARXIV\n\t\n\n\n\t\n\t\t\n\t\tUSE THE NOTEBOOK TO GET STARTED!\n\t\n\nhttps://github.com/somewheresystems/dataclysm\n\n\n\t\n\t\t\n\t\n\t\n\t\tsomewheresystems/dataclysm-wikipedia-titles\n\t\n\nThis dataset comprises of 3,360,984 English language arXiv papers from the Cornell/arXiv dataset, with two new columns added: title-embeddings and abstract-embeddings. These additional columns were generated using the bge-small-en-v1.5 embeddings model. The dataset was sourced from the Cornell/arXiv GCP‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somewheresystems/dataclysm-arxiv.","url":"https://huggingface.co/datasets/somewheresystems/dataclysm-arxiv","creator_name":"S2","creator_url":"https://huggingface.co/somewheresystems","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["English","cc0-1.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-499715","keyword":"science","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-499715 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-499715 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-499715.","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-499715","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"curie","keyword":"science","description":"\n\t\n\t\t\n\t\tCurie Dataset\n\t\n\nHF version of the dataset:\nCURIE: Evaluating LLMs On Multitask Scientific Long Context Understanding and Reasoning.\nAlso available via GitHub (Apache-2.0 license).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nCURIE consists of 10 tasks that are mapped to 8 datasets. The datasets are: \n\n\t\n\t\t\nDataset ID\nTask Name\nDomain\nDescription\n\n\n\t\t\nbiogr\nBiodiversity Georeferencing\nBiodiversity\nDetermine the latitude, longitude bounding box encompassing the region in the map image.\n\n\ndft\nDensity‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nhop/curie.","url":"https://huggingface.co/datasets/nhop/curie","creator_name":"Niklas Hoepner","creator_url":"https://huggingface.co/nhop","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"HiPhO","keyword":"science","description":"\n\nü•á HiPhO: High School Physics Olympiad Benchmark\n\n[üèÜ Leaderboard]\n[üìä Dataset]\n[‚ú® GitHub]\n[üìÑ Paper]\n\n\n\n\n\nüèÜ New (Sep. 16): We launched \"PhyArena\", a physics reasoning leaderboard incorporating the HiPhO benchmark.\n\n\t\n\t\n\t\n\t\tüåê Introduction\n\t\n\nHiPhO (High School Physics Olympiad Benchmark) is the first benchmark specifically designed to evaluate the physical reasoning abilities of (M)LLMs on real-world Physics Olympiads from 2024‚Äì2025.\n\n  \n\n\n\n\t\n\t\t\n\t\t‚ú® Key Features\n\t\n\n\nUp-to-date Coverage:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SciYu/HiPhO.","url":"https://huggingface.co/datasets/SciYu/HiPhO","creator_name":"Fangchen Yu","creator_url":"https://huggingface.co/SciYu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","image-text-to-text","English","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_10th","keyword":"science","description":"KadamParth/NCERT_Science_10th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_10th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"MathVision","keyword":"science","description":"\n\t\n\t\t\n\t\tMeasuring Multimodal Mathematical Reasoning with the MATH-Vision Dataset\n\t\n\n[üíª Github] [üåê Homepage]  [üìä Leaderboard ] [üìä Open Source Leaderboard ] [üîç Visualization] [üìñ Paper]\n\n\t\n\t\t\n\t\n\t\n\t\tüöÄ Data Usage\n\t\n\n\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"MathLLMs/MathVision\")\nprint(dataset)\n\n\n\t\n\t\t\n\t\tüí• News\n\t\n\n\n[2025.05.16] üí• We now support the official open-source leaderboard! üî•üî•üî• Skywork-R1V2-38B is the best open-source model, scoring 49.7% on MATH-Vision. üî•üî•üî•‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathVision.","url":"https://huggingface.co/datasets/MathLLMs/MathVision","creator_name":"LLMs for Reasoning","creator_url":"https://huggingface.co/MathLLMs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","visual-question-answering","text-generation","expert-generated"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-64-24","keyword":"science","description":"\n\t\n\t\t\n\t\tscidocs-c-64-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-64-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24.","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"VISCO","keyword":"science","description":"\n\t\n\t\t\n\t\n\t\n\t\tVISCO\n\t\n\nBenchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning\nüåê Project | üìñ Paper | üíª Github\n\n\nOutline:\n\nIntroduction\nData\nCitation\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nVISCO is a benchmark for evaluating the critique and correction capabilities of LVLMs. VISCO contains:\n\n1645 pairs of questions and LVLM-generated answers. Each answer includes a chain-of-thought with multiple reasonign steps.\n5604 step-wise annotations of critique, showing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/uclanlp/VISCO.","url":"https://huggingface.co/datasets/uclanlp/VISCO","creator_name":"UCLA NLP","creator_url":"https://huggingface.co/uclanlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","mit","1K<n<10K","arxiv:2412.02172"],"keywords_longer_than_N":true},
	{"name":"MMR1-RL","keyword":"science","description":"\n\t\n\t\t\n\t\tMMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources\n\t\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nThis repository introduces the MMR1 project, focusing on enhancing large multimodal reasoning models. While rapid progress has been made, advancements are constrained by two major limitations:\n\nThe absence of open, large-scale, high-quality long chain-of-thought (CoT) data.\nThe instability of reinforcement learning (RL) algorithms in post-training, where standard Group‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MMR1/MMR1-RL.","url":"https://huggingface.co/datasets/MMR1/MMR1-RL","creator_name":"MMR1","creator_url":"https://huggingface.co/MMR1","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-15062024-atex-webapp","keyword":"science","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-15062024-atex-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-15062024-atex-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp.","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"science_materials","keyword":"science","description":"deep-principle/science_materials dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/deep-principle/science_materials","creator_name":"Deep Principle","creator_url":"https://huggingface.co/deep-principle","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5222024-hkde-webapp","keyword":"reviews","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5222024-hkde-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"code repository search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5222024-hkde-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5222024-hkde-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5222024-hkde-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Yelp_Reviews_for_Sentiment_Analysis_fine_grained_5_classes","keyword":"reviews","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThe Yelp reviews full star dataset is constructed by randomly taking 130,000 training samples and 10,000 testing samples for each review star from 1 to 5. In total there are 650,000 trainig samples and 50,000 testing samples.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe files train.csv and test.csv contain all the training samples as comma-sparated values. There are 2 columns in them, corresponding to class index (1 to 5) and review text. The review texts are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yassiracharki/Yelp_Reviews_for_Sentiment_Analysis_fine_grained_5_classes.","url":"https://huggingface.co/datasets/yassiracharki/Yelp_Reviews_for_Sentiment_Analysis_fine_grained_5_classes","creator_name":"yassir acharki","creator_url":"https://huggingface.co/yassiracharki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"amazon_review_metadata","keyword":"reviews","description":"\n\t\n\t\t\n\t\tReview Text Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains review texts with simple ID indexing.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nid: Unique identifier (integer)\ntext: Review text content\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"your-username/review-texts\")\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is released under the CC-BY-4.0 license.\n","url":"https://huggingface.co/datasets/Jyshen/amazon_review_metadata","creator_name":"Junyi SHEN","creator_url":"https://huggingface.co/Jyshen","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SOPBench","keyword":"science","description":"\n\t\n\t\t\n\t\tSOPBench: Evaluating Language Agents at Following Standard Operating Procedures and Constraints\n\t\n\n\n\t\n\t\t\n\t\tPurpose and scope\n\t\n\nAs language agents increasingly automate critical tasks, their ability to follow domain-specific standard operating procedures (SOPs), policies, and constraints when taking actions and making tool calls becomes essential yet remains underexplored. To address this gap, we develop an automated evaluation pipeline with: (1) executable environments containing 167‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Zekunli/SOPBench.","url":"https://huggingface.co/datasets/Zekunli/SOPBench","creator_name":"Zekun Li","creator_url":"https://huggingface.co/Zekunli","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"scientific_question-generation","keyword":"science","description":"Data originated from: \nhttps://openstax.org.‚Äù\nhttps://openstax.org/details/books/chemistry-2e\n","url":"https://huggingface.co/datasets/leaschuessler/scientific_question-generation","creator_name":"Lea Sch√º√üler","creator_url":"https://huggingface.co/leaschuessler","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","feature-extraction","text-generation","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"scientific_papers_from_arxiv","keyword":"science","description":"\n\t\n\t\t\n\t\tscientific_papers_from_arxiv Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic paper search for scientific research\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scientific_papers_from_arxiv model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scientific_papers_from_arxiv.","url":"https://huggingface.co/datasets/fine-tuned/scientific_papers_from_arxiv","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"sib-cl","keyword":"science","description":"\n\t\n\t\t\n\t\tSIB-CL Datasets\n\t\n\nThis repository contains the Surrogate- and Invariance-Boosted Contrastive Learning (SIB-CL) datasets for two scientific problems:\n\nPhC2D: 2D photonic crystal density-of-states (DOS) and bandstructure data.\nTISE: 3D time-independent Schr√∂dinger equation eigenvalue and eigenvector solutions.\n\nThe data and loader scripts reproduce the behavior of the original PyTorch Dataset classes from the SIB-CL paper:\n\nLoh, C., Christensen, T., Dangovski, R., Kim, S., & Soljaƒçiƒá‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cgeorgiaw/sib-cl.","url":"https://huggingface.co/datasets/cgeorgiaw/sib-cl","creator_name":"Georgia Channing","creator_url":"https://huggingface.co/cgeorgiaw","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["apache-2.0","üá∫üá∏ Region: US","photonic-crystal","quantum","contrastive-learning"],"keywords_longer_than_N":true},
	{"name":"aifgen-long-piecewise","keyword":"science","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset is a continual dataset in long piecewise scenario given two tasks:\n\nDomain: Education (math, sciences, and social sciences), Objective: QnA, Preference: hinted answer\nDomain: Education (math, sciences, and social sciences), Objective: QnA, Preference: direct answer\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nAs a subset of a larger repository of datasets generated and curated carefully for Lifelong Alignment of Agents‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LifelongAlignment/aifgen-long-piecewise.","url":"https://huggingface.co/datasets/LifelongAlignment/aifgen-long-piecewise","creator_name":"Lifelong Alignment of Agents","creator_url":"https://huggingface.co/LifelongAlignment","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"play_market_2025_1m_reviews_500_titles","keyword":"reviews","description":"\n\t\n\t\t\n\t\tüìä Play Market 2025 - 1M Reviews, 550+ Titles\n\t\n\nThis dataset provides cleaned and structured data from the Google Play Market, featuring over 1 million user reviews, detailed metadata for 335 games and 217 applications, and processed fields for advanced analysis.\n\n\n\t\n\t\t\n\t\tüßæ Dataset Contents\n\t\n\n\n\t\n\t\t\n\t\tapps_info.csv\n\t\n\nMetadata for mobile applications, including:\n\napp_id: Unique identifier\napp_name: Name of the app\ndescription: Cleaned full description\nscore: Average user rating (0‚Äì5)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dmytrobuhai/play_market_2025_1m_reviews_500_titles.","url":"https://huggingface.co/datasets/dmytrobuhai/play_market_2025_1m_reviews_500_titles","creator_name":"Dmytro Buhai","creator_url":"https://huggingface.co/dmytrobuhai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","zero-shot-classification","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"2d-photonic-topology","keyword":"science","description":"A collection of band structure and lattice datasets across various plane groups. This dataset supports research in crystallography, solid state physics, and generative materials science, particularly for evaluating structure-property relationships and model generalization across symmetry groups.\n","url":"https://huggingface.co/datasets/cgeorgiaw/2d-photonic-topology","creator_name":"Georgia Channing","creator_url":"https://huggingface.co/cgeorgiaw","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["cc-by-4.0","üá∫üá∏ Region: US","physics","materials","photonics"],"keywords_longer_than_N":true},
	{"name":"aifgen-merged","keyword":"science","description":"\n\t\n\t\t\n\t\tDataset Card for aif-gen static dataset\n\t\n\n\n\nThis dataset is a set of static RLHF datasets used to generate continual RLHF datasets for benchmarking Lifelong RL on language models. \nThe data used in the paper can be found under the directory 4omini_generation and the rest are included for reference and are used in the experiments for the paper.\nThe continual datasets created for benchmarking can be found with their dataset cards in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LifelongAlignment/aifgen-merged.","url":"https://huggingface.co/datasets/LifelongAlignment/aifgen-merged","creator_name":"Lifelong Alignment of Agents","creator_url":"https://huggingface.co/LifelongAlignment","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_6th","keyword":"science","description":"KadamParth/NCERT_Science_6th dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_6th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true}
]
;
