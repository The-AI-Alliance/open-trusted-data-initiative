const data_for_domain_science = 
[
	{"name":"AtomicGPT-3.0_Dataset","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Atomic-Ai/AtomicGPT-3.0_Dataset","creator_name":"Atomic Ai Studios","creator_url":"https://huggingface.co/Atomic-Ai","description":"Atomic-Ai/AtomicGPT-3.0_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","German","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"rag-qa-arena","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rajistics/rag-qa-arena","creator_name":"Rajiv Shah","creator_url":"https://huggingface.co/rajistics","description":"\n\t\n\t\t\n\t\tRAG QA Arena Annotated Dataset\n\t\n\nA comprehensive multi-domain question-answering dataset with citation annotations designed for evaluating Retrieval-Augmented Generation (RAG) systems, featuring faithful answers with proper source attribution across 6 specialized domains.\n\n\t\n\t\t\n\t\t🎯 Dataset Overview\n\t\n\nThis annotated version of the RAG QA Arena dataset includes citation information and gold document IDs, making it ideal for evaluating not just answer accuracy but also answer grounding… See the full description on the dataset page: https://huggingface.co/datasets/rajistics/rag-qa-arena.","first_N":5,"first_N_keywords":["question-answering","text-generation","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Scientific_Research_Tokenized","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Allanatrix/Scientific_Research_Tokenized","creator_name":"Allanatrix","creator_url":"https://huggingface.co/Allanatrix","description":"\n\t\n\t\t\n\t\tScientific Dataset for 110M Mixture-of-Experts Model\n\t\n\nStatus: Active \n— Allan\n","first_N":5,"first_N_keywords":["token-classification","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"s1_54k_filter","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/XuHu6736/s1_54k_filter","creator_name":"XuHu","creator_url":"https://huggingface.co/XuHu6736","description":"\n\t\n\t\t\n\t\tDataset Card for XuHu6736/s1_54k_filter\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nXuHu6736/s1_54k_filter is a filtered version of the XuHu6736/s1_59k dataset. This dataset has been processed to remove records containing empty or null values in any field, with the specific exception of the 'cot' (Chain-of-Thought) column. If any other field in a record is empty, that entire record is discarded.\nThe original s1_59k dataset was prepared for Supervised Fine-Tuning (SFT) of large language models by… See the full description on the dataset page: https://huggingface.co/datasets/XuHu6736/s1_54k_filter.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"aifgen-piecewise-preference-shift","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LifelongAlignment/aifgen-piecewise-preference-shift","creator_name":"Lifelong Alignment of Agents","creator_url":"https://huggingface.co/LifelongAlignment","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset is a continual dataset in a piecewise non stationarity scenario of both domains and preferences given a combination of given three recurring tasks:\n\nDomain: Politics, Objective: Generation, Preference: Respond like a rapper\nDomain: Politics, Objective: Generation, Preference: Respond like Shakespeare\nDomain: Politics, Objective: Generation, Preference: Respond formally\nDomain: Politics, Objective: Generation, Preference: Respond like a… See the full description on the dataset page: https://huggingface.co/datasets/LifelongAlignment/aifgen-piecewise-preference-shift.","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"MM-MathInstruct","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MathLLMs/MM-MathInstruct","creator_name":"LLMs for Reasoning","creator_url":"https://huggingface.co/MathLLMs","description":"\n\t\n\t\t\n\t\tMathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning\n\t\n\nRepo: https://github.com/mathllm/MathCoder\nPaper: https://huggingface.co/papers/2505.10557\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWe introduce MathCoder-VL, a series of open-source large multimodal models (LMMs) specifically tailored for general math problem-solving. We also introduce FigCodifier-8B, an image-to-code model.\n\n\t\n\t\t\nBase Model\nOurs\n\n\n\t\t\nMini-InternVL-Chat-2B-V1-5\nMathCoder-VL-2B\n\n\nInternVL2-8B… See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MM-MathInstruct.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","visual-question-answering","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"curie","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nhop/curie","creator_name":"Niklas Hoepner","creator_url":"https://huggingface.co/nhop","description":"\n\t\n\t\t\n\t\tCurie Dataset\n\t\n\nHF version of the dataset:\nCURIE: Evaluating LLMs On Multitask Scientific Long Context Understanding and Reasoning.\nAlso available via GitHub (Apache-2.0 license).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nCURIE consists of 10 tasks that are mapped to 8 datasets. The datasets are: \n\n\t\n\t\t\nDataset ID\nTask Name\nDomain\nDescription\n\n\n\t\t\nbiogr\nBiodiversity Georeferencing\nBiodiversity\nDetermine the latitude, longitude bounding box encompassing the region in the map image.\n\n\ndft\nDensity… See the full description on the dataset page: https://huggingface.co/datasets/nhop/curie.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"SOPBench","keyword":"science","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Zekunli/SOPBench","creator_name":"Zekun Li","creator_url":"https://huggingface.co/Zekunli","description":"\n\t\n\t\t\n\t\tSOPBench: Evaluating Language Agents at Following Standard Operating Procedures and Constraints\n\t\n\n\n\t\n\t\t\n\t\tPurpose and scope\n\t\n\nAs language agents increasingly automate critical tasks, their ability to follow domain-specific standard operating procedures (SOPs), policies, and constraints when taking actions and making tool calls becomes essential yet remains underexplored. To address this gap, we develop an automated evaluation pipeline with: (1) executable environments containing 167… See the full description on the dataset page: https://huggingface.co/datasets/Zekunli/SOPBench.","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"ru_biosses_sts","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kostya165/ru_biosses_sts","creator_name":"pleroma_cascade","creator_url":"https://huggingface.co/Kostya165","description":"Это переведенная на русский язык версия mteb/biosses-sts - Biomedical Semantic Similarity Estimation.\nМетрики некоторых моделей ( через косинусное сходство):\n\n\t\n\t\t\nМодель (cls-pooling)\nPearson\nSpearman\nMAE\nRMSE\n\n\n\t\t\njinaai/jina-embeddings-v3\n0.8222\n0.7768\n2.2463\n2.4468\n\n\ncointegrated/rubert-tiny2\n0.6897\n0.6793\n2.1546\n2.3944\n\n\nDeepPavlov/rubert-base-cased\n0.2982\n0.4966\n2.7042\n2.9374\n\n\nai-forever/ruRoberta-large\n-0.0096\n0.0219\n2.3931\n2.6905\n\n\n\t\n\n\n\t\n\t\t\nМодель  (mean-pooling)\nPearson\nSpearman\nMAE… See the full description on the dataset page: https://huggingface.co/datasets/Kostya165/ru_biosses_sts.","first_N":5,"first_N_keywords":["sentence-similarity","Russian","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"WebInstruct-verified","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/WebInstruct-verified","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\n\t\n\t\t\n\t\tGeneral-Reasoner: Advancing LLM Reasoning Across All Domains\n\t\n\n\n  💻 Code |\n  📄 Paper |\n  📊 Dataset |\n  🤗 Model |\n  🌐 Project Page\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\n\n  \n\n\n  \n    Figure: Effectiveness of General-Reasoner trained with diverse verifiable reasoning questions using model-based verifier compared to baseline methods on various reasoning tasks.\n  General-Reasoner is a training paradigm for large language models (LLMs), designed to robustly enhance reasoning abilities across… See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/WebInstruct-verified.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"OpenThoughts3-1.2M","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/open-thoughts/OpenThoughts3-1.2M","creator_name":"Open Thoughts","creator_url":"https://huggingface.co/open-thoughts","description":"\n    \n\n\n\npaper |\ndataset |\nmodel\n\n\n\n[!NOTE]\nWe have released a paper for OpenThoughts! See our paper here.\n\n\n \n\n\n\n\n\t\n\t\n\t\n\t\tOpenThoughts3-1.2M\n\t\n\nOpen-source state-of-the-art reasoning dataset with 1.2M rows. 🚀\nOpenThoughts3-1.2M is the third iteration in our line of OpenThoughts datasets, building on our previous OpenThoughts-114k and OpenThoughts2-1M.\nThis time around, we scale even further and generate our dataset in a much more systematic way -- OpenThoughts3-1.2M is the result of a… See the full description on the dataset page: https://huggingface.co/datasets/open-thoughts/OpenThoughts3-1.2M.","first_N":5,"first_N_keywords":["text-generation","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Open-Omega-Forge-1M","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Open-Omega-Forge-1M","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\n\n\t\n\t\t\n\t\tOpen-Omega-Forge-1M\n\t\n\n\nOpen-Omega-Forge-1M is a carefully curated and optimized collection derived from multiple high-quality datasets, specifically designed to enhance reasoning capabilities across mathematical, scientific, and coding domains. This dataset represents a focused subset that maintains the quality and diversity of reasoning patterns while providing a more manageable size for training and evaluation. A high-quality, compact reasoning dataset designed for mathematics… See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Open-Omega-Forge-1M.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Poseidon-Reasoning-5M","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Poseidon-Reasoning-5M","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\n\n\t\n\t\t\n\t\tPoseidon-Reasoning-5M\n\t\n\n\nPoseidon-Reasoning-5M is a high-quality, compact reasoning dataset curated for advanced applications in mathematics, coding, and science. The dataset distinctly emphasizes mathematical and general reasoning challenges, ensuring its suitability for large language model (LLM) research, benchmarking, and STEM-focused educational tools.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tQuick Start with Hugging Face Datasets🤗\n\t\n\npip install -U datasets\n\nfrom datasets import load_dataset\n\ndataset =… See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Poseidon-Reasoning-5M.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"MMMU","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMMU/MMMU","creator_name":"MMMU","creator_url":"https://huggingface.co/MMMU","description":"\n\t\n\t\t\n\t\tMMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI)\n\t\n\n🌐 Homepage | 🏆 Leaderboard | 🤗 Dataset | 🤗 Paper | 📖 arXiv | GitHub\n\n\t\n\t\t\n\t\n\t\n\t\t🔔News\n\t\n\n\n🛠️[2024-05-30]: Fixed duplicate option issues in Materials dataset items (validation_Materials_25; test_Materials_17, 242) and content error in validation_Materials_25.\n🛠️[2024-04-30]: Fixed missing \"-\" or \"^\" signs in Math dataset items (dev_Math_2, validation_Math_11, 12, 16; test_Math_8… See the full description on the dataset page: https://huggingface.co/datasets/MMMU/MMMU.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Open-Omega-Atom-1.5M","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Open-Omega-Atom-1.5M","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\n\n\t\n\t\t\n\t\tOpen-Omega-Atom-1.5M\n\t\n\n\nOpen-Omega-Atom-1.5M is a carefully curated and optimized collection derived from multiple high-quality datasets, specifically designed to enhance reasoning capabilities across mathematical and scientific domains. This dataset represents a focused subset that maintains the quality and diversity of reasoning patterns while providing an efficient size for training and evaluation. A high-quality, compact reasoning dataset designed for mathematics, science, and… See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Open-Omega-Atom-1.5M.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Open-Omega-Explora-2.5M","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Open-Omega-Explora-2.5M","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\n\n\t\n\t\t\n\t\tOpen-Omega-Explora-2.5M\n\t\n\n\nOpen-Omega-Explora-2.5M is a high-quality, large-scale reasoning dataset blending the strengths of both Open-Omega-Forge-1M and Open-Omega-Atom-1.5M. This unified dataset is crafted for advanced tasks in mathematics, coding, and science reasoning, featuring a robust majority of math-centric examples. Its construction ensures comprehensive coverage and balanced optimization for training, evaluation, and benchmarking in AI research, STEM education, and… See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Open-Omega-Explora-2.5M.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Poseidon-Reasoning-Mini-300K","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Poseidon-Reasoning-Mini-300K","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\n\n\t\n\t\t\n\t\tPoseidon-Reasoning-Mini-300K\n\t\n\n\nPoseidon-Reasoning-Mini-300K is a compact, high-quality reasoning dataset designed for advanced tasks in mathematics, coding, and science. This smaller-scale collection maintains the depth and quality of its larger counterparts, with a focus on multi-step and general reasoning—making it ideal for model pretraining, fine-tuning, benchmarking, and STEM educational applications.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tQuick Start with Hugging Face Datasets🤗\n\t\n\npip install -U… See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Poseidon-Reasoning-Mini-300K.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"MathVision","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MathLLMs/MathVision","creator_name":"LLMs for Reasoning","creator_url":"https://huggingface.co/MathLLMs","description":"\n\t\n\t\t\n\t\tMeasuring Multimodal Mathematical Reasoning with the MATH-Vision Dataset\n\t\n\n[💻 Github] [🌐 Homepage]  [📊 Leaderboard ] [📊 Open Source Leaderboard ] [🔍 Visualization] [📖 Paper]\n\n\t\n\t\t\n\t\n\t\n\t\t🚀 Data Usage\n\t\n\n\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"MathLLMs/MathVision\")\nprint(dataset)\n\n\n\t\n\t\t\n\t\t💥 News\n\t\n\n\n[2025.05.16] 💥 We now support the official open-source leaderboard! 🔥🔥🔥 Skywork-R1V2-38B is the best open-source model, scoring 49.7% on MATH-Vision. 🔥🔥🔥… See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathVision.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","visual-question-answering","text-generation","expert-generated"],"keywords_longer_than_N":true},
	{"name":"Celestia3-DeepSeek-R1-0528","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Celestia3-DeepSeek-R1-0528","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Click here to support our open-source dataset and model releases!\nCelestia3-DeepSeek-R1-0528 is a dataset focused on science, testing the limits of DeepSeek R1 0528's science-reasoning skills!\nThis dataset contains:\n\n90.9k synthetically generated science prompts, with all responses generated using DeepSeek R1 0528.\nPrimary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\nAll prompts are synthetic, taken… See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Celestia3-DeepSeek-R1-0528.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"b2w-reviews01","keyword":"reviews","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ruanchaves/b2w-reviews01","creator_name":"Ruan Chaves Rodrigues","creator_url":"https://huggingface.co/ruanchaves","description":"B2W-Reviews01 is an open corpus of product reviews. It contains more than 130k e-commerce customer reviews, collected from the Americanas.com website between January and May, 2018. B2W-Reviews01 offers rich information about the reviewer profile, such as gender, age, and geographical location. The corpus also has two different review rates","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","intent-classification","topic-classification"],"keywords_longer_than_N":true},
	{"name":"ScienceQA","keyword":"science","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/derek-thomas/ScienceQA","creator_name":"Derek Thomas","creator_url":"https://huggingface.co/derek-thomas","description":"\n\t\n\t\t\n\t\tDataset Card Creation Guide\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLearn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMulti-modal Multiple Choice\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nExplore more samples here.\n{'image': Image,\n 'question': 'Which of these states is farthest north?',\n 'choices': ['West Virginia', 'Louisiana', 'Arizona', 'Oklahoma'],\n 'answer': 0… See the full description on the dataset page: https://huggingface.co/datasets/derek-thomas/ScienceQA.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","other","visual-question-answering","text-classification"],"keywords_longer_than_N":true},
	{"name":"MathVista","keyword":"science","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI4Math/MathVista","creator_name":"AI for Math Reasoning","creator_url":"https://huggingface.co/AI4Math","description":"\n\t\n\t\t\n\t\tDataset Card for MathVista\n\t\n\n\nDataset Description\nPaper Information\nDataset Examples\nLeaderboard\nDataset Usage\nData Downloading\nData Format\nData Visualization\nData Source\nAutomatic Evaluation\n\n\nLicense\nCitation\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nMathVista is a consolidated Mathematical reasoning benchmark within Visual contexts. It consists of three newly created datasets, IQTest, FunctionQA, and PaperQA, which address the missing visual domains and are tailored to evaluate logical… See the full description on the dataset page: https://huggingface.co/datasets/AI4Math/MathVista.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","text-classification","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"scientific_studies","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yousefg/scientific_studies","creator_name":"Yousef Rafat Gamaleldin","creator_url":"https://huggingface.co/yousefg","description":"yousefg/scientific_studies dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"Celestia","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Celestia","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Celestia is a dataset containing science-instruct data.\nThe 2024-10-30 version contains:\n\n126k rows of synthetic science-instruct data, using synthetically generated prompts and responses generated using Llama 3.1 405b Instruct. Primary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\n\nThis dataset contains synthetically generated data and has not been subject to manual review.\n","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"gardian-cigi-ai-documents","keyword":"science","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CGIAR/gardian-cigi-ai-documents","creator_name":"CGIAR","creator_url":"https://huggingface.co/CGIAR","description":"Pages: 1,438,332\nTokens: 277,445,818\n\n\t\n\t\t\n\t\tA Curated Research Corpus for Agricultural Advisory AI Applications\n\t\n\nThis dataset represents a comprehensive collection of 43,745 agricultural research publications from CGIAR,\nspecifically processed and structured for Large Language Model (LLM) applications in agricultural advisory services. \nThis dataset bridges the gap between advanced agricultural research and field-level advisory needs, \ndrawing from CGIAR's extensive scientific knowledge… See the full description on the dataset page: https://huggingface.co/datasets/CGIAR/gardian-cigi-ai-documents.","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","10M<n<100M","doi:10.57967/hf/4327"],"keywords_longer_than_N":true},
	{"name":"WildSci","keyword":"science","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JustinTX/WildSci","creator_name":"Tengxiao Liu","creator_url":"https://huggingface.co/JustinTX","description":"\n\t\n\t\t\n\t\t🧪 WildSci: Advancing Scientific Reasoning from In-the-Wild Literature\n\t\n\n\n\t\n\t\t\n\t\tPurpose and scope\n\t\n\nDespite recent advances in LLM reasoning, there remains a notable lack of diverse, domain-rich science datasets “in the wild” to support progress on science reasoning tasks. While existing work has demonstrated strong performance in specialized areas such as mathematical reasoning, there is still a gap in datasets that capture the complexity and breadth of reasoning required across… See the full description on the dataset page: https://huggingface.co/datasets/JustinTX/WildSci.","first_N":5,"first_N_keywords":["English","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"matpes","keyword":"science","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/mavrl/matpes","creator_name":"Materials Virtual Lab","creator_url":"https://huggingface.co/mavrl","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPotential energy surface datasets with near-complete coverage of the periodic table are used to train foundation\npotentials (FPs), i.e., machine learning interatomic potentials (MLIPs) with near-complete coverage of the periodic\ntable.  MatPES is an initiative by the Materials Virtual Lab and the Materials Project to address\ncritical deficiencies in such PES datasets for materials.\n\nAccuracy. MatPES is computed using static DFT calculations with stringent… See the full description on the dataset page: https://huggingface.co/datasets/mavrl/matpes.","first_N":5,"first_N_keywords":["tabular-regression","English","bsd-3-clause","100K<n<1M","arxiv:2306.06482"],"keywords_longer_than_N":true},
	{"name":"SFE","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PrismaX/SFE","creator_name":"PrismaX","creator_url":"https://huggingface.co/PrismaX","description":"\n\t\n\t\t\n\t\tScientists' First Exam: Probing Cognitive Abilities of MLLM via Perception, Understanding, and Reasoning\n\t\n\n\n  \n\n\n\n| Leaderboard | Paper  | Website  | HuggingFace  |\n\n\n\n\nLatest News 🔥\n[Latest] We officially released SFE! SFE is designed to evaluate the scientific cognitive capacities of MLLMs through three cognitive levels: scientific signal perception, scientific attribute understanding, and scientific comparative reasoning.\n\nUnfold to see more details.\n\n\n\n[2025/06] We officially… See the full description on the dataset page: https://huggingface.co/datasets/PrismaX/SFE.","first_N":5,"first_N_keywords":["visual-question-answering","English","Chinese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"letterboxd-all-movie-data","keyword":"reviews","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pkchwy/letterboxd-all-movie-data","creator_name":"Salih Mert Canseven","creator_url":"https://huggingface.co/pkchwy","description":"\n\t\n\t\t\n\t\tLetterboxd Film Dataset\n\t\n\nThis dataset contains a comprehensive collection of 847,209 films from the Letterboxd platform, including movie information, user reviews, and ratings.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Films: 847,209\nFile Size: ~1.12 GB (1,120,572,122 bytes)\nFormat: JSONL (JSON Lines)\nLanguage: Primarily English, with some multilingual content\n\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach line contains a JSON object with the following fields:\n{\n  \"url\":… See the full description on the dataset page: https://huggingface.co/datasets/pkchwy/letterboxd-all-movie-data.","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","English","Turkish"],"keywords_longer_than_N":true},
	{"name":"multiscale_rotten_tomatoes_critic_reviews","keyword":"reviews","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/frankier/multiscale_rotten_tomatoes_critic_reviews","creator_name":"Frankie Robertson","creator_url":"https://huggingface.co/frankier","description":"Cleaned up version of the rotten tomatoes critic reviews dataset. The original\nis obtained from Kaggle:\nhttps://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset\nData has been scraped from the publicly available website\nhttps://www.rottentomatoes.com as of 2020-10-31.\nThe clean up process drops anything without both a review and a rating, as well\nas standardising the ratings onto several integer, ordinal scales.\nRequires the kaggle library to be… See the full description on the dataset page: https://huggingface.co/datasets/frankier/multiscale_rotten_tomatoes_critic_reviews.","first_N":5,"first_N_keywords":["text-classification","text-scoring","sentiment-scoring","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"shopee-reviews-tl-stars","keyword":"reviews","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/scaredmeow/shopee-reviews-tl-stars","creator_name":"Neil Riego","creator_url":"https://huggingface.co/scaredmeow","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nTagalog (TL)\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA typical data point, comprises of a text and the corresponding label.\nAn example from the YelpReviewFull test set looks as follows:\n{\n    'label': 2… See the full description on the dataset page: https://huggingface.co/datasets/scaredmeow/shopee-reviews-tl-stars.","first_N":5,"first_N_keywords":["text-classification","Tagalog","mpl-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"amazon_reviews_mobile_electronics","keyword":"reviews","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rkf2778/amazon_reviews_mobile_electronics","creator_name":"Rohit Kochikkat Francis","creator_url":"https://huggingface.co/rkf2778","description":"rkf2778/amazon_reviews_mobile_electronics dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","English","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"TheoremQA","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/TheoremQA","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\n\t\n\t\t\n\t\tDataset Card for \"TheoremQA\"\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWe propose the first question-answering dataset driven by STEM theorems. We annotated 800 QA pairs covering 350+ theorems spanning across Math, EE&CS, Physics and Finance. The dataset is collected by human experts with very high quality. We provide the dataset as a new benchmark to test the limit of large language models to apply theorems to solve challenging university-level questions. We provide a pipeline in the following to… See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/TheoremQA.","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"geo-reviews-dataset-2023","keyword":"reviews","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/geo-reviews-dataset-2023","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\n\t\n\t\t\n\t\tGeo Reviews Dataset 2023\n\t\n\nYandex is making available the largest Russian-language dataset of reviews about organizations published on Yandex Maps.\nUse it for academic and research purposes, share your results with us in Issues.\n\n\t\n\t\t\n\t\tDescription\n\t\n\n\n500,000 unique reviews\nOnly reviews about organizations in Russia\nAvailable on Yandex Maps\nPublished from January to July 2023\nThe dataset does not contain short one-word reviews\nReviews have been cleared of personal data (phone numbers… See the full description on the dataset page: https://huggingface.co/datasets/d0rj/geo-reviews-dataset-2023.","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","token-classification","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"arxiv-metadata-snapshot","keyword":"science","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/librarian-bots/arxiv-metadata-snapshot","creator_name":"Librarian Bots","creator_url":"https://huggingface.co/librarian-bots","description":"\n\t\n\t\t\n\t\tDataset Card for \"arxiv-metadata-oai-snapshot\"\n\t\n\nMore Information needed\nThis is a mirror of the metadata portion of the arXiv dataset. \nThe sync will take place weekly so may fall behind the original datasets slightly if there are more regular updates to the source dataset. \n\n\t\n\t\t\n\t\n\t\n\t\tMetadata\n\t\n\nThis dataset is a mirror of the original ArXiv data. This dataset contains an entry for each paper, containing:\n\nid: ArXiv ID (can be used to access the paper, see below)\nsubmitter: Who… See the full description on the dataset page: https://huggingface.co/datasets/librarian-bots/arxiv-metadata-snapshot.","first_N":5,"first_N_keywords":["text-generation","text-classification","English","cc0-1.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"UltraTextbooks","keyword":"science","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/UltraTextbooks","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\n\t\n\t\t\n\t\tDataset Card for \"UltraTextbooks\"\n\t\n\n\nIn the digital expanse, a Tree of Knowledge grows,\nIts branches of code and words intertwine in prose.\nSynthetic leaves shimmer, human insights compose,\nA binary symphony where wisdom forever flows.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tRepository\n\t\n\nThe \"UltraTextbooks\" dataset is hosted on the Hugging Face platform.\n\n\t\n\t\t\n\t\n\t\n\t\tPurpose\n\t\n\nThe \"UltraTextbooks\" dataset is a comprehensive collection of high-quality synthetic and… See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/UltraTextbooks.","first_N":5,"first_N_keywords":["text-generation","English","code","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"nlp_taxonomy_data","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TimSchopf/nlp_taxonomy_data","creator_name":"Tim Schopf","creator_url":"https://huggingface.co/TimSchopf","description":"\n\t\n\t\t\n\t\tNLP Taxonomy Classification Data\n\t\n\nThe dataset consists of titles and abstracts from NLP-related papers. Each paper is annotated with multiple fields of study from the NLP taxonomy. Each sample is annotated with all possible lower-level concepts and their hypernyms in the NLP taxonomy. The training dataset contains 178,521 weakly annotated samples. The test dataset consists of 828 manually annotated samples from the EMNLP22 conference. The manually labeled test dataset might not… See the full description on the dataset page: https://huggingface.co/datasets/TimSchopf/nlp_taxonomy_data.","first_N":5,"first_N_keywords":["text-classification","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"arxiv_categories","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TimSchopf/arxiv_categories","creator_name":"Tim Schopf","creator_url":"https://huggingface.co/TimSchopf","description":"📄 Paper: Efficient Few-shot Learning for Multi-label Classification of Scientific Documents with Many Classes (ICNLSP 2024)\n💻 GitHub: https://github.com/sebischair/FusionSent\nThis is a dataset of scientific documents derived from arXiv metadata. The arXiv metadata provides information about more than 2 million scholarly articles published in arXiv from various scientific fields. We use this metadata to create a dataset of 203,961 titles and abstracts categorized into 130 different classes.… See the full description on the dataset page: https://huggingface.co/datasets/TimSchopf/arxiv_categories.","first_N":5,"first_N_keywords":["text-classification","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"MMMU","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aslessor/MMMU","creator_name":"Alex","creator_url":"https://huggingface.co/aslessor","description":"\n\t\n\t\t\n\t\tMMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI)\n\t\n\n🌐 Homepage | 🤗 Dataset | 🤗 Paper | 📖 arXiv | GitHub\n\n\t\n\t\t\n\t\n\t\n\t\t🔔News\n\t\n\n\n🔥[2023-12-04]: Our evaluation server for test set is now availble on EvalAI. We welcome all submissions and look forward to your participation! 😆\n\n\n\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe introduce MMMU: a new benchmark designed to evaluate multimodal models on massive multi-discipline… See the full description on the dataset page: https://huggingface.co/datasets/aslessor/MMMU.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"TaoGPT-v1","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/agency888/TaoGPT-v1","creator_name":"agency","creator_url":"https://huggingface.co/agency888","description":"\n\t\n\t\t\n\t\tToaGPT Dataset\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Adithya S K\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [English]\nLicense: [MIT]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: https://github.com/agencyxr/taogpt7B\nDemo [optional]: [More Information Needed]… See the full description on the dataset page: https://huggingface.co/datasets/agency888/TaoGPT-v1.","first_N":5,"first_N_keywords":["question-answering","table-question-answering","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Luganda_Sci-Math-Bio_Translations","keyword":"science","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allandclive/Luganda_Sci-Math-Bio_Translations","creator_name":"Allan D Clive","creator_url":"https://huggingface.co/allandclive","description":"\n\t\n\t\t\n\t\tLuganda Sci-Math-Bio Translations\n\t\n\nThis dataset contains Luganda and English translations of biologicial, mathematical and scientific terms\n","first_N":5,"first_N_keywords":["translation","Ganda","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"arc-cot","keyword":"science","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/arc-cot","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\n\t\n\t\t\n\t\tAugmented ARC-Challenge Dataset with Chain-of-Thought Reasoning\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset was created by augmenting the train subset of the AI2 Reasoning Challenge (ARC) dataset with chain-of-thought reasoning generated by Google's Gemini Pro language model. The goal is to provide additional context and intermediate reasoning steps to help models better solve the challenging multiple-choice science questions in ARC.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains… See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/arc-cot.","first_N":5,"first_N_keywords":["question-answering","English","cc-by-sa-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"food_reviews-sentiment-analysis","keyword":"reviews","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Shekswess/food_reviews-sentiment-analysis","creator_name":"Bojan Jakimovski","creator_url":"https://huggingface.co/Shekswess","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\n\nTopic: Food Reviews\nDomains: Fast Food, Fine Dining, Home Cooking\nFocus: This dataset contains food reviews for different styles of cooking.\nNumber of Entries: 500\nDataset Type: Sentiment Analysis Dataset\nModel Used: bedrock/us.amazon.nova-pro-v1:0\nLanguage: English\nAdditional Information: The dataset is designed to help analyze the sentiment of reviews across various food styles.\nGenerated by: SynthGenAI Package\n\n","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"scidocs-keywords-exkeyliword","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nicolauduran45/scidocs-keywords-exkeyliword","creator_name":"Nicolau Duran","creator_url":"https://huggingface.co/nicolauduran45","description":"\n\t\n\t\t\n\t\tSciDocs Keywords exKEYliWORD\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSciDocs2Keywords is a dataset consisting of scientific papers (title and abstract) and their associated author-provided keywords. It is designed for use in task of keyword extraction or abstraction.\nEach entry in the dataset includes:\n\nTitle: The title of the scientific paper.\nAbstract: A brief summary of the paper.\nAuthor Keywords: Keywords provided by the authors to highlight the main topics or concepts of the paper.… See the full description on the dataset page: https://huggingface.co/datasets/nicolauduran45/scidocs-keywords-exkeyliword.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"OpenThoughts-TR-18k","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/selimc/OpenThoughts-TR-18k","creator_name":"selim","creator_url":"https://huggingface.co/selimc","description":"\n\t\n\t\t\n\t\tOpenThoughts-TR-18k: Turkish Synthetic Reasoning Dataset\n\t\n\nOpenThoughts-TR-18k is a Turkish translation of a subset of the original Open-Thoughts-114k dataset. It contains ~18k high-quality synthetic reasoning examples covering mathematics, science, coding problems, and puzzles, all translated into Turkish. This dataset is designed to support reasoning task fine tuning for Turkish language models.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n~18k translated reasoning examples\nCovers multiple domains:… See the full description on the dataset page: https://huggingface.co/datasets/selimc/OpenThoughts-TR-18k.","first_N":5,"first_N_keywords":["Turkish","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"aifgen-short-piecewise","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LifelongAlignment/aifgen-short-piecewise","creator_name":"Lifelong Alignment of Agents","creator_url":"https://huggingface.co/LifelongAlignment","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset is a continual dataset in short piecewise scenario given two tasks:\n\nDomain: Education (math, sciences, and social sciences), Objective: QnA, Preference: hinted answer\nDomain: Education (math, sciences, and social sciences), Objective: QnA, Preference: direct answer\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nAs a subset of a larger repository of datasets generated and curated carefully for Lifelong Alignment of Agents… See the full description on the dataset page: https://huggingface.co/datasets/LifelongAlignment/aifgen-short-piecewise.","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"aifgen-lipschitz","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LifelongAlignment/aifgen-lipschitz","creator_name":"Lifelong Alignment of Agents","creator_url":"https://huggingface.co/LifelongAlignment","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset is a continual dataset in lipschitz bounded scenario given three tasks:\n\nDomain: Technology and Physics, Objective: Summarization, Preference: Explain Like I'm 5\nDomain: Technology and Physics, Objective: Summarization, Preference: Explain Like I'm a High School Student\nDomain: Technology and Physics, Objective: Summarization, Preference: Explain Like I'm an expert\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\nAs a… See the full description on the dataset page: https://huggingface.co/datasets/LifelongAlignment/aifgen-lipschitz.","first_N":5,"first_N_keywords":["summarization","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"aifgen-domain-preference-shift","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LifelongAlignment/aifgen-domain-preference-shift","creator_name":"Lifelong Alignment of Agents","creator_url":"https://huggingface.co/LifelongAlignment","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset is a continual dataset in a mixed non stationarity scenario of both domains and preferences given a combination of given two tasks:\n\nDomain: Education (math, sciences, and social sciences), Objective: QnA, Preference: Explain like I'm 5 answer\nDomain: Education (math, sciences, and social sciences), Objective: QnA, Preference: Expert answer\nDomain: Politics, Objective: Summary, Preference: Explain like I'm 5 answer\nDomain: Politics… See the full description on the dataset page: https://huggingface.co/datasets/LifelongAlignment/aifgen-domain-preference-shift.","first_N":5,"first_N_keywords":["question-answering","summarization","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"aifgen-long-piecewise","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LifelongAlignment/aifgen-long-piecewise","creator_name":"Lifelong Alignment of Agents","creator_url":"https://huggingface.co/LifelongAlignment","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset is a continual dataset in long piecewise scenario given two tasks:\n\nDomain: Education (math, sciences, and social sciences), Objective: QnA, Preference: hinted answer\nDomain: Education (math, sciences, and social sciences), Objective: QnA, Preference: direct answer\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nAs a subset of a larger repository of datasets generated and curated carefully for Lifelong Alignment of Agents… See the full description on the dataset page: https://huggingface.co/datasets/LifelongAlignment/aifgen-long-piecewise.","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"dataclysm-arxiv","keyword":"science","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/somewheresystems/dataclysm-arxiv","creator_name":"S2","creator_url":"https://huggingface.co/somewheresystems","description":"\n\t\n\t\t\n\t\tDATACLYSM PATCH 0.0.2: ARXIV\n\t\n\n\n\t\n\t\t\n\t\tUSE THE NOTEBOOK TO GET STARTED!\n\t\n\nhttps://github.com/somewheresystems/dataclysm\n\n\n\t\n\t\t\n\t\n\t\n\t\tsomewheresystems/dataclysm-wikipedia-titles\n\t\n\nThis dataset comprises of 3,360,984 English language arXiv papers from the Cornell/arXiv dataset, with two new columns added: title-embeddings and abstract-embeddings. These additional columns were generated using the bge-small-en-v1.5 embeddings model. The dataset was sourced from the Cornell/arXiv GCP… See the full description on the dataset page: https://huggingface.co/datasets/somewheresystems/dataclysm-arxiv.","first_N":5,"first_N_keywords":["English","cc0-1.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"dataclysm-pubmed","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/somewheresystems/dataclysm-pubmed","creator_name":"S2","creator_url":"https://huggingface.co/somewheresystems","description":"\n\t\n\t\t\n\t\n\t\n\t\tDATACLYSM PATCH 0.0.4: PUBMED\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tUSE THE NOTEBOOK TO GET STARTED!\n\t\n\nhttps://github.com/somewheresystems/dataclysm\n\n\t\n\t\t\n\t\n\t\n\t\tsomewheresystems/dataclysm-pubmed\n\t\n\nThis dataset comprises of 35.7 million PubMed metadata entries including title and some (~69% with) abstracts, with two new columns added: title-embeddings and abstract-embeddings. These additional columns were generated using the bge-small-en-v1.5 embeddings model. The dataset was sourced from the PubMed… See the full description on the dataset page: https://huggingface.co/datasets/somewheresystems/dataclysm-pubmed.","first_N":5,"first_N_keywords":["English","apache-2.0","10M<n<100M","🇺🇸 Region: US","pubmed"],"keywords_longer_than_N":true},
	{"name":"yandex-geo-reviews-embeddings","keyword":"reviews","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lockiultra/yandex-geo-reviews-embeddings","creator_name":"Dmitry","creator_url":"https://huggingface.co/lockiultra","description":"Dataset full description: https://www.kaggle.com/datasets/lockiultra/yandex-geo-reviews-embeddings\nDataset contains index column, 768 embedding columns and rating column. Each row corresponds to an embedding representation of the review text with same index.\n","first_N":5,"first_N_keywords":["feature-extraction","Russian","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"Astro-mcqa","keyword":"science","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/patrickfleith/Astro-mcqa","creator_name":"Patrick Fleith","creator_url":"https://huggingface.co/patrickfleith","description":"\n\t\n\t\t\n\t\tAstroMCQA Dataset\n\t\n\n\n\t\n\t\t\n\t\tPurpose and scope\n\t\n\nThe primary purpose of AstroMCQA is for application developers in the domain of space engineering to be able to comparatively assess LLM performances on the specific task of multiple-choice question-answering\n\n\t\n\t\t\n\t\tIntended Usage\n\t\n\nComparative assessement of differents LLMs, Model evaluation, audit, and model selection. Assessment of different quantization levels, different prompting strategies, and assessing effectiveness of domain… See the full description on the dataset page: https://huggingface.co/datasets/patrickfleith/Astro-mcqa.","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"amazon-food-reviews-dataset","keyword":"reviews","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jhan21/amazon-food-reviews-dataset","creator_name":"misschestnut","creator_url":"https://huggingface.co/jhan21","description":"\n\t\n\t\t\n\t\tDataset Card for \"Amazon Food Reviews\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be used for numerous tasks like sentiment analysis, text… See the full description on the dataset page: https://huggingface.co/datasets/jhan21/amazon-food-reviews-dataset.","first_N":5,"first_N_keywords":["text-classification","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"ghana-news","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/ghana-news","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\n\t\n\t\t\n\t\tDescription 🙅‍♂️🤖\n\t\n\nGhanaNews dataset is a collection of news articles from various Ghanaian News Portals (MyJoyOnline, GraphicOnline, GhanaWeb, PulseGh, CitiNewsOnline, ect). The dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc), information retrieval (ranking, search, etc), xml, data compression, data streaming, and any other non-commercial activity.\nThe Ghana news topic classification dataset is constructed by… See the full description on the dataset page: https://huggingface.co/datasets/worldboss/ghana-news.","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"VisualWebInstruct-Seed","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct-Seed","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis is the seed dataset we used to conduct Google Search.\n\n\t\n\t\t\n\t\tLinks\n\t\n\nGithub|\nPaper|\nWebsite\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@article{visualwebinstruct,\n    title={VisualWebInstruct: Scaling up Multimodal Instruction Data through Web Search},\n    author = {Jia, Yiming and Li, Jiachen and Yue, Xiang and Li, Bo and Nie, Ping and Zou, Kai and Chen, Wenhu},\n    journal={arXiv preprint arXiv:2503.10582},\n    year={2025}\n}\n\n","first_N":5,"first_N_keywords":["question-answering","image-text-to-text","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SciFact-512-192-gpt-4o-2024-05-13-866232","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-866232","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSciFact-512-192-gpt-4o-2024-05-13-866232 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-512-192-gpt-4o-2024-05-13-866232 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-866232.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-512-192-gpt-4o-2024-05-13-650620","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-650620","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSCIDOCS-512-192-gpt-4o-2024-05-13-650620 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"arxiv paper domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SCIDOCS-512-192-gpt-4o-2024-05-13-650620 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-650620.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"AstroChat","keyword":"science","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/patrickfleith/AstroChat","creator_name":"Patrick Fleith","creator_url":"https://huggingface.co/patrickfleith","description":"\n\t\n\t\t\n\t\tAstroChat Dataset Description\n\t\n\n\n\t\n\t\t\n\t\tPurpose and Scope\n\t\n\nThe AstroChat dataset is a collection of 901 dialogues, synthetically generated, tailored to the specific domain of Astronautics / Space Mission Engineering.\nThis dataset will be frequently updated following feedback from the community. If you would like to contribute, please reach out in the community discussion.\n\n\t\n\t\t\n\t\tIntended Use\n\t\n\nThe dataset is intended to be used for supervised fine-tuning of chat LLMs (Large… See the full description on the dataset page: https://huggingface.co/datasets/patrickfleith/AstroChat.","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"gliner-bird-diet-synthetic","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wjbmattingly/gliner-bird-diet-synthetic","creator_name":"William Mattingly","creator_url":"https://huggingface.co/wjbmattingly","description":"\n\t\n\t\t\n\t\n\t\n\t\tGLiNER Bird Diet Synthetic Dataset\n\t\n\nThis is an NER dataset focused on ornithological data, specifically focused on the diets of birds. The data is purely synthetic and should not be taken as factual. We created this dataset using Qwen2-7B-Instruct. It consists of ~2k descriptions. The format of the annotations consists with the GLiNER format. We used this data to finetune a GLiNER model. For the base model, we used NuNerZero Span. You can visit our model here: GLiNER Ecology… See the full description on the dataset page: https://huggingface.co/datasets/wjbmattingly/gliner-bird-diet-synthetic.","first_N":5,"first_N_keywords":["token-classification","English","mit","1K<n<10K","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"CoMDataset","keyword":"science","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qijimrc/CoMDataset","creator_name":"Ji Qi","creator_url":"https://huggingface.co/qijimrc","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nWe open-source both the Automatically Synthesized CoM Data and the Manually Annotated CoM-Math Data to facilitate potential research. The automatically synthesized CoM data (i.e., com.jsonl) consists of 84K positive reasoning chains, which was produced by an automated data generation pipeline with an LLM-based (GPT-4) linguistic solving steps generation and a VFMs-based (GroundingDINO, PaddleOCR) visual evidence compensation upon massive public VQA samples. We… See the full description on the dataset page: https://huggingface.co/datasets/qijimrc/CoMDataset.","first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","expert-generated","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-15062024-atex-webapp","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-15062024-atex-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"general domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-15062024-atex-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-1562024-to89-webapp","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1562024-to89-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tBAAI_bge-large-en-v1_5-1562024-to89-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific research in medicine, biology, and technology\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the BAAI_bge-large-en-v1_5-1562024-to89-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1562024-to89-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scientific_papers_from_arxiv","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scientific_papers_from_arxiv","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tscientific_papers_from_arxiv Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic paper search for scientific research\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scientific_papers_from_arxiv model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scientific_papers_from_arxiv.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MAiDE-up","keyword":"reviews","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MichiganNLP/MAiDE-up","creator_name":"LIT @ UMich","creator_url":"https://huggingface.co/MichiganNLP","description":"\n\t\n\t\t\n\t\tDataset Card for MAiDE-up: Multilingual Deception Detection of GPT-generated Hotel Reviews\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMultilingual Deception Detection of GPT-generated Hotel Reviews. We compare real hotel reviews from Booking with LLM-generated hotel reviews in 10 languages.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in 10 languages: Chinese, English, French, German, Italian, Romanian, Korean, Russian, Spanish, Turkish\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTODO… See the full description on the dataset page: https://huggingface.co/datasets/MichiganNLP/MAiDE-up.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-scidocs","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scidocs","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-scidocs Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-scidocs model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scidocs.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for scientific papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tscidocs Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for scientific papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tscidocs-c Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset\n\ndataset =… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Amazon_Reviews_Binary_for_Sentiment_Analysis","keyword":"reviews","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yassiracharki/Amazon_Reviews_Binary_for_Sentiment_Analysis","creator_name":"yassir acharki","creator_url":"https://huggingface.co/yassiracharki","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThe Amazon reviews polarity dataset is constructed by taking review score 1 and 2 as negative, and 4 and 5 as positive. Samples of score 3 is ignored. In the dataset, class 1 is the negative and class 2 is the positive. Each class has 1,800,000 training samples and 200,000 testing samples.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe files train.csv and test.csv contain all the training samples as comma-sparated values. There are 3… See the full description on the dataset page: https://huggingface.co/datasets/yassiracharki/Amazon_Reviews_Binary_for_Sentiment_Analysis.","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"Amazon_Reviews_for_Sentiment_Analysis_fine_grained_5_classes","keyword":"reviews","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yassiracharki/Amazon_Reviews_for_Sentiment_Analysis_fine_grained_5_classes","creator_name":"yassir acharki","creator_url":"https://huggingface.co/yassiracharki","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThe Amazon reviews full score dataset is constructed by randomly taking 600,000 training samples and 130,000 testing samples for each review score from 1 to 5. In total there are 3,000,000 trainig samples and 650,000 testing samples.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe files train.csv and test.csv contain all the training samples as comma-sparated values. There are 3 columns in them, corresponding to class index (1 to 5)… See the full description on the dataset page: https://huggingface.co/datasets/yassiracharki/Amazon_Reviews_for_Sentiment_Analysis_fine_grained_5_classes.","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"Yelp_Reviews_for_Binary_Senti_Analysis","keyword":"reviews","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yassiracharki/Yelp_Reviews_for_Binary_Senti_Analysis","creator_name":"yassir acharki","creator_url":"https://huggingface.co/yassiracharki","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThe Yelp reviews polarity dataset is constructed by considering stars 1 and 2 negative, and 3 and 4 positive. For each polarity 280,000 training samples and 19,000 testing samples are take randomly. In total there are 560,000 trainig samples and 38,000 testing samples. Negative polarity is class 1, and positive class 2.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe files train.csv and test.csv contain all the training samples as comma-sparated values. There are 2… See the full description on the dataset page: https://huggingface.co/datasets/yassiracharki/Yelp_Reviews_for_Binary_Senti_Analysis.","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"Yelp_Reviews_for_Sentiment_Analysis_fine_grained_5_classes","keyword":"reviews","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yassiracharki/Yelp_Reviews_for_Sentiment_Analysis_fine_grained_5_classes","creator_name":"yassir acharki","creator_url":"https://huggingface.co/yassiracharki","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThe Yelp reviews full star dataset is constructed by randomly taking 130,000 training samples and 10,000 testing samples for each review star from 1 to 5. In total there are 650,000 trainig samples and 50,000 testing samples.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe files train.csv and test.csv contain all the training samples as comma-sparated values. There are 2 columns in them, corresponding to class index (1 to 5) and review text. The review texts are… See the full description on the dataset page: https://huggingface.co/datasets/yassiracharki/Yelp_Reviews_for_Sentiment_Analysis_fine_grained_5_classes.","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-128-24","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tscidocs-c-128-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic search for scientific papers\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-128-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-128-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-256-24","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tscidocs-c-256-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic paper search for scientific articles\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-256-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-256-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-64-24","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tscidocs-c-64-24 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"academic research papers search engine\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the scidocs-c-64-24 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\nfrom datasets import load_dataset… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"M4U","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/M4U-Benchmark/M4U","creator_name":"M4U-Benchmark","creator_url":"https://huggingface.co/M4U-Benchmark","description":"\n\t\n\t\t\n\t\tM4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models\n\t\n\nCode for the Paper M4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models.\n[Webpage] [Paper] [Huggingface Dataset] [Leaderboard]\n\n\t\n\t\t\n\t\n\t\n\t\t💥 News 💥\n\t\n\n\n[2024.05.23] Our paper, dataset and code are public aviailable.\n\n\n\t\n\t\n\t\n\t\t👀 About M4U\n\t\n\n\n     \n\n\nMultilingual multimodal reasoning is a core component to achieve human-level intelligence. However, most of the… See the full description on the dataset page: https://huggingface.co/datasets/M4U-Benchmark/M4U.","first_N":5,"first_N_keywords":["visual-question-answering","English","Chinese","German","mit"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5222024-hkde-webapp","keyword":"reviews","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5222024-hkde-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-5222024-hkde-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"code repository search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-5222024-hkde-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5222024-hkde-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-526066","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-526066","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-526066 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-526066 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-526066.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-994884","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-994884","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-994884 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-994884 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-994884.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-3778","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-3778","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-3778 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-3778 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-3778.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-204265","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-204265","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-204265 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-204265 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-204265.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-499715","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-499715","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-499715 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-499715 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-499715.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-478897","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-478897","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\n\t\n\t\t\n\t\tSciFact-256-24-gpt-4o-2024-05-13-478897 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"scientific claim verification\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-478897 model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-478897.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MMMU_Pro","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMMU/MMMU_Pro","creator_name":"MMMU","creator_url":"https://huggingface.co/MMMU","description":"\n\t\n\t\t\n\t\tMMMU-Pro (A More Robust Multi-discipline Multimodal Understanding Benchmark)\n\t\n\n🌐 Homepage | 🏆 Leaderboard | 🤗 Dataset | 🤗 Paper | 📖 arXiv | GitHub\n\n\t\n\t\t\n\t\n\t\n\t\t🔔News\n\t\n\n\n🛠️🛠️ [2025-03-08] Fixed mismatch between inner image labels and shuffled options in Vision and Standard (10 options) settings. (test_Chemistry_5,94,147,216,314,345,354,461,560,570; test_Materials_450; test_Pharmacy_198; validation_Chemistry_12,26,29; validation_Materials_10,28; validation_Psychology_1)… See the full description on the dataset page: https://huggingface.co/datasets/MMMU/MMMU_Pro.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"gardian-ai-ready-docs","keyword":"science","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CGIAR/gardian-ai-ready-docs","creator_name":"CGIAR","creator_url":"https://huggingface.co/CGIAR","description":"\n\n\t\n\t\t\n\t\t⚠️ Heads up: Updated Dataset Available\n\t\n\nThis dataset has been updated with a newer version published on 27 Feb 2025. The latest version includes more updated and refined set of documents.\nWe recommend using the latest version, available at https://huggingface.co/datasets/CGIAR/gardian-cigi-ai-documents. This version remains accessible for reference and reproducibility purposes.\n\n\n\t\n\t\t\n\t\n\t\n\t\tA Curated Research Corpus for Agricultural Advisory AI Applications\n\t\n\nThis dataset… See the full description on the dataset page: https://huggingface.co/datasets/CGIAR/gardian-ai-ready-docs.","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"KhmunuChronicles","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/KhmunuChronicles","creator_name":"NIONGOLO Chrys Fé-Marty","creator_url":"https://huggingface.co/Svngoku","description":"Svngoku/KhmunuChronicles dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","French","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"science_materials","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deep-principle/science_materials","creator_name":"Deep Principle","creator_url":"https://huggingface.co/deep-principle","description":"deep-principle/science_materials dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","csv","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"amazon-2023-all-category-k-core","keyword":"reviews","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChenglongMa/amazon-2023-all-category-k-core","creator_name":"Chenglong Ma","creator_url":"https://huggingface.co/ChenglongMa","description":"\n\t\n\t\t\n\t\tDataset Card for Amazon Reviews 2023 All-Category k-Core\n\t\n\n\nThese datasets are subsets of Amazon reviews dataset, collected in 2023 by McAuley Lab. \n\nIt contains all categories of the reviews from the original dataset that have more than $k \\in [5, 20]$ interactions. \n\nThe original dataset contains reviews in the period of May. 1996 to Sep. 2023. \n\nThe reviews are grouped into 25 categories. \n\nThe dataset is in .parquet format.\n\n\n\n\nk-core means that every user and every item has at… See the full description on the dataset page: https://huggingface.co/datasets/ChenglongMa/amazon-2023-all-category-k-core.","first_N":5,"first_N_keywords":["English","gpl-3.0","100M - 1B","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"VISCO","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/uclanlp/VISCO","creator_name":"UCLA NLP","creator_url":"https://huggingface.co/uclanlp","description":"\n\t\n\t\t\n\t\n\t\n\t\tVISCO\n\t\n\nBenchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning\n🌐 Project | 📖 Paper | 💻 Github\n\n\nOutline:\n\nIntroduction\nData\nCitation\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nVISCO is a benchmark for evaluating the critique and correction capabilities of LVLMs. VISCO contains:\n\n1645 pairs of questions and LVLM-generated answers. Each answer includes a chain-of-thought with multiple reasonign steps.\n5604 step-wise annotations of critique, showing… See the full description on the dataset page: https://huggingface.co/datasets/uclanlp/VISCO.","first_N":5,"first_N_keywords":["visual-question-answering","English","mit","1K<n<10K","arxiv:2412.02172"],"keywords_longer_than_N":true},
	{"name":"Celestia2","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Celestia2","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Celestia 2 is a multi-turn agent-instruct dataset containing science data.\nThis dataset focuses on challenging multi-turn conversations and contains:\n\n176k rows of synthetic multi-turn science-instruct data, using Microsoft's AgentInstruct style. All prompts and responses are synthetically generated using Llama 3.1 405b Instruct. Primary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\n\nThis dataset… See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Celestia2.","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"protobowl-11-13","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mgor/protobowl-11-13","creator_name":"Maharshi Gor","creator_url":"https://huggingface.co/mgor","description":"\n\t\n\t\t\n\t\tProgressive Quiz Bowl Clues Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains Quiz Bowl questions and their corresponding progressive clues, designed for evaluating question-answering systems.\nThe progressive clues subset contains additional features such as GPT-3.5 generated categories and subcategories specific to each progressive clue.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nName: protobowl-11-13\nVersion: 1.0\nMaintainer: mgor\nHub URL: https://huggingface.co/datasets/mgor/protobowl-11-13… See the full description on the dataset page: https://huggingface.co/datasets/mgor/protobowl-11-13.","first_N":5,"first_N_keywords":["question-answering","text-retrieval","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"MultiSimV2","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MichaelR207/MultiSimV2","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","description":"\n\t\n\t\t\n\t\tDataset Card for MultiSim Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe MultiSim benchmark is a growing collection of text simplification datasets targeted at sentence simplification in several languages.  Currently, the benchmark spans 12 languages.\n\n\n\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\n\nSentence Simplification\n\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets importload_dataset\n\ndataset = load_dataset(\"MichaelR207/MultiSimV2\")\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this benchmark, please cite our paper:… See the full description on the dataset page: https://huggingface.co/datasets/MichaelR207/MultiSimV2.","first_N":5,"first_N_keywords":["summarization","text-generation","English","French","Russian"],"keywords_longer_than_N":true},
	{"name":"MMMU-Thai","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iapp/MMMU-Thai","creator_name":"iApp Technology","creator_url":"https://huggingface.co/iapp","description":"\n\t\n\t\t\n\t\tMMMU Thai (MMMU Benchmark Translated to Thai)\n\t\n\nMMMU Thai is a dataset for evaluating multimodal models on massive multi-discipline tasks requiring college-level knowledge and deliberate reasoning. This dataset is translated from MMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI) into Thai.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nMMMU Thai consists of 11,500 meticulously collected multimodal questions from college exams, quizzes, and textbooks… See the full description on the dataset page: https://huggingface.co/datasets/iapp/MMMU-Thai.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","Thai","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Burmese-General-Reviews","keyword":"reviews","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Rickaym/Burmese-General-Reviews","creator_name":"Pyae Sone Myo","creator_url":"https://huggingface.co/Rickaym","description":"\n\t\n\t\t\n\t\tBurmese General Reviews\n\t\n\nA collection of 5k e-commerce reviews. Only a portion has been uploaded.\n⚫⚪⚪⚪⚪⚪⚪ 13.9%\n(695/5,000)\nThis dataset card aims to be of value to NLP endeavors in Burmese.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSourced from various e-commerce platforms and communities. Uses Burmese Unicode. \nThe reviews are normalized with [product], and [seller] in place of original names and products (this is still a work in progress)\nBecause the data comes… See the full description on the dataset page: https://huggingface.co/datasets/Rickaym/Burmese-General-Reviews.","first_N":5,"first_N_keywords":["Burmese","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"steam-reviews-constructiveness-binary-label-annotations-1.5k","keyword":"reviews","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abullard1/steam-reviews-constructiveness-binary-label-annotations-1.5k","creator_name":"Samuel Bullard","creator_url":"https://huggingface.co/abullard1","description":"\n\n\n    \n\n\n\n\n\n\n\n    1.5K Steam Reviews Binary Labeled for Constructiveness\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,461 Steam reviews from 10 of the most reviewed games. Each game has about the same amount of reviews. Each review is annotated with a binary label indicating whether the review is constructive or not. The dataset is designed to support tasks related to text classification, particularly constructiveness detection tasks in the gaming domain.\n\nAlso available as… See the full description on the dataset page: https://huggingface.co/datasets/abullard1/steam-reviews-constructiveness-binary-label-annotations-1.5k.","first_N":5,"first_N_keywords":["text-classification","expert-generated","found","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"Spurline","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Spurline","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Spurline is a dataset containing complex responses, emphasizing logical reasoning and using Shining Valiant's friendly, magical personality style.\nThe 2024-10-30 version contains:\n\n10.7k rows of synthetic queries, using randomly selected prompts from migtissera/Synthia-v1.5-I and responses generated using Llama 3.1 405b Instruct.\n\nThis dataset contains synthetically generated data and has not been subject to manual review.\n","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Math-Question-Answer","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aixr/Math-Question-Answer","creator_name":"Aixr AI","creator_url":"https://huggingface.co/Aixr","description":"Aixr/Math-Question-Answer dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"amazon-beauty-reviews-dataset","keyword":"reviews","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jhan21/amazon-beauty-reviews-dataset","creator_name":"misschestnut","creator_url":"https://huggingface.co/jhan21","description":"\n\t\n\t\t\n\t\tDataset Card for \"Amazon Beauty Reviews\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of reviews of \"All Beauty\" category from amazon. The data includes all ~700,000 reviews up to 2023. Reviews include product and user information, ratings, and a plain text review. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be used for numerous tasks like sentiment analysis, text classification, and user behavior analysis. It's particularly useful for training models to… See the full description on the dataset page: https://huggingface.co/datasets/jhan21/amazon-beauty-reviews-dataset.","first_N":5,"first_N_keywords":["text-classification","English","cc0-1.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"VisualWebInstruct","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\n\t\n\t\t\n\t\tVisualWebInstruct: Scaling up Multimodal Instruction Data through Web Search\n\t\n\nVisualWebInstruct is a large-scale, diverse multimodal instruction dataset designed to enhance vision-language models' reasoning capabilities. The dataset contains approximately 900K question-answer (QA) pairs, with 40% consisting of visual QA pairs associated with 163,743 unique images, while the remaining 60% are text-only QA pairs.\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nGitHub Repository\nResearch Paper\nProject Website… See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"aifgen","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LifelongAlignment/aifgen","creator_name":"Lifelong Alignment of Agents","creator_url":"https://huggingface.co/LifelongAlignment","description":"\n\t\n\t\t\n\t\tDataset Card for aif-gen static dataset\n\t\n\n\n\nThis dataset is a set of static RLHF datasets used to generate continual RLHF datasets for benchmarking Lifelong RL on language models. \nThe data used in the paper can be found under the directory 4omini_generation and the rest are included for reference and are used in the experiments for the paper.\nThe continual datasets created for benchmarking can be found with their dataset cards in… See the full description on the dataset page: https://huggingface.co/datasets/LifelongAlignment/aifgen.","first_N":5,"first_N_keywords":["summarization","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"walmart-reviews-dataset","keyword":"reviews","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/crawlfeeds/walmart-reviews-dataset","creator_name":"Crawl Feeds","creator_url":"https://huggingface.co/crawlfeeds","description":"\n\t\n\t\t\n\t\t🛒 Walmart Product Reviews Dataset (6.7K Records)\n\t\n\nThis dataset contains 6,700+ structured customer reviews from Walmart.com. Each entry includes product-level metadata along with review details, making it ideal for small-scale machine learning models, sentiment analysis, and ecommerce insights.\n\n\n\t\n\t\t\n\t\t📑 Dataset Fields\n\t\n\n\n\t\n\t\t\nColumn\nDescription\n\n\n\t\t\nurl\nDirect product page URL\n\n\nname\nProduct name/title\n\n\nsku\nProduct SKU (Stock Keeping Unit)\n\n\nprice\nProduct price (numeric, USD)… See the full description on the dataset page: https://huggingface.co/datasets/crawlfeeds/walmart-reviews-dataset.","first_N":5,"first_N_keywords":["text-classification","text-generation","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"s1_59k","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/XuHu6736/s1_59k","creator_name":"XuHu","creator_url":"https://huggingface.co/XuHu6736","description":"\n\t\n\t\t\n\t\tDataset Card for XuHu6736/s1_59k\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nXuHu6736/s1_59k is a dataset specifically prepared for Supervised Fine-Tuning (SFT) of large language models. It is constructed by merging and processing two existing Hugging Face datasets: simplescaling/data_ablation_full59K and qfq/train_featurized.\nThe simplescaling/data_ablation_full59K dataset is a collection of approximately 59,000 questions and solutions spanning various domains including mathematics, science… See the full description on the dataset page: https://huggingface.co/datasets/XuHu6736/s1_59k.","first_N":5,"first_N_keywords":["question-answering","text-generation","XuHu6736 (merging process)","simplescaling (source dataset: data_ablation_full59K)","qfq (source dataset: train_featurized, annotation based on 's1: Simple test-time scaling')"],"keywords_longer_than_N":true},
	{"name":"everyday-science","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nirajandhakal/everyday-science","creator_name":"Nirajan Dhakal","creator_url":"https://huggingface.co/nirajandhakal","description":"\n\t\n\t\t\n\t\tEveryday Science Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Everyday Science\" dataset is a synthetically generated collection of question-answer pairs covering a diverse range of topics within everyday science. Each entry includes a topic, a specific question, a scientific explanation or principle, a relatable everyday example, relevant scientific concepts (keywords), and further reasoning or inference.\nThis dataset contains question-and-answer pairs focused on everyday science… See the full description on the dataset page: https://huggingface.co/datasets/nirajandhakal/everyday-science.","first_N":5,"first_N_keywords":["table-question-answering","question-answering","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"YuLan-Mini-Text-Datasets","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yulan-team/YuLan-Mini-Text-Datasets","creator_name":"RUC-GSAI-YuLan","creator_url":"https://huggingface.co/yulan-team","description":"\n\t\n\t\t\n\t\tNews\n\t\n\n\n[2025.04.11] Add dataset mixture: link.\n[2025.03.30] Text datasets upload finished.\n\n\nThis is text dataset.\n这是文本格式的数据集。\nSince we have used BPE-Dropout, in order to ensure accuracy, you can find the tokenized dataset here.\n由于我们使用了BPE-Dropout，为了保证准确性，你可以在这里找到分词后的数据。\nFor more information, please refer to our datasets details and preprocess details.\n\n\n\t\t\n\t\tContributing\n\t\n\nWe welcome any form of contribution, including feedback on model bad cases, feature suggestions, and example… See the full description on the dataset page: https://huggingface.co/datasets/yulan-team/YuLan-Mini-Text-Datasets.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","mit","100M - 1B"],"keywords_longer_than_N":true},
	{"name":"natural-science-reasoning","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dvilasuero/natural-science-reasoning","creator_name":"Daniel Vila","creator_url":"https://huggingface.co/dvilasuero","description":"\n\t\n\t\t\n\t\tNatural Sciences Reasoning: the \"smolest\" reasoning dataset\n\t\n\nA smol-scale open dataset for reasoning tasks using Hugging Face Inference Endpoints. While intentionally limited in scale, this resource prioritizes:\n\nReproducible pipeline for reasoning tasks using a variety of models (Deepseek V3, Deepsek-R1, Llama70B-Instruct, etc.)\n\nKnowledge sharing for domains other than Math and Code reasoning\n\n\nIn this repo, you can find:\n\nThe prompts and the pipeline (see the config file).\nThe… See the full description on the dataset page: https://huggingface.co/datasets/dvilasuero/natural-science-reasoning.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"ScienceGlossary","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JonyC/ScienceGlossary","creator_name":"Jonatan Cohen","creator_url":"https://huggingface.co/JonyC","description":"\n\t\n\t\t\n\t\tDataset Card for Science Terms and Phrases Glossary\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset contains scientific terms and phrases from various disciplines, compiled from multiple sources.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset was created by web scraping scientific glossaries from sources like Wikipedia, NASA, and other academic references. Additionally, some terms were generated using ChatGPT-4.0.  \nIt is designed for token classification, meaning it includes both scientific… See the full description on the dataset page: https://huggingface.co/datasets/JonyC/ScienceGlossary.","first_N":5,"first_N_keywords":["text-classification","token-classification","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"aifgen-merged","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LifelongAlignment/aifgen-merged","creator_name":"Lifelong Alignment of Agents","creator_url":"https://huggingface.co/LifelongAlignment","description":"\n\t\n\t\t\n\t\tDataset Card for aif-gen static dataset\n\t\n\n\n\nThis dataset is a set of static RLHF datasets used to generate continual RLHF datasets for benchmarking Lifelong RL on language models. \nThe data used in the paper can be found under the directory 4omini_generation and the rest are included for reference and are used in the experiments for the paper.\nThe continual datasets created for benchmarking can be found with their dataset cards in… See the full description on the dataset page: https://huggingface.co/datasets/LifelongAlignment/aifgen-merged.","first_N":5,"first_N_keywords":["English","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"InqBench","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/InqModel/InqBench","creator_name":"junjie Lu","creator_url":"https://huggingface.co/InqModel","description":"InqModel/InqBench dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_6th","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_6th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Science_6th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_7th","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_7th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Science_7th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_8th","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_8th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Science_8th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_9th","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_9th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Science_9th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_10th","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_10th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Science_10th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"scips_qa","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zorpsoon/scips_qa","creator_name":"Prasoon Bajpai","creator_url":"https://huggingface.co/zorpsoon","description":"zorpsoon/scips_qa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"academic-section-classification","keyword":"science","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nhop/academic-section-classification","creator_name":"Niklas Hoepner","creator_url":"https://huggingface.co/nhop","description":"\n\t\n\t\t\n\t\tDataset for Classification of Sections of Academic Papers\n\t\n\nA dataset mapping sections of academic papers to one of the following section types:\n0: Introduction 1: Background 2: Methodology 3: Experiments and Results 4: Conclusion \nThe dataset was collected by taking the GROBID parses of academic papers in the ACL-OCL dataset and matching the section headings to one of the synonyms of each section type. Sections that did not have a match were disregarded. The following synonyms are… See the full description on the dataset page: https://huggingface.co/datasets/nhop/academic-section-classification.","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"sentiment-polarity-dataset-v2.0","keyword":"reviews","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/polsci/sentiment-polarity-dataset-v2.0","creator_name":"Geoff Ford","creator_url":"https://huggingface.co/polsci","description":"\n\t\n\t\t\n\t\tSentiment Polarity Dataset Version 2.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is available on NLTK as the \"movie_reviews\" dataset. The Sentiment Polarity Dataset Version 2.0 was developed by Bo Pang and Lillian Lee. I'm uploading it as a Huggingface dataset for a lab task.\nThe following information is from the README file distributed with the NLTK version of the data-set.\n=======\n\n\t\n\t\t\n\t\n\t\n\t\tData Format Summary\n\t\n\n  File names consist of a cross-validation tag plus the name of… See the full description on the dataset page: https://huggingface.co/datasets/polsci/sentiment-polarity-dataset-v2.0.","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"gp_surgery_reviews_fake_and_real","keyword":"reviews","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/janduplessis886/gp_surgery_reviews_fake_and_real","creator_name":"Jan du Plessis","creator_url":"https://huggingface.co/janduplessis886","description":"\n\t\n\t\t\n\t\tGP Surgery Reviews Dataset Data Card\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset consists of GP Surgery reviews designed for binary classification tasks. It includes both real and fake reviews, where the label feature marks real reviews as 0 and fake reviews as 1. The fake reviews were generated using DeepSeek LLM (Ollama) and then passed through a processing pipeline to derive additional features.\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\n\nTotal Records: 9,974\n\n\n\t\n\t\t\n\t\tFeatures:\n\t\n\n\nfree_text:\nThe… See the full description on the dataset page: https://huggingface.co/datasets/janduplessis886/gp_surgery_reviews_fake_and_real.","first_N":5,"first_N_keywords":["text-classification","English","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"ScImage","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/casszhao/ScImage","creator_name":"casszhao","creator_url":"https://huggingface.co/casszhao","description":"The prompt for ICLR2025 paper \nScImage: HOW GOOD ARE MULTIMODAL LARGE LANGUAGE MODELS AT SCIENTIFIC TEXT-TO-IMAGE GENERATION?\nThe prompt template and the object list will be added soon.\n@inproceedings{\nscimage2025,\ntitle={ScImage: How Good Are Multimodal Large Language Models at Scientific Text-to-Image Generation?},\nauthor={Zhang, Leixin and Cheng, Yinjie and Zhai, Weihe and Eger, Steffen and Belouadi, Jonas and Moafian, Fahimeh and Zhao, Zhixue},\nbooktitle={The Thirteenth International… See the full description on the dataset page: https://huggingface.co/datasets/casszhao/ScImage.","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"CoTton-38k-6525-Collective","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NewstaR/CoTton-38k-6525-Collective","creator_name":"Newstar Research ASIA","creator_url":"https://huggingface.co/NewstaR","description":"\n\t\n\t\t\n\t\tCoTton-38k-6525-Collective\n\t\n\nCoTton-38k is a 38,350-example dataset of soft reasoning conversations in the ShareGPT format. Each entry contains an exchange between a user and a model, showcasing high-quality Chain-of-Thought (CoT) reasoning in natural language.\nThe dataset is distilled from open LLMs:\n\nQwen3 235B A22B\nAM Thinking\nQwQ 32B\nDeepseek R1\nR1 0528\n\nThe name CoTton encodes multiple layers of meaning:\n\nCoT: Chain-of-Thought is embedded in the name\nTON: The dataset contains a… See the full description on the dataset page: https://huggingface.co/datasets/NewstaR/CoTton-38k-6525-Collective.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MNLP_M3_quantized_dataset","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlirezaAbdollahpoor/MNLP_M3_quantized_dataset","creator_name":"Alireza Abdollahopoorrostam","creator_url":"https://huggingface.co/AlirezaAbdollahpoor","description":"\n\t\n\t\t\n\t\tEnhanced MCQA Test Dataset for Comprehensive Model Evaluation\n\t\n\nThis dataset contains 400 carefully selected test samples from MetaMathQA, AQuA-RAT, OpenBookQA, and SciQ datasets, designed for comprehensive MCQA (Multiple Choice Question Answering) model evaluation and quantization testing across multiple domains.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Samples: 400\nMetaMathQA Samples: 100 (mathematical problems)\nAQuA-RAT Samples: 100 (algebraic word problems)\nOpenBookQA Samples: 100… See the full description on the dataset page: https://huggingface.co/datasets/AlirezaAbdollahpoor/MNLP_M3_quantized_dataset.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciDA","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-a-p/SciDA","creator_name":"Multimodal Art Projection","creator_url":"https://huggingface.co/m-a-p","description":"m-a-p/SciDA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"math-formulas-tr","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/esholmess/math-formulas-tr","creator_name":"İlknur Yaren K.","creator_url":"https://huggingface.co/esholmess","description":"esholmess/math-formulas-tr dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Turkish","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"physics-formulas-tr","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/esholmess/physics-formulas-tr","creator_name":"İlknur Yaren K.","creator_url":"https://huggingface.co/esholmess","description":"esholmess/physics-formulas-tr dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Turkish","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"WebInstruct-verified-unfiltered","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/WebInstruct-verified-unfiltered","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"This repo contains the unfiltered version WebInstruct-verified in the General Reasoner work.\n\n\t\n\t\t\n\t\tGeneral-Reasoner: Advancing LLM Reasoning Across All Domains\n\t\n\n\n  💻 Code |\n  📄 Paper |\n  📊 Dataset |\n  🤗 Model |\n  🌐 Project Page\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\n\n  \n\n\n  \n    Figure: Effectiveness of General-Reasoner trained with diverse verifiable reasoning questions using model-based verifier compared to baseline methods on various reasoning tasks.\n  General-Reasoner is a training paradigm… See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/WebInstruct-verified-unfiltered.","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"MathVision_with_difficulty_level","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JierunChen/MathVision_with_difficulty_level","creator_name":"Jierun Chen","creator_url":"https://huggingface.co/JierunChen","description":"\n\t\n\t\t\n\t\tMathVision with difficulty level tags\n\t\n\nThis dataset extends the 🤗 MathVision  benchmark by introducing two additional tags: passrate_for_qwen2.5_vl_7b and difficulty_level_for_qwen2.5_vl_7b. Further details are available in our paper The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs.\n\n\t\n\t\t\n\t\n\t\n\t\t🚀 Data Usage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"JierunChen/MathVision_with_difficulty_level\")\nprint(dataset)… See the full description on the dataset page: https://huggingface.co/datasets/JierunChen/MathVision_with_difficulty_level.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","visual-question-answering","text-generation","expert-generated"],"keywords_longer_than_N":true},
	{"name":"MMMU_with_difficulty_level","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JierunChen/MMMU_with_difficulty_level","creator_name":"Jierun Chen","creator_url":"https://huggingface.co/JierunChen","description":"\n\t\n\t\t\n\t\tMMMU with difficulty level tags\n\t\n\nThis dataset extends the 🤗 MMMU val benchmark by introducing two additional tags: passrate_for_qwen2.5_vl_7b and difficulty_level_for_qwen2.5_vl_7b. Further details are available in our paper The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs.\n\n\t\n\t\t\n\t\n\t\n\t\t🚀 Data Usage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"JierunChen/MMMU_with_difficulty_level\")\nprint(dataset)\n\n\n\t\n\t\n\t\n\t\t📑… See the full description on the dataset page: https://huggingface.co/datasets/JierunChen/MMMU_with_difficulty_level.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"SciGen-Figure","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nhop/SciGen-Figure","creator_name":"Niklas Hoepner","creator_url":"https://huggingface.co/nhop","description":"\n\t\n\t\t\n\t\tSciGen-Figures\n\t\n\nSciGen-Figures is an augmented version of the SciGen dataset, which includes images of table figures alongside the original text.\nThe dataset is designed for tasks that involve reasoning over scientific tables and generating text based on table figures. \nEach entry includes both the textual representation of a table and a corresponding image of the table. \nThe goal is to test LLM's ability to correctly reason over the textual and visual representation of scientific… See the full description on the dataset page: https://huggingface.co/datasets/nhop/SciGen-Figure.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Trustpilot-Reviews-Dataset-20K-Sample","keyword":"reviews","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/crawlfeeds/Trustpilot-Reviews-Dataset-20K-Sample","creator_name":"Crawl Feeds","creator_url":"https://huggingface.co/crawlfeeds","description":"\n\t\n\t\t\n\t\tTrustpilot Reviews Dataset – 20K Sample\n\t\n\nThis dataset contains a curated sample of 20,000 English-language user reviews sourced exclusively from Trustpilot.com. It is a representative subset of our larger collection containing over 1 million Trustpilot reviews across various industries and companies.\n\n\t\n\t\t\n\t\t🗂️ Dataset Overview\n\t\n\n\nSource: Trustpilot  \nTotal Records: 20,000  \nLanguage: English  \nIndustries: E-commerce, SaaS, Travel, Finance, Education, and more  \nUse Case: NLP tasks… See the full description on the dataset page: https://huggingface.co/datasets/crawlfeeds/Trustpilot-Reviews-Dataset-20K-Sample.","first_N":5,"first_N_keywords":["text-classification","text-generation","zero-shot-classification","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"ScienceOlympiad","keyword":"science","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ByteDance-Seed/ScienceOlympiad","creator_name":"ByteDance Seed","creator_url":"https://huggingface.co/ByteDance-Seed","description":"\n\t\n\t\t\n\t\tScienceOlympiad: Challenging AI with Olympiad-Level Multimodal Science Problems\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe ScienceOlympiad dataset is a meticulously curated benchmark designed to test the limits of current AI models in scientific reasoning. It comprises elite, competition-level problems in physics and chemistry. Addressing the need for more diverse and realistic challenges, ScienceOlympiad introduces multimodal integration as a key dimension. Unlike purely text-based… See the full description on the dataset page: https://huggingface.co/datasets/ByteDance-Seed/ScienceOlympiad.","first_N":5,"first_N_keywords":["cc0-1.0","< 1K","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"PhysUniBench","keyword":"science","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PrismaX/PhysUniBench","creator_name":"PrismaX","creator_url":"https://huggingface.co/PrismaX","description":"\n\t\n\t\t\n\t\tPhysUniBench\n\t\n\nAn Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models\nPaper: https://arxiv.org/abs/2506.17667\nRepository: https://github.com/PrismaX-Team/PhysUniBenchmark\nProject page: https://prismax-team.github.io/PhysUniBenchmark/\nPhysUniBench is the first large-scale multimodal physics benchmark specifically designed for undergraduate-level understanding, reasoning, and problem-solving. It provides a valuable testbed for advancing multimodal large language models… See the full description on the dataset page: https://huggingface.co/datasets/PrismaX/PhysUniBench.","first_N":5,"first_N_keywords":["image-text-to-text","English","Chinese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"EEE-Bench","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/afdsafas/EEE-Bench","creator_name":"Ming Li","creator_url":"https://huggingface.co/afdsafas","description":"\n\t\n\t\t\n\t\tEEE-Bench: A Comprehensive Multimodal Electrical And Electronics Engineering Benchmark\n\t\n\n\n\t\n\t\t\n\t\tIntroduction:\n\t\n\nEEE-Bench is a multimodal benchmark designed to evaluate the practical engineering capabilities of large multimodal models (LMMs), using electrical and electronics engineering (EEE) as the domain focus. It comprises 2,860 carefully curated problems across 10 core subdomains, including analog circuits and control systems, featuring complex visual inputs such as abstract… See the full description on the dataset page: https://huggingface.co/datasets/afdsafas/EEE-Bench.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","visual-question-answering","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"shortlist-reason-v1","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/catsaresupercool/shortlist-reason-v1","creator_name":"Burchid Sipt","creator_url":"https://huggingface.co/catsaresupercool","description":"\n\t\n\t\t\n\t\tShort List Reason V1\n\t\n\nA fully synthetic fine-tuning dataset of reasoning questions across multiple domains, generated using advanced language models.\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nShort List Reason V1 is a fully synthetic dataset made for fine-tuning large language models on reasoning tasks. It contains question-answer pairs from various subjects such as:\n\nMathematics  \nScience  \nBusiness  \nAnd other reasoning-oriented topics\n\nAll question-answer pairs are fully synthetic and generated by… See the full description on the dataset page: https://huggingface.co/datasets/catsaresupercool/shortlist-reason-v1.","first_N":5,"first_N_keywords":["question-answering","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MathVista_with_difficulty_level","keyword":"science","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JierunChen/MathVista_with_difficulty_level","creator_name":"Jierun Chen","creator_url":"https://huggingface.co/JierunChen","description":"\n\t\n\t\t\n\t\tMathVista with difficulty level tags\n\t\n\nThis dataset extends the 🤗 MathVista testmini benchmark by introducing two additional tags: passrate_for_qwen2.5_vl_7b and difficulty_level_for_qwen2.5_vl_7b. Further details are available in our paper  The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs.\n\n\t\n\t\t\n\t\n\t\n\t\t🚀 Data Usage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"JierunChen/MathVista_with_difficulty_level\")… See the full description on the dataset page: https://huggingface.co/datasets/JierunChen/MathVista_with_difficulty_level.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","text-classification","multiple-choice-qa"],"keywords_longer_than_N":true}
]
;
