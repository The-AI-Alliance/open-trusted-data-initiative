const data_for_domain_science = 
[
	{"name":"dataclysm-pubmed","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/somewheresystems/dataclysm-pubmed","creator_name":"S2","creator_url":"https://huggingface.co/somewheresystems","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDATACLYSM PATCH 0.0.4: PUBMED\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUSE THE NOTEBOOK TO GET STARTED!\\n\\t\\n\\nhttps://github.com/somewheresystems/dataclysm\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsomewheresystems/dataclysm-pubmed\\n\\t\\n\\nThis dataset comprises of 35.7 million PubMed metadata entries including title and some (~69% with) abstracts, with two new columns added: title-embeddings and abstract-embeddings. These additional columns were generated using the bge-small-en-v1.5 embeddings model. The dataset was sourced from the PubMedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/somewheresystems/dataclysm-pubmed.","first_N":5,"first_N_keywords":["English","apache-2.0","10M<n<100M","ðŸ‡ºðŸ‡¸ Region: US","pubmed"],"keywords_longer_than_N":true},
	{"name":"yandex-geo-reviews-embeddings","keyword":"reviews","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lockiultra/yandex-geo-reviews-embeddings","creator_name":"Dmitry","creator_url":"https://huggingface.co/lockiultra","description":"Dataset full description: https://www.kaggle.com/datasets/lockiultra/yandex-geo-reviews-embeddings\\nDataset contains index column, 768 embedding columns and rating column. Each row corresponds to an embedding representation of the review text with same index.\\n","first_N":5,"first_N_keywords":["feature-extraction","Russian","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"Luganda_Sci-Math-Bio_Translations","keyword":"science","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allandclive/Luganda_Sci-Math-Bio_Translations","creator_name":"Allan D Clive","creator_url":"https://huggingface.co/allandclive","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLuganda Sci-Math-Bio Translations\\n\\t\\n\\nThis dataset contains Luganda and English translations of biologicial, mathematical and scientific terms\\n","first_N":5,"first_N_keywords":["text2text-generation","translation","Ganda","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Astro-mcqa","keyword":"science","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/patrickfleith/Astro-mcqa","creator_name":"Patrick Fleith","creator_url":"https://huggingface.co/patrickfleith","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAstroMCQA Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose and scope\\n\\t\\n\\nThe primary purpose of AstroMCQA is for application developers in the domain of space engineering to be able to comparatively assess LLM performances on the specific task of multiple-choice question-answering\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntended Usage\\n\\t\\n\\nComparative assessement of differents LLMs, Model evaluation, audit, and model selection. Assessment of different quantization levels, different prompting strategies, and assessingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/patrickfleith/Astro-mcqa.","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"scientific_studies","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yousefg/scientific_studies","creator_name":"Yousef Rafat Gamaleldin","creator_url":"https://huggingface.co/yousefg","description":"yousefg/scientific_studies dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"scientific_papers_from_arxiv","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scientific_papers_from_arxiv","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tscientific_papers_from_arxiv Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic paper search for scientific research\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the scientific_papers_from_arxiv model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scientific_papers_from_arxiv.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MAiDE-up","keyword":"reviews","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MichiganNLP/MAiDE-up","creator_name":"LIT @ UMich","creator_url":"https://huggingface.co/MichiganNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MAiDE-up: Multilingual Deception Detection of GPT-generated Hotel Reviews\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultilingual Deception Detection of GPT-generated Hotel Reviews. We compare real hotel reviews from Booking with LLM-generated hotel reviews in 10 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in 10 languages: Chinese, English, French, German, Italian, Romanian, Korean, Russian, Spanish, Turkish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboardsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MichiganNLP/MAiDE-up.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic research papers search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-scidocs","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scidocs","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-en-scidocs Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic research papers search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-scidocs model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scidocs.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic search for scientific papers\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tscidocs Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic search for scientific papers\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the scidocs model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tscidocs-c Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic research papers search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the scidocs-c model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-128-24","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tscidocs-c-128-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic search for scientific papers\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the scidocs-c-128-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-128-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-256-24","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tscidocs-c-256-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic paper search for scientific articles\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the scidocs-c-256-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-256-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"scidocs-c-64-24","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tscidocs-c-64-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic research papers search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the scidocs-c-64-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"M4U","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/M4U-Benchmark/M4U","creator_name":"M4U-Benchmark","creator_url":"https://huggingface.co/M4U-Benchmark","description":"\\n\\t\\n\\t\\t\\n\\t\\tM4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models\\n\\t\\n\\nCode for the Paper M4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models.\\n[Webpage] [Paper] [Huggingface Dataset] [Leaderboard]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸ’¥ News ðŸ’¥\\n\\t\\n\\n\\n[2024.05.23] Our paper, dataset and code are public aviailable.\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tðŸ‘€ About M4U\\n\\t\\n\\n\\n     \\n\\n\\nMultilingual multimodal reasoning is a core component to achieve human-level intelligence. However, most of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/M4U-Benchmark/M4U.","first_N":5,"first_N_keywords":["visual-question-answering","English","Chinese","German","mit"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-5222024-hkde-webapp","keyword":"reviews","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5222024-hkde-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-en-5222024-hkde-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"code repository search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-en-5222024-hkde-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-5222024-hkde-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-526066","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-526066","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSciFact-256-24-gpt-4o-2024-05-13-526066 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"scientific claim verification\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-526066 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-526066.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-994884","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-994884","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSciFact-256-24-gpt-4o-2024-05-13-994884 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"scientific claim verification search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-994884 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-994884.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-3778","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-3778","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSciFact-256-24-gpt-4o-2024-05-13-3778 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"scientific claim verification\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-3778 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-3778.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-204265","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-204265","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSciFact-256-24-gpt-4o-2024-05-13-204265 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"scientific claim verification\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-204265 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-204265.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-499715","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-499715","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSciFact-256-24-gpt-4o-2024-05-13-499715 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"scientific claim verification\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-499715 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-499715.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SciFact-256-24-gpt-4o-2024-05-13-478897","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-478897","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSciFact-256-24-gpt-4o-2024-05-13-478897 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"scientific claim verification\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-478897 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-478897.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"VisualWebInstruct-Seed","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct-Seed","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is the seed dataset we used to conduct Google Search.\\n\\n\\t\\n\\t\\t\\n\\t\\tLinks\\n\\t\\n\\nGithub|\\nPaper|\\nWebsite\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{visualwebinstruct,\\n    title={VisualWebInstruct: Scaling up Multimodal Instruction Data through Web Search},\\n    author = {Jia, Yiming and Li, Jiachen and Yue, Xiang and Li, Bo and Nie, Ping and Zou, Kai and Chen, Wenhu},\\n    journal={arXiv preprint arXiv:2503.10582},\\n    year={2025}\\n}\\n\\n","first_N":5,"first_N_keywords":["question-answering","image-text-to-text","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SciFact-512-192-gpt-4o-2024-05-13-866232","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-866232","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSciFact-512-192-gpt-4o-2024-05-13-866232 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"general domain\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SciFact-512-192-gpt-4o-2024-05-13-866232 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-866232.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"SCIDOCS-512-192-gpt-4o-2024-05-13-650620","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-650620","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSCIDOCS-512-192-gpt-4o-2024-05-13-650620 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"arxiv paper domain\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SCIDOCS-512-192-gpt-4o-2024-05-13-650620 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets libraryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-650620.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"AstroChat","keyword":"science","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/patrickfleith/AstroChat","creator_name":"Patrick Fleith","creator_url":"https://huggingface.co/patrickfleith","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAstroChat Dataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose and Scope\\n\\t\\n\\nThe AstroChat dataset is a collection of 901 dialogues, synthetically generated, tailored to the specific domain of Astronautics / Space Mission Engineering.\\nThis dataset will be frequently updated following feedback from the community. If you would like to contribute, please reach out in the community discussion.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntended Use\\n\\t\\n\\nThe dataset is intended to be used for supervised fine-tuning of chat LLMsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/patrickfleith/AstroChat.","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"gliner-bird-diet-synthetic","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wjbmattingly/gliner-bird-diet-synthetic","creator_name":"William Mattingly","creator_url":"https://huggingface.co/wjbmattingly","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGLiNER Bird Diet Synthetic Dataset\\n\\t\\n\\nThis is an NER dataset focused on ornithological data, specifically focused on the diets of birds. The data is purely synthetic and should not be taken as factual. We created this dataset using Qwen2-7B-Instruct. It consists of ~2k descriptions. The format of the annotations consists with the GLiNER format. We used this data to finetune a GLiNER model. For the base model, we used NuNerZero Span. You can visit our model here: GLiNER Ecologyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wjbmattingly/gliner-bird-diet-synthetic.","first_N":5,"first_N_keywords":["token-classification","English","mit","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"CoMDataset","keyword":"science","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qijimrc/CoMDataset","creator_name":"Ji Qi","creator_url":"https://huggingface.co/qijimrc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe open-source both the Automatically Synthesized CoM Data and the Manually Annotated CoM-Math Data to facilitate potential research. The automatically synthesized CoM data (i.e., com.jsonl) consists of 84K positive reasoning chains, which was produced by an automated data generation pipeline with an LLM-based (GPT-4) linguistic solving steps generation and a VFMs-based (GroundingDINO, PaddleOCR) visual evidence compensation upon massive public VQA samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/qijimrc/CoMDataset.","first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","expert-generated","found","expert-generated"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-15062024-atex-webapp","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBAAI_bge-large-en-15062024-atex-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"general domain\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the BAAI_bge-large-en-15062024-atex-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_bge-large-en-v1_5-1562024-to89-webapp","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1562024-to89-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBAAI_bge-large-en-v1_5-1562024-to89-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"scientific research in medicine, biology, and technology\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the BAAI_bge-large-en-v1_5-1562024-to89-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can loadâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1562024-to89-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Amazon_Reviews_Binary_for_Sentiment_Analysis","keyword":"reviews","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yassiracharki/Amazon_Reviews_Binary_for_Sentiment_Analysis","creator_name":"yassir acharki","creator_url":"https://huggingface.co/yassiracharki","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThe Amazon reviews polarity dataset is constructed by taking review score 1 and 2 as negative, and 4 and 5 as positive. Samples of score 3 is ignored. In the dataset, class 1 is the negative and class 2 is the positive. Each class has 1,800,000 training samples and 200,000 testing samples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe files train.csv and test.csv contain all the training samples as comma-sparated values.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yassiracharki/Amazon_Reviews_Binary_for_Sentiment_Analysis.","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"Yelp_Reviews_for_Binary_Senti_Analysis","keyword":"reviews","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yassiracharki/Yelp_Reviews_for_Binary_Senti_Analysis","creator_name":"yassir acharki","creator_url":"https://huggingface.co/yassiracharki","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThe Yelp reviews polarity dataset is constructed by considering stars 1 and 2 negative, and 3 and 4 positive. For each polarity 280,000 training samples and 19,000 testing samples are take randomly. In total there are 560,000 trainig samples and 38,000 testing samples. Negative polarity is class 1, and positive class 2.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe files train.csv and test.csv contain all the training samples as comma-sparated values.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yassiracharki/Yelp_Reviews_for_Binary_Senti_Analysis.","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"Yelp_Reviews_for_Sentiment_Analysis_fine_grained_5_classes","keyword":"reviews","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yassiracharki/Yelp_Reviews_for_Sentiment_Analysis_fine_grained_5_classes","creator_name":"yassir acharki","creator_url":"https://huggingface.co/yassiracharki","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThe Yelp reviews full star dataset is constructed by randomly taking 130,000 training samples and 10,000 testing samples for each review star from 1 to 5. In total there are 650,000 trainig samples and 50,000 testing samples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe files train.csv and test.csv contain all the training samples as comma-sparated values. There are 2 columns in them, corresponding to class index (1 to 5) and review text. The review textsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yassiracharki/Yelp_Reviews_for_Sentiment_Analysis_fine_grained_5_classes.","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"Celestia","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Celestia","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Celestia is a dataset containing science-instruct data.\\nThe 2024-10-30 version contains:\\n\\n126k rows of synthetic science-instruct data, using synthetically generated prompts and responses generated using Llama 3.1 405b Instruct. Primary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\\n\\nThis dataset contains synthetically generated data and has not been subject to manual review.\\n","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"gardian-ai-ready-docs","keyword":"science","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CGIAR/gardian-ai-ready-docs","creator_name":"CGIAR","creator_url":"https://huggingface.co/CGIAR","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tâš ï¸ Heads up: Updated Dataset Available\\n\\t\\n\\nThis dataset has been updated with a newer version published on 27 Feb 2025. The latest version includes more updated and refined set of documents.\\nWe recommend using the latest version, available at https://huggingface.co/datasets/CGIAR/gardian-cigi-ai-documents. This version remains accessible for reference and reproducibility purposes.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tA Curated Research Corpus for Agricultural Advisory AI Applications\\n\\t\\n\\nThis datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CGIAR/gardian-ai-ready-docs.","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"protobowl-11-13","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mgor/protobowl-11-13","creator_name":"Maharshi Gor","creator_url":"https://huggingface.co/mgor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProgressive Quiz Bowl Clues Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains Quiz Bowl questions and their corresponding progressive clues, designed for evaluating question-answering systems.\\nThe progressive clues subset contains additional features such as GPT-3.5 generated categories and subcategories specific to each progressive clue.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nName: protobowl-11-13\\nVersion: 1.0\\nMaintainer: mgor\\nHub URL:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mgor/protobowl-11-13.","first_N":5,"first_N_keywords":["question-answering","text-retrieval","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"academic-section-classification","keyword":"science","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nhop/academic-section-classification","creator_name":"Niklas Hoepner","creator_url":"https://huggingface.co/nhop","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset for Classification of Sections of Academic Papers\\n\\t\\n\\nA dataset mapping sections of academic papers to one of the following section types:\\n0: Introduction 1: Background 2: Methodology 3: Experiments and Results 4: Conclusion \\nThe dataset was collected by taking the GROBID parses of academic papers in the ACL-OCL dataset and matching the section headings to one of the synonyms of each section type. Sections that did not have a match were disregarded. The following synonyms areâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nhop/academic-section-classification.","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"MMMU_Pro","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMMU/MMMU_Pro","creator_name":"MMMU","creator_url":"https://huggingface.co/MMMU","description":"\\n\\t\\n\\t\\t\\n\\t\\tMMMU-Pro (A More Robust Multi-discipline Multimodal Understanding Benchmark)\\n\\t\\n\\nðŸŒ Homepage | ðŸ† Leaderboard | ðŸ¤— Dataset | ðŸ¤— Paper | ðŸ“– arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸ””News\\n\\t\\n\\n\\nðŸ› ï¸ðŸ› ï¸ [2025-03-08] Fixed mismatch between inner image labels and shuffled options in Vision and Standard (10 options) settings. (test_Chemistry_5,94,147,216,314,345,354,461,560,570; test_Materials_450; test_Pharmacy_198; validation_Chemistry_12,26,29; validation_Materials_10,28; validation_Psychology_1)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MMMU/MMMU_Pro.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"steam-reviews-constructiveness-binary-label-annotations-1.5k","keyword":"reviews","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abullard1/steam-reviews-constructiveness-binary-label-annotations-1.5k","creator_name":"Samuel Bullard","creator_url":"https://huggingface.co/abullard1","description":"\\n\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n    1.5K Steam Reviews Binary Labeled for Constructiveness\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 1,461 Steam reviews from 10 of the most reviewed games. Each game has about the same amount of reviews. Each review is annotated with a binary label indicating whether the review is constructive or not. The dataset is designed to support tasks related to text classification, particularly constructiveness detection tasks in the gaming domain.\\n\\nAlso available asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abullard1/steam-reviews-constructiveness-binary-label-annotations-1.5k.","first_N":5,"first_N_keywords":["text-classification","expert-generated","found","monolingual","extended"],"keywords_longer_than_N":true},
	{"name":"Spurline","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Spurline","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Spurline is a dataset containing complex responses, emphasizing logical reasoning and using Shining Valiant's friendly, magical personality style.\\nThe 2024-10-30 version contains:\\n\\n10.7k rows of synthetic queries, using randomly selected prompts from migtissera/Synthia-v1.5-I and responses generated using Llama 3.1 405b Instruct.\\n\\nThis dataset contains synthetically generated data and has not been subject to manual review.\\n","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"scips_qa","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zorpsoon/scips_qa","creator_name":"Prasoon Bajpai","creator_url":"https://huggingface.co/zorpsoon","description":"zorpsoon/scips_qa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_6th","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_6th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Science_6th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_7th","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_7th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Science_7th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"InqBench","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/InqModel/InqBench","creator_name":"junjie Lu","creator_url":"https://huggingface.co/InqModel","description":"InqModel/InqBench dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"amazon-2023-all-category-k-core","keyword":"reviews","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChenglongMa/amazon-2023-all-category-k-core","creator_name":"Chenglong Ma","creator_url":"https://huggingface.co/ChenglongMa","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Amazon Reviews 2023 All-Category k-Core\\n\\t\\n\\n\\nThese datasets are subsets of Amazon reviews dataset, collected in 2023 by McAuley Lab. \\n\\nIt contains all categories of the reviews from the original dataset that have more than $k \\\\in [5, 20]$ interactions. \\n\\nThe original dataset contains reviews in the period of May. 1996 to Sep. 2023. \\n\\nThe reviews are grouped into 25 categories. \\n\\nThe dataset is in .parquet format.\\n\\n\\n\\n\\nk-core means that every user and every item has atâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChenglongMa/amazon-2023-all-category-k-core.","first_N":5,"first_N_keywords":["English","gpl-3.0","100M - 1B","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"Celestia2","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Celestia2","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Celestia 2 is a multi-turn agent-instruct dataset containing science data.\\nThis dataset focuses on challenging multi-turn conversations and contains:\\n\\n176k rows of synthetic multi-turn science-instruct data, using Microsoft's AgentInstruct style. All prompts and responses are synthetically generated using Llama 3.1 405b Instruct. Primary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\\n\\nThis datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Celestia2.","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"VisualWebInstruct","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is the final dataset we used to train MAmmoTH-VL2.\\n\\n\\t\\n\\t\\t\\n\\t\\tSubset\\n\\t\\n\\n\\nconversation: this subset contains VisualWebInstruct + LLavaCoT in the form of conversation.\\nexample: this subset is mainly for visualizing the examples.\\nvisualwebinstruct: this subset contains our dataset in the QA format.\\nimage: all the images are in imgs.tar.gz\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLinks\\n\\t\\n\\nGithub|\\nPaper|\\nWebsite|\\nModel\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{visualwebinstruct,\\n    title={VisualWebInstruct: Scalingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"MathVista","keyword":"science","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI4Math/MathVista","creator_name":"AI for Math Reasoning","creator_url":"https://huggingface.co/AI4Math","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MathVista\\n\\t\\n\\n\\nDataset Description\\nPaper Information\\nDataset Examples\\nLeaderboard\\nDataset Usage\\nData Downloading\\nData Format\\nData Visualization\\nData Source\\nAutomatic Evaluation\\n\\n\\nLicense\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMathVista is a consolidated Mathematical reasoning benchmark within Visual contexts. It consists of three newly created datasets, IQTest, FunctionQA, and PaperQA, which address the missing visual domains and are tailored to evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AI4Math/MathVista.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","text-classification","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"natural-science-reasoning","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dvilasuero/natural-science-reasoning","creator_name":"Daniel Vila","creator_url":"https://huggingface.co/dvilasuero","description":"\\n\\t\\n\\t\\t\\n\\t\\tNatural Sciences Reasoning: the \\\"smolest\\\" reasoning dataset\\n\\t\\n\\nA smol-scale open dataset for reasoning tasks using Hugging Face Inference Endpoints. While intentionally limited in scale, this resource prioritizes:\\n\\nReproducible pipeline for reasoning tasks using a variety of models (Deepseek V3, Deepsek-R1, Llama70B-Instruct, etc.)\\n\\nKnowledge sharing for domains other than Math and Code reasoning\\n\\n\\nIn this repo, you can find:\\n\\nThe prompts and the pipeline (see the config file).\\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dvilasuero/natural-science-reasoning.","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"ScienceQA","keyword":"science","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/derek-thomas/ScienceQA","creator_name":"Derek Thomas","creator_url":"https://huggingface.co/derek-thomas","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card Creation Guide\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLearn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMulti-modal Multiple Choice\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nExplore more samples here.\\n{'image': Image,\\n 'question': 'Which of these states is farthest north?',\\n 'choices': ['West Virginia', 'Louisiana', 'Arizona'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/derek-thomas/ScienceQA.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","other","visual-question-answering","text-classification"],"keywords_longer_than_N":true},
	{"name":"gardian-cigi-ai-documents","keyword":"science","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CGIAR/gardian-cigi-ai-documents","creator_name":"CGIAR","creator_url":"https://huggingface.co/CGIAR","description":"Pages: 1,438,332\\nTokens: 277,445,818\\n\\n\\t\\n\\t\\t\\n\\t\\tA Curated Research Corpus for Agricultural Advisory AI Applications\\n\\t\\n\\nThis dataset represents a comprehensive collection of 43,745 agricultural research publications from CGIAR,\\nspecifically processed and structured for Large Language Model (LLM) applications in agricultural advisory services. \\nThis dataset bridges the gap between advanced agricultural research and field-level advisory needs, \\ndrawing from CGIAR's extensive scientific knowledgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CGIAR/gardian-cigi-ai-documents.","first_N":5,"first_N_keywords":["summarization","English","cc-by-4.0","10M<n<100M","doi:10.57967/hf/4327"],"keywords_longer_than_N":true},
	{"name":"amazon-food-reviews-dataset","keyword":"reviews","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jhan21/amazon-food-reviews-dataset","creator_name":"misschestnut","creator_url":"https://huggingface.co/jhan21","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Amazon Food Reviews\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be used for numerous tasks like sentiment analysisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhan21/amazon-food-reviews-dataset.","first_N":5,"first_N_keywords":["text-classification","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"MMMU","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMMU/MMMU","creator_name":"MMMU","creator_url":"https://huggingface.co/MMMU","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI)\\n\\t\\n\\nðŸŒ Homepage | ðŸ† Leaderboard | ðŸ¤— Dataset | ðŸ¤— Paper | ðŸ“– arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸ””News\\n\\t\\n\\n\\nðŸ› ï¸[2024-05-30]: Fixed duplicate option issues in Materials dataset items (validation_Materials_25; test_Materials_17, 242) and content error in validation_Materials_25.\\nðŸ› ï¸[2024-04-30]: Fixed missing \\\"-\\\" or \\\"^\\\" signs in Math dataset items (dev_Math_2, validation_Math_11, 12, 16;â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MMMU/MMMU.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"nlp_taxonomy_data","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TimSchopf/nlp_taxonomy_data","creator_name":"Tim Schopf","creator_url":"https://huggingface.co/TimSchopf","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNLP Taxonomy Classification Data\\n\\t\\n\\nThe dataset consists of titles and abstracts from NLP-related papers. Each paper is annotated with multiple fields of study from the NLP taxonomy. Each sample is annotated with all possible lower-level concepts and their hypernyms in the NLP taxonomy. The training dataset contains 178,521 weakly annotated samples. The test dataset consists of 828 manually annotated samples from the EMNLP22 conference. The manually labeled test dataset might notâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TimSchopf/nlp_taxonomy_data.","first_N":5,"first_N_keywords":["text-classification","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"arxiv_categories","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TimSchopf/arxiv_categories","creator_name":"Tim Schopf","creator_url":"https://huggingface.co/TimSchopf","description":"ðŸ“„ Paper: Efficient Few-shot Learning for Multi-label Classification of Scientific Documents with Many Classes (ICNLSP 2024)\\nðŸ’» GitHub: https://github.com/sebischair/FusionSent\\nThis is a dataset of scientific documents derived from arXiv metadata. The arXiv metadata provides information about more than 2 million scholarly articles published in arXiv from various scientific fields. We use this metadata to create a dataset of 203,961 titles and abstracts categorized into 130 different classes.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/TimSchopf/arxiv_categories.","first_N":5,"first_N_keywords":["text-classification","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"TheoremQA","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/TheoremQA","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"TheoremQA\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe propose the first question-answering dataset driven by STEM theorems. We annotated 800 QA pairs covering 350+ theorems spanning across Math, EE&CS, Physics and Finance. The dataset is collected by human experts with very high quality. We provide the dataset as a new benchmark to test the limit of large language models to apply theorems to solve challenging university-level questions. We provide a pipeline in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/TheoremQA.","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"UltraTextbooks","keyword":"science","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/UltraTextbooks","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"UltraTextbooks\\\"\\n\\t\\n\\n\\nIn the digital expanse, a Tree of Knowledge grows,\\nIts branches of code and words intertwine in prose.\\nSynthetic leaves shimmer, human insights compose,\\nA binary symphony where wisdom forever flows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRepository\\n\\t\\n\\nThe \\\"UltraTextbooks\\\" dataset is hosted on the Hugging Face platform.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nThe \\\"UltraTextbooks\\\" dataset is a comprehensive collection of high-quality synthetic andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/UltraTextbooks.","first_N":5,"first_N_keywords":["text-generation","English","code","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"MathVision","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MathLLMs/MathVision","creator_name":"LLMs for Math Reasoning","creator_url":"https://huggingface.co/MathLLMs","description":"\\n\\t\\n\\t\\t\\n\\t\\tMeasuring Multimodal Mathematical Reasoning with the MATH-Vision Dataset\\n\\t\\n\\n[ðŸ’» Github] [ðŸŒ Homepage]  [ðŸ“Š Leaderboard ] [ðŸ” Visualization] [ðŸ“– ArXiv Paper]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸš€ Data Usage\\n\\t\\n\\n\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"MathLLMs/MathVision\\\")\\nprint(dataset)\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tðŸ’¥ News\\n\\t\\n\\n\\n[2025.03.10] ðŸ’¥ Kimi k1.6 Preview ðŸ¥‡ Sets New SOTA on MATH-V with 53.29%!See the full leaderboard.\\n[2025.02.28] ðŸ’¥ Doubao-1.5-pro Sets New SOTA on MATH-V with 48.62%! Read more on theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathVision.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","visual-question-answering","text-generation","expert-generated"],"keywords_longer_than_N":true},
	{"name":"arc-cot","keyword":"science","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/arc-cot","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAugmented ARC-Challenge Dataset with Chain-of-Thought Reasoning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset was created by augmenting the train subset of the AI2 Reasoning Challenge (ARC) dataset with chain-of-thought reasoning generated by Google's Gemini Pro language model. The goal is to provide additional context and intermediate reasoning steps to help models better solve the challenging multiple-choice science questions in ARC.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/arc-cot.","first_N":5,"first_N_keywords":["question-answering","English","cc-by-sa-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Amazon_Reviews_for_Sentiment_Analysis_fine_grained_5_classes","keyword":"reviews","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yassiracharki/Amazon_Reviews_for_Sentiment_Analysis_fine_grained_5_classes","creator_name":"yassir acharki","creator_url":"https://huggingface.co/yassiracharki","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThe Amazon reviews full score dataset is constructed by randomly taking 600,000 training samples and 130,000 testing samples for each review score from 1 to 5. In total there are 3,000,000 trainig samples and 650,000 testing samples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe files train.csv and test.csv contain all the training samples as comma-sparated values. There are 3 columns in them, corresponding to class index (1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yassiracharki/Amazon_Reviews_for_Sentiment_Analysis_fine_grained_5_classes.","first_N":5,"first_N_keywords":["text-classification","English","apache-2.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"MultiSimV2","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MichaelR207/MultiSimV2","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiSim Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe MultiSim benchmark is a growing collection of text simplification datasets targeted at sentence simplification in several languages.  Currently, the benchmark spans 12 languages.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nSentence Simplification\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"MichaelR207/MultiSimV2\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you use this benchmark, please cite ourâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MichaelR207/MultiSimV2.","first_N":5,"first_N_keywords":["summarization","text2text-generation","text-generation","English","French"],"keywords_longer_than_N":true},
	{"name":"MMMU-Thai","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iapp/MMMU-Thai","creator_name":"iApp Technology","creator_url":"https://huggingface.co/iapp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU Thai (MMMU Benchmark Translated to Thai)\\n\\t\\n\\nMMMU Thai is a dataset for evaluating multimodal models on massive multi-discipline tasks requiring college-level knowledge and deliberate reasoning. This dataset is translated from MMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI) into Thai.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nMMMU Thai consists of 11,500 meticulously collected multimodal questions from college exams, quizzes, and textbooksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iapp/MMMU-Thai.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","Thai","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Burmese-General-Reviews","keyword":"reviews","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Rickaym/Burmese-General-Reviews","creator_name":"Pyae Sone Myo","creator_url":"https://huggingface.co/Rickaym","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBurmese General Reviews\\n\\t\\n\\nA collection of 5k e-commerce reviews. Only a portion has been uploaded.\\nâš«âšªâšªâšªâšªâšªâšª 13.9%\\n(695/5,000)\\nThis dataset card aims to be of value to NLP endeavors in Burmese.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nSourced from various e-commerce platforms and communities. Uses Burmese Unicode. \\nThe reviews are normalized with [product], and [seller] in place of original names and products (this is still a work in progress)\\nBecause theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rickaym/Burmese-General-Reviews.","first_N":5,"first_N_keywords":["Burmese","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"VISCO","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/uclanlp/VISCO","creator_name":"UCLA NLP","creator_url":"https://huggingface.co/uclanlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVISCO\\n\\t\\n\\nBenchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning\\nðŸŒ Project | ðŸ“– Paper | ðŸ’» Github\\n\\n\\nOutline:\\n\\nIntroduction\\nData\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nVISCO is a benchmark for evaluating the critique and correction capabilities of LVLMs. VISCO contains:\\n\\n1645 pairs of questions and LVLM-generated answers. Each answer includes a chain-of-thought with multiple reasonign steps.\\n5604 step-wise annotations of critique, showingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/uclanlp/VISCO.","first_N":5,"first_N_keywords":["visual-question-answering","English","mit","1K<n<10K","arxiv:2412.02172"],"keywords_longer_than_N":true},
	{"name":"Math-Question-Answer","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aixr/Math-Question-Answer","creator_name":"Aixr AI","creator_url":"https://huggingface.co/Aixr","description":"Aixr/Math-Question-Answer dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"OpenThoughts-TR-18k","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/selimc/OpenThoughts-TR-18k","creator_name":"selim","creator_url":"https://huggingface.co/selimc","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpenThoughts-TR-18k: Turkish Synthetic Reasoning Dataset\\n\\t\\n\\nOpenThoughts-TR-18k is a Turkish translation of a subset of the original Open-Thoughts-114k dataset. It contains ~18k high-quality synthetic reasoning examples covering mathematics, science, coding problems, and puzzles, all translated into Turkish. This dataset is designed to support reasoning task fine tuning for Turkish language models.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n~18k translated reasoning examples\\nCovers multiple domains:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/selimc/OpenThoughts-TR-18k.","first_N":5,"first_N_keywords":["Turkish","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"multiscale_rotten_tomatoes_critic_reviews","keyword":"reviews","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/frankier/multiscale_rotten_tomatoes_critic_reviews","creator_name":"Frankie Robertson","creator_url":"https://huggingface.co/frankier","description":"Cleaned up version of the rotten tomatoes critic reviews dataset. The original\\nis obtained from Kaggle:\\nhttps://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset\\nData has been scraped from the publicly available website\\nhttps://www.rottentomatoes.com as of 2020-10-31.\\nThe clean up process drops anything without both a review and a rating, as well\\nas standardising the ratings onto several integer, ordinal scales.\\nRequires the kaggle library to beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/frankier/multiscale_rotten_tomatoes_critic_reviews.","first_N":5,"first_N_keywords":["text-classification","text-scoring","sentiment-scoring","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"b2w-reviews01","keyword":"reviews","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ruanchaves/b2w-reviews01","creator_name":"Ruan Chaves Rodrigues","creator_url":"https://huggingface.co/ruanchaves","description":"B2W-Reviews01 is an open corpus of product reviews. It contains more than 130k e-commerce customer reviews, collected from the Americanas.com website between January and May, 2018. B2W-Reviews01 offers rich information about the reviewer profile, such as gender, age, and geographical location. The corpus also has two different review rates","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","intent-classification","topic-classification"],"keywords_longer_than_N":true},
	{"name":"shopee-reviews-tl-stars","keyword":"reviews","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/scaredmeow/shopee-reviews-tl-stars","creator_name":"Neil Riego","creator_url":"https://huggingface.co/scaredmeow","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nTagalog (TL)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nA typical data point, comprises of a text and the corresponding label.\\nAn example from the YelpReviewFull test set looks as follows:\\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/scaredmeow/shopee-reviews-tl-stars.","first_N":5,"first_N_keywords":["text-classification","Tagalog","mpl-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"arxiv-metadata-snapshot","keyword":"science","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/librarian-bots/arxiv-metadata-snapshot","creator_name":"Librarian Bots","creator_url":"https://huggingface.co/librarian-bots","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"arxiv-metadata-oai-snapshot\\\"\\n\\t\\n\\nMore Information needed\\nThis is a mirror of the metadata portion of the arXiv dataset. \\nThe sync will take place weekly so may fall behind the original datasets slightly if there are more regular updates to the source dataset. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMetadata\\n\\t\\n\\nThis dataset is a mirror of the original ArXiv data. This dataset contains an entry for each paper, containing:\\n\\nid: ArXiv ID (can be used to access the paper, see below)\\nsubmitter: Whoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/librarian-bots/arxiv-metadata-snapshot.","first_N":5,"first_N_keywords":["text-generation","text-classification","English","cc0-1.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"TaoGPT-v1","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/agency888/TaoGPT-v1","creator_name":"agency","creator_url":"https://huggingface.co/agency888","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tToaGPT Dataset\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: Adithya S K\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [English]\\nLicense: [MIT]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: https://github.com/agencyxr/taogpt7B\\nDemo [optional]: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agency888/TaoGPT-v1.","first_N":5,"first_N_keywords":["question-answering","text2text-generation","table-question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"ghana-news","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldboss/ghana-news","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription ðŸ™…â€â™‚ï¸ðŸ¤–\\n\\t\\n\\nGhanaNews dataset is a collection of news articles from various Ghanaian News Portals (MyJoyOnline, GraphicOnline, GhanaWeb, PulseGh, CitiNewsOnline, ect). The dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc), information retrieval (ranking, search, etc), xml, data compression, data streaming, and any other non-commercial activity.\\nThe Ghana news topic classification dataset is constructed byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/worldboss/ghana-news.","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"amazon_reviews_mobile_electronics","keyword":"reviews","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rkf2778/amazon_reviews_mobile_electronics","creator_name":"Rohit Kochikkat Francis","creator_url":"https://huggingface.co/rkf2778","description":"rkf2778/amazon_reviews_mobile_electronics dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","English","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"geo-reviews-dataset-2023","keyword":"reviews","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/geo-reviews-dataset-2023","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeo Reviews Dataset 2023\\n\\t\\n\\nYandex is making available the largest Russian-language dataset of reviews about organizations published on Yandex Maps.\\nUse it for academic and research purposes, share your results with us in Issues.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\n500,000 unique reviews\\nOnly reviews about organizations in Russia\\nAvailable on Yandex Maps\\nPublished from January to July 2023\\nThe dataset does not contain short one-word reviews\\nReviews have been cleared of personal data (phoneâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/geo-reviews-dataset-2023.","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","token-classification","text2text-generation","monolingual"],"keywords_longer_than_N":true},
	{"name":"MMMU","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aslessor/MMMU","creator_name":"Alex","creator_url":"https://huggingface.co/aslessor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI)\\n\\t\\n\\nðŸŒ Homepage | ðŸ¤— Dataset | ðŸ¤— Paper | ðŸ“– arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸ””News\\n\\t\\n\\n\\nðŸ”¥[2023-12-04]: Our evaluation server for test set is now availble on EvalAI. We welcome all submissions and look forward to your participation! ðŸ˜†\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe introduce MMMU: a new benchmark designed to evaluate multimodal models on massiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aslessor/MMMU.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"dataclysm-arxiv","keyword":"science","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/somewheresystems/dataclysm-arxiv","creator_name":"S2","creator_url":"https://huggingface.co/somewheresystems","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDATACLYSM PATCH 0.0.2: ARXIV\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUSE THE NOTEBOOK TO GET STARTED!\\n\\t\\n\\nhttps://github.com/somewheresystems/dataclysm\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsomewheresystems/dataclysm-wikipedia-titles\\n\\t\\n\\nThis dataset comprises of 3,360,984 English language arXiv papers from the Cornell/arXiv dataset, with two new columns added: title-embeddings and abstract-embeddings. These additional columns were generated using the bge-small-en-v1.5 embeddings model. The dataset was sourced from the Cornell/arXivâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/somewheresystems/dataclysm-arxiv.","first_N":5,"first_N_keywords":["English","cc0-1.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"scidocs-keywords-exkeyliword","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nicolauduran45/scidocs-keywords-exkeyliword","creator_name":"Nicolau Duran","creator_url":"https://huggingface.co/nicolauduran45","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSciDocs Keywords exKEYliWORD\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nSciDocs2Keywords is a dataset consisting of scientific papers (title and abstract) and their associated author-provided keywords. It is designed for use in task of keyword extraction or abstraction.\\nEach entry in the dataset includes:\\n\\nTitle: The title of the scientific paper.\\nAbstract: A brief summary of the paper.\\nAuthor Keywords: Keywords provided by the authors to highlight the main topics or concepts of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicolauduran45/scidocs-keywords-exkeyliword.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"ScImage","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/casszhao/ScImage","creator_name":"casszhao","creator_url":"https://huggingface.co/casszhao","description":"The prompt for ICLR2025 paper \\nScImage: HOW GOOD ARE MULTIMODAL LARGE LANGUAGE MODELS AT SCIENTIFIC TEXT-TO-IMAGE GENERATION?\\nThe prompt template and the object list will be added soon.\\n@inproceedings{\\nscimage2025,\\ntitle={ScImage: How Good Are Multimodal Large Language Models at Scientific Text-to-Image Generation?},\\nauthor={Zhang, Leixin and Cheng, Yinjie and Zhai, Weihe and Eger, Steffen and Belouadi, Jonas and Moafian, Fahimeh and Zhao, Zhixue},\\nbooktitle={The Thirteenth Internationalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/casszhao/ScImage.","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_8th","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_8th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Science_8th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_9th","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_9th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Science_9th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"NCERT_Science_10th","keyword":"science","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_10th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Science_10th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"food_reviews-sentiment-analysis","keyword":"reviews","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Shekswess/food_reviews-sentiment-analysis","creator_name":"Bojan Jakimovski","creator_url":"https://huggingface.co/Shekswess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\nTopic: Food Reviews\\nDomains: Fast Food, Fine Dining, Home Cooking\\nFocus: This dataset contains food reviews for different styles of cooking.\\nNumber of Entries: 500\\nDataset Type: Sentiment Analysis Dataset\\nModel Used: bedrock/us.amazon.nova-pro-v1:0\\nLanguage: English\\nAdditional Information: The dataset is designed to help analyze the sentiment of reviews across various food styles.\\nGenerated by: SynthGenAI Package\\n\\n","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"gp_surgery_reviews_fake_and_real","keyword":"reviews","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/janduplessis886/gp_surgery_reviews_fake_and_real","creator_name":"Jan du Plessis","creator_url":"https://huggingface.co/janduplessis886","description":"\\n\\t\\n\\t\\t\\n\\t\\tGP Surgery Reviews Dataset Data Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset consists of GP Surgery reviews designed for binary classification tasks. It includes both real and fake reviews, where the label feature marks real reviews as 0 and fake reviews as 1. The fake reviews were generated using DeepSeek LLM (Ollama) and then passed through a processing pipeline to derive additional features.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Composition\\n\\t\\n\\n\\nTotal Records: 9,974\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFeatures:\\n\\t\\n\\n\\nfree_text:\\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/janduplessis886/gp_surgery_reviews_fake_and_real.","first_N":5,"first_N_keywords":["text-classification","English","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"amazon-beauty-reviews-dataset","keyword":"reviews","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jhan21/amazon-beauty-reviews-dataset","creator_name":"misschestnut","creator_url":"https://huggingface.co/jhan21","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"Amazon Beauty Reviews\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of reviews of \\\"All Beauty\\\" category from amazon. The data includes all ~700,000 reviews up to 2023. Reviews include product and user information, ratings, and a plain text review. \\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be used for numerous tasks like sentiment analysis, text classification, and user behavior analysis. It's particularly useful for training models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhan21/amazon-beauty-reviews-dataset.","first_N":5,"first_N_keywords":["text-classification","English","cc0-1.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"ScienceGlossary","keyword":"science","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JonyC/ScienceGlossary","creator_name":"Jonatan Cohen","creator_url":"https://huggingface.co/JonyC","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Science Terms and Phrases Glossary\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThis dataset contains scientific terms and phrases from various disciplines, compiled from multiple sources.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset was created by web scraping scientific glossaries from sources like Wikipedia, NASA, and other academic references. Additionally, some terms were generated using ChatGPT-4.0.  \\nIt is designed for token classification, meaning it includes both scientificâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JonyC/ScienceGlossary.","first_N":5,"first_N_keywords":["text-classification","token-classification","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true}
]
;
