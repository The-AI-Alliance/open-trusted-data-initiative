var data_for_science = [

  {"name":"dataclysm-pubmed","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/somewheresystems/dataclysm-pubmed","creator_name":"S2","creator_url":"https://huggingface.co/somewheresystems","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDATACLYSM PATCH 0.0.4: PUBMED\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUSE THE NOTEBOOK TO GET STARTED!\\n\\t\\n\\nhttps://github.com/somewheresystems/dataclysm\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsomewheresystems/dataclysm-pubmed\\n\\t\\n\\nThis dataset comprises of 35.7 million PubMed metadata entries including title and some (~69% with) abstracts, with two new columns added: title-embeddings and abstract-embeddings. These additional columns were generated using the bge-small-en-v1.5 embeddings model. The dataset was sourced from the PubMed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somewheresystems/dataclysm-pubmed."},
  {"name":"Luganda_Sci-Math-Bio_Translations","keyword":"science","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/allandclive/Luganda_Sci-Math-Bio_Translations","creator_name":"Allan D Clive","creator_url":"https://huggingface.co/allandclive","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLuganda Sci-Math-Bio Translations\\n\\t\\n\\nThis dataset contains Luganda and English translations of biologicial, mathematical and scientific terms\\n"},
  {"name":"Astro-mcqa","keyword":"science","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/patrickfleith/Astro-mcqa","creator_name":"Patrick Fleith","creator_url":"https://huggingface.co/patrickfleith","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAstroMCQA Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose and scope\\n\\t\\n\\nThe primary purpose of AstroMCQA is for application developers in the domain of space engineering to be able to comparatively assess LLM performances on the specific task of multiple-choice question-answering\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntended Usage\\n\\t\\n\\nComparative assessement of differents LLMs, Model evaluation, audit, and model selection. Assessment of different quantization levels, different prompting strategies, and assessing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/patrickfleith/Astro-mcqa."},
  {"name":"scientific_studies","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/yousefg/scientific_studies","creator_name":"Yousef Rafat Gamaleldin","creator_url":"https://huggingface.co/yousefg","description":"yousefg/scientific_studies dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"scientific_papers_from_arxiv","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/scientific_papers_from_arxiv","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tscientific_papers_from_arxiv Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic paper search for scientific research\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the scientific_papers_from_arxiv model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scientific_papers_from_arxiv."},
  {"name":"jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic research papers search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scientific-papers-from-arxiv."},
  {"name":"jinaai_jina-embeddings-v2-base-en-scidocs","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scidocs","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-en-scidocs Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic research papers search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-scidocs model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-scidocs."},
  {"name":"jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic search for scientific papers\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-jinaai_jina-embeddings-v2-base-en-sc."},
  {"name":"scidocs","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/scidocs","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tscidocs Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic search for scientific papers\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the scidocs model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs."},
  {"name":"scidocs-c","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tscidocs-c Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic research papers search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the scidocs-c model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c."},
  {"name":"scidocs-c-128-24","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tscidocs-c-128-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic search for scientific papers\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the scidocs-c-128-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-128-24."},
  {"name":"scidocs-c-256-24","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tscidocs-c-256-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic paper search for scientific articles\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the scidocs-c-256-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-256-24."},
  {"name":"scidocs-c-64-24","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tscidocs-c-64-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"academic research papers search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the scidocs-c-64-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/scidocs-c-64-24."},
  {"name":"M4U","keyword":"science","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/M4U-Benchmark/M4U","creator_name":"M4U-Benchmark","creator_url":"https://huggingface.co/M4U-Benchmark","description":"\\n\\t\\n\\t\\t\\n\\t\\tM4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models\\n\\t\\n\\nCode for the Paper M4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models.\\n[Webpage] [Paper] [Huggingface Dataset] [Leaderboard]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüí• News üí•\\n\\t\\n\\n\\n[2024.05.23] Our paper, dataset and code are public aviailable.\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tüëÄ About M4U\\n\\t\\n\\n\\n     \\n\\n\\nMultilingual multimodal reasoning is a core component to achieve human-level intelligence. However, most of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/M4U-Benchmark/M4U."},
  {"name":"SciFact-256-24-gpt-4o-2024-05-13-526066","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-526066","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSciFact-256-24-gpt-4o-2024-05-13-526066 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"scientific claim verification\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-526066 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-526066."},
  {"name":"SciFact-256-24-gpt-4o-2024-05-13-994884","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-994884","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSciFact-256-24-gpt-4o-2024-05-13-994884 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"scientific claim verification search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-994884 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-994884."},
  {"name":"SciFact-256-24-gpt-4o-2024-05-13-3778","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-3778","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSciFact-256-24-gpt-4o-2024-05-13-3778 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"scientific claim verification\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-3778 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-3778."},
  {"name":"SciFact-256-24-gpt-4o-2024-05-13-204265","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-204265","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSciFact-256-24-gpt-4o-2024-05-13-204265 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"scientific claim verification\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-204265 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-204265."},
  {"name":"SciFact-256-24-gpt-4o-2024-05-13-499715","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-499715","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSciFact-256-24-gpt-4o-2024-05-13-499715 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"scientific claim verification\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-499715 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-499715."},
  {"name":"SciFact-256-24-gpt-4o-2024-05-13-478897","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-478897","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSciFact-256-24-gpt-4o-2024-05-13-478897 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"scientific claim verification\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SciFact-256-24-gpt-4o-2024-05-13-478897 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-256-24-gpt-4o-2024-05-13-478897."},
  {"name":"VisualWebInstruct-Seed","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct-Seed","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is the seed dataset we used to conduct Google Search.\\n\\n\\t\\n\\t\\t\\n\\t\\tLinks\\n\\t\\n\\nGithub|\\nPaper|\\nWebsite\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{visualwebinstruct,\\n    title={VisualWebInstruct: Scaling up Multimodal Instruction Data through Web Search},\\n    author = {Jia, Yiming and Li, Jiachen and Yue, Xiang and Li, Bo and Nie, Ping and Zou, Kai and Chen, Wenhu},\\n    journal={arXiv preprint arXiv:2503.10582},\\n    year={2025}\\n}\\n\\n"},
  {"name":"SciFact-512-192-gpt-4o-2024-05-13-866232","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-866232","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSciFact-512-192-gpt-4o-2024-05-13-866232 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"general domain\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SciFact-512-192-gpt-4o-2024-05-13-866232 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SciFact-512-192-gpt-4o-2024-05-13-866232."},
  {"name":"SCIDOCS-512-192-gpt-4o-2024-05-13-650620","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-650620","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSCIDOCS-512-192-gpt-4o-2024-05-13-650620 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"arxiv paper domain\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SCIDOCS-512-192-gpt-4o-2024-05-13-650620 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-512-192-gpt-4o-2024-05-13-650620."},
  {"name":"AstroChat","keyword":"science","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/patrickfleith/AstroChat","creator_name":"Patrick Fleith","creator_url":"https://huggingface.co/patrickfleith","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAstroChat Dataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose and Scope\\n\\t\\n\\nThe AstroChat dataset is a collection of 901 dialogues, synthetically generated, tailored to the specific domain of Astronautics / Space Mission Engineering.\\nThis dataset will be frequently updated following feedback from the community. If you would like to contribute, please reach out in the community discussion.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntended Use\\n\\t\\n\\nThe dataset is intended to be used for supervised fine-tuning of chat LLMs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/patrickfleith/AstroChat."},
  {"name":"gliner-bird-diet-synthetic","keyword":"science","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/wjbmattingly/gliner-bird-diet-synthetic","creator_name":"William Mattingly","creator_url":"https://huggingface.co/wjbmattingly","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGLiNER Bird Diet Synthetic Dataset\\n\\t\\n\\nThis is an NER dataset focused on ornithological data, specifically focused on the diets of birds. The data is purely synthetic and should not be taken as factual. We created this dataset using Qwen2-7B-Instruct. It consists of ~2k descriptions. The format of the annotations consists with the GLiNER format. We used this data to finetune a GLiNER model. For the base model, we used NuNerZero Span. You can visit our model here: GLiNER Ecology‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wjbmattingly/gliner-bird-diet-synthetic."},
  {"name":"CoMDataset","keyword":"science","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/qijimrc/CoMDataset","creator_name":"Ji Qi","creator_url":"https://huggingface.co/qijimrc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe open-source both the Automatically Synthesized CoM Data and the Manually Annotated CoM-Math Data to facilitate potential research. The automatically synthesized CoM data (i.e., com.jsonl) consists of 84K positive reasoning chains, which was produced by an automated data generation pipeline with an LLM-based (GPT-4) linguistic solving steps generation and a VFMs-based (GroundingDINO, PaddleOCR) visual evidence compensation upon massive public VQA samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qijimrc/CoMDataset."},
  {"name":"BAAI_bge-large-en-15062024-atex-webapp","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBAAI_bge-large-en-15062024-atex-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"general domain\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the BAAI_bge-large-en-15062024-atex-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-15062024-atex-webapp."},
  {"name":"BAAI_bge-large-en-v1_5-1562024-to89-webapp","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1562024-to89-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBAAI_bge-large-en-v1_5-1562024-to89-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"scientific research in medicine, biology, and technology\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the BAAI_bge-large-en-v1_5-1562024-to89-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-1562024-to89-webapp."},
  {"name":"Celestia","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sequelbox/Celestia","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Celestia is a dataset containing science-instruct data.\\nThe 2024-10-30 version contains:\\n\\n126k rows of synthetic science-instruct data, using synthetically generated prompts and responses generated using Llama 3.1 405b Instruct. Primary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\\n\\nThis dataset contains synthetically generated data and has not been subject to manual review.\\n"},
  {"name":"gardian-ai-ready-docs","keyword":"science","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CGIAR/gardian-ai-ready-docs","creator_name":"CGIAR","creator_url":"https://huggingface.co/CGIAR","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\t‚ö†Ô∏è Heads up: Updated Dataset Available\\n\\t\\n\\nThis dataset has been updated with a newer version published on 27 Feb 2025. The latest version includes more updated and refined set of documents.\\nWe recommend using the latest version, available at https://huggingface.co/datasets/CGIAR/gardian-cigi-ai-documents. This version remains accessible for reference and reproducibility purposes.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tA Curated Research Corpus for Agricultural Advisory AI Applications\\n\\t\\n\\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CGIAR/gardian-ai-ready-docs."},
  {"name":"protobowl-11-13","keyword":"science","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mgor/protobowl-11-13","creator_name":"Maharshi Gor","creator_url":"https://huggingface.co/mgor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProgressive Quiz Bowl Clues Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains Quiz Bowl questions and their corresponding progressive clues, designed for evaluating question-answering systems.\\nThe progressive clues subset contains additional features such as GPT-3.5 generated categories and subcategories specific to each progressive clue.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nName: protobowl-11-13\\nVersion: 1.0\\nMaintainer: mgor\\nHub URL:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mgor/protobowl-11-13."},
  {"name":"academic-section-classification","keyword":"science","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/nhop/academic-section-classification","creator_name":"Niklas Hoepner","creator_url":"https://huggingface.co/nhop","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset for Classification of Sections of Academic Papers\\n\\t\\n\\nA dataset mapping sections of academic papers to one of the following section types:\\n0: Introduction 1: Background 2: Methodology 3: Experiments and Results 4: Conclusion \\nThe dataset was collected by taking the GROBID parses of academic papers in the ACL-OCL dataset and matching the section headings to one of the synonyms of each section type. Sections that did not have a match were disregarded. The following synonyms are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nhop/academic-section-classification."},
  {"name":"MMMU_Pro","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/MMMU/MMMU_Pro","creator_name":"MMMU","creator_url":"https://huggingface.co/MMMU","description":"\\n\\t\\n\\t\\t\\n\\t\\tMMMU-Pro (A More Robust Multi-discipline Multimodal Understanding Benchmark)\\n\\t\\n\\nüåê Homepage | üèÜ Leaderboard | ü§ó Dataset | ü§ó Paper | üìñ arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüîîNews\\n\\t\\n\\n\\nüõ†Ô∏èüõ†Ô∏è [2025-03-08] Fixed mismatch between inner image labels and shuffled options in Vision and Standard (10 options) settings. (test_Chemistry_5,94,147,216,314,345,354,461,560,570; test_Materials_450; test_Pharmacy_198; validation_Chemistry_12,26,29; validation_Materials_10,28; validation_Psychology_1)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MMMU/MMMU_Pro."},
  {"name":"Spurline","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sequelbox/Spurline","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Spurline is a dataset containing complex responses, emphasizing logical reasoning and using Shining Valiant's friendly, magical personality style.\\nThe 2024-10-30 version contains:\\n\\n10.7k rows of synthetic queries, using randomly selected prompts from migtissera/Synthia-v1.5-I and responses generated using Llama 3.1 405b Instruct.\\n\\nThis dataset contains synthetically generated data and has not been subject to manual review.\\n"},
  {"name":"scips_qa","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zorpsoon/scips_qa","creator_name":"Prasoon Bajpai","creator_url":"https://huggingface.co/zorpsoon","description":"zorpsoon/scips_qa dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"NCERT_Science_6th","keyword":"science","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_6th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Science_6th dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"NCERT_Science_7th","keyword":"science","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_7th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Science_7th dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"InqBench","keyword":"science","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/InqModel/InqBench","creator_name":"junjie Lu","creator_url":"https://huggingface.co/InqModel","description":"InqModel/InqBench dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Celestia2","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sequelbox/Celestia2","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Celestia 2 is a multi-turn agent-instruct dataset containing science data.\\nThis dataset focuses on challenging multi-turn conversations and contains:\\n\\n176k rows of synthetic multi-turn science-instruct data, using Microsoft's AgentInstruct style. All prompts and responses are synthetically generated using Llama 3.1 405b Instruct. Primary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\\n\\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Celestia2."},
  {"name":"VisualWebInstruct","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is the final dataset we used to train MAmmoTH-VL2.\\n\\n\\t\\n\\t\\t\\n\\t\\tSubset\\n\\t\\n\\n\\nconversation: this subset contains VisualWebInstruct + LLavaCoT in the form of conversation.\\nexample: this subset is mainly for visualizing the examples.\\nvisualwebinstruct: this subset contains our dataset in the QA format.\\nimage: all the images are in imgs.tar.gz\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLinks\\n\\t\\n\\nGithub|\\nPaper|\\nWebsite|\\nModel\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{visualwebinstruct,\\n    title={VisualWebInstruct: Scaling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct."},
  {"name":"MathVista","keyword":"science","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/AI4Math/MathVista","creator_name":"AI for Math Reasoning","creator_url":"https://huggingface.co/AI4Math","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MathVista\\n\\t\\n\\n\\nDataset Description\\nPaper Information\\nDataset Examples\\nLeaderboard\\nDataset Usage\\nData Downloading\\nData Format\\nData Visualization\\nData Source\\nAutomatic Evaluation\\n\\n\\nLicense\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMathVista is a consolidated Mathematical reasoning benchmark within Visual contexts. It consists of three newly created datasets, IQTest, FunctionQA, and PaperQA, which address the missing visual domains and are tailored to evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI4Math/MathVista."},
  {"name":"natural-science-reasoning","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dvilasuero/natural-science-reasoning","creator_name":"Daniel Vila","creator_url":"https://huggingface.co/dvilasuero","description":"\\n\\t\\n\\t\\t\\n\\t\\tNatural Sciences Reasoning: the \\\"smolest\\\" reasoning dataset\\n\\t\\n\\nA smol-scale open dataset for reasoning tasks using Hugging Face Inference Endpoints. While intentionally limited in scale, this resource prioritizes:\\n\\nReproducible pipeline for reasoning tasks using a variety of models (Deepseek V3, Deepsek-R1, Llama70B-Instruct, etc.)\\n\\nKnowledge sharing for domains other than Math and Code reasoning\\n\\n\\nIn this repo, you can find:\\n\\nThe prompts and the pipeline (see the config file).\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dvilasuero/natural-science-reasoning."},
  {"name":"ScienceQA","keyword":"science","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/derek-thomas/ScienceQA","creator_name":"Derek Thomas","creator_url":"https://huggingface.co/derek-thomas","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card Creation Guide\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLearn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMulti-modal Multiple Choice\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nExplore more samples here.\\n{'image': Image,\\n 'question': 'Which of these states is farthest north?',\\n 'choices': ['West Virginia', 'Louisiana', 'Arizona'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/derek-thomas/ScienceQA."},
  {"name":"gardian-cigi-ai-documents","keyword":"science","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CGIAR/gardian-cigi-ai-documents","creator_name":"CGIAR","creator_url":"https://huggingface.co/CGIAR","description":"Pages: 1,438,332\\nTokens: 277,445,818\\n\\n\\t\\n\\t\\t\\n\\t\\tA Curated Research Corpus for Agricultural Advisory AI Applications\\n\\t\\n\\nThis dataset represents a comprehensive collection of 43,745 agricultural research publications from CGIAR,\\nspecifically processed and structured for Large Language Model (LLM) applications in agricultural advisory services. \\nThis dataset bridges the gap between advanced agricultural research and field-level advisory needs, \\ndrawing from CGIAR's extensive scientific knowledge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CGIAR/gardian-cigi-ai-documents."},
  {"name":"MMMU","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/MMMU/MMMU","creator_name":"MMMU","creator_url":"https://huggingface.co/MMMU","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI)\\n\\t\\n\\nüåê Homepage | üèÜ Leaderboard | ü§ó Dataset | ü§ó Paper | üìñ arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüîîNews\\n\\t\\n\\n\\nüõ†Ô∏è[2024-05-30]: Fixed duplicate option issues in Materials dataset items (validation_Materials_25; test_Materials_17, 242) and content error in validation_Materials_25.\\nüõ†Ô∏è[2024-04-30]: Fixed missing \\\"-\\\" or \\\"^\\\" signs in Math dataset items (dev_Math_2, validation_Math_11, 12, 16;‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MMMU/MMMU."},
  {"name":"nlp_taxonomy_data","keyword":"science","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/TimSchopf/nlp_taxonomy_data","creator_name":"Tim Schopf","creator_url":"https://huggingface.co/TimSchopf","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNLP Taxonomy Classification Data\\n\\t\\n\\nThe dataset consists of titles and abstracts from NLP-related papers. Each paper is annotated with multiple fields of study from the NLP taxonomy. Each sample is annotated with all possible lower-level concepts and their hypernyms in the NLP taxonomy. The training dataset contains 178,521 weakly annotated samples. The test dataset consists of 828 manually annotated samples from the EMNLP22 conference. The manually labeled test dataset might not‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TimSchopf/nlp_taxonomy_data."},
  {"name":"arxiv_categories","keyword":"science","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/TimSchopf/arxiv_categories","creator_name":"Tim Schopf","creator_url":"https://huggingface.co/TimSchopf","description":"üìÑ Paper: Efficient Few-shot Learning for Multi-label Classification of Scientific Documents with Many Classes (ICNLSP 2024)\\nüíª GitHub: https://github.com/sebischair/FusionSent\\nThis is a dataset of scientific documents derived from arXiv metadata. The arXiv metadata provides information about more than 2 million scholarly articles published in arXiv from various scientific fields. We use this metadata to create a dataset of 203,961 titles and abstracts categorized into 130 different classes.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TimSchopf/arxiv_categories."},
  {"name":"TheoremQA","keyword":"science","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/TIGER-Lab/TheoremQA","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"TheoremQA\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe propose the first question-answering dataset driven by STEM theorems. We annotated 800 QA pairs covering 350+ theorems spanning across Math, EE&CS, Physics and Finance. The dataset is collected by human experts with very high quality. We provide the dataset as a new benchmark to test the limit of large language models to apply theorems to solve challenging university-level questions. We provide a pipeline in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/TheoremQA."},
  {"name":"UltraTextbooks","keyword":"science","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Locutusque/UltraTextbooks","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"UltraTextbooks\\\"\\n\\t\\n\\n\\nIn the digital expanse, a Tree of Knowledge grows,\\nIts branches of code and words intertwine in prose.\\nSynthetic leaves shimmer, human insights compose,\\nA binary symphony where wisdom forever flows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRepository\\n\\t\\n\\nThe \\\"UltraTextbooks\\\" dataset is hosted on the Hugging Face platform.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nThe \\\"UltraTextbooks\\\" dataset is a comprehensive collection of high-quality synthetic and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/UltraTextbooks."},
  {"name":"MathVision","keyword":"science","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MathLLMs/MathVision","creator_name":"LLMs for Math Reasoning","creator_url":"https://huggingface.co/MathLLMs","description":"\\n\\t\\n\\t\\t\\n\\t\\tMeasuring Multimodal Mathematical Reasoning with the MATH-Vision Dataset\\n\\t\\n\\n[üíª Github] [üåê Homepage]  [üìä Leaderboard ] [üîç Visualization] [üìñ ArXiv Paper]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüöÄ Data Usage\\n\\t\\n\\n\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"MathLLMs/MathVision\\\")\\nprint(dataset)\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tüí• News\\n\\t\\n\\n\\n[2025.03.10] üí• Kimi k1.6 Preview ü•á Sets New SOTA on MATH-V with 53.29%!See the full leaderboard.\\n[2025.02.28] üí• Doubao-1.5-pro Sets New SOTA on MATH-V with 48.62%! Read more on the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathVision."},
  {"name":"arc-cot","keyword":"science","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Locutusque/arc-cot","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAugmented ARC-Challenge Dataset with Chain-of-Thought Reasoning\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset was created by augmenting the train subset of the AI2 Reasoning Challenge (ARC) dataset with chain-of-thought reasoning generated by Google's Gemini Pro language model. The goal is to provide additional context and intermediate reasoning steps to help models better solve the challenging multiple-choice science questions in ARC.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/arc-cot."},
  {"name":"MultiSimV2","keyword":"science","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MichaelR207/MultiSimV2","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiSim Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe MultiSim benchmark is a growing collection of text simplification datasets targeted at sentence simplification in several languages.  Currently, the benchmark spans 12 languages.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nSentence Simplification\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"MichaelR207/MultiSimV2\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you use this benchmark, please cite our‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MichaelR207/MultiSimV2."},
  {"name":"MMMU-Thai","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/iapp/MMMU-Thai","creator_name":"iApp Technology","creator_url":"https://huggingface.co/iapp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU Thai (MMMU Benchmark Translated to Thai)\\n\\t\\n\\nMMMU Thai is a dataset for evaluating multimodal models on massive multi-discipline tasks requiring college-level knowledge and deliberate reasoning. This dataset is translated from MMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI) into Thai.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nMMMU Thai consists of 11,500 meticulously collected multimodal questions from college exams, quizzes, and textbooks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iapp/MMMU-Thai."},
  {"name":"VISCO","keyword":"science","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/uclanlp/VISCO","creator_name":"UCLA NLP","creator_url":"https://huggingface.co/uclanlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVISCO\\n\\t\\n\\nBenchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning\\nüåê Project | üìñ Paper | üíª Github\\n\\n\\nOutline:\\n\\nIntroduction\\nData\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nVISCO is a benchmark for evaluating the critique and correction capabilities of LVLMs. VISCO contains:\\n\\n1645 pairs of questions and LVLM-generated answers. Each answer includes a chain-of-thought with multiple reasonign steps.\\n5604 step-wise annotations of critique, showing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/uclanlp/VISCO."},
  {"name":"Math-Question-Answer","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Aixr/Math-Question-Answer","creator_name":"Aixr AI","creator_url":"https://huggingface.co/Aixr","description":"Aixr/Math-Question-Answer dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"OpenThoughts-TR-18k","keyword":"science","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/selimc/OpenThoughts-TR-18k","creator_name":"selim","creator_url":"https://huggingface.co/selimc","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpenThoughts-TR-18k: Turkish Synthetic Reasoning Dataset\\n\\t\\n\\nOpenThoughts-TR-18k is a Turkish translation of a subset of the original Open-Thoughts-114k dataset. It contains ~18k high-quality synthetic reasoning examples covering mathematics, science, coding problems, and puzzles, all translated into Turkish. This dataset is designed to support reasoning task fine tuning for Turkish language models.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n~18k translated reasoning examples\\nCovers multiple domains:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/selimc/OpenThoughts-TR-18k."},
  {"name":"arxiv-metadata-snapshot","keyword":"science","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/librarian-bots/arxiv-metadata-snapshot","creator_name":"Librarian Bots","creator_url":"https://huggingface.co/librarian-bots","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"arxiv-metadata-oai-snapshot\\\"\\n\\t\\n\\nMore Information needed\\nThis is a mirror of the metadata portion of the arXiv dataset. \\nThe sync will take place weekly so may fall behind the original datasets slightly if there are more regular updates to the source dataset. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMetadata\\n\\t\\n\\nThis dataset is a mirror of the original ArXiv data. This dataset contains an entry for each paper, containing:\\n\\nid: ArXiv ID (can be used to access the paper, see below)\\nsubmitter: Who‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/librarian-bots/arxiv-metadata-snapshot."},
  {"name":"TaoGPT-v1","keyword":"science","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/agency888/TaoGPT-v1","creator_name":"agency","creator_url":"https://huggingface.co/agency888","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tToaGPT Dataset\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: Adithya S K\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [English]\\nLicense: [MIT]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: https://github.com/agencyxr/taogpt7B\\nDemo [optional]: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agency888/TaoGPT-v1."},
  {"name":"ghana-news","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/worldboss/ghana-news","creator_name":"Theophilus Siameh","creator_url":"https://huggingface.co/worldboss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription üôÖ‚Äç‚ôÇÔ∏èü§ñ\\n\\t\\n\\nGhanaNews dataset is a collection of news articles from various Ghanaian News Portals (MyJoyOnline, GraphicOnline, GhanaWeb, PulseGh, CitiNewsOnline, ect). The dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc), information retrieval (ranking, search, etc), xml, data compression, data streaming, and any other non-commercial activity.\\nThe Ghana news topic classification dataset is constructed by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worldboss/ghana-news."},
  {"name":"MMMU","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/aslessor/MMMU","creator_name":"Alex","creator_url":"https://huggingface.co/aslessor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI)\\n\\t\\n\\nüåê Homepage | ü§ó Dataset | ü§ó Paper | üìñ arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüîîNews\\n\\t\\n\\n\\nüî•[2023-12-04]: Our evaluation server for test set is now availble on EvalAI. We welcome all submissions and look forward to your participation! üòÜ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe introduce MMMU: a new benchmark designed to evaluate multimodal models on massive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aslessor/MMMU."},
  {"name":"dataclysm-arxiv","keyword":"science","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/somewheresystems/dataclysm-arxiv","creator_name":"S2","creator_url":"https://huggingface.co/somewheresystems","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDATACLYSM PATCH 0.0.2: ARXIV\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUSE THE NOTEBOOK TO GET STARTED!\\n\\t\\n\\nhttps://github.com/somewheresystems/dataclysm\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsomewheresystems/dataclysm-wikipedia-titles\\n\\t\\n\\nThis dataset comprises of 3,360,984 English language arXiv papers from the Cornell/arXiv dataset, with two new columns added: title-embeddings and abstract-embeddings. These additional columns were generated using the bge-small-en-v1.5 embeddings model. The dataset was sourced from the Cornell/arXiv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somewheresystems/dataclysm-arxiv."},
  {"name":"scidocs-keywords-exkeyliword","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nicolauduran45/scidocs-keywords-exkeyliword","creator_name":"Nicolau Duran","creator_url":"https://huggingface.co/nicolauduran45","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSciDocs Keywords exKEYliWORD\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nSciDocs2Keywords is a dataset consisting of scientific papers (title and abstract) and their associated author-provided keywords. It is designed for use in task of keyword extraction or abstraction.\\nEach entry in the dataset includes:\\n\\nTitle: The title of the scientific paper.\\nAbstract: A brief summary of the paper.\\nAuthor Keywords: Keywords provided by the authors to highlight the main topics or concepts of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicolauduran45/scidocs-keywords-exkeyliword."},
  {"name":"ScImage","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/casszhao/ScImage","creator_name":"casszhao","creator_url":"https://huggingface.co/casszhao","description":"The prompt for ICLR2025 paper \\nScImage: HOW GOOD ARE MULTIMODAL LARGE LANGUAGE MODELS AT SCIENTIFIC TEXT-TO-IMAGE GENERATION?\\nThe prompt template and the object list will be added soon.\\n@inproceedings{\\nscimage2025,\\ntitle={ScImage: How Good Are Multimodal Large Language Models at Scientific Text-to-Image Generation?},\\nauthor={Zhang, Leixin and Cheng, Yinjie and Zhai, Weihe and Eger, Steffen and Belouadi, Jonas and Moafian, Fahimeh and Zhao, Zhixue},\\nbooktitle={The Thirteenth International‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/casszhao/ScImage."},
  {"name":"NCERT_Science_8th","keyword":"science","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_8th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Science_8th dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"NCERT_Science_9th","keyword":"science","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_9th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Science_9th dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"NCERT_Science_10th","keyword":"science","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/KadamParth/NCERT_Science_10th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Science_10th dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"ScienceGlossary","keyword":"science","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/JonyC/ScienceGlossary","creator_name":"Jonatan Cohen","creator_url":"https://huggingface.co/JonyC","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Science Terms and Phrases Glossary\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThis dataset contains scientific terms and phrases from various disciplines, compiled from multiple sources.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset was created by web scraping scientific glossaries from sources like Wikipedia, NASA, and other academic references. Additionally, some terms were generated using ChatGPT-4.0.  \\nIt is designed for token classification, meaning it includes both scientific‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JonyC/ScienceGlossary."}
];
