var data_for_math = 
[
	{"name":"IMO-geometry","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/theblackcat102/IMO-geometry","creator_name":"theblackcat102","creator_url":"https://huggingface.co/theblackcat102","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIMO geometry questions\\n\\t\\n\\n32 IMO geometry questions from 2000 to 2021 (filter by category \\\"IMO\\\")\\nData source : https://artofproblemsolving.com/wiki/index.php/Category:Olympiad_Geometry_Problems\\n55 more questions from others (other regional olympiad competition) as well as 13 GPT-4 generate ones.\\nOnly the raw questions are available, if you want to use them for alpha geometry there's still a missing translation step.\\nThis is the example shown in Alpha Geometry\\nQuestion:\\nLet ABC be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/theblackcat102/IMO-geometry."},
	{"name":"basic-math-1m","keyword":"math","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrfakename/basic-math-1m","creator_name":"mrfakename","creator_url":"https://huggingface.co/mrfakename","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBasic Math 1M\\n\\t\\n\\nA dataset of 1 million basic arithmetic problems with potential user prompts.\\nBasic Math 10M was inspired by Simple Math.\\n"},
	{"name":"Luganda_Sci-Math-Bio_Translations","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allandclive/Luganda_Sci-Math-Bio_Translations","creator_name":"Allan D Clive","creator_url":"https://huggingface.co/allandclive","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLuganda Sci-Math-Bio Translations\\n\\t\\n\\nThis dataset contains Luganda and English translations of biologicial, mathematical and scientific terms\\n"},
	{"name":"polytopes-4d","keyword":"math","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/calabi-yau-data/polytopes-4d","creator_name":"Calabi-Yau data","creator_url":"https://huggingface.co/calabi-yau-data","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFour-Dimensional Reflexive Lattice Polytopes\\n\\t\\n\\nThis dataset contains all four-dimensional reflexive lattice polytopes. The data was\\ncompiled by Maximilian Kreuzer and Harald Skarke in\\narXiv:hep-th/0002240. More information is\\navailable at the Calabi-Yau data website.\\nPlease cite the paper when referencing this dataset:\\n@article{Kreuzer:2000xy,\\n    author = \\\"Kreuzer, Maximilian and Skarke, Harald\\\",\\n    title = \\\"{Complete classification of reflexive polyhedra in four-dimensions}\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/calabi-yau-data/polytopes-4d."},
	{"name":"ChatML-Capybara","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-Capybara","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"LDJnr/Capybara in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"LDJnr/Capybara\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = []\\n    conversationColumn = columns[\\\"conversation\\\"]\\n\\n    for i in range(len(conversationColumn)):\\n        messages.append({\\n            \\\"role\\\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-Capybara."},
	{"name":"MetaMathQA","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sharathhebbar24/MetaMathQA","creator_name":"Sharath S Hebbar","creator_url":"https://huggingface.co/Sharathhebbar24","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMeta Math Filtered\\n\\t\\n\\nThis is a combined and filtered (removed all the redundant rows) version of meta-math/MetaMathQA and meta-math/MetaMathQA-40K\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"Sharathhebbar24/MetaMathQA\\\", split=\\\"train\\\")\\n\\n"},
	{"name":"muInstruct","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EleutherAI/muInstruct","creator_name":"EleutherAI","creator_url":"https://huggingface.co/EleutherAI","description":"ŒºInstruct is a dataset of 1600 instruction-response pairs collected from highly-rated Stack Exchange answers, the Khan Academy subset of AMPS, and the MATH training set. All training examples are valid Markdown have been manually reviewed by a human for quality. \\nThe ŒºInstruct dataset is most useful when mixed in with larger instruction or chat datasets, such as OpenHermes. Because ŒºInstruct is especially high-quality, you may consider oversampling it in your training mixture. \\nŒºInstruct was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EleutherAI/muInstruct."},
	{"name":"Knowledge_Pile","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Query-of-CC/Knowledge_Pile","creator_name":"Query-of-CC","creator_url":"https://huggingface.co/Query-of-CC","description":"Knowledge Pile is a knowledge-related data leveraging Query of CC.\\nThis dataset is a partial of Knowledge Pile(about 40GB disk size), full datasets have been released in [ü§ó knowledge_pile_full], a total of 735GB disk size and 188B tokens (using Llama2 tokenizer).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuery of CC\\n\\t\\n\\nJust like the figure below, we initially collected seed information in some specific domains, such as keywords, frequently asked questions, and textbooks, to serve as inputs for the Query Bootstrapping‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Query-of-CC/Knowledge_Pile."},
	{"name":"hercules-v2.0","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/hercules-v2.0","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Hercules-v2.0\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nDataset Name: Hercules-v2.0\\nVersion: 2.0\\nDate of Release: February 2, 2024\\nSize: 1,307,174\\nData Sources: \\nHercules-v2.0 is an enriched instruction dataset derived from OpenHermes-2.5, aimed at enhancing its diversity and scope. The dataset amalgamates contributions from various data sources, with a strong emphasis on Biology, Physics, Medicine, Math, Computer Science, Instruction Following, Function Calling, and Roleplay. The data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/hercules-v2.0."},
	{"name":"Math-Multiturn-1K-ShareGPT","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PJMixers/Math-Multiturn-1K-ShareGPT","creator_name":"Peanut Jar Mixers","creator_url":"https://huggingface.co/PJMixers","description":"All samples were created with this script, no GPT, just python.\\n"},
	{"name":"Math-Multiturn-100K-ShareGPT","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PJMixers/Math-Multiturn-100K-ShareGPT","creator_name":"Peanut Jar Mixers","creator_url":"https://huggingface.co/PJMixers","description":"All samples were created with this script, no GPT, just python.\\n"},
	{"name":"Math-Multiturn-10K-ShareGPT","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PJMixers/Math-Multiturn-10K-ShareGPT","creator_name":"Peanut Jar Mixers","creator_url":"https://huggingface.co/PJMixers","description":"All samples were created with this script, no GPT, just python.\\n"},
	{"name":"Open-Platypus","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sharathhebbar24/Open-Platypus","creator_name":"Sharath S Hebbar","creator_url":"https://huggingface.co/Sharathhebbar24","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen Platypus Code\\n\\t\\n\\nThis is a cleansed version of garage-bAInd/Open-Platypus\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"Sharathhebbar24/Open-Platypus\\\", split=\\\"train\\\")\\n\\n"},
	{"name":"ZharfaTech-Open-Platypus-Persian-Farsi","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZharfaTech/ZharfaTech-Open-Platypus-Persian-Farsi","creator_name":"ZharfaTech","creator_url":"https://huggingface.co/ZharfaTech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPersian Open-Platypus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout ZharfaTech\\n\\t\\n\\nZharfaTech is a pioneer in developing Language Learning Models (LLMs) tailored for the Persian language, aiming to empower over 100 million Persian speakers worldwide. Our mission encompasses bridging the digital divide in LLM-related services like content generation, customer relationship systems, and more, with a dual approach of fostering open-source collaboration and delivering high-value, specialized closed-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZharfaTech/ZharfaTech-Open-Platypus-Persian-Farsi."},
	{"name":"math_LinearAlgebra_ner","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hengzongshu/math_LinearAlgebra_ner","creator_name":"Xiaziye","creator_url":"https://huggingface.co/Hengzongshu","description":"ËøôÊòØ‰∏Ä‰∏™Âü∫‰∫éÁª¥Âü∫ÁôæÁßëÂà∂‰ΩúÁöÑËΩªÈáèËÆ≠ÁªÉÈõÜÔºå‰∏ªË¶ÅÁî®‰∫éÊï∞Â≠¶Á∫øÊÄß‰ª£Êï∞È¢ÜÂüüÁöÑËã±ËØ≠ÂëΩÂêçÂÆû‰ΩìËØÜÂà´Ôºå‰ª•ÂèäÁü•ËØÜÂõæË∞±ÊûÑÂª∫„ÄÇ\\nÊ†πÊçÆÁª¥Âü∫ÁôæÁßëËØçÊù°ÂØπÈìæÊé•ËøõË°å‰∏≤ËÅîÈÄâÂèñÔºåÂÖ±Êúâ234Âè•ÔºåÊó†Ê†áÁÇπÁ¨¶Âè∑„ÄÅÊï∞Â≠óÔºå‰∏çÂå∫ÂàÜÂ≠óÊØçÂ§ßÂ∞èÂÜô„ÄÇ\\nÊ†áÁ≠æÊ†áÊ≥®‰ΩøÁî®DoccanoÔºåÊúâjsonlÔºådataset‰∏étxtÁâàÊú¨„ÄÇÔºàjsonlÂèØËΩ¨Êç¢‰∏∫jsonÔºâ\\nThis is a lightweight training dataset created based on Wikipedia, primarily used for English Named Entity Recognition (NER) in the field of mathematics linear algebra, as well as knowledge graph construction. \\nLink selections were made based on Wikipedia entries, resulting in 234 sentences. The sentences contain no punctuation, numbers, and are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hengzongshu/math_LinearAlgebra_ner."},
	{"name":"YarraEsrever","keyword":"math","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewiswatson/YarraEsrever","creator_name":"Lewis","creator_url":"https://huggingface.co/lewiswatson","description":"Introducing YarraEsrever: The Ultimate Integer Array Reversal Dataset for Cutting-Edge AI Research\\nPrepare to revolutionise your machine learning workflows with YarraEsrever, a groundbreaking dataset that pushes the boundaries of integer array reversal. This state-of-the-art collection boasts an impressive 1,000,000 unique supervised training pairs, meticulously curated to empower researchers and data scientists in their quest to master the art of reversing integer arrays.\\nDon't waste your‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewiswatson/YarraEsrever."},
	{"name":"MMOS","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cyzhh/MMOS","creator_name":"Yezeng Chen","creator_url":"https://huggingface.co/cyzhh","description":"ArXiv | Models | Data | Code | \\nYou can download the dataset as follows\\nfrom datasets import load_dataset\\nds = load_dataset(\\\"cyzhh/MMOS\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema\\n\\t\\n\\nEach dataset row has the following structure\\n{\\n  \\\"idx\\\": ..., # problem id\\n  \\\"prompt\\\": ..., # problem \\n  \\\"completion\\\": ... # reasoning path with python\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nWe do not alter the license of any of the underlying data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nFor the MMOS, cite \\n@misc{chen2024empirical,\\n      title={An Empirical Study‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyzhh/MMOS."},
	{"name":"math-orca-arch","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pharaouk/math-orca-arch","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\n\\nThis dataset contains ~200K grade school math word problems. All the answers in this dataset is generated using Azure GPT4-Turbo. Please refer to Orca-Math: Unlocking the potential of\\nSLMs in Grade School Math for details about the dataset construction. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\n\\n\\nRepository: microsoft/orca-math-word-problems-200k\\nPaper: Orca-Math: Unlocking the potential of\\nSLMs in Grade School Math\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDirect Use\\n\\t\\n\\n\\n\\nThis dataset has been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/math-orca-arch."},
	{"name":"distilabel-capybara-kto-15k-binarized","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla/distilabel-capybara-kto-15k-binarized","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCapybara-KTO 15K binarized\\n\\t\\n\\n\\nA KTO signal transformed version of the highly loved Capybara-DPO 7K binarized, A DPO dataset built with distilabel atop the awesome LDJnr/Capybara\\n\\n\\nThis is a preview version to collect feedback from the community. v2 will include the full base dataset and responses from more powerful models.\\n\\n\\n    \\n\\n\\n\\n  \\n    \\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy KTO?\\n\\t\\n\\nThe KTO paper states:\\n\\nKTO matches or exceeds DPO performance at scales from 1B to 30B parameters.1 That is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/argilla/distilabel-capybara-kto-15k-binarized."},
	{"name":"orca-math-word-problems-200k","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/agicorp/orca-math-word-problems-200k","creator_name":"agicorp","creator_url":"https://huggingface.co/agicorp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\n\\nThis dataset contains ~200K grade school math word problems. All the answers in this dataset is generated using Azure GPT4-Turbo. Please refer to Orca-Math: Unlocking the potential of\\nSLMs in Grade School Math for details about the dataset construction. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\n\\n\\nRepository: microsoft/orca-math-word-problems-200k\\nPaper: Orca-Math: Unlocking the potential of\\nSLMs in Grade School Math\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDirect Use\\n\\t\\n\\n\\n\\nThis dataset has been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agicorp/orca-math-word-problems-200k."},
	{"name":"MetaMathQA","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/agicorp/MetaMathQA","creator_name":"agicorp","creator_url":"https://huggingface.co/agicorp","description":"View the project page:\\nhttps://meta-math.github.io/\\nsee our paper at https://arxiv.org/abs/2309.12284\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\nAll MetaMathQA data are augmented from the training sets of GSM8K and MATH. \\nNone of the augmented data is from the testing set.\\nYou can check the original_question in meta-math/MetaMathQA, each item is from the GSM8K or MATH train set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Details\\n\\t\\n\\nMetaMath-Mistral-7B is fully fine-tuned on the MetaMathQA datasets and based on the powerful Mistral-7B model.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agicorp/MetaMathQA."},
	{"name":"MathInstruct","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/agicorp/MathInstruct","creator_name":"agicorp","creator_url":"https://huggingface.co/agicorp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü¶£ MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning\\n\\t\\n\\nMathInstruct is a meticulously curated instruction tuning dataset that is lightweight yet generalizable. MathInstruct is compiled from 13 math rationale datasets, six of which are newly curated by this work. It uniquely focuses on the hybrid use of chain-of-thought (CoT) and program-of-thought (PoT) rationales, and ensures extensive coverage of diverse mathematical fields. \\nProject Page:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agicorp/MathInstruct."},
	{"name":"basic-math-10m","keyword":"math","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrfakename/basic-math-10m","creator_name":"mrfakename","creator_url":"https://huggingface.co/mrfakename","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBasic Math 10M\\n\\t\\n\\nA dataset of 10 million basic arithmetic problems with potential user prompts. It is an extended version of Basic Math 1M.\\nBasic Math 10M was inspired by Simple Math.\\n"},
	{"name":"OpenCerebrum-SFT","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/OpenCerebrum-SFT","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenCerebrum SFT subset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nOpenCerebrum is my take on creating an open source version of Aether Research's proprietary Cerebrum dataset. This repository contains the SFT subset, which contains about 1,200,00 examples. Unfortunately, I was unsure about how I would compress this dataset to just 5,000 examples like in the original Cerebrum dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration\\n\\t\\n\\nThis dataset was curated using a simple and logical rationale. The goal was to use‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/OpenCerebrum-SFT."},
	{"name":"grad_school_math_instructions_fr_Mixtral","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIffl/grad_school_math_instructions_fr_Mixtral","creator_name":"AIffl : AI For French Language","creator_url":"https://huggingface.co/AIffl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for grad_school_math_instructions_fr_Mixtral\\n\\t\\n\\nThis dataset was made thanks to the instruction of the vigogne's dataset but the output were generated with Mixtral-8x7B-Instruct instead of GPT3.5 to make it open-source.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card Contact\\n\\t\\n\\nrobinjo\\n"},
	{"name":"orca-math-portuguese-64k","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rhaymison/orca-math-portuguese-64k","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","description":"translated for:\\n\\n\\nRepository: microsoft/orca-math-word-problems-200k\\nPaper: Orca-Math: Unlocking the potential of\\nSLMs in Grade School Math\\n\\n"},
	{"name":"ReAlign-GSM8K","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GAIR/ReAlign-GSM8K","creator_name":"SII - GAIR","creator_url":"https://huggingface.co/GAIR","description":"Please refer to our GitHub repo for more details.\\n"},
	{"name":"MathCodeInstruct","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MathLLMs/MathCodeInstruct","creator_name":"LLMs for Math Reasoning","creator_url":"https://huggingface.co/MathLLMs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning\\n\\t\\n\\nPaper: https://arxiv.org/pdf/2310.03731.pdf\\nRepo: https://github.com/mathllm/MathCoder\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce MathCoder, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving.\\n\\n\\t\\n\\t\\t\\nBase Model: Llama-2\\nBase Model: Code Llama\\n\\n\\n\\t\\t\\nMathCoder-L-7B\\nMathCoder-CL-7B\\n\\n\\nMathCoder-L-13B\\nMathCoder-CL-34B\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTraining Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathCodeInstruct."},
	{"name":"DiagGSM8K","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pharaouk/DiagGSM8K","creator_name":"Farouk","creator_url":"https://huggingface.co/pharaouk","description":"View the project page:\\nhttps://github.com/dvlab-research/DiagGSM8K\\nsee our paper at https://arxiv.org/abs/2312.17080\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nIn this work, we introduce a novel evaluation paradigm for Large Language Models, \\none that challenges them to engage in meta-reasoning. Our paradigm shifts the focus from result-oriented assessments, \\nwhich often overlook the reasoning process, to a more holistic evaluation that effectively differentiates \\nthe cognitive capabilities among models. For‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pharaouk/DiagGSM8K."},
	{"name":"OpenCerebrum-2.0-SFT","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/OpenCerebrum-2.0-SFT","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenCerebrum SFT subset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nOpenCerebrum is my take on creating an open source version of Aether Research's proprietary Cerebrum dataset. This repository contains the SFT subset, which contains about 6,400 examples. To compress this dataset to such a small size, I used an in-house curation technique at Cognitive Computations. More information about this technique will come in the future. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration\\n\\t\\n\\nAs mentioned earlier, I used an in-house‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/OpenCerebrum-2.0-SFT."},
	{"name":"OpenCerebrum-2.0-DPO","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/OpenCerebrum-2.0-DPO","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenCerebrum DPO subset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nOpenCerebrum is my take on creating an open source version of Aether Research's proprietary Cerebrum dataset. This repository contains the DPO subset, which contains about 720 examples. To compress this dataset to such a small size, I used an in-house curation technique at Cognitive Computations. More information about this technique will come in the future. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration\\n\\t\\n\\nAs mentioned earlier, I used an in-house‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/OpenCerebrum-2.0-DPO."},
	{"name":"MetaMathQA-ShareGPT","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pbatra/MetaMathQA-ShareGPT","creator_name":"Piyush Batra","creator_url":"https://huggingface.co/pbatra","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMetaMathQA-ShareGPT\\n\\t\\n\\nThis repository contains the ShareGPT format version of the MetaMathQA dataset. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe MetaMathQA-ShareGPT dataset is a transformed version of the MetaMathQA dataset, which has been reformatted to fit the ShareGPT conversation format. Each entry in the dataset consists of a series of user-assistant interactions, making it suitable for training and evaluating conversational models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFormat\\n\\t\\n\\nEach entry in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pbatra/MetaMathQA-ShareGPT."},
	{"name":"alpaca_jp_math","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/alpaca_jp_math","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\talpaca_jp_math\\n\\t\\n\\n\\nalpaca_jp_math„ÅØ„ÄÅ  \\n\\nStanford Alpaca„ÅÆÊâãÊ≥ï  \\nmistralai/Mixtral-8x22B-Instruct-v0.1\\n\\n„Åß‰Ωú„Å£„ÅüÂêàÊàê„Éá„Éº„Çø(Synthetic data)„Åß„Åô„ÄÇ„É¢„Éá„É´„ÅÆÂà©Áî®„Å´„ÅØDeepinfra„ÇíÂà©Áî®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ  \\n„Åæ„Åü„ÄÅ\\\"_cleaned\\\"„Åå„Å§„ÅÑ„Åü„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØ‰ª•‰∏ã„ÅÆÊâãÊ≥ï„ÅßÁ≤æÊüª„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ  \\n\\npython„ÅÆË®àÁÆóÁµêÊûú„Åå„Åç„Å°„Çì„Å®„ÄÅ„ÉÜ„Ç≠„Çπ„Éà„ÅÆË®àÁÆóÁµêÊûú„ÅåÂêåÁ≠â„Åß„ÅÇ„Çã„ÅãÁ¢∫Ë™ç\\nLLM(mistralai/Mixtral-8x22B-Instruct-v0.1)„Å´„Çà„ÇãÁ¢∫Ë™çÔºàË©≥Á¥∞„ÅØ‰∏ãË®òÔºâ\\n\\ncode_result, text_result„ÅØÂ∞èÊï∞Á¨¨‰∏â‰Ωç„ÅßÂõõÊç®‰∫îÂÖ•„Åó„Å¶„ÅÇ„Çä„Åæ„Åô„ÄÇ\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\nCurated by: HachiML\\nLanguage(s) (NLP): Japanese\\nLicense: Apache 2.0\\nGithub:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HachiML/alpaca_jp_math."},
	{"name":"math-instruct-dataset","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/patrickjmcbride/math-instruct-dataset","creator_name":"Patrick McBride","creator_url":"https://huggingface.co/patrickjmcbride","description":"This is a reformatted version of Feynman Innovations' Maths-College dataset. \\nFull credit to Feynman Innovations for the dataset.\\nIt is just formatted to be ready for fine-tuning an instruct model \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields are as follows:\\ninstruction: describes the task that the model needs to perform. (all instructions are the same \\\"Write an educational piece related to the following text snippet:\\\")\\ncontext:     additional context containing the math concept to explain‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/patrickjmcbride/math-instruct-dataset."},
	{"name":"math-instruct-binned","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/patrickjmcbride/math-instruct-binned","creator_name":"Patrick McBride","creator_url":"https://huggingface.co/patrickjmcbride","description":"This is a pre-binned instruction formatted version of Feynman Innovations' Maths-College dataset. \\nCredit to Feynman Innovations for the base dataset.\\nIt is formatted to be ready for fine-tuning an instruct model. \\nThe splits are based on the size of the full instruction ('text') after being tokenized with the Llama-3-8B-Instruct tokenizer (based on tiktoken).\\nA non-split version is avalible as math-instruct-dataset\\nBinned by length of tokenized 'text' field\\n\\nsmall:  [min-1024)\\nmedium:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/patrickjmcbride/math-instruct-binned."},
	{"name":"stem_mcqa_questions","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mvujas/stem_mcqa_questions","creator_name":"Milos Vujasinovic","creator_url":"https://huggingface.co/mvujas","description":"This is a dataset of questions in various stem field generated using GPT-4o. The fields contain math, physics, chemistry, biology, computer_science and technical_sciences with around 400 samples in each.\\n"},
	{"name":"MM_Math","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/THU-KEG/MM_Math","creator_name":"Knowledge Engineer Group @ Tsinghua University","creator_url":"https://huggingface.co/THU-KEG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMM_Math Datasets\\n\\t\\n\\nWe introduce our multimodal mathematics dataset, MM-MATH,. \\nThis dataset is collected from real middle school exams in China, and all the math problems are open-ended to evaluate the mathematical problem-solving abilities of current multimodal models. MM-MATH is annotated with fine-grained three-dimensional labels: difficulty, grade, and knowledge points. The difficulty level is determined based on the average scores of student exams, the grade labels are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/THU-KEG/MM_Math."},
	{"name":"Maths-College-ko","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/Maths-College-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"Translated 5% ajibawa-2023/Maths-College using nayohan/llama3-instrucTrans-enko-8b.\\n"},
	{"name":"Multilingual-Benchmark","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \\nBibTex\\n@misc{lu2024languagecountslearnunlearn,\\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \\n      author={Taiming Lu and Philipp Koehn},\\n      year={2024},\\n      eprint={2406.13748},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2406.13748}, \\n}\\n\\n"},
	{"name":"gsm8k_multiturn","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/euclaise/gsm8k_multiturn","creator_name":"Jade","creator_url":"https://huggingface.co/euclaise","description":"The \\\"socratic\\\" version of GSM8K has the model reflect and ask itself sub-questions about the initial question, before coming to a final answer.\\nThis dataset reformats the socratic GSM8K version into a multi-turn conversation, where the sub-questions are asked by the user rather than being self-asked by the model.\\n"},
	{"name":"TigerMath-Evaluated","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/thesven/TigerMath-Evaluated","creator_name":"Michael Svendsen","creator_url":"https://huggingface.co/thesven","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTigerMath Evaluated\\n\\t\\n\\nTigerMath-Evaluated is a dataset comprising 101,000 rows of grade 4-5 ranked responses sourced from the TIGER-Lab/MathInstruct dataset.\\nThe responses were graded using Prometheus V2 with a GPTQ 4-bit quantized version of the V2 7B model.\\nThis dataset aims to support research and development in educational AI and automated grading systems.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nsource: The original source where the data was gathered by Tiger Lab\\nresponse: The original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thesven/TigerMath-Evaluated."},
	{"name":"PLoRA_datasets","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xiaochen233/PLoRA_datasets","creator_name":"wxc","creator_url":"https://huggingface.co/xiaochen233","description":"View the project page:\\nhttps://meta-math.github.io/\\nsee our paper at https://arxiv.org/abs/2309.12284\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\nAll MetaMathQA data are augmented from the training sets of GSM8K and MATH. \\nNone of the augmented data is from the testing set.\\nYou can check the original_question in meta-math/MetaMathQA, each item is from the GSM8K or MATH train set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Details\\n\\t\\n\\nMetaMath-Mistral-7B is fully fine-tuned on the MetaMathQA datasets and based on the powerful Mistral-7B model.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xiaochen233/PLoRA_datasets."},
	{"name":"Kapibara","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alban-labs/Kapibara","creator_name":"Albanian Labs","creator_url":"https://huggingface.co/alban-labs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKapibara: Albanian Multi-turn Conversation Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKapibara is a comprehensive Albanian language dataset designed for multi-turn conversations. It contains over 5,300 entries covering a wide range of topics including physics, biology, mathematics, chemistry, culture, and logic. The dataset is aimed at improving text generation and question-answering capabilities in the Albanian language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\nThe dataset supports the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alban-labs/Kapibara."},
	{"name":"math-expressions-1m","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Gusarich/math-expressions-1m","creator_name":"Daniil Sedov","creator_url":"https://huggingface.co/Gusarich","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMath Expressions 1M\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is a comprehensive collection of 1,000,000 mathematical expressions, including both valid and invalid expressions. This dataset is intended for use in various machine learning and natural language processing tasks, such as calculations, mathematical reasoning, and validation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset consists of mathematical expressions generated using a combination of basic arithmetic operations and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gusarich/math-expressions-1m."},
	{"name":"Polytope","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sequelbox/Polytope","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","description":"Polytope is a dataset containing math-instruct data.\\nThe 2024-08-15 version contains:\\n\\n42.3k rows of synthetic math-instruct data, using randomly selected, permissively licensed CoT prompts from TIGER-Lab/MathInstruct and responses generated using Llama 3.1 405b Instruct.\\n\\nThis dataset contains synthetically generated data and has not been subject to manual review.\\n"},
	{"name":"NuminaMath-CoT-Small-215k","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NotASI/NuminaMath-CoT-Small-215k","creator_name":"Liu Hong Yuan Tom","creator_url":"https://huggingface.co/NotASI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis dataset is a scaled down version of the original AI-MO/NuminaMath-CoT dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource breakdown\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nSource\\nNumber of Originial Samples\\nNumber of Samples in This Dataset\\n\\n\\n\\t\\t\\naops_forum\\n30201\\n7548\\n\\n\\namc_aime\\n4072\\n1017\\n\\n\\ncn_k12\\n276591\\n69138\\n\\n\\ngsm8k\\n7345\\n1835\\n\\n\\nmath\\n7478\\n1869\\n\\n\\nolympiads\\n150581\\n37640\\n\\n\\norca_math\\n153334\\n38328\\n\\n\\nsynthetic_amc\\n62111\\n15527\\n\\n\\nsynthetic_math\\n167895\\n41968\\n\\n\\nTotal\\n859608\\n214870\\n\\n\\n\\t\\n\\n"},
	{"name":"NuminaMath-CoT-Small-Hard-200k","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NotASI/NuminaMath-CoT-Small-Hard-200k","creator_name":"Liu Hong Yuan Tom","creator_url":"https://huggingface.co/NotASI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis dataset is a scaled down version of the original AI-MO/NuminaMath-CoT dataset with more focus on hard math.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource breakdown\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nSource\\nNumber of Originial Samples\\nNumber of Samples in This Dataset\\n\\n\\n\\t\\t\\naops_forum\\n30201\\n5000\\n\\n\\namc_aime\\n4072\\n4070\\n\\n\\ncn_k12\\n276591\\n55310\\n\\n\\ngsm8k\\n7345\\n1000\\n\\n\\nmath\\n7478\\n1000\\n\\n\\nolympiads\\n150581\\n37640\\n\\n\\norca_math\\n153334\\n30662\\n\\n\\nsynthetic_amc\\n62111\\n31054\\n\\n\\nsynthetic_math\\n167895\\n33574\\n\\n\\nTotal\\n859608\\n199310\\n\\n\\n\\t\\n\\n"},
	{"name":"CleverBoi","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/CleverBoi","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCleverBoi\\n\\t\\n\\nThe CleverBoi Collection is based on a number of data sets that emphasize logic, inference, empathy, math and coding.\\nThe data set has been formatted to follow the alpaca format (instruction + input -> output) when fine tuning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Sets\\n\\t\\n\\nThe source data sets used in the CleverBoi Collection are listed below, ordered by size.\\n\\nKK04/LogicInference_OA\\nmlabonne/Evol-Instruct-Python-26k\\ngarage-bAInd/Open-Platypus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/theprint/CleverBoi."},
	{"name":"ko-math","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kikikara/ko-math","creator_name":"kimjeasung","creator_url":"https://huggingface.co/kikikara","description":"hendrycks/math datasetÏùÑ ÌïúÍµ≠Ïñ¥Î°ú Î≤àÏó≠Ìïú dataset ÏûÖÎãàÎã§.\\n"},
	{"name":"Arabic_LLaMA_Math_Dataset","keyword":"math","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jr23xd23/Arabic_LLaMA_Math_Dataset","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic LLaMA Math Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample Entries\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\nDataset Name: Arabic_LLaMA_Math_Dataset.csv\\nNumber of Records: 12,496\\nNumber of Columns: 3\\nFile Format: CSV\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns:\\n\\t\\n\\n\\nInstruction: The problem statement or question (text, in Arabic)\\nInput: Additional input for model fine-tuning (empty in this dataset)\\nSolution: The solution or answer to the problem (text, in Arabic)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/Arabic_LLaMA_Math_Dataset."},
	{"name":"bd-bcs-multimodal","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/azminetoushikwasi/bd-bcs-multimodal","creator_name":"Azmine Toushik Wasi","creator_url":"https://huggingface.co/azminetoushikwasi","description":"azminetoushikwasi/bd-bcs-multimodal dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"EpicPRM","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SunW7777/EpicPRM","creator_name":"Sun","creator_url":"https://huggingface.co/SunW7777","description":"\\n\\t\\n\\t\\t\\n\\t\\tAn Efficient and Precise Training Data Construction Framework for Process-supervised Reward Model in Mathematical Reasoning\\n\\t\\n\\nWe propose a framework EpicPRM which improvements to existing automatic annotating methods. \\nOur framework refines the method for evaluating the correctness of intermediate reasoning steps, effectively reducing the prevalence of false positive and false negative labels. \\nAdditionally, we optimize the algorithm for identifying the first erroneous step by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SunW7777/EpicPRM."},
	{"name":"Math_small_corpus","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lap1official/Math_small_corpus","creator_name":"Lap","creator_url":"https://huggingface.co/Lap1official","description":"Lap1official/Math_small_corpus dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"NuminaMath-CoT-decontaminated-filtered","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/flatlander1024/NuminaMath-CoT-decontaminated-filtered","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Decontaminated version of AI-MO/NuminaMath-CoT/train that remove the collided data from math/test, gsm8k/test, olympiadbench/test, minerva_math/test, college_math/test, mmlu_stem/test, gaokao, amc23, aime24 and math500.\\nAligned with flatlander1024/QwQ-LongCoT-130K-decontaminated NuminaMath\\nTotal number of rows: 102238\\n"},
	{"name":"QwQ-LongCoT-decontaminated-filtered","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/flatlander1024/QwQ-LongCoT-decontaminated-filtered","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Decontaminated version of gghfez/QwQ-LongCoT-130K-cleaned that remove the collided data from math/test, gsm8k/test, olympiadbench/test, minerva_math/test, college_math/test, mmlu_stem/test, gaokao, amc23, aime24 and math500.\\nWith source=='NuminaMath'.\\nTotal number of rows: 88083\\n"},
	{"name":"NuminaMath-longcot-cot-combined","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/flatlander1024/NuminaMath-longcot-cot-combined","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Contains Decontaminated version of AI-MO/NuminaMath-CoT/train and the decontaminated version of gghfez/QwQ-LongCoT-130K-cleaned.\\nRemove duplicates and merged them into 1 data with 2 different solution rows.\\nTotal number of rows: 87057\\n"},
	{"name":"flemish_multimodal_exams_physician","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jjzha/flemish_multimodal_exams_physician","creator_name":"Mike Zhang","creator_url":"https://huggingface.co/jjzha","description":"jjzha/flemish_multimodal_exams_physician dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"subset_math_generated_solutions","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cupalex/subset_math_generated_solutions","creator_name":"Aleksandra","creator_url":"https://huggingface.co/cupalex","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for a Subset of MATH-500 Generated Solutions\\n\\t\\n\\nThis dataset contains model-generated answers and chain-of-thought solutions to a subset of 20 problems from the MATH-500 dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEach item in this dataset includes a problem from the MATH-500 dataset, along with pairs of chain-of-thought solutions and short answers generated using two different strategies:\\n\\nGreedy Chain-of-Thought Decoding\\n\\nWeighted Best-of-N‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cupalex/subset_math_generated_solutions."},
	{"name":"math-500-qwen-2.5-rpm-post-training","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hannayukhymenko/math-500-qwen-2.5-rpm-post-training","creator_name":"Hanna Yukhymenko","creator_url":"https://huggingface.co/hannayukhymenko","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card\\n\\t\\n\\nDataset consists of 20 randomly sampled problems for level 1-3 in MATH-500 dataset dataset and solutions, scored by a reward model.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\nThe dataset is based on MATH-500 dataset. The methods used reproduce the approach from Hugging Face blogpost \\\"Scaling Test Time Compute with Open Models\\\"\\n\\n\\t\\n\\t\\t\\n\\t\\tMethods\\n\\t\\n\\nWe used two methods to generate solutions and answers:\\n\\nGreedy decoding: sampling 1 solution using temperature=0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hannayukhymenko/math-500-qwen-2.5-rpm-post-training."},
	{"name":"AWPCD","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HelloCephalopod/AWPCD","creator_name":"Matthew Waller","creator_url":"https://huggingface.co/HelloCephalopod","description":"\\n\\t\\n\\t\\t\\n\\t\\tArithmetic Word Problem Compendium Dataset (AWPCD)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a comprehensive collection of mathematical word problems spanning multiple domains with rich metadata and natural language variations. The problems contain 1 - 5 steps of mathematical operations that are specifically designed to encourage showing work and maintaining appropriate decimal precision throughout calculations. \\nThe available data is a sample of 1,000 problems, and commerical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HelloCephalopod/AWPCD."},
	{"name":"r103","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zjrwtxtechstudio/r103","creator_name":"zjrwtx","creator_url":"https://huggingface.co/zjrwtxtechstudio","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."},
	{"name":"camel","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Wendong-Fan/camel","creator_name":"Wendong.Fan","creator_url":"https://huggingface.co/Wendong-Fan","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."},
	{"name":"camel_dataset_example_2","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Wendong-Fan/camel_dataset_example_2","creator_name":"Wendong.Fan","creator_url":"https://huggingface.co/Wendong-Fan","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."},
	{"name":"NuminaMath-1.5-Verifiable","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yentinglin/NuminaMath-1.5-Verifiable","creator_name":"Yen-Ting Lin","creator_url":"https://huggingface.co/yentinglin","description":"\\n\\t\\n\\t\\t\\n\\t\\tNuminaMath-1.5-Verifiable\\n\\t\\n\\nA filtered subset of NuminaMath-1.5, retaining only non-synthetic examples with valid answers.\\nFiltering Criteria\\n    ‚Ä¢\\tExcludes synthetic examples.\\n    ‚Ä¢\\tKeeps only entries with non-empty, meaningful answers.\\n    ‚Ä¢\\tRemoves generic placeholders like ‚Äúproof‚Äù and ‚Äúnotfound.‚Äù\\n\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"yentinglin/NuminaMath-1.5-Verifiable\\\")\\n\\n"},
	{"name":"NuminaMath-CoT-cn_k12-20000-old","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tttonyyy/NuminaMath-CoT-cn_k12-20000-old","creator_name":"shaozhen liu","creator_url":"https://huggingface.co/tttonyyy","description":"Êú¨Êï∞ÊçÆÈõÜ‰∏∫NuminaMath-CoTÂú®cn_k12Á±ªÂà´‰∏ãÂâç20000Êù°Êï∞ÊçÆ‰∏≠ËøõË°åÁöÑÈïøCoTÊñáÊú¨ÁîüÊàêÂ∞ùËØï„ÄÇ\\nÈáåÈù¢Êúâ‰∏§‰∏™Êï∞ÊçÆÊñá‰ª∂Ôºåcompletion.jsonlÂíådistilled.jsonl„ÄÇ\\nÂÖ∂‰∏≠Ôºåcompletion.jsonlÊòØgemma2-27b-itÁîüÊàêÁöÑÊï∞ÊçÆÔºåÂõ†‰∏∫gemma2-27b-itÊúÄÂêéÂæóÂà∞ÁöÑÁªìÊûúÂèØËÉΩÊèêÂèñ‰∏çÂá∫\\\\boxed{}ÈáåÈù¢ÁöÑÂÜÖÂÆπÁ≠âÂõ†Á¥†ÔºåÊâÄ‰ª•ÊúÄÂêéÁîüÊàê‰∫ÜÁ∫¶18.6kÁöÑÊï∞ÊçÆ„ÄÇ\\nËÄådistilled.jsonlÊòØÂü∫‰∫é‰∏äÈù¢ÁöÑÂõûÁ≠îÊàêÂäüÁöÑÈóÆÈ¢òÔºå‰ΩøÁî®DeepSeek-R1-Distill-Qwen-32BÁîüÊàêÁöÑÊï∞ÊçÆÔºàÂÖ∂ÂÆû‰∏çÂ∫îËØ•ËøôÊ†∑Ôºå‰πãÂêéÊúâÊú∫‰ºöÂÜç‰ªé20000Êù°ÈáåÈù¢Áõ¥Êé•ÁîüÊàêÔºâ„ÄÇ\\nÂõ†‰∏∫NuminaMath-CoTÁöÑcn_k12Êï∞ÊçÆÂ§ßÂ§öÊòØ‰∏Ä‰∫õÁªºÂêàÂ∫îÁî®È¢òÔºå‰∏ÄÊù°Êï∞ÊçÆ‰∏≠‰ºöÊúâÂ§ö‰∏™Â≠êÈóÆÈ¢òÔºåÂõûÁ≠îÁöÑÊó∂ÂÄô‰πüË¶ÅÂàÜÂà´ÂõûÁ≠î„ÄÇÂØπÈóÆÈ¢òÂõûÁ≠îÁöÑÁ≠îÊ°àËøõË°åÈ™åËØÅËæÉÈöæÔºåÂ∞öÊú™ËøõË°åÁ≠îÊ°àÈ™åËØÅÔºåÈúÄË¶Å‰∏ãËΩΩ‰∏ãÊù•‰πãÂêéÂÜçËøõË°åÊõ¥Á≤æÁªÜÂåñÁöÑÂ§ÑÁêÜ„ÄÇ\\ncompletion.jsonl‰∏≠ÁöÑÊï∞ÊçÆÊ†áÁ≠æÊèèËø∞Ôºö\\n\\nsource (String)ÔºöÊï∞ÊçÆÊù•Ê∫êÁ±ªÂà´Ôºå‰∏∫ÂéüÂßãÊ†áÁ≠æ\\nproblem (String)ÔºöÊï∞Â≠¶ÈóÆÈ¢òÊñáÊú¨Ôºå‰∏∫ÂéüÂßãÊ†áÁ≠æ\\nsolution‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tttonyyy/NuminaMath-CoT-cn_k12-20000-old."},
	{"name":"NMC-cn_k12-20k-r1_32b_distilled","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tttonyyy/NMC-cn_k12-20k-r1_32b_distilled","creator_name":"shaozhen liu","creator_url":"https://huggingface.co/tttonyyy","description":"Êú¨Êï∞ÊçÆÈõÜÊï∞ÊçÆÊù•Ê∫ê‰∏∫NuminaMath-CoTÊï∞ÊçÆÈõÜÁöÑcn_k12Êï∞ÊçÆ„ÄÇÊàë‰ª¨‰ªéËøôÈáåÈù¢ÊèêÂèñ‰∫Ü20000Êù°ÈóÆÈ¢òÔºåÂπ∂‰ΩøÁî®DeepSeek-R1-Distill-Qwen-32BÊ®°ÂûãËøõË°å‰∫ÜÂõûÁ≠î„ÄÇ\\ndistilled_s0_e20000.jsonlÂåÖÂê´Ëøô‰∏™Êï∞ÊçÆÈõÜÁöÑÊï∞ÊçÆÔºå‰∏ãÈù¢‰ªãÁªçÊï∞ÊçÆÊ†áÁ≠æÔºö\\n\\nidxÔºöÁ¥¢ÂºïÂè∑Ôºà0~19999Ôºâ\\nquestionÔºöÂéüÊï∞ÊçÆÈõÜ‰∏≠ÁöÑproblemÊ†áÁ≠æÔºåÊòØ‰∏Ä‰∏™ÂèØËÉΩÂåÖÂê´Â§ö‰∏™Â≠êÈóÆÈ¢òÁöÑÊï∞Â≠¶ÈóÆÈ¢òÂ≠óÁ¨¶‰∏≤\\ngt_cotÔºöÊÑøÊï∞ÊçÆÈõÜ‰∏≠ÁöÑsolutionÊ†áÁ≠æÔºåÊòØÁªèËøáGPT-4oÊï¥ÁêÜÁöÑÁ≠îÊ°àÂ≠óÁ¨¶‰∏≤\\npred_cotÔºöÊ†πÊçÆquestionÊ†áÁ≠æÔºåÊ®°ÂûãDeepSeek-R1-Distill-Qwen-32BÁöÑÂõûÁ≠îÂ≠óÁ¨¶‰∏≤\\npred_cot_token_lenÔºöpred_cotÊ†áÁ≠æ‰∏ãÁöÑÂ≠óÁ¨¶‰∏≤ËΩ¨ÂåñÊàêtoken‰πãÂêéÁöÑÈïøÂ∫¶Ôºà‰∏çÂåÖÂê´ÊúÄÂâçÈù¢ÁöÑ<think>\\\\nÈÉ®ÂàÜÔºåËøô‰∏™Âú®ÁîüÊàêÁöÑÊó∂ÂÄôÊòØÂú®promptÈáåÈù¢ÔºåÊàëÂêéÊù•Âä†Âà∞ËøôÈáå‰∫ÜÔºâ\\nmessageÔºöÊ†πÊçÆquestionÊ†áÁ≠æÂíåpred_cotÊ†áÁ≠æÔºåÊûÑÈÄ†ÁöÑÈóÆÈ¢ò-ÂõûÁ≠îÊï∞ÊçÆÂØπ\\n\\nÁªüËÆ°‰∫Ü‰∏Ä‰∏ãÂπ≥ÂùáÂõûÁ≠îtokenÈïøÂ∫¶Ôºå‰∏∫3169.4251\\n"},
	{"name":"OpenR1-Math-220k-paired","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIR-hl/OpenR1-Math-220k-paired","creator_name":"Hsu Shihyueh","creator_url":"https://huggingface.co/AIR-hl","description":"\\n\\t\\n\\t\\t\\n\\t\\t!!! Is there anyone can help me? https://github.com/huggingface/trl/issues/2994\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset is built by filtering the open-r1/OpenR1-Math-220k dataset according to the following rules:\\n\\nFirst, filter all of rows with only correct answers\\nThe chosen contains the shortest and correct generation, the rejected contains the wrong generation.\\nAll data with a prompt+chosen length exceeding 16k are filtered out.\\nWe provide the length for both chosen and rejected‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AIR-hl/OpenR1-Math-220k-paired."},
	{"name":"CNTXTAI-Ranking-Dataset","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CNTXTAI0/CNTXTAI-Ranking-Dataset","creator_name":"CNTXT AI","creator_url":"https://huggingface.co/CNTXTAI0","description":"General Overview\\nThis dataset is to be used for LLM Trainings, This is a sample, visit https://www.cntxt.tech/ to learn more\\nThe dataset consists of 50 rows (excluding headers) and 8 columns. The columns capture various aspects of ranked responses to prompts, including:\\nNumeric_ID (Unique Identifier - Integer)\\nPrompt (The Question or Task - Text)\\nAnswer_A / Answer_B (Response Options - Text)\\nCategory (Type of Task - Categorical)\\nBest Answer (Preferred Response - Categorical)\\nLikeRT Score‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CNTXTAI0/CNTXTAI-Ranking-Dataset."},
	{"name":"dutch-central-exam-mcq","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jjzha/dutch-central-exam-mcq","creator_name":"Mike Zhang","creator_url":"https://huggingface.co/jjzha","description":"Multiple Choice Questions of the Dutch Central Exam 1999-2024\\n\\nWhat?\\n\\nThis dataset contains only multiple choice questions from the Dutch Central Exam (High School level). From Wikipedia:\\nThe Eindexamen (Dutch pronunciation: [Àà…õiÃØnt…õksam…ôn]) or centraal examen (CE) is the matriculation exam in the Netherlands, which takes place in a student's final year of high school education (voortgezet onderwijs; \\\"continued education\\\"). The exam is regulated by the Dutch Secondary Education Act[1] and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jjzha/dutch-central-exam-mcq."},
	{"name":"MMMU_Pro","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMMU/MMMU_Pro","creator_name":"MMMU","creator_url":"https://huggingface.co/MMMU","description":"\\n\\t\\n\\t\\t\\n\\t\\tMMMU-Pro (A More Robust Multi-discipline Multimodal Understanding Benchmark)\\n\\t\\n\\nüåê Homepage | üèÜ Leaderboard | ü§ó Dataset | ü§ó Paper | üìñ arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüîîNews\\n\\t\\n\\n\\nüõ†Ô∏èüõ†Ô∏è [2025-03-08] Fixed mismatch between inner image labels and shuffled options in Vision and Standard (10 options) settings. (test_Chemistry_5,94,147,216,314,345,354,461,560,570; test_Materials_450; test_Pharmacy_198; validation_Chemistry_12,26,29; validation_Materials_10,28; validation_Psychology_1)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MMMU/MMMU_Pro."},
	{"name":"OpenMath-GSM8K-masked","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VishwamAI/OpenMath-GSM8K-masked","creator_name":"VishwamAI","creator_url":"https://huggingface.co/VishwamAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenMath-GSM8K-masked Dataset\\n\\t\\n\\nThis dataset is a masked version of the GSM8K dataset, designed for training and evaluating generative AI models on math-related reasoning tasks. The masked dataset is provided as part of the VishwamAI initiative to enhance AI's understanding of mathematical problem solving, specifically in text-to-math problems and chain-of-thought reasoning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\nNumber of rows: 7,473\\nFile Size: 6.07 MB (auto-converted Parquet files:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VishwamAI/OpenMath-GSM8K-masked."},
	{"name":"smolThink","keyword":"math","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AILaborant/smolThink","creator_name":"AI Laborant","creator_url":"https://huggingface.co/AILaborant","description":"A small dataset that contains reasoning and complex mathematical problems, along with physics, and a little bit of geometry.\\n"},
	{"name":"smolBasisTolk","keyword":"math","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AILaborant/smolBasisTolk","creator_name":"AI Laborant","creator_url":"https://huggingface.co/AILaborant","description":"Smol but a wide variety of topics dataset for basic AI training.\\n"},
	{"name":"DeepScaler-QwQ_32b","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tttonyyy/DeepScaler-QwQ_32b","creator_name":"shaozhen liu","creator_url":"https://huggingface.co/tttonyyy","description":"Ëøô‰∏™Êï∞ÊçÆÈõÜÊòØÂü∫‰∫éDeepScalerRÊï∞ÊçÆÈõÜÈááÊ†∑20000Êù°Êï∞ÊçÆÔºå‰ΩøÁî®QwQ-32BËøõË°åÂõûÁ≠îËÄåÊî∂ÈõÜÂà∞ÁöÑ„ÄÇ\\nÂú®Ëøô‰∏™Êï∞ÊçÆÈõÜ‰∏≠ÔºåÊñá‰ª∂Êú´Â∞æÊòØ_final.jsonÁöÑÊñá‰ª∂ÊòØÁªèËøáËøáÊª§ÔºåÂè™‰øùÁïô‰∫ÜÂõûÁ≠îÊ≠£Á°ÆÊï∞ÊçÆÁöÑÁâàÊú¨„ÄÇ\\nËÄåÊú´Â∞æÊòØ.jsonlÁöÑÊñá‰ª∂ÊòØÂéüÂßãÊñá‰ª∂ÔºåÈáåÈù¢ÂåÖÂê´‰∫ÜÊâÄÊúâÂõûÁ≠îÊ≠£Á°ÆÂíåÈîôËØØÁöÑÊï∞ÊçÆ„ÄÇ\\nÊï¥‰∏™ÁîüÊàêÁöÑÊ≠£Á°ÆÊÄß‰∏∫Ôºö78.3%\\nÈáçË¶ÅÁöÑÂ±ûÊÄßÊ†áÁ≠æÔºö\\n\\nquestionÔºöÈóÆÈ¢ò\\ngt_cotÔºöÂéüÊú¨Êï∞ÊçÆÈõÜÁöÑÂõûÁ≠î\\ngtÔºöÂéüÊú¨ÁöÑÊï∞Â≠óÁ≠îÊ°à\\npred_cotÔºöÊ®°ÂûãÁöÑÂõûÁ≠î\\npred_cot_token_lenÔºöÊ®°ÂûãÂõûÁ≠îÁöÑtokenÈïøÂ∫¶\\ncorrectÔºöÊ®°ÂûãÂõûÁ≠îÁöÑÊòØÂê¶Ê≠£Á°Æ\\nmessageÔºöÔºàÂ¶ÇÊûúÊúâÔºâË°®Á§∫‰∏Ä‰∏™ÊèêÈóÆÂõûÁ≠îÂØπÔºåÂèØ‰ª•Áõ¥Êé•‰∫§Áªôllama-factoryÂæÆË∞É\\n\\n"},
	{"name":"math_problem_traces_test2","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Wendong-Fan/math_problem_traces_test2","creator_name":"Wendong.Fan","creator_url":"https://huggingface.co/Wendong-Fan","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."},
	{"name":"PyRe-v2","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/PyRe-v2","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"\\n\\t\\n\\t\\t\\n\\t\\tPyRe 2\\n\\t\\n\\nThis data set is a mix of samples from a number of public data sets (sources indidcated in the actual data). The goal with this set was to create a smaller set focused on coding (primarily Python), math, and reasoning.\\n"},
	{"name":"camel_loong_medicine","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zikaixiao1/camel_loong_medicine","creator_name":"zikaixiao","creator_url":"https://huggingface.co/zikaixiao1","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."},
	{"name":"CleverBoi-Data-20k","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/theprint/CleverBoi-Data-20k","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","description":"theprint/CleverBoi-Data-20k dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"enwikimath","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/s-kat0/enwikimath","creator_name":"Shota Kato","creator_url":"https://huggingface.co/s-kat0","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\nThis dataset is created from the English Wikipedia dump file (enwiki-20240901-pages-articles-multistream.xml.bz2), available for download from Wikimedia Dumps. It includes pages containing mathematical content, extracted using the wikimathextractor tool, which is an adaptation of the wikiextractor specifically designed to extract mathematical contents.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nRepository: s-kat0/wikimathextractor\\nData Source: Wikipedia Dumps‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/s-kat0/enwikimath."},
	{"name":"ru_OpenMathInstruct-2","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mizinovmv/ru_OpenMathInstruct-2","creator_name":"maksim","creator_url":"https://huggingface.co/mizinovmv","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenMathInstruct-2\\n\\t\\n\\n–ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π Qwen2.5-32B-Instruct-GPTQ-Int8\\nOpenMathInstruct-2 is a math instruction tuning dataset with 14M problem-solution pairs \\ngenerated using the Llama3.1-405B-Instruct model.\\nThe training set problems of GSM8K\\nand MATH are used for constructing the dataset in the following ways: \\n\\nSolution augmentation: Generating chain-of-thought solutions for training set problems in GSM8K and MATH. \\nProblem-Solution augmentation: Generating new problems‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mizinovmv/ru_OpenMathInstruct-2."},
	{"name":"algebra_misconceptions","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nanote/algebra_misconceptions","creator_name":"Nancy Otero","creator_url":"https://huggingface.co/nanote","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMaE: Math Misconceptions and Errors Dataset\\n\\t\\n\\nThis dataset supports the research described in the paper A Benchmark for Math Misconceptions: Bridging Gaps in Middle School Algebra with AI-Supported Instruction by Nancy Otero, Stefania Druga, and Andrew Lan.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe MaE (Math Misconceptions and Errors) dataset is a collection of 220 diagnostic examples designed by math learning researchers that represent 55 common algebra misconceptions among middle school‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nanote/algebra_misconceptions."},
	{"name":"MATH_LVL5_fr","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/le-leadboard/MATH_LVL5_fr","creator_name":"le-leadboard","creator_url":"https://huggingface.co/le-leadboard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MATH_LVL5_fr\\n\\t\\n\\nle-leadboard/MATH_LVL5_fr fait partie de l'initiative OpenLLM French Leaderboard, proposant une adaptation fran√ßaise des probl√®mes math√©matiques de niveau avanc√© du dataset MATH.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMATH_LVL5_fr est une adaptation fran√ßaise des probl√®mes math√©matiques de niveau 5 (le plus avanc√©) du dataset MATH original. Il comprend des probl√®mes de comp√©tition math√©matique de niveau lyc√©e, format√©s de mani√®re coh√©rente avec LaTeX pour‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/le-leadboard/MATH_LVL5_fr."},
	{"name":"dpo-merged","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CultriX/dpo-merged","creator_name":"CultriX","creator_url":"https://huggingface.co/CultriX","description":"CultriX/dpo-merged dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"dpo-merged-binarized","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CultriX/dpo-merged-binarized","creator_name":"CultriX","creator_url":"https://huggingface.co/CultriX","description":"CultriX/dpo-merged-binarized dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Qu-QA-v2","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ereeeeef3/Qu-QA-v2","creator_name":"ffhs9","creator_url":"https://huggingface.co/Ereeeeef3","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQu QA v2 Dataset\\n\\t\\n\\nQu QA v2 is a large-scale question-answering (QA) dataset designed for training and evaluating machine learning models. It consists of question-answer pairs in English, making it suitable for general-purpose QA tasks, as well as specialized domains like code-related question answering and GSM8k-style problems.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nFeatures:\\n\\ninput: A string representing the question (dtype: string).\\noutput: A string representing the answer (dtype:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ereeeeef3/Qu-QA-v2."},
	{"name":"SWAP","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sxiong/SWAP","creator_name":"Siheng Xiong","creator_url":"https://huggingface.co/sxiong","description":"\\n\\t\\n\\t\\t\\n\\t\\tSWAP: A Synthetic Dataset for Complex Reasoning with Trajectories and Process Supervision\\n\\t\\n\\nThis repository contains the data for the paper Deliberate Reasoning for LLMs as Structure-aware Planning with Accurate World Model.\\nSWAP (Structure-aware Planning) solves complex reasoning by introducing a Generator-Discriminator architecture, and incorporates structural information to guide the reasoning process and provides a soft verification mechanism over the steps.\\nWe generate the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sxiong/SWAP."},
	{"name":"math_problem_traces_test","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Wendong-Fan/math_problem_traces_test","creator_name":"Wendong.Fan","creator_url":"https://huggingface.co/Wendong-Fan","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."},
	{"name":"DeepScale-qwen2.5_7b-multi","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tttonyyy/DeepScale-qwen2.5_7b-multi","creator_name":"shaozhen liu","creator_url":"https://huggingface.co/tttonyyy","description":"‰ΩøÁî®Qwen2.5-7b-InstructÊ®°ÂûãÔºå‰ªéDeepScalerÊï∞ÊçÆÈõÜ‰∏≠ÊäΩÂèñ20000Êù°Êï∞ÊçÆÔºå‰ΩøÁî®Â§öËΩÆÂØπËØùÁöÑÊñπÂºèËé∑ÂæóÊï∞Â≠¶Á≠îÊ°à„ÄÇ\\npromptÊ®°ÊùøÔºö\\n\\n‰ΩøÁî®ÁöÑsystem_promptÊòØLLAMA_MATH_SYSTEM_PROMPT\\nÂ§öËΩÆÂØπËØùÁöÑpromptÊòØITER_GEN_MULTI_TURN_STEP_PROMPTS\\n\\nLLAMA_MATH_SYSTEM_PROMPT = \\\"\\\"\\nSolve the following math problem efficiently and clearly:\\n\\n- For simple problems (2 steps or fewer):\\nProvide a concise solution with minimal explanation.\\n\\n- For complex problems (3 steps or more):\\nUse this step-by-step format:\\n\\n## Step 1: [Concise description]\\n[Brief explanation and calculations]\\n\\n##‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tttonyyy/DeepScale-qwen2.5_7b-multi."},
	{"name":"metamath_ja_950_reka3flash","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kurogane/metamath_ja_950_reka3flash","creator_name":"kurogane himaki","creator_url":"https://huggingface.co/kurogane","description":"\\n\\t\\n\\t\\t\\n\\t\\tmetamath_ja_950_reka3flash\\n\\t\\n\\nmeta-math/MetaMathQA„ÅÆÊúÄÂàù„ÅÆ1000‰ª∂„ÇíRekaAI/reka-flash-3„ÅßÁøªË®≥„Åó„ÅüÂæå„ÄÅ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„ÅåÁ∂≠ÊåÅ„Åï„Çå„Å™„Åã„Å£„Åü„ÇÇ„ÅÆ„ÇíÈô§Âéª„Åó„Åæ„Åó„Åü„ÄÇ\\n„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØ1000‰ª∂„ÅÇ„Çä„Åæ„Åô„Åå„ÄÅÂÆüÈöõ„ÅØ950‰ª∂Á®ãÂ∫¶„Åß„Åô„ÄÇ\\n„Åæ„Åü„ÄÅ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„ÅÆ„Åø„Åß„ÇØ„É™„Éº„Éã„É≥„Ç∞„Åó„Åü„ÅÆ„Åß„ÄÅÂá∫ÂäõËá™‰Ωì„Åå„Åä„Åã„Åó„ÅÑ„ÇÇ„ÅÆ„ÅØÈô§Âéª„Åß„Åç„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ„Åì„ÅÆ„ÅÇ„Åü„Çä„ÅØÂêÑËá™„Åß„ÇØ„É™„Éº„Éã„É≥„Ç∞„ÅóÁõ¥„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\t‰æã\\n\\t\\n\\ninput\\n\\\\n„Ç∞„É¨„Ç§„Ç∑„Éº„Å®„Ç∏„Éß„Éº„ÅØË§áÁ¥†Âπ≥Èù¢‰∏ä„ÅßÊï∞„ÇíÈÅ∏„Çì„Åß„ÅÑ„Åæ„Åô„ÄÇ„Ç∏„Éß„Éº„ÅØÁÇπ $1+2i$ „ÇíÈÅ∏„Å≥„ÄÅ„Ç∞„É¨„Ç§„Ç∑„Éº„ÅØ $-1+i$ „ÇíÈÅ∏„Å≥„Åæ„Åó„Åü„ÄÇ‰∫å‰∫∫„ÅÆÁÇπÈñì„ÅÆË∑ùÈõ¢„ÅØ„Å©„Çå„Åè„Çâ„ÅÑ„Åß„Åô„ÅãÔºü\\\\n\\\\n\\n\\noutput\\n\\\\nË§áÁ¥†Âπ≥Èù¢‰∏ä„ÅÆÁÇπ $(x_1,y_1)$ „Å® $(x_2,y_2)$ „ÅÆË∑ùÈõ¢„ÅØ„ÄÅÂºè $\\\\\\\\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}$ „ÅßÊ±Ç„ÇÅ„Çâ„Çå„Åæ„Åô„ÄÇ  \\\\n„Åì„ÅÆÂ†¥Âêà„ÄÅ„Ç∏„Éß„Éº„ÅÆÁÇπ„ÅØ$(1,2)$„ÄÅ„Ç∞„É¨„Ç§„Ç∑„Éº„ÅÆÁÇπ„ÅØ$(-1,1)$„Åß„Åô„ÄÇ  \\\\n„Åó„Åü„Åå„Å£„Å¶„ÄÅÂΩº„Çâ„ÅÆÁÇπÈñì„ÅÆË∑ùÈõ¢„ÅØ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kurogane/metamath_ja_950_reka3flash."},
	{"name":"gs8k_thai_r1_example","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/StelleX/gs8k_thai_r1_example","creator_name":"StelleX","creator_url":"https://huggingface.co/StelleX","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."},
	{"name":"countdown-numbers-3-8","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/alexjackson17/countdown-numbers-3-8","creator_name":"Alex Jackson","creator_url":"https://huggingface.co/alexjackson17","description":"\\n\\t\\n\\t\\t\\n\\t\\tCountdown Numbers Game Dataset\\n\\t\\n\\nThis dataset contains configurations and solutions for variations of the Countdown numbers game. Each example comprises a sequence of numbers, a target number, the computed solution (closest value), the arithmetic expression that achieves that value, the difference between the target and the computed value, and the final Countdown score.\\n\\n\\t\\n\\t\\t\\n\\t\\tHuggingFace Download Links\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\nDataset Variant\\nDataset Name\\nDownload\\n\\n\\n\\t\\t\\nRandom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexjackson17/countdown-numbers-3-8."},
	{"name":"countdown-numbers-3-8-nz","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/alexjackson17/countdown-numbers-3-8-nz","creator_name":"Alex Jackson","creator_url":"https://huggingface.co/alexjackson17","description":"\\n\\t\\n\\t\\t\\n\\t\\tCountdown Numbers Game Dataset\\n\\t\\n\\nThis dataset contains configurations and solutions for variations of the Countdown numbers game. Each example comprises a sequence of numbers, a target number, the computed solution (closest value), the arithmetic expression that achieves that value, the difference between the target and the computed value, and the final Countdown score.\\n\\n\\t\\n\\t\\t\\n\\t\\tHuggingFace Download Links\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\nDataset Variant\\nDataset Name\\nDownload\\n\\n\\n\\t\\t\\nRandom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexjackson17/countdown-numbers-3-8-nz."},
	{"name":"AIME25","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/AIME25","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"The AIME25 part 1 exam from the website.\\n"},
	{"name":"upload-test","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/koookiy/upload-test","creator_name":"yaoke","creator_url":"https://huggingface.co/koookiy","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."},
	{"name":"orca-math-word-reflection","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Harshkmr/orca-math-word-reflection","creator_name":"Harsh Kumar","creator_url":"https://huggingface.co/Harshkmr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"orca-math-word-reflection\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Orca-Math Word Problems with Reflection dataset is an extension of subset of the original ORCA Math Word Problems 200k dataset. This new version introduces a \\\"Thinking and Reflection\\\" format designed to enhance problem-solving approaches by encouraging step-by-step thinking before producing a solution. \\nIn this dataset, each math word problem and its corresponding solution from the original dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Harshkmr/orca-math-word-reflection."},
	{"name":"CompositionalGSM_augmented","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuGyouk/CompositionalGSM_augmented","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCompositional GSM_augmented\\n\\t\\n\\nCompositional GSM_augmented is a math instruction dataset, inspired by Not All LLM Reasoners Are Created Equal.\\nIt is based on nvidia/OpenMathInstruct-2 dataset, so you can use this dataset as training dataset.\\nIt is generated using meta-llama/Meta-Llama-3.1-70B-Instruct model by Hyperbloic AI link. (Thanks for free credit!)\\nReplace the description of the data with the contents in the paper.\\n\\nEach question in compositional GSM consists of two‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/CompositionalGSM_augmented."},
	{"name":"VisualWebInstruct","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is the final dataset we used to train MAmmoTH-VL2.\\n\\n\\t\\n\\t\\t\\n\\t\\tSubset\\n\\t\\n\\n\\nconversation: this subset contains VisualWebInstruct + LLavaCoT in the form of conversation.\\nexample: this subset is mainly for visualizing the examples.\\nvisualwebinstruct: this subset contains our dataset in the QA format.\\nimage: all the images are in imgs.tar.gz\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLinks\\n\\t\\n\\nGithub|\\nPaper|\\nWebsite|\\nModel\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{visualwebinstruct,\\n    title={VisualWebInstruct: Scaling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/VisualWebInstruct."},
	{"name":"NuminaMath-CoT","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI-MO/NuminaMath-CoT","creator_name":"Project-Numina","creator_url":"https://huggingface.co/AI-MO","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NuminaMath CoT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nApproximately 860k math problems, where each solution is formatted in a Chain of Thought (CoT) manner. The sources of the dataset range from Chinese high school math exercises to US and international mathematics olympiad competition problems. The data were primarily collected from online exam paper PDFs and mathematics discussion forums. The processing steps include (a) OCR from the original PDFs, (b) segmentation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI-MO/NuminaMath-CoT."},
	{"name":"Light-R1-DPOData","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qihoo360/Light-R1-DPOData","creator_name":"Âåó‰∫¨Â•áËôéÁßëÊäÄÊúâÈôêÂÖ¨Âè∏","creator_url":"https://huggingface.co/qihoo360","description":"\\n\\t\\n\\t\\t\\n\\t\\tLight-R1: Surpassing R1-Distill from Scratch* with $1000 through Curriculum SFT & DPO\\n\\t\\n\\n*from models without long COT\\ntechnical report\\nGitHub page\\nHere is the DPO data we used to train Light-R1-32B.\\nSimply refer to dpo-pairs.json\\n\\n\\t\\n\\t\\t\\nModel\\nTrained From\\nRelease Date\\nAIME24\\nAIME25\\n\\n\\n\\t\\t\\nDeepSeek-R1-Distill-Llama-70B\\nLlama-3.3-70B-Instruct\\n25.1.20\\n70.0\\n54.1\\n\\n\\nDeepSeek-R1-Distill-Qwen-32B\\nQwen2.5-32B\\n25.1.20\\n72.6\\n54.9\\n\\n\\nLIMO (32B)\\nQwen2.5-32B-Instruct25.2.4\\n56.3\\n47.1\\n\\n\\ns1.1-32B‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qihoo360/Light-R1-DPOData."},
	{"name":"MetaMathQA","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meta-math/MetaMathQA","creator_name":"MetaMath","creator_url":"https://huggingface.co/meta-math","description":"View the project page:\\nhttps://meta-math.github.io/\\nsee our paper at https://arxiv.org/abs/2309.12284\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\nAll MetaMathQA data are augmented from the training sets of GSM8K and MATH. \\nNone of the augmented data is from the testing set.\\nYou can check the original_question in meta-math/MetaMathQA, each item is from the GSM8K or MATH train set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Details\\n\\t\\n\\nMetaMath-Mistral-7B is fully fine-tuned on the MetaMathQA datasets and based on the powerful Mistral-7B model.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meta-math/MetaMathQA."},
	{"name":"OpenMathInstruct-2","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nvidia/OpenMathInstruct-2","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenMathInstruct-2\\n\\t\\n\\nOpenMathInstruct-2 is a math instruction tuning dataset with 14M problem-solution pairs \\ngenerated using the Llama3.1-405B-Instruct model.\\nThe training set problems of GSM8K\\nand MATH are used for constructing the dataset in the following ways: \\n\\nSolution augmentation: Generating chain-of-thought solutions for training set problems in GSM8K and MATH. \\nProblem-Solution augmentation: Generating new problems, followed by solutions for these new problems.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/OpenMathInstruct-2."},
	{"name":"NuminaMath-1.5","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI-MO/NuminaMath-1.5","creator_name":"Project-Numina","creator_url":"https://huggingface.co/AI-MO","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for NuminaMath 1.5\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the second iteration of the popular NuminaMath dataset, bringing high quality post-training data for approximately 900k competition-level math problems.  Each solution is formatted in a Chain of Thought (CoT) manner. The sources of the dataset range from Chinese high school math exercises to US and international mathematics olympiad competition problems. The data were primarily collected from online exam paper PDFs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI-MO/NuminaMath-1.5."},
	{"name":"HoT","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/groundingauburn/HoT","creator_name":"grounding_auburn","creator_url":"https://huggingface.co/groundingauburn","description":"\\n\\t\\n\\t\\t\\n\\t\\tüìö Fact-Enhanced Math Question Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains math word, logical reasoning, question answering and reading comprehension problems with automatically reformatted questions and answers using XML tags for facts. It is designed to facilitate research in explainable AI (XAI), Human-AI interaction.\\nEach question is reformatted to explicitly highlight key facts using XML-style tags (<fact1>, <fact2>, etc.), and the answer explanation follows a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/groundingauburn/HoT."},
	{"name":"MathInstruct","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/MathInstruct","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü¶£ MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning\\n\\t\\n\\nMathInstruct is a meticulously curated instruction tuning dataset that is lightweight yet generalizable. MathInstruct is compiled from 13 math rationale datasets, six of which are newly curated by this work. It uniquely focuses on the hybrid use of chain-of-thought (CoT) and program-of-thought (PoT) rationales, and ensures extensive coverage of diverse mathematical fields. \\nProject Page:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/MathInstruct."},
	{"name":"GSM8K_zh","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meta-math/GSM8K_zh","creator_name":"MetaMath","creator_url":"https://huggingface.co/meta-math","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\nGSM8K_zh is a dataset for mathematical reasoning in Chinese, question-answer pairs are translated from GSM8K (https://github.com/openai/grade-school-math/tree/master) by GPT-3.5-Turbo with few-shot prompting.\\nThe dataset consists of 7473 training samples and 1319 testing samples. The former is for supervised fine-tuning, while the latter is for evaluation.\\nfor training samples, question_zh and answer_zh are question and answer keys, respectively;\\nfor testing samples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meta-math/GSM8K_zh."},
	{"name":"aops","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sparsh35/aops","creator_name":"SPARSH TEWATIA","creator_url":"https://huggingface.co/sparsh35","description":"sparsh35/aops dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Omni-MATH","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KbsdJames/Omni-MATH","creator_name":"Bofei Gao","creator_url":"https://huggingface.co/KbsdJames","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Omni-MATH\\n\\t\\n\\n\\n\\nRecent advancements in AI, particularly in large language models (LLMs), have led to significant breakthroughs in mathematical reasoning capabilities. However, existing benchmarks like GSM8K or MATH are now being solved with high accuracy (e.g., OpenAI o1 achieves 94.8% on MATH dataset), indicating their inadequacy for truly challenging these models. To mitigate this limitation, we propose a comprehensive and challenging benchmark specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KbsdJames/Omni-MATH."},
	{"name":"ProcessBench","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Qwen/ProcessBench","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProcessBench\\n\\t\\n\\nThis repository contains the dataset of the ProcessBench benchmark proposed by Qwen Team.\\nYou can refer to our GitHub repository for the evaluation code and the prompt templates we use in this work.\\nIf you find this work relevant or helpful to your work, please kindly cite us:\\n@article{processbench,\\n  title={ProcessBench: Identifying Process Errors in Mathematical Reasoning}, \\n  author={\\n    Chujie Zheng and Zhenru Zhang and Beichen Zhang and Runji Lin and Keming Lu‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Qwen/ProcessBench."},
	{"name":"proof-pile","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hoskinson-center/proof-pile","creator_name":"Hoskinson Center for Formal Mathematics","creator_url":"https://huggingface.co/hoskinson-center","description":"A dataset of high quality mathematical text."},
	{"name":"naturalproofs-gen","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wellecks/naturalproofs-gen","creator_name":"Sean Welleck","creator_url":"https://huggingface.co/wellecks","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNaturalproofs-gen\\n\\t\\n\\nThis dataset contains the Naturalproofs-gen corpus from:\\nNaturalProver: Grounded Mathematical Proof Generation with Language ModelsSean Welleck*, Jiacheng Liu*, Ximing Lu, Hannaneh Hajishirzi, Yejin ChoiNeurIPS 2022\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nMIT\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\nPlease cite:\\n@inproceedings{welleck2022naturalprover,\\n    title={NaturalProver: Grounded Mathematical Proof Generation with Language Models},\\n    author={Sean Welleck and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wellecks/naturalproofs-gen."},
	{"name":"Puffin","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/Puffin","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Puffin dataset. Exactly 3,000 examples with each response created using GPT-4.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPLEASE USE THE NEWER VERSION OF PUFFIN CALLED PURE-DOVE, IT IS NO LONGER RECCOMENDED TO USE PUFFIN\\n\\t\\n\\n\\nComprised of over 2,000 multi-turn conversations between GPT-4 and real humans.\\n\\nAverage context length per conversation is over 1,000 tokens. (will measure this more accurately soon)\\n\\nAverage turns per conversation is more than 10. (will measure this more accurately‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Puffin."},
	{"name":"LessWrong-Amplify-Instruct","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/LessWrong-Amplify-Instruct","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official LessWrong-Amplify-Instruct dataset. Over 500 multi-turn examples, and many more coming soon!\\n\\t\\n\\n\\nThis leverages Amplify-Instruct method to extend thousands of scraped Less-Wrong posts into advanced in-depth multi-turn conversations.\\n\\nComprised of over 500 highly filtered multi-turn synthetic conversations.\\n\\nAverage context length per conversation is over 2,000 tokens. (will measure this more accurately soon)\\n\\nSynthetically created using a newly developed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/LessWrong-Amplify-Instruct."},
	{"name":"Pure-Dove","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/Pure-Dove","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Pure-Dove dataset. Over 3K multi-turn examples, and many more coming soon!\\n\\t\\n\\nThis dataset aims to be the largest highest quality cluster of real human back and forth conversations with GPT-4.\\nSteps have even been done to ensure that only the best GPT-4 conversations in comparisons are kept, there are many instances where two GPT-4 responses are rated as equal to eachother or as both bad. We exclude all such responses from Pure Dove and make sure to only‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Pure-Dove."},
	{"name":"Conic10K","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WenyangHui/Conic10K","creator_name":"huiwy","creator_url":"https://huggingface.co/WenyangHui","description":"WenyangHui/Conic10K dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"distilabel-math-preference-dpo","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla/distilabel-math-preference-dpo","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"distilabel-math-preference-dpo\\\"\\n\\t\\n\\nMore Information needed\\n"},
	{"name":"MMMU","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMMU/MMMU","creator_name":"MMMU","creator_url":"https://huggingface.co/MMMU","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI)\\n\\t\\n\\nüåê Homepage | üèÜ Leaderboard | ü§ó Dataset | ü§ó Paper | üìñ arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüîîNews\\n\\t\\n\\n\\nüõ†Ô∏è[2024-05-30]: Fixed duplicate option issues in Materials dataset items (validation_Materials_25; test_Materials_17, 242) and content error in validation_Materials_25.\\nüõ†Ô∏è[2024-04-30]: Fixed missing \\\"-\\\" or \\\"^\\\" signs in Math dataset items (dev_Math_2, validation_Math_11, 12, 16;‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MMMU/MMMU."},
	{"name":"MetaMathQA_GSM8K_zh","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meta-math/MetaMathQA_GSM8K_zh","creator_name":"MetaMath","creator_url":"https://huggingface.co/meta-math","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\nMetaMathQA_GSM8K_zh is a dataset for mathematical reasoning in Chinese, \\nquestion-answer pairs are translated from MetaMathQA (https://huggingface.co/datasets/meta-math/MetaMathQA) by GPT-3.5-Turbo with few-shot prompting.\\nThe dataset consists of 231685 samples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you find the GSM8K_zh dataset useful for your projects/papers, please cite the following paper.\\n@article{yu2023metamath,\\n  title={MetaMath: Bootstrap Your Own Mathematical Questions for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meta-math/MetaMathQA_GSM8K_zh."},
	{"name":"Capybara","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/Capybara","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Capybara dataset. Over 10,000 multi-turn examples.\\n\\t\\n\\nCapybara is the culmination of insights derived from synthesis techniques like Evol-instruct (used for WizardLM), Alpaca, Orca, Vicuna, Lamini, FLASK and others.\\nThe single-turn seeds used to initiate the Amplify-Instruct synthesis of conversations are mostly based on datasets that i've personally vetted extensively, and are often highly regarded for their diversity and demonstration of logical robustness‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Capybara."},
	{"name":"ws-5d","keyword":"math","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/calabi-yau-data/ws-5d","creator_name":"Calabi-Yau data","creator_url":"https://huggingface.co/calabi-yau-data","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWeight Systems Defining Five-Dimensional IP Lattice Polytopes\\n\\t\\n\\nThis dataset contains all weight systems defining five-dimensional reflexive and\\nnon-reflexive IP lattice polytopes, instrumental in the study of Calabi-Yau fourfolds in\\nmathematics and theoretical physics. The data was compiled by Harald Skarke and Friedrich\\nSch√∂ller in arXiv:1808.02422. More information is\\navailable at the Calabi-Yau data website. The\\ndataset can be explored using the search\\nfrontend. See below for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/calabi-yau-data/ws-5d."},
	{"name":"Mr-GSM8K","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Randolphzeng/Mr-GSM8K","creator_name":"Randolphzeng","creator_url":"https://huggingface.co/Randolphzeng","description":"View the project page:\\nhttps://github.com/dvlab-research/DiagGSM8K\\nsee our paper at https://arxiv.org/abs/2312.17080\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nIn this work, we introduce a novel evaluation paradigm for Large Language Models, \\none that challenges them to engage in meta-reasoning. Our paradigm shifts the focus from result-oriented assessments, \\nwhich often overlook the reasoning process, to a more holistic evaluation that effectively differentiates \\nthe cognitive capabilities among models. For‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Randolphzeng/Mr-GSM8K."},
	{"name":"Latex-VLM","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JosselinSom/Latex-VLM","creator_name":"Josselin Somerville","creator_url":"https://huggingface.co/JosselinSom","description":"JosselinSom/Latex-VLM dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"image2struct-latex-v1","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stanford-crfm/image2struct-latex-v1","creator_name":"Stanford CRFM","creator_url":"https://huggingface.co/stanford-crfm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tImage2Struct - Latex\\n\\t\\n\\nPaper | Website | Datasets (Webpages, Latex, Music sheets) | Leaderboard | HELM repo | Image2Struct repo\\nLicense: Apache License Version 2.0, January 2004\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\nImage2struct is a benchmark for evaluating vision-language models in practical tasks of extracting structured information from images.\\nThis subdataset focuses on LaTeX code. The model is given an image of the expected output with the prompt:\\nPlease provide the LaTex code‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stanford-crfm/image2struct-latex-v1."},
	{"name":"distilabel-capybara-dpo-7k-binarized","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla/distilabel-capybara-dpo-7k-binarized","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCapybara-DPO 7K binarized\\n\\t\\n\\n\\nA DPO dataset built with distilabel atop the awesome LDJnr/Capybara\\n\\n\\nThis is a preview version to collect feedback from the community. v2 will include the full base dataset and responses from more powerful models.\\n\\n\\n    \\n\\n\\n\\n  \\n    \\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy?\\n\\t\\n\\nMulti-turn dialogue data is key to fine-tune capable chat models. Multi-turn preference data has been used by the most relevant RLHF works (Anthropic, Meta Llama2, etc.). Unfortunately, there are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/argilla/distilabel-capybara-dpo-7k-binarized."},
	{"name":"UltraTextbooks","keyword":"math","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Locutusque/UltraTextbooks","creator_name":"Sebastian Gabarain","creator_url":"https://huggingface.co/Locutusque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"UltraTextbooks\\\"\\n\\t\\n\\n\\nIn the digital expanse, a Tree of Knowledge grows,\\nIts branches of code and words intertwine in prose.\\nSynthetic leaves shimmer, human insights compose,\\nA binary symphony where wisdom forever flows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRepository\\n\\t\\n\\nThe \\\"UltraTextbooks\\\" dataset is hosted on the Hugging Face platform.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nThe \\\"UltraTextbooks\\\" dataset is a comprehensive collection of high-quality synthetic and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Locutusque/UltraTextbooks."},
	{"name":"distilabel-math-preference-dpo-de","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mayflowergmbh/distilabel-math-preference-dpo-de","creator_name":"Mayflower GmbH","creator_url":"https://huggingface.co/mayflowergmbh","description":"German azureml translation of argilla/distilabel-math-preference-dpo\\nfor dpo finetuning.\\n"},
	{"name":"orca-math-word-problems-200k","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/microsoft/orca-math-word-problems-200k","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\n\\nThis dataset contains ~200K grade school math word problems. All the answers in this dataset is generated using Azure GPT4-Turbo. Please refer to Orca-Math: Unlocking the potential of\\nSLMs in Grade School Math for details about the dataset construction. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\n\\n\\nRepository: microsoft/orca-math-word-problems-200k\\nPaper: Orca-Math: Unlocking the potential of\\nSLMs in Grade School Math\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDirect Use\\n\\t\\n\\n\\n\\nThis dataset has been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/microsoft/orca-math-word-problems-200k."},
	{"name":"MATH-plus","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/MATH-plus","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"This dataset contains the MetaMath, MATH-orca and some additional MATH-augmented dataset with GPT-4. This dataset is being used to train MAmmoTH2-plus version (https://tiger-ai-lab.github.io/MAmmoTH2/).\\n"},
	{"name":"MathCodeInstruct-Plus","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MathLLMs/MathCodeInstruct-Plus","creator_name":"LLMs for Math Reasoning","creator_url":"https://huggingface.co/MathLLMs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning\\n\\t\\n\\nPaper: https://arxiv.org/pdf/2310.03731.pdf\\nRepo: https://github.com/mathllm/MathCoder\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce MathCoder, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving.\\n\\n\\t\\n\\t\\t\\nBase Model: Llama-2\\nBase Model: Code Llama\\n\\n\\n\\t\\t\\nMathCoder-L-7B\\nMathCoder-CL-7B\\n\\n\\nMathCoder-L-13B\\nMathCoder-CL-34B\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTraining Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathCodeInstruct-Plus."},
	{"name":"UniMER_Dataset","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanderkid/UniMER_Dataset","creator_name":"Bin Wang","creator_url":"https://huggingface.co/wanderkid","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUniMER Dataset\\n\\t\\n\\nFor detailed instructions on using the dataset, please refer to the project homepage: UniMERNet Homepage\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe UniMER dataset is a specialized collection curated to advance the field of Mathematical Expression Recognition (MER). It encompasses the comprehensive UniMER-1M training set, featuring over one million instances that represent a diverse and intricate range of mathematical expressions, coupled with the UniMER Test Set‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wanderkid/UniMER_Dataset."},
	{"name":"BRIGHT","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xlangai/BRIGHT","creator_name":"XLang NLP Lab","creator_url":"https://huggingface.co/xlangai","description":"\\n\\t\\n\\t\\t\\n\\t\\tBRIGHT benchmark\\n\\t\\n\\nBRIGHT is the first text retrieval benchmark that requires intensive reasoning to retrieve relevant documents. \\nThe queries are collected from diverse domains (StackExchange, LeetCode, and math competitions), all sourced from realistic human data.\\nExperiments show that existing retrieval models perform poorly on BRIGHT, where the highest score is only 22.1 measured by nDCG@10.\\nBRIGHT provides a good testbed for future retrieval research in more realistic and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xlangai/BRIGHT."},
	{"name":"mathdial","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/eth-nlped/mathdial","creator_name":"Language, Reasoning and Education lab","creator_url":"https://huggingface.co/eth-nlped","description":"\\n\\t\\n\\t\\t\\n\\t\\tMathdial dataset\\n\\t\\n\\nhttps://arxiv.org/abs/2305.14536\\nMathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems.\\nMathDial is grounded in math word problems as well as student confusions which provide a challenging testbed for creating faithful and equitable dialogue tutoring models able to reason over complex information. Current models achieve high accuracy in solving such problems but they fail in the task of teaching.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eth-nlped/mathdial."},
	{"name":"NuminaMath-TIR","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI-MO/NuminaMath-TIR","creator_name":"Project-Numina","creator_url":"https://huggingface.co/AI-MO","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NuminaMath CoT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTool-integrated reasoning (TIR) plays a crucial role in this competition. However, collecting and annotating such data is both costly and time-consuming. To address this, we selected approximately 70k problems from the NuminaMath-CoT dataset, focusing on those with numerical outputs, most of which are integers. We then utilized a pipeline leveraging GPT-4 to generate TORA-like reasoning paths, executing the code and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI-MO/NuminaMath-TIR."},
	{"name":"OlympiadBench","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hothan/OlympiadBench","creator_name":"Hothan Bega","creator_url":"https://huggingface.co/Hothan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems\\n\\t\\n\\nüìñ arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nOlympiadBench is an Olympiad-level bilingual multimodal scientific benchmark, featuring 8,476 problems from Olympiad-level mathematics and physics competitions, including the Chinese college entrance exam. Each problem is detailed with expert-level annotations for step-by-step reasoning. Notably, the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hothan/OlympiadBench."},
	{"name":"math-hard-calibration","keyword":"math","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/math-hard-calibration","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMath Hard Calibration\\n\\t\\n\\nThis dataset is generated from lighteval/MATH-Hard, intended for model quantization calibration.\\n"},
	{"name":"MMMU-Thai","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iapp/MMMU-Thai","creator_name":"iApp Technology","creator_url":"https://huggingface.co/iapp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU Thai (MMMU Benchmark Translated to Thai)\\n\\t\\n\\nMMMU Thai is a dataset for evaluating multimodal models on massive multi-discipline tasks requiring college-level knowledge and deliberate reasoning. This dataset is translated from MMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI) into Thai.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nMMMU Thai consists of 11,500 meticulously collected multimodal questions from college exams, quizzes, and textbooks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iapp/MMMU-Thai."},
	{"name":"24-game","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nlile/24-game","creator_name":"nathan lile","creator_url":"https://huggingface.co/nlile","description":"\\n\\t\\n\\t\\t\\n\\t\\tMath Twenty Four (24s Game) Dataset\\n\\t\\n\\nA comprehensive dataset for the classic math twenty four game (also known as the 4 numbers game / 24s game / Game of 24). This dataset of mathematical reasoning challenges was collected from 4nums.com, featuring over 1,300 unique puzzles of the Game of 24, with difficulty metrics derived from over 6.4 million human solution attempts since 2012.\\nIn each puzzle, players must use exactly four numbers and basic arithmetic operations (+, -, √ó, /) to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nlile/24-game."},
	{"name":"MAmmoTH-VL-Instruct-12M","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MAmmoTH-VL/MAmmoTH-VL-Instruct-12M","creator_name":"MAmmoTH-VL","creator_url":"https://huggingface.co/MAmmoTH-VL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMAmmoTH-VL-Instruct-12M\\n\\t\\n\\nüè† Homepage | ü§ñ MAmmoTH-VL-8B | üíª Code | üìÑ Arxiv | üìï PDF | üñ•Ô∏è Demo\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nOur simple yet scalable visual instruction data rewriting pipeline consists of three steps: manual data source collection, rewriting using MLLMs/LLMs, and filtering via the same MLLM as a judge. Examples below illustrate transformations in math and science categories, showcasing detailed, step-by-step responses.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe data distribution of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MAmmoTH-VL/MAmmoTH-VL-Instruct-12M."},
	{"name":"VISCO","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/uclanlp/VISCO","creator_name":"UCLA NLP","creator_url":"https://huggingface.co/uclanlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVISCO\\n\\t\\n\\nBenchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning\\nüåê Project | üìñ Paper | üíª Github\\n\\n\\nOutline:\\n\\nIntroduction\\nData\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nVISCO is a benchmark for evaluating the critique and correction capabilities of LVLMs. VISCO contains:\\n\\n1645 pairs of questions and LVLM-generated answers. Each answer includes a chain-of-thought with multiple reasonign steps.\\n5604 step-wise annotations of critique, showing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/uclanlp/VISCO."},
	{"name":"u-math","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/toloka/u-math","creator_name":"Toloka","creator_url":"https://huggingface.co/toloka","description":"U-MATH is a comprehensive benchmark of 1,100 unpublished university-level problems sourced from real teaching materials. \\nIt is designed to evaluate the mathematical reasoning capabilities of Large Language Models (LLMs). The dataset is balanced across six core mathematical topics and includes 20% of multimodal problems (involving visual elements such as graphs and diagrams). \\nFor fine-grained performance evaluation results and detailed discussion, check out our paper.\\n\\nüìä U-MATH benchmark at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/toloka/u-math."},
	{"name":"mu-math","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/toloka/mu-math","creator_name":"Toloka","creator_url":"https://huggingface.co/toloka","description":"Œº-MATH (Meta U-MATH) is a meta-evaluation dataset derived from the U-MATH benchmark.\\nIt is intended to assess the ability of LLMs to judge free-form mathematical solutions. The dataset includes 1,084 labeled samples generated from 271 U-MATH tasks, covering problems of varying assessment complexity.\\nFor fine-grained performance evaluation results, in-depth analyses and detailed discussions on behaviors and biases of LLM judges, check out our paper.\\n\\nüìä U-MATH benchmark at Huggingface\\nüîé Œº-MATH‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/toloka/mu-math."},
	{"name":"CodeMathGen","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lFelix/CodeMathGen","creator_name":"Fan Liu","creator_url":"https://huggingface.co/lFelix","description":"lFelix/CodeMathGen dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Math-Solve","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Math-Solve","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Math-Solve dataset is a collection of math problems and their solutions, designed to facilitate training and evaluation of models for tasks such as text generation, question answering, and summarization. The dataset contains nearly 25k rows of math-related problems, each paired with a detailed solution.\\nThis dataset is particularly useful for researchers and developers working on AI models that require mathematical reasoning and problem-solving capabilities.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Math-Solve."},
	{"name":"PyThagoreans-Merged","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/PyThagoreans-Merged","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tPyThagoreans Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe PyThagoreans dataset is a comprehensive collection of math problems and their solutions, designed to assist in learning and practicing mathematical problem-solving. This dataset includes a variety of problems, expected answers, and predicted answers, making it a valuable resource for students, educators, and researchers.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tModalities\\n\\t\\n\\n\\nText: The dataset primarily contains text data, including math‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/PyThagoreans-Merged."},
	{"name":"Math-Forge-Hard","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Math-Forge-Hard","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tMath-Forge-Hard Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Math-Forge-Hard dataset is a collection of challenging math problems designed to test and improve problem-solving skills. This dataset includes a variety of word problems that cover different mathematical concepts, making it a valuable resource for students, educators, and researchers.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tModalities\\n\\t\\n\\n\\nText: The dataset primarily contains text data, including math word problems.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFormats‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Math-Forge-Hard."},
	{"name":"Math-Question-Answer","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aixr/Math-Question-Answer","creator_name":"Aixr AI","creator_url":"https://huggingface.co/Aixr","description":"Aixr/Math-Question-Answer dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"numinamath_verifiable_cleaned","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/flatlander1024/numinamath_verifiable_cleaned","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Adapt from https://huggingface.co/datasets/AI-MO/NuminaMath-CoT and filtered problems with verifiable answers.\\nRemoved duplicates and decontaminated from test datasets.\\nTotal number of rows: 678759\\n"},
	{"name":"math-squared","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/veds12/math-squared","creator_name":"Vedant Shah","creator_url":"https://huggingface.co/veds12","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Name\\n\\t\\n\\nMATH2\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMATH2 is a mathematical reasoning evaluation dataset curated using a human-in-the-loop approach proposed in the paper AI-Assisted Generation of Difficult Math Questions. The dataset consists of 210 questions formed by combining 2 math domain skills using frontier LLMs. These skills were extracted from the MATH [Hendrycks et al., 2021] dataset.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\n\\nPaper: AI-Assisted Generation of Difficult Math‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/veds12/math-squared."},
	{"name":"Grade-Math-18K","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Grade-Math-18K","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tGrade-Math-18K dataset\\n\\t\\n\\nThis dataset contains math question and answer pairs, designed for training and evaluating machine learning models in elementary and middle school math problem solving. \\nThe dataset includes text formatted in CSV and is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\nNumber of questions: 18,000\\nGrades: Elementary and Middle School\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tModalities\\n\\t\\n\\n\\nText\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFormats\\n\\t\\n\\n\\nCSV\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nEnglish\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLicense\\n\\t\\n\\nThe license for this dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Grade-Math-18K."},
	{"name":"Math-Solve-Singleshot","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Math-Solve-Singleshot","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tMath-Solve-Singleshot\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset, named Math-Solve-Singleshot, is designed for solving single-shot mathematical problems. It contains a variety of math problems formatted in text, suitable for training and evaluating models on mathematical reasoning tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\tModalities\\n\\t\\n\\n\\nText\\nFormats: CSV\\nSize: 1.05M rows\\nLibraries: pandas\\n\\n\\nCroissant\\nLicense: Apache-2.0\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nTrain Split: 1.05 million rows\\nProblem String Lengths:\\nLength 1: 16‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Math-Solve-Singleshot."},
	{"name":"GSM8K_zh_tw","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DoggiAI/GSM8K_zh_tw","creator_name":"Doggi AI","creator_url":"https://huggingface.co/DoggiAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset\\n\\t\\n\\nGSM8K_zh_tw is a dataset for mathematical reasoning in Traditional Chinese. It is derived from the GSM8K_zh dataset by translating question-answer pairs into Traditional Chinese using OpenCC. The dataset consists of 7473 training samples and 1319 testing samples.\\nIn addition to translation, the dataset includes modifications to improve regional adaptation, such as replacing some China-specific terms with those more suitable for Traditional Chinese users. Simplified Chinese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DoggiAI/GSM8K_zh_tw."},
	{"name":"MetaMathQA-R1","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oumi-ai/MetaMathQA-R1","creator_name":"Oumi","creator_url":"https://huggingface.co/oumi-ai","description":"\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\toumi-ai/MetaMathQA-R1\\n\\t\\n\\nMetaMathQA-R1 is a text dataset designed to train Conversational Language Models with DeepSeek-R1 level reasoning.\\nPrompts were augmented from GSM8K and MATH training sets with responses directly from DeepSeek-R1.\\nMetaMathQA-R1 was used to train MiniMath-R1-1.5B, which achieves 44.4% accuracy on MMLU-Pro-Math, the highest of any model with <=1.5B parameters.\\n\\nCurated by: Oumi AI using Oumi inference on Parasail\\nLanguage(s) (NLP): English\\nLicense:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oumi-ai/MetaMathQA-R1."},
	{"name":"WebInstruct-CFT","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/WebInstruct-CFT","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\tWebInstruct-CFT Dataset\\n\\t\\n\\nThis dataset is introduced in our paper Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate.\\n| üöÄProject Page | üìñPaper | üîóGithub | ü§ó7B Model | ü§ó32B Model |\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nWebInstruct-CFT is a critique-based instruction dataset derived from WebInstruct. Unlike traditional instruction datasets that focus on correct answers, our dataset includes critiques of responses, enabling models to learn through critical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/WebInstruct-CFT."},
	{"name":"amc_aime_self_improving","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/camel-ai/amc_aime_self_improving","creator_name":"CAMEL-AI.org","creator_url":"https://huggingface.co/camel-ai","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."},
	{"name":"amc_aime_distilled","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/camel-ai/amc_aime_distilled","creator_name":"CAMEL-AI.org","creator_url":"https://huggingface.co/camel-ai","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."},
	{"name":"gsm8k_distilled","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/camel-ai/gsm8k_distilled","creator_name":"CAMEL-AI.org","creator_url":"https://huggingface.co/camel-ai","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."},
	{"name":"aime2025-ru","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kristaller486/aime2025-ru","creator_name":"Kristaller486","creator_url":"https://huggingface.co/kristaller486","description":"\\n\\t\\n\\t\\t\\n\\t\\tRussian Description (English below)\\n\\t\\n\\n–ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –±–µ–Ω—á–º–∞—Ä–∫–∞ AIME 2025 –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫. –ú–æ–¥–µ–ª—å-–ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ - Gemini 2.0 Pro Experimental.\\n\\n\\t\\n\\t\\t\\n\\t\\tEnglish Description\\n\\t\\n\\nTranslated version of AIME 2025 into Russian. Model-translator - Gemini 2.0 Pro Experimental.\\n\\n\\t\\n\\t\\t\\n\\t\\tLeaderboard\\n\\t\\n\\n\\n"},
	{"name":"Persian-Math-SFT","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xmanii/Persian-Math-SFT","creator_name":"mani mirzaei","creator_url":"https://huggingface.co/xmanii","description":"\\n\\t\\n\\t\\t\\n\\t\\tüéØ Persian Math Questions Dataset for SFT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tüìù Description\\n\\t\\n\\nThis dataset contains Persian questions primarily focused on mathematical concepts, designed for Supervised Fine-Tuning (SFT) of Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\tüîç Features\\n\\t\\n\\n\\nHigh-quality Persian questions\\nDetailed subtopic categorization\\nFocused on mathematical concepts\\nTokens count for each conversation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tüöÄ Coming Soon\\n\\t\\n\\n\\nDetailed answers for each question\\nAdditional topics beyond mathematics\\nEnhanced‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xmanii/Persian-Math-SFT."},
	{"name":"SciCode","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SciCode1/SciCode","creator_name":"SciCode","creator_url":"https://huggingface.co/SciCode1","description":"This dataset was presented in SciCode: A Research Coding Benchmark Curated by Scientists.\\n"},
	{"name":"OpenReasonerZero","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tonic/OpenReasonerZero","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-Reasoner-Zero Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Open-Reasoner-Zero dataset is a carefully curated collection of reasoning tasks designed to enhance the problem-solving capabilities of language models. It is optimized for scalable Reasoner-Zero training by focusing on three key aspects: quantity, diversity, and quality. The dataset comprises approximately 57,000 samples spanning STEM, mathematics, and reasoning domains.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nFeature\\nCount\\n\\n\\n\\t\\t\\nTotal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tonic/OpenReasonerZero."},
	{"name":"HoT_User_Study_Data","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/groundingauburn/HoT_User_Study_Data","creator_name":"grounding_auburn","creator_url":"https://huggingface.co/groundingauburn","description":"\\n\\t\\n\\t\\t\\n\\t\\tüìö Fact-Enhanced Math Problem Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains mathematical reasoning problems where key facts are highlighted using fact tags (e.g., <fact1>, <fact2>). The dataset is designed for training and evaluating explainable AI (XAI) models, especially in fact-referencing reasoning tasks.\\nEach question and answer pair follows a structured format where supporting facts are explicitly referenced to improve transparency in mathematical problem-solving.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/groundingauburn/HoT_User_Study_Data."},
	{"name":"kolmogorov-3","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/attn-signs/kolmogorov-3","creator_name":"Attention Signs","creator_url":"https://huggingface.co/attn-signs","description":"\\n\\t\\n\\t\\t\\n\\t\\tKolmogorov-3\\n\\t\\n\\nCarefully selected, checked and formatted PhD-level russian math instruction dataset.Contains olympiad/university/science-level tasks from various sources.\\n\\n\\t\\n\\t\\t\\n\\t\\tContents:\\n\\t\\n\\nMathematics\\n\\nPre-algebra\\nPre-calculus\\nCalculus\\nAlgebra\\nNumber theory\\nGeometry\\nProbability theory\\nSet theory\\nMathematical proofs\\n\\nCode\\n\\nCode-to-math problems\\nAlgorithms\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tFormats:\\n\\t\\n\\nDataset is formatted in conversation manner, can be also used for GRPO problem-answer training\\n"},
	{"name":"oaCamel","keyword":"math","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/checkai/oaCamel","creator_name":"Lucas Barker","creator_url":"https://huggingface.co/checkai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for oaCamel\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is the chemistry, biology, math, and physics datasets created by CAMEL ai. https://huggingface.co/camel-ai\\nThey have been combined and converted to the Open Assistant format.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThis dataset follows the OA format, which is:\\n\\nINSTRUCTION (string): Instruction text\\nRESPONSE (string): Expected response to the instruction\\nSOURCE (string): Original data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/checkai/oaCamel."},
	{"name":"reasoning-gsm-qna-oa","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/0x22almostEvil/reasoning-gsm-qna-oa","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GSM QnA reasoning with ~8.8K entries.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nContains Parquet of a list of instructions and answers.\\nEach row consists of\\n\\nINSTRUCTION\\nRESPONSE\\nSOURCE\\nMETADATA (json with language).\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOriginal Datasets are available here:\\n\\t\\n\\n\\nhttps://huggingface.co/datasets/gsm8k\\nhttps://huggingface.co/datasets/reasoning-machines/gsm-hard\\n\\n"},
	{"name":"atlas-math-sets","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AtlasUnified/atlas-math-sets","creator_name":"Atlas Unified","creator_url":"https://huggingface.co/AtlasUnified","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tATLAS MATH SETS\\n\\t\\n\\n\\nThis set of data consists of mathematical computations. Simple in nature as it derived from python scripts, this dataset contains addition, subtraction, multiplication, division, fractions, decimals, square roots, cube roots, exponents, and factors.\\nFormat of the JSONL is as follows:\\n{\\\"answer\\\": \\\"[num]\\\", \\\"input\\\": \\\"[equation]\\\", \\\"output\\\": \\\"[num]\\\", \\\"instruction\\\": \\\"[pre-generated_instruction] [equation]\\\"}\\n"},
	{"name":"Calc-svamp","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MU-NLPC/Calc-svamp","creator_name":"NLP Centre, Faculty of Informatics, Masaryk University","creator_url":"https://huggingface.co/MU-NLPC","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Calc-SVAMP\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nThe dataset is a collection of simple math word problems focused on arithmetics. It is derived from https://github.com/arkilpatel/SVAMP/.\\nThe main addition in this dataset variant is the chain column. It was created by converting the solution to a simple html-like language that can be easily\\nparsed (e.g. by BeautifulSoup). The data contains 3 types of tags:\\n\\ngadget: A tag whose content is intended to be evaluated by calling an external‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MU-NLPC/Calc-svamp."},
	{"name":"Calc-mawps","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MU-NLPC/Calc-mawps","creator_name":"NLP Centre, Faculty of Informatics, Masaryk University","creator_url":"https://huggingface.co/MU-NLPC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Calc-MAWPS\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThe dataset is a collection of simple math word problems focused on arithmetics. It is derived from https://huggingface.co/datasets/omarxadel/MaWPS-ar.\\nThe main addition in this dataset variant is the chain column. It was created by converting the solution to a simple html-like language that can be easily\\nparsed (e.g. by BeautifulSoup). The data contains 3 types of tags:\\n\\ngadget: A tag whose content is intended to be evaluated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MU-NLPC/Calc-mawps."},
	{"name":"Verified-Camel","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LDJnr/Verified-Camel","creator_name":"Luigi D","creator_url":"https://huggingface.co/LDJnr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Verified Camel dataset. Just over 100 verified examples, and many more coming soon!\\n\\t\\n\\n\\nComprised of over 100 highly filtered and curated examples from specific portions of CamelAI stem datasets. \\n\\nThese examples are verified to be true by experts in the specific related field, with atleast a bachelors degree in the subject.\\n\\nRoughly 30-40% of the originally curated data from CamelAI was found to have atleast minor errors and/or incoherent questions(as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LDJnr/Verified-Camel."},
	{"name":"Arithmo-Data","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akjindal53244/Arithmo-Data","creator_name":"Ashvini Kumar Jindal","creator_url":"https://huggingface.co/akjindal53244","description":"Arithmo dataset is prepared as combination of MetaMathQA, MathInstruct, and lila ood. Refer to Model Training Data section in Arithmo-Mistral-7B project GitHub page for more details.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupport My Work\\n\\t\\n\\nBuilding LLMs takes time and resources; if you find my work interesting, your support would be epic!\\n\\nReferences\\n\\n@article{yu2023metamath,\\n  title={MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models},\\n  author={Yu, Longhui and Jiang, Weisen and Shi, Han and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akjindal53244/Arithmo-Data."},
	{"name":"minimath","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cxllin/minimath","creator_name":"Collin Heenan","creator_url":"https://huggingface.co/cxllin","description":"Condensed version of the meta-math dataset \\narxiv.org/abs/2309.12284\\nView the project page:\\nhttps://meta-math.github.io/\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{yu2023metamath,\\n  title={MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models},\\n  author={Yu, Longhui and Jiang, Weisen and Shi, Han and Yu, Jincheng and Liu, Zhengying and Zhang, Yu and Kwok, James T and Li, Zhenguo and Weller, Adrian and Liu, Weiyang},\\n  journal={arXiv preprint arXiv:2309.12284},\\n  year={2023}\\n}\\n\\n"},
	{"name":"Verified-Camel-KO","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuotient/Verified-Camel-KO","creator_name":"Jisoo Kim","creator_url":"https://huggingface.co/kuotient","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVerified-Camel-KO\\n\\t\\n\\nÏù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùÄ https://huggingface.co/datasets/LDJnr/Verified-Camel Ïùò ÌïúÍµ≠Ïñ¥ Î≤àÏó≠ÏûÖÎãàÎã§.\\nGPT4 TurboÎ°ú Î≤àÏó≠Ìïú Îí§, ÏïΩÍ∞ÑÏùò ÏàòÏ†ïÏùÑ Í±∞Ï≥§ÏäµÎãàÎã§.\\nÏù¥ Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú Î∞©Ïπ®ÏùÄ Ï†ÑÎ∂Ä Ïõê Ï†ÄÏûêÏùò Î∞©Ïπ®ÏùÑ Îî∞Î¶ÖÎãàÎã§.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Verified Camel dataset. Just over 100 verified examples, and many more coming soon!\\n\\t\\n\\n\\nComprised of over 100 highly filtered and curated examples from specific portions of CamelAI stem datasets. \\n\\nThese examples are verified to be true by experts in the specific related field, with atleast‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kuotient/Verified-Camel-KO."},
	{"name":"MATH_1GRADE","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mito0o852/MATH_1GRADE","creator_name":"Moustapha","creator_url":"https://huggingface.co/mito0o852","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"MATH_1GRADE\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1st Grade Math Problems Dataset\\n\\t\\n\\nThis dataset, available on Hugging Face, offers a unique collection of math problems tailored for first-grade students. The problems have been synthetically generated using Python scripts and are designed to challenge and enhance the mathematical skills of young learners in an engaging and accessible way. This README provides an overview of the dataset, including its structure, contents, and how to use‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mito0o852/MATH_1GRADE."},
	{"name":"manimation","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mediciresearch/manimation","creator_name":"Medici Research","creator_url":"https://huggingface.co/mediciresearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMedici Animation Instruct Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSmall instruct dataset for animation generation with ManimCE\\n\\t\\n\\n"},
	{"name":"Verified-Camel-zh","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/noobmaster29/Verified-Camel-zh","creator_name":"Victor Sung","creator_url":"https://huggingface.co/noobmaster29","description":"This is a direct Chinese translation using GPT4 of the Verified-Camel dataset. I hope you find it useful. \\nhttps://huggingface.co/datasets/LDJnr/Verified-Camel\\nCitation:\\n@article{daniele2023amplify-instruct,\\n  title={Amplify-Instruct: Synthetically Generated Diverse Multi-turn Conversations for Effecient LLM Training.},\\n  author={Daniele, Luigi and Suphavadeeprasit},\\n  journal={arXiv preprint arXiv:(comming soon)},\\n  year={2023}\\n}\\n\\n"},
	{"name":"vi_math_problem_crawl","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hllj/vi_math_problem_crawl","creator_name":"Bui Van Hop","creator_url":"https://huggingface.co/hllj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Vietnamese Elementary Math Knowledge and Workbook\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe data includes information about elementary school math knowledge in Vietnam, as well as exercises compiled from books. This is a crawlable dataset that can be trained for text generation tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe majority of the data is in Vietnamese, but there is still some English from some bilingual workbooks.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hllj/vi_math_problem_crawl."},
	{"name":"vi_grade_school_math_mcq","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hllj/vi_grade_school_math_mcq","creator_name":"Bui Van Hop","creator_url":"https://huggingface.co/hllj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Vietnamese Grade School Math Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset includes multiple-choice math exercises for elementary school students from grades 1 to 5 in Vietnam.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe majority of the data is in Vietnamese.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe data includes information about the page paths we crawled and some text that has been post-processed.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hllj/vi_grade_school_math_mcq."},
	{"name":"Capybara-Converted","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cfahlgren1/Capybara-Converted","creator_name":"Caleb Fahlgren","creator_url":"https://huggingface.co/cfahlgren1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Capybara dataset. Over 10,000 multi-turn examples.\\n\\t\\n\\nCapybara is the culmination of insights derived from synthesis techniques like Evol-instruct (used for WizardLM), Alpaca, Orca, Vicuna, Lamini, FLASK and others.\\nThe single-turn seeds used to intiate the Amplify-Instruct synthesis of conversations are mostly based on datasets that i've personally vetted extensively, and are often highly regarded for their diversity and demonstration of logical robustness and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cfahlgren1/Capybara-Converted."},
	{"name":"capybara-sharegpt","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Doctor-Shotgun/capybara-sharegpt","creator_name":"Doctor Shotgun","creator_url":"https://huggingface.co/Doctor-Shotgun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcapybara-sharegpt\\n\\t\\n\\nLDJnr/Capybara converted to ShareGPT format for use in common training repositories.\\nPlease refer to the original repository's dataset card for more information. All credit goes to the original creator.\\n"},
	{"name":"MMMU","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aslessor/MMMU","creator_name":"Alex","creator_url":"https://huggingface.co/aslessor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI)\\n\\t\\n\\nüåê Homepage | ü§ó Dataset | ü§ó Paper | üìñ arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüîîNews\\n\\t\\n\\n\\nüî•[2023-12-04]: Our evaluation server for test set is now availble on EvalAI. We welcome all submissions and look forward to your participation! üòÜ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe introduce MMMU: a new benchmark designed to evaluate multimodal models on massive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aslessor/MMMU."},
	{"name":"MATH-500-Overall","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fluently-sets/MATH-500-Overall","creator_name":"Fluently Datasets","creator_url":"https://huggingface.co/fluently-sets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMATH-500-Overall\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout the dataset\\n\\t\\n\\nThis dataset of only 500 examples combines mathematics, physics and logic in English with reasoning and step-by-step problem solving, the dataset was created synthetically, CoT of Qwen2.5-72B-Instruct and Llama3.3-70B-Instruct.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBrief information\\n\\t\\n\\n\\nNumber of rows: 500\\nType of dataset files: parquet\\nType of dataset: text, alpaca with system prompts\\nLanguage: English\\nLicense: MIT\\n\\nStructure:\\nmath¬Ø¬Ø¬Ø¬Ø¬Ø‚åâ\\n   school-level‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fluently-sets/MATH-500-Overall."},
	{"name":"synmath-1-dsv3-87k","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Gusarich/synmath-1-dsv3-87k","creator_name":"Daniil Sedov","creator_url":"https://huggingface.co/Gusarich","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsynmath-1-dsv3-87k\\n\\t\\n\\nsynmath-1-dsv3-87k is a dataset consisting of 86,700 math problems and their corresponding solutions, formatted in a chain-of-thought manner. The problems span 867 distinct mathematical domains, providing diverse and comprehensive coverage for fine-tuning smaller models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nsynmath-1-dsv3-87k contains synthetically generated math problems and step-by-step solutions designed to enhance mathematical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gusarich/synmath-1-dsv3-87k."},
	{"name":"step_sft","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xiaodongguaAIGC/step_sft","creator_name":"xiaodongguaAIGC","creator_url":"https://huggingface.co/xiaodongguaAIGC","description":"Mix:\\n\\n\\t\\n\\t\\t\\nÊï∞ÊçÆÈõÜÂêçÁß∞\\nÊòØÂê¶Êúâstep\\nÂèØÁî®‰∫éPRMËÆ≠ÁªÉ\\nÊ†áÁ≠æÂΩ¢Âºè\\nTitle\\nÂ§áÊ≥®\\n\\n\\n\\t\\t\\nGSM8K\\n‚úÖ\\n‚ùå\\nÁ≠îÊ°à\\nTraining Verifiers to Solve Math Word Problems\\n\\n\\n\\nMATH\\n‚ùå\\n‚ùå\\nÁ≠îÊ°à\\nMeasuring Mathematical Problem Solving With the MATH Dataset\\nNon-Step\\n\\n\\nPRM800K\\n‚úÖ\\n‚úÖ\\nÊ≠£Á°ÆÁ±ªÂà´\\nLet's Verify Step by Step\\nprompt deduplication\\n\\n\\nMath-Shepherd\\n‚úÖ\\n‚úÖ\\nÊ≠£Á°ÆÁ±ªÂà´\\nMath-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations\\nNot used\\n\\n\\nProcessBench\\n‚úÖ\\n‚úÖ\\nÈ¶ñ‰∏™ÈîôËØØÊ≠•È™§\\nProcessBench: Identifying Process Errors in Mathematical Reasoning\\nonly label -1\\n\\n\\n\\t\\n\\n"},
	{"name":"that-one-google-math-dataset","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/metapoiesis/that-one-google-math-dataset","creator_name":"EVE","creator_url":"https://huggingface.co/metapoiesis","description":"apolocheese for poor format, it's because I Don't Care (i'm tired and still working)\\ndata from: https://github.com/google-deepmind/mathematics_dataset\\nfrom huggingface_hub import snapshot_download\\nfrom datasets import load_dataset\\nimport os\\n\\ndef get_all_files(directory):\\n    file_paths = []\\n    for root, dirs, files in os.walk(directory):\\n        for name in files:\\n            full_path = os.path.join(root, name)\\n            file_paths.append(os.path.abspath(full_path))\\n    return file_paths‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/metapoiesis/that-one-google-math-dataset."},
	{"name":"mathlib_handler_benchmark_410","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ruc-ai4math/mathlib_handler_benchmark_410","creator_name":"ruc-ai4math","creator_url":"https://huggingface.co/ruc-ai4math","description":"This dataset is used in the paper Assisting Mathematical Formalization with A Learning-based Premise Retriever.  It contains data for training and evaluating a premise retriever for the Lean theorem prover.\\nThe dataset is described in detail in the GitHub repository.  It consists of proof states and corresponding premises from the Mathlib library.  The data is designed to train a model to effectively retrieve relevant premises for a given proof state, assisting users in the mathematical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ruc-ai4math/mathlib_handler_benchmark_410."},
	{"name":"ugmathbench","keyword":"math","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UGMathBench/ugmathbench","creator_name":"UGMathBench","creator_url":"https://huggingface.co/UGMathBench","description":"\\n\\t\\n\\t\\t\\n\\t\\tUGMathBench: A Diverse and Dynamic Benchmark for Undergraduate-Level Mathematical Reasoning with Large Language Models\\n\\t\\n\\nUGMathBench is a diverse and dynamic benchmark specifically designed for evaluating undergraduate-level mathematical reasoning with LLMs. \\nUGMathBench comprises 5,062 problems across 16 subjects and 111 topics, featuring 10 distinct answer types.\\nEach problem includes three randomized versions.\\nPaper: https://huggingface.co/papers/2501.13766\\nGitHub page:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UGMathBench/ugmathbench."},
	{"name":"camel_LongCoT","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tofu0142/camel_LongCoT","creator_name":"Zhang","creator_url":"https://huggingface.co/Tofu0142","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."},
	{"name":"countdown-numbers-6-gr","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/alexjackson17/countdown-numbers-6-gr","creator_name":"Alex Jackson","creator_url":"https://huggingface.co/alexjackson17","description":"\\n\\t\\n\\t\\t\\n\\t\\tCountdown Numbers Game Dataset\\n\\t\\n\\nThis dataset contains configurations and solutions for variations of the Countdown numbers game. Each example comprises a sequence of numbers, a target number, the computed solution (closest value), the arithmetic expression that achieves that value, the difference between the target and the computed value, and the final Countdown score.\\n\\n\\t\\n\\t\\t\\n\\t\\tHuggingFace Download Links\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\nDataset Variant\\nDataset Name\\nDownload\\n\\n\\n\\t\\t\\nRandom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexjackson17/countdown-numbers-6-gr."},
	{"name":"GammaCorpus-Math-QA-2m","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Math-QA-2m","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","description":"\\n\\t\\n\\t\\t\\n\\t\\tGammaCorpus: Math QA 2m\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is it?\\n\\t\\n\\nGammaCorpus Math QA 2m is a dataset that consists of 2,760,000 mathematical question-and-answer. It consists of 917,196 addition questions, 916,662 subtraction questions, 917,015 multiplication questions, and 9,126 division questions.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nNumber of Rows: 2,760,000\\nFormat: JSONL\\nData Type: Mathematical Question Pairs\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe dataset is formatted in JSONL, where‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Math-QA-2m."},
	{"name":"NuminaMath-CoT","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oieieio/NuminaMath-CoT","creator_name":"Jorge Alonso","creator_url":"https://huggingface.co/oieieio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for NuminaMath CoT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nApproximately 860k math problems, where each solution is formatted in a Chain of Thought (CoT) manner. The sources of the dataset range from Chinese high school math exercises to US and international mathematics olympiad competition problems. The data were primarily collected from online exam paper PDFs and mathematics discussion forums. The processing steps include (a) OCR from the original PDFs, (b) segmentation into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oieieio/NuminaMath-CoT."},
	{"name":"NuminaMath-TIR","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oieieio/NuminaMath-TIR","creator_name":"Jorge Alonso","creator_url":"https://huggingface.co/oieieio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for NuminaMath CoT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTool-integrated reasoning (TIR) plays a crucial role in this competition. However, collecting and annotating such data is both costly and time-consuming. To address this, we selected approximately 70k problems from the NuminaMath-CoT dataset, focusing on those with numerical outputs, most of which are integers. We then utilized a pipeline leveraging GPT-4 to generate TORA-like reasoning paths, executing the code and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oieieio/NuminaMath-TIR."},
	{"name":"OCTAL-Math-CoT-47k","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qingy2024/OCTAL-Math-CoT-47k","creator_name":"Qingyun Li","creator_url":"https://huggingface.co/qingy2024","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOptimizing Chain of Thought for Adaptable LLMs\\n\\t\\n\\nOCTAL has high quality math chain-of-thought (CoT) data for LLM fine-tuning. It contains more discrete reasoning steps and logic than the original dataset, NuminaMathCoT.\\nReasoning based on QwQ 32B Preview, reformatting and cleaning based on Llama 3.1 70B Instruct. All answers cross-checked.\\n"},
	{"name":"step_prm","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xiaodongguaAIGC/step_prm","creator_name":"xiaodongguaAIGC","creator_url":"https://huggingface.co/xiaodongguaAIGC","description":"\\n\\t\\n\\t\\t\\nÊï∞ÊçÆÈõÜÂêçÁß∞\\nÊòØÂê¶Êúâstep\\nÂèØÁî®‰∫éPRMËÆ≠ÁªÉ\\nÊ†áÁ≠æÂΩ¢Âºè\\nTitle\\nÂ§áÊ≥®\\n\\n\\n\\t\\t\\nGSM8K\\n‚úÖ\\n‚ùå\\nÁ≠îÊ°à\\nTraining Verifiers to Solve Math Word Problems\\n\\n\\n\\nMATH\\n‚ùå\\n‚ùå\\nÁ≠îÊ°à\\nMeasuring Mathematical Problem Solving With the MATH Dataset\\nNon-Step\\n\\n\\nPRM800K\\n‚úÖ\\n‚úÖ\\nÊ≠£Á°ÆÁ±ªÂà´\\nLet's Verify Step by Step\\nprompt deduplication\\n\\n\\nMath-Shepherd\\n‚úÖ\\n‚úÖ\\nÊ≠£Á°ÆÁ±ªÂà´\\nMath-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations\\nNot used\\n\\n\\nProcessBench\\n‚úÖ\\n‚úÖ\\nÈ¶ñ‰∏™ÈîôËØØÊ≠•È™§\\nProcessBench: Identifying Process Errors in Mathematical Reasoning\\nonly label -1\\n\\n\\n\\t\\n\\n"},
	{"name":"QwQ-LongCoT-130K-decontaminated","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/flatlander1024/QwQ-LongCoT-130K-decontaminated","creator_name":"Xinzhi Zhang","creator_url":"https://huggingface.co/flatlander1024","description":"Decontaminated version of gghfez/QwQ-LongCoT-130K-cleaned that remove the collided data from math/test, gsm8k/test, olympiadbench/test, minerva_math/test, college_math/test, mmlu_stem/test, gaokao, amc23, aime24 and math500.\\nTotal number of rows: 124594\\n"},
	{"name":"math500_post-training","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cmpatino/math500_post-training","creator_name":"Carlos Miguel Pati√±o","creator_url":"https://huggingface.co/cmpatino","description":"\\n\\t\\n\\t\\t\\n\\t\\tMATH500 Subset for Small Model Post-Training\\n\\t\\n\\nThis dataset contains a subset of 20 problems from the MATH500 dataset.\\nThe dataset contains the following columns:\\n\\nproblem_id: Unique problem id that corresponds to the unique_id from the MATH500 dataset.\\nproblem: Text describing the problem the model needs to solve.\\nsolution: The solution generated by OpenAI available in the original dataset.\\nanswer: The ground truth answer.\\nsubject: Problem's subject from 7 possible values (Algebra‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmpatino/math500_post-training."},
	{"name":"scicode","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Zilinghan/scicode","creator_name":"Zilinghan Li","creator_url":"https://huggingface.co/Zilinghan","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Zilinghan/scicode."},
	{"name":"DistillMath","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/csh0101/DistillMath","creator_name":"csh0101","creator_url":"https://huggingface.co/csh0101","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."},
	{"name":"GammaCorpus-CoT-Math-170k","keyword":"math","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-CoT-Math-170k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","description":"\\n\\t\\n\\t\\t\\n\\t\\tGammaCorpus: CoT Math 170k\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is it?\\n\\t\\n\\nGammaCorpus CoT Math 170k is a dataset that consists of 170,000 math problems, each with step-by-step Chain-of-Thought (CoT) reasoning. It's designed to help in training and evaluating AI models for mathematical reasoning and problem-solving tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nNumber of Rows: 169,527\\nFormat: JSONL\\nLanguage: English\\nData Type: Math problems with step-by-step reasoning (Chain-of-Thought)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-CoT-Math-170k."},
	{"name":"distillation01","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zjrwtxtechstudio/distillation01","creator_name":"zjrwtx","creator_url":"https://huggingface.co/zjrwtxtechstudio","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."},
	{"name":"r101","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zjrwtxtechstudio/r101","creator_name":"zjrwtx","creator_url":"https://huggingface.co/zjrwtxtechstudio","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."},
	{"name":"r102","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zjrwtxtechstudio/r102","creator_name":"zjrwtx","creator_url":"https://huggingface.co/zjrwtxtechstudio","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."},
	{"name":"r109","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zjrwtxtechstudio/r109","creator_name":"zjrwtx","creator_url":"https://huggingface.co/zjrwtxtechstudio","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."},
	{"name":"arabic_dialects_question_and_answer","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CNTXTAI0/arabic_dialects_question_and_answer","creator_name":"CNTXT AI","creator_url":"https://huggingface.co/CNTXTAI0","description":"Data Content\\nThe file provided: Q/A Reasoning dataset\\ncontains the following columns:\\n\\n\\nID # : Denotes the reference ID for:\\na. Question\\nb. Answer to the question\\nc. Hint\\nd. Reasoning\\ne. Word count for items a to d above\\nDialects: Contains the following dialects in separate columns:\\na. English\\nb. MSA\\nc. Emirati\\nd. Egyptian\\ne. Levantine Syria\\nf. Levantine Jordan\\ng. Levantine Palestine\\nh. Levantine Lebanon\\nData Generation Process\\nThe following are the steps that were followed to curate the data:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CNTXTAI0/arabic_dialects_question_and_answer."},
	{"name":"camel_dataset_example","keyword":"math","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Wendong-Fan/camel_dataset_example","creator_name":"Wendong.Fan","creator_url":"https://huggingface.co/Wendong-Fan","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process."}
]
;
