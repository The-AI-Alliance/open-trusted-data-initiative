const data_for_domain_geospatial = 
[
	{"name":"AtomicGPT-3.0_Dataset","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Atomic-Ai/AtomicGPT-3.0_Dataset","creator_name":"Atomic Ai Studios","creator_url":"https://huggingface.co/Atomic-Ai","description":"Atomic-Ai/AtomicGPT-3.0_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","German","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"AtomicGPT-3.0_Dataset","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Atomic-Ai/AtomicGPT-3.0_Dataset","creator_name":"Atomic Ai Studios","creator_url":"https://huggingface.co/Atomic-Ai","description":"Atomic-Ai/AtomicGPT-3.0_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","German","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"CropClimateX","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/torchgeo/CropClimateX","creator_name":"TorchGeo","creator_url":"https://huggingface.co/torchgeo","description":"\n\t\n\t\t\n\t\tCropClimateX\n\t\n\n\nRepository: TBA\nPaper: TBA\n\n\nThe database includes 15,500 small data cubes (i.e., minicubes), each with a spatial coverage of 12x12km, spanning 1527 counties in the US. The minicubes comprise data from multiple sensors (Sentinel-2, Landsat-8, MODIS), weather and extreme events (Daymet, heat/cold waves, and U.S. drought monitor maps), as well as soil and terrain features, making it suitable for various agricultural monitoring tasks. It integrates crop- and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/torchgeo/CropClimateX.","first_N":5,"first_N_keywords":["time-series-forecasting","tabular-regression","tabular-classification","image-feature-extraction","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CropClimateX","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/torchgeo/CropClimateX","creator_name":"TorchGeo","creator_url":"https://huggingface.co/torchgeo","description":"\n\t\n\t\t\n\t\tCropClimateX\n\t\n\n\nRepository: TBA\nPaper: TBA\n\n\nThe database includes 15,500 small data cubes (i.e., minicubes), each with a spatial coverage of 12x12km, spanning 1527 counties in the US. The minicubes comprise data from multiple sensors (Sentinel-2, Landsat-8, MODIS), weather and extreme events (Daymet, heat/cold waves, and U.S. drought monitor maps), as well as soil and terrain features, making it suitable for various agricultural monitoring tasks. It integrates crop- and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/torchgeo/CropClimateX.","first_N":5,"first_N_keywords":["time-series-forecasting","tabular-regression","tabular-classification","image-feature-extraction","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CropClimateX","keyword":"remote-sensing","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/torchgeo/CropClimateX","creator_name":"TorchGeo","creator_url":"https://huggingface.co/torchgeo","description":"\n\t\n\t\t\n\t\tCropClimateX\n\t\n\n\nRepository: TBA\nPaper: TBA\n\n\nThe database includes 15,500 small data cubes (i.e., minicubes), each with a spatial coverage of 12x12km, spanning 1527 counties in the US. The minicubes comprise data from multiple sensors (Sentinel-2, Landsat-8, MODIS), weather and extreme events (Daymet, heat/cold waves, and U.S. drought monitor maps), as well as soil and terrain features, making it suitable for various agricultural monitoring tasks. It integrates crop- and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/torchgeo/CropClimateX.","first_N":5,"first_N_keywords":["time-series-forecasting","tabular-regression","tabular-classification","image-feature-extraction","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CropClimateX","keyword":"earth-observation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/torchgeo/CropClimateX","creator_name":"TorchGeo","creator_url":"https://huggingface.co/torchgeo","description":"\n\t\n\t\t\n\t\tCropClimateX\n\t\n\n\nRepository: TBA\nPaper: TBA\n\n\nThe database includes 15,500 small data cubes (i.e., minicubes), each with a spatial coverage of 12x12km, spanning 1527 counties in the US. The minicubes comprise data from multiple sensors (Sentinel-2, Landsat-8, MODIS), weather and extreme events (Daymet, heat/cold waves, and U.S. drought monitor maps), as well as soil and terrain features, making it suitable for various agricultural monitoring tasks. It integrates crop- and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/torchgeo/CropClimateX.","first_N":5,"first_N_keywords":["time-series-forecasting","tabular-regression","tabular-classification","image-feature-extraction","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"CAFOSat","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nibir/CAFOSat","creator_name":"Nibir Chandra Mandal","creator_url":"https://huggingface.co/Nibir","description":"\n\t\n\t\t\n\t\tCAFOSat: CAFO Infrastructure Dataset\n\t\n\nCAFOSat is a remote sensing dataset designed for identifying and classifying Concentrated Animal Feeding Operations (CAFOs) across various U.S. states. It includes high-resolution image patches, infrastructure annotations, bounding boxes, and experimental train-test splits for multiple configurations.\n\n\t\n\t\t\n\t\tüîó Resources\n\t\n\n\nGitHub Repository: oishee-hoque/CAFOSat\nExplore the Dataset: CAFOSat Data Loader and Examples\n\n\n\t\n\t\t\n\t\t\n\t\n\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nibir/CAFOSat.","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","webdataset","Image","Text"],"keywords_longer_than_N":true},
	{"name":"CAFOSat","keyword":"remote-sensing","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nibir/CAFOSat","creator_name":"Nibir Chandra Mandal","creator_url":"https://huggingface.co/Nibir","description":"\n\t\n\t\t\n\t\tCAFOSat: CAFO Infrastructure Dataset\n\t\n\nCAFOSat is a remote sensing dataset designed for identifying and classifying Concentrated Animal Feeding Operations (CAFOs) across various U.S. states. It includes high-resolution image patches, infrastructure annotations, bounding boxes, and experimental train-test splits for multiple configurations.\n\n\t\n\t\t\n\t\tüîó Resources\n\t\n\n\nGitHub Repository: oishee-hoque/CAFOSat\nExplore the Dataset: CAFOSat Data Loader and Examples\n\n\n\t\n\t\t\n\t\t\n\t\n\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nibir/CAFOSat.","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","webdataset","Image","Text"],"keywords_longer_than_N":true},
	{"name":"IRRISIGHT","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nibir/IRRISIGHT","creator_name":"Nibir Chandra Mandal","creator_url":"https://huggingface.co/Nibir","description":"\n\t\n\t\t\n\t\tIRRISIGHT\n\t\n\nIRRISIGHT is a large-scale multimodal dataset to address water availability problems in agriculture. It is designed to support supervised and semi-supervised learning tasks related to agricultural water use monitoring.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach sample is stored in an HDF5 file within the Data/ directory and contains:\n\nrgb: Sentinel-2 RGB image\nagri_index: Multiband vegetation indices (e.g., NDVI, NDWI, EVI)\nland_mask, crop_mask, irr_mask, subirr_mask: Label and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nibir/IRRISIGHT.","first_N":5,"first_N_keywords":["image-segmentation","image-classification","object-detection","visual-question-answering","monolingual"],"keywords_longer_than_N":true},
	{"name":"IRRISIGHT","keyword":"remote-sensing","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nibir/IRRISIGHT","creator_name":"Nibir Chandra Mandal","creator_url":"https://huggingface.co/Nibir","description":"\n\t\n\t\t\n\t\tIRRISIGHT\n\t\n\nIRRISIGHT is a large-scale multimodal dataset to address water availability problems in agriculture. It is designed to support supervised and semi-supervised learning tasks related to agricultural water use monitoring.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach sample is stored in an HDF5 file within the Data/ directory and contains:\n\nrgb: Sentinel-2 RGB image\nagri_index: Multiband vegetation indices (e.g., NDVI, NDWI, EVI)\nland_mask, crop_mask, irr_mask, subirr_mask: Label and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nibir/IRRISIGHT.","first_N":5,"first_N_keywords":["image-segmentation","image-classification","object-detection","visual-question-answering","monolingual"],"keywords_longer_than_N":true},
	{"name":"IRRISIGHT","keyword":"earth-observation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nibir/IRRISIGHT","creator_name":"Nibir Chandra Mandal","creator_url":"https://huggingface.co/Nibir","description":"\n\t\n\t\t\n\t\tIRRISIGHT\n\t\n\nIRRISIGHT is a large-scale multimodal dataset to address water availability problems in agriculture. It is designed to support supervised and semi-supervised learning tasks related to agricultural water use monitoring.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach sample is stored in an HDF5 file within the Data/ directory and contains:\n\nrgb: Sentinel-2 RGB image\nagri_index: Multiband vegetation indices (e.g., NDVI, NDWI, EVI)\nland_mask, crop_mask, irr_mask, subirr_mask: Label and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nibir/IRRISIGHT.","first_N":5,"first_N_keywords":["image-segmentation","image-classification","object-detection","visual-question-answering","monolingual"],"keywords_longer_than_N":true},
	{"name":"traffic_crashes_chicago","keyword":"geospatial","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Chloecky/traffic_crashes_chicago","creator_name":"Chloe Cai","creator_url":"https://huggingface.co/Chloecky","description":"\n\t\n\t\t\n\t\t\n\t\n\nThis dataset is derived from the City of Chicago Open Data Portal, which is provided under a CC0 1.0 Public Domain Dedication.\nWe redistribute this dataset here for ease of access and experimentation.\n","first_N":5,"first_N_keywords":["cc0-1.0","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"country-flags-dataset","keyword":"geography","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aniket96/country-flags-dataset","creator_name":"Aniket Shirsat","creator_url":"https://huggingface.co/Aniket96","description":"\n\t\n\t\t\n\t\tWorld Country Flags Dataset\n\t\n\nThis dataset contains flag images from sovereign states with their country names as labels.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA comprehensive collection of flag images for all sovereign nations, organized for machine learning tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Images: 195 country flags\nFormat: PNG (640x427 pixels)\nTask: Image classification\nLanguage: English country names\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\nimage: The flag image in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniket96/country-flags-dataset.","first_N":5,"first_N_keywords":["image-classification","English","cc0-1.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"chile-seismological-records","keyword":"geography","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LeoBorai/chile-seismological-records","creator_name":"Leo Borai","creator_url":"https://huggingface.co/LeoBorai","description":"\n\t\n\t\t\n\t\tChile's Seismological Records\n\t\n\n","first_N":5,"first_N_keywords":["Spanish","mit","10K - 100K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"extraction-examples","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/alexdzm/extraction-examples","creator_name":"Alex","creator_url":"https://huggingface.co/alexdzm","description":"\n\t\n\t\t\n\t\tExtraction Examples Dataset\n\t\n\nThis dataset contains 17 examples for testing extraction workflows.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example includes:\n\nPDF file: Original document \nmap_info.json: Map extraction metadata\ndirection.json: Direction information  \nGeoJSON files: Polygon geometries\nArea JSON files: Area definitions\n\n\n\t\n\t\t\n\t\tFile Organization\n\t\n\nfiles/\n‚îú‚îÄ‚îÄ example1/\n‚îÇ   ‚îú‚îÄ‚îÄ document.pdf\n‚îÇ   ‚îú‚îÄ‚îÄ map_info.json\n‚îÇ   ‚îú‚îÄ‚îÄ direction.json\n‚îÇ   ‚îú‚îÄ‚îÄ polygon1.geojson\n‚îÇ   ‚îî‚îÄ‚îÄ area1.json‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexdzm/extraction-examples.","first_N":5,"first_N_keywords":["other","mit","< 1K","arrow","Document"],"keywords_longer_than_N":true},
	{"name":"Geo_dataset","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wsdwJohn1231/Geo_dataset","creator_name":"xiaoxinghhh","creator_url":"https://huggingface.co/wsdwJohn1231","description":"\n\t\n\t\t\n\t\tDataset Card for Geo_dataset\n\t\n\n\n\nThe Geo_dataset is a cross-domain segmentation dataset for remote sensing images, comprising four subsets: ISPRS Potsdam, ISPRS Vaihingen, Loveda Urban, and Loveda Rural. It is suitable for conducting domain adaptation and domain generalization experiments.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\n\n\n\n -->\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\n\nPaper : https://arxiv.org/abs/2504.06220\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wsdwJohn1231/Geo_dataset.","first_N":5,"first_N_keywords":["apache-2.0","Image","Geospatial","arxiv:2504.06220","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Geo_dataset","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wsdwJohn1231/Geo_dataset","creator_name":"xiaoxinghhh","creator_url":"https://huggingface.co/wsdwJohn1231","description":"\n\t\n\t\t\n\t\tDataset Card for Geo_dataset\n\t\n\n\n\nThe Geo_dataset is a cross-domain segmentation dataset for remote sensing images, comprising four subsets: ISPRS Potsdam, ISPRS Vaihingen, Loveda Urban, and Loveda Rural. It is suitable for conducting domain adaptation and domain generalization experiments.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\n\n\n\n -->\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\n\nPaper : https://arxiv.org/abs/2504.06220\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wsdwJohn1231/Geo_dataset.","first_N":5,"first_N_keywords":["apache-2.0","Image","Geospatial","arxiv:2504.06220","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Glacier-Dataset","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cuibinge/Glacier-Dataset","creator_name":"Cui Binge","creator_url":"https://huggingface.co/cuibinge","description":"\n\t\n\t\t\n\t\tPolar Glacier Bitemporal Remote Sensing Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset contains bitemporal remote sensing images from two representative polar regions:\n\n\t\n\t\t\n\t\tSoutheastern Coast of Greenland\n\t\n\n(Latitude 64¬∞‚Äì66¬∞N, Longitude 51¬∞‚Äì56¬∞W):Dominated by glaciers and icefields, this area features exposed bedrock mountains and narrow coastal vegetation zones. It is a key region for studying glacier dynamics, with typical crevasse systems on the glacier surface and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cuibinge/Glacier-Dataset.","first_N":5,"first_N_keywords":["image-classification","image-segmentation","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Glacier-Dataset","keyword":"remote-sensing","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cuibinge/Glacier-Dataset","creator_name":"Cui Binge","creator_url":"https://huggingface.co/cuibinge","description":"\n\t\n\t\t\n\t\tPolar Glacier Bitemporal Remote Sensing Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset contains bitemporal remote sensing images from two representative polar regions:\n\n\t\n\t\t\n\t\tSoutheastern Coast of Greenland\n\t\n\n(Latitude 64¬∞‚Äì66¬∞N, Longitude 51¬∞‚Äì56¬∞W):Dominated by glaciers and icefields, this area features exposed bedrock mountains and narrow coastal vegetation zones. It is a key region for studying glacier dynamics, with typical crevasse systems on the glacier surface and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cuibinge/Glacier-Dataset.","first_N":5,"first_N_keywords":["image-classification","image-segmentation","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Glacier-Dataset","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cuibinge/Glacier-Dataset","creator_name":"Cui Binge","creator_url":"https://huggingface.co/cuibinge","description":"\n\t\n\t\t\n\t\tPolar Glacier Bitemporal Remote Sensing Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset contains bitemporal remote sensing images from two representative polar regions:\n\n\t\n\t\t\n\t\tSoutheastern Coast of Greenland\n\t\n\n(Latitude 64¬∞‚Äì66¬∞N, Longitude 51¬∞‚Äì56¬∞W):Dominated by glaciers and icefields, this area features exposed bedrock mountains and narrow coastal vegetation zones. It is a key region for studying glacier dynamics, with typical crevasse systems on the glacier surface and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cuibinge/Glacier-Dataset.","first_N":5,"first_N_keywords":["image-classification","image-segmentation","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TAMMs","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IceInPot/TAMMs","creator_name":"ÈîÖ‰∏≠ÂÜ∞","creator_url":"https://huggingface.co/IceInPot","description":"\n\t\n\t\t\n\t\tTAMMs: Temporal-Aware Multimodal Model for Satellite Image Change Understanding and Forecasting\n\t\n\nTAMMs is a large-scale dataset derived from the Functional Map of the World (fMoW) dataset, curated to support multimodal and temporal reasoning tasks such as change detection and future prediction.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 37,003 high-quality temporal sequences, each consisting of at least four distinct satellite images of the same location captured at different‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IceInPot/TAMMs.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"TAMMs","keyword":"remote-sensing","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IceInPot/TAMMs","creator_name":"ÈîÖ‰∏≠ÂÜ∞","creator_url":"https://huggingface.co/IceInPot","description":"\n\t\n\t\t\n\t\tTAMMs: Temporal-Aware Multimodal Model for Satellite Image Change Understanding and Forecasting\n\t\n\nTAMMs is a large-scale dataset derived from the Functional Map of the World (fMoW) dataset, curated to support multimodal and temporal reasoning tasks such as change detection and future prediction.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 37,003 high-quality temporal sequences, each consisting of at least four distinct satellite images of the same location captured at different‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IceInPot/TAMMs.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"MMMG","keyword":"geography","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMMGBench/MMMG","creator_name":"MMMG","creator_url":"https://huggingface.co/MMMGBench","description":"\n\t\n\t\t\n\t\tüß† MMMG: Massive Multi-Discipline Multi-Tier Knowledge Image Benchmark\n\t\n\n\n  üß¨ Project Page ‚Ä¢\n  üìÇ Code\n\n\nMMMG introduces knowledge image generation as a new frontier in text-to-image research. This benchmark probes the reasoning capabilities of image generation models by challenging them to produce educational and scientific visuals grounded in structured knowledge.\nKnowledge images‚Äîsuch as charts, diagrams, mind maps, and scientific illustrations‚Äîplay a crucial role in human‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MMMGBench/MMMG.","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"CAFOSat","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oishee3003/CAFOSat","creator_name":"Oishee Hoque","creator_url":"https://huggingface.co/oishee3003","description":"\n\t\n\t\t\n\t\tCAFOSat: CAFO Infrastructure Dataset\n\t\n\nCAFOSat is a remote sensing dataset designed for identifying and classifying Concentrated Animal Feeding Operations (CAFOs) across various U.S. states. It includes high-resolution image patches, infrastructure annotations, bounding boxes, and experimental train-test splits for multiple configurations.\n\n\t\n\t\t\n\t\tüîó Resources\n\t\n\n\nGitHub Repository: oishee-hoque/CAFOSat\nExplore the Dataset: CAFOSat Data Loader and Examples\n\n\n\t\n\t\t\n\t\t\n\t\n\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oishee3003/CAFOSat.","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","webdataset","Image","Text"],"keywords_longer_than_N":true},
	{"name":"CAFOSat","keyword":"remote-sensing","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oishee3003/CAFOSat","creator_name":"Oishee Hoque","creator_url":"https://huggingface.co/oishee3003","description":"\n\t\n\t\t\n\t\tCAFOSat: CAFO Infrastructure Dataset\n\t\n\nCAFOSat is a remote sensing dataset designed for identifying and classifying Concentrated Animal Feeding Operations (CAFOs) across various U.S. states. It includes high-resolution image patches, infrastructure annotations, bounding boxes, and experimental train-test splits for multiple configurations.\n\n\t\n\t\t\n\t\tüîó Resources\n\t\n\n\nGitHub Repository: oishee-hoque/CAFOSat\nExplore the Dataset: CAFOSat Data Loader and Examples\n\n\n\t\n\t\t\n\t\t\n\t\n\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oishee3003/CAFOSat.","first_N":5,"first_N_keywords":["cc-by-4.0","10K - 100K","webdataset","Image","Text"],"keywords_longer_than_N":true},
	{"name":"DeepExtremeCubes-video","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tacofoundation/DeepExtremeCubes-video","creator_name":"tacofoundation","creator_url":"https://huggingface.co/tacofoundation","description":"\n\n\nThis dataset follows the TACO specification.\n\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDeepExtremeCubes-video: Sentinel-2 Minicubes in Video Format for Compound-Extreme Analysis\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìù Description\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tüì¶ Dataset\n\t\n\nDeepExtremeCubes-video is a storage-efficient, analysis-ready re-packaging of the original DeepExtremeCubes collection.\nAll 42 k Sentinel-2 minicubes (2.56 km √ó 2.56 km, 2016-2022, 7 bands, 5-daily cadence) have been transcoded with xarrayvideointo H.265/HEVC videos, achieving ~12 √ó‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tacofoundation/DeepExtremeCubes-video.","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"DeepExtremeCubes-video","keyword":"remote-sensing","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tacofoundation/DeepExtremeCubes-video","creator_name":"tacofoundation","creator_url":"https://huggingface.co/tacofoundation","description":"\n\n\nThis dataset follows the TACO specification.\n\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDeepExtremeCubes-video: Sentinel-2 Minicubes in Video Format for Compound-Extreme Analysis\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìù Description\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tüì¶ Dataset\n\t\n\nDeepExtremeCubes-video is a storage-efficient, analysis-ready re-packaging of the original DeepExtremeCubes collection.\nAll 42 k Sentinel-2 minicubes (2.56 km √ó 2.56 km, 2016-2022, 7 bands, 5-daily cadence) have been transcoded with xarrayvideointo H.265/HEVC videos, achieving ~12 √ó‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tacofoundation/DeepExtremeCubes-video.","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"french-geography-10K","keyword":"geography","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Dorian2B/french-geography-10K","creator_name":"Dorian Dominici","creator_url":"https://huggingface.co/Dorian2B","description":"\n  \n  \n  \n  \n  \n    \n    \n    \n  \n  \n  \n    \n    \n      \n      \n        \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n      \n      \n      French Geography\n        Langue Fran√ßaise\n      \n    \n    \n    \n    \n    Dataset de Pre-Training\n  \n\n\n\nCe jeu de donn√©es propose 10 000 exemples soigneusement r√©dig√©s en fran√ßais, repr√©sentant environ 1,8 million jetons. Il est destin√© sp√©cifiquement au pr√©-entra√Ænement ou au fine-tuning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Dorian2B/french-geography-10K.","first_N":5,"first_N_keywords":["text-generation","French","apache-2.0","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"french-geography-json-10K","keyword":"geography","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Dorian2B/french-geography-json-10K","creator_name":"Dorian Dominici","creator_url":"https://huggingface.co/Dorian2B","description":"\n  \n  \n  \n  \n  \n    \n    \n    \n  \n  \n  \n    \n    \n      \n      \n        \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n      \n      \n      French Geography\n        Langue Fran√ßaise\n      \n    \n    \n    \n    \n    Dataset de Pre-Training\n  \n\n\n\nCe jeu de donn√©es propose 10 000 exemples soigneusement r√©dig√©s en fran√ßais, repr√©sentant environ 1,8 million jetons. Il est destin√© sp√©cifiquement au pr√©-entra√Ænement ou au fine-tuning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Dorian2B/french-geography-json-10K.","first_N":5,"first_N_keywords":["text-generation","French","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"IRRISIGHT","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OBH30/IRRISIGHT","creator_name":"Oishee Bintey Hoque","creator_url":"https://huggingface.co/OBH30","description":"\n\t\n\t\t\n\t\tIRRISIGHT\n\t\n\nIRRISIGHT is a large-scale multimodal dataset to address water availability problems in agriculture. It is designed to support supervised and semi-supervised learning tasks related to agricultural water use monitoring.\nDue to the space constraints, we uploaded the files across multiple repositories as follows:\nTo download Pennsylvania and Maryland, use the current repository (OBH30/IRRISIGHT). \nTo download Arizona, Arkansas, Florida, Georgia, New Jersey, North Carolina‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OBH30/IRRISIGHT.","first_N":5,"first_N_keywords":["image-segmentation","image-classification","object-detection","visual-question-answering","monolingual"],"keywords_longer_than_N":true},
	{"name":"IRRISIGHT","keyword":"remote-sensing","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OBH30/IRRISIGHT","creator_name":"Oishee Bintey Hoque","creator_url":"https://huggingface.co/OBH30","description":"\n\t\n\t\t\n\t\tIRRISIGHT\n\t\n\nIRRISIGHT is a large-scale multimodal dataset to address water availability problems in agriculture. It is designed to support supervised and semi-supervised learning tasks related to agricultural water use monitoring.\nDue to the space constraints, we uploaded the files across multiple repositories as follows:\nTo download Pennsylvania and Maryland, use the current repository (OBH30/IRRISIGHT). \nTo download Arizona, Arkansas, Florida, Georgia, New Jersey, North Carolina‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OBH30/IRRISIGHT.","first_N":5,"first_N_keywords":["image-segmentation","image-classification","object-detection","visual-question-answering","monolingual"],"keywords_longer_than_N":true},
	{"name":"IRRISIGHT","keyword":"earth-observation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OBH30/IRRISIGHT","creator_name":"Oishee Bintey Hoque","creator_url":"https://huggingface.co/OBH30","description":"\n\t\n\t\t\n\t\tIRRISIGHT\n\t\n\nIRRISIGHT is a large-scale multimodal dataset to address water availability problems in agriculture. It is designed to support supervised and semi-supervised learning tasks related to agricultural water use monitoring.\nDue to the space constraints, we uploaded the files across multiple repositories as follows:\nTo download Pennsylvania and Maryland, use the current repository (OBH30/IRRISIGHT). \nTo download Arizona, Arkansas, Florida, Georgia, New Jersey, North Carolina‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OBH30/IRRISIGHT.","first_N":5,"first_N_keywords":["image-segmentation","image-classification","object-detection","visual-question-answering","monolingual"],"keywords_longer_than_N":true},
	{"name":"IRRISIGHT","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NibirMandal/IRRISIGHT","creator_name":"Nibir Mandal","creator_url":"https://huggingface.co/NibirMandal","description":"\n\t\n\t\t\n\t\tIRRISIGHT\n\t\n\nIRRISIGHT is a large-scale multimodal dataset to address water availability problems in agriculture. It is designed to support supervised and semi-supervised learning tasks related to agricultural water use monitoring.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach sample is stored in an HDF5 file within the Data/ directory and contains:\n\nrgb: Sentinel-2 RGB image\nagri_index: Multiband vegetation indices (e.g., NDVI, NDWI, EVI)\nland_mask, crop_mask, irr_mask, subirr_mask: Label and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NibirMandal/IRRISIGHT.","first_N":5,"first_N_keywords":["image-segmentation","image-classification","object-detection","visual-question-answering","monolingual"],"keywords_longer_than_N":true},
	{"name":"IRRISIGHT","keyword":"remote-sensing","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NibirMandal/IRRISIGHT","creator_name":"Nibir Mandal","creator_url":"https://huggingface.co/NibirMandal","description":"\n\t\n\t\t\n\t\tIRRISIGHT\n\t\n\nIRRISIGHT is a large-scale multimodal dataset to address water availability problems in agriculture. It is designed to support supervised and semi-supervised learning tasks related to agricultural water use monitoring.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach sample is stored in an HDF5 file within the Data/ directory and contains:\n\nrgb: Sentinel-2 RGB image\nagri_index: Multiband vegetation indices (e.g., NDVI, NDWI, EVI)\nland_mask, crop_mask, irr_mask, subirr_mask: Label and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NibirMandal/IRRISIGHT.","first_N":5,"first_N_keywords":["image-segmentation","image-classification","object-detection","visual-question-answering","monolingual"],"keywords_longer_than_N":true},
	{"name":"IRRISIGHT","keyword":"earth-observation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NibirMandal/IRRISIGHT","creator_name":"Nibir Mandal","creator_url":"https://huggingface.co/NibirMandal","description":"\n\t\n\t\t\n\t\tIRRISIGHT\n\t\n\nIRRISIGHT is a large-scale multimodal dataset to address water availability problems in agriculture. It is designed to support supervised and semi-supervised learning tasks related to agricultural water use monitoring.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach sample is stored in an HDF5 file within the Data/ directory and contains:\n\nrgb: Sentinel-2 RGB image\nagri_index: Multiband vegetation indices (e.g., NDVI, NDWI, EVI)\nland_mask, crop_mask, irr_mask, subirr_mask: Label and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NibirMandal/IRRISIGHT.","first_N":5,"first_N_keywords":["image-segmentation","image-classification","object-detection","visual-question-answering","monolingual"],"keywords_longer_than_N":true},
	{"name":"geolayers","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/arjunrao2000/geolayers","creator_name":"Arjun Rao","creator_url":"https://huggingface.co/arjunrao2000","description":"\n\t\n\t\t\n\t\tGeolayers-Data\n\t\n\n\n\n -->\nThis dataset card contains usage instructions and metadata for all data-products released with our paper:Using Multiple Input Modalities can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery. We release 3 modified versions of 3 benchmark datasets spanning land-cover segmentation, tree-cover regression, and multi-label land-cover classification tasks. These datasets are augmented with auxiliary, geographic inputs. A full list of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arjunrao2000/geolayers.","first_N":5,"first_N_keywords":["image-classification","image-segmentation","found","monolingual","SustainBench"],"keywords_longer_than_N":true},
	{"name":"geolayers","keyword":"remote-sensing","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/arjunrao2000/geolayers","creator_name":"Arjun Rao","creator_url":"https://huggingface.co/arjunrao2000","description":"\n\t\n\t\t\n\t\tGeolayers-Data\n\t\n\n\n\n -->\nThis dataset card contains usage instructions and metadata for all data-products released with our paper:Using Multiple Input Modalities can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery. We release 3 modified versions of 3 benchmark datasets spanning land-cover segmentation, tree-cover regression, and multi-label land-cover classification tasks. These datasets are augmented with auxiliary, geographic inputs. A full list of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arjunrao2000/geolayers.","first_N":5,"first_N_keywords":["image-classification","image-segmentation","found","monolingual","SustainBench"],"keywords_longer_than_N":true},
	{"name":"MMMU","keyword":"geography","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMMU/MMMU","creator_name":"MMMU","creator_url":"https://huggingface.co/MMMU","description":"\n\t\n\t\t\n\t\tMMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI)\n\t\n\nüåê Homepage | üèÜ Leaderboard | ü§ó Dataset | ü§ó Paper | üìñ arXiv | GitHub\n\n\t\n\t\t\n\t\n\t\n\t\tüîîNews\n\t\n\n\nüõ†Ô∏è[2024-05-30]: Fixed duplicate option issues in Materials dataset items (validation_Materials_25; test_Materials_17, 242) and content error in validation_Materials_25.\nüõ†Ô∏è[2024-04-30]: Fixed missing \"-\" or \"^\" signs in Math dataset items (dev_Math_2, validation_Math_11, 12, 16; test_Math_8‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MMMU/MMMU.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"foursquare_places_100M","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/do-me/foursquare_places_100M","creator_name":"Dominik Weckm√ºller","creator_url":"https://huggingface.co/do-me","description":"\n\t\n\t\t\n\t\tFoursquare OS Places 100M\n\t\n\nFull Foursquare OS Places dump from https://opensource.foursquare.com/os-places/.\nThis is a single (geo-)parquet file based on the 81 individual parquet files from fused.io on https://source.coop/fused/fsq-os-places/2024-11-19/places.\nAs it's just 10Gb, it's fairly easy to handle as a single file and can easily be queried over modern technologies like httpfs. \n\n\t\n\t\t\n\t\n\t\n\t\tWays to query the file & visualize the results\n\t\n\nIf you just want to poke around in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/do-me/foursquare_places_100M.","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","100M - 1B","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"foursquare_places_100M","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/do-me/foursquare_places_100M","creator_name":"Dominik Weckm√ºller","creator_url":"https://huggingface.co/do-me","description":"\n\t\n\t\t\n\t\tFoursquare OS Places 100M\n\t\n\nFull Foursquare OS Places dump from https://opensource.foursquare.com/os-places/.\nThis is a single (geo-)parquet file based on the 81 individual parquet files from fused.io on https://source.coop/fused/fsq-os-places/2024-11-19/places.\nAs it's just 10Gb, it's fairly easy to handle as a single file and can easily be queried over modern technologies like httpfs. \n\n\t\n\t\t\n\t\n\t\n\t\tWays to query the file & visualize the results\n\t\n\nIf you just want to poke around in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/do-me/foursquare_places_100M.","first_N":5,"first_N_keywords":["feature-extraction","apache-2.0","100M - 1B","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"ScienceQA","keyword":"geography","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/derek-thomas/ScienceQA","creator_name":"Derek Thomas","creator_url":"https://huggingface.co/derek-thomas","description":"\n\t\n\t\t\n\t\tDataset Card Creation Guide\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLearn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMulti-modal Multiple Choice\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nExplore more samples here.\n{'image': Image,\n 'question': 'Which of these states is farthest north?',\n 'choices': ['West Virginia', 'Louisiana', 'Arizona', 'Oklahoma'],\n 'answer': 0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/derek-thomas/ScienceQA.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","other","visual-question-answering","text-classification"],"keywords_longer_than_N":true},
	{"name":"snow_removal_transactions_in_montreal","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cimadure/snow_removal_transactions_in_montreal","creator_name":"Ronan Cimadure","creator_url":"https://huggingface.co/cimadure","description":"cimadure/snow_removal_transactions_in_montreal dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc-by-4.0","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"airbnb","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kraina/airbnb","creator_name":"Kraina","creator_url":"https://huggingface.co/kraina","description":"This dataset contains accommodation offers from the AirBnb platform from 10 European cities.\nIt has been copied from https://zenodo.org/record/4446043#.ZEV8d-zMI-R to make it available as a Huggingface Dataset.\nIt was originally published as supplementary material for the article: Determinants of Airbnb prices in European cities: A spatial econometrics approach\n(DOI: https://doi.org/10.1016/j.tourman.2021.104319)","first_N":5,"first_N_keywords":["cc-by-4.0","100K - 1M","Tabular","Text","Geospatial"],"keywords_longer_than_N":true},
	{"name":"airbnb","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kraina/airbnb","creator_name":"Kraina","creator_url":"https://huggingface.co/kraina","description":"This dataset contains accommodation offers from the AirBnb platform from 10 European cities.\nIt has been copied from https://zenodo.org/record/4446043#.ZEV8d-zMI-R to make it available as a Huggingface Dataset.\nIt was originally published as supplementary material for the article: Determinants of Airbnb prices in European cities: A spatial econometrics approach\n(DOI: https://doi.org/10.1016/j.tourman.2021.104319)","first_N":5,"first_N_keywords":["cc-by-4.0","100K - 1M","Tabular","Text","Geospatial"],"keywords_longer_than_N":true},
	{"name":"tutorial-senegal-lcluc","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nasa-cisto-data-science-group/tutorial-senegal-lcluc","creator_name":"NASA CISTO Data Science Group","creator_url":"https://huggingface.co/nasa-cisto-data-science-group","description":"nasa-cisto-data-science-group/tutorial-senegal-lcluc dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","Geospatial","Image"],"keywords_longer_than_N":true},
	{"name":"SODA-A","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/satellite-image-deep-learning/SODA-A","creator_name":"satellite-image-deep-learning","creator_url":"https://huggingface.co/satellite-image-deep-learning","description":"SODA-A comprises 2513 high-resolution images of aerial scenes, which has 872069 instances annotated with oriented rectangle box annotations over 9 classes. \n\nWebsite\n\n\n","first_N":5,"first_N_keywords":["mit","Image","Geospatial","üá∫üá∏ Region: US","remote-sensing"],"keywords_longer_than_N":true},
	{"name":"SODA-A","keyword":"remote-sensing","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/satellite-image-deep-learning/SODA-A","creator_name":"satellite-image-deep-learning","creator_url":"https://huggingface.co/satellite-image-deep-learning","description":"SODA-A comprises 2513 high-resolution images of aerial scenes, which has 872069 instances annotated with oriented rectangle box annotations over 9 classes. \n\nWebsite\n\n\n","first_N":5,"first_N_keywords":["mit","Image","Geospatial","üá∫üá∏ Region: US","remote-sensing"],"keywords_longer_than_N":true},
	{"name":"MMMU","keyword":"geography","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aslessor/MMMU","creator_name":"Alex","creator_url":"https://huggingface.co/aslessor","description":"\n\t\n\t\t\n\t\tMMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI)\n\t\n\nüåê Homepage | ü§ó Dataset | ü§ó Paper | üìñ arXiv | GitHub\n\n\t\n\t\t\n\t\n\t\n\t\tüîîNews\n\t\n\n\nüî•[2023-12-04]: Our evaluation server for test set is now availble on EvalAI. We welcome all submissions and look forward to your participation! üòÜ\n\n\n\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe introduce MMMU: a new benchmark designed to evaluate multimodal models on massive multi-discipline‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aslessor/MMMU.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"DOTAv2","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/satellite-image-deep-learning/DOTAv2","creator_name":"satellite-image-deep-learning","creator_url":"https://huggingface.co/satellite-image-deep-learning","description":"DOTA v2 Dataset with OBB, specifically the version from the Ultralytics docs\n\nWebsite\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tFull License\n\t\n\nHere reproduced from the website webpage\nLicense for Academic Non-Commercial Use Only\nThis DOTA dataset is made available under the following terms:\n\nThe Google Earth images in this dataset are subject to Google Earth's terms of use, which must be adhered to.\nThe GF-2 and JL-1 satellite images are provided by the China Centre for Resources Satellite Data and Application. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/satellite-image-deep-learning/DOTAv2.","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","imagefolder","Image","Text"],"keywords_longer_than_N":true},
	{"name":"DOTAv2","keyword":"remote-sensing","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/satellite-image-deep-learning/DOTAv2","creator_name":"satellite-image-deep-learning","creator_url":"https://huggingface.co/satellite-image-deep-learning","description":"DOTA v2 Dataset with OBB, specifically the version from the Ultralytics docs\n\nWebsite\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tFull License\n\t\n\nHere reproduced from the website webpage\nLicense for Academic Non-Commercial Use Only\nThis DOTA dataset is made available under the following terms:\n\nThe Google Earth images in this dataset are subject to Google Earth's terms of use, which must be adhered to.\nThe GF-2 and JL-1 satellite images are provided by the China Centre for Resources Satellite Data and Application. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/satellite-image-deep-learning/DOTAv2.","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","imagefolder","Image","Text"],"keywords_longer_than_N":true},
	{"name":"msi-drone-crop-surveys","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/su-fmi/msi-drone-crop-surveys","creator_name":"Sofia University, Faculty of Mathematics and Informatics","creator_url":"https://huggingface.co/su-fmi","description":"\n\t\n\t\t\n\t\tDataset Metadata\n\t\n\n\n\t\n\t\t\n\t\tIdentification Information\n\t\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\n\nTitle:Aerial surveys of a sunflower crop‚Äôs lifecycle from April to September 2023  \nOriginator: Sofia University - Faculty of Mathematics and Informatics, SAP LABS Bulgaria \nPublication Date: 2023.11.08\n\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nEfficient food production is shaping up to be one of the new frontiers for new technologies and solutions. One such prominent domain is the remote sensing ecosystem, and more precicely‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/su-fmi/msi-drone-crop-surveys.","first_N":5,"first_N_keywords":["English","cc-by-4.0","1K - 10K","imagefolder","Geospatial"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_seasons","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yachay/text_coordinates_seasons","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\n\t\n\t\t\n\t\tDataset Card for Geo-Tagged Social Media Posts with Timestamps\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Seasons\" dataset is a collection of over 600,000 social media posts spanning 12 months and encompassing 15 distinct time zones. It focuses on six countries: Cuba, Iran, Russia, North Korea, Syria, and Venezuela, with each post containing textual content, timestamps, and geographical coordinates. The dataset's primary objective is to investigate the correlation between the timing of posts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_seasons.","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_seasons","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yachay/text_coordinates_seasons","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\n\t\n\t\t\n\t\tDataset Card for Geo-Tagged Social Media Posts with Timestamps\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Seasons\" dataset is a collection of over 600,000 social media posts spanning 12 months and encompassing 15 distinct time zones. It focuses on six countries: Cuba, Iran, Russia, North Korea, Syria, and Venezuela, with each post containing textual content, timestamps, and geographical coordinates. The dataset's primary objective is to investigate the correlation between the timing of posts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_seasons.","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_regions","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Regions\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\nKey Features:\n\nTextual Data: The dataset contains 500,000 text samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_regions","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Regions\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\nKey Features:\n\nTextual Data: The dataset contains 500,000 text samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"Core-S1RTC","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S1RTC","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\t\n\t\t\n\t\tCore-S1RTC\n\t\n\nContains a global coverage of Sentinel-1 (RTC) patches, each of size 1,068 x 1,068 pixels.\n\n\t\n\t\t\nSource\nSensing Type\nNumber of Patches\nPatch Size\nTotal Pixels\n\n\n\t\t\nSentinel-1 RTC\nSynthetic Aperture Radar\n1,469,955\n1,068 x 1,068 (10 m)\n> 1.676 Trillion\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nColumn\nDetails\nResolution\n\n\n\t\t\nVV\nReceived Linear Power in the VV Polarization\n10m\n\n\nVH\nReceived Linear Power in the VV Polarization\n10m\n\n\nthumbnail\nRescaled false colour1 saved as png\n10m1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S1RTC.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1M - 10M","parquet","Image","Tabular"],"keywords_longer_than_N":true},
	{"name":"Core-S1RTC","keyword":"earth-observation","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S1RTC","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\t\n\t\t\n\t\tCore-S1RTC\n\t\n\nContains a global coverage of Sentinel-1 (RTC) patches, each of size 1,068 x 1,068 pixels.\n\n\t\n\t\t\nSource\nSensing Type\nNumber of Patches\nPatch Size\nTotal Pixels\n\n\n\t\t\nSentinel-1 RTC\nSynthetic Aperture Radar\n1,469,955\n1,068 x 1,068 (10 m)\n> 1.676 Trillion\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nColumn\nDetails\nResolution\n\n\n\t\t\nVV\nReceived Linear Power in the VV Polarization\n10m\n\n\nVH\nReceived Linear Power in the VV Polarization\n10m\n\n\nthumbnail\nRescaled false colour1 saved as png\n10m1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S1RTC.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1M - 10M","parquet","Image","Tabular"],"keywords_longer_than_N":true},
	{"name":"Core-S1RTC","keyword":"remote-sensing","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S1RTC","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\t\n\t\t\n\t\tCore-S1RTC\n\t\n\nContains a global coverage of Sentinel-1 (RTC) patches, each of size 1,068 x 1,068 pixels.\n\n\t\n\t\t\nSource\nSensing Type\nNumber of Patches\nPatch Size\nTotal Pixels\n\n\n\t\t\nSentinel-1 RTC\nSynthetic Aperture Radar\n1,469,955\n1,068 x 1,068 (10 m)\n> 1.676 Trillion\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nColumn\nDetails\nResolution\n\n\n\t\t\nVV\nReceived Linear Power in the VV Polarization\n10m\n\n\nVH\nReceived Linear Power in the VV Polarization\n10m\n\n\nthumbnail\nRescaled false colour1 saved as png\n10m1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S1RTC.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1M - 10M","parquet","Image","Tabular"],"keywords_longer_than_N":true},
	{"name":"Core-S1RTC","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S1RTC","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\t\n\t\t\n\t\tCore-S1RTC\n\t\n\nContains a global coverage of Sentinel-1 (RTC) patches, each of size 1,068 x 1,068 pixels.\n\n\t\n\t\t\nSource\nSensing Type\nNumber of Patches\nPatch Size\nTotal Pixels\n\n\n\t\t\nSentinel-1 RTC\nSynthetic Aperture Radar\n1,469,955\n1,068 x 1,068 (10 m)\n> 1.676 Trillion\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nColumn\nDetails\nResolution\n\n\n\t\t\nVV\nReceived Linear Power in the VV Polarization\n10m\n\n\nVH\nReceived Linear Power in the VV Polarization\n10m\n\n\nthumbnail\nRescaled false colour1 saved as png\n10m1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S1RTC.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1M - 10M","parquet","Image","Tabular"],"keywords_longer_than_N":true},
	{"name":"CellularTrafficPrediction","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/GreatLove/CellularTrafficPrediction","creator_name":"Great Love Immortal Venerable ü•∞","creator_url":"https://huggingface.co/GreatLove","description":"GreatLove/CellularTrafficPrediction dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10M - 100M","csv","Geospatial","Tabular"],"keywords_longer_than_N":true},
	{"name":"airbnb-usa-co-denver","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michaelmallari/airbnb-usa-co-denver","creator_name":"Michael Mallari","creator_url":"https://huggingface.co/michaelmallari","description":"michaelmallari/airbnb-usa-co-denver dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"airbnb-usa-nc-asheville","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michaelmallari/airbnb-usa-nc-asheville","creator_name":"Michael Mallari","creator_url":"https://huggingface.co/michaelmallari","description":"michaelmallari/airbnb-usa-nc-asheville dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"airbnb-usa-tx-austin","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michaelmallari/airbnb-usa-tx-austin","creator_name":"Michael Mallari","creator_url":"https://huggingface.co/michaelmallari","description":"michaelmallari/airbnb-usa-tx-austin dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"airbnb-usa-mt-bozeman","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michaelmallari/airbnb-usa-mt-bozeman","creator_name":"Michael Mallari","creator_url":"https://huggingface.co/michaelmallari","description":"michaelmallari/airbnb-usa-mt-bozeman dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"airbnb-usa-tn-nashville","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michaelmallari/airbnb-usa-tn-nashville","creator_name":"Michael Mallari","creator_url":"https://huggingface.co/michaelmallari","description":"michaelmallari/airbnb-usa-tn-nashville dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"airbnb-usa-ny-newyork","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michaelmallari/airbnb-usa-ny-newyork","creator_name":"Michael Mallari","creator_url":"https://huggingface.co/michaelmallari","description":"michaelmallari/airbnb-usa-ny-newyork dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"airbnb-usa-or-portland","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michaelmallari/airbnb-usa-or-portland","creator_name":"Michael Mallari","creator_url":"https://huggingface.co/michaelmallari","description":"michaelmallari/airbnb-usa-or-portland dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"airbnb-usa-ri","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michaelmallari/airbnb-usa-ri","creator_name":"Michael Mallari","creator_url":"https://huggingface.co/michaelmallari","description":"michaelmallari/airbnb-usa-ri dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"airbnb-usa-hi","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michaelmallari/airbnb-usa-hi","creator_name":"Michael Mallari","creator_url":"https://huggingface.co/michaelmallari","description":"michaelmallari/airbnb-usa-hi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"airbnb-usa-ca-sandiego","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michaelmallari/airbnb-usa-ca-sandiego","creator_name":"Michael Mallari","creator_url":"https://huggingface.co/michaelmallari","description":"michaelmallari/airbnb-usa-ca-sandiego dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"airbnb-usa-mn-twincities","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michaelmallari/airbnb-usa-mn-twincities","creator_name":"Michael Mallari","creator_url":"https://huggingface.co/michaelmallari","description":"michaelmallari/airbnb-usa-mn-twincities dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"airbnb-ca-on-toronto","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michaelmallari/airbnb-ca-on-toronto","creator_name":"Michael Mallari","creator_url":"https://huggingface.co/michaelmallari","description":"michaelmallari/airbnb-ca-on-toronto dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"airbnb-ca-mb-winnipeg","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michaelmallari/airbnb-ca-mb-winnipeg","creator_name":"Michael Mallari","creator_url":"https://huggingface.co/michaelmallari","description":"michaelmallari/airbnb-ca-mb-winnipeg dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"airbnb-ca-bc-vancouver","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michaelmallari/airbnb-ca-bc-vancouver","creator_name":"Michael Mallari","creator_url":"https://huggingface.co/michaelmallari","description":"michaelmallari/airbnb-ca-bc-vancouver dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"airbnb-usa-dc-washington","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michaelmallari/airbnb-usa-dc-washington","creator_name":"Michael Mallari","creator_url":"https://huggingface.co/michaelmallari","description":"michaelmallari/airbnb-usa-dc-washington dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"JL1-CD","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/circleLZY/JL1-CD","creator_name":"Ziyuan Liu","creator_url":"https://huggingface.co/circleLZY","description":"\n\t\n\t\t\n\t\tDataset Card for JL1-CD\n\t\n\n\n\t\n\t\t\n\t\tDataset Description (English)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nJL1-CD is a large-scale, sub-meter, all-inclusive open-source dataset for remote sensing image change detection (CD). It contains 5,000 pairs of 512√ó512 pixel satellite images with a resolution of 0.5 to 0.75 meters, covering various types of surface changes in multiple regions of China. JL1-CD includes not only common human-induced changes (e.g., buildings, roads) but also natural changes (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/circleLZY/JL1-CD.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","English","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"JL1-CD","keyword":"remote-sensing","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/circleLZY/JL1-CD","creator_name":"Ziyuan Liu","creator_url":"https://huggingface.co/circleLZY","description":"\n\t\n\t\t\n\t\tDataset Card for JL1-CD\n\t\n\n\n\t\n\t\t\n\t\tDataset Description (English)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nJL1-CD is a large-scale, sub-meter, all-inclusive open-source dataset for remote sensing image change detection (CD). It contains 5,000 pairs of 512√ó512 pixel satellite images with a resolution of 0.5 to 0.75 meters, covering various types of surface changes in multiple regions of China. JL1-CD includes not only common human-induced changes (e.g., buildings, roads) but also natural changes (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/circleLZY/JL1-CD.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","English","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"Geonames","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/do-me/Geonames","creator_name":"Dominik Weckm√ºller","creator_url":"https://huggingface.co/do-me","description":"\n\t\n\t\t\n\t\tGeonames\n\t\n\nA simple parquet conversion of Geonames place database and ZIP codes. \n\n\t\n\t\t\n\t\tSource\n\t\n\nThe tab-separated, zipped textfiles allCountries.zip from:\n\nhttps://download.geonames.org/export/dump/ and\nhttps://download.geonames.org/export/zip/.\n\n\n\t\n\t\t\n\t\tColumns\n\t\n\nallCountries.zip\nThe main 'geoname' table has the following fields :\n---------------------------------------------------\ngeonameid         : integer id of record in geonames database\nname              : name of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/do-me/Geonames.","first_N":5,"first_N_keywords":["cc-by-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Geonames","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/do-me/Geonames","creator_name":"Dominik Weckm√ºller","creator_url":"https://huggingface.co/do-me","description":"\n\t\n\t\t\n\t\tGeonames\n\t\n\nA simple parquet conversion of Geonames place database and ZIP codes. \n\n\t\n\t\t\n\t\tSource\n\t\n\nThe tab-separated, zipped textfiles allCountries.zip from:\n\nhttps://download.geonames.org/export/dump/ and\nhttps://download.geonames.org/export/zip/.\n\n\n\t\n\t\t\n\t\tColumns\n\t\n\nallCountries.zip\nThe main 'geoname' table has the following fields :\n---------------------------------------------------\ngeonameid         : integer id of record in geonames database\nname              : name of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/do-me/Geonames.","first_N":5,"first_N_keywords":["cc-by-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"devbox","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jacktang/devbox","creator_name":"jack tang","creator_url":"https://huggingface.co/jacktang","description":"jacktang/devbox dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","Geospatial","Image"],"keywords_longer_than_N":true},
	{"name":"DurhamTrees","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ziyuan111/DurhamTrees","creator_name":"Ma","creator_url":"https://huggingface.co/Ziyuan111","description":"\n\t\n\t\t\n\t\tDurham Urban Canopy Analysis and Enhancement Initiative (DUCAEI)\n\t\n\nThe Class is a custom dataset class that brings together information from two distinct domains into a unified dataset. \nThis class is designed to streamline the process of working with data from different sources and enable users to seamlessly access and analyze combined datasets.\n\n\t\n\t\t\n\t\tProject Overview\n\t\n\n\n(I also upload a seperate analysis .py file to show some visualization)\nThe Durham Urban Canopy Analysis and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ziyuan111/DurhamTrees.","first_N":5,"first_N_keywords":["token-classification","table-question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Core-S2L2A","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2L2A","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\t\n\t\t\n\t\tCore-S2L2A\n\t\n\nContains a global coverage of Sentinel-2 (Level 2A) patches, each of size 1,068 x 1,068 pixels.\n\n\t\n\t\t\nSource\nSensing Type\nNumber of Patches\nPatch Size\nTotal Pixels\n\n\n\t\t\nSentinel-2 Level-2A\nOptical Multispectral\n2,245,886\n1,068 x 1,068 (10 m)\n> 2.564 Trillion\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nColumn\nDetails\nResolution\n\n\n\t\t\nB01\nCoastal aerosol, 442.7 nm (S2A), 442.3 nm (S2B)\n60m\n\n\nB02\nBlue, 492.4 nm (S2A), 492.1 nm (S2B)\n10m\n\n\nB03\nGreen, 559.8 nm (S2A), 559.0 nm (S2B)\n10m‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2L2A.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1M - 10M","parquet","Image","Tabular"],"keywords_longer_than_N":true},
	{"name":"Core-S2L2A","keyword":"earth-observation","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2L2A","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\t\n\t\t\n\t\tCore-S2L2A\n\t\n\nContains a global coverage of Sentinel-2 (Level 2A) patches, each of size 1,068 x 1,068 pixels.\n\n\t\n\t\t\nSource\nSensing Type\nNumber of Patches\nPatch Size\nTotal Pixels\n\n\n\t\t\nSentinel-2 Level-2A\nOptical Multispectral\n2,245,886\n1,068 x 1,068 (10 m)\n> 2.564 Trillion\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nColumn\nDetails\nResolution\n\n\n\t\t\nB01\nCoastal aerosol, 442.7 nm (S2A), 442.3 nm (S2B)\n60m\n\n\nB02\nBlue, 492.4 nm (S2A), 492.1 nm (S2B)\n10m\n\n\nB03\nGreen, 559.8 nm (S2A), 559.0 nm (S2B)\n10m‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2L2A.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1M - 10M","parquet","Image","Tabular"],"keywords_longer_than_N":true},
	{"name":"Core-S2L2A","keyword":"remote-sensing","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2L2A","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\t\n\t\t\n\t\tCore-S2L2A\n\t\n\nContains a global coverage of Sentinel-2 (Level 2A) patches, each of size 1,068 x 1,068 pixels.\n\n\t\n\t\t\nSource\nSensing Type\nNumber of Patches\nPatch Size\nTotal Pixels\n\n\n\t\t\nSentinel-2 Level-2A\nOptical Multispectral\n2,245,886\n1,068 x 1,068 (10 m)\n> 2.564 Trillion\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nColumn\nDetails\nResolution\n\n\n\t\t\nB01\nCoastal aerosol, 442.7 nm (S2A), 442.3 nm (S2B)\n60m\n\n\nB02\nBlue, 492.4 nm (S2A), 492.1 nm (S2B)\n10m\n\n\nB03\nGreen, 559.8 nm (S2A), 559.0 nm (S2B)\n10m‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2L2A.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1M - 10M","parquet","Image","Tabular"],"keywords_longer_than_N":true},
	{"name":"Core-S2L2A","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2L2A","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\t\n\t\t\n\t\tCore-S2L2A\n\t\n\nContains a global coverage of Sentinel-2 (Level 2A) patches, each of size 1,068 x 1,068 pixels.\n\n\t\n\t\t\nSource\nSensing Type\nNumber of Patches\nPatch Size\nTotal Pixels\n\n\n\t\t\nSentinel-2 Level-2A\nOptical Multispectral\n2,245,886\n1,068 x 1,068 (10 m)\n> 2.564 Trillion\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nColumn\nDetails\nResolution\n\n\n\t\t\nB01\nCoastal aerosol, 442.7 nm (S2A), 442.3 nm (S2B)\n60m\n\n\nB02\nBlue, 492.4 nm (S2A), 492.1 nm (S2B)\n10m\n\n\nB03\nGreen, 559.8 nm (S2A), 559.0 nm (S2B)\n10m‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2L2A.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1M - 10M","parquet","Image","Tabular"],"keywords_longer_than_N":true},
	{"name":"geosql-llm-eval","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/naamche/geosql-llm-eval","creator_name":"Naamche","creator_url":"https://huggingface.co/naamche","description":"This is a dataset made for the purpose of evaluating Text-to-SQL systems for geography-based applications.\nCurrently, we have only released 109 examples of natural_language, sql_query pairs.\nSteps:\n\nFirst, unzip all the .shp files and load them into your postgres database instance.\nLoad the text,sql pair from the .csv file into your desired program.\nGenerate SQL for the questions using your own LLM and compare the results any way you like.\n\n###REQUIREMENTS.\n\nYou need postgres SQL installed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/naamche/geosql-llm-eval.","first_N":5,"first_N_keywords":["English","mit","n<1K","Geospatial","Text"],"keywords_longer_than_N":true},
	{"name":"sentinel_trajectory_ist_mont","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/negengec/sentinel_trajectory_ist_mont","creator_name":"Necip Enes Genge√ß","creator_url":"https://huggingface.co/negengec","description":"negengec/sentinel_trajectory_ist_mont dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["image-segmentation","cc-by-4.0","Geospatial","üá∫üá∏ Region: US","remote-sensing"],"keywords_longer_than_N":true},
	{"name":"sentinel_trajectory_ist_mont","keyword":"remote-sensing","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/negengec/sentinel_trajectory_ist_mont","creator_name":"Necip Enes Genge√ß","creator_url":"https://huggingface.co/negengec","description":"negengec/sentinel_trajectory_ist_mont dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["image-segmentation","cc-by-4.0","Geospatial","üá∫üá∏ Region: US","remote-sensing"],"keywords_longer_than_N":true},
	{"name":"Core-S2L1C","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2L1C","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\t\n\t\t\n\t\tCore-S2L1C\n\t\n\nContains a global coverage of Sentinel-2 (Level 1C) patches, each of size 1,068 x 1,068 pixels.\n\n\t\n\t\t\nSource\nSensing Type\nNumber of Patches\nPatch Size\nTotal Pixels\n\n\n\t\t\nSentinel-2 Level-1C\nOptical Multispectral\n2,245,886\n1,068x1,068\n2.56 Trillion\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nColumn\nDetails\nResolution\n\n\n\t\t\nB01\nCoastal aerosol, 442.7 nm (S2A), 442.3 nm (S2B)\n60m\n\n\nB02\nBlue, 492.4 nm (S2A), 492.1 nm (S2B)\n10m\n\n\nB03\nGreen, 559.8 nm (S2A), 559.0 nm (S2B)\n10m\n\n\nB04\nRed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2L1C.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1M - 10M","parquet","Image","Tabular"],"keywords_longer_than_N":true},
	{"name":"Core-S2L1C","keyword":"earth-observation","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2L1C","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\t\n\t\t\n\t\tCore-S2L1C\n\t\n\nContains a global coverage of Sentinel-2 (Level 1C) patches, each of size 1,068 x 1,068 pixels.\n\n\t\n\t\t\nSource\nSensing Type\nNumber of Patches\nPatch Size\nTotal Pixels\n\n\n\t\t\nSentinel-2 Level-1C\nOptical Multispectral\n2,245,886\n1,068x1,068\n2.56 Trillion\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nColumn\nDetails\nResolution\n\n\n\t\t\nB01\nCoastal aerosol, 442.7 nm (S2A), 442.3 nm (S2B)\n60m\n\n\nB02\nBlue, 492.4 nm (S2A), 492.1 nm (S2B)\n10m\n\n\nB03\nGreen, 559.8 nm (S2A), 559.0 nm (S2B)\n10m\n\n\nB04\nRed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2L1C.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1M - 10M","parquet","Image","Tabular"],"keywords_longer_than_N":true},
	{"name":"Core-S2L1C","keyword":"remote-sensing","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2L1C","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\t\n\t\t\n\t\tCore-S2L1C\n\t\n\nContains a global coverage of Sentinel-2 (Level 1C) patches, each of size 1,068 x 1,068 pixels.\n\n\t\n\t\t\nSource\nSensing Type\nNumber of Patches\nPatch Size\nTotal Pixels\n\n\n\t\t\nSentinel-2 Level-1C\nOptical Multispectral\n2,245,886\n1,068x1,068\n2.56 Trillion\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nColumn\nDetails\nResolution\n\n\n\t\t\nB01\nCoastal aerosol, 442.7 nm (S2A), 442.3 nm (S2B)\n60m\n\n\nB02\nBlue, 492.4 nm (S2A), 492.1 nm (S2B)\n10m\n\n\nB03\nGreen, 559.8 nm (S2A), 559.0 nm (S2B)\n10m\n\n\nB04\nRed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2L1C.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1M - 10M","parquet","Image","Tabular"],"keywords_longer_than_N":true},
	{"name":"Core-S2L1C","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2L1C","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\t\n\t\t\n\t\tCore-S2L1C\n\t\n\nContains a global coverage of Sentinel-2 (Level 1C) patches, each of size 1,068 x 1,068 pixels.\n\n\t\n\t\t\nSource\nSensing Type\nNumber of Patches\nPatch Size\nTotal Pixels\n\n\n\t\t\nSentinel-2 Level-1C\nOptical Multispectral\n2,245,886\n1,068x1,068\n2.56 Trillion\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nColumn\nDetails\nResolution\n\n\n\t\t\nB01\nCoastal aerosol, 442.7 nm (S2A), 442.3 nm (S2B)\n60m\n\n\nB02\nBlue, 492.4 nm (S2A), 492.1 nm (S2B)\n10m\n\n\nB03\nGreen, 559.8 nm (S2A), 559.0 nm (S2B)\n10m\n\n\nB04\nRed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2L1C.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1M - 10M","parquet","Image","Tabular"],"keywords_longer_than_N":true},
	{"name":"govgis_nov2023","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/joshuasundance/govgis_nov2023","creator_name":"Joshua Sundance Bailey","creator_url":"https://huggingface.co/joshuasundance","description":"\n\t\n\t\t\n\t\n\t\n\t\tgovgis_nov2023\n\t\n\nü§ñ This README was written by GPT-4. ü§ñ\ngovgis_nov2023 is an extensive compilation of metadata, documenting geospatial data from known government servers as of November 15 2023. This should provide a rich resource for GIS analysis, research, and application development.\nThese datasets contain data from various Federal, State, County, and City ArcGIS Servers listed by Joseph Elfelt of Mapping Support. It serves as a unique snapshot capturing the state of these‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joshuasundance/govgis_nov2023.","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"govgis_nov2023","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/joshuasundance/govgis_nov2023","creator_name":"Joshua Sundance Bailey","creator_url":"https://huggingface.co/joshuasundance","description":"\n\t\n\t\t\n\t\n\t\n\t\tgovgis_nov2023\n\t\n\nü§ñ This README was written by GPT-4. ü§ñ\ngovgis_nov2023 is an extensive compilation of metadata, documenting geospatial data from known government servers as of November 15 2023. This should provide a rich resource for GIS analysis, research, and application development.\nThese datasets contain data from various Federal, State, County, and City ArcGIS Servers listed by Joseph Elfelt of Mapping Support. It serves as a unique snapshot capturing the state of these‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joshuasundance/govgis_nov2023.","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"CovidCases.csv","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fadingNA/CovidCases.csv","creator_name":"Nonthachai Plodthong","creator_url":"https://huggingface.co/fadingNA","description":"fadingNA/CovidCases.csv dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"govgis_nov2023-slim-spatial","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/joshuasundance/govgis_nov2023-slim-spatial","creator_name":"Joshua Sundance Bailey","creator_url":"https://huggingface.co/joshuasundance","description":"\n\t\n\t\t\n\t\n\t\n\t\tgovgis_nov2023-slim-spatial\n\t\n\nü§ñ This README was written by HuggingFaceH4/zephyr-7b-beta. ü§ñ\nIntroducing the govgis_nov2023-slim-spatial dataset, a carefully curated and georeferenced subset of the extensive govgis_nov2023 collection. This dataset stands out for its focus on geospatial data analysis, enriched with vector embeddings. While we have only explored a portion of this vast collection, the variety and richness of the content encountered have been remarkable, making it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joshuasundance/govgis_nov2023-slim-spatial.","first_N":5,"first_N_keywords":["English","mit","100K<n<1M","Geospatial","doi:10.57967/hf/1369"],"keywords_longer_than_N":true},
	{"name":"govgis_nov2023-slim-spatial","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/joshuasundance/govgis_nov2023-slim-spatial","creator_name":"Joshua Sundance Bailey","creator_url":"https://huggingface.co/joshuasundance","description":"\n\t\n\t\t\n\t\n\t\n\t\tgovgis_nov2023-slim-spatial\n\t\n\nü§ñ This README was written by HuggingFaceH4/zephyr-7b-beta. ü§ñ\nIntroducing the govgis_nov2023-slim-spatial dataset, a carefully curated and georeferenced subset of the extensive govgis_nov2023 collection. This dataset stands out for its focus on geospatial data analysis, enriched with vector embeddings. While we have only explored a portion of this vast collection, the variety and richness of the content encountered have been remarkable, making it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joshuasundance/govgis_nov2023-slim-spatial.","first_N":5,"first_N_keywords":["English","mit","100K<n<1M","Geospatial","doi:10.57967/hf/1369"],"keywords_longer_than_N":true},
	{"name":"StreetView360AtoZ","keyword":"geography","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/everettshen/StreetView360AtoZ","creator_name":"Everett Shen","creator_url":"https://huggingface.co/everettshen","description":"StreetView 360X is a dataset containing 6342 360 degree equirectangular street view images randomly sampled and downloaded from Google Street View. It is published as part of the paper \"StreetView360X: A Location-Conditioned Latent Diffusion Model for Generating Equirectangular 360 Degree Street Views\" (Princeton COS Senior Independent Work by Everett Shen). Images are labelled with their capture coordinates and panorama IDs. Scripts for extending the dataset (i.e. fetching additional images)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/everettshen/StreetView360AtoZ.","first_N":5,"first_N_keywords":["text-to-image","image-classification","image-to-text","image-feature-extraction","mit"],"keywords_longer_than_N":true},
	{"name":"eco_composition","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lauransotomayor/eco_composition","creator_name":"Laura Sotomayor","creator_url":"https://huggingface.co/lauransotomayor","description":"Data sample for testing DL code\n","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","Geospatial","Image"],"keywords_longer_than_N":true},
	{"name":"Copernicus-Pretrain","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wangyi111/Copernicus-Pretrain","creator_name":"Yi Wang","creator_url":"https://huggingface.co/wangyi111","description":"\n\t\n\t\t\n\t\tDataset Card for Copernicus-Pretrain\n\t\n\n\n\nCopernicus-Pretrain is a large-scale EO pretraining dataset with 18.7M aligned images covering all major Sentinel missions (S1,2,3,5P).\nOfficially named Copernicus-Pretrain, also referred to as SSL4EO-S (\"S\" means Sentinel), as an extension of SSL4EO-S12 to the whole Sentinel series.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\nCopernicus-Pretrain contains 18.7M aligned imagery from all major Sentinel missions in operation (Sentinel-1 SAR, Sentinel-2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wangyi111/Copernicus-Pretrain.","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","cc-by-4.0","10M<n<100M","Geospatial"],"keywords_longer_than_N":true},
	{"name":"Copernicus-Pretrain","keyword":"earth-observation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wangyi111/Copernicus-Pretrain","creator_name":"Yi Wang","creator_url":"https://huggingface.co/wangyi111","description":"\n\t\n\t\t\n\t\tDataset Card for Copernicus-Pretrain\n\t\n\n\n\nCopernicus-Pretrain is a large-scale EO pretraining dataset with 18.7M aligned images covering all major Sentinel missions (S1,2,3,5P).\nOfficially named Copernicus-Pretrain, also referred to as SSL4EO-S (\"S\" means Sentinel), as an extension of SSL4EO-S12 to the whole Sentinel series.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\nCopernicus-Pretrain contains 18.7M aligned imagery from all major Sentinel missions in operation (Sentinel-1 SAR, Sentinel-2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wangyi111/Copernicus-Pretrain.","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","cc-by-4.0","10M<n<100M","Geospatial"],"keywords_longer_than_N":true},
	{"name":"Copernicus-Pretrain","keyword":"remote-sensing","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wangyi111/Copernicus-Pretrain","creator_name":"Yi Wang","creator_url":"https://huggingface.co/wangyi111","description":"\n\t\n\t\t\n\t\tDataset Card for Copernicus-Pretrain\n\t\n\n\n\nCopernicus-Pretrain is a large-scale EO pretraining dataset with 18.7M aligned images covering all major Sentinel missions (S1,2,3,5P).\nOfficially named Copernicus-Pretrain, also referred to as SSL4EO-S (\"S\" means Sentinel), as an extension of SSL4EO-S12 to the whole Sentinel series.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\nCopernicus-Pretrain contains 18.7M aligned imagery from all major Sentinel missions in operation (Sentinel-1 SAR, Sentinel-2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wangyi111/Copernicus-Pretrain.","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","cc-by-4.0","10M<n<100M","Geospatial"],"keywords_longer_than_N":true},
	{"name":"classify-embeddings-sf-baseball-marinas","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/made-with-clay/classify-embeddings-sf-baseball-marinas","creator_name":"Clay Foundation","creator_url":"https://huggingface.co/made-with-clay","description":"made-with-clay/classify-embeddings-sf-baseball-marinas dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","10K - 100K","parquet","Geospatial","Text"],"keywords_longer_than_N":true},
	{"name":"ImageConfounding","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cjerzak/ImageConfounding","creator_name":"Connor T. Jerzak","creator_url":"https://huggingface.co/cjerzak","description":"\nReplication Data for:  Integrating Earth Observation Data into Causal Inference: Challenges and Opportunities \nDetails:\nYandW_mat.csv contains individual-level observational data. In the dataset, LONGITUDE and LATITUDE refer to the approximate geo-referenced long/lat of observational units.  Experimental outcomes are stored in Yobs. The treatment variable is stored in Wobs. The unique image key for each observational unit is saved in UNIQUE_ID.\nGeo-referenced satellite images are saved in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cjerzak/ImageConfounding.","first_N":5,"first_N_keywords":["mit","1K - 10K","csv","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"ImageConfounding","keyword":"earth-observation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cjerzak/ImageConfounding","creator_name":"Connor T. Jerzak","creator_url":"https://huggingface.co/cjerzak","description":"\nReplication Data for:  Integrating Earth Observation Data into Causal Inference: Challenges and Opportunities \nDetails:\nYandW_mat.csv contains individual-level observational data. In the dataset, LONGITUDE and LATITUDE refer to the approximate geo-referenced long/lat of observational units.  Experimental outcomes are stored in Yobs. The treatment variable is stored in Wobs. The unique image key for each observational unit is saved in UNIQUE_ID.\nGeo-referenced satellite images are saved in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cjerzak/ImageConfounding.","first_N":5,"first_N_keywords":["mit","1K - 10K","csv","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"ImageConfounding","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cjerzak/ImageConfounding","creator_name":"Connor T. Jerzak","creator_url":"https://huggingface.co/cjerzak","description":"\nReplication Data for:  Integrating Earth Observation Data into Causal Inference: Challenges and Opportunities \nDetails:\nYandW_mat.csv contains individual-level observational data. In the dataset, LONGITUDE and LATITUDE refer to the approximate geo-referenced long/lat of observational units.  Experimental outcomes are stored in Yobs. The treatment variable is stored in Wobs. The unique image key for each observational unit is saved in UNIQUE_ID.\nGeo-referenced satellite images are saved in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cjerzak/ImageConfounding.","first_N":5,"first_N_keywords":["mit","1K - 10K","csv","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"TourismLLMDB","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VaishVV/TourismLLMDB","creator_name":"Vaishnav","creator_url":"https://huggingface.co/VaishVV","description":"VaishVV/TourismLLMDB dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Geospatial","Text"],"keywords_longer_than_N":true},
	{"name":"LandsatQuake","keyword":"geospatial","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Vihaanakshaay/LandsatQuake","creator_name":"Vihaan Akshaay Rajendiran","creator_url":"https://huggingface.co/Vihaanakshaay","description":"Vihaanakshaay/LandsatQuake dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","imagefolder","Geospatial","Image"],"keywords_longer_than_N":true},
	{"name":"Core-DEM","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-DEM","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tMajor TOM Core-DEM\n\t\n\nContains a global coverage of Copernicus DEM, each of size 356 x 356 pixels.\n\n\t\n\t\t\nSource\nModality Type\nNumber of Patches\nPatch Size\nTotal Pixels\n\n\n\t\t\nCopernicus DEM 30\nDigital Surface Model (DSM)\n1,837,843\n356 x 356 (30 m)\n> 1.654 Billion\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nColumn\nDetails\nResolution\nDEM\nOriginal data\n30m\n\n\nthumbnail\ncompressed hillshade visualisation\n30m\n\n\ncompressed\ncompressed png of original data\n30m\n\n\n\t\n\n\n\t\n\t\t\n\t\tSpatial Coverage\n\t\n\nThis is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-DEM.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1M - 10M","parquet","Image","Tabular"],"keywords_longer_than_N":true},
	{"name":"Core-DEM","keyword":"earth-observation","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-DEM","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tMajor TOM Core-DEM\n\t\n\nContains a global coverage of Copernicus DEM, each of size 356 x 356 pixels.\n\n\t\n\t\t\nSource\nModality Type\nNumber of Patches\nPatch Size\nTotal Pixels\n\n\n\t\t\nCopernicus DEM 30\nDigital Surface Model (DSM)\n1,837,843\n356 x 356 (30 m)\n> 1.654 Billion\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nColumn\nDetails\nResolution\nDEM\nOriginal data\n30m\n\n\nthumbnail\ncompressed hillshade visualisation\n30m\n\n\ncompressed\ncompressed png of original data\n30m\n\n\n\t\n\n\n\t\n\t\t\n\t\tSpatial Coverage\n\t\n\nThis is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-DEM.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1M - 10M","parquet","Image","Tabular"],"keywords_longer_than_N":true},
	{"name":"Core-DEM","keyword":"remote-sensing","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-DEM","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tMajor TOM Core-DEM\n\t\n\nContains a global coverage of Copernicus DEM, each of size 356 x 356 pixels.\n\n\t\n\t\t\nSource\nModality Type\nNumber of Patches\nPatch Size\nTotal Pixels\n\n\n\t\t\nCopernicus DEM 30\nDigital Surface Model (DSM)\n1,837,843\n356 x 356 (30 m)\n> 1.654 Billion\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nColumn\nDetails\nResolution\nDEM\nOriginal data\n30m\n\n\nthumbnail\ncompressed hillshade visualisation\n30m\n\n\ncompressed\ncompressed png of original data\n30m\n\n\n\t\n\n\n\t\n\t\t\n\t\tSpatial Coverage\n\t\n\nThis is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-DEM.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1M - 10M","parquet","Image","Tabular"],"keywords_longer_than_N":true},
	{"name":"Core-DEM","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-DEM","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tMajor TOM Core-DEM\n\t\n\nContains a global coverage of Copernicus DEM, each of size 356 x 356 pixels.\n\n\t\n\t\t\nSource\nModality Type\nNumber of Patches\nPatch Size\nTotal Pixels\n\n\n\t\t\nCopernicus DEM 30\nDigital Surface Model (DSM)\n1,837,843\n356 x 356 (30 m)\n> 1.654 Billion\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nColumn\nDetails\nResolution\nDEM\nOriginal data\n30m\n\n\nthumbnail\ncompressed hillshade visualisation\n30m\n\n\ncompressed\ncompressed png of original data\n30m\n\n\n\t\n\n\n\t\n\t\t\n\t\tSpatial Coverage\n\t\n\nThis is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-DEM.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1M - 10M","parquet","Image","Tabular"],"keywords_longer_than_N":true},
	{"name":"us-ev-charging-locations","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cfahlgren1/us-ev-charging-locations","creator_name":"Caleb Fahlgren","creator_url":"https://huggingface.co/cfahlgren1","description":"\n\t\n\t\t\n\t\tUnited States Electric Vehicle Charging Locations\n\t\n\n\n","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","json","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"us-ev-charging-locations","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cfahlgren1/us-ev-charging-locations","creator_name":"Caleb Fahlgren","creator_url":"https://huggingface.co/cfahlgren1","description":"\n\t\n\t\t\n\t\tUnited States Electric Vehicle Charging Locations\n\t\n\n\n","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","json","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"text2geoql","keyword":"geospatial","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/yuiseki/text2geoql","creator_name":"Yui Matsumura","creator_url":"https://huggingface.co/yuiseki","description":"\n\t\n\t\t\n\t\ttext2geoql\n\t\n\n\nI have defined a natural language processing task named text2geoql and am in the process of building a dataset for it\ntext2geoql is a task that translates arbitrary natural language into reasonable geoql based on the intent\ngeoql is an abbreviation for \"Geospatial data query languages\"\nOff course, geoql contains overpassql\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\ttext2geoql-dataset\n\t\n\n\nhttps://github.com/yuiseki/text2geoql-dataset\nThis repository publishes over 1000 Overpass QLs that are paired‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yuiseki/text2geoql.","first_N":5,"first_N_keywords":["English","wtfpl","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"text2geoql","keyword":"geospatial","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/yuiseki/text2geoql","creator_name":"Yui Matsumura","creator_url":"https://huggingface.co/yuiseki","description":"\n\t\n\t\t\n\t\ttext2geoql\n\t\n\n\nI have defined a natural language processing task named text2geoql and am in the process of building a dataset for it\ntext2geoql is a task that translates arbitrary natural language into reasonable geoql based on the intent\ngeoql is an abbreviation for \"Geospatial data query languages\"\nOff course, geoql contains overpassql\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\ttext2geoql-dataset\n\t\n\n\nhttps://github.com/yuiseki/text2geoql-dataset\nThis repository publishes over 1000 Overpass QLs that are paired‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yuiseki/text2geoql.","first_N":5,"first_N_keywords":["English","wtfpl","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"mussel-seg-1024-1024","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HakaiInstitute/mussel-seg-1024-1024","creator_name":"Hakai Institute","creator_url":"https://huggingface.co/HakaiInstitute","description":"\n\t\n\t\t\n\t\tMusselSeg: Semantic Segmentation for Rocky Intertidal Mussel Habitat\n\t\n\n\n\t\n\t\t\n\t\tDataset description\n\t\n\nMusselSeg is a large-scale dataset for semantic segmentation of mussel habitat using high resolution drone imagery. It covers coastal mussel habitat located on the central coast of British Columbia, Canada, as well as areas in California, USA and provides pixel-wise annotation for mussel beds.\n\nSource: Imagery collected by the Hakai Institute and University of California Santa Cruz‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HakaiInstitute/mussel-seg-1024-1024.","first_N":5,"first_N_keywords":["image-segmentation","English","cc-by-4.0","1K - 10K","webdataset"],"keywords_longer_than_N":true},
	{"name":"mussel-seg-1024-1024","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HakaiInstitute/mussel-seg-1024-1024","creator_name":"Hakai Institute","creator_url":"https://huggingface.co/HakaiInstitute","description":"\n\t\n\t\t\n\t\tMusselSeg: Semantic Segmentation for Rocky Intertidal Mussel Habitat\n\t\n\n\n\t\n\t\t\n\t\tDataset description\n\t\n\nMusselSeg is a large-scale dataset for semantic segmentation of mussel habitat using high resolution drone imagery. It covers coastal mussel habitat located on the central coast of British Columbia, Canada, as well as areas in California, USA and provides pixel-wise annotation for mussel beds.\n\nSource: Imagery collected by the Hakai Institute and University of California Santa Cruz‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HakaiInstitute/mussel-seg-1024-1024.","first_N":5,"first_N_keywords":["image-segmentation","English","cc-by-4.0","1K - 10K","webdataset"],"keywords_longer_than_N":true},
	{"name":"CloudSEN12Plus","keyword":"geospatial","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/isp-uv-es/CloudSEN12Plus","creator_name":"Image and Signal Processing ‚Ä¢ ISP","creator_url":"https://huggingface.co/isp-uv-es","description":"\n\t\n\t\t\n\t\tüö® New Dataset Version Released!\n\t\n\n\n\t\n\t\t\n\t\tWe are excited to announce the release of Version [1.1] of our dataset!\n\t\n\n\n\t\n\t\t\n\t\tThis update includes:\n\t\n\n\n[L2A & L1C support].\n[Temporal support].\n[Check the data without downloading (Cloud-optimized properties)].\n\n\n\t\n\t\t\n\t\tüì• Go to: https://huggingface.co/datasets/tacofoundation/cloudsen12 and follow the instructions in colab\n\t\n\n\n\n\n\n\nCloudSEN12+ is a significant extension of the CloudSEN12 dataset, which doubles the number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isp-uv-es/CloudSEN12Plus.","first_N":5,"first_N_keywords":["image-segmentation","English","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"CloudSEN12Plus","keyword":"earth-observation","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/isp-uv-es/CloudSEN12Plus","creator_name":"Image and Signal Processing ‚Ä¢ ISP","creator_url":"https://huggingface.co/isp-uv-es","description":"\n\t\n\t\t\n\t\tüö® New Dataset Version Released!\n\t\n\n\n\t\n\t\t\n\t\tWe are excited to announce the release of Version [1.1] of our dataset!\n\t\n\n\n\t\n\t\t\n\t\tThis update includes:\n\t\n\n\n[L2A & L1C support].\n[Temporal support].\n[Check the data without downloading (Cloud-optimized properties)].\n\n\n\t\n\t\t\n\t\tüì• Go to: https://huggingface.co/datasets/tacofoundation/cloudsen12 and follow the instructions in colab\n\t\n\n\n\n\n\n\nCloudSEN12+ is a significant extension of the CloudSEN12 dataset, which doubles the number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isp-uv-es/CloudSEN12Plus.","first_N":5,"first_N_keywords":["image-segmentation","English","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"CloudSEN12Plus","keyword":"remote-sensing","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/isp-uv-es/CloudSEN12Plus","creator_name":"Image and Signal Processing ‚Ä¢ ISP","creator_url":"https://huggingface.co/isp-uv-es","description":"\n\t\n\t\t\n\t\tüö® New Dataset Version Released!\n\t\n\n\n\t\n\t\t\n\t\tWe are excited to announce the release of Version [1.1] of our dataset!\n\t\n\n\n\t\n\t\t\n\t\tThis update includes:\n\t\n\n\n[L2A & L1C support].\n[Temporal support].\n[Check the data without downloading (Cloud-optimized properties)].\n\n\n\t\n\t\t\n\t\tüì• Go to: https://huggingface.co/datasets/tacofoundation/cloudsen12 and follow the instructions in colab\n\t\n\n\n\n\n\n\nCloudSEN12+ is a significant extension of the CloudSEN12 dataset, which doubles the number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isp-uv-es/CloudSEN12Plus.","first_N":5,"first_N_keywords":["image-segmentation","English","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"CloudSEN12Plus","keyword":"geospatial","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/isp-uv-es/CloudSEN12Plus","creator_name":"Image and Signal Processing ‚Ä¢ ISP","creator_url":"https://huggingface.co/isp-uv-es","description":"\n\t\n\t\t\n\t\tüö® New Dataset Version Released!\n\t\n\n\n\t\n\t\t\n\t\tWe are excited to announce the release of Version [1.1] of our dataset!\n\t\n\n\n\t\n\t\t\n\t\tThis update includes:\n\t\n\n\n[L2A & L1C support].\n[Temporal support].\n[Check the data without downloading (Cloud-optimized properties)].\n\n\n\t\n\t\t\n\t\tüì• Go to: https://huggingface.co/datasets/tacofoundation/cloudsen12 and follow the instructions in colab\n\t\n\n\n\n\n\n\nCloudSEN12+ is a significant extension of the CloudSEN12 dataset, which doubles the number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/isp-uv-es/CloudSEN12Plus.","first_N":5,"first_N_keywords":["image-segmentation","English","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"RSTeller_legacy","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SlytherinGe/RSTeller_legacy","creator_name":"Slytherin Ge","creator_url":"https://huggingface.co/SlytherinGe","description":"\n\t\n\t\t\n\t\t‚õî Usage Warning\n\t\n\nThis is the legacy version of the RSTeller dataset and is not the latest version referenced in our paper. We are keeping it available here to provide the community with easy access to additional data.\nFor the details and the usage of the dataset, please refer to our github page.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you find the dataset and our paper useful, please consider citing our paper:\n@article{ge2025rsteller,\n  title={RSTeller: Scaling up visual language modeling in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SlytherinGe/RSTeller_legacy.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","visual-question-answering","zero-shot-classification","summarization"],"keywords_longer_than_N":true},
	{"name":"RSTeller_legacy","keyword":"remote-sensing","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SlytherinGe/RSTeller_legacy","creator_name":"Slytherin Ge","creator_url":"https://huggingface.co/SlytherinGe","description":"\n\t\n\t\t\n\t\t‚õî Usage Warning\n\t\n\nThis is the legacy version of the RSTeller dataset and is not the latest version referenced in our paper. We are keeping it available here to provide the community with easy access to additional data.\nFor the details and the usage of the dataset, please refer to our github page.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you find the dataset and our paper useful, please consider citing our paper:\n@article{ge2025rsteller,\n  title={RSTeller: Scaling up visual language modeling in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SlytherinGe/RSTeller_legacy.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","visual-question-answering","zero-shot-classification","summarization"],"keywords_longer_than_N":true},
	{"name":"global-streetscapes","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NUS-UAL/global-streetscapes","creator_name":"NUS Urban Analytics Lab","creator_url":"https://huggingface.co/NUS-UAL","description":"\n\t\n\t\t\n\t\tGlobal Streetscapes\n\t\n\nRepository for the tabular portion of the Global Streetscapes dataset by the Urban Analytics Lab (UAL) at the National University of Singapore (NUS).\n\n\t\n\t\t\n\t\tContent Breakdown\n\t\n\nGlobal Streetscapes (74 GB)\n‚îú‚îÄ‚îÄ data/ (49 GB)\n‚îÇ   ‚îú‚îÄ‚îÄ 21 CSV files with 346 unique features in total and 10M rows each (37 GB)\n‚îÇ   ‚îú‚îÄ‚îÄ parquet/ (12 GB) (New)\n‚îÇ       ‚îú‚îÄ‚îÄ 21 Parquet equivalents of the 21 CSV files (New)    \n‚îÇ       ‚îú‚îÄ‚îÄ 1 combined Parquet file (New)\n‚îú‚îÄ‚îÄ manual_labels/ (23‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NUS-UAL/global-streetscapes.","first_N":5,"first_N_keywords":["image-classification","image-segmentation","image-feature-extraction","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"global-streetscapes","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NUS-UAL/global-streetscapes","creator_name":"NUS Urban Analytics Lab","creator_url":"https://huggingface.co/NUS-UAL","description":"\n\t\n\t\t\n\t\tGlobal Streetscapes\n\t\n\nRepository for the tabular portion of the Global Streetscapes dataset by the Urban Analytics Lab (UAL) at the National University of Singapore (NUS).\n\n\t\n\t\t\n\t\tContent Breakdown\n\t\n\nGlobal Streetscapes (74 GB)\n‚îú‚îÄ‚îÄ data/ (49 GB)\n‚îÇ   ‚îú‚îÄ‚îÄ 21 CSV files with 346 unique features in total and 10M rows each (37 GB)\n‚îÇ   ‚îú‚îÄ‚îÄ parquet/ (12 GB) (New)\n‚îÇ       ‚îú‚îÄ‚îÄ 21 Parquet equivalents of the 21 CSV files (New)    \n‚îÇ       ‚îú‚îÄ‚îÄ 1 combined Parquet file (New)\n‚îú‚îÄ‚îÄ manual_labels/ (23‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NUS-UAL/global-streetscapes.","first_N":5,"first_N_keywords":["image-classification","image-segmentation","image-feature-extraction","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"gnaf-2022","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dylanhogg/gnaf-2022","creator_name":"Dylan Hogg","creator_url":"https://huggingface.co/dylanhogg","description":"\n\t\n\t\t\n\t\tGeoscape Geocoded National Address File (GNAF) 2022\n\t\n\n\n\t\n\t\t\n\t\tDataset overview\n\t\n\nGeoscape GNAF is the geocoded address database for Australian businesses and governments. It‚Äôs the trusted source of geocoded address data for Australia with over 50 million contributed addresses distilled into 15.4 million G-NAF addresses. It is built and maintained by Geoscape Australia using independently examined and validated government data.\nIt contains the state, suburb, street, number and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dylanhogg/gnaf-2022.","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"gnaf-2022","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dylanhogg/gnaf-2022","creator_name":"Dylan Hogg","creator_url":"https://huggingface.co/dylanhogg","description":"\n\t\n\t\t\n\t\tGeoscape Geocoded National Address File (GNAF) 2022\n\t\n\n\n\t\n\t\t\n\t\tDataset overview\n\t\n\nGeoscape GNAF is the geocoded address database for Australian businesses and governments. It‚Äôs the trusted source of geocoded address data for Australia with over 50 million contributed addresses distilled into 15.4 million G-NAF addresses. It is built and maintained by Geoscape Australia using independently examined and validated government data.\nIt contains the state, suburb, street, number and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dylanhogg/gnaf-2022.","first_N":5,"first_N_keywords":["text-classification","English","cc-by-4.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"Gowalla-CA-POI","keyword":"poi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/w11wo/Gowalla-CA-POI","creator_name":"Wilson Wongso","creator_url":"https://huggingface.co/w11wo","description":"This repository contains the dataset used in the paper GenUP: Generative User Profilers as In-Context Learners for Next POI Recommender Systems.\nThe dataset consists of user profiles and POI data for the FourSquare-NYC, Gowalla-CA, and FourSquare-TKY datasets.\nCode: https://github.com/w11wo/GenUP\n","first_N":5,"first_N_keywords":["other","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S1RTC-SSL4EO","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S1RTC-SSL4EO","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S1RTC-SSL4EO üì°‚ö°üõ∞Ô∏è\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S1RTC-SSL4EO\nSentinel-1 RTC\n36,748,875\nSAR\nGeneral-Purpose Global\nCore-S1RTC\nSSL4EO-ResNet50-MOCO\n332.5 GB\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nTypeDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u\nint\nMajor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S1RTC-SSL4EO.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S1RTC-SSL4EO","keyword":"earth-observation","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S1RTC-SSL4EO","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S1RTC-SSL4EO üì°‚ö°üõ∞Ô∏è\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S1RTC-SSL4EO\nSentinel-1 RTC\n36,748,875\nSAR\nGeneral-Purpose Global\nCore-S1RTC\nSSL4EO-ResNet50-MOCO\n332.5 GB\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nTypeDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u\nint\nMajor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S1RTC-SSL4EO.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S1RTC-SSL4EO","keyword":"remote-sensing","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S1RTC-SSL4EO","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S1RTC-SSL4EO üì°‚ö°üõ∞Ô∏è\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S1RTC-SSL4EO\nSentinel-1 RTC\n36,748,875\nSAR\nGeneral-Purpose Global\nCore-S1RTC\nSSL4EO-ResNet50-MOCO\n332.5 GB\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nTypeDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u\nint\nMajor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S1RTC-SSL4EO.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S1RTC-SSL4EO","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S1RTC-SSL4EO","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S1RTC-SSL4EO üì°‚ö°üõ∞Ô∏è\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S1RTC-SSL4EO\nSentinel-1 RTC\n36,748,875\nSAR\nGeneral-Purpose Global\nCore-S1RTC\nSSL4EO-ResNet50-MOCO\n332.5 GB\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nTypeDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u\nint\nMajor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S1RTC-SSL4EO.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S2L1C-SSL4EO","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2L1C-SSL4EO","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S2L1C-SSL4EO  üü•üü©üü¶üüßüü®üü™ üõ∞Ô∏è\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S2L1C-SSL4EO\nSentinel-2 (Level 1C)\n56,147,150\nMulti-Spectral\nGeneral-Purpose Global\nCore-S2L1C\nSSL4EO-ResNet50-DINO\n252.9 GB\n\n\n\t\n\n\n\t\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nType\nDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2L1C-SSL4EO.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S2L1C-SSL4EO","keyword":"earth-observation","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2L1C-SSL4EO","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S2L1C-SSL4EO  üü•üü©üü¶üüßüü®üü™ üõ∞Ô∏è\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S2L1C-SSL4EO\nSentinel-2 (Level 1C)\n56,147,150\nMulti-Spectral\nGeneral-Purpose Global\nCore-S2L1C\nSSL4EO-ResNet50-DINO\n252.9 GB\n\n\n\t\n\n\n\t\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nType\nDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2L1C-SSL4EO.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S2L1C-SSL4EO","keyword":"remote-sensing","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2L1C-SSL4EO","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S2L1C-SSL4EO  üü•üü©üü¶üüßüü®üü™ üõ∞Ô∏è\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S2L1C-SSL4EO\nSentinel-2 (Level 1C)\n56,147,150\nMulti-Spectral\nGeneral-Purpose Global\nCore-S2L1C\nSSL4EO-ResNet50-DINO\n252.9 GB\n\n\n\t\n\n\n\t\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nType\nDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2L1C-SSL4EO.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S2L1C-SSL4EO","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2L1C-SSL4EO","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S2L1C-SSL4EO  üü•üü©üü¶üüßüü®üü™ üõ∞Ô∏è\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S2L1C-SSL4EO\nSentinel-2 (Level 1C)\n56,147,150\nMulti-Spectral\nGeneral-Purpose Global\nCore-S2L1C\nSSL4EO-ResNet50-DINO\n252.9 GB\n\n\n\t\n\n\n\t\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nType\nDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2L1C-SSL4EO.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Placekey/FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN","creator_name":"Placekey","creator_url":"https://huggingface.co/Placekey","description":"\n\t\n\t\t\n\t\tPlacekey Inner Join of Overture (2024-11-13.0) and Foursquare Open Source Places (2024-11-19)\n\t\n\n\n\t\n\t\t\n\t\tSummary of the Join\n\t\n\n\nMatched Placekeys inner: 7,868,660\nFoursquare Open Source Places Total Placekeys: 103,413,964\nOverture Total Placekeys: 42,084,985\n\n\n\n\t\n\t\t\n\t\tüöÄ Foursquare Uplift\n\t\n\nFoursquare Open Source Places (Apache 2.0) docs contributed the following data enhancements when joined with Overture:\n\n\t\n\t\t\nField\nValues Added\n\n\n\t\t\ngeometry\n7,868,660\n\n\nconfidence\n7,868,660‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Placekey/FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN.","first_N":5,"first_N_keywords":["apache-2.0","1M - 10M","parquet","Text","Geospatial"],"keywords_longer_than_N":true},
	{"name":"FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Placekey/FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN","creator_name":"Placekey","creator_url":"https://huggingface.co/Placekey","description":"\n\t\n\t\t\n\t\tPlacekey Inner Join of Overture (2024-11-13.0) and Foursquare Open Source Places (2024-11-19)\n\t\n\n\n\t\n\t\t\n\t\tSummary of the Join\n\t\n\n\nMatched Placekeys inner: 7,868,660\nFoursquare Open Source Places Total Placekeys: 103,413,964\nOverture Total Placekeys: 42,084,985\n\n\n\n\t\n\t\t\n\t\tüöÄ Foursquare Uplift\n\t\n\nFoursquare Open Source Places (Apache 2.0) docs contributed the following data enhancements when joined with Overture:\n\n\t\n\t\t\nField\nValues Added\n\n\n\t\t\ngeometry\n7,868,660\n\n\nconfidence\n7,868,660‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Placekey/FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN.","first_N":5,"first_N_keywords":["apache-2.0","1M - 10M","parquet","Text","Geospatial"],"keywords_longer_than_N":true},
	{"name":"FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN","keyword":"poi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Placekey/FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN","creator_name":"Placekey","creator_url":"https://huggingface.co/Placekey","description":"\n\t\n\t\t\n\t\tPlacekey Inner Join of Overture (2024-11-13.0) and Foursquare Open Source Places (2024-11-19)\n\t\n\n\n\t\n\t\t\n\t\tSummary of the Join\n\t\n\n\nMatched Placekeys inner: 7,868,660\nFoursquare Open Source Places Total Placekeys: 103,413,964\nOverture Total Placekeys: 42,084,985\n\n\n\n\t\n\t\t\n\t\tüöÄ Foursquare Uplift\n\t\n\nFoursquare Open Source Places (Apache 2.0) docs contributed the following data enhancements when joined with Overture:\n\n\t\n\t\t\nField\nValues Added\n\n\n\t\t\ngeometry\n7,868,660\n\n\nconfidence\n7,868,660‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Placekey/FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN.","first_N":5,"first_N_keywords":["apache-2.0","1M - 10M","parquet","Text","Geospatial"],"keywords_longer_than_N":true},
	{"name":"dutch-central-exam-mcq-multimodal-subset","keyword":"geography","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jjzha/dutch-central-exam-mcq-multimodal-subset","creator_name":"Mike Zhang","creator_url":"https://huggingface.co/jjzha","description":"Multimodal Multiple Choice Questions of the Dutch Central Exam 1999-2024\n\nWhat?\n\nThis dataset contains only multimodal multiple choice questions from the Dutch Central Exam (High School level). From Wikipedia:\nThe Eindexamen (Dutch pronunciation: [Àà…õiÃØnt…õksam…ôn]) or centraal examen (CE) is the matriculation exam in the Netherlands, which takes place in a student's final year of high school education (voortgezet onderwijs; \"continued education\"). The exam is regulated by the Dutch Secondary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jjzha/dutch-central-exam-mcq-multimodal-subset.","first_N":5,"first_N_keywords":["question-answering","Dutch","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"LA_fire_jan_2025","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fbos/LA_fire_jan_2025","creator_name":"Francesco","creator_url":"https://huggingface.co/fbos","description":"\n\t\n\t\t\n\t\tGeoJSON Dataset for Building Damage Assessment\n\t\n\nThis repository contains the GeoJSON dataset used to fine-tune the UNet model with resnext50_32x4d backbone for building damage assessment on LA fire of January 2025. The dataset is referred to the Eaton fire area and provides detailed annotations of buildings and their damage status.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\n\nFormat: GeoJSON\nClasses:\nBackground\nBuilding (Healthy Building)\nDamaged Building\n\n\n\n\n\t\n\t\n\t\n\t\tHow to Use the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fbos/LA_fire_jan_2025.","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","Geospatial","Image"],"keywords_longer_than_N":true},
	{"name":"MMMU-Thai","keyword":"geography","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iapp/MMMU-Thai","creator_name":"iApp Technology","creator_url":"https://huggingface.co/iapp","description":"\n\t\n\t\t\n\t\tMMMU Thai (MMMU Benchmark Translated to Thai)\n\t\n\nMMMU Thai is a dataset for evaluating multimodal models on massive multi-discipline tasks requiring college-level knowledge and deliberate reasoning. This dataset is translated from MMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI) into Thai.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nMMMU Thai consists of 11,500 meticulously collected multimodal questions from college exams, quizzes, and textbooks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iapp/MMMU-Thai.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","Thai","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Core-S2RGB-SigLIP","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2RGB-SigLIP","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S2RGB-SigLIP üî¥üü¢üîµ\n\t\n\n\n\t\n\t\t\nModality\nNumber of Embeddings\nSensing Type\nComments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nSentinel-2 Level 2A (RGB)\n20,212,974\nTrue Colour\nVision-Language Global\nCore-S2L2A\nSigLIP-SO400M-384\n41.3 GB\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nTypeDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u\nint\nMajor TOM cell row‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2RGB-SigLIP.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S2RGB-SigLIP","keyword":"earth-observation","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2RGB-SigLIP","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S2RGB-SigLIP üî¥üü¢üîµ\n\t\n\n\n\t\n\t\t\nModality\nNumber of Embeddings\nSensing Type\nComments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nSentinel-2 Level 2A (RGB)\n20,212,974\nTrue Colour\nVision-Language Global\nCore-S2L2A\nSigLIP-SO400M-384\n41.3 GB\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nTypeDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u\nint\nMajor TOM cell row‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2RGB-SigLIP.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S2RGB-SigLIP","keyword":"remote-sensing","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2RGB-SigLIP","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S2RGB-SigLIP üî¥üü¢üîµ\n\t\n\n\n\t\n\t\t\nModality\nNumber of Embeddings\nSensing Type\nComments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nSentinel-2 Level 2A (RGB)\n20,212,974\nTrue Colour\nVision-Language Global\nCore-S2L2A\nSigLIP-SO400M-384\n41.3 GB\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nTypeDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u\nint\nMajor TOM cell row‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2RGB-SigLIP.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S2RGB-SigLIP","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2RGB-SigLIP","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S2RGB-SigLIP üî¥üü¢üîµ\n\t\n\n\n\t\n\t\t\nModality\nNumber of Embeddings\nSensing Type\nComments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nSentinel-2 Level 2A (RGB)\n20,212,974\nTrue Colour\nVision-Language Global\nCore-S2L2A\nSigLIP-SO400M-384\n41.3 GB\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nTypeDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u\nint\nMajor TOM cell row‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2RGB-SigLIP.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S2RGB-DINOv2","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2RGB-DINOv2","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S2RGB-DINOv2 üî¥üü¢üîµ\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S2RGB-SigLIP\nSentinel-2 Level 2A (RGB)\n56,147,150\nTrue Colour (RGB)\nGeneral-Purpose Global\nCore-S2L2A\nDINOv2\n223.1 GB\n\n\n\t\n\n\n\t\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nType\nDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2RGB-DINOv2.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S2RGB-DINOv2","keyword":"earth-observation","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2RGB-DINOv2","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S2RGB-DINOv2 üî¥üü¢üîµ\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S2RGB-SigLIP\nSentinel-2 Level 2A (RGB)\n56,147,150\nTrue Colour (RGB)\nGeneral-Purpose Global\nCore-S2L2A\nDINOv2\n223.1 GB\n\n\n\t\n\n\n\t\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nType\nDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2RGB-DINOv2.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S2RGB-DINOv2","keyword":"remote-sensing","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2RGB-DINOv2","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S2RGB-DINOv2 üî¥üü¢üîµ\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S2RGB-SigLIP\nSentinel-2 Level 2A (RGB)\n56,147,150\nTrue Colour (RGB)\nGeneral-Purpose Global\nCore-S2L2A\nDINOv2\n223.1 GB\n\n\n\t\n\n\n\t\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nType\nDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2RGB-DINOv2.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S2RGB-DINOv2","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2RGB-DINOv2","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S2RGB-DINOv2 üî¥üü¢üîµ\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S2RGB-SigLIP\nSentinel-2 Level 2A (RGB)\n56,147,150\nTrue Colour (RGB)\nGeneral-Purpose Global\nCore-S2L2A\nDINOv2\n223.1 GB\n\n\n\t\n\n\n\t\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nType\nDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2RGB-DINOv2.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"landvote","keyword":"geospatial","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/boettiger-lab/landvote","creator_name":"C. Boettiger Research Group","creator_url":"https://huggingface.co/boettiger-lab","description":"boettiger-lab/landvote dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["bsd-2-clause","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"FourSquare-SaoPaulo-POI","keyword":"poi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/w11wo/FourSquare-SaoPaulo-POI","creator_name":"Wilson Wongso","creator_url":"https://huggingface.co/w11wo","description":"This repository contains the dataset from the paper GenUP: Generative User Profilers as In-Context Learners for Next POI Recommender Systems.\nThis dataset is used for generating natural language user profiles from large-scale location-based social network check-ins. It can be used to improve POI (Point of Interest) prediction accuracy while offering enhanced transparency.\nCode: https://github.com/w11wo/GenUP\n","first_N":5,"first_N_keywords":["other","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"RSTeller_metadata","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SlytherinGe/RSTeller_metadata","creator_name":"Slytherin Ge","creator_url":"https://huggingface.co/SlytherinGe","description":"\n\t\n\t\t\n\t\tMetadata for RSTeller\n\t\n\nThis dataset contains the necessary metadata for the dataset SlytherinGe/RSTeller.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe metadata table provides detailed information for the RSTeller dataset, with the following columns:\n\npatch_id: The primary key of the table, corresponding to the \"__key__\" or the \"patch_id\" field in the JSON of the RSTeller dataset.\n\npatch_lat and patch_lon: The latitude and longitude coordinates of the patch center in WGS84‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SlytherinGe/RSTeller_metadata.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","visual-question-answering","zero-shot-classification","summarization"],"keywords_longer_than_N":true},
	{"name":"RSTeller_metadata","keyword":"remote-sensing","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SlytherinGe/RSTeller_metadata","creator_name":"Slytherin Ge","creator_url":"https://huggingface.co/SlytherinGe","description":"\n\t\n\t\t\n\t\tMetadata for RSTeller\n\t\n\nThis dataset contains the necessary metadata for the dataset SlytherinGe/RSTeller.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe metadata table provides detailed information for the RSTeller dataset, with the following columns:\n\npatch_id: The primary key of the table, corresponding to the \"__key__\" or the \"patch_id\" field in the JSON of the RSTeller dataset.\n\npatch_lat and patch_lon: The latitude and longitude coordinates of the patch center in WGS84‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SlytherinGe/RSTeller_metadata.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","visual-question-answering","zero-shot-classification","summarization"],"keywords_longer_than_N":true},
	{"name":"flood-mapping","keyword":"geospatial","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rodekruis/flood-mapping","creator_name":"Netherlands Red Cross 510","creator_url":"https://huggingface.co/rodekruis","description":"rodekruis/flood-mapping dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["gpl-3.0","< 1K","parquet","Geospatial","Text"],"keywords_longer_than_N":true},
	{"name":"m4-sar","keyword":"remote-sensing","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wchao0601/m4-sar","creator_name":"wchao0601","creator_url":"https://huggingface.co/wchao0601","description":"\n\n M4-SAR: A Multi-Resolution, Multi-Polarization, Multi-Scene, Multi-Source Dataset and Benchmark for Optical-SAR Fusion Object Detection\n 2025\n\n\n\n\t\n\t\t\n\t\tDataset description\n\t\n\nSingle-source remote sensing object detection using optical or SAR images struggles in complex environments. Optical images offer rich textural details but are often affected by low-light, cloud-obscured, or low-resolution conditions, reducing the detection performance. SAR images are robust to weather, but suffer from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wchao0601/m4-sar.","first_N":5,"first_N_keywords":["object-detection","English","cc-by-4.0","100K<n<1M","arxiv:2505.10931"],"keywords_longer_than_N":true},
	{"name":"IndLands","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DataUploader/IndLands","creator_name":"Anonymous Data uploader","creator_url":"https://huggingface.co/DataUploader","description":"\n\t\n\t\t\n\t\tIndLands Dataset\n\t\n\nThis dataset contains landslide data considering events from four Indian states: Himachal Pradesh, Mizoram, Sikkim, and Uttarakhand as our study region\n\n\t\n\t\t\n\t\tStructure\n\t\n\nEach state contains multiple event folders. Every event folder includes:\n\npre_event_features.csv: Features captured before the landslide event.\npost_event_features.csv: Features captured after the landslide event.\nfeature_list.csv: The list of features used for the event.\nevent_metadata.txt:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DataUploader/IndLands.","first_N":5,"first_N_keywords":["feature-extraction","cc-by-4.0","1M<n<10M","Geospatial","Text"],"keywords_longer_than_N":true},
	{"name":"global-ocean-floor-bathymetry-enhancement-dataset","keyword":"earth-observation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jomaminoza/global-ocean-floor-bathymetry-enhancement-dataset","creator_name":"Jose Marie Antonio Minoza","creator_url":"https://huggingface.co/jomaminoza","description":"--\n\n\t\n\t\t\n\t\tOcean Floor Bathymetry Enhancement Dataset\n\t\n\nThis dataset contains bathymetric data supporting the research presented in \"Learning Enhanced Structural Representations with Block-Based Uncertainties for Ocean Floor Mapping\" (ICLR 2025). It provides paired low-resolution and high-resolution bathymetric samples from various ocean regions worldwide.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nAccurate ocean modeling and coastal hazard prediction depend on high-resolution bathymetric data; yet, current‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jomaminoza/global-ocean-floor-bathymetry-enhancement-dataset.","first_N":5,"first_N_keywords":["image-segmentation","other","super-resolution","semantic-segmentation","English"],"keywords_longer_than_N":true},
	{"name":"NASADEM_DATASET","keyword":"geography","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SalvadorCB/NASADEM_DATASET","creator_name":"Salvador Cantuarias Bra√±es","creator_url":"https://huggingface.co/SalvadorCB","description":"\n\t\n\t\t\n\t\tNASADEM_DATASET/\n  README.md\n  train/metadata.csv\n  train.zip \n\t\n\n","first_N":5,"first_N_keywords":["feature-extraction","English","afl-3.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"dutch-central-exam-mcq","keyword":"geography","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jjzha/dutch-central-exam-mcq","creator_name":"Mike Zhang","creator_url":"https://huggingface.co/jjzha","description":"Multiple Choice Questions of the Dutch Central Exam 1999-2024\n\nImportant Note\n\nPer 01 Apr. 2025: This data is now split accordingly to the benchmark test sets of:\nhttps://huggingface.co/datasets/CohereForAI/include-base-44\nhttps://huggingface.co/datasets/CohereForAI/include-lite-44\nAny question that appears in the development or test set of the INCLUDE benchmark are now in a separate split. \nWe put both the base and lite questions in one test split.\nWe suggest using the INCLUDE benchmark for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jjzha/dutch-central-exam-mcq.","first_N":5,"first_N_keywords":["multiple-choice","Dutch","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"CHOICE","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/An-Xiao/CHOICE","creator_name":"AnXiao","creator_url":"https://huggingface.co/An-Xiao","description":"\n\t\n\t\t\n\t\tCHOICE: Benchmarking The Remote Sensing Capabilities of Large Vision-Language Models\n\t\n\n Abstract: The rapid advancement of Large Vision-Language Models (VLMs), both general-domain models and those specifically tailored for remote sensing, has demonstrated exceptional perception and reasoning capabilities in Earth observation tasks. However, a benchmark for systematically evaluating their capabilities in this domain is still lacking. To bridge this gap, we propose CHOICE, an extensive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/An-Xiao/CHOICE.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"CHOICE","keyword":"remote-sensing","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/An-Xiao/CHOICE","creator_name":"AnXiao","creator_url":"https://huggingface.co/An-Xiao","description":"\n\t\n\t\t\n\t\tCHOICE: Benchmarking The Remote Sensing Capabilities of Large Vision-Language Models\n\t\n\n Abstract: The rapid advancement of Large Vision-Language Models (VLMs), both general-domain models and those specifically tailored for remote sensing, has demonstrated exceptional perception and reasoning capabilities in Earth observation tasks. However, a benchmark for systematically evaluating their capabilities in this domain is still lacking. To bridge this gap, we propose CHOICE, an extensive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/An-Xiao/CHOICE.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"asia-landuse-3class-v1","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/asia-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/asia-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"asia-landuse-3class-v1","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/asia-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/asia-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"asia-landuse-3class-v1","keyword":"poi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/asia-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/asia-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"south-america-landuse-3class-v1","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/south-america-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/south-america-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"south-america-landuse-3class-v1","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/south-america-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/south-america-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"south-america-landuse-3class-v1","keyword":"poi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/south-america-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/south-america-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"north-america-landuse-3class-v1","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/north-america-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/north-america-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"north-america-landuse-3class-v1","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/north-america-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/north-america-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"north-america-landuse-3class-v1","keyword":"poi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/north-america-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/north-america-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"central-america-landuse-3class-v1","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/central-america-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/central-america-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"central-america-landuse-3class-v1","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/central-america-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/central-america-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"central-america-landuse-3class-v1","keyword":"poi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/central-america-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/central-america-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"oceania-landuse-3class-v1","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/oceania-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/oceania-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"oceania-landuse-3class-v1","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/oceania-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/oceania-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"oceania-landuse-3class-v1","keyword":"poi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/oceania-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/oceania-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"Italian_Parcels","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/do-me/Italian_Parcels","creator_name":"Dominik Weckm√ºller","creator_url":"https://huggingface.co/do-me","description":"\n\t\n\t\t\n\t\tItalian Parcels - Cartografia Catastale - ITALIA\n\t\n\nAll official Italian parcels and commune geometries as geoparquet. \n\nExample for Catania.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nhttps://geodati.gov.it/geoportale/eng/metadata-search-results?keyword=cartografia+catastale\n\nThis URL offers both, a WFS service for direct use in QGIS or a batch download in a funny format: a zip of zips of zips of zips of gml and gfs, lol.\nThe structure looks like this: \n\n\n\t\n\t\t\n\t\n\t\n\t\tLimitations\n\t\n\n\nFor some reason Trentino‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/do-me/Italian_Parcels.","first_N":5,"first_N_keywords":["apache-2.0","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"NCERT_Social_Studies_10th","keyword":"geography","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KadamParth/NCERT_Social_Studies_10th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Social_Studies_10th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"NCERT_Social_Studies_9th","keyword":"geography","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KadamParth/NCERT_Social_Studies_9th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Social_Studies_9th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"francecrops","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saget-antoine/francecrops","creator_name":"Antoine Saget","creator_url":"https://huggingface.co/saget-antoine","description":"\n\t\n\t\t\n\t\tDataset Card for FranceCrops\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFranceCrops is a satellite imagery time series dataset for crop classification in France. \nEach sample in the dataset consists of:\n\nInput Features (x): 3D arrays of shape (100, 60, 12) in float16:\n100: number of timeseries sampled within an agricultural field\n60: temporal dimension (measurements every 5 days from 01/02/2022 to 30/11/2022)\n12: spectral bands from Sentinel-2 satellite\n\n\nLabels (y): Integer class labels (int16)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saget-antoine/francecrops.","first_N":5,"first_N_keywords":["image-classification","cc-by-sa-4.0","10K - 100K","arrow","Geospatial"],"keywords_longer_than_N":true},
	{"name":"francecrops","keyword":"earth-observation","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saget-antoine/francecrops","creator_name":"Antoine Saget","creator_url":"https://huggingface.co/saget-antoine","description":"\n\t\n\t\t\n\t\tDataset Card for FranceCrops\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFranceCrops is a satellite imagery time series dataset for crop classification in France. \nEach sample in the dataset consists of:\n\nInput Features (x): 3D arrays of shape (100, 60, 12) in float16:\n100: number of timeseries sampled within an agricultural field\n60: temporal dimension (measurements every 5 days from 01/02/2022 to 30/11/2022)\n12: spectral bands from Sentinel-2 satellite\n\n\nLabels (y): Integer class labels (int16)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saget-antoine/francecrops.","first_N":5,"first_N_keywords":["image-classification","cc-by-sa-4.0","10K - 100K","arrow","Geospatial"],"keywords_longer_than_N":true},
	{"name":"francecrops","keyword":"remote-sensing","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saget-antoine/francecrops","creator_name":"Antoine Saget","creator_url":"https://huggingface.co/saget-antoine","description":"\n\t\n\t\t\n\t\tDataset Card for FranceCrops\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFranceCrops is a satellite imagery time series dataset for crop classification in France. \nEach sample in the dataset consists of:\n\nInput Features (x): 3D arrays of shape (100, 60, 12) in float16:\n100: number of timeseries sampled within an agricultural field\n60: temporal dimension (measurements every 5 days from 01/02/2022 to 30/11/2022)\n12: spectral bands from Sentinel-2 satellite\n\n\nLabels (y): Integer class labels (int16)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saget-antoine/francecrops.","first_N":5,"first_N_keywords":["image-classification","cc-by-sa-4.0","10K - 100K","arrow","Geospatial"],"keywords_longer_than_N":true},
	{"name":"francecrops","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saget-antoine/francecrops","creator_name":"Antoine Saget","creator_url":"https://huggingface.co/saget-antoine","description":"\n\t\n\t\t\n\t\tDataset Card for FranceCrops\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFranceCrops is a satellite imagery time series dataset for crop classification in France. \nEach sample in the dataset consists of:\n\nInput Features (x): 3D arrays of shape (100, 60, 12) in float16:\n100: number of timeseries sampled within an agricultural field\n60: temporal dimension (measurements every 5 days from 01/02/2022 to 30/11/2022)\n12: spectral bands from Sentinel-2 satellite\n\n\nLabels (y): Integer class labels (int16)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saget-antoine/francecrops.","first_N":5,"first_N_keywords":["image-classification","cc-by-sa-4.0","10K - 100K","arrow","Geospatial"],"keywords_longer_than_N":true},
	{"name":"smolBasisTolk","keyword":"geography","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AILaborant/smolBasisTolk","creator_name":"AI Laborant","creator_url":"https://huggingface.co/AILaborant","description":"Smol but a wide variety of topics dataset for basic AI training.\n","first_N":5,"first_N_keywords":["English","gpl-3.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S2L1C-DeCUR","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2L1C-DeCUR","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S2L1C-DeCUR  üü•üü©üü¶üüßüü®üü™ üõ∞Ô∏è\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S2L1C-DeCUR\nSentinel-2 (Level 1C)\n56,147,150\nMulti-Spectral\nGeneral-Purpose Global\nCore-S2L1C\nDeCUR\n342.7 GB\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nTypeDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2L1C-DeCUR.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S2L1C-DeCUR","keyword":"earth-observation","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2L1C-DeCUR","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S2L1C-DeCUR  üü•üü©üü¶üüßüü®üü™ üõ∞Ô∏è\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S2L1C-DeCUR\nSentinel-2 (Level 1C)\n56,147,150\nMulti-Spectral\nGeneral-Purpose Global\nCore-S2L1C\nDeCUR\n342.7 GB\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nTypeDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2L1C-DeCUR.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S2L1C-DeCUR","keyword":"remote-sensing","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2L1C-DeCUR","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S2L1C-DeCUR  üü•üü©üü¶üüßüü®üü™ üõ∞Ô∏è\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S2L1C-DeCUR\nSentinel-2 (Level 1C)\n56,147,150\nMulti-Spectral\nGeneral-Purpose Global\nCore-S2L1C\nDeCUR\n342.7 GB\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nTypeDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2L1C-DeCUR.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S2L1C-DeCUR","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S2L1C-DeCUR","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S2L1C-DeCUR  üü•üü©üü¶üüßüü®üü™ üõ∞Ô∏è\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S2L1C-DeCUR\nSentinel-2 (Level 1C)\n56,147,150\nMulti-Spectral\nGeneral-Purpose Global\nCore-S2L1C\nDeCUR\n342.7 GB\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nTypeDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S2L1C-DeCUR.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M - 100M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"africa-landuse-3class-v1","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/africa-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/africa-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","Geospatial","doi:10.57967/hf/4625","üá∫üá∏ Region: US","geospatial"],"keywords_longer_than_N":true},
	{"name":"africa-landuse-3class-v1","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/africa-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/africa-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","Geospatial","doi:10.57967/hf/4625","üá∫üá∏ Region: US","geospatial"],"keywords_longer_than_N":true},
	{"name":"africa-landuse-3class-v1","keyword":"poi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/africa-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/africa-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","Geospatial","doi:10.57967/hf/4625","üá∫üá∏ Region: US","geospatial"],"keywords_longer_than_N":true},
	{"name":"europe-landuse-3class-v1","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/europe-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/europe-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"europe-landuse-3class-v1","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/europe-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/europe-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"europe-landuse-3class-v1","keyword":"poi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapSpaceORNL/europe-landuse-3class-v1","creator_name":"MapSpace Global Land Use","creator_url":"https://huggingface.co/MapSpaceORNL","description":"\n\t\n\t\t\n\t\tPOI-based land use classification\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nPOI-based land use datasets generated and shared by the [Geospatial Science and Human Security Division in Oak Ridge National Laboratory](https://mapspace.ornl.gov/). \nThis dataset classifies land use into three classes: residential, non-residential and open space. \nThe dataset has a spatial resolution of 500 meters and covers all countries and regions of the world except for the US and Greenland. \n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapSpaceORNL/europe-landuse-3class-v1.","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","imagefolder","Image","Geospatial"],"keywords_longer_than_N":true},
	{"name":"NCERT_Geography_11th","keyword":"geography","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KadamParth/NCERT_Geography_11th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Geography_11th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"NCERT_Geography_12th","keyword":"geography","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KadamParth/NCERT_Geography_12th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Geography_12th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"WorldFlags-Every-Nation-Flag","keyword":"geography","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Huggbottle/WorldFlags-Every-Nation-Flag","creator_name":"Simon Axelsen","creator_url":"https://huggingface.co/Huggbottle","description":"\n\t\n\t\t\n\t\tWorld Nation Flags Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains images of flags (Feb 2025) for every sovereign nation in the world. It is designed for tasks such as image classification, flag recognition, and geographic education.\nIt also include some less recognized Sovereign state, such as: Abkhazia, Cook_islands, Niue, Northern_Cyprus, Sahrawi_Arab_Democratic_Republic, Somaliland, Taiwan, Transnistria.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Huggbottle/WorldFlags-Every-Nation-Flag.","first_N":5,"first_N_keywords":["image-classification","English","cc0-1.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"NCERT_Social_Studies_8th","keyword":"geography","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KadamParth/NCERT_Social_Studies_8th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Social_Studies_8th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"NCERT_Social_Studies_6th","keyword":"geography","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KadamParth/NCERT_Social_Studies_6th","creator_name":"Parth Kadam","creator_url":"https://huggingface.co/KadamParth","description":"KadamParth/NCERT_Social_Studies_6th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"overture-places","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/do-me/overture-places","creator_name":"Dominik Weckm√ºller","creator_url":"https://huggingface.co/do-me","description":"\n\t\n\t\t\n\t\tOverture Places\n\t\n\nA lightweight frontend app using transformers.js showcasing the use of semantic similarity for geospatial applications such as geosocial media. Building on Overturempas Places, dynamically loading data from a singe 8Gb flatgeobuf file.\n\nApp: https://do-me.github.io/overture-places/\nGitHub: https://github.com/do-me/overture-places\n\n\n\t\n\t\t\n\t\n\t\n\t\tSearch the whole world with natural language!\n\t\n\n\nData on Huggingface:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/do-me/overture-places.","first_N":5,"first_N_keywords":["feature-extraction","English","mit","< 1K","Geospatial"],"keywords_longer_than_N":true},
	{"name":"TrafficBottleNecksAccidentsNY","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ysaismartinez/TrafficBottleNecksAccidentsNY","creator_name":"Ysais Martinez","creator_url":"https://huggingface.co/ysaismartinez","description":"ysaismartinez/TrafficBottleNecksAccidentsNY dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","text","Geospatial","Text"],"keywords_longer_than_N":true},
	{"name":"FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jarredparrett/FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN","creator_name":"Jarred Parrett","creator_url":"https://huggingface.co/jarredparrett","description":"\n\t\n\t\t\n\t\tPlacekey Inner Join of Overture (2024-11-13.0) and Foursquare Open Source Places (2024-11-19)\n\t\n\n\n\t\n\t\t\n\t\tSummary of the Join\n\t\n\n\nMatched Placekeys inner: 7,868,660\nFoursquare Open Source Places Total Placekeys: 103,413,964\nOverture Total Placekeys: 42,084,985\n\n\n\n\t\n\t\t\n\t\tüöÄ Foursquare Uplift\n\t\n\nFoursquare Open Source Places (Apache 2.0) docs contributed the following data enhancements when joined with Overture:\n\n\t\n\t\t\nField\nValues Added\n\n\n\t\t\ngeometry\n7,868,660\n\n\nconfidence\n7,868,660‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jarredparrett/FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN.","first_N":5,"first_N_keywords":["apache-2.0","1M - 10M","parquet","Text","Geospatial"],"keywords_longer_than_N":true},
	{"name":"FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jarredparrett/FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN","creator_name":"Jarred Parrett","creator_url":"https://huggingface.co/jarredparrett","description":"\n\t\n\t\t\n\t\tPlacekey Inner Join of Overture (2024-11-13.0) and Foursquare Open Source Places (2024-11-19)\n\t\n\n\n\t\n\t\t\n\t\tSummary of the Join\n\t\n\n\nMatched Placekeys inner: 7,868,660\nFoursquare Open Source Places Total Placekeys: 103,413,964\nOverture Total Placekeys: 42,084,985\n\n\n\n\t\n\t\t\n\t\tüöÄ Foursquare Uplift\n\t\n\nFoursquare Open Source Places (Apache 2.0) docs contributed the following data enhancements when joined with Overture:\n\n\t\n\t\t\nField\nValues Added\n\n\n\t\t\ngeometry\n7,868,660\n\n\nconfidence\n7,868,660‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jarredparrett/FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN.","first_N":5,"first_N_keywords":["apache-2.0","1M - 10M","parquet","Text","Geospatial"],"keywords_longer_than_N":true},
	{"name":"FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN","keyword":"poi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jarredparrett/FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN","creator_name":"Jarred Parrett","creator_url":"https://huggingface.co/jarredparrett","description":"\n\t\n\t\t\n\t\tPlacekey Inner Join of Overture (2024-11-13.0) and Foursquare Open Source Places (2024-11-19)\n\t\n\n\n\t\n\t\t\n\t\tSummary of the Join\n\t\n\n\nMatched Placekeys inner: 7,868,660\nFoursquare Open Source Places Total Placekeys: 103,413,964\nOverture Total Placekeys: 42,084,985\n\n\n\n\t\n\t\t\n\t\tüöÄ Foursquare Uplift\n\t\n\nFoursquare Open Source Places (Apache 2.0) docs contributed the following data enhancements when joined with Overture:\n\n\t\n\t\t\nField\nValues Added\n\n\n\t\t\ngeometry\n7,868,660\n\n\nconfidence\n7,868,660‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jarredparrett/FOURSQUARE_OPEN_SOURCE_PLACES_x_OVERTURE_INNER_JOIN.","first_N":5,"first_N_keywords":["apache-2.0","1M - 10M","parquet","Text","Geospatial"],"keywords_longer_than_N":true},
	{"name":"MapEval-Textual","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapEval/MapEval-Textual","creator_name":"MapEval","creator_url":"https://huggingface.co/MapEval","description":"\n\t\n\t\t\n\t\tMapEval-Textual\n\t\n\nMapEval-Textual is created using MapQaTor.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load dataset\nds = load_dataset(\"MapEval/MapEval-Textual\", name=\"benchmark\")\n\n# Generate better prompts\nfor item in ds[\"test\"]:\n    # Start with a clear task description\n    prompt = (\n        \"You are a highly intelligent assistant. \"\n        \"Based on the given context, answer the multiple-choice question by selecting the correct option.\\n\\n\"\n        \"Context:\\n\" +‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapEval/MapEval-Textual.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","expert-generated","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MapEval-Textual","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapEval/MapEval-Textual","creator_name":"MapEval","creator_url":"https://huggingface.co/MapEval","description":"\n\t\n\t\t\n\t\tMapEval-Textual\n\t\n\nMapEval-Textual is created using MapQaTor.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load dataset\nds = load_dataset(\"MapEval/MapEval-Textual\", name=\"benchmark\")\n\n# Generate better prompts\nfor item in ds[\"test\"]:\n    # Start with a clear task description\n    prompt = (\n        \"You are a highly intelligent assistant. \"\n        \"Based on the given context, answer the multiple-choice question by selecting the correct option.\\n\\n\"\n        \"Context:\\n\" +‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapEval/MapEval-Textual.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","expert-generated","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"BRIGHT","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kullervo/BRIGHT","creator_name":"Hongruixuan Chen","creator_url":"https://huggingface.co/Kullervo","description":"Overview  \n\nBRIGHT is the first open-access, globally distributed, event-diverse multimodal dataset specifically curated to support AI-based disaster response.\nIt covers five types of natural disasters and two types of man-made disasters across 14 regions worldwide, with a particular focus on developing countries.\nAbout 4,200 paired optical and SAR images containing over 380,000 building instances in BRIGHT, with a spatial resolution between 0.3 and 1 meters, provides detailed representations‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kullervo/BRIGHT.","first_N":5,"first_N_keywords":["image-segmentation","English","cc-by-sa-4.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"BRIGHT","keyword":"earth-observation","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kullervo/BRIGHT","creator_name":"Hongruixuan Chen","creator_url":"https://huggingface.co/Kullervo","description":"Overview  \n\nBRIGHT is the first open-access, globally distributed, event-diverse multimodal dataset specifically curated to support AI-based disaster response.\nIt covers five types of natural disasters and two types of man-made disasters across 14 regions worldwide, with a particular focus on developing countries.\nAbout 4,200 paired optical and SAR images containing over 380,000 building instances in BRIGHT, with a spatial resolution between 0.3 and 1 meters, provides detailed representations‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kullervo/BRIGHT.","first_N":5,"first_N_keywords":["image-segmentation","English","cc-by-sa-4.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"BRIGHT","keyword":"remote-sensing","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kullervo/BRIGHT","creator_name":"Hongruixuan Chen","creator_url":"https://huggingface.co/Kullervo","description":"Overview  \n\nBRIGHT is the first open-access, globally distributed, event-diverse multimodal dataset specifically curated to support AI-based disaster response.\nIt covers five types of natural disasters and two types of man-made disasters across 14 regions worldwide, with a particular focus on developing countries.\nAbout 4,200 paired optical and SAR images containing over 380,000 building instances in BRIGHT, with a spatial resolution between 0.3 and 1 meters, provides detailed representations‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kullervo/BRIGHT.","first_N":5,"first_N_keywords":["image-segmentation","English","cc-by-sa-4.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"RSTeller","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SlytherinGe/RSTeller","creator_name":"Slytherin Ge","creator_url":"https://huggingface.co/SlytherinGe","description":"\n\t\n\t\t\n\t\t‚ö†Ô∏è Usage Warning\n\t\n\nThis is the latest version of RSTeller, updated on 2025-01-28. Users who accessed this dataset before this date can find the legacy version, which is preserved for reference. Additionally, we have released the metadata for this dataset.\nFor the details and the usage of the dataset, please refer to our github repository page.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you find the dataset and our paper useful, please consider citing our paper:\n@article{ge2025rsteller‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SlytherinGe/RSTeller.","first_N":5,"first_N_keywords":["image-to-text","English","apache-2.0","1M - 10M","webdataset"],"keywords_longer_than_N":true},
	{"name":"RSTeller","keyword":"remote-sensing","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SlytherinGe/RSTeller","creator_name":"Slytherin Ge","creator_url":"https://huggingface.co/SlytherinGe","description":"\n\t\n\t\t\n\t\t‚ö†Ô∏è Usage Warning\n\t\n\nThis is the latest version of RSTeller, updated on 2025-01-28. Users who accessed this dataset before this date can find the legacy version, which is preserved for reference. Additionally, we have released the metadata for this dataset.\nFor the details and the usage of the dataset, please refer to our github repository page.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you find the dataset and our paper useful, please consider citing our paper:\n@article{ge2025rsteller‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SlytherinGe/RSTeller.","first_N":5,"first_N_keywords":["image-to-text","English","apache-2.0","1M - 10M","webdataset"],"keywords_longer_than_N":true},
	{"name":"global-streetscapes-parquet","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ClaireDons/global-streetscapes-parquet","creator_name":"Claire Donnelly","creator_url":"https://huggingface.co/ClaireDons","description":"\n\t\n\t\t\n\t\tGlobal Streetscapes\n\t\n\nRepository for the tabular portion of the Global Streetscapes dataset by the Urban Analytics Lab (UAL) at the National University of Singapore (NUS).\n\n\t\n\t\t\n\t\tContent Breakdown\n\t\n\nGlobal Streetscapes (62+ GB)\n‚îú‚îÄ‚îÄ data/ (37 GB)\n‚îÇ   ‚îú‚îÄ‚îÄ 21 CSV files with 346 unique features in total and 10M rows each\n‚îú‚îÄ‚îÄ manual_labels/ (23 GB)\n‚îÇ   ‚îú‚îÄ‚îÄ train/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 8 CSV files with manual labels for contextual attributes (training)\n‚îÇ   ‚îú‚îÄ‚îÄ test/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 8 CSV files with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ClaireDons/global-streetscapes-parquet.","first_N":5,"first_N_keywords":["image-classification","image-segmentation","image-feature-extraction","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"global-streetscapes-parquet","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ClaireDons/global-streetscapes-parquet","creator_name":"Claire Donnelly","creator_url":"https://huggingface.co/ClaireDons","description":"\n\t\n\t\t\n\t\tGlobal Streetscapes\n\t\n\nRepository for the tabular portion of the Global Streetscapes dataset by the Urban Analytics Lab (UAL) at the National University of Singapore (NUS).\n\n\t\n\t\t\n\t\tContent Breakdown\n\t\n\nGlobal Streetscapes (62+ GB)\n‚îú‚îÄ‚îÄ data/ (37 GB)\n‚îÇ   ‚îú‚îÄ‚îÄ 21 CSV files with 346 unique features in total and 10M rows each\n‚îú‚îÄ‚îÄ manual_labels/ (23 GB)\n‚îÇ   ‚îú‚îÄ‚îÄ train/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 8 CSV files with manual labels for contextual attributes (training)\n‚îÇ   ‚îú‚îÄ‚îÄ test/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 8 CSV files with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ClaireDons/global-streetscapes-parquet.","first_N":5,"first_N_keywords":["image-classification","image-segmentation","image-feature-extraction","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"SmallMinesDS","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ellaampy/SmallMinesDS","creator_name":"SOA","creator_url":"https://huggingface.co/ellaampy","description":"\n\t\n\t\t\n\t\tSmallMinesDS\n\t\n\nThe gradual expansion of unregularized artisanal small-scale gold mining (ASGM) fuels environmental degradation and poses risk to miners and mining communities. To enforce sustainable mining, support reclamation initiatives and pave the way for understudying the impacts of mining, we present SmallMinesDS, a benchmark dataset for mapping artisanal small-scale gold mining from multi-sensor satellite images. The initial version of the dataset covers five districts in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ellaampy/SmallMinesDS.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","1K - 10K","csv","Image","Text"],"keywords_longer_than_N":true},
	{"name":"Core-S1RTC-DeCUR","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S1RTC-DeCUR","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S1RTC-DeCUR üì°‚ö°üõ∞Ô∏è\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S1RTC-SSL4EO\nSentinel-1 RTC\n36,748,875\nSAR\nGeneral-Purpose Global\nCore-S1RTC\nDeCUR\nGB\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nTypeDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u\nint\nMajor TOM cell row‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S1RTC-DeCUR.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M<n<100M","Geospatial","arxiv:2412.05600","doi:10.57967/hf/5239"],"keywords_longer_than_N":true},
	{"name":"Core-S1RTC-DeCUR","keyword":"earth-observation","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S1RTC-DeCUR","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S1RTC-DeCUR üì°‚ö°üõ∞Ô∏è\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S1RTC-SSL4EO\nSentinel-1 RTC\n36,748,875\nSAR\nGeneral-Purpose Global\nCore-S1RTC\nDeCUR\nGB\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nTypeDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u\nint\nMajor TOM cell row‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S1RTC-DeCUR.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M<n<100M","Geospatial","arxiv:2412.05600","doi:10.57967/hf/5239"],"keywords_longer_than_N":true},
	{"name":"Core-S1RTC-DeCUR","keyword":"remote-sensing","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S1RTC-DeCUR","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S1RTC-DeCUR üì°‚ö°üõ∞Ô∏è\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S1RTC-SSL4EO\nSentinel-1 RTC\n36,748,875\nSAR\nGeneral-Purpose Global\nCore-S1RTC\nDeCUR\nGB\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nTypeDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u\nint\nMajor TOM cell row‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S1RTC-DeCUR.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M<n<100M","Geospatial","arxiv:2412.05600","doi:10.57967/hf/5239"],"keywords_longer_than_N":true},
	{"name":"Core-S1RTC-DeCUR","keyword":"geospatial","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Major-TOM/Core-S1RTC-DeCUR","creator_name":"Major TOM","creator_url":"https://huggingface.co/Major-TOM","description":"\n\n\t\n\t\t\n\t\tCore-S1RTC-DeCUR üì°‚ö°üõ∞Ô∏è\n\t\n\n\n\t\n\t\t\nDataset\nModality\nNumber of Embeddings\nSensing Type\nTotal Comments\nSource Dataset\nSource Model\nSize\n\n\n\t\t\nCore-S1RTC-SSL4EO\nSentinel-1 RTC\n36,748,875\nSAR\nGeneral-Purpose Global\nCore-S1RTC\nDeCUR\nGB\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tContent\n\t\n\n\n\t\n\t\t\nField\nTypeDescription\n\n\n\t\t\nunique_id\nstring\nhash generated from geometry, time, product_id, and embedding model\n\n\nembedding\narray\nraw embedding array\n\n\ngrid_cell\nstring\nMajor TOM cell\n\n\ngrid_row_u\nint\nMajor TOM cell row‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Major-TOM/Core-S1RTC-DeCUR.","first_N":5,"first_N_keywords":["cc-by-sa-4.0","10M<n<100M","Geospatial","arxiv:2412.05600","doi:10.57967/hf/5239"],"keywords_longer_than_N":true},
	{"name":"MapEval-Visual","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapEval/MapEval-Visual","creator_name":"MapEval","creator_url":"https://huggingface.co/MapEval","description":"\n\t\n\t\t\n\t\tMapEval-Visual\n\t\n\nThis dataset was introduced in MapEval: A Map-Based Evaluation of Geo-Spatial Reasoning in Foundation Models\n\n\t\n\t\t\n\t\tExample\n\t\n\n\n\n\t\n\t\t\n\t\tQuery\n\t\n\nI am presently visiting Mount Royal Park . Could you please inform me about the nearby historical landmark?\n\n\t\n\t\t\n\t\tOptions\n\t\n\n\nCircle Stone\nSecret pool\nMaison William Caldwell Cottingham\nPoste de cavalerie du Service de police de la Ville de Montreal\n\n\n\t\n\t\t\n\t\tCorrect Option\n\t\n\n\nCircle Stone\n\n\n\t\n\t\t\n\t\tPrerequisite\n\t\n\nDownload‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapEval/MapEval-Visual.","first_N":5,"first_N_keywords":["multiple-choice","visual-question-answering","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MapEval-Visual","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapEval/MapEval-Visual","creator_name":"MapEval","creator_url":"https://huggingface.co/MapEval","description":"\n\t\n\t\t\n\t\tMapEval-Visual\n\t\n\nThis dataset was introduced in MapEval: A Map-Based Evaluation of Geo-Spatial Reasoning in Foundation Models\n\n\t\n\t\t\n\t\tExample\n\t\n\n\n\n\t\n\t\t\n\t\tQuery\n\t\n\nI am presently visiting Mount Royal Park . Could you please inform me about the nearby historical landmark?\n\n\t\n\t\t\n\t\tOptions\n\t\n\n\nCircle Stone\nSecret pool\nMaison William Caldwell Cottingham\nPoste de cavalerie du Service de police de la Ville de Montreal\n\n\n\t\n\t\t\n\t\tCorrect Option\n\t\n\n\nCircle Stone\n\n\n\t\n\t\t\n\t\tPrerequisite\n\t\n\nDownload‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapEval/MapEval-Visual.","first_N":5,"first_N_keywords":["multiple-choice","visual-question-answering","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MapEval-API","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapEval/MapEval-API","creator_name":"MapEval","creator_url":"https://huggingface.co/MapEval","description":"\n\t\n\t\t\n\t\tMapEval-API\n\t\n\nMapEval-API is created using MapQaTor.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load dataset\nds = load_dataset(\"MapEval/MapEval-API\", name=\"benchmark\")\n\n# Generate better prompts\nfor item in ds[\"test\"]:\n    # Start with a clear task description\n    prompt = (\n        \"You are a highly intelligent assistant. \"\n        \"Answer the multiple-choice question by selecting the correct option.\\n\\n\"\n        \"Question:\\n\" + item[\"question\"] + \"\\n\\n\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapEval/MapEval-API.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MapEval-API","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MapEval/MapEval-API","creator_name":"MapEval","creator_url":"https://huggingface.co/MapEval","description":"\n\t\n\t\t\n\t\tMapEval-API\n\t\n\nMapEval-API is created using MapQaTor.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load dataset\nds = load_dataset(\"MapEval/MapEval-API\", name=\"benchmark\")\n\n# Generate better prompts\nfor item in ds[\"test\"]:\n    # Start with a clear task description\n    prompt = (\n        \"You are a highly intelligent assistant. \"\n        \"Answer the multiple-choice question by selecting the correct option.\\n\\n\"\n        \"Question:\\n\" + item[\"question\"] + \"\\n\\n\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MapEval/MapEval-API.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"metamaterial-MetaModulus","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cjpcool/metamaterial-MetaModulus","creator_name":"Jianpeng Chen","creator_url":"https://huggingface.co/cjpcool","description":"\n\t\n\t\t\n\t\tüìä Metamaterial MetaModulus Dataset\n\t\n\n\n\t\n\t\t\n\t\tüßæ Dataset Summary\n\t\n\nThis dataset contains 3D metamaterial lattice structures for predicting mechanical modulus properties, including Young's modulus, Shear modulus, and Poisson's ratio. Each sample is preprocessed into a format compatible with PyTorch Geometric (PyG) for downstream machine learning tasks such as structure-property prediction, graph representation learning, and lattice optimization.\nCheck our paper on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cjpcool/metamaterial-MetaModulus.","first_N":5,"first_N_keywords":["graph-ml","mit","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"STARCOP-fast-products","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/onboard-coop/STARCOP-fast-products","creator_name":"Onboard intelligence cooperation","creator_url":"https://huggingface.co/onboard-coop","description":"\n\t\n\t\t\n\t\tPaper\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository hosts curated data products used for evaluation and training in the article\n\"Optimizing Methane Detection Onboard Satellites: Speed, Accuracy, and Low-Power Solutions for Resource-Constrained Hardware.\"\nThe dataset consists exclusively of products generated from 72 hyperspectral channels within the wavelength range of 2122‚Äì2488 nm. These products served as the training data for the models available here.\nThe original raw hyperspectral data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/onboard-coop/STARCOP-fast-products.","first_N":5,"first_N_keywords":["image-segmentation","cc-by-4.0","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"STARCOP-fast-products","keyword":"remote-sensing","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/onboard-coop/STARCOP-fast-products","creator_name":"Onboard intelligence cooperation","creator_url":"https://huggingface.co/onboard-coop","description":"\n\t\n\t\t\n\t\tPaper\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository hosts curated data products used for evaluation and training in the article\n\"Optimizing Methane Detection Onboard Satellites: Speed, Accuracy, and Low-Power Solutions for Resource-Constrained Hardware.\"\nThe dataset consists exclusively of products generated from 72 hyperspectral channels within the wavelength range of 2122‚Äì2488 nm. These products served as the training data for the models available here.\nThe original raw hyperspectral data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/onboard-coop/STARCOP-fast-products.","first_N":5,"first_N_keywords":["image-segmentation","cc-by-4.0","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"earthquake-events-180d","keyword":"geospatial","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/leorigasaki54/earthquake-events-180d","creator_name":"Sohaib Ahmed","creator_url":"https://huggingface.co/leorigasaki54","description":"\n\t\n\t\t\n\t\tEarthquake Events (Past 180 Days)\n\t\n\nThis dataset contains global earthquake event records for the past 180 days, sourced from the USGS Earthquake API. It includes magnitude, location, time, depth, and URL for each event.\n\n\n\t\n\t\t\n\t\tüìë Dataset Details\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nid\nstring\nUnique event identifier\n\n\nmag\nfloat\nMagnitude of the earthquake\n\n\nplace\nstring\nText description of location\n\n\ntime_utc\ndatetime\nEvent occurrence time (UTC)\n\n\nlongitude\nfloat\nLongitude of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/leorigasaki54/earthquake-events-180d.","first_N":5,"first_N_keywords":["cc0-1.0","10K - 100K","csv","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"earthquake-events-180d","keyword":"geospatial","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/leorigasaki54/earthquake-events-180d","creator_name":"Sohaib Ahmed","creator_url":"https://huggingface.co/leorigasaki54","description":"\n\t\n\t\t\n\t\tEarthquake Events (Past 180 Days)\n\t\n\nThis dataset contains global earthquake event records for the past 180 days, sourced from the USGS Earthquake API. It includes magnitude, location, time, depth, and URL for each event.\n\n\n\t\n\t\t\n\t\tüìë Dataset Details\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nid\nstring\nUnique event identifier\n\n\nmag\nfloat\nMagnitude of the earthquake\n\n\nplace\nstring\nText description of location\n\n\ntime_utc\ndatetime\nEvent occurrence time (UTC)\n\n\nlongitude\nfloat\nLongitude of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/leorigasaki54/earthquake-events-180d.","first_N":5,"first_N_keywords":["cc0-1.0","10K - 100K","csv","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"places","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/piemonte/places","creator_name":"patrick piemonte","creator_url":"https://huggingface.co/piemonte","description":"\n\t\n\t\t\n\t\tPlaces Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains information of roughly 70,000 places with associated metadata including locations, attribution tags, and some contact details. The data includes geographic coordinates, place descriptions, categorization through attribution tags, and some social media presence information.\n\n\t\n\t\t\n\t\tLLM Applications\n\t\n\nThis dataset is particularly valuable for training and fine-tuning Large Language Models (LLMs) for geospatial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/piemonte/places.","first_N":5,"first_N_keywords":["text-generation","text-classification","English","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"places","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/piemonte/places","creator_name":"patrick piemonte","creator_url":"https://huggingface.co/piemonte","description":"\n\t\n\t\t\n\t\tPlaces Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains information of roughly 70,000 places with associated metadata including locations, attribution tags, and some contact details. The data includes geographic coordinates, place descriptions, categorization through attribution tags, and some social media presence information.\n\n\t\n\t\t\n\t\tLLM Applications\n\t\n\nThis dataset is particularly valuable for training and fine-tuning Large Language Models (LLMs) for geospatial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/piemonte/places.","first_N":5,"first_N_keywords":["text-generation","text-classification","English","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"places","keyword":"poi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/piemonte/places","creator_name":"patrick piemonte","creator_url":"https://huggingface.co/piemonte","description":"\n\t\n\t\t\n\t\tPlaces Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains information of roughly 70,000 places with associated metadata including locations, attribution tags, and some contact details. The data includes geographic coordinates, place descriptions, categorization through attribution tags, and some social media presence information.\n\n\t\n\t\t\n\t\tLLM Applications\n\t\n\nThis dataset is particularly valuable for training and fine-tuning Large Language Models (LLMs) for geospatial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/piemonte/places.","first_N":5,"first_N_keywords":["text-generation","text-classification","English","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"MMMU_with_difficulty_level","keyword":"geography","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JierunChen/MMMU_with_difficulty_level","creator_name":"Jierun Chen","creator_url":"https://huggingface.co/JierunChen","description":"\n\t\n\t\t\n\t\tMMMU with difficulty level tags\n\t\n\nThis dataset extends the ü§ó MMMU val benchmark by introducing two additional tags: passrate_for_qwen2.5_vl_7b and difficulty_level_for_qwen2.5_vl_7b. Further details are available in our paper The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs.\n\n\t\n\t\t\n\t\n\t\n\t\tüöÄ Data Usage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"JierunChen/MMMU_with_difficulty_level\")\nprint(dataset)\n\n\n\t\n\t\n\t\n\t\tüìë‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JierunChen/MMMU_with_difficulty_level.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"light-stable-semantics","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mpg-ranch/light-stable-semantics","creator_name":"MPG Ranch","creator_url":"https://huggingface.co/mpg-ranch","description":"\n\t\n\t\t\n\t\tLight Stable Semantics Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains aerial orthomosaic tiles captured at three different times of day (10:00, 12:00, and 15:00) to develop vision encoders that are semantically stable under varying lighting conditions. The dataset is designed for training computer vision models that can maintain consistent feature representations despite changes in illumination.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nPurpose: Training light-stable semantic vision‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mpg-ranch/light-stable-semantics.","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"light-stable-semantics","keyword":"remote-sensing","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mpg-ranch/light-stable-semantics","creator_name":"MPG Ranch","creator_url":"https://huggingface.co/mpg-ranch","description":"\n\t\n\t\t\n\t\tLight Stable Semantics Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains aerial orthomosaic tiles captured at three different times of day (10:00, 12:00, and 15:00) to develop vision encoders that are semantically stable under varying lighting conditions. The dataset is designed for training computer vision models that can maintain consistent feature representations despite changes in illumination.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nPurpose: Training light-stable semantic vision‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mpg-ranch/light-stable-semantics.","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"buildings","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mahmoodalikhan1999/buildings","creator_name":"Mahmood Ali Khan","creator_url":"https://huggingface.co/mahmoodalikhan1999","description":"mahmoodalikhan1999/buildings dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","Geospatial","Image"],"keywords_longer_than_N":true},
	{"name":"vexcel_google_images","keyword":"geospatial","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mikadishen/vexcel_google_images","creator_name":"Leandro da Silva Gregorio","creator_url":"https://huggingface.co/mikadishen","description":"mikadishen/vexcel_google_images dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["gpl-3.0","< 1K","imagefolder","Geospatial","Image"],"keywords_longer_than_N":true},
	{"name":"nesteo-prototype","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nesteo-datasets/nesteo-prototype","creator_name":"NestEO Datasets","creator_url":"https://huggingface.co/nesteo-datasets","description":"\n\t\n\t\t\n\t\tNestEO: Modular and Hierarchical EO Dataset Framework\n\t\n\nNestEO is a hierarchical, resolution-aligned, UTM-based nested grid dataset framework supporting general-purpose, multi-scale multimodal Earth Observation workflows. Built from diverse EO sources and enriched with metadata for landcover, climate zones, and population, it enables scalable, representative and progressive sampling for AI4EO.\nGrid Levels: 120000m, 12000m, 2400m, 1200m, 600m, 300m, 150mGrid Metadata: ESA WorldCover‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nesteo-datasets/nesteo-prototype.","first_N":5,"first_N_keywords":["image-segmentation","image-classification","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"nesteo-prototype","keyword":"earth-observation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nesteo-datasets/nesteo-prototype","creator_name":"NestEO Datasets","creator_url":"https://huggingface.co/nesteo-datasets","description":"\n\t\n\t\t\n\t\tNestEO: Modular and Hierarchical EO Dataset Framework\n\t\n\nNestEO is a hierarchical, resolution-aligned, UTM-based nested grid dataset framework supporting general-purpose, multi-scale multimodal Earth Observation workflows. Built from diverse EO sources and enriched with metadata for landcover, climate zones, and population, it enables scalable, representative and progressive sampling for AI4EO.\nGrid Levels: 120000m, 12000m, 2400m, 1200m, 600m, 300m, 150mGrid Metadata: ESA WorldCover‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nesteo-datasets/nesteo-prototype.","first_N":5,"first_N_keywords":["image-segmentation","image-classification","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"nesteo-prototype","keyword":"remote-sensing","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nesteo-datasets/nesteo-prototype","creator_name":"NestEO Datasets","creator_url":"https://huggingface.co/nesteo-datasets","description":"\n\t\n\t\t\n\t\tNestEO: Modular and Hierarchical EO Dataset Framework\n\t\n\nNestEO is a hierarchical, resolution-aligned, UTM-based nested grid dataset framework supporting general-purpose, multi-scale multimodal Earth Observation workflows. Built from diverse EO sources and enriched with metadata for landcover, climate zones, and population, it enables scalable, representative and progressive sampling for AI4EO.\nGrid Levels: 120000m, 12000m, 2400m, 1200m, 600m, 300m, 150mGrid Metadata: ESA WorldCover‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nesteo-datasets/nesteo-prototype.","first_N":5,"first_N_keywords":["image-segmentation","image-classification","monolingual","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"NOAH-mini","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mutakabbirCarleton/NOAH-mini","creator_name":"Mutakabbir","creator_url":"https://huggingface.co/mutakabbirCarleton","description":"\n\t\n\t\t\n\t\tMOAH mini\n\t\n\nThe dataset prest here is a very samll sample of NOAH dataset.\nIn the original dataset each satellite image is ~650MB with 234,089 images present in 11 bands.\nIt is not feasible to upload the complete dataset. \nA sample of the dataset across diffrent modalities can be seen in the figure below:\n\nThe diffrence between NOAH and NOAH mini is hilighted in the figure below.\nEach subplot is a band of Landsat 8 in NOAH.\nThe region hilighted in red is the region available in NOAH‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mutakabbirCarleton/NOAH-mini.","first_N":5,"first_N_keywords":["image-to-image","mit","< 1K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"NOAH-mini","keyword":"remote-sensing","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mutakabbirCarleton/NOAH-mini","creator_name":"Mutakabbir","creator_url":"https://huggingface.co/mutakabbirCarleton","description":"\n\t\n\t\t\n\t\tMOAH mini\n\t\n\nThe dataset prest here is a very samll sample of NOAH dataset.\nIn the original dataset each satellite image is ~650MB with 234,089 images present in 11 bands.\nIt is not feasible to upload the complete dataset. \nA sample of the dataset across diffrent modalities can be seen in the figure below:\n\nThe diffrence between NOAH and NOAH mini is hilighted in the figure below.\nEach subplot is a band of Landsat 8 in NOAH.\nThe region hilighted in red is the region available in NOAH‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mutakabbirCarleton/NOAH-mini.","first_N":5,"first_N_keywords":["image-to-image","mit","< 1K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"sentinel2_Haiphongcity_2025","keyword":"geospatial","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lopmaybay/sentinel2_Haiphongcity_2025","creator_name":"Pham Dang Hien","creator_url":"https://huggingface.co/lopmaybay","description":"lopmaybay/sentinel2_Haiphongcity_2025 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["mit","< 1K","imagefolder","Geospatial","Image"],"keywords_longer_than_N":true},
	{"name":"ahgd","keyword":"geospatial","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/massomo/ahgd","creator_name":"Massimo Raso","creator_url":"https://huggingface.co/massomo","description":"\n\t\n\t\t\n\t\tAustralian Health and Geographic Data (AHGD)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Australian Health and Geographic Data (AHGD) dataset provides comprehensive health, demographic, and environmental indicators at the Statistical Area Level 2 (SA2) geography across Australia. This dataset integrates multiple authoritative Australian data sources to enable health geography research, policy analysis, and machine learning applications.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nGeographic Coverage:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/massomo/ahgd.","first_N":5,"first_N_keywords":["other","English","cc-by-4.0","n<1K","Geospatial"],"keywords_longer_than_N":true},
	{"name":"ahgd","keyword":"geography","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/massomo/ahgd","creator_name":"Massimo Raso","creator_url":"https://huggingface.co/massomo","description":"\n\t\n\t\t\n\t\tAustralian Health and Geographic Data (AHGD)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Australian Health and Geographic Data (AHGD) dataset provides comprehensive health, demographic, and environmental indicators at the Statistical Area Level 2 (SA2) geography across Australia. This dataset integrates multiple authoritative Australian data sources to enable health geography research, policy analysis, and machine learning applications.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nGeographic Coverage:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/massomo/ahgd.","first_N":5,"first_N_keywords":["other","English","cc-by-4.0","n<1K","Geospatial"],"keywords_longer_than_N":true},
	{"name":"abscorrespondance","keyword":"geography","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/massomo/abscorrespondance","creator_name":"Massimo Raso","creator_url":"https://huggingface.co/massomo","description":"\n\t\n\t\t\n\t\tAustralian Geographic Correspondence Table (ABS ASGS Edition 3)\n\t\n\nA comprehensive correspondence table linking Australian geographic hierarchies (POA ‚Üî LGA ‚Üî SA2 ‚Üî Branch Catchments) built using real Australian Bureau of Statistics (ABS) data.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset provides complete spatial correspondence relationships between different levels of the Australian Statistical Geography Standard (ASGS) Edition 3, enabling accurate feature aggregation and geographic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/massomo/abscorrespondance.","first_N":5,"first_N_keywords":["feature-extraction","tabular-classification","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"banting","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zh4rif/banting","creator_name":"Mohamad Zharif Aiman bin Mohd Zaidi","creator_url":"https://huggingface.co/zh4rif","description":"zh4rif/banting dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","< 1K","imagefolder","Geospatial","Image"],"keywords_longer_than_N":true},
	{"name":"s2lcd","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neuronelab/s2lcd","creator_name":"NeuRoNeLab","creator_url":"https://huggingface.co/neuronelab","description":"\n\t\n\t\t\n\t\tSentinel-2 Land-cover Captioning Dataset\n\t\n\nThe Sentinel-2 Land-cover Captioning Dataset (S2LCD) is a newly proposed dataset specifically designed for deep learning research on remote sensing image captioning. It comprises 1533 image patches, each of size 224 √ó 224 pixels, derived from Sentinel-2 L2A images. The dataset ensures a diverse representation of land cover and land use types in temperate regions, including forests, mountains, agricultural lands, and urban areas, each one with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neuronelab/s2lcd.","first_N":5,"first_N_keywords":["zero-shot-classification","image-classification","image-to-text","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"s2lcd","keyword":"remote-sensing","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neuronelab/s2lcd","creator_name":"NeuRoNeLab","creator_url":"https://huggingface.co/neuronelab","description":"\n\t\n\t\t\n\t\tSentinel-2 Land-cover Captioning Dataset\n\t\n\nThe Sentinel-2 Land-cover Captioning Dataset (S2LCD) is a newly proposed dataset specifically designed for deep learning research on remote sensing image captioning. It comprises 1533 image patches, each of size 224 √ó 224 pixels, derived from Sentinel-2 L2A images. The dataset ensures a diverse representation of land cover and land use types in temperate regions, including forests, mountains, agricultural lands, and urban areas, each one with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neuronelab/s2lcd.","first_N":5,"first_N_keywords":["zero-shot-classification","image-classification","image-to-text","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Datathon-Pemuda_Kalcer","keyword":"geospatial","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/umarmanggar/Datathon-Pemuda_Kalcer","creator_name":"Muhammad Umar","creator_url":"https://huggingface.co/umarmanggar","description":"umarmanggar/Datathon-Pemuda_Kalcer dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["apache-2.0","Geospatial","üá∫üá∏ Region: US"],"keywords_longer_than_N":false}
]
;
