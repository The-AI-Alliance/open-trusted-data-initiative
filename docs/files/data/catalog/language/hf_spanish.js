var data_for_language_spanish = [

  {"name":"mittens","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/google/mittens","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMiTTenS: A Dataset for Evaluating Misgendering in Translation\\n\\t\\n\\nMisgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scripts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/mittens."},
  {"name":"Reportes-radiologicos","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/feliipert/Reportes-radiologicos","creator_name":"LUIS FELIPE RAMIREZ","creator_url":"https://huggingface.co/feliipert","description":"feliipert/Reportes-radiologicos dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"boletin-oficial-argentina","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/marianbasti/boletin-oficial-argentina","creator_name":"Marian Basti","creator_url":"https://huggingface.co/marianbasti","description":"\\n\\t\\n\\t\\t\\n\\t\\tBolet√≠n Oficial de la Rep√∫blica Argentina\\n\\t\\n\\nEste dataset se actualiza diariamente a trav√©s de argentina.gob.ar, usando la librer√≠a de SandboxAI\\n\\n\\t\\n\\t\\t\\n\\t\\tFormato\\n\\t\\n\\nEl formato del dataset es el siguiente:\\n{\\n  \\\"title\\\":\\\"T√≠tulo resumido de la entrada\\\",\\n  \\\"name\\\":\\\"Nombre asignado\\\",\\n  \\\"entity\\\":\\\"Entidad gubernamental que la emite\\\",\\n  \\\"summary\\\":\\\"Resumen de la entrada\\\",\\n  \\\"full_text\\\":\\\"Contenido completo\\\",\\n  \\\"url_in_articles\\\":\\\"URLs encontradas en la entrada\\\",\\n  \\\"date\\\":\\\"Fecha publicada\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marianbasti/boletin-oficial-argentina."},
  {"name":"panlex","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex."},
  {"name":"Dominican_reddit_raw_corpus","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Arconte/Dominican_reddit_raw_corpus","creator_name":"Alejandro","creator_url":"https://huggingface.co/Arconte","description":"This is a dataset made from the scrape of the Dominican reddit r/Dominicanos, basically it is an excel with 3 columns, title, body and comments\\nThe /// symbol identifies individual comments\\nThe objective of this dataset is to transform it into useful text for fine tuning, such as dividing the text into chunks and generating a pair of questions and answers, etc.\\n"},
  {"name":"Results-Radiology","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/feliipert/Results-Radiology","creator_name":"LUIS FELIPE RAMIREZ","creator_url":"https://huggingface.co/feliipert","description":"feliipert/Results-Radiology dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"MSD_manual_topics_user_base","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nuvocare/MSD_manual_topics_user_base","creator_name":"Nuvocare","creator_url":"https://huggingface.co/nuvocare","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMSD_manual_topics_user_base\\n\\t\\n\\nThis dataset has been built with the website https://www.msdmanuals.com/ provided by Merck & Co for the greater audience.\\nThe MSD manual is an essential source of knowledge for many topics related to symptoms, diseases, health and other related topics. The manual makes an extra effort to make it available both for professionals and patients by having two distinct version. \\nThe content, while being labelled the same, differs by the type of user in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuvocare/MSD_manual_topics_user_base."},
  {"name":"ChatML-aya_dataset","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = [\\n        {\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": columns[\\\"inputs\\\"].strip(),\\n        },\\n        {‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset."},
  {"name":"eagle","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MasahiroKaneko/eagle","creator_name":"Masahiro Kaneko","creator_url":"https://huggingface.co/MasahiroKaneko","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEagle ü¶Ö: Ethical Dataset Given from Real Interactions\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repository contains the Eagle dataset, which is an ethical dataset of real interactions between humans and ChatGPT. This dataset is created to evaluate social bias, opinion bias, toxic language, and morality in Large Language Models (LLMs).\\nIf you use the Eagle dataset in your research, please cite the following:\\n@inproceedings{Eagle:arxiv:2024,\\n    title={Eagle: Ethical Dataset Given from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MasahiroKaneko/eagle."},
  {"name":"cometa","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HiTZ/cometa","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tü™Å CoMeta\\n\\t\\n\\n\\n\\nCoMeta is a manually annotated dataset corpus for metaphor detection in Spanish consisting of 3633 sentences of texts of multiple domains. We believe that CoMeta is the largest publicly available dataset with metaphorical annotations in texts of general domain for the Spanish language.\\n\\nRepository: Code and dataset in tabulated format available at https://github.com/ixa-ehu/cometa\\nPaper: Leveraging a New Spanish Corpus for Multilingual and Cross-lingual Metaphor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/cometa."},
  {"name":"UltraLink","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/R0k1e/UltraLink","creator_name":"Haoyu Wang","creator_url":"https://huggingface.co/R0k1e","description":"\\n\\n\\nmulti-lingual, knowledge-grounded, multi-round dialogue dataset and model\\n\\n  Summary  ‚Ä¢\\n Construction Process ‚Ä¢\\n Paper ‚Ä¢\\n  UltraLink-LM ‚Ä¢\\n  Github\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for UltraLink\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nUltraLink is a multi-lingual, knowledge-grounded data augmented, multi-round dialogue dataset. It contains language-specific chat data, language-agnostic chat data, code data and math data in 5 languages: English, Chinese, Spanish, Russian, and French. Different from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/R0k1e/UltraLink."},
  {"name":"Memedroid","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/JL2132131231/Memedroid","creator_name":"K","creator_url":"https://huggingface.co/JL2132131231","description":"Dataset creado con el fin de entrenar a LLama 2 7B para que hable igual que lo har√≠a un memedroider\\n"},
  {"name":"tinyllama-context-retrieval","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/GFCACACE/tinyllama-context-retrieval","creator_name":"Guillermo Federico Cacace","creator_url":"https://huggingface.co/GFCACACE","description":"GFCACACE/tinyllama-context-retrieval dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"medieval","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATMuS/medieval","creator_name":"CATMuS: Consistent Approach to Transcribing ManuScripts","creator_url":"https://huggingface.co/CATMuS","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for CATMuS Medieval\\n\\t\\n\\n\\nJoin our Discord to ask questions about the dataset: \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nHandwritten Text Recognition (HTR) has emerged as a crucial tool for converting manuscripts images into machine-readable formats, \\nenabling researchers and scholars to analyse vast collections efficiently. \\nDespite significant technological progress, establishing consistent ground truth across projects for HTR tasks, \\nparticularly for complex and heterogeneous‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATMuS/medieval."},
  {"name":"X-SVAMP_en_zh_ko_it_es","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/zhihz0535/X-SVAMP_en_zh_ko_it_es","creator_name":"Zhihan Zhang","creator_url":"https://huggingface.co/zhihz0535","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tX-SVAMP\\n\\t\\n\\nü§ó Paper | üìñ arXiv\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nX-SVAMP is an evaluation benchmark for multilingual large language models (LLMs), including questions and answers in 5 languages (English, Chinese, Korean, Italian and Spanish).\\nIt is intended to evaluate the math reasoning abilities of LLMs. The dataset is translated by GPT-4-turbo from the original English-version SVAMP.\\nIn our paper, we evaluate LLMs in a zero-shot generative setting: prompt the instruction-tuned‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zhihz0535/X-SVAMP_en_zh_ko_it_es."},
  {"name":"X-TruthfulQA_en_zh_ko_it_es","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zhihz0535/X-TruthfulQA_en_zh_ko_it_es","creator_name":"Zhihan Zhang","creator_url":"https://huggingface.co/zhihz0535","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tX-TruthfulQA\\n\\t\\n\\nü§ó Paper | üìñ arXiv\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nX-TruthfulQA is an evaluation benchmark for multilingual large language models (LLMs), including questions and answers in 5 languages (English, Chinese, Korean, Italian and Spanish).\\nIt is intended to evaluate the truthfulness of LLMs. The dataset is translated by GPT-4 from the original English-version TruthfulQA.\\nIn our paper, we evaluate LLMs in a zero-shot generative setting: prompt the instruction-tuned LLM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zhihz0535/X-TruthfulQA_en_zh_ko_it_es."},
  {"name":"MAGBIG","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/felfri/MAGBIG","creator_name":"Felix Friedrich","creator_url":"https://huggingface.co/felfri","description":"\\n\\t\\n\\t\\t\\n\\t\\tMAGBIG benchmark\\n\\t\\n\\nThis is the MAGBIG benchmark proposed in https://arxiv.org/abs/2401.16092\\nThis benchmark is intended for multilingual text-to-image models. With MAGBIG, you can generate images for a diverse set of prompts across ten different languages. These images can be evaluated for differences across languages. MAGBIG is designed to uncover and assess biases across languages such as gender, race, age, etc. This way, we can measure whether bias exists in a language, but also if‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/felfri/MAGBIG."},
  {"name":"SentiMP-Sp","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rbnuria/SentiMP-Sp","creator_name":"Nuria Rodr√≠guez Barroso","creator_url":"https://huggingface.co/rbnuria","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentiMP-Sp Dataset\\n\\t\\n\\nThe SentiMP-Sp Dataset is a spanish sentiment analysis dataset based on tweets written by members of parliament in Spain in 2021.  It has been developed collaboratively by the Andalusian Research Institute in Data Science and Computational Intelligence (DaSCI) research  group from the University of Granada, the SINAI research group from the University of Ja√©n and the Cardiff NLP research group from the University of Cardiff.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rbnuria/SentiMP-Sp."},
  {"name":"parallel_corpus_webcrawl_english_spanish_1","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Thermostatic/parallel_corpus_webcrawl_english_spanish_1","creator_name":"Irving Ernesto Quezada Ram√≠rez","creator_url":"https://huggingface.co/Thermostatic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis parallel corpus dataset contains about 21k rows of parallel English and Spanish texts obtained by crawling different websites. It has been filtered strictly.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nThis is a parallel corpus of bilingual texts crawled from multilingual websites, which contains 21, 005 TUs. A strict validation process has been followed, which resulted in discarding:\\n\\nTUs from crawled websites that do‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Thermostatic/parallel_corpus_webcrawl_english_spanish_1."},
  {"name":"parallel_corpus_webcrawl_english_spanish_1","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Thermostatic/parallel_corpus_webcrawl_english_spanish_1","creator_name":"Irving Ernesto Quezada Ram√≠rez","creator_url":"https://huggingface.co/Thermostatic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis parallel corpus dataset contains about 21k rows of parallel English and Spanish texts obtained by crawling different websites. It has been filtered strictly.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nThis is a parallel corpus of bilingual texts crawled from multilingual websites, which contains 21, 005 TUs. A strict validation process has been followed, which resulted in discarding:\\n\\nTUs from crawled websites that do‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Thermostatic/parallel_corpus_webcrawl_english_spanish_1."},
  {"name":"spa_climate_detection","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/somosnlp/spa_climate_detection","creator_name":"SomosNLP","creator_url":"https://huggingface.co/somosnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BERTIN-ClimID: BERTIN-Base Climate-related text Identification\\n\\t\\n\\nREADME Spanish Version: README_ES \\nDataset for BERTIN-ClimID was developed as the fusion of different sources (open-source).\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nCurated by: Gerardo Huerta Gabriela Zu√±iga\\nFunded by: SomosNLP, HuggingFace\\nLanguage(s): es-ES, es-PE\\nLicense: cc-by-nc-sa-4.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nRepository: somosnlp/spa_climate_detection‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp/spa_climate_detection."},
  {"name":"synthetic-introduction-extraction","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/angelmmiguel/synthetic-introduction-extraction","creator_name":"Angel M De Miguel","creator_url":"https://huggingface.co/angelmmiguel","description":"angelmmiguel/synthetic-introduction-extraction dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"MMedBench","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/aisc-team-c2/MMedBench","creator_name":"AISC Team C2","creator_url":"https://huggingface.co/aisc-team-c2","description":"This is a dataset repository made for the AISC class at Harvard Medical School. Please find the original dataset repository here: https://huggingface.co/datasets/Henrychur/MMedBench \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMedBench\\n\\t\\n\\nüíªGithub Repo   üñ®Ô∏èarXiv Paper\\nThe official benchmark for \\\"Towards Building Multilingual Language Model for Medicine\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repo contains MMedBench, a comprehensive multilingual medical benchmark comprising 45,048 QA pairs for training and 8,518 QA pairs for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aisc-team-c2/MMedBench."},
  {"name":"NFR_Spanish_requirements_classification","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/MariaIsabel/NFR_Spanish_requirements_classification","creator_name":"Maria Isabel Limaylla Lunarejo","creator_url":"https://huggingface.co/MariaIsabel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nReSpaN(Spanish Dataset for non-functional requirements classification): Published version of dataset used for paper 'Towards a FAIR Dataset for non-functional requirements'.This dataset was created following the FAIR principles. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nSpanish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nIn the dataset_structure file.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInitial Data Collection and Normalization\\n\\t\\n\\nThis dataset was created‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MariaIsabel/NFR_Spanish_requirements_classification."},
  {"name":"PROMISE_NFR_translated","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/MariaIsabel/PROMISE_NFR_translated","creator_name":"Maria Isabel Limaylla Lunarejo","creator_url":"https://huggingface.co/MariaIsabel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPublished version of PROMISE NFR translated to Spanish used for paper 'Requirements Classification Using FastText and BETO in Spanish Documents'\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nSpanish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nProject: Project's Identifier.\\nRequirement: Description of the software requirement.\\nLabel: Label of the requirement: F (functional requirement) and NF (non-functional requirement).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MariaIsabel/PROMISE_NFR_translated."},
  {"name":"InstructTranslation-EN-ES","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Iker/InstructTranslation-EN-ES","creator_name":"Iker Garc√≠a-Ferrero","creator_url":"https://huggingface.co/Iker","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTranslation of Instructions EN-ES\\n\\t\\n\\nThis dataset contains prompts and answers from teknium/OpenHermes-2.5 translated to Spanish using GPT-4-0125-preview. The dataset is intended to be used for training a model to translate instructions from English to Spanish.\\nThe dataset is formatted with the TowerInstruct format. It is ready to finetune a Tower translation model. if you want the raw translations, there are available here:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Iker/InstructTranslation-EN-ES."},
  {"name":"InstructTranslation-EN-ES-Raw","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Iker/InstructTranslation-EN-ES-Raw","creator_name":"Iker Garc√≠a-Ferrero","creator_url":"https://huggingface.co/Iker","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTranslation of Instructions EN-ES\\n\\t\\n\\nThis dataset contains prompts and answers from teknium/OpenHermes-2.5 translated to Spanish using GPT-4-0125-preview. The dataset is intended to be used for training a model to translate instructions from English to Spanish.\\nThe dataset contains a conversation field in with the English instruction/answer and translation with the translated text. example_no and conversation_no corresponds to the original example id and conversation number in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Iker/InstructTranslation-EN-ES-Raw."},
  {"name":"multilingual-wealth-alpaca","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/dgallitelli/multilingual-wealth-alpaca","creator_name":"Davide Gallitelli","creator_url":"https://huggingface.co/dgallitelli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Wealth Alpaca Dataset\\n\\t\\n\\n\\nWork derivative of gbharti/wealth-alpaca_lora dataset. The original dataset is a combination of Stanford's Alpaca (https://github.com/tatsu-lab/stanford_alpaca) and FiQA (https://sites.google.com/view/fiqa/) with another 1.3k pairs custom generated using GPT3.5 . This version is a cleaned up version, which also has: \\n\\nmutlilingual support (en, it, fr, es, de)\\nCSV and JSON files\\n\\n"},
  {"name":"MSD_instruct","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nuvocare/MSD_instruct","creator_name":"Nuvocare","creator_url":"https://huggingface.co/nuvocare","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMSD_manual_topics_user_base\\n\\t\\n\\nThis dataset has been built with the website https://www.msdmanuals.com/ provided by Merck & Co for the greater audience.\\nThe MSD manual is an essential source of knowledge for many topics related to symptoms, diseases, health and other related topics. The manual makes an extra effort to make it available both for professionals and patients by having two distinct version. \\nThe content, while being labelled the same, differs by the type of user in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuvocare/MSD_instruct."},
  {"name":"Multi-lingual_Detection","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Manirathinam21/Multi-lingual_Detection","creator_name":"Manirathinam","creator_url":"https://huggingface.co/Manirathinam21","description":"Manirathinam21/Multi-lingual_Detection dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"refugiados_qa","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/narhim/refugiados_qa","creator_name":"Teresa Martin Soeder","creator_url":"https://huggingface.co/narhim","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFiltered Spanish Instruction Question-Answering Legal Refugiados\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nFiltered Spanish Instruction Question-Answering Legal Refugiados is a collection of instruction queries filtered from the dataset at edumunozsala/instruct-legal-refugiados-es and split into train and test.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCompuesto por unos 10.326 registros que contienen los campos:\\n\\ninstrucci√≥n: una instrucci√≥n o consulta.\\ninput: un contexto para resolver la‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/narhim/refugiados_qa."},
  {"name":"instruct-legal-refugiados-es","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/edumunozsala/instruct-legal-refugiados-es","creator_name":"Eduardo Mu√±oz Sala","creator_url":"https://huggingface.co/edumunozsala","description":"\\n    \\n\\nLegal Refugiados: Un dataset para QA en temas legales de refugio, asilo y protecci√≥n internacional.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nInstruction Question-Answering Legal Refugiados es una colecci√≥n de instrucciones extra√≠das de una gran cantidad de documentos legales del gobierno de Espa√±a, principalmente, y de otras instituciones de la UE y tambi√©n de otros pa√≠ses de habla hispana como M√©xico o Venezuela. Todos ellos est√°n relacionados con leyes y disposiciones legales sobre‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/edumunozsala/instruct-legal-refugiados-es."},
  {"name":"SMC","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/somosnlp/SMC","creator_name":"SomosNLP","creator_url":"https://huggingface.co/somosnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spanish Medical Corpus (SMC)\\n\\t\\n\\n\\n\\n\\n\\n\\n\\nThis dataset groups and organizes several datasets present in hugginface (e.g.: PlanTL-GOB-ES/cantemist-ner, PlanTL-GOB-ES/pharmaconer)\\nand other public resources created by researchers with different formats (e.g.; MedLexSp )\\nto allow it to be a source of knowledge of large language models in Spanish for the medical domain.\\n\\n\\nDataset Card in Spanish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\nCurated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp/SMC."},
  {"name":"iati-policy-markers","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/devinitorg/iati-policy-markers","creator_name":"Development Initiatives","creator_url":"https://huggingface.co/devinitorg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInternational Aid Transparency Initiative (IATI) Policy Marker Dataset\\n\\t\\n\\nA multi-purpose dataset including all activity title and description text published to IATI with metadata for policy markers.\\nFor more information on IATI policy markers, see the element page on the IATI Standard Website.\\nIATI is a living data source, and this dataset was last updated on 21 August, 2024. For the code to generate an updated version of this dataset, please see my Github repository here.\\nFor any‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/devinitorg/iati-policy-markers."},
  {"name":"Publico","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hugosousa/Publico","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tP√∫blico\\n\\t\\n\\nThis dataset was build by translating a set of 34,157 news from P√∫blico, an European Portuguese news paper. The news have been translated using Google Translator.\\nTo now more about the data visit the Github repos used to scrape and translate the news.\\n"},
  {"name":"mewsli-x","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\\nand converted into different parts (see process.py):\\n\\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\\n\\nRaw data files are in raw.tar.gz, which contains:\\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\\n[...] 9.8M Feb 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x."},
  {"name":"Barcenas-Economia","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Danielbrdz/Barcenas-Economia","creator_name":"Daniel","creator_url":"https://huggingface.co/Danielbrdz","description":"Este dataset, completamente en espa√±ol, es una valiosa colecci√≥n de 2000 ejemplos centrados en el amplio campo de la econom√≠a. Cubre una variedad de corrientes econ√≥micas, incluyendo la econom√≠a liberal, nacional y socialista, entre otras.\\nEstos datos fueron creados por GPT 3.5 Turbo.\\nThis dataset, entirely in Spanish, is a valuable collection of 2000 examples focused on the broad field of economics. It covers a variety of economic currents, including liberal, national, and socialist economics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Danielbrdz/Barcenas-Economia."},
  {"name":"Barcenas-Economia","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Danielbrdz/Barcenas-Economia","creator_name":"Daniel","creator_url":"https://huggingface.co/Danielbrdz","description":"Este dataset, completamente en espa√±ol, es una valiosa colecci√≥n de 2000 ejemplos centrados en el amplio campo de la econom√≠a. Cubre una variedad de corrientes econ√≥micas, incluyendo la econom√≠a liberal, nacional y socialista, entre otras.\\nEstos datos fueron creados por GPT 3.5 Turbo.\\nThis dataset, entirely in Spanish, is a valuable collection of 2000 examples focused on the broad field of economics. It covers a variety of economic currents, including liberal, national, and socialist economics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Danielbrdz/Barcenas-Economia."},
  {"name":"MentorES","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/MentorES","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMentor_ES is an open source dataset of 10,175 instructions in Spanish organized in several of the behavioral categories outlined in the InstructGPT paper, including closed QA, open QA, general QA, classification, information extraction, summarization, creative writing and brainstorming.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nUseful for fine-tuning instructions in large language models for downstream tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThis dataset is in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/MentorES."},
  {"name":"arc-c-okapi-eval-es","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/alvarobartt/arc-c-okapi-eval-es","creator_name":"Alvaro Bartolome","creator_url":"https://huggingface.co/alvarobartt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tARC-Challenge translated to Spanish\\n\\t\\n\\nThis dataset was generated by the Natural Language Processing Group of the University of Oregon, where they used the\\noriginal ARC-Challenge dataset in English and translated it into different languages using ChatGPT.\\nThis dataset only contains the Spanish translation, but the following languages are also covered within the original\\nsubsets posted by the University of Oregon at http://nlp.uoregon.edu/download/okapi-eval/datasets/.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alvarobartt/arc-c-okapi-eval-es."},
  {"name":"data","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/omarmus/data","creator_name":"Omar Gutierrez Condori","creator_url":"https://huggingface.co/omarmus","description":"Datos para el entrenamiento de un chatbot.\\n"},
  {"name":"MultiQ","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiQ\\n\\t\\n\\nThis is the dataset corresponding to the paper \\\"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\\\". \\nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \\ntranslated into 137 typologically diverse languages. \\n\\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ."},
  {"name":"NoticIA","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Iker/NoticIA","creator_name":"Iker Garc√≠a-Ferrero","creator_url":"https://huggingface.co/Iker","description":"\\n    \\n\\n\\n\\\"A Clickbait Article Summarization Dataset in Spanish.\\\"\\n\\nWe present NoticIA, a dataset consisting of 850 Spanish news articles featuring prominent clickbait headlines, each paired with high-quality, single-sentence generative summarizations written by humans.\\n\\nüìñ Paper: NoticIA: A Clickbait Article Summarization Dataset in Spanish\\nüíª Baseline Code: https://github.com/ikergarcia1996/NoticIA\\nü§ñ Pre Trained Models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Iker/NoticIA."},
  {"name":"MMedBench","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/aisc-team-c1/MMedBench","creator_name":"AISC Team C1","creator_url":"https://huggingface.co/aisc-team-c1","description":"This is a dataset repository made for the AISC class at Harvard Medical School. Please find the original dataset repository here: https://huggingface.co/datasets/Henrychur/MMedBench \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMedBench\\n\\t\\n\\nüíªGithub Repo   üñ®Ô∏èarXiv Paper\\nThe official benchmark for \\\"Towards Building Multilingual Language Model for Medicine\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repo contains MMedBench, a comprehensive multilingual medical benchmark comprising 45,048 QA pairs for training and 8,518 QA pairs for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aisc-team-c1/MMedBench."},
  {"name":"es-ner-massive","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/hlhdatscience/es-ner-massive","creator_name":"H√©ctor L√≥pez Hidalgo","creator_url":"https://huggingface.co/hlhdatscience","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for es-ner-massive\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe es-ner-massive dataset is a combination of three datasets: tner/wikineural, conll2002, and polyglot_ner. It is designed for Named Entity Recognition (NER) tasks. Tags are curated to be span-based and encoded according to the following convention:\\n\\n  encodings_dictionary = {\\n      \\\"O\\\": 0,\\n      \\\"PER\\\": 1,\\n      'ORG': 2,\\n      \\\"LOC\\\": 3,\\n      \\\"MISC\\\": 4\\n  }\\n \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hlhdatscience/es-ner-massive."},
  {"name":"bhojpuri","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri."},
  {"name":"Reglamento_Aeronautico_Colombiano_2024","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/somosnlp/Reglamento_Aeronautico_Colombiano_2024","creator_name":"SomosNLP","creator_url":"https://huggingface.co/somosnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RAC Corpus: Base de Datos del Reglamento Aeron√°utico Colombiano üõ´üìöüá®üá¥\\n\\t\\n\\n\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nTotal etiquetado: 100%\\n\\nEtiquetado y Curado: 24,478\\nPendiente: 0\\nBorradores: 0\\nDescartados: 696\\n\\nEste dataset contiene muestras etiquetadas del Reglamento Aeron√°utico Colombiano (RAC), abarcando la totalidad de sus cap√≠tulos. Tras una meticulosa labor de curaci√≥n y etiquetado, el dataset ha alcanzado un progreso del 100%, equivalente a un total de 25,174‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp/Reglamento_Aeronautico_Colombiano_2024."},
  {"name":"MiFirma-Ejemplo","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/devdroide/MiFirma-Ejemplo","creator_name":"devdroide","creator_url":"https://huggingface.co/devdroide","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMi Firma - Preguntas y respuestas\\n\\t\\n\\nEste colecci√≥n contiene preguntas y respuestas de una aplicaci√≥n web ficticia que se encarga de firmar documentos\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContenido\\n\\t\\n\\nTiene preguntas y repuestas con un contexto dado, como de:\\n\\nInformaci√≥n de la aplicaci√≥n\\nPerfiles\\nProductos que cubre\\nQuienes pueden firmar\\nErrores que comunes de la aplicaci√≥n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsos\\n\\t\\n\\nLa colecci√≥n tiene como objetivo ampliar la disponibilidad de datos conversacionales para la investigaci√≥n en IA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/devdroide/MiFirma-Ejemplo."},
  {"name":"multi-hatecheck","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/multi-hatecheck","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nCombines multilingual HateCheck datasets (10 languages, including English), by Paul Roettger and colleagues (2021, 2022).\\nThe original English dataset can be found under https://github.com/Paul/hatecheck.\\nDatasets for other languages are found at:\\n\\nhttps://github.com/Paul/hatecheck-arabic\\nhttps://github.com/Paul/hatecheck-mandarin\\nhttps://github.com/Paul/hatecheck-german\\nhttps://github.com/Paul/hatecheck-french\\nhttps://github.com/Paul/hatecheck-hindi‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/multi-hatecheck."},
  {"name":"mabama-v","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/aztro/mabama-v","creator_name":"Jose Omar Vieyra","creator_url":"https://huggingface.co/aztro","description":"aztro/mabama-v dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"casimedicos-exp","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/HiTZ/casimedicos-exp","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n    \\n    \\n    \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAntidote CasiMedicos Dataset - Possible Answers Explanations in Resident Medical Exams\\n\\t\\n\\nWe present a new multilingual parallel medical dataset of commented medical exams which includes not only explanatory arguments\\nfor the correct answer but also arguments to explain why the remaining possible answers are incorrect.\\nThis dataset can be used for various NLP tasks including: Medical Question Answering, Explanatory Argument Extraction or Explanation Generation.\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/casimedicos-exp."},
  {"name":"enfermedades-wiki-marzo-2024","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Alvaro8gb/enfermedades-wiki-marzo-2024","creator_name":"Alvaro Garcia Barragan","creator_url":"https://huggingface.co/Alvaro8gb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnglish Version\\n\\t\\n\\nThis dataset contains detailed information on a total of 945 diseases, extracted from Wikipedia in Spanish (https://es.wikipedia.org/) in March 2024. The main purpose of this dataset is to serve as a comprehensive resource for training Large Language Models (LLMs) in Spanish, specifically for instruction tuning, pre-training, and other natural language processing (NLP) tasks. This dataset promises to be a valuable tool for research and development in Spanish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Alvaro8gb/enfermedades-wiki-marzo-2024."},
  {"name":"en-to-es-auto-finance","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bstraehle/en-to-es-auto-finance","creator_name":"B. Straehle","creator_url":"https://huggingface.co/bstraehle","description":"What: English sentences and Spanish translations in the auto finance domain in random sort order.\\nModels:\\n\\nmeta-llama/Llama-2-70b-chat-hf\\nmistralai/Mistral-7B-Instruct-v0.1\\n\\nHyperparameters: Temperature: 0.7\\nSystem Prompt: You are an English to Spanish translator with a professional tone.\\nUser Prompts: Generate 100 unique English sentences and Spanish translation about <...> in JSON format.\\n\\nnew car financing\\nused car financing\\nauto loans\\nauto leases\\nauto loan originations\\nauto lease‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bstraehle/en-to-es-auto-finance."},
  {"name":"recetasdelaabuela_genstruct_it","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/somosnlp/recetasdelaabuela_genstruct_it","creator_name":"SomosNLP","creator_url":"https://huggingface.co/somosnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescripci√≥n\\n\\t\\n\\nDataset creado para la hackathon #Somos600M con el objetivo de entrenar un modelo que pueda recomendar recetas de paises hispanohablantes.\\nEste conjunto de datos consiste en pregunta-respuesta y fue elaborado a partir de un contexto usando Genstruct-7B y distilabel.\\nElaborado a partir del dataset en crudo somosnlp/RecetasDeLaAbuela elaborado por el equipo recetasdelaabuela mediante web scraping.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOrigen del Dataset\\n\\t\\n\\nEl dataset se obtuvo mediante web‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp/recetasdelaabuela_genstruct_it."},
  {"name":"panlex-meanings","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings."},
  {"name":"Mod_Temperatura","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/albertomarun/Mod_Temperatura","creator_name":"ALBERTO MARUN","creator_url":"https://huggingface.co/albertomarun","description":"library_name: Mod_Temperatura\\nlibrary_version: 1.0.0\\ninference: false\\ndataset-index:\\n\\nname: albertomarun/Mod_Temperatura\\ndescription: This dataset has different numbers related to the temperature conversion between Celsius and Fahrenheit.\\nresults:\\ntask:\\n  type: temperature-conversion\\ndataset:\\n  type: Mod_Temperatura.h5\\n\\n\\n\\n\\nModelo to support this \\nSimpleTemperatureCalculation\\nMore models and dataset available at: AlbertoMarunIA\\n"},
  {"name":"casimedicos-squad","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/HiTZ/casimedicos-squad","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n    \\n    \\n    \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAntidote CasiMedicos in SQuAD Format for Explanatory Argument Extraction\\n\\t\\n\\nWe present a new multilingual parallel medical dataset of commented medical exams which includes not only explanatory arguments\\nfor the correct answer but also arguments to explain why the remaining possible answers are incorrect.\\nFurthermore, this dataset allows us to setup a novel extractive task\\nwhich consists of identifying the explanation of the correct answer written by\\nmedical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/casimedicos-squad."},
  {"name":"Multilingual-BioASQ-6B","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HiTZ/Multilingual-BioASQ-6B","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n    \\n    \\n    Mutilingual BioASQ-6B\\n    \\n\\n\\nWe translate the BioASQ-6B English Question Answering dataset to generate parallel French, Italian and Spanish versions using the NLLB200 3B parameter model. For more info read the original task description: [http://bioasq.org/participate/challenges_year_6](http://bioasq.org/participate/challenges_year_6)\\n\\nWe translate the body, snippets, ideal_answer and exact_answer fields. We have validated the quality of the ideal_answer field, however, the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/Multilingual-BioASQ-6B."},
  {"name":"GPBusiness","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CarlosFersoft/GPBusiness","creator_name":"Carlos Granados","creator_url":"https://huggingface.co/CarlosFersoft","description":"CarlosFersoft/GPBusiness dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"eurlex-multilingual","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/eurlex-multilingual","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"eurlex-multilingual\\\"\\n\\t\\n\\nMore Information needed\\n"},
  {"name":"justicio-BOE-A-1978-31229-constitucion-100-chunks","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dariolopez/justicio-BOE-A-1978-31229-constitucion-100-chunks","creator_name":"Dario Lopez Padial","creator_url":"https://huggingface.co/dariolopez","description":"# -*- coding: utf-8 -*-\\n\\\"\\\"\\nAutomatically generated by Colab.\\n\\nOriginal file is located at\\n    https://colab.research.google.com/drive/1iAhLoc8FxHXijhyljdKhrIJbn342bhPD\\n\\\"\\\"\\n\\n# Commented out IPython magic to ensure Python compatibility.\\n# %pip install --upgrade langchain datasets\\n\\nimport requests\\nfrom bs4 import BeautifulSoup\\n\\nCONFIG = {\\n    'title': 'Constituci√≥n Espa√±ola',\\n    'url': \\\"https://www.boe.es/diario_boe/xml.php?id=BOE-A-1978-31229\\\",\\n    'chunk_size': 1300,\\n    'chunk_overlap': 150‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dariolopez/justicio-BOE-A-1978-31229-constitucion-100-chunks."},
  {"name":"biblenlp-corpus-mmteb","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb."},
  {"name":"biblenlp-corpus-mmteb","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb."},
  {"name":"LingComp_QA","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/somosnlp/LingComp_QA","creator_name":"SomosNLP","creator_url":"https://huggingface.co/somosnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LingComp_QA, un corpus educativo de ling√º√≠stica computacional en espa√±ol\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\nCurated by: Jorge Zamora Rey, Isabel Moyano Moreno, Mario Crespo Miguel \\nFunded by: SomosNLP, HuggingFace, Argilla, Instituto de Ling√º√≠stica Aplicada de la Universidad de C√°diz \\nLanguage(s) (NLP): es-ES \\nLicense: apache-2.0 \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nRepository: https://github.com/reddrex/lingcomp_QA/tree/main‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp/LingComp_QA."},
  {"name":"LingComp_QA","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/somosnlp/LingComp_QA","creator_name":"SomosNLP","creator_url":"https://huggingface.co/somosnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LingComp_QA, un corpus educativo de ling√º√≠stica computacional en espa√±ol\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\nCurated by: Jorge Zamora Rey, Isabel Moyano Moreno, Mario Crespo Miguel \\nFunded by: SomosNLP, HuggingFace, Argilla, Instituto de Ling√º√≠stica Aplicada de la Universidad de C√°diz \\nLanguage(s) (NLP): es-ES \\nLicense: apache-2.0 \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nRepository: https://github.com/reddrex/lingcomp_QA/tree/main‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp/LingComp_QA."},
  {"name":"constitucion-politica-del-peru-1993-qa","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/daqc/constitucion-politica-del-peru-1993-qa","creator_name":"David Quispe","creator_url":"https://huggingface.co/daqc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCompuesto por unos 2075 registros que contienen los campos:\\n\\npregunta: pregunta que sirve como una instrucci√≥n o consulta sobre alg√∫n aspecto de la Constituci√≥n Pol√≠tica del Per√∫ de 1993.\\nrespuesta: La respuesta proporcionada para cada pregunta es un contexto relevante que ayuda a resolver la consulta. Este contexto es un extracto de la Constituci√≥n.\\nfuente: Para cada respuesta, se indica el cap√≠tulo y/o art√≠culo de la Constituci√≥n Pol√≠tica del Per√∫ de 1993‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/daqc/constitucion-politica-del-peru-1993-qa."},
  {"name":"constitucion-politica-del-peru-1993-qa","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/somosnlp/constitucion-politica-del-peru-1993-qa","creator_name":"SomosNLP","creator_url":"https://huggingface.co/somosnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCompuesto por unos 2075 registros que contienen los campos:\\n\\npregunta: pregunta que sirve como una instrucci√≥n o consulta sobre alg√∫n aspecto de la Constituci√≥n Pol√≠tica del Per√∫ de 1993.\\nrespuesta: La respuesta proporcionada para cada pregunta es un contexto relevante que ayuda a resolver la consulta. Este contexto es un extracto de la Constituci√≥n.\\nfuente: Para cada respuesta, se indica el cap√≠tulo y/o art√≠culo de la Constituci√≥n Pol√≠tica del Per√∫ de 1993‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp/constitucion-politica-del-peru-1993-qa."},
  {"name":"reescritura-textos-administrativos","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/somosnlp/reescritura-textos-administrativos","creator_name":"SomosNLP","creator_url":"https://huggingface.co/somosnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for reescritura-textos-administrativos\\n\\t\\n\\nThis dataset has been created with Argilla.\\nAs shown in the sections below, this dataset can be loaded into Argilla as explained in Load with Argilla, or used directly with the datasets library in Load with datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains:\\n\\nA dataset configuration file conforming to the Argilla dataset format named argilla.yaml. This configuration file will be used to configure the dataset when‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp/reescritura-textos-administrativos."},
  {"name":"reddit-ask-v0","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/pkseeg/reddit-ask-v0","creator_name":"Parker Seegmiller","creator_url":"https://huggingface.co/pkseeg","description":"\\n\\t\\n\\t\\t\\n\\t\\tReddit r/Ask{Topic} Questions and Answers\\n\\t\\n\\n903 questions and 15,711 answers gathered from Reddit's r/Ask{Topic} communities. Each question is paired with 3+ answers (top-level comments) and each answer is assigned a community perception score (upvote ration). Dataset statistics will be given below.\\n"},
  {"name":"MedExpQA","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/HiTZ/MedExpQA","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n    \\n    \\n    \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMexExpQA: Multilingual Benchmarking of Medical QA with reference gold explanations and Retrieval Augmented Generation (RAG)\\n\\t\\n\\nWe present a new multilingual parallel medical benchmark, MedExpQA, for the evaluation of LLMs on Medical Question Answering.\\nThis benchmark can be used for various NLP tasks including: Medical Question Answering or Explanation Generation.\\nAlthough the design of MedExpQA is independent of any specific dataset, for the first version of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/MedExpQA."},
  {"name":"opus100","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Maximofn/opus100","creator_name":"Maximo Fernandez Nu√±ez","creator_url":"https://huggingface.co/Maximofn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Opus100 EN-ES\\\"\\n\\t\\n\\nMore Information needed\\n"},
  {"name":"oasst2_orpo_mix_tokenizer_phi_3_v1","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NickyNicky/oasst2_orpo_mix_tokenizer_phi_3_v1","creator_name":"Nicky","creator_url":"https://huggingface.co/NickyNicky","description":"\\nhttps://huggingface.co/datasets/NickyNicky/orpo-dpo-mix-54k\\n\\n"},
  {"name":"Codigo_Civil_y_Comercial_Argentina-QA","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Mdetry/Codigo_Civil_y_Comercial_Argentina-QA","creator_name":"Matias Detry","creator_url":"https://huggingface.co/Mdetry","description":"Mdetry/Codigo_Civil_y_Comercial_Argentina-QA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"swim-ir-cross-lingual","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SWIM-IR (Cross-lingual)\\n\\t\\n\\n\\n\\n\\nThis is the cross-lingual subset of the SWIM-IR dataset, where the query generated is in the target language and the passage is in English.\\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is a synthetic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual."},
  {"name":"spam_ham_spanish","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/softecapps/spam_ham_spanish","creator_name":"softecapps","creator_url":"https://huggingface.co/softecapps","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAn√°lisis de Dataset de Mensajes de Texto\\n\\t\\n\\nEste dataset contiene un total de 1000 mensajes de texto en espa√±ol, junto con una etiqueta que indica si el mensaje es considerado \\\"spam\\\" o \\\"ham\\\" (leg√≠timo).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tComposici√≥n del Dataset\\n\\t\\n\\nEl dataset est√° compuesto por dos columnas:\\nMensaje: Contiene el texto del mensaje.\\nEtiqueta: Indica si el mensaje es \\\"spam\\\" o \\\"ham\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPotenciales Usos\\n\\t\\n\\nEste dataset puede ser utilizado para entrenar modelos de Machine Learning con‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/softecapps/spam_ham_spanish."},
  {"name":"xsimplusplus","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n"},
  {"name":"DataSetServiefectivo","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/karlitoxz/DataSetServiefectivo","creator_name":"Juan Romero","creator_url":"https://huggingface.co/karlitoxz","description":"karlitoxz/DataSetServiefectivo dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"oasst2_orpo_mix_function_call_phi_3_v1","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NickyNicky/oasst2_orpo_mix_function_call_phi_3_v1","creator_name":"Nicky","creator_url":"https://huggingface.co/NickyNicky","description":"\\nhttps://huggingface.co/datasets/NickyNicky/function_call_orpo_sft_phi3_chatML_only\\nhttps://huggingface.co/datasets/NickyNicky/oasst2_orpo_mix_tokenizer_phi_3_v1\\n\\n\\n"},
  {"name":"Colossal-Instruction-Translation-EN-ES","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Iker/Colossal-Instruction-Translation-EN-ES","creator_name":"Iker Garc√≠a-Ferrero","creator_url":"https://huggingface.co/Iker","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColossal Instruction Translation Corpus (English - Spanish )\\n\\t\\n\\n\\nA deduplicated version of this dataset can be found here, thanks to @NickyNicky: https://huggingface.co/datasets/NickyNicky/Iker-Colossal-Instruction-Translation-EN-ES_deduplicated\\n\\nThis dataset contains 2284632 instructions and answers translated from English into Spanish. Is a fully synthetic corpus generated using machine translation. We used the model Iker/TowerInstruct-13B-v0.1-EN2ES. A few examples were also‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Iker/Colossal-Instruction-Translation-EN-ES."},
  {"name":"Iker-Colossal-Instruction-Translation-EN-ES_deduplicated","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NickyNicky/Iker-Colossal-Instruction-Translation-EN-ES_deduplicated","creator_name":"Nicky","creator_url":"https://huggingface.co/NickyNicky","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tfinal dataset.\\n\\t\\n\\nhttps://huggingface.co/datasets/NickyNicky/Iker-Colossal-Instruction-Translation-EN-ES_deduplicated_length_3600\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\toriginal dataset\\n\\t\\n\\nhttps://huggingface.co/datasets/Iker/Colossal-Instruction-Translation-EN-ES\\n\\n\\ninicial dataset: \\\"2.284.632\\\"\\ndeduplicated: \\\"1.848.374\\\"\\nremove: \\\"436.258\\\"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColossal Instruction Translation Corpus (English - Spanish ) (ORIGINAL CARD Iker)\\n\\t\\n\\nThis dataset contains 2284632 instructions and answers translated from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NickyNicky/Iker-Colossal-Instruction-Translation-EN-ES_deduplicated."},
  {"name":"OpenHermes-2.5-English-Spanish","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Iker/OpenHermes-2.5-English-Spanish","creator_name":"Iker Garc√≠a-Ferrero","creator_url":"https://huggingface.co/Iker","description":"This dataset contains parallel instructions from teknium/OpenHermes-2.5 and Iker/OpenHermes-2.5-Spanish.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tteknium/OpenHermes-2.5\\n\\t\\n\\nThe Open Hermes 2.5 dataset includes 1 million primarily synthetically generated instruction and chat samples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIker/OpenHermes-2.5-Spanish\\n\\t\\n\\nThis is a translation of the Open Hermes 2.5 dataset to Spanish using the Iker/TowerInstruct-13B-v0.1-EN2ES model. For more information about how the dataset was compiled, refer to the Dataset Card.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Iker/OpenHermes-2.5-English-Spanish."},
  {"name":"biblenlp-corpus-mmteb","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb."},
  {"name":"biblenlp-corpus-mmteb","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb."},
  {"name":"Iker-Colossal-Instruction-Translation-EN-ES_deduplicated_length_3600","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NickyNicky/Iker-Colossal-Instruction-Translation-EN-ES_deduplicated_length_3600","creator_name":"Nicky","creator_url":"https://huggingface.co/NickyNicky","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\toriginal dataset\\n\\t\\n\\nhttps://huggingface.co/datasets/Iker/Colossal-Instruction-Translation-EN-ES\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttake dataset\\n\\t\\n\\nhttps://huggingface.co/datasets/NickyNicky/Iker-Colossal-Instruction-Translation-EN-ES_deduplicated\\n\\n\\ninicial dataset: \\\"1.848.342\\\"\\n\\ngood inferences: \\\"1.698.239\\\"\\n\\nremove: \\\"150.103\\\"\\n\\n2.284.632 - 1.698.239 = 586.393\\n\\ntotal deleted: 586.393\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColossal Instruction Translation Corpus (English - Spanish ) (ORIGINAL CARD Iker)\\n\\t\\n\\nThis dataset contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NickyNicky/Iker-Colossal-Instruction-Translation-EN-ES_deduplicated_length_3600."},
  {"name":"Colossal_Translation_EN_ES_ORPO_DPO_Gemma","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NickyNicky/Colossal_Translation_EN_ES_ORPO_DPO_Gemma","creator_name":"Nicky","creator_url":"https://huggingface.co/NickyNicky","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\toriginal dataset\\n\\t\\n\\nhttps://huggingface.co/datasets/Iker/Colossal-Instruction-Translation-EN-ES\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttake dataset\\n\\t\\n\\nNickyNicky/Iker-Colossal-Instruction-Translation-EN-ES_deduplicated_length_3600\\n\\n\\n"},
  {"name":"tele_con_ciencia","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ciempiess/tele_con_ciencia","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for tele_con_ciencia\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAccording to the Facebook page of Tele con Ciencia:\\n\\\"Nuestra misi√≥n es la comunicaci√≥n p√∫blica de la ciencia y la tecnolog√≠a mexicana. El objetivo, \\nla participaci√≥n activa de todos los mexicanos en las √°reas del descubrimiento cient√≠fico y el \\ndesarrollo tecnol√≥gico.\\\"\\n\\\"Our mission is to spread the achievements of the Mexican Science and Technology. The main goal\\nis to promote the active participation of mexican‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/tele_con_ciencia."},
  {"name":"tele_con_ciencia","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ciempiess/tele_con_ciencia","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for tele_con_ciencia\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAccording to the Facebook page of Tele con Ciencia:\\n\\\"Nuestra misi√≥n es la comunicaci√≥n p√∫blica de la ciencia y la tecnolog√≠a mexicana. El objetivo, \\nla participaci√≥n activa de todos los mexicanos en las √°reas del descubrimiento cient√≠fico y el \\ndesarrollo tecnol√≥gico.\\\"\\n\\\"Our mission is to spread the achievements of the Mexican Science and Technology. The main goal\\nis to promote the active participation of mexican‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/tele_con_ciencia."},
  {"name":"librivox_spanish","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ciempiess/librivox_spanish","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for librivox_spanish\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLibrivox is a non-commercial, non-profit and ad-free project that is dedicated to make all books in the public domain available, for free, in audio format on the internet. According to this, we downloaded 300 titles in Spanish to create the LIBRIVOX SPANISH CORPUS.\\nThe LIBRIVOX SPANISH CORPUS has a duration of 73 hours and it is constituted by audio files between 3 and 10 seconds long, manually segmented.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/librivox_spanish."},
  {"name":"voxforge_spanish","keyword":"spanish","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/ciempiess/voxforge_spanish","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for voxforge_spanish\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nVoxForge was set up to collect transcribed speech for use with Free and Open Source Speech Recognition Engines (on Linux, Windows and Mac). They promise they will make available all submitted audio files under the GPL license, and then 'compile' them into acoustic models for use with Open Source speech recognition engines such as CMU Sphinx, ISIP, Julius and HTK. According to this, we downloaded the Spanish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/voxforge_spanish."},
  {"name":"lenguaje-claro-dataset","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/somosnlp/lenguaje-claro-dataset","creator_name":"SomosNLP","creator_url":"https://huggingface.co/somosnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Lenguaje-Claro-Dataset\\n\\t\\n\\nNombre del corpus: Lenguaje-Claro-Dataset\\nIdioma: Espa√±ol\\nEl corpus \\\"Lenguaje-Claro-Dataset\\\" se compone de textos legales y administrativos en espa√±ol que han sido simplificados para mejorar su comprensi√≥n por parte del p√∫blico general. Este dataset ha sido desarrollado para apoyar la creaci√≥n de modelos de procesamiento de lenguaje natural que faciliten la accesibilidad a documentos gubernamentales, promoviendo una mayor transparencia y‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp/lenguaje-claro-dataset."},
  {"name":"instruct-legal-refugiados-es","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/somosnlp/instruct-legal-refugiados-es","creator_name":"SomosNLP","creator_url":"https://huggingface.co/somosnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AsistenciaRefugiados\\n\\t\\n\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\nREADME in Spanish\\nSpain is the third country with the highest number of asylum applications, receiving each year approximately more than 100,000 applications, and the third with the lowest number of approvals within the EU.\\nThe main objective of this project is to facilitate the tasks of NGOs in this field and other institutions and help them to obtain answers to questions (QA) related to refugee legislation in Spanish. With‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp/instruct-legal-refugiados-es."},
  {"name":"LLM_SQL_BaseDatosEspanol","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/somosnlp/LLM_SQL_BaseDatosEspanol","creator_name":"SomosNLP","creator_url":"https://huggingface.co/somosnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsos\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsos directos\\n\\t\\n\\nEl objetivo principal de este dataset es proporcionar ejemplos simples para el fine-tuning de modelos \\nde procesamiento de lenguaje natural (NLP) en el contexto de consultas SQL.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsos fuera de mira\\n\\t\\n\\nPodria usarse para el entrenamiento de una IA que sirva como creadora de base de datos artificiales \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEstructura del conjunto de datos\\n\\t\\n\\n\\nQuestion: Es la pegunta que el usuario le dara al chatbot\\nAnswer: La respuesta el que‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp/LLM_SQL_BaseDatosEspanol."},
  {"name":"meta4xnli","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HiTZ/meta4xnli","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nMeta4XNLI is a parallel dataset with annotations in English and Spanish for metaphor detection at token level (13320 sentences) and metaphor interpretation framed within NLI the task (9990 premise-hypothesis pairs).\\nIt is a collection of existing NLI datasets manually labeled for both metaphor tasks.\\n\\nRepository: data available also in .tsv format at https://github.com/elisanchez-beep/meta4xnli\\nPaper: Meta4XNLI: A Crosslingual Parallel Corpus for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/meta4xnli."},
  {"name":"medquades","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/altbrainblock/medquades","creator_name":"alt","creator_url":"https://huggingface.co/altbrainblock","description":"Spanish partial version of MEDQUAD datset (BenAbacha-BMC-2019) with 15869 question-answers."},
  {"name":"medquades","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/altbrainblock/medquades","creator_name":"alt","creator_url":"https://huggingface.co/altbrainblock","description":"Spanish partial version of MEDQUAD datset (BenAbacha-BMC-2019) with 15869 question-answers."},
  {"name":"Barcenas-Hackathon-2024-Somos-NLP-Transcripcion","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Danielbrdz/Barcenas-Hackathon-2024-Somos-NLP-Transcripcion","creator_name":"Daniel","creator_url":"https://huggingface.co/Danielbrdz","description":"Transcripci√≥n de las Keynotes del Hackathon 2024 de Somos NLP.\\nTranscripciones hechas por Whisper Small.\\nAgradecemos a todos los participantes de este Hackathon 2024 y en especial a Mar√≠a Grandury por organizar el evento de este a√±o.\\n\\nTranscription of the Keynotes from the 2024 Somos NLP Hackathon.\\nTranscriptions made by Whisper Small.\\nWe would like to thank all the participants of this Hackathon 2024 and especially Mar√≠a Grandury for organizing this year's event.\\nMade with ‚ù§Ô∏è in Guadalupe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Danielbrdz/Barcenas-Hackathon-2024-Somos-NLP-Transcripcion."},
  {"name":"mabama-v5","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ovieyra21/mabama-v5","creator_name":"Oma Vieyra","creator_url":"https://huggingface.co/ovieyra21","description":"ovieyra21/mabama-v5 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"spanish-news","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MarcOrfilaCarreras/spanish-news","creator_name":"Marc Orfila Carreras","creator_url":"https://huggingface.co/MarcOrfilaCarreras","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpanish News\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Spain News is a collection of news articles sourced from various Spanish publications covering a wide range of topics. This dataset is curated to provide a comprehensive view of news trends and developments within Spain.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContent\\n\\t\\n\\nThe dataset includes articles from reputable Spanish news sources spanning different categories such as politics, economy, sports, culture, technology, and more.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nThe purpose‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MarcOrfilaCarreras/spanish-news."},
  {"name":"qonto-open-qa","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ThomasCdnns/qonto-open-qa","creator_name":"Thomas Chardonnens","creator_url":"https://huggingface.co/ThomasCdnns","description":"ThomasCdnns/qonto-open-qa dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Document-Translation-en-es","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Iker/Document-Translation-en-es","creator_name":"Iker Garc√≠a-Ferrero","creator_url":"https://huggingface.co/Iker","description":"This dataset contains 10533 news articles from ELiRF/dacsa translated from Spanish to English using GPT-3.5-turbo. The dataset is intended to be used for training a model to translate text from English to Spanish and vicerversa. The dataset is also usefull to evaluate document level machine translation models.\\nWe use the following prompt\\n\\ndef get_conversation(text: str, id: int) -> str:\\n    messages = {\\n        \\\"custom_id\\\": str(id),\\n        \\\"method\\\": \\\"POST\\\",\\n        \\\"url\\\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Iker/Document-Translation-en-es."},
  {"name":"OpenHermes-2.5-Spanish","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Iker/OpenHermes-2.5-Spanish","creator_name":"Iker Garc√≠a-Ferrero","creator_url":"https://huggingface.co/Iker","description":"\\nteknium/OpenHermes-2.5 dataset translated to Spanish using the Iker/TowerInstruct-13B-v0.1-EN2ES model. This dataset has a total of 1 Million High-Quality instructions in Spanish!!\\nThe original dataset can be found here: https://hf.co/datasets/teknium/OpenHermes-2.5\\nI have also added the following datasets:\\n\\nIker/Document-Translation-en-es\\nIker/InstructTranslation-EN-ES\\nHelsinki-NLP/opus-100 (en-es, only a few examples to reach 1 million instructions)\\nprojecte-aina/RAG_Multilingual(es only‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Iker/OpenHermes-2.5-Spanish."},
  {"name":"Colossal_Translation_Spanish_to_English_AND_English_to_Spanish_ORPO_DPO_Gemma","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NickyNicky/Colossal_Translation_Spanish_to_English_AND_English_to_Spanish_ORPO_DPO_Gemma","creator_name":"Nicky","creator_url":"https://huggingface.co/NickyNicky","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\toriginal dataset\\n\\t\\n\\nhttps://huggingface.co/datasets/Iker/Colossal-Instruction-Translation-EN-ES\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttake dataset\\n\\t\\n\\nNickyNicky/Iker-Colossal-Instruction-Translation-EN-ES_deduplicated_length_3600\\n\\n\\n"},
  {"name":"SPACCC-Spanish-NER","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/IEETA/SPACCC-Spanish-NER","creator_name":"Institute of Electronics and Informatics Engineering of Aveiro","creator_url":"https://huggingface.co/IEETA","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe merged dataset utilized in this project combines four distinct annotated datasets, all based on the Spanish Clinical Case Corpus (SPACCC), a compilation of clinical case reports from Spanish medical publications. This merged dataset encompasses a total of 16,504 sentences across 1,000 clinical cases. The dataset focuses on identifying various medical entities within clinical narratives, including symptoms, medical procedures, diseases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IEETA/SPACCC-Spanish-NER."},
  {"name":"sib200","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200."},
  {"name":"MAiDE-up","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MichiganNLP/MAiDE-up","creator_name":"LIT @ UMich","creator_url":"https://huggingface.co/MichiganNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MAiDE-up: Multilingual Deception Detection of GPT-generated Hotel Reviews\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultilingual Deception Detection of GPT-generated Hotel Reviews. We compare real hotel reviews from Booking with LLM-generated hotel reviews in 10 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in 10 languages: Chinese, English, French, German, Italian, Romanian, Korean, Russian, Spanish, Turkish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MichiganNLP/MAiDE-up."},
  {"name":"kmZQBkk558WWAGV","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/israel/kmZQBkk558WWAGV","creator_name":"Israel Abebe Azime","creator_url":"https://huggingface.co/israel","description":"israel/kmZQBkk558WWAGV dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"kmZQBkk558WWAGV","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/israel/kmZQBkk558WWAGV","creator_name":"Israel Abebe Azime","creator_url":"https://huggingface.co/israel","description":"israel/kmZQBkk558WWAGV dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"financial_phrasebank_traslate_En_Es","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NickyNicky/financial_phrasebank_traslate_En_Es","creator_name":"Nicky","creator_url":"https://huggingface.co/NickyNicky","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttime traslation.\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlabels.\\n\\t\\n\\n\\nNegativo: 0\\nNeutral: 1\\nPositivo: 2\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmodel use for traslation.\\n\\t\\n\\nhttps://huggingface.co/NickyNicky/gemma-1.1-2b-it_orpo_traslate_en_es_V1\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\toriginal dataset:\\n\\t\\n\\nhttps://huggingface.co/datasets/financial_phrasebank\\n\\n"},
  {"name":"toxi-text-es_and_en-2M","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NickyNicky/toxi-text-es_and_en-2M","creator_name":"Nicky","creator_url":"https://huggingface.co/NickyNicky","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\toriginal dataset\\n\\t\\n\\nhttps://huggingface.co/datasets/FredZhang7/toxi-text-3M\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tis_toxic.\\n\\t\\n\\ntoxic: 1\\nno toxic: 0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported types of toxicity:\\n\\t\\n\\n- Identity Hate/Homophobia\\n- Misogyny\\n- Violent Extremism\\n- Hate Speech\\n- Offensive Insults\\n- Sexting\\n- Obscene\\n- Threats\\n- Harassment\\n- Racism\\n- Trolling\\n- Doxing\\n- Others\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported languages:\\n\\t\\n\\n- en\\n- es\\n\\n"},
  {"name":"DIBT_prompts_ranked_English_to_Spanish_translator","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NickyNicky/DIBT_prompts_ranked_English_to_Spanish_translator","creator_name":"Nicky","creator_url":"https://huggingface.co/NickyNicky","description":"https://huggingface.co/datasets/NickyNicky/DIBT_prompts_ranked\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tnota:\\n\\t\\n\\n\\nno se tradujo texto mayor a 2048 tokens,\\n\\n"},
  {"name":"justicio-BOE-A-1978-31229-constitucion-by-articles","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dariolopez/justicio-BOE-A-1978-31229-constitucion-by-articles","creator_name":"Dario Lopez Padial","creator_url":"https://huggingface.co/dariolopez","description":"dariolopez/justicio-BOE-A-1978-31229-constitucion-by-articles dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"justicio-BOE-A-1978-31229-constitucion-by-articles-qa-reduced","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dariolopez/justicio-BOE-A-1978-31229-constitucion-by-articles-qa-reduced","creator_name":"Dario Lopez Padial","creator_url":"https://huggingface.co/dariolopez","description":"dariolopez/justicio-BOE-A-1978-31229-constitucion-by-articles-qa-reduced dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"SPACCC-documents","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/IEETA/SPACCC-documents","creator_name":"Institute of Electronics and Informatics Engineering of Aveiro","creator_url":"https://huggingface.co/IEETA","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SPACCC (Original Documents)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe SPACCC (Spanish Clinical Case Corpus) dataset consists of original clinical case documents in Spanish. \\nThese documents should be utilized in conjucntion with this dataset in order to perform biomedical Named Entity Recognition.\\nThis is a redistribution of the original dataset, which can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset supports tasks related to named entity‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IEETA/SPACCC-documents."},
  {"name":"justicio-BOE-A-1978-31229-constitucion-by-articles-qa","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dariolopez/justicio-BOE-A-1978-31229-constitucion-by-articles-qa","creator_name":"Dario Lopez Padial","creator_url":"https://huggingface.co/dariolopez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset summary\\n\\t\\n\\nIt is a synthetic dataset created to evaluate a RAG pattern for Justicio.\\n\\nDomain: Legal, Law, Spanish Constitution\\nLanguage: Spanish\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tJusticio summary\\n\\t\\n\\nJusticio is a Question/Answering Assistant that generates answers from user questions about the official state gazette of Spain: Bolet√≠n Oficial del Estado (BOE).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\nnumber: Number of the article of the Spanish Constitution.\\ncontext: Text of the article of the Spanish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dariolopez/justicio-BOE-A-1978-31229-constitucion-by-articles-qa."},
  {"name":"newscrawl_enhanced_gender_balance","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jurasova/newscrawl_enhanced_gender_balance","creator_name":"Daniela Jur√°≈°ov√°","creator_url":"https://huggingface.co/jurasova","description":"This dataset is the product of our work focused on the investigation of the development of the representation of gender forms, specifically male and female forms of occupations, in textual data.\\nWe used the newscrawl dataset (Newscrawl doc-split data; WMT overview paper) for Czech, German, Spanish and Polish and employed clustering and filtering techniques (based on temporal and topic information) to extract a gender-balanced portion of the data. The dataset is therefore released under the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jurasova/newscrawl_enhanced_gender_balance."},
  {"name":"google-la-voices","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ittailup/google-la-voices","creator_name":"Gabriel Puliatti","creator_url":"https://huggingface.co/ittailup","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"google-la-voices\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpeaker Durations\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nSpeaker\\nDuration (seconds)\\n\\n\\n\\t\\t\\n00295\\n1606.144\\n\\n\\n00610\\n7026.261\\n\\n\\n01208\\n3284.907\\n\\n\\n01523\\n6309.888\\n\\n\\n02121\\n4687.445\\n\\n\\n02436\\n4654.080\\n\\n\\n02484\\n9379.925\\n\\n\\n02485\\n130.219\\n\\n\\n03034\\n5186.048\\n\\n\\n03349\\n5143.381\\n\\n\\n03397\\n7852.203\\n\\n\\n03398\\n118.101\\n\\n\\n03853\\n638.037\\n\\n\\n04310\\n8260.437\\n\\n\\n04311\\n105.472\\n\\n\\n04766\\n590.165\\n\\n\\n05223\\n8257.773\\n\\n\\n05679\\n846.251\\n\\n\\n06136\\n10207.707\\n\\n\\n06592\\n863.659\\n\\n\\n07049\\n7580.715\\n\\n\\n07060\\n575.659\\n\\n\\n07505‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ittailup/google-la-voices."},
  {"name":"justicio-BOE-A-1978-31229-constitucion-by-articles-qa-qa-groq_llama3_70b_8192","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dariolopez/justicio-BOE-A-1978-31229-constitucion-by-articles-qa-qa-groq_llama3_70b_8192","creator_name":"Dario Lopez Padial","creator_url":"https://huggingface.co/dariolopez","description":"dariolopez/justicio-BOE-A-1978-31229-constitucion-by-articles-qa-qa-groq_llama3_70b_8192 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"squad-es-v2-1-filtrado","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CarPeAs/squad-es-v2-1-filtrado","creator_name":"Carlos P√©rez","creator_url":"https://huggingface.co/CarPeAs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSQuAD-es v2.1 Filtrado\\n\\t\\n\\nEste dataset es una versi√≥n filtrada del SQuAD-es v2.0, donde solo se incluyen los registros con m√°s de 10 p√°rrafos en el conjunto de entrenamiento.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEstructura del Dataset\\n\\t\\n\\n\\ntrain: Conjunto de entrenamiento.\\ntest: Conjunto de prueba.\\nvalidation: Conjunto de validaci√≥n.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEjemplo de Uso\\n\\t\\n\\nfrom datasets import load_dataset\\n\\n# Cargar el dataset\\ndataset = load_dataset('CarPeAs/squad-es-v2-1-filtrado-dataset')\\n\\n# Acceder a un ejemplo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CarPeAs/squad-es-v2-1-filtrado."},
  {"name":"justicio-BOE-A-1978-31229-constitucion-by-articles-qa-qa-groq_llama3_70b_8192-sas","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dariolopez/justicio-BOE-A-1978-31229-constitucion-by-articles-qa-qa-groq_llama3_70b_8192-sas","creator_name":"Dario Lopez Padial","creator_url":"https://huggingface.co/dariolopez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset summary\\n\\t\\n\\nIt is an end-to-end evaluation dataset (using SAS metric) for Justicio.\\n\\nDomain: Legal, Law, Spanish Constitution\\nLanguage: Spanish\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSAS summary\\n\\t\\n\\nThe concept of Semantic Answer Similarity refers to the evaluation of the semantic similarity between the generated answer and the ground truth. The score ranges from 0 to 1. A higher score indicates a better match between the generated answer and the ground truth.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tJusticio summary\\n\\t\\n\\nJusticio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dariolopez/justicio-BOE-A-1978-31229-constitucion-by-articles-qa-qa-groq_llama3_70b_8192-sas."},
  {"name":"multilingual-llava-bench-in-the-wild","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual LLaVA Bench in the Wild\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote that this is a copy from https://huggingface.co/datasets/MBZUAI/multilingual-llava-bench-in-the-wild\\n\\t\\n\\nIt was created due to issues in the original repo. It also includes the image features and has a uniform and joined structure.\\nIf you use this dataset, please cite the original authors:\\n@article{PALO2024,\\n  title={Palo: A Large Multilingual Multimodal Language Model},\\n  author={Maaz, Muhammad and Rasheed, Hanoona and Shaker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild."},
  {"name":"CONAN-MT-SP","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/SINAI/CONAN-MT-SP","creator_name":"Grupo de investigaci√≥n en Sistemas Inteligentes de Acceso a la Informaci√≥n (SINAI) de la Universidad de Ja√©n","creator_url":"https://huggingface.co/SINAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCONAN-MT-SP\\n\\t\\n\\nCONAN-SP is a a new dataset for Spanish counter-narrative. It include a hate-speech comment (HS) and the corresponded counter-narrative (CN). \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow is constructed?\\n\\t\\n\\nThe English CONAN Multitarget (CONAN-MT) corpus (Margherita Fanton et al. , 2021 is taken as a starting point and an automatic translation is carried out using the API of DeepL to obtain the CONAN-MT-SP (CONAN Multitarget in Spanish) corpus.  CONAN-MT consists of 5003 HS-CN pairs covering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SINAI/CONAN-MT-SP."},
  {"name":"ParaNames","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames."},
  {"name":"xm3600","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\nIt also includes the image features as PIL Image and has a uniform and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600."},
  {"name":"xm3600_1k","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600 - 1K Split\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a 1K split of XM3600!\\n\\t\\n\\nFor this, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k."},
  {"name":"xflickrco","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/xflickrco","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"floschne/xflickrco dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"latam-xix","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Flaglab/latam-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","description":"Flaglab/latam-xix dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"latam-xix","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Flaglab/latam-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","description":"Flaglab/latam-xix dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"spanish-corpus-xix","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Flaglab/spanish-corpus-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","description":"Flaglab/spanish-corpus-xix dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"spanish-corpus-xix","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Flaglab/spanish-corpus-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","description":"Flaglab/spanish-corpus-xix dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Big-Spanish-1.2M","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Kukedlc/Big-Spanish-1.2M","creator_name":"Eugenio Schiavoni","creator_url":"https://huggingface.co/Kukedlc","description":"\\n        Big Spanish 1.2M\\n        \\n            \\n        \\n    \\n    \\n        Este proyecto tiene como fin armar un dataset masivo en espa√±ol, con versiones para largo contexto, para QA, para RP, para RAG, y traducciones entre otras. Por ahora, unifiqu√© todos los datasets que encontr√© en Hugging Face en espa√±ol en uno solo.\\n        Pr√≥ximamente planeo subir algunas versiones curadas para prop√≥sitos espec√≠ficos como QA de medicina, traducciones espa√±ol/ingl√©s y viceversa, y un dataset de DPO en‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kukedlc/Big-Spanish-1.2M."},
  {"name":"multiturn_chat_milei_gpt","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/machinelearnear/multiturn_chat_milei_gpt","creator_name":"machinelearnear","creator_url":"https://huggingface.co/machinelearnear","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMilei-GPT Dataset\\n\\t\\n\\nChe y si queremos hacer un LLM que hable de la misma forma que un famoso ... como hacemos? Este repo es una excusa para aprender a preparar un dataset para fine-tunear alg√∫n LLM, aprender como evaluarlo, como tokenizarlo, como extenderlo de formar sint√©tica, y tantas otras cosas. Al final, si todo sale bien, vamos a tener un modelo que va a hablar como la persona que elegimos, y le podemos poner un RAG (retrieval augmented generation) encima para que nos traiga‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/machinelearnear/multiturn_chat_milei_gpt."},
  {"name":"info_itp","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jeisonf97/info_itp","creator_name":"iglesias","creator_url":"https://huggingface.co/jeisonf97","description":"jeisonf97/info_itp dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Finance_sentiment_and_topic_classification_Translation_English_to_Spanish_v1","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NickyNicky/Finance_sentiment_and_topic_classification_Translation_English_to_Spanish_v1","creator_name":"Nicky","creator_url":"https://huggingface.co/NickyNicky","description":""},
  {"name":"x-fact","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"x-fact\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact."},
  {"name":"from-one-to-many-toxicity-mitigation","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation","creator_name":"Luiza Pozzobon","creator_url":"https://huggingface.co/luizapzbn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFrom One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\\n\\t\\n\\n[arxiv][code][data]\\nData accompanying the paper \\\"From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\\\" accepted to ACL Findings 2024.\\nAbstract: To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, it‚Äôs crucial our safety measures keep pace. Recognizing this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation."},
  {"name":"xflickrco_1k","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/xflickrco_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"floschne/xflickrco_1k dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Open-Hermes-ES","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SiguienteGlobal/Open-Hermes-ES","creator_name":"Siguiente","creator_url":"https://huggingface.co/SiguienteGlobal","description":"SiguienteGlobal/Open-Hermes-ES dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Finance_cryptocurrency_Spanish_5.5k","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NickyNicky/Finance_cryptocurrency_Spanish_5.5k","creator_name":"Nicky","creator_url":"https://huggingface.co/NickyNicky","description":""},
  {"name":"legal-dataset-01","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/a01110946/legal-dataset-01","creator_name":"Fernando Maytorena Espinosa de los Monteros","creator_url":"https://huggingface.co/a01110946","description":"a01110946/legal-dataset-01 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"europa-random-split","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/NCube/europa-random-split","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EUROPA\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\\nKey Features:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa-random-split."},
  {"name":"spanishBFF2","keyword":"spanish","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/MMG/spanishBFF2","creator_name":"dezzai","creator_url":"https://huggingface.co/MMG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nSpanish-BFF-2 is the second Spanish AI-generated dictionary using GPT4.\\n\\nPaper: Building another Spanish dictionary, this time with GPT-4: https://arxiv.org/abs/2406.11218\\nPoint of Contact: oscar.garcia@dezzai.com , alfonso.ardoiz@dezzai.com\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpanish-BFF contains a total of 76,963 lemmas with its definitions.\\nThese lemmas correspond to nominal, adjetival, verbal and adverbial classes.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nSpanish (es)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MMG/spanishBFF2."},
  {"name":"nano_finance_200k_en_es_chatML_gemma_orpo_dpo","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/NickyNicky/nano_finance_200k_en_es_chatML_gemma_orpo_dpo","creator_name":"Nicky","creator_url":"https://huggingface.co/NickyNicky","description":""},
  {"name":"justicio-BOE-A-1978-31229-constitucion-by-articles-qa-multilingual-e5-large-groq_llama3_70b-sas","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dariolopez/justicio-BOE-A-1978-31229-constitucion-by-articles-qa-multilingual-e5-large-groq_llama3_70b-sas","creator_name":"Dario Lopez Padial","creator_url":"https://huggingface.co/dariolopez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset summary\\n\\t\\n\\nIt is an end-to-end evaluation dataset (using SAS metric) for Justicio.\\n\\nDomain: Legal, Law, Spanish Constitution\\nLanguage: Spanish\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSAS summary\\n\\t\\n\\nThe concept of Semantic Answer Similarity refers to the evaluation of the semantic similarity between the generated answer and the ground truth. The score ranges from 0 to 1. A higher score indicates a better match between the generated answer and the ground truth.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tJusticio summary\\n\\t\\n\\nJusticio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dariolopez/justicio-BOE-A-1978-31229-constitucion-by-articles-qa-multilingual-e5-large-groq_llama3_70b-sas."},
  {"name":"MultiPICo","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo","creator_name":"MultilingualPerspectivistNLU","creator_url":"https://huggingface.co/Multilingual-Perspectivist-NLU","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultiPICo (Multilingual Perspectivist Irony Corpus) is a disaggregated multilingual corpus for irony detection, containing 18,778 pairs of short conversations (post-reply) from Twitter (8,956) and Reddit (9,822), along with the demographic information of each annotator (age, nationality, gender, and so on). \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nIrony classification task using soft labels (i.e., distribution of annotations) or hard labels (i.e.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo."},
  {"name":"europa","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/NCube/europa","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EUROPA\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\\nKey Features:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa."},
  {"name":"law_entity_recognition","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/rubenamtz0/law_entity_recognition","creator_name":"Ruben Alvarez","creator_url":"https://huggingface.co/rubenamtz0","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThe dataset transforms complex legal passages into structured outputs, detailing entities, their interrelationships, and claims, providing a foundation for a legal knowledge graph to facilitate advanced analysis and applications.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nThe dataset in question is a specialized collection designed for legal text analysis, where each input is a passage of legal text‚Äîranging from case law‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rubenamtz0/law_entity_recognition."},
  {"name":"M3GIA","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Songweii/M3GIA","creator_name":"Wei Song","creator_url":"https://huggingface.co/Songweii","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tM3GIA: A Cognition Inspired Multilingual and Multimodal General Intelligence Ability\\n\\t\\n\\n[üåê Homepage] | ü§ó Dataset | ü§ó Paper | üìñ arXiv | üíª GitHub\\nThe evaluation code can be found in üíª GitHub.\\n[Abstract]\\nAs recent multi-modality large language models (MLLMs) have shown formidable proficiency on various complex tasks, there has been increasing attention on debating whether these models could eventually mirror human intelligence. However, existing benchmarks mainly focus on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Songweii/M3GIA."},
  {"name":"Chatgpt","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt."},
  {"name":"CorDiCas","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/epuertas94/CorDiCas","creator_name":"Elia Puertas Rib√©s","creator_url":"https://huggingface.co/epuertas94","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorDiCas\\n\\t\\n\\nCorDiCas es un prototipo de corpus diacr√≥nico cuyos documentos proceden de una colecci√≥n de m√°s de 120 documentos in√©ditos de car√°cter semiprivado, cuya tem√°tica gira en torno a la sedentarizaci√≥n e inserci√≥n forzosas de la poblaci√≥n gitana durante el siglo XVIII. \\nEn la siguiente tabla se ofrece la informaci√≥n estructurada sobre los periodos que se abordan en la colecci√≥n:\\n\\n\\t\\n\\t\\t\\nSignatura\\nPeriodo\\nN.¬∫ textos\\n\\n\\n\\t\\t\\nAMH_01430\\n1745 - 1746\\n4 textos\\n\\n\\n\\n1748\\n14 textos\\n\\n\\n\\n1749‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/epuertas94/CorDiCas."},
  {"name":"credpolv1","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/pablomo83/credpolv1","creator_name":"Ontiveros","creator_url":"https://huggingface.co/pablomo83","description":"pablomo83/credpolv1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"oasst2_es_instruct_hf","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bertin-project/oasst2_es_instruct_hf","creator_name":"BERTIN Project","creator_url":"https://huggingface.co/bertin-project","description":"This is the Spanish subset from the OpenAssistant/oasst2 dataset.\\nThe dataset has been extracted from the 2023-11-05_oasst2_ready.trees.jsonl.gz file to parse all the conversation trees and put it in a huggingface-friendly format so you can use apply_chat_template as explained on the Chat Templating documentation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample\\n\\t\\n\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"mistralai/Mistral-7B-Instruct-v0.1\\\")\\n\\nchat = [\\n\\n  {\\\"role\\\": \\\"user\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bertin-project/oasst2_es_instruct_hf."},
  {"name":"synthetic_multilingual_llm_prompts","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","description":"\\n  \\n  Image generated by DALL-E. See prompt for more details\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìùüåê Synthetic Multilingual LLM Prompts\\n\\t\\n\\nWelcome to the \\\"Synthetic Multilingual LLM Prompts\\\" dataset! This comprehensive collection features 1,250 synthetic LLM prompts generated using Gretel Navigator, available in seven different languages. To ensure accuracy and diversity in prompts, and translation quality and consistency across the different languages, we employed Gretel Navigator both as a generation tool and as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts."},
  {"name":"h4rmony_dpo_multilingual","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/neovalle/h4rmony_dpo_multilingual","creator_name":"Jorge Vallego","creator_url":"https://huggingface.co/neovalle","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neovalle/h4rmony_dpo_multilingual."},
  {"name":"zenobia","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/alvp/zenobia","creator_name":"√Ålvaro P√©rez Pozo","creator_url":"https://huggingface.co/alvp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZenobia\\n\\t\\n\\n\\n  \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescripci√≥n\\n\\t\\n\\nZenobia es un conjunto de datos de poes√≠a espa√±ola recopilado a partir del sitio web poesi.as. Este dataset contiene poemas, as√≠ como metadatos generados sint√©ticamente utilizando el modelo Llama3-70B. Es una valiosa fuente de referencia para proyectos relacionados con el procesamiento del lenguaje natural (NLP) y la poes√≠a en espa√±ol.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumnas\\n\\t\\n\\n\\npoem: El texto completo del poema.\\nthemes: Temas principales del poema‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alvp/zenobia."},
  {"name":"zenobia-instruct-hf","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/bertin-project/zenobia-instruct-hf","creator_name":"BERTIN Project","creator_url":"https://huggingface.co/bertin-project","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZenobia Instruct\\n\\t\\n\\n\\n  \\n\\n\\n\\nThis dataset has been extracted from alvp/zenobia and alvp/stanzas, and parsed into a huggingface-friendly format so you can use apply_chat_template as explained on the Chat Templating documentation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample\\n\\t\\n\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"mistralai/Mistral-7B-Instruct-v0.1\\\")\\n\\nchat = [\\n\\n  {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Escribe un terceto sobre la naturaleza en un paisaje nevado.\\\"}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bertin-project/zenobia-instruct-hf."},
  {"name":"BLEnD","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/nayeon212/BLEnD","creator_name":"Nayeon Lee","creator_url":"https://huggingface.co/nayeon212","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLEnD\\n\\t\\n\\nThis is the official repository of BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages (Submitted to NeurIPS 2024 Datasets and Benchmarks Track).\\n24/12/05: Updated translation errors\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout\\n\\t\\n\\n\\nLarge language models (LLMs) often lack culture-specific everyday knowledge, especially across diverse regions and non-English languages. Existing benchmarks for evaluating LLMs' cultural sensitivities are usually limited to a single‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nayeon212/BLEnD."},
  {"name":"FairytaleQA-translated-spanish","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/benjleite/FairytaleQA-translated-spanish","creator_name":"Bernardo Leite","creator_url":"https://huggingface.co/benjleite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for FairytaleQA-translated-ptBR\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis repository contains the Spanish machine-translated version of the original English FairytaleQA dataset (https://huggingface.co/datasets/WorkInTheDark/FairytaleQA). FairytaleQA is an open-source dataset designed to enhance comprehension of narratives, aimed at students from kindergarten to eighth grade. The dataset is meticulously annotated by education experts following an evidence-based theoretical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjleite/FairytaleQA-translated-spanish."},
  {"name":"CaLMQA","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/shanearora/CaLMQA","creator_name":"Shane Arora","creator_url":"https://huggingface.co/shanearora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\n\\nCaLMQA is a long-form question answering (LFQA) dataset spanning 23 high- to low-resource languages. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCaLMQA is an LFQA dataset with 2K questions from 23 languages, 11 high- to mid-resource and 12 low-resource.\\nQuestions are either culturally specific ‚Äì uniquely or more likely to be asked by people of a specific\\nculture ‚Äì or culturally agnostic (not culturally specific). These questions were‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shanearora/CaLMQA."},
  {"name":"SN-echoes","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/SoccerNet/SN-echoes","creator_name":"SoccerNet","creator_url":"https://huggingface.co/SoccerNet","description":"[Paper] | [GitHub]\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for SoccerNet-Echoes\\n\\t\\n\\nThis dataset card aims to provide comprehensive details for the SoccerNet-Echoes dataset, an audio commentary dataset for soccer games.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nSoccerNet-Echoes is an audio commentary dataset for soccer games, curated by SimulaMet under the AI-Storyteller project. It is funded by the Research Council of Norway (project number 346671) and shared by the SoccerNet team. The dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SoccerNet/SN-echoes."},
  {"name":"ESCI","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/henilp105/ESCI","creator_name":"henil panchal","creator_url":"https://huggingface.co/henilp105","description":"henilp105/ESCI dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"MELA","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Geralt-Targaryen/MELA","creator_name":"Ziyin Zhang","creator_url":"https://huggingface.co/Geralt-Targaryen","description":"See the GitHub repo for details.\\n"},
  {"name":"ESX","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SiguienteGlobal/ESX","creator_name":"Siguiente","creator_url":"https://huggingface.co/SiguienteGlobal","description":"SiguienteGlobal/ESX dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"bonanza-hf","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/bertin-project/bonanza-hf","creator_name":"BERTIN Project","creator_url":"https://huggingface.co/bertin-project","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBonanza: Dataset de instrucciones en Espa√±ol y Catal√°n\\n\\t\\n\\nEste dataset combina m√∫ltiples fuentes para proporcionar instrucciones en espa√±ol y catal√°n. Los datasets combinados son los siguientes:\\n\\nOpenAssistant/oasst2\\nCohereForAI/aya_dataset\\nprojecte-aina/RAG_Multilingual\\nbertin-project/alpaca-spanish\\ndariolopez/Llama-2-databricks-dolly-oasst1-es\\nprojecte-aina/MentorES\\nprojecte-aina/MentorCA\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescripci√≥n\\n\\t\\n\\nEste conjunto de datos proporciona una rica colecci√≥n de‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bertin-project/bonanza-hf."},
  {"name":"bitext_sib200_miners","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"ecuadorfood","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/pabloce/ecuadorfood","creator_name":"Pablo Carrera („Éë„Éñ„É≠)","creator_url":"https://huggingface.co/pabloce","description":"pabloce/ecuadorfood dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Test_dataset_3","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Yarik/Test_dataset_3","creator_name":"Yar","creator_url":"https://huggingface.co/Yarik","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHellow this is my dataset\\n\\t\\n\\ncolumns:\\n\\nemotion: \\ntext:\\n\\n"},
  {"name":"esbieta","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/pabloce/esbieta","creator_name":"Pablo Carrera („Éë„Éñ„É≠)","creator_url":"https://huggingface.co/pabloce","description":"pabloce/esbieta dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fleurs_clean","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean."},
  {"name":"mabama-v6-audio","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ovieyra21/mabama-v6-audio","creator_name":"Oma Vieyra","creator_url":"https://huggingface.co/ovieyra21","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmabama-v6-audio Dataset\\n\\t\\n\\nEste dataset, mabama-v6-audio, est√° dise√±ado para tareas de text-to-speech (TTS) y contiene grabaciones de audio junto con sus correspondientes transcripciones en espa√±ol. Est√° dividido en tres partes: entrenamiento, prueba y validaci√≥n, permitiendo un desarrollo y evaluaci√≥n efectivos de modelos TTS.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEstructura del Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nfile_name: Nombre del archivo de audio.\\ntext: Transcripci√≥n del audio.\\nspeaker_id:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ovieyra21/mabama-v6-audio."},
  {"name":"xP3x-Kongo","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo."},
  {"name":"multilingual_tinystories","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/robrenaud/multilingual_tinystories","creator_name":"Robert Neuhaus","creator_url":"https://huggingface.co/robrenaud","description":"An TinyStories dataset for Spanish.  The code to generate this is here.  https://github.com/rrenaud/multilingual_tinystories\\n"},
  {"name":"AyaRedTeaming","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/walledai/AyaRedTeaming","creator_name":"Walled AI","creator_url":"https://huggingface.co/walledai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Aya Red-teaming\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe Aya Red-teaming dataset is a human-annotated multilingual red-teaming dataset consisting of harmful prompts in 8 languages across 9 different categories of harm with explicit labels for \\\"global\\\" and \\\"local\\\" harm.\\n\\n\\n\\n\\n\\n\\nCurated by: Professional compensated annotators\\nLanguages: Arabic, English, Filipino, French, Hindi, Russian, Serbian and Spanish\\nLicense: Apache 2.0\\nPaper: arxiv link\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHarm‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/walledai/AyaRedTeaming."},
  {"name":"mermaid_code","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bucaro/mermaid_code","creator_name":"Jonathan B√∫caro","creator_url":"https://huggingface.co/bucaro","description":"bucaro/mermaid_code dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"replique-a","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/opsci/replique-a","creator_name":"opsci","creator_url":"https://huggingface.co/opsci","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe JSONL file generated by the script below contains detailed information about a corpus of public domain films, including their subtitles in multiple languages. Here is a detailed description of its structure:\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tJSONL file structure\\n\\t\\n\\n\\nIMDB: Unique identifier for the movie in the IMDb database.\\nprimary_title: Primary title of the movie.\\noriginal_title:  Original title of the movie.\\nfrench: \\nfilepath: Relative path to the French subtitles file.\\nsubtitles:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opsci/replique-a."},
  {"name":"Multilingual-Benchmark","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \\nBibTex\\n@misc{lu2024languagecountslearnunlearn,\\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \\n      author={Taiming Lu and Philipp Koehn},\\n      year={2024},\\n      eprint={2406.13748},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2406.13748}, \\n}\\n\\n"},
  {"name":"modern","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATMuS/modern","creator_name":"CATMuS: Consistent Approach to Transcribing ManuScripts","creator_url":"https://huggingface.co/CATMuS","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CATMuS Modern and Contemporary (McCATMuS)\\n\\t\\n\\nJoin our Discord to ask questions about the dataset: \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nHandwritten Text Recognition (HTR) has emerged as a crucial tool for converting manuscripts images into machine-readable formats, enabling researchers and scholars to analyze vast collections efficiently. Despite significant technological progress, establishing consistent ground truth across projects for HTR tasks, particularly for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATMuS/modern."},
  {"name":"squad_indicaciones_es","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/edyfjm07/squad_indicaciones_es","creator_name":"Edy Jimenez","creator_url":"https://huggingface.co/edyfjm07","description":"edyfjm07/squad_indicaciones_es dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"sDtext","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/BueormLLC/sDtext","creator_name":"Bueorm LLC","creator_url":"https://huggingface.co/BueormLLC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInformation\\n\\t\\n\\nThis dataset collects several HuggingFace datasets and extracts their emotions with an AI model adjusted for that task in Spanish.\\n\\nThanks to the original creators of the collected datasets.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDonations\\n\\t\\n\\n\\nPaypal Thanks!!\\nPatreon Thanks!!\\n\\nThanks For Download\\n || \\nGracias por Descargar\\n"},
  {"name":"justicio-BOE-A-1978-31229-constitucion-by-articles-qa-bge-m3-groq_llama3_70b_8192-sas","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dariolopez/justicio-BOE-A-1978-31229-constitucion-by-articles-qa-bge-m3-groq_llama3_70b_8192-sas","creator_name":"Dario Lopez Padial","creator_url":"https://huggingface.co/dariolopez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset summary\\n\\t\\n\\nIt is an end-to-end evaluation dataset (using SAS metric) for Justicio.\\n\\nDomain: Legal, Law, Spanish Constitution\\nLanguage: Spanish\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSAS summary\\n\\t\\n\\nThe concept of Semantic Answer Similarity refers to the evaluation of the semantic similarity between the generated answer and the ground truth. The score ranges from 0 to 1. A higher score indicates a better match between the generated answer and the ground truth.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tJusticio summary\\n\\t\\n\\nJusticio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dariolopez/justicio-BOE-A-1978-31229-constitucion-by-articles-qa-bge-m3-groq_llama3_70b_8192-sas."},
  {"name":"dataset-mmb-v1","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/gitgato/dataset-mmb-v1","creator_name":"Git Porter","creator_url":"https://huggingface.co/gitgato","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmabama-v6-audio Dataset\\n\\t\\n\\nEste dataset, mabama-v6-audio, est√° dise√±ado para tareas de text-to-speech (TTS) y contiene grabaciones de audio junto con sus correspondientes transcripciones en espa√±ol. Est√° dividido en tres partes: entrenamiento, prueba y validaci√≥n, permitiendo un desarrollo y evaluaci√≥n efectivos de modelos TTS.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEstructura del Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nfile_name: Nombre del archivo de audio.\\ntext: Transcripci√≥n del audio.\\nspeaker_id:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gitgato/dataset-mmb-v1."},
  {"name":"merit","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/de-Rodrigo/merit","creator_name":"de Rodrigo","creator_url":"https://huggingface.co/de-Rodrigo","description":"\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tThe MERIT Dataset üéíüìÉüèÜ\\n\\t\\n\\nThe MERIT Dataset is a multimodal dataset (image + text + layout) designed for training and benchmarking Large Language Models (LLMs) on Visually Rich Document Understanding (VrDU) tasks. It is a fully labeled synthetic dataset generated using our opensource pipeline available on GitHub. You can explore more details about the dataset and pipeline reading our paper.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction ‚ÑπÔ∏è\\n\\t\\n\\nAI faces some dynamic and technical issues that push‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/de-Rodrigo/merit."},
  {"name":"LLama3Flashcard","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Michito97/LLama3Flashcard","creator_name":"Adrian De La Cruz","creator_url":"https://huggingface.co/Michito97","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEste dataset contiene pares de instrucciones, entradas y salidas dise√±adas para generar tarjetas de memoria (flashcards) educativas. Es ideal para modelos de generaci√≥n de texto enfocados en la creaci√≥n de contenidos educativos.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumnas\\n\\t\\n\\n\\ninstruction: La‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Michito97/LLama3Flashcard."},
  {"name":"mabama-v1-audio","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ovieyra21/mabama-v1-audio","creator_name":"Oma Vieyra","creator_url":"https://huggingface.co/ovieyra21","description":"ovieyra21/mabama-v1-audio dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"teleia","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/gonzmart/teleia","creator_name":"Gonzalo","creator_url":"https://huggingface.co/gonzmart","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpanish Language Benchmark for Artificial Intelligence Models (TELEIA)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAuthors and Affiliations\\n\\t\\n\\nMarina Mayor-Rocher1 , Nina Melero2,3 , Elena Merino-G√≥mez4 , Miguel Gonz√°lez2 , Raquel Ferrando2 , Javier Conde2 and Pedro Reviriego2\\n\\nUniversidad Aut√≥noma de Madrid\\nUniversidad Polit√©cnica de Madrid\\nNew York University\\nUniversidad de Valladolid\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe dataset contains test questions to evaluate LLMs in Spanish\\n\\nTELEIA_Cervantes_AVE.xlsx: test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gonzmart/teleia."},
  {"name":"teleia","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/gonzmart/teleia","creator_name":"Gonzalo","creator_url":"https://huggingface.co/gonzmart","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpanish Language Benchmark for Artificial Intelligence Models (TELEIA)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAuthors and Affiliations\\n\\t\\n\\nMarina Mayor-Rocher1 , Nina Melero2,3 , Elena Merino-G√≥mez4 , Miguel Gonz√°lez2 , Raquel Ferrando2 , Javier Conde2 and Pedro Reviriego2\\n\\nUniversidad Aut√≥noma de Madrid\\nUniversidad Polit√©cnica de Madrid\\nNew York University\\nUniversidad de Valladolid\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe dataset contains test questions to evaluate LLMs in Spanish\\n\\nTELEIA_Cervantes_AVE.xlsx: test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gonzmart/teleia."},
  {"name":"librivox-tracks","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\\nChanges:\\n\\nUsed archive.org metadata API to annotate rows with \\\"duration\\\" column\\n\\n"},
  {"name":"orpo-es-v0.0.2","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/SiguienteGlobal/orpo-es-v0.0.2","creator_name":"Siguiente","creator_url":"https://huggingface.co/SiguienteGlobal","description":"SiguienteGlobal/orpo-es-v0.0.2 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"EC-Guide","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AiMijie/EC-Guide","creator_name":"AiMijie","creator_url":"https://huggingface.co/AiMijie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis repo is only used for dataset viewer. Please download from here.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAmazon KDDCup 2024 Team ZJU-AI4H‚Äôs Solution and Dataset (Track 2 Top 2; Track 5 Top 5)\\n\\t\\n\\nThe Amazon KDD Cup‚Äô24 competition presents a unique challenge by focusing on the application of LLMs in E-commerce across multiple tasks. Our solution for addressing Tracks 2 and 5 involves a comprehensive pipeline encompassing dataset construction, instruction tuning, post-training quantization, and inference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AiMijie/EC-Guide."},
  {"name":"fact-check-bureau","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau","creator_name":"Younes","creator_url":"https://huggingface.co/NaughtyConstrictor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFact-Check Retrieval Dataset\\n\\t\\n\\nThis dataset is designed to support the development and evaluation of fact-check retrieval pipelines. It is structured to work with FactCheckBureau, a tool for designing and evaluating fact-check retrieval pipelines. The dataset comprises a list of claims, fact-check articles, and precomputed embeddings for English and French fact-checks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset consists of the following files and directories:\\n\\narticles.csv:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau."},
  {"name":"amadesus-trl-assistant-dataset-v2-0","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/JsBetancourt/amadesus-trl-assistant-dataset-v2-0","creator_name":"Juan Sebastian Betancourt","creator_url":"https://huggingface.co/JsBetancourt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAMADEUS_TRL_DATASET\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\namadesu_trl_assistant_dataset is designed to train intelligent assistants in evaluating the Technology Readiness Level (TRL) in the field of agriculture, using the TRL metric developed by NASA. The dataset is organized into two parts:\\n\\nConceptual Knowledge Dataset: Provides essential knowledge about TRL concepts and definitions, levels, objectives, and goals for each level, as well as related technological development‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JsBetancourt/amadesus-trl-assistant-dataset-v2-0."},
  {"name":"preguntasmedicas","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/fhirfly/preguntasmedicas","creator_name":"Richard Braman","creator_url":"https://huggingface.co/fhirfly","description":"fhirfly/preguntasmedicas dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"zenless_zone_zero_interknots_v1.0","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZZZ Interknots\\n\\t\\n\\nThis datasets contains extracted Interknot posts and comments (Áª≥ÁΩëÁöÑÂçöÂÆ¢‰∏éËØÑËÆ∫) in multi-language.\\nUp to game version: 1.0\\n\\nInterknot posts and comments examples\\n\\n{\\n  \\\"id\\\": \\\"1021\\\",\\n  \\\"poster\\\": \\\"Sorrowful Intern\\\",\\n  \\\"title\\\": \\\"[Commission] Missing Bangboo merchants\\\",\\n  \\\"text\\\": \\\"Hello, pros... Some of the senior Bangboo of our merchant association have gone missing! We urgently need an expert to help find them!!\\\\nLet me explain, I recently joined a very prestigious‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0."},
  {"name":"XL-HeadTags","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/faisaltareque/XL-HeadTags","creator_name":"Faisal Tareque Shohan","creator_url":"https://huggingface.co/faisaltareque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for XL-HeadTags Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Source\\n\\t\\n\\nWe have used M3LS and XL-Sum as source for this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n We provide XL-HeadTags, a large-scale news headline and tags generation dataset. The dataset consists of 20 languages across six diverse language families. It contains 415K news headline-article pairs with auxiliary information such as image captions, topic words (read more).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/faisaltareque/XL-HeadTags."},
  {"name":"versat-intro","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/eddyjj92/versat-intro","creator_name":"Eddy Javier Jorge Herrera","creator_url":"https://huggingface.co/eddyjj92","description":"eddyjj92/versat-intro dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"cantemist","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/masaenger/cantemist","creator_name":"Mario S√§nger","creator_url":"https://huggingface.co/masaenger","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CANTEMIST\\n\\t\\n\\nCollection of 1301 oncological clinical case reports written in Spanish, with tumor morphology mentions manually annotated and mapped by clinical experts to a controlled terminology. Every tumor morphology mention is linked to an eCIE-O code (the Spanish equivalent of ICD-O).\\nThe original dataset is distributed in Brat format, and was randomly sampled into 3 subsets. The training, development and test sets contain 501, 500 and 300 documents each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masaenger/cantemist."},
  {"name":"teleia","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/migonsa/teleia","creator_name":"Miguel Gonz√°lez","creator_url":"https://huggingface.co/migonsa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpanish Language Benchmark for Artificial Intelligence Models (TELEIA)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAuthors and Affiliations\\n\\t\\n\\nMarina Mayor-Rocher1 , Nina Melero2,3 , Elena Merino-G√≥mez4 , Miguel Gonz√°lez2 , Raquel Ferrando2 , Javier Conde2 and Pedro Reviriego2\\n\\nUniversidad Aut√≥noma de Madrid\\nUniversidad Polit√©cnica de Madrid\\nNew York University\\nUniversidad de Valladolid\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe dataset contains test questions to evaluate LLMs in Spanish\\n\\nTELEIA_Cervantes_AVE: test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/migonsa/teleia."},
  {"name":"teleia","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/migonsa/teleia","creator_name":"Miguel Gonz√°lez","creator_url":"https://huggingface.co/migonsa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpanish Language Benchmark for Artificial Intelligence Models (TELEIA)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAuthors and Affiliations\\n\\t\\n\\nMarina Mayor-Rocher1 , Nina Melero2,3 , Elena Merino-G√≥mez4 , Miguel Gonz√°lez2 , Raquel Ferrando2 , Javier Conde2 and Pedro Reviriego2\\n\\nUniversidad Aut√≥noma de Madrid\\nUniversidad Polit√©cnica de Madrid\\nNew York University\\nUniversidad de Valladolid\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe dataset contains test questions to evaluate LLMs in Spanish\\n\\nTELEIA_Cervantes_AVE: test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/migonsa/teleia."},
  {"name":"mmarco-hard-negatives-reranker-score","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score","creator_name":"Yuichi Tateno","creator_url":"https://huggingface.co/hotchpotch","description":"\\nhotchpotch/mmarco-hard-negatives-reranker-score\\n\\nThis repository contains data from mMARCO scored using the reranker BAAI/bge-reranker-v2-m3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Covered\\n\\t\\n\\ntarget_languages = [\\n    \\\"english\\\",\\n    \\\"chinese\\\", \\n    \\\"french\\\",\\n    \\\"german\\\",\\n    \\\"indonesian\\\",\\n    \\\"italian\\\",\\n    \\\"portuguese\\\",\\n    \\\"russian\\\",\\n    \\\"spanish\\\",\\n    \\\"arabic\\\",\\n    \\\"dutch\\\",\\n    \\\"hindi\\\",\\n    \\\"japanese\\\",\\n    \\\"vietnamese\\\"\\n]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHard Negative Data\\n\\t\\n\\nThe hard negative data is derived from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score."},
  {"name":"Multi-Opthalingua","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AAAIBenchmark/Multi-Opthalingua","creator_name":"AAAIBenchmark","creator_url":"https://huggingface.co/AAAIBenchmark","description":"AAAIBenchmark/Multi-Opthalingua dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"jurisprudencia-Argentina-SAIJ","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/marianbasti/jurisprudencia-Argentina-SAIJ","creator_name":"Marian Basti","creator_url":"https://huggingface.co/marianbasti","description":"\\n\\t\\n\\t\\t\\n\\t\\tJurisprudencia de la Rep√πblica Argentina - Sistema Argentino de Informaci√≥n Jur√≠dica\\n\\t\\n\\nEste dataset es actualizado diariamente con la informaci√≥n de SAIJ utilizando la librer√≠a de SandboxAI\\n\\n\\t\\n\\t\\t\\n\\t\\tFormato\\n\\t\\n\\nEl formato del dataset es el siguiente:\\n{\\n  \\\"numero-sumario\\\": \\\"N√∫mero de identificaci√≥n del sumario\\\",\\n  \\\"materia\\\": \\\"√Årea del derecho a la que pertenece el caso\\\",\\n  \\\"timestamp\\\": \\\"Fecha y hora de creaci√≥n del registro\\\",\\n  \\\"timestamp-m\\\": \\\"Fecha y hora de la √∫ltima modificaci√≥n del‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marianbasti/jurisprudencia-Argentina-SAIJ."},
  {"name":"wiki-talks","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lflage/wiki-talks","creator_name":"Lucas Fonseca Lage","creator_url":"https://huggingface.co/lflage","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWiki-Talks\\n\\t\\n\\nThe Wiki-Talks dataset is a collection of conversational threads extracted from the talk pages on Wikipedia.\\nThis dataset captures collaborative dialogue, discussion patterns, and consensus-building among Wikipedia contributors.\\nIt is useful for NLP research focused on dialogue, sentiment analysis, and community dynamics.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDetails\\n\\t\\n\\nCurrently due to PyArrow incompatibility to the long recursive structures in the dataset there is an intrinsic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lflage/wiki-talks."},
  {"name":"muri-it-language-split","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split."},
  {"name":"mls-annotated","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PHBJT/mls-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotations of non English MLS\\n\\t\\n\\nThis dataset consists in annotations of a the Non English subset of the Multilingual LibriSpeech (MLS) dataset. \\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/mls-annotated."},
  {"name":"weather-in-Boulder-CO","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Alike/weather-in-Boulder-CO","creator_name":"Alejandro Sosa","creator_url":"https://huggingface.co/Alike","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Alike/weather-in-Boulder-CO."},
  {"name":"ManyToDanishTranslations-tatoeba","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/trollek/ManyToDanishTranslations-tatoeba","creator_name":"Trolle Karlsson","creator_url":"https://huggingface.co/trollek","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDanske overs√¶ttelser\\n\\t\\n\\nTak til Helsinki-NLP for deres tatoeba dataset (CC-BY-2.0).\\nModeller der kan adskillige sprog kan sj√¶ldent dansk. At overs√¶tte eksisterende dataset virker som en fornuftig l√∏sning p√• det problem, men af fornuftige overs√¶ttelsesv√¶rkt√∏jer er der kun f√•. Mad props til Mabeck for arbejdet med SlimOrca. Much inspired. Great thank.\\nSom sagt kan polylinvistiske modeller som regel engelsk, kinesisk, fransk, tysk, osv. og m√•ske mangler der bare noget‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trollek/ManyToDanishTranslations-tatoeba."},
  {"name":"DuncanSign-instruct-manual","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/devdroide/DuncanSign-instruct-manual","creator_name":"devdroide","creator_url":"https://huggingface.co/devdroide","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDuncanSign-instruct-manual\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescripci√≥n de la colecci√≥n\\n\\t\\n\\nEsta colecci√≥n contiene Categorias, Etiquiquetas, Preguntas, Contexto y respuestas de una aplicaci√≥n web ficticia llamada DuncanSign que permite firmar documentos\\nde forma no prensecial. \\n\\nEl contenido es hecho de forma manual\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContenido\\n\\t\\n\\nTiene preguntas y repuestas con un contexto dado sobre:\\n\\nInformaci√≥n de la aplicaci√≥n.\\nPerfiles.\\nProductos que cubre.\\nQuienes pueden firmar.\\nErrores comunes de‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/devdroide/DuncanSign-instruct-manual."},
  {"name":"PangeaBench-xm100","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM100\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n"},
  {"name":"EADOP-RAG-out-of-domain","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/alinia/EADOP-RAG-out-of-domain","creator_name":"Alinia AI","creator_url":"https://huggingface.co/alinia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEADOP RAG out-of-domain Dataset Card\\n\\t\\n\\nThis dataset consists of 2,000+ human annotated in- and out-of-domain user messages and assistant responses \\nin the context of a chatbot that can provide helpful information about the current Catalan legislation. \\nThe dataset was collected in collaboration with the \\nEntitat Aut√≤noma del Diari Oficial i de Publicacions (EADOP) in the \\ncontext of a collaboration between the Language Technologies Unit at the Barcelona Supercomputing Center \\nand‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alinia/EADOP-RAG-out-of-domain."},
  {"name":"comment-translation-01","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ifmain/comment-translation-01","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","description":"This dataset is based on Kaggle.  \\nThis dataset includes translations of 69,000 Reddit comments into 17 languages (English to 16 languages):\\nBelarusian, Czech, German,\\nEnglish, Spanish, Finnish,\\nFrench, Italian, Japanese,\\nKazakh, Korean, Latvian,\\nPolish, Russian, Swedish,\\nUkrainian, and Chinese.\\nIt contains 50% regular comments and 50% highly negative ones.\\nEnjoy using it!\\n"},
  {"name":"ApolloMoEDataset","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüåà Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset."},
  {"name":"ApolloMoEBench","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüåà Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench."},
  {"name":"sipangpt-v1","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ussipan/sipangpt-v1","creator_name":"Universidad Se√±or de Sip√°n","creator_url":"https://huggingface.co/ussipan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sip√°nGPT\\n\\t\\n\\n\\nEste dataset contiene 57 reglamentos, todas las mallas curriculares de pregrado y posgrado, autoridades y centro preuss de la universidad se√±or de sip√°n de Lambayeque, estos ser√°n utiles para entrenar el modelo Sip√°nGPT.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset para Sip√°nGPT - TRANSPARENCIA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tESTATUTO, PLAN ESTRAT√âGICO Y REGLAMENTOS DE LA UNIVERSIDAD\\n\\t\\n\\n\\n Misi√≥n y Visi√≥n Institucional.\\n Estatuto Universitario\\n Resumen de Plan Estrat√©gico\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tREGLAMENTOS‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ussipan/sipangpt-v1."},
  {"name":"aya_redteaming_consitutional","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/pbevan11/aya_redteaming_consitutional","creator_name":"Peter J. Bevan","creator_url":"https://huggingface.co/pbevan11","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Aya Red-teaming-constiutional\\n\\t\\n\\nThis dataset is an extended version of CohereForAI/aya_redteaming, with added targeted constitutional principles, aiming to allow multilingual constitional AI using the Aya Red team prompts.\\nWe take the Anthropic constitutional principles and manually cut out the existing harms so that we can dynamically insert harms specific to our red team prompts.\\nThere are 16 critiques and 16 revisions for each red-team prompt, each targeting the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pbevan11/aya_redteaming_consitutional."},
  {"name":"curated_20k_spanish","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Kukedlc/curated_20k_spanish","creator_name":"Eugenio Schiavoni","creator_url":"https://huggingface.co/Kukedlc","description":"Kukedlc/curated_20k_spanish dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"MegaWika","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/conceptofmind/MegaWika","creator_name":"Enrico Shippole","creator_url":"https://huggingface.co/conceptofmind","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. Furthermore, nearly 130 million English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/conceptofmind/MegaWika."},
  {"name":"WiNNL","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/peemil/WiNNL","creator_name":"Emile Peetermans","creator_url":"https://huggingface.co/peemil","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWiNNL\\n\\t\\n\\nWikiNews Named entity recognition and Linking (WiNNL) is a multilingual news NER & NEL benchmark based on Wikinews articles.\\nThe dataset was created by automatically scraping and tagging news articles, and manually corrected by native speakers to ensure accuracy.\\nYou can find more information in the paper:\\nhttps://aclanthology.org/2024.dlnld-1.3.pdf\\nThe dataset includes the following NER classes in IOB format (labels):\\n\\nPER (Person): person names \\nLOC (Location):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/peemil/WiNNL."},
  {"name":"toxicity-protests-ES","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/bgonzalezbustamante/toxicity-protests-ES","creator_name":"Basti√°n Gonz√°lez-Bustamante","creator_url":"https://huggingface.co/bgonzalezbustamante","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nDescription and codebook in progress.\\n\\nGitHub repository.\\nDataset on Zenodo.\\nReference paper\\n\\n"},
  {"name":"maykel_dataset","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/mayk00/maykel_dataset","creator_name":"cortes","creator_url":"https://huggingface.co/mayk00","description":"cualquier mmd\\n"},
  {"name":"toxicity-Constitution-ES","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/bgonzalezbustamante/toxicity-Constitution-ES","creator_name":"Basti√°n Gonz√°lez-Bustamante","creator_url":"https://huggingface.co/bgonzalezbustamante","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nDescription and codebook in progress.\\n\\nGitHub repository.\\nDataset on Zenodo.\\nReference paper\\n\\n"},
  {"name":"Tridis","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/magistermilitum/Tridis","creator_name":"Sergio Torres","creator_url":"https://huggingface.co/magistermilitum","description":"This is the first dataset version of the corpora used in TRIDIS (Tria Digita Scribunt) which is a series of Handwriting Text Recognition models trained on semi-diplomatic transcriptions \\nfrom medieval and Early Modern Manuscripts.\\nThe dataset involves 4k pages of manuscripts and is suitable for work on documentary manuscripts, that is, manuscripts arising  from legal, administrative, and memorial practices such as registers, feudal books, charters, proceedings, comptability more commonly from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/magistermilitum/Tridis."},
  {"name":"aya-mm-exams-spanish-medical","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/amayuelas/aya-mm-exams-spanish-medical","creator_name":"Alfonso Amayuelas","creator_url":"https://huggingface.co/amayuelas","description":"Medical Spanish Exams for the Multimodal Aya Exams Projects. \\n  Questions available in file: data.json \\n  Images stored in: /images\\nOriginal data and file available here: link\\n"},
  {"name":"unal-repository-dataset","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/JulianVelandia/unal-repository-dataset","creator_name":"Juli√°n Camilo Velandia","creator_url":"https://huggingface.co/JulianVelandia","description":"Formato Alternativo\\nT√≠tulo: Metadatos y Contenido de Tesis del Repositorio UNALDescripci√≥n: Este dataset contiene informaci√≥n estructurada y texto extra√≠do de 1910 tesis del repositorio de la Universidad Nacional de Colombia. Incluye datos como el autor, asesor, fecha de emisi√≥n, descripci√≥n, t√≠tulo, programa acad√©mico, facultad y el contenido textual (cuando est√° disponible).  \\nColumnas:\\n\\nURI: Ruta √∫nica del PDF en el repositorio UNAL.  \\nadvisor: Nombre del asesor de la tesis.  \\nauthor:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JulianVelandia/unal-repository-dataset."},
  {"name":"unal-repository-dataset-test-instruct","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/JulianVelandia/unal-repository-dataset-test-instruct","creator_name":"Juli√°n Camilo Velandia","creator_url":"https://huggingface.co/JulianVelandia","description":"T√≠tulo: Grade Works UNAL Dataset Instruct Test (split 75/25)\\nDescripci√≥n: Split 25% del dataset original. \\nEste dataset contiene un formato estructurado de Pregunta: Respuesta generado a partir del contenido de los trabajos de grado del repositorio de la Universidad Nacional de Colombia. Cada registro incluye un fragmento del contenido del trabajo, una pregunta generada a partir de este y su respuesta correspondiente. Este dataset es ideal para tareas de fine-tuning en modelos de lenguaje para‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JulianVelandia/unal-repository-dataset-test-instruct."},
  {"name":"aya-mm-exams-spanish-nursing","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/amayuelas/aya-mm-exams-spanish-nursing","creator_name":"Alfonso Amayuelas","creator_url":"https://huggingface.co/amayuelas","description":"Nursing Spanish Exams for the Multimodal Aya Exams Projects.\\nQuestions available in file: data.json\\nImages stored in: /images\\nOriginal data and file available here: link\\n"},
  {"name":"boletin-oficial-argentina-questions","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/marianbasti/boletin-oficial-argentina-questions","creator_name":"Marian Basti","creator_url":"https://huggingface.co/marianbasti","description":"\\n\\t\\n\\t\\t\\n\\t\\tBORA y preguntas contextualmente relevantes\\n\\t\\n\\nEste dataset contiene textos de hasta 2000 caracteres extra√≠dos del Bolet√≠n Oficial de la Rep√∫blica Argentina, junto a preguntas sintetizadas relevantes para el contexto previsto.\\nEste dataset es posible gracias a la colaboraci√≥n entre SandboxAI e IdeaLab/CITECCA, de la Universidad Nacional de Rio Negro\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPara qu√©?\\n\\t\\n\\nEl objetivo de este dataset es el entrenamiento de un modelo de embeddings en el √°mbito legal argentino.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marianbasti/boletin-oficial-argentina-questions."},
  {"name":"gn-offensive-language-identification","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mmaguero/gn-offensive-language-identification","creator_name":"Marvin M. Ag√ºero-Torales","creator_url":"https://huggingface.co/mmaguero","description":"\\n\\t\\n\\t\\t\\n\\t\\tText-based afective computing\\n\\t\\n\\nWe collected a dataset of tweets primarily written in Guarani (and Jopara, a code-switching language that combines Guarani and Spanish) and annotated them for three widely-used dimensions in sentiment analysis: \\n\\nemotion recognition (https://huggingface.co/datasets/mmaguero/gn-emotion-recognition),  \\nhumor detection (https://huggingface.co/datasets/mmaguero/gn-humor-detection), and\\noffensive language identification (this repo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mmaguero/gn-offensive-language-identification."},
  {"name":"gn-emotion-recognition","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mmaguero/gn-emotion-recognition","creator_name":"Marvin M. Ag√ºero-Torales","creator_url":"https://huggingface.co/mmaguero","description":"\\n\\t\\n\\t\\t\\n\\t\\tText-based afective computing\\n\\t\\n\\nWe collected a dataset of tweets primarily written in Guarani (and Jopara, a code-switching language that combines Guarani and Spanish) and annotated them for three widely-used dimensions in sentiment analysis: \\n\\nemotion recognition (this repo, https://huggingface.co/datasets/mmaguero/gn-emotion-recognition),  \\nhumor detection (https://huggingface.co/datasets/mmaguero/gn-humor-detection), and\\noffensive language identification‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mmaguero/gn-emotion-recognition."},
  {"name":"GammaCorpus-Polylingo-50k","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","description":"\\n\\t\\n\\t\\t\\n\\t\\tGammaCorpus Polylingo 50k\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is it?\\n\\t\\n\\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\\n\\nInput: A user prompt or question.\\nOutput: A response generated by an AI assistant.\\nLanguage: The language used in the interaction.\\n\\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k."},
  {"name":"OpenThoughts-114k-spanish","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/amias-mx/OpenThoughts-114k-spanish","creator_name":"Alianza Mexicana para la IA soberana","creator_url":"https://huggingface.co/amias-mx","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Translation\\n\\t\\n\\nThis repository contains the Spanish translation of dataset subsets from \\nopen-thoughts/OpenThoughts-114k.\\nEach subset is preserved as a separate config, maintaining the original structure.\\nNote: The translations are generated using machine translation and may contain\\ntypical automated translation artifacts.\\n"},
  {"name":"unal-repository-dataset-alternative-format","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/JulianVelandia/unal-repository-dataset-alternative-format","creator_name":"Juli√°n Camilo Velandia","creator_url":"https://huggingface.co/JulianVelandia","description":"T√≠tulo: Metadatos y Contenido de Tesis del Repositorio UNALDescripci√≥n: Este dataset contiene informaci√≥n estructurada y texto extra√≠do de 1910 tesis del repositorio de la Universidad Nacional de Colombia. Incluye datos como el autor, asesor, fecha de emisi√≥n, descripci√≥n, t√≠tulo, programa acad√©mico, facultad y el contenido textual (cuando est√° disponible).  \\nColumnas:\\n\\nURI: Ruta √∫nica del PDF en el repositorio UNAL.  \\nadvisor: Nombre del asesor de la tesis.  \\nauthor: Nombre del autor de la‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JulianVelandia/unal-repository-dataset-alternative-format."},
  {"name":"AIME2025-Multilingual","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/fedric95/AIME2025-Multilingual","creator_name":"Federico Ricciuti","creator_url":"https://huggingface.co/fedric95","description":"\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nThis repository contains a multi language version of the AIME2025 dataset. \\nAs the english reference version, we haved used the one created by the authors of MathArena.\\nFor completness, we have included the english version also in this repository, please, refer to the one contained in the MathArena github repository for the original one (https://github.com/eth-sri/matharena/tree/main/data/aime). Many thanks to Jasper Dekoninck for the help in understanding the structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fedric95/AIME2025-Multilingual."},
  {"name":"Resident-Evil-Roleplay-L3.2","keyword":"spanish","license":"Artistic License 2.0","language":"en","url":"https://huggingface.co/datasets/Novaciano/Resident-Evil-Roleplay-L3.2","creator_name":"Novaciano","creator_url":"https://huggingface.co/Novaciano","description":"\\n\\n¬°Descubre el oscuro mundo de Resident Evil con nuestro exclusivo dataset!\\nSum√©rgete en la Era de Umbrella, donde los horrores de Raccoon City y los secretos de la corporaci√≥n m√°s temida del mundo cobran vida. Nuestro dataset abarca los eventos cruciales desde Resident Evil 1 hasta Resident Evil: Code Ver√≥nica, ofreciendo una rica colecci√≥n de datos que te permitir√° entrenar modelos de lenguaje (LLM) con un enfoque √∫nico en esta ic√≥nica saga de survival horror.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t¬øQu√© incluye este‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Novaciano/Resident-Evil-Roleplay-L3.2."},
  {"name":"NSM-emoji","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hspencer/NSM-emoji","creator_name":"Herbert Spencer","creator_url":"https://huggingface.co/hspencer","description":"hspencer/NSM-emoji dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"multilingualcrowspairs","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/FrancophonIA/multilingualcrowspairs","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://gitlab.inria.fr/corpus4ethics/multilingualcrowspairs/\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultiLingualCrowsPairs\\n\\t\\n\\nMultilingual CrowS-Pairs, a challenge dataset for measuring stereotypical biases present in the masked language models (MLMs) in 7 different languages. \\nThis challenge dataset was built on the Crows-Pairs corpus (Nangia et al. 2020) using the methodology described in (N√©v√©ol et al. 2023). \\nThe 7 new languages are the following:\\n\\nArabic from Maghreb and the Arab world in general‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/multilingualcrowspairs."},
  {"name":"hastasiemprepresidente","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ljcamargo/hastasiemprepresidente","creator_name":"Luis J Camargo","creator_url":"https://huggingface.co/ljcamargo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHasta Siempre Presidente\\n\\t\\n\\nDataset de la versi√≥nes estenogr√°ficas de todas la conferencias \\\"ma√±aneras\\\" y actos p√∫blicos de la presidencia de Andr√©s Manuel L√≥pez Obrador, M√©xico (2018-2024)\\n(english at the bottom)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tObtenci√≥n\\n\\t\\n\\nObtenido de la p√°gina oficial de la presidencia en aquel momento, https://www.gob.mx/presidencia obtenidos automatizadamente, homologados, limpiados y estructurados en di√°logos en jsonl para permitir el entrenamiento de modelos de lenguaje o su‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ljcamargo/hastasiemprepresidente."},
  {"name":"sipangpt","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ussipan/sipangpt","creator_name":"Universidad Se√±or de Sip√°n","creator_url":"https://huggingface.co/ussipan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sip√°nGPT\\n\\t\\n\\n\\nEste dataset contiene 57 reglamentos, todas las mallas curriculares de pregrado y posgrado, autoridades y centro preuss de la universidad se√±or de sip√°n de Lambayeque, estos ser√°n utiles para entrenar el modelo Sip√°nGPT.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCreaci√≥n del dataset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset para Sip√°nGPT - TRANSPARENCIA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tESTATUTO, PLAN ESTRAT√âGICO Y REGLAMENTOS DE LA UNIVERSIDAD\\n\\t\\n\\n\\n Misi√≥n y Visi√≥n Institucional.\\n Estatuto Universitario\\n Resumen de Plan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ussipan/sipangpt."},
  {"name":"SpeechQE-CoVoST2","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/h-j-han/SpeechQE-CoVoST2","creator_name":"HyoJung Han","creator_url":"https://huggingface.co/h-j-han","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpeechQE: Estimating the Quality of Direct Speech Translation\\n\\t\\n\\nThis is a benchmark and training corpus for the task of quality estimation for speech translation (SpeechQE).\\nWe subsample about 80k segments from the training set and 500 from the dev and test of CoVoST2, then run seven different direct ST models to generate the ST hypotheses.\\nSo,test split consists of 3500 instances(500*7). We also provide splits for each translation model.\\n*(We provide test split first, and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/h-j-han/SpeechQE-CoVoST2."},
  {"name":"casimedicos-arg","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/HiTZ/casimedicos-arg","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n    \\n    \\n    \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures\\n\\t\\n\\nCasiMedicos-Arg is, to the best of our knowledge, the first \\nmultilingual dataset for Medical Question Answering where correct and incorrect diagnoses for a clinical case are \\nenriched with a natural language explanation written by doctors. \\nThe casimedicos-exp have been manually annotated with \\nargument components (i.e., premise, claim) and argument‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/casimedicos-arg."},
  {"name":"amazon-esci-data","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/milistu/amazon-esci-data","creator_name":"Milutin Studen","creator_url":"https://huggingface.co/milistu","description":"\\n\\t\\n\\t\\t\\n\\t\\tAmazon Shopping Queries Dataset\\n\\t\\n\\nA comprehensive dataset for improving product search, ranking and recommendations, featuring query-product pairs with detailed relevance labels.\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe dataset contains search queries paired with up to 40 potentially relevant products, each labeled using the ESCI system:\\n\\nExact match: Products that perfectly match the customer's search intent (e.g., searching \\\"iPhone 13\\\" and finding \\\"Apple iPhone 13 128GB\\\")\\nSubstitute product:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/milistu/amazon-esci-data."},
  {"name":"isuee_gus","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/gusornu/isuee_gus","creator_name":"GUSTAVO ORDO√ëEZ NU√ëEZ","creator_url":"https://huggingface.co/gusornu","description":"gusornu/isuee_gus dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Datasets_Jhona","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Jhonatan321/Datasets_Jhona","creator_name":"Jhonatan reyes vazquez","creator_url":"https://huggingface.co/Jhonatan321","description":"Jhonatan321/Datasets_Jhona dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Barcenas-Cartas-HN","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Danielbrdz/Barcenas-Cartas-HN","creator_name":"Daniel","creator_url":"https://huggingface.co/Danielbrdz","description":"Barcenas Cartas HN y Compresi√≥n Barcenas HN\\nEste dataset fue hecho de manera sint√©tica con gemini-exp-1121.\\nContiene 1,001 cartas con un razonamiento tr√°gico y hasta violento entre una pareja.\\nPara hacer el dataset se uso compresi√≥n Barcenas HN.\\n¬øQu√© es compresi√≥n Barcenas HN?\\nEs una versi√≥n m√°s pulida de las anteriores versiones de compresi√≥n Barcenas, pero quise que esta versi√≥n fuera m√°s tr√°gica y violenta, que las historias tuvieran esa crudeza que muchas veces pasan en la vida real, tan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Danielbrdz/Barcenas-Cartas-HN."},
  {"name":"parallel_corpus_game_2024","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bot-yaya/parallel_corpus_game_2024","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","description":"https://github.com/mnbvc-parallel-corpus-team/parallel_corpus_mnbvc\\nMNBVCÂπ≥Ë°åËØ≠ÊñôÂ∞èÁªÑÔºöÊ∏∏ÊàèËØ≠Êñô\\n‰∏çÂÆöÊúüÊõ¥Êñ∞ÔºåÁõÆÂâçÂ∑≤Êî∂ÂΩïÁöÑÊ∏∏ÊàèËØ≠ÊñôÊñá‰ª∂ÔºåÂÖ±29‰ªΩÔºö\\n\\nÂçöÂæ∑‰πãÈó®3\\nËµõÂçöÊúãÂÖã2077\\nÈªëÊöó‰πãÈ≠Ç3\\nÂ∫ïÁâπÂæãÔºöÂåñË∫´‰∏∫‰∫∫\\nÈ••Ëçí\\nËâæÂ∞îÁôªÊ≥ïÁéØ\\nÂéüÁ•û\\nÈªëÂ∏ùÊñØ\\nÈúçÊ†ºÊ≤ÉÂÖπ‰πãÈÅó\\nIb\\nÂ¶ÇÈæô8\\nÂ¶ÇÈæô7Â§ñ‰º†\\nËçíÈáéÂ§ßÈïñÂÆ¢2\\nÂè™ÁãºÔºöÂΩ±ÈÄù‰∫åÂ∫¶\\nÊñáÊòé6\\nÊùÄÊàÆÂ∞ñÂ°î\\nÂ¥©ÂùèÊòüÁ©πÈìÅÈÅì\\nÁæ§Êòü\\nÊ≥∞ÊãâÁëû‰∫ö\\nÂ∑´Â∏à3\\nÈ≠îÂ•≥‰πãÊ≥â3\\nÈ≠îÂ•≥‰πãÊ≥âR\\nÈ∏£ÊΩÆ\\nÂ¶ÇÈæô3\\nÂ¶ÇÈæô4\\nÂ¶ÇÈæô5\\nÂ¶ÇÈæô6\\nÂ¶ÇÈæôÊûÅ2\\nÂ¶ÇÈæô7\\n\\n"},
  {"name":"hhh_alignment_es","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/BSC-LT/hhh_alignment_es","creator_name":"Language Technologies Unit @ Barcelona Supercomputing Center","creator_url":"https://huggingface.co/BSC-LT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for hhh_alignment_es\\n\\t\\n\\n\\n\\nhhh_alignment_es is a question answering dataset in Spanish, professionally translated from the main version of the hhh_alignment dataset in English. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nhhh_alignment_es (Helpful, Honest, & Harmless - a Pragmatic Alignment Evaluation - Spanish) is designed to evaluate language models on alignment, pragmatically broken down into the categories of helpfulness, honesty/accuracy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BSC-LT/hhh_alignment_es."},
  {"name":"cml-tts-filtered-annotated","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Filtred and annotated CML TTS\\n\\t\\n\\nThis dataset is an annotated and filtred version of a CML-TTS [1]. \\nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated."},
  {"name":"X-ALMA-Preference","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\\nsource: the source sentence.\\nchosen: the preferred translation.\\nreject: the dis-preferred translation.\\ndirections: the translation direction.\\n@misc{xu2024xalmaplugplay,\\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \\n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\\n      year={2024},\\n      eprint={2410.03115}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference."},
  {"name":"Muscle_Fatigue_Cycling","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/YominE/Muscle_Fatigue_Cycling","creator_name":"YominJaramilloM","creator_url":"https://huggingface.co/YominE","description":"This dataset was created with healthy participants aged between 18 and 25 years old. The participants in this dataset were not frequent athletes.\\nThe dataset consists of 8 EMG signals recorded from the domineering foot of each participant during a cycling trial. The participants performed exercises on a conditioned cycle, alternating with short periods of high-intensity sprints. When a participant could no longer sustain the sprint intensity, this was considered the first index of fatigue and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YominE/Muscle_Fatigue_Cycling."},
  {"name":"comparador-planes-co","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/andresayac/comparador-planes-co","creator_name":"Andres Aya","creator_url":"https://huggingface.co/andresayac","description":"andresayac/comparador-planes-co dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Eventlog","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/LOmarPR/Eventlog","creator_name":"Omar Palomeque","creator_url":"https://huggingface.co/LOmarPR","description":"LOmarPR/Eventlog dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"poplyrics-1k","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ashuwhy/poplyrics-1k","creator_name":"Ashutosh Sharma","creator_url":"https://huggingface.co/ashuwhy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPop Lyrics Dataset\\n\\t\\n\\nThis dataset contains up to 1,000 pop songs with their lyrics, songwriters, genres, and other relevant metadata. The data was collected from Spotify and Genius.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\ntrack_name: Name of the song.\\nalbum: Album name.\\nrelease_date: Release date of the song.\\nsong_length: Duration of the song.\\npopularity: Popularity score from Spotify.\\nsongwriters: List of songwriters.\\nartist: Name of the artist.\\nlyrics: Cleaned lyrics of the song.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ashuwhy/poplyrics-1k."},
  {"name":"ner-cat","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Ugiat/ner-cat","creator_name":"Ugiat Technologies","creator_url":"https://huggingface.co/Ugiat","description":"\\n\\t\\n\\t\\t\\n\\t\\tNERCat Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe NERCat dataset is a manually annotated collection of Catalan-language television transcriptions, designed to improve Named Entity Recognition (NER) performance for the Catalan language. The dataset covers diverse domains such as politics, sports, and culture, and includes 9,242 sentences with 13,732 named entities annotated across eight categories: Person, Facility, Organization, Location, Product, Event, Date, and Law. The dataset was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ugiat/ner-cat."},
  {"name":"BRIGHTER-emotion-intensities","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\tBRIGHTER Emotion Intensities Dataset\\n\\t\\n\\nThis dataset contains the emotion intensities data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe BRIGHTER Emotion Intensities dataset is a comprehensive multi-language emotion intensity dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple languages, providing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities."},
  {"name":"semeval-2025-task11-track-a","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track A Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track A, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 26 standard ISO codes\\nTotal examples: 115159\\nSplits: train, dev, test\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguage Configurations\\n\\t\\n\\nEach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a."},
  {"name":"semeval-2025-task11-track-c","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track C Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track C, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 30 standard ISO codes\\nTotal examples: 57254\\nSplits: dev, test (Track C has no train split)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTrack‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c."},
  {"name":"Historical_Data_of_Ecuador_Stock_Exchange","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/beta3/Historical_Data_of_Ecuador_Stock_Exchange","creator_name":"David Arias","creator_url":"https://huggingface.co/beta3","description":"Historical Data of Ecuador's Stock Exchange\\nUnlock the latest financial trends with up-to-date data from the market\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tContext\\n\\t\\n\\nThe Guayaquil Stock Exchange (Bolsa de Valores de Guayaquil - BVG) and Quito Stock Exchange (Bolsa de Valores de Quito - BVQ) play a crucial role in Ecuador's financial markets, facilitating trading of stocks, bonds, and other securities. However, historical financial data from this exchange is often difficult to access in a structured and ready-to-use format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/beta3/Historical_Data_of_Ecuador_Stock_Exchange."},
  {"name":"corn-kernel-synthetic-dataset-3000","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/psychocyber/corn-kernel-synthetic-dataset-3000","creator_name":"Paulo Ramos","creator_url":"https://huggingface.co/psychocyber","description":"psychocyber/corn-kernel-synthetic-dataset-3000 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Address-Classifyer","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/5m4ck3r/Address-Classifyer","creator_name":"Pryanshu Sharma","creator_url":"https://huggingface.co/5m4ck3r","description":"5m4ck3r/Address-Classifyer dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"kurage_training_data","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lightblue/kurage_training_data","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"lightblue/kurage_training_data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Barcenas-Cartas","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Danielbrdz/Barcenas-Cartas","creator_name":"Daniel","creator_url":"https://huggingface.co/Danielbrdz","description":"Barcenas Cartas\\nEste dataset fue hecho de manera sint√©tica con Llama 3.1 70B.\\nContiene 10,000 cartas con su razonamiento y sentimiento, todo en espa√±ol.\\nPara hacer el dataset se uso compresi√≥n Barcenas. \\n¬øQu√© es compresi√≥n Barcenas?\\nInspirado en el proyecto Quiet-STaR que tambi√©n deriva Strawberry de OpenAI, es un sistema de razonamiento y compresi√≥n para un LLM sin necesidad de fine tuning, en especifico para comprender una carta con muchos sentimientos y hacer m√°s cartas derivadas de este‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Danielbrdz/Barcenas-Cartas."},
  {"name":"mini-croupier","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Anngelillo/mini-croupier","creator_name":"Angelo Lillo","creator_url":"https://huggingface.co/Anngelillo","description":"Anngelillo/mini-croupier dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"turismo","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/malejaa/turismo","creator_name":"Maria","creator_url":"https://huggingface.co/malejaa","description":"[\\n    { \\\"inputs\\\": \\\"[INST] ¬øQu√© puedo hacer en Bogot√° durante un fin de semana? [/INST] En Bogot√°, puedes visitar el Museo del Oro, recorrer el cerro de Monserrate y disfrutar de la vida nocturna en la Zona T.\\\" },\\n    { \\\"inputs\\\": \\\"[INST] ¬øQu√© zonas de Colombia son ideales para ecoturismo? [/INST] Colombia ofrece grandes oportunidades para el ecoturismo en la regi√≥n amaz√≥nica, el Parque Nacional Natural Los Nevados, y la Sierra Nevada de Santa Marta.\\\" },\\n    { \\\"inputs\\\": \\\"[INST] ¬øQu√© ciudades son‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malejaa/turismo."},
  {"name":"mosel","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description, Collection, and Source\\n\\t\\n\\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel."},
  {"name":"pictos-to-nl","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/arasaac/pictos-to-nl","creator_name":"ARASAAC","creator_url":"https://huggingface.co/arasaac","description":"arasaac/pictos-to-nl dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Barcenas-Cartas-Gemini","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Danielbrdz/Barcenas-Cartas-Gemini","creator_name":"Daniel","creator_url":"https://huggingface.co/Danielbrdz","description":"Barcenas Cartas Gemini\\nEste dataset fue hecho de manera sint√©tica con Gemini 1.5 flash EXP 0827 y Gemini 1.5 flash 002.\\nContiene 10,000 cartas con su razonamiento y sentimiento, todo en espa√±ol.\\nPara hacer el dataset se uso compresi√≥n Barcenas R (Refresh).\\n¬øQu√© es compresi√≥n Barcenas R?\\nEs una versi√≥n mejorada y refinada del original compresi√≥n Barcenas, esta nueva versi√≥n incluye una mejor variedad de escritura en las cartas con diferentes situaciones y un mejor razonamiento a la hora de‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Danielbrdz/Barcenas-Cartas-Gemini."},
  {"name":"ine","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/davidgasquez/ine","creator_name":"David Gasquez","creator_url":"https://huggingface.co/davidgasquez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tINE\\n\\t\\n\\nEste repositorio contiene todas las tablas¬π del Instituto Nacional de Estad√≠stica exportadas a ficheros Parquet.\\nPuedes encontrar los datos de las tablas como sus metadatos en la carpeta tablas. Cada dataset est√° identificado un una ID.  Puedes encontrar el ID en la URL de la tabla en la web del INE (es el n√∫mero que aparece en la URL) or en el archivo tablas.parquet de este repositorio.\\nPor ejemplo, la tabla de √çndices nacionales de clases se corresponde al ID 50904 (en la‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidgasquez/ine."},
  {"name":"PangeaBench-xchat","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/neulab/PangeaBench-xchat","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"neulab/PangeaBench-xchat dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Conversational-Cancer-Lung-Detection","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/BrokenSoul/Conversational-Cancer-Lung-Detection","creator_name":"Ricardo Robledo","creator_url":"https://huggingface.co/BrokenSoul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tConversational Cancer Lung Detection Dataset\\n\\t\\n\\nThis dataset, Conversational Cancer Lung Detection, is a conversationally structured dataset derived from the original Lung Cancer Detection dataset by Jillani Soft Tech on Kaggle. It has been transformed to simulate medical records in a conversational format, enabling AI applications to interact in a question-answer style format about lung cancer detection.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThe Conversational Cancer Lung Detection‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BrokenSoul/Conversational-Cancer-Lung-Detection."},
  {"name":"mc-translation","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/efederici/mc-translation","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","description":"This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy This Dataset?\\n\\t\\n\\nTranslation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specialized‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation."},
  {"name":"lexic-ai-tutorial-dataset","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/smartloop-ai/lexic-ai-tutorial-dataset","creator_name":"Smartloop","creator_url":"https://huggingface.co/smartloop-ai","description":"smartloop-ai/lexic-ai-tutorial-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"multilingual-crows-pairs","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/multilingual-crows-pairs/multilingual-crows-pairs","creator_name":"MultiLingualCrowsPairs","creator_url":"https://huggingface.co/multilingual-crows-pairs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@inproceedings{fort-etal-2024-stereotypical,\\n    title = \\\"Your Stereotypical Mileage May Vary: Practical Challenges of Evaluating Biases in Multiple Languages and Cultural Contexts\\\",\\n    author = \\\"Fort, Karen  and\\n      Alonso Alemany, Laura  and\\n      Benotti, Luciana  and\\n      Bezan{\\\\c{c}}on, Julien  and\\n      Borg, Claudia  and\\n      Borg, Marthese  and\\n      Chen, Yongjian  and\\n      Ducel, Fanny  and\\n      Dupont, Yoann  and\\n      Ivetta, Guido  and\\n      Li‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/multilingual-crows-pairs/multilingual-crows-pairs."},
  {"name":"product-database","keyword":"spanish","license":"GNU Affero General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Food Facts Database\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is üçä Open Food Facts?\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tA food products database\\n\\t\\n\\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\\n\\n\\t\\n\\t\\t\\n\\t\\tMade by everyone\\n\\t\\n\\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database."},
  {"name":"global-festivals-translated","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/azminetoushikwasi/global-festivals-translated","creator_name":"Azmine Toushik Wasi","creator_url":"https://huggingface.co/azminetoushikwasi","description":"azminetoushikwasi/global-festivals-translated dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"leyes_ambientales_cordoba","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/kar-pal/leyes_ambientales_cordoba","creator_name":"Karen Palacio","creator_url":"https://huggingface.co/kar-pal","description":"Leyes ambientales c√≥rdoba\\nPeque√±o dataset hecho a mano sobre algunas leyes ambientales de c√≥rdoba. Las fuentes que se usaron para armarlo son documentos oficiales del gobierno de la Provincia de C√≥rdoba:\\nhttp://web2.cba.gov.ar/web/leyes.nsf/0/B9E1E8726334EC1A0325723400665A2A?OpenDocument&Highlight=0,9219\\nhttp://web2.cba.gov.ar/web/leyes.nsf/0/813F022B2233772A0325723400641ED3?OpenDocument&Highlight=0,8066‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kar-pal/leyes_ambientales_cordoba."},
  {"name":"leyes_ambientales_cordoba","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/kar-pal/leyes_ambientales_cordoba","creator_name":"Karen Palacio","creator_url":"https://huggingface.co/kar-pal","description":"Leyes ambientales c√≥rdoba\\nPeque√±o dataset hecho a mano sobre algunas leyes ambientales de c√≥rdoba. Las fuentes que se usaron para armarlo son documentos oficiales del gobierno de la Provincia de C√≥rdoba:\\nhttp://web2.cba.gov.ar/web/leyes.nsf/0/B9E1E8726334EC1A0325723400665A2A?OpenDocument&Highlight=0,9219\\nhttp://web2.cba.gov.ar/web/leyes.nsf/0/813F022B2233772A0325723400641ED3?OpenDocument&Highlight=0,8066‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kar-pal/leyes_ambientales_cordoba."},
  {"name":"testIA","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ofarcis/testIA","creator_name":"Oscar Fernandez","creator_url":"https://huggingface.co/ofarcis","description":"ofarcis/testIA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"test_4","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4."},
  {"name":"prompt-injection-multilingual","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/rikka-snow/prompt-injection-multilingual","creator_name":"Le Xuan Hoang","creator_url":"https://huggingface.co/rikka-snow","description":"rikka-snow/prompt-injection-multilingual dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"mabama-data","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/aztro/mabama-data","creator_name":"Jose Omar Vieyra","creator_url":"https://huggingface.co/aztro","description":"aztro/mabama-data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"databenchSPA","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/SINAI/databenchSPA","creator_name":"Grupo de investigaci√≥n en Sistemas Inteligentes de Acceso a la Informaci√≥n (SINAI) de la Universidad de Ja√©n","creator_url":"https://huggingface.co/SINAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataBench SPAnish\\n\\t\\n\\nThis repository contains the original 10 datasets used for the paper Towards Quality Benchmarking in Question Answering over Tabular Data in Spanish which appeared in SEPLN 2024.\\nIt is a spin-off of the original suite in English, which you can find here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\n# Load all QA pairs\\nall_qa = load_dataset(\\\"SINAI/databenchSPA\\\", name=\\\"qa\\\")\\n\\n# Load PRESTA QA splits\\niberlef_train_qa = load_dataset(\\\"SINAI/databenchSPA\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SINAI/databenchSPA."},
  {"name":"pictos-to-nl","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/juanda99/pictos-to-nl","creator_name":"Juan Daniel","creator_url":"https://huggingface.co/juanda99","description":"juanda99/pictos-to-nl dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"xtreme-up-semantic-parsing","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrixnli\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSee XTREME-UP GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 20 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import load_dataset\\ndata = load_dataset('Davlan/xtreme-up-semantic-parsing', 'yor') \\n# Please, specify the language code\\n# A data point example is below:\\n{\\n\\\"id\\\": \\\"3231323330393336\\\",\\n\\\"split\\\": \\\"test\\\",\\n\\\"intent\\\": \\\"IN:GET_REMINDER\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing."},
  {"name":"cml-tts-filtered","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Filtred and CML-TTS\\n\\t\\n\\nThis dataset is a filtred version of a CML-TTS [1]. \\nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered."},
  {"name":"wsdm2024-cot-dataset","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ruggsea/wsdm2024-cot-dataset","creator_name":"Ruggero Marino Lazzaroni","creator_url":"https://huggingface.co/ruggsea","description":"This dataset is created by ruggsea for the WSDM 2024 competition. It is a semisynthetic dataset created by asking Llama 3.1 70B to generate rationales for the responses to the prompts in the WSDM 2024 competition. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nid: Unique identifier for each example\\nprompt: The input prompt given to the model\\nresponse_a: First response option\\nresponse_b: Second response option\\nwinner: The winning response (0 or 1)\\nrationale: The rationale generated by Llama 3.1 70B explaining why‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ruggsea/wsdm2024-cot-dataset."},
  {"name":"spanish_tokenized_train","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nikhil-405/spanish_tokenized_train","creator_name":"Nikhil Goyal","creator_url":"https://huggingface.co/nikhil-405","description":"nikhil-405/spanish_tokenized_train dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"IFEval_es","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/BSC-LT/IFEval_es","creator_name":"Language Technologies Unit @ Barcelona Supercomputing Center","creator_url":"https://huggingface.co/BSC-LT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for IFEval_es\\n\\t\\n\\n\\n\\nIFEval_es is a prompt dataset in Spanish, professionally translated from the main version of the IFEval dataset in English. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nIFEval_es (Instruction-Following Eval benchmark - Spanish) is designed to evaluating chat or instruction fine-tuned language models. The dataset comprises 541 \\\"verifiable instructions\\\" such as \\\"write in more than 400 words\\\" and \\\"mention the keyword of AI at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BSC-LT/IFEval_es."},
  {"name":"llm-ideology-analysis","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/aida-ugent/llm-ideology-analysis","creator_name":"Ghent University Artificial Intelligence & Data Analytics Group","creator_url":"https://huggingface.co/aida-ugent","description":"This dataset contains evaluations of political figures by a diverse set of Large Language Models (LLMs), such that the ideology of these LLMs can be characterized.\\n\\n\\t\\n\\t\\t\\n\\t\\tüìù Dataset Description\\n\\t\\n\\nThe dataset contains responses from 19 different Large Language Models evaluating 3,991 political figures, with responses collected in the six UN languages: Arabic, Chinese, English, French, Russian, and Spanish. \\nThe evaluations were conducted using a two-stage prompting strategy to assess the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aida-ugent/llm-ideology-analysis."},
  {"name":"talking-to-chatbots-chats","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/reddgr/talking-to-chatbots-chats","creator_name":"David G. R.","creator_url":"https://huggingface.co/reddgr","description":"This work-in-progress dataset contains conversations with various LLM tools, sourced by the author of the website  Talking to Chatbots. \\nThe format chosen for structuring this dataset is similar to that of lmsys/lmsys-chat-1m. \\nConversations are identified by a UUID (v4) and 'wrapped' in a JSON format where each message is contained in the 'content' key. The 'role' key identifies whether the message is a prompt ('user') or a response by the LLM ('assistant'). For each dictionary, 'turn'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/reddgr/talking-to-chatbots-chats."},
  {"name":"talking-to-chatbots-unwrapped-chats","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/reddgr/talking-to-chatbots-unwrapped-chats","creator_name":"David G. R.","creator_url":"https://huggingface.co/reddgr","description":"This work-in-progress dataset contains conversations with various LLM tools, sourced by the author of the website  Talking to Chatbots. \\nA simplified version of this dataset can be found at reddgr/talking-to-chatbots-chats, where messages belonging to a same conversation are 'wrapped' inside a single record. In this extended dataset, each conversation turn (pair of messages consisting of a user prompt and a response by the LLM) is presented as an individual record, with additional metrics and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/reddgr/talking-to-chatbots-unwrapped-chats."},
  {"name":"orca-agente-instruct","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Siguiente-ia/orca-agente-instruct","creator_name":"Ryan Pridgen","creator_url":"https://huggingface.co/Siguiente-ia","description":"Siguiente-ia/orca-agente-instruct dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Personas_Spanish-40k","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Kukedlc/Personas_Spanish-40k","creator_name":"Eugenio Schiavoni","creator_url":"https://huggingface.co/Kukedlc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset de Personas en Espa√±ol\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescripci√≥n\\n\\t\\n\\nEste dataset contiene descripciones detalladas de personas en espa√±ol, dise√±ado espec√≠ficamente para entrenamiento y generaci√≥n de datos sint√©ticos, creaci√≥n de agentes conversacionales y desarrollo de sistemas de procesamiento de lenguaje natural. Las descripciones incluyen roles profesionales en el √°mbito art√≠stico y cultural, con √©nfasis en el sector teatral latinoamericano.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContenido\\n\\t\\n\\nEl dataset incluye‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kukedlc/Personas_Spanish-40k."},
  {"name":"test7","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ccdamian/test7","creator_name":"camila opazo","creator_url":"https://huggingface.co/ccdamian","description":"ccdamian/test7 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Spain-Fuel-Prices","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/xus/Spain-Fuel-Prices","creator_name":"Xus Zoyo","creator_url":"https://huggingface.co/xus","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Spain Fuel Prices\\n\\t\\n\\nThis dataset is the result of collecting and parsing every day of the year 2024 the data provided from \\nGobierno de Espa√±a. Ministerio para la Transici√≥n Ecol√≥gica y el Reto Demogr√°fico and the \\nthe price of a barrel of Brent provided by Cincodias. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tfuel-prices-2024-SPAIN.jsonl\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nField\\nType\\nDescription\\n\\n\\n\\t\\t\\nid\\nint\\nStation ID (Unique)\\n\\n\\nbrand\\nstr\\nGas station's brand\\n\\n\\nmunicipality\\nstr\\nMunicipality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xus/Spain-Fuel-Prices."},
  {"name":"semeval-2025-task11-track-b","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track B Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track B, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 11 standard ISO codes\\nTotal examples: 47111\\nSplits: train, dev, test\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTrack Information\\n\\t\\n\\nTrack B has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b."},
  {"name":"prueba_parquet","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlosdanielhernandezmena/prueba_parquet","creator_name":"Carlos Daniel Hern√°ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository with parquet files only.\\n"},
  {"name":"multiCHILDES","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/IParraMartin/multiCHILDES","creator_name":"I√±igo Parra","creator_url":"https://huggingface.co/IParraMartin","description":"\\n\\t\\n\\t\\t\\n\\t\\tmultiCHILDES: Multilingual Child-Directed Speech Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains child-directed speech from 19 languages, extracted from the CHILDES corpus. The text has been cleaned and is designed for text generation tasks, particularly in studying early language acquisition.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nSource: CHILDES corpus\\nLanguages: 19 languages\\nText Type: Child-directed speech\\nTask: Text Generation, Language Modeling\\nData Processing: The dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IParraMartin/multiCHILDES."},
  {"name":"SquadES_Ex1","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/itorrento/SquadES_Ex1","creator_name":"Iker Torrent√≥","creator_url":"https://huggingface.co/itorrento","description":"itorrento/SquadES_Ex1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"movies_dataset_hugginface","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lmah/movies_dataset_hugginface","creator_name":"Luis Miguel Arag√≥n Huerta","creator_url":"https://huggingface.co/lmah","description":"title: Nombre de la pel√≠cula.\\nrelease_year: A√±o en que se estren√≥ la pel√≠cula.\\ncritic_score: Puntuaci√≥n otorgada por cr√≠ticos de cine, generalmente en una escala de 0 a 100.\\naudience_score: Puntuaci√≥n otorgada por la audiencia, tambi√©n en una escala de 0 a 100.\\nbox_office_millions: Recaudaci√≥n en taquilla de la pel√≠cula, expresada en millones de d√≥lares.\\npopularity: Indicador de popularidad basado en m√©tricas como b√∫squedas, visualizaciones o menciones.\\nduration_minutes: Duraci√≥n de la‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lmah/movies_dataset_hugginface."},
  {"name":"devops_v2","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bichito69/devops_v2","creator_name":"Dario Ag√ºero","creator_url":"https://huggingface.co/bichito69","description":"bichito69/devops_v2 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"BenchMAX_Question_Answering","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from UN Parallel Corpus and xquad.\\nThe haystacks are from UN Parallel Corpus Test and Development Sets and we translate them to other languages by Google Translate.\\nThe multilingual QA data is from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering."},
  {"name":"M-ABSA","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tM-ABSA\\n\\t\\n\\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Description:\\n\\t\\n\\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\\nAll datasets are stored in the data/ folder:\\n\\nAll dataset contains 7 domains.\\n\\ndomains = [\\\"coursera\\\", \\\"hotel\\\", \\\"laptop\\\", \\\"restaurant\\\", \\\"phone\\\", \\\"sight\\\", \\\"food\\\"]\\n\\n\\nEach dataset contains 21 languages.\\n\\nlangs = [\\\"ar\\\", \\\"da\\\", \\\"de\\\", \\\"en\\\", \\\"es\\\", \\\"fr\\\", \\\"hi\\\", \\\"hr\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA."},
  {"name":"E-FAQ","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/GoBotsAI/E-FAQ","creator_name":"GoBots","creator_url":"https://huggingface.co/GoBotsAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tE-FAQ\\n\\t\\n\\nWe present the E-FAQ, a weakly-supervised dataset consisting of a collection of e-commerce frequently asked questions (FAQs). Each entry i of the\\ndataset is the pair (q_{i}, Q_{i}), in which q_{i} is an anchor question sentence and Q_{i} is a set of questions similar to the\\nanchor. All sentences are uttered in brazilian portuguese or spanish.\\n"},
  {"name":"mmlu-redux-2.0-spanish","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/amias-mx/mmlu-redux-2.0-spanish","creator_name":"Alianza Mexicana para la IA soberana","creator_url":"https://huggingface.co/amias-mx","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Translation\\n\\t\\n\\nThis repository contains the Spanish translation of dataset subsets from \\nedinburgh-dawg/mmlu-redux-2.0.\\nEach subset is preserved as a separate config, maintaining the original structure.\\nNote: The translations are generated using machine translation and may contain\\ntypical automated translation artifacts.\\n"},
  {"name":"SpanishCasualChat","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/mariagrandury/SpanishCasualChat","creator_name":"Mar√≠a Grandury","creator_url":"https://huggingface.co/mariagrandury","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpanishCasualChat\\n\\t\\n\\ntags: conversational-AI, dialogue-system, Spanish-language\\nNote: This is an AI-generated dataset so its content may be inaccurate or false\\nDataset Description:\\nThe 'SpanishCasualChat' dataset is a collection of Spanish conversational text aimed at training machine learning models for dialogue systems. It contains dialogues of various topics such as hobbies, travel experiences, and daily routines, presented in a casual and lengthy format to simulate real-life‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mariagrandury/SpanishCasualChat."},
  {"name":"Wikipedia-Abstract","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/laion/Wikipedia-Abstract","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"Wikipedia Abstract\\n\\n\\n  \\n\\n\\n\\nIntroducing Wikipedia Abstract, a comprehensive dataset encompassing abstracts, complete articles, and a popularity score index for both widely spoken and lesser-known Wikipedia subsets. Our dedication to Wikipedia-X ensures a centralized Wikipedia dataset that undergoes regular updates and adheres to the highest standards.\\nA central focus of our efforts was to include exotic languages that often lack up-to-date Wikipedia dumps or may not have any dumps at all.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laion/Wikipedia-Abstract."},
  {"name":"COPA-es","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/BSC-LT/COPA-es","creator_name":"Language Technologies Unit @ Barcelona Supercomputing Center","creator_url":"https://huggingface.co/BSC-LT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for COPA-es\\n\\t\\n\\n\\n\\nCOPA-es is a textual entailment dataset in Spanish, professionally translated from the COPA dataset in English. The dataset consists of 600 premises, each given a question and two choices with a label encoding which of the choices is more plausible given the annotator.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nCOPA-es (Choice of Plausible Alternatives - Spanish) is designed to simulate causal reasoning of text from commonsense‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BSC-LT/COPA-es."},
  {"name":"spanish-roleplay-4.5k","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Kukedlc/spanish-roleplay-4.5k","creator_name":"Eugenio Schiavoni","creator_url":"https://huggingface.co/Kukedlc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpanish Role Play 4.5k\\n\\t\\n\\n\\n\\n"},
  {"name":"OpenO1-SFT-ESP_10000first_","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/erickfmm/OpenO1-SFT-ESP_10000first_","creator_name":"Erick Merino","creator_url":"https://huggingface.co/erickfmm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nVersi√≥n traducida al espa√±ol de https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nVersi√≥n traducida autom√°ticamente usando modelo opus de HelsinkiNLP (ver c√≥digo fuente usado en la traducci√≥n en archivos del dataset)\\nPor limitaciones t√©cnicas s√≥lo se tradujeron los primeros 12mil, de los cuales se realiz√≥ una limpieza de consistencia r√°pida y quedaron aproximadamente 10mil.\\nSe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/erickfmm/OpenO1-SFT-ESP_10000first_."},
  {"name":"RegTweets","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/guillermoruiz/RegTweets","creator_name":"Luis Guillermo Ruiz","creator_url":"https://huggingface.co/guillermoruiz","description":"This is a dataset created from Tweets written in Spanish, particularly from M√©xico. The classification task is to chose the Mexican State where the message was written from.\\nThe label correspond to the state given the following table:\\n\\n\\t\\n\\t\\t\\nState name\\nLabel\\nState name\\nLabel\\n\\n\\n\\t\\t\\nAguascalientes\\nAguascalientes\\nMexico\\nMexico\\n\\n\\nBaja California\\nBC\\nNayarit\\nNayarit\\n\\n\\nBaja California Sur\\nBCS\\nNuevo Le√≥n\\nNL\\n\\n\\nCampeche\\nCampeche\\nOaxaca\\nOaxaca\\n\\n\\nChiapas\\nChiapas\\nPuebla\\nPuebla\\n\\n\\nChihuahua\\nChihuahua\\nQuer√©taro‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/guillermoruiz/RegTweets."},
  {"name":"MexEmojis","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/guillermoruiz/MexEmojis","creator_name":"Luis Guillermo Ruiz","creator_url":"https://huggingface.co/guillermoruiz","description":"This is a dataset of tweets written in Mexican Spanish and the labels is an emoji describing the emotion.\\nThe region columns is the token for the Mexican state from where the message was written.\\nThe state token is one of the following:\\n\\n\\t\\n\\t\\t\\nState name\\nLabel\\nState name\\nLabel\\n\\n\\n\\t\\t\\nAguascalientes\\nAguascalientes\\nMexico\\nMexico\\n\\n\\nBaja California\\nBC\\nNayarit\\nNayarit\\n\\n\\nBaja California Sur\\nBCS\\nNuevo Le√≥n\\nNL\\n\\n\\nCampeche\\nCampeche\\nOaxaca\\nOaxaca\\n\\n\\nChiapas\\nChiapas\\nPuebla\\nPuebla\\n\\n\\nChihuahua\\nChihuahua‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/guillermoruiz/MexEmojis."},
  {"name":"multilingual_refusals","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/s-nlp/multilingual_refusals","creator_name":"s-nlp","creator_url":"https://huggingface.co/s-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\tData description\\n\\t\\n\\nThis dataset is designed to train and evaluate models for the task of refusal detection in generated responses. The dataset consists of input prompts sourced from the lmsys/lmsys-chat-1m collection, encompassing a variety of languages including English, German, French, Russian, and Spanish. To increase refusal diversity, the responses and refusals were generated using two models, Gemini Flash 1.5 and LLaMA-3.3-70b.\\nThe dataset is primarily intended to train‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/s-nlp/multilingual_refusals."},
  {"name":"mmmlu_lite","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMLU-Lite\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is about‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite."},
  {"name":"CL4Lang","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AntiplagiatCompany/CL4Lang","creator_name":"Antiplagiat","creator_url":"https://huggingface.co/AntiplagiatCompany","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCross-lingual plagiarism detection: Two are better than one\\n\\t\\n\\nThe widespread availability of scientific documents in multiple languages, coupled with the development of automatic translation and editing tools, has created a demand for efficient methods that can detect plagiarism across different languages.\\nA dataset for cross-lingual plagiarism evaluation. Collection consists of a subset of Wikipedia articles on 4 languages (ru, hy, es, en). Quary consists of wikipedia documents‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AntiplagiatCompany/CL4Lang."},
  {"name":"spanish_ner_dataset","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HUMADEX/spanish_ner_dataset","creator_name":"HUMADEX Research Group","creator_url":"https://huggingface.co/HUMADEX","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpanish NER dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgement\\n\\t\\n\\nThis dataset had been created as part of joint research of HUMADEX research group (https://www.linkedin.com/company/101563689/) and has received funding by the European Union Horizon Europe Research and Innovation Program project SMILE (grant number 101080923) and Marie Sk≈Çodowska-Curie Actions (MSCA) Doctoral Networks, project BosomShield ((rant number 101073222). Responsibility for the information and views expressed herein‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HUMADEX/spanish_ner_dataset."},
  {"name":"spanish_ner_dataset","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HUMADEX/spanish_ner_dataset","creator_name":"HUMADEX Research Group","creator_url":"https://huggingface.co/HUMADEX","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpanish NER dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgement\\n\\t\\n\\nThis dataset had been created as part of joint research of HUMADEX research group (https://www.linkedin.com/company/101563689/) and has received funding by the European Union Horizon Europe Research and Innovation Program project SMILE (grant number 101080923) and Marie Sk≈Çodowska-Curie Actions (MSCA) Doctoral Networks, project BosomShield ((rant number 101073222). Responsibility for the information and views expressed herein‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HUMADEX/spanish_ner_dataset."},
  {"name":"text-moderation-02-multilingual","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ifmain/text-moderation-02-multilingual","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","description":"This dataset is based on Kaggle.It represents a version of @ifmain/text-moderation-410K that has been cleansed of semantically similar values and normalized to a 50/50 ratio of negative and neutral entries.\\nThe dataset contains 1.5M entries (91K * 17 languages).  \\nBefore use, augmentation is recommended! (e.g., character substitution to bypass moderation).\\nFor augmentation, you can use @ifmain/StringAugmentor.  \\nEnjoy using it!\\n"},
  {"name":"Multilingal-sakalt-data","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"„Éû„É´„ÉÅ„É™„É≥„Ç¨„É´„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇmit„É©„Ç§„Çª„É≥„Çπ„Åß„Åô„ÄÇ\\n"},
  {"name":"tachiwin_translate","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ljcamargo/tachiwin_translate","creator_name":"Luis J Camargo","creator_url":"https://huggingface.co/ljcamargo","description":"ljcamargo/tachiwin_translate dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Rasonamiento_noticias_test","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NickyNicky/Rasonamiento_noticias_test","creator_name":"Nicky","creator_url":"https://huggingface.co/NickyNicky","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNota:\\n\\t\\n\\n** Se observa alu en las infe\\n"},
  {"name":"multilingual-coco","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/romrawinjp/multilingual-coco","creator_name":"Romrawin Chumpu","creator_url":"https://huggingface.co/romrawinjp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Common Objects in Context (COCO) Dataset\\n\\t\\n\\nThis dataset is a collection of multiple language open-source captions of COCO dataset. \\nThe split in this dataset is set according to Andrej Karpathy's split from dataset_coco.json file. The collection was created specifically for simplicity of use in training and evaluation pipeline by non-commercial and research purposes. The COCO images dataset is licensed under a Creative Commons Attribution 4.0 License.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/romrawinjp/multilingual-coco."},
  {"name":"AyaVisionBench","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/AyaVisionBench","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Aya Vision Benchmark\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \\nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/AyaVisionBench."},
  {"name":"webfaq","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\\n\\n   \\n       Overview |\\n       Details  |\\n       Structure  |\\n       Examples |\\n       Considerations |\\n       License |\\n       Citation |\\n       Contact |\\n       Acknowledgement\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq."},
  {"name":"oasst1","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1."},
  {"name":"Everything_Instruct_Multilingual","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEverything Instruct (Multilingual Edition)\\n\\t\\n\\nEverything you need... all in one place üíò\\n\\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\\nNote2: This version of the dataset supports the following languages:\\n\\nEnglish\\nRussian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual."},
  {"name":"ShareGPT52K","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/RyokoAI/ShareGPT52K","creator_name":"Ryoko AI","creator_url":"https://huggingface.co/RyokoAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ShareGPT52K90K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a collection of approximately 52,00090,000 conversations scraped via the ShareGPT API before it was shut down.\\nThese conversations include both user prompts and responses from OpenAI's ChatGPT.\\nThis repository now contains the new 90K conversations version. The previous 52K may\\nbe found in the old/ directory.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntext-generation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RyokoAI/ShareGPT52K."},
  {"name":"oasst2","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen Assistant Conversations Dataset Release 2 (OASST2)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \\nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \\nAll messages have a role property: this can either be \\\"assistant\\\" or \\\"prompter\\\". The roles in \\nconversation threads from prompt to leaf node strictly alternate between \\\"prompter\\\" and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2."},
  {"name":"Global-MMLU","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU üåç is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) üóΩ or Culturally Agnostic (CA) ‚öñÔ∏è. These annotations were collected as part of an open‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU."},
  {"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\tlightblue/reasoning-multilingual-R1-Llama-70B-train\\n\\t\\n\\nThis is a multilingual reasoning dataset covering more than 30 languages.\\nThis dataset was made by:\\n\\nSampling prompts from English datasets and translating them to various languages\\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\\n\\nThis dataset was then used to train a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train."},
  {"name":"wmt24pp","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tWMT24++\\n\\t\\n\\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\\nthe publication\\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\\nIf you are interested in the images of the source URLs for each document, please see here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema\\n\\t\\n\\nEach language pair is stored in its own jsonl file.\\nEach row is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp."},
  {"name":"thinking-multilingual-30-23-small-690","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \\nOr use the \\\"big\\\" version: big 10k rows version\\n"},
  {"name":"conceptnet5","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/conceptnet5/conceptnet5","creator_name":"conceptnet5","creator_url":"https://huggingface.co/conceptnet5","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Conceptnet5\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nConceptNet is a multilingual knowledge base, representing words and\\nphrases that people use and the common-sense relationships between\\nthem. The knowledge in ConceptNet is collected from a variety of\\nresources, including crowd-sourced resources (such as Wiktionary and\\nOpen Mind Common Sense), games with a purpose (such as Verbosity and\\nnadya.jp), and expert-created resources (such as WordNet and JMDict).\\nYou can browse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/conceptnet5/conceptnet5."},
  {"name":"exams","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mhardalov/exams","creator_name":"Momchil Hardalov","creator_url":"https://huggingface.co/mhardalov","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nEXAMS is a benchmark dataset for multilingual and cross-lingual question answering from high school examinations. It consists of more than 24,000 high-quality high school exam questions in 16 languages, covering 8 language families and 24 school subjects from Natural Sciences and Social Sciences, among others.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mhardalov/exams."},
  {"name":"xquad","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/google/xquad","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xquad\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nXQuAD (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering\\nperformance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set\\nof SQuAD v1.1 (Rajpurkar et al., 2016) together with their professional translations into ten languages: Spanish, German,\\nGreek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/xquad."},
  {"name":"xtreme","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xtreme\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme."},
  {"name":"CC-NEWS-ES","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES","creator_name":"Leonardo Ignacio C√≥rdoba","creator_url":"https://huggingface.co/LeoCordoba","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CC-NEWS-ES\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCC-NEWS-ES is a Spanish-language dataset of news. The corpus was generated by extracting the Spanish articles from CC-NEWS (news index of Common Crawl) of 2019. For doing that FastText model was used for language prediction.\\nIt contains a total of 7,473,286 texts and 1,812,009,283 words distributed as follows:\\n\\n\\t\\n\\t\\t\\ndomain\\ntexts\\nwords\\n\\n\\n\\t\\t\\nar\\n532703\\n1.45127e+08\\n\\n\\nbo\\n29557\\n7.28996e+06\\n\\n\\nbr\\n107\\n14207\\n\\n\\ncl\\n116661‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES."},
  {"name":"cantemist-ner","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PlanTL-GOB-ES/cantemist-ner","creator_name":"Plan de Tecnolog√≠as del Lenguaje - Gobierno de Espa√±a","creator_url":"https://huggingface.co/PlanTL-GOB-ES","description":"https://temu.bsc.es/cantemist/"},
  {"name":"cantemist-ner","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PlanTL-GOB-ES/cantemist-ner","creator_name":"Plan de Tecnolog√≠as del Lenguaje - Gobierno de Espa√±a","creator_url":"https://huggingface.co/PlanTL-GOB-ES","description":"https://temu.bsc.es/cantemist/"},
  {"name":"mfaq","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/clips/mfaq","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"We present the first multilingual FAQ dataset publicly available. We collected around 6M FAQ pairs from the web, in 21 different languages."},
  {"name":"mqa","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages."},
  {"name":"multilingual_librispeech","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/facebook/multilingual_librispeech","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiLingual LibriSpeech\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \\nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/multilingual_librispeech."},
  {"name":"spanish_imdb_synopsis","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/mathigatti/spanish_imdb_synopsis","creator_name":"Mathias Gatti","creator_url":"https://huggingface.co/mathigatti","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spanish IMDb Synopsis\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n4969 movie synopsis from IMDb in spanish.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[N/A]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nAll descriptions are in spanish, the other fields have some mix of spanish and english.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n[N/A]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\ndescription: IMDb description for the movie (string), should be spanish\\nkeywords: IMDb keywords for the movie (string), mix of spanish and english‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mathigatti/spanish_imdb_synopsis."},
  {"name":"voxpopuli","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/facebook/voxpopuli","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation."},
  {"name":"multilingual-sentiments","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/tyqiangz/multilingual-sentiments","creator_name":"Tay Yong Qiang","creator_url":"https://huggingface.co/tyqiangz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Sentiments Dataset\\n\\t\\n\\nA collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.\\nMost multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments."},
  {"name":"go_emotions-es-mt","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/mrm8488/go_emotions-es-mt","creator_name":"Manuel Romero","creator_url":"https://huggingface.co/mrm8488","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGoEmotions Spanish\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tA Spanish translation (using EasyNMT) of the GoEmotions dataset.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFor more information check the official Model Card\\n\\t\\n\\n"},
  {"name":"codiesp","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/bigbio/codiesp","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"Synthetic corpus of 1,000 manually selected clinical case studies in Spanish\\nthat was designed for the Clinical Case Coding in Spanish Shared Task, as part\\nof the CLEF 2020 conference.\\n\\nThe goal of the task was to automatically assign ICD10 codes (CIE-10, in\\nSpanish) to clinical case documents, being evaluated against manually generated\\nICD10 codifications. The CodiEsp corpus was selected manually by practicing\\nphysicians and clinical documentalists and annotated by clinical coding\\nprofessionals meeting strict quality criteria. They reached an inter-annotator\\nagreement of 88.6% for diagnosis coding, 88.9% for procedure coding and 80.5%\\nfor the textual reference annotation.\\n\\nThe final collection of 1,000 clinical cases that make up the corpus had a total\\nof 16,504 sentences and 396,988 words. All documents are in Spanish language and\\nCIE10 is the coding terminology (the Spanish version of ICD10-CM and ICD10-PCS).\\nThe CodiEsp corpus has been randomly sampled into three subsets. The train set\\ncontains 500 clinical cases, while the development and test sets have 250\\nclinical cases each. In addition to these, a collection of 176,294 abstracts\\nfrom Lilacs and Ibecs with the corresponding ICD10 codes (ICD10-CM and\\nICD10-PCS) was provided by the task organizers. Every abstract has at least one\\nassociated code, with an average of 2.5 ICD10 codes per abstract.\\n\\nThe CodiEsp track was divided into three sub-tracks (2 main and 1 exploratory):\\n\\n- CodiEsp-D: The Diagnosis Coding sub-task, which requires automatic ICD10-CM\\n  [CIE10-Diagn√≥stico] code assignment.\\n- CodiEsp-P: The Procedure Coding sub-task, which requires automatic ICD10-PCS\\n  [CIE10-Procedimiento] code assignment.\\n- CodiEsp-X: The Explainable AI exploratory sub-task, which requires to submit\\n  the reference to the predicted codes (both ICD10-CM and ICD10-PCS). The goal \\n  of this novel task was not only to predict the correct codes but also to \\n  present the reference in the text that supports the code predictions.\\n\\nFor further information, please visit https://temu.bsc.es/codiesp or send an\\nemail to encargo-pln-life@bsc.es"},
  {"name":"lambada_openai","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/EleutherAI/lambada_openai","creator_name":"EleutherAI","creator_url":"https://huggingface.co/EleutherAI","description":"The LAMBADA dataset as processed by OpenAI. It is used to evaluate the capabilities\\nof computational models for text understanding by means of a word prediction task.\\nLAMBADA is a collection of narrative texts sharing the characteristic that human subjects\\nare able to guess their last word if they are exposed to the whole text, but not\\nif they only see the last sentence preceding the target word. To succeed on LAMBADA,\\ncomputational models cannot simply rely on local context, but must be able to keep track\\nof information in the broader discourse.\\n\\nReference: https://github.com/openai/gpt-2/issues/131#issuecomment-497136199"},
  {"name":"odex","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/neulab/odex","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"ODEX is an Open-Domain EXecution-based NL-to-Code generation data benchmark. \\nIt contains 945 samples with a total of 1,707 human-written test cases, \\ncovering intents in four different natural languages -- 439 in English, 90 in Spanish, 164 in Japanese, and 252 in Russian."},
  {"name":"legal-mc4","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/legal-mc4","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"Legal-MC4: A Corpus Covering the Legal Part of MC4 for European Languages"},
  {"name":"multiconer_v2","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/MultiCoNER/multiconer_v2","creator_name":"MultiCoNER","creator_url":"https://huggingface.co/MultiCoNER","description":"Complex named entities (NE), like the titles of creative works, are not simple nouns and pose challenges for NER systems (Ashwini and Choi, 2014). They can take the form of any linguistic constituent, like an imperative clause (‚ÄúDial M for Murder‚Äù), and do not look like traditional NEs (Persons, Locations, etc.). This syntactic ambiguity makes it challenging to recognize them based on context. We organized the MultiCoNER task (Malmasi et al., 2022) at SemEval-2022 to address these challenges in 11 languages, receiving a very positive community response with 34 system papers. Results confirmed the challenges of processing complex and long-tail NEs: even the largest pre-trained Transformers did not achieve top performance without external knowledge. The top systems infused transformers with knowledge bases and gazetteers. However, such solutions are brittle against out of knowledge-base entities and noisy scenarios like the presence of spelling mistakes and typos. We propose MultiCoNER II which represents novel challenges through new tasks that emphasize the shortcomings of the current top models.\\n\\nMultiCoNER II features complex NER in these languages:\\n\\n1. English\\n2. Spanish\\n3. Hindi\\n4. Bangla\\n5. Chinese\\n6. Swedish\\n7. Farsi\\n8. French\\n9. Italian\\n10. Portugese\\n11. Ukranian\\n12. German\\n\\nFor more details see https://multiconer.github.io/\\n\\n## References\\n* Sandeep Ashwini and Jinho D. Choi. 2014. Targetable named entity recognition in social media. CoRR, abs/1408.0782.\\n* Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta Kar, Oleg Rokhlenko. 2022. SemEval-2022 Task 11: Multilingual Complex Named Entity Recognition (MultiCoNER)."},
  {"name":"alpaca-spanish","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/bertin-project/alpaca-spanish","creator_name":"BERTIN Project","creator_url":"https://huggingface.co/bertin-project","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBERTIN Alpaca Spanish\\n\\t\\n\\nThis dataset is a translation to Spanish of alpaca_data_cleaned.json, a clean version of the Alpaca dataset made at Stanford.\\nAn earlier version used Facebook's NLLB 1.3B model, but the current version uses OpenAI's gpt-3.5-turbo, hence this dataset cannot be used to create models that compete in any way against OpenAI.\\n"},
  {"name":"oa-stackexchange","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/donfu/oa-stackexchange","creator_name":"Donfu","creator_url":"https://huggingface.co/donfu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStackexchange Instructions for OpenAssistant\\n\\t\\n\\nThis dataset is taken from https://archive.org/details/stackexchange.\\nThere's a single parquet file combining all stackexchange sites. The threads\\nhave been filtered as follows: only threads with an accepted answer, for which\\nboth the question and response is less than 1000 characters have been choosen.\\nOther answers, or questions without accepted answers, or long entries have been\\ndroppped.\\nEach row consists of\\n\\nINSTRUCTION\\nRESPONSE‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/donfu/oa-stackexchange."},
  {"name":"recetas-cocina","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/somosnlp/recetas-cocina","creator_name":"SomosNLP","creator_url":"https://huggingface.co/somosnlp","description":"somosnlp/recetas-cocina dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"mgsm","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/juletxara/mgsm","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","description":"Multilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper [Language models are multilingual chain-of-thought reasoners](http://arxiv.org/abs/2210.03057).\\n\\nThe same 250 problems from [GSM8K](https://arxiv.org/abs/2110.14168) are each translated via human annotators in 10 languages. The 10 languages are:\\n- Spanish\\n- French\\n- German\\n- Russian\\n- Chinese\\n- Japanese\\n- Thai\\n- Swahili\\n- Bengali\\n- Telugu\\n\\nYou can find the input and targets for each of the ten languages (and English) as `.tsv` files.\\nWe also include few-shot exemplars that are also manually translated from each language in `exemplars.py`."},
  {"name":"sumstew","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Joemgu/sumstew","creator_name":"Jonas","creator_url":"https://huggingface.co/Joemgu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"sumstew\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTL;DR:\\n\\t\\n\\nSumstew is a abstractive, multilingual Dataset, with a balanced number of samples from a diverse set of summarization Datasets. The input sizes range up to 16384 tokens.\\nFiltered using a diverse set of heuristics to encourage high coverage, accuracy and factual consistency. Code to reproduce Dataset available at TODO\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTask Information\\n\\t\\n\\n\\nTask Categories: The tasks covered by this dataset are primarily summarization‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Joemgu/sumstew."},
  {"name":"toxi-text-3M","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\\n\\n\\t\\n\\t\\t\\n\\nToxic\\nNeutral\\nTotal\\n\\n\\n\\t\\t\\nmultilingual-train-deduplicated.csv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M."},
  {"name":"similarity-sentences-spanish","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jaimevera1107/similarity-sentences-spanish","creator_name":"Jaime Vera","creator_url":"https://huggingface.co/jaimevera1107","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsimilarity-sentences-spanish (SSS)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset comprises a collection of sentences generated using Chat GPT-3, covering various general topics.\\nThe dataset also includes sentences from two existing datasets, STS-ES and STSB-Multi-MT, as well as SICK, which were used as additional sources.\\nThe sentences in this dataset were generated to exhibit varying levels of similarity based on randomly divided prompts.\\n\\n\\t\\n\\t\\t\\nSource\\nShare (rows)\\nCount (rows)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jaimevera1107/similarity-sentences-spanish."},
  {"name":"massive_translation_dataset","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Amani27/massive_translation_dataset","creator_name":"Amani N","creator_url":"https://huggingface.co/Amani27","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Massive Dataset for Translation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is derived from AmazonScience/MASSIVE dataset for translation task purpose.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nTranslation\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nEnglish (en_US)\\nGerman (de_DE)\\nHindi (hi_IN)\\nSpanish (es_ES)\\nFrench (fr_FR)\\nItalian (it_IT)\\nArabic (ar_SA)\\nDutch (nl_NL)\\nJapanese (ja_JP)\\nPortugese (pt_PT)\\n\\n"},
  {"name":"esci","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/tasksource/esci","creator_name":"tasksource","creator_url":"https://huggingface.co/tasksource","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"esci\\\"\\n\\t\\n\\nESCI product search dataset\\nhttps://github.com/amazon-science/esci-data/\\nPreprocessings: \\n-joined the two relevant files\\n-product_text aggregate all product text\\n-mapped esci_label to full name \\n@article{reddy2022shopping,\\ntitle={Shopping Queries Dataset: A Large-Scale {ESCI} Benchmark for Improving Product Search},\\nauthor={Chandan K. Reddy and Llu√≠s M√†rquez and Fran Valero and Nikhil Rao and Hugo Zaragoza and Sambaran Bandyopadhyay and Arnab Biswas and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tasksource/esci."},
  {"name":"belebele","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\\n\\t\\n\\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele."},
  {"name":"GSM8KInstruct_Parallel","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Mathoctopus/GSM8KInstruct_Parallel","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","description":"Mathoctopus/GSM8KInstruct_Parallel dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Open_Assistant_Conversation_Chains","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\n\\n\\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\\n\\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\\n\\nIt was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains."},
  {"name":"cml-tts","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ylacombe/cml-tts","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for CML-TTS\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG).\\nCML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in Dutch, German, French, Italian, Polish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/cml-tts."},
  {"name":"librivox-tracks","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\n"},
  {"name":"multilingual-tts","keyword":"spanish","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/MohamedRashad/multilingual-tts","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBefore Anything and Everything ‚ö±\\n\\t\\n\\nIn the time of writing this Dataset Card, 17,490 18,412 civilian has been killed in Palestine (7,870 8,000 are children and 6,121 6,200 are women).\\nSeek any non-profit organization to help them with what you can (For myself, I use Mersal) üáµüá∏\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Multilingual TTS dataset is an exceptional compilation of text-to-speech (TTS) samples, meticulously crafted to showcase the richness and diversity of human languages.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/multilingual-tts."},
  {"name":"multilingual-pl-bert","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\\n"},
  {"name":"databench","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/cardiffnlp/databench","creator_name":"Cardiff NLP","creator_url":"https://huggingface.co/cardiffnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\tüíæüèãÔ∏èüíæ DataBench üíæüèãÔ∏èüíæ\\n\\t\\n\\nThis repository contains the original 65 datasets used for the paper Question Answering over Tabular Data with DataBench:\\nA Large-Scale Empirical Evaluation of LLMs which appeared in LREC-COLING 2024.\\nLarge Language Models (LLMs) are showing emerging abilities, and one of the latest recognized ones is tabular\\nreasoning in question answering on tabular data. Although there are some available datasets to assess question\\nanswering systems on tabular data, they‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cardiffnlp/databench."},
  {"name":"openassistant-deepseek-coder","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using:\\nB_INST = '\\\\n### Instruction:\\\\n'\\nE_INST = '\\\\n### Response:\\\\n'\\nBOS = '<ÔΩúbegin‚ñÅof‚ñÅsentenceÔΩú>'\\nEOS = '\\\\n<|EOT|>\\\\n'\\n\\nSample Preparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder."},
  {"name":"sharegpt_dialogue_base","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base","creator_name":"Hieu Lam","creator_url":"https://huggingface.co/lamhieu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe dataset is from unknown, formatted as dialogues for speed and ease of use. Many thanks to author for releasing it.\\nImportantly, this format is easy to use via the default chat template of transformers, meaning you can use huggingface/alignment-handbook immediately, unsloth.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\nView online through viewer.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\nWe advise you to reconsider before use, thank you. If you find it useful, please like and follow this account.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base."},
  {"name":"sib200","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200."},
  {"name":"aya_dataset","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_dataset","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\n\\nCurated by: Contributors of Aya Open Science Intiative.\\n\\nLanguage(s): 65 languages (71 including dialects &‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_dataset."},
  {"name":"aya_collection","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_collection","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection."},
  {"name":"aya_evaluation_suite","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\\n\\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\\nmachine-translations of handpicked examples into 101 languages ‚Üí‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite."},
  {"name":"CulturaY","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \\nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \\nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY."},
  {"name":"GPT-4-Prompts","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/erfanzar/GPT-4-Prompts","creator_name":"Erfan zare chavoshi","creator_url":"https://huggingface.co/erfanzar","description":"Multi-Turn Conversational Prompts from ChatGPT-4 (10K+ Tokens)\\nAbstract:\\nThis dataset offers a valuable collection of multi-turn conversational prompts generated by ChatGPT-4, carefully curated for diverse prompt styles (chatml, gemma, llama). Each prompt exceeds 10,000 tokens, providing ample context and inspiration for training and evaluating large language models. Ideal for researchers and developers interested in exploring advanced conversational AI capabilities.\\nTable of Contents:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/erfanzar/GPT-4-Prompts."},
  {"name":"bio-mqm-dataset","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zouharvi/bio-mqm-dataset","creator_name":"Vil√©m Zouhar","creator_url":"https://huggingface.co/zouharvi","description":"This dataset is compiled from the official Amazon repository (all respective licensing applies).\\nIt contains system translations, multiple references, and their quality evaluation on the MQM scale. It accompanies the ACL 2024 paper Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains.\\nWatch a brief 4 minutes-long video.\\n\\nAbstract: We introduce a new, extensive multidimensional quality metrics (MQM) annotated dataset covering 11 language pairs in the biomedical domain. We use this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/bio-mqm-dataset."},
  {"name":"XMedbench","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/XMedbench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Medicine: Model, Dataset, Benchmark, Code\\n\\t\\n\\nCovering English, Chinese, French, Hindi, Spanish, Hindi, Arabic So far\\n\\n   üë®üèª‚ÄçüíªGithub ‚Ä¢üìÉ Paper ‚Ä¢ ü§ó ApolloCorpus ‚Ä¢ ü§ó XMedBench \\n      ‰∏≠Êñá  |  English\\n\\n\\n\\n\\n\\n\\t\\t\\n\\t\\tüåà Update\\n\\t\\n\\n\\n[2024.03.07] Paper released.\\n[2024.02.12] ApolloCorpus and  XMedBench  is publishedÔºÅüéâ\\n[2024.01.23] Apollo repo is publishedÔºÅüéâ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tResults\\n\\t\\n\\n   \\n\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\n\\nZip File\\nData category\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData:\\n\\t\\n\\n\\nEN:\\n\\nMedQA-USMLE \\nMedMCQA\\nPubMedQA:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/XMedbench."},
  {"name":"basqueparl","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HiTZ/basqueparl","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBasqueParl: A Bilingual Corpus of Basque Parliamentary Transcriptions\\n\\t\\n\\nThis repository contains BasqueParl, a bilingual corpus for political discourse analysis. It covers transcriptions from the Parliament of \\nthe Basque Autonomous Community for eight years and two legislative terms (2012-2020), and its main characteristic is the presence of Basque-Spanish \\ncode-switching speeches.\\nüìñ Paper: BasqueParl A Bilingual Corpus of Basque Parliamentary Transcriptions In LREC 2022.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/basqueparl."},
  {"name":"aya_collection_language_split","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_collection_language_split","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection_language_split."},
  {"name":"tokenizer-wiki-bench","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Tokenizer Benchmark\\n\\t\\n\\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \\nfrom transformers import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench."},
  {"name":"MediaSpeech","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ymoslem/MediaSpeech","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMediaSpeech\\n\\t\\n\\nMediaSpeech is a dataset of Arabic, French, Spanish, and Turkish media speech built with the purpose of testing Automated Speech Recognition (ASR) systems performance. The dataset contains 10 hours of speech for each language provided.\\nThe dataset consists of short speech segments automatically extracted from media videos available on YouTube and manually transcribed, with some pre-processing and post-processing.\\nBaseline models and WAV version of the dataset can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/MediaSpeech."},
  {"name":"Multilingual-Medical-Corpus","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HiTZ/Multilingual-Medical-Corpus","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n    \\n    \\n    Mutilingual Medical Corpus\\n    \\n\\n\\nMultilingual-Medical-Corpus a 3 billion word multilingual corpus for training LLMs adapted to the medical domain. Multilingual-Medical-Corpus includes four languages, namely, English, Spanish, French, and Italian.\\n\\n\\n\\nüìñ Paper: Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The Medical Domain\\nüåê Project Website: https://univ-cotedazur.eu/antidote\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpus Description\\n\\t\\n\\n\\nDeveloped by: Iker Garc√≠a-Ferrero, Rodrigo Agerri‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/Multilingual-Medical-Corpus."},
  {"name":"RAG_Multilingual","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/RAG_Multilingual","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RAG_Multilingual\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nRAG_Multilingual is an instruction-following synthetic QA dataset created from extractive QA datasets from Catalan, English and Spanish reference sets.\\nThe reference datasets were: SQAD (https://huggingface.co/datasets/rajpurkar/squad), Catalanqa (https://huggingface.co/datasets/projecte-aina/catalanqa) and SQAC (https://huggingface.co/datasets/PlanTL-GOB-ES/SQAC).\\nThis dataset, of 56.406 instances, was created by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/RAG_Multilingual."},
  {"name":"mCoT-MATH","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/laihuiyuan/mCoT-MATH","creator_name":"Huiyuan Lai","creator_url":"https://huggingface.co/laihuiyuan","description":"\\n\\t\\n\\t\\t\\n\\t\\tmCoT: Multilingual Instruction Tuning for Reasoning Consistency in Language Models\\n\\t\\n\\nPaper: https://arxiv.org/abs/2406.02301\\nCode: https://github.com/laihuiyuan/mCoT\\nModel: https://huggingface.co/laihuiyuan/mCoT\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nBased on MetaMathQA and MathInstruct\\n, we use machine translation to compile mCoT-MATH, the first large-scale multilingual math CoT reasoning dataset containing around 6.3 million samples for 11 diverse languages.\\nWe train a 7B parameter model mCoT for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laihuiyuan/mCoT-MATH."},
  {"name":"orca_dpo_pairs","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/multilingual/orca_dpo_pairs","creator_name":"mLLM multilingual","creator_url":"https://huggingface.co/multilingual","description":"\\n    \\n\\n\\nmLLM IMPLEMENTATION OF Intel/orca_dpo_pairs.\\nLANGUAGES:\\nARABIC\\nCHINESE\\nFRENCH\\nGERMAN\\nRUSSIAN\\nSPANISH\\nTURKISH\\n(WIP)\\n"},
  {"name":"Reglamento_Aeronautico_Colombiano_2024GemmaQA","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/somosnlp/Reglamento_Aeronautico_Colombiano_2024GemmaQA","creator_name":"SomosNLP","creator_url":"https://huggingface.co/somosnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RAC Corpus: Base de Datos del Reglamento Aeron√°utico Colombiano üõ´üìöüá®üá¥ - Formato Gemma\\n\\t\\n\\n\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nTotal etiquetado: 100%\\n\\nEtiquetado y Curado: 24,478\\nPendiente: 0\\nBorradores: 0\\nDescartados: 696\\n\\nEste dataset contiene muestras etiquetadas del Reglamento Aeron√°utico Colombiano (RAC), abarcando la totalidad de sus cap√≠tulos. Tras una meticulosa labor de curaci√≥n y etiquetado, el dataset ha alcanzado un progreso del 100%, equivalente a un‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp/Reglamento_Aeronautico_Colombiano_2024GemmaQA."},
  {"name":"CareQA","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HPAI-BSC/CareQA","creator_name":"High Performance Artificial Intelligence @ Barcelona Supercomputing Center (HPAI at BSC)","creator_url":"https://huggingface.co/HPAI-BSC","description":"\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for CareQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCareQA is a healthcare QA dataset with two versions:\\n\\nClosed-Ended Version: A multichoice question answering (MCQA) dataset containing 5,621 QA pairs across six categories. Available in English and Spanish.\\nOpen-Ended Version: A free-response dataset derived from the closed version, containing 2,769 QA pairs (English only).\\n\\nThe dataset originates from official sources of the Spanish Specialized Healthcare Training (FSE)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPAI-BSC/CareQA."},
  {"name":"synthetic-pii-ner-mistral-v1","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/urchade/synthetic-pii-ner-mistral-v1","creator_name":"Urchade Zaratiana","creator_url":"https://huggingface.co/urchade","description":"This the synthetic dataset used for training https://huggingface.co/urchade/gliner_multi_pii-v1. You can get it by browsing the files and dowloading the data.json file.\\n"},
  {"name":"swim-ir-monolingual","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/nthakur/swim-ir-monolingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SWIM-IR (Monolingual)\\n\\t\\n\\n\\n\\n\\nThis is the monolingual subset of the SWIM-IR dataset, where the query generated and the passage are both in the same language.\\nA few remaining languages will be added in the upcoming v2 version of SWIM-IR. The dataset is available as CC-BY-SA 4.0.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is a synthetic multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-monolingual."},
  {"name":"webui-dom-snapshots","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WebUI DOM snapshots\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: Gary Benson\\nLanguages: Mostly English (87%);\\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\\nLicense: CC0 1.0 Universal\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots."},
  {"name":"xvnli","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/floschne/xvnli","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXVNLI\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from the original repo: https://github.com/e-bug/iglue\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{bugliarello-etal-2022-iglue,\\n  title = \\t {{IGLUE}: A Benchmark for Transfer Learning across Modalities, Tasks, and Languages},\\n  author =       {Bugliarello, Emanuele and Liu, Fangyu and Pfeiffer, Jonas and Reddy, Siva and Elliott, Desmond and Ponti, Edoardo Maria and Vuli{\\\\'c}, Ivan},\\n  booktitle = \\t {Proceedings of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xvnli."},
  {"name":"neovalle_H4rmony_dpo_translated_English_to_Spanish","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/NickyNicky/neovalle_H4rmony_dpo_translated_English_to_Spanish","creator_name":"Nicky","creator_url":"https://huggingface.co/NickyNicky","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\toriginal dataset.\\n\\t\\n\\nhttps://huggingface.co/datasets/neovalle/H4rmony_dpo\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmodel use _translate.\\n\\t\\n\\nhttps://huggingface.co/NickyNicky/gemma-1.1-2b-it_orpo_traslate_en_es_V1\\n\\n"},
  {"name":"GlotCC-V1","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
  {"name":"GlotCC-V1","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
  {"name":"Reddit-Post-Translation","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Iker/Reddit-Post-Translation","creator_name":"Iker Garc√≠a-Ferrero","creator_url":"https://huggingface.co/Iker","description":"\\nMost machine translation datasets are based on formal texts from newspapers or other professionally written sources. This causes models to underperform when asked to translate colloquial text found on the internet. To address this issue, we have retrieved approximately 15K Reddit posts from SophieTr/reddit_clean and translated them into Spanish using GPT-4.\\nWarning: This dataset contains random posts from Reddit, which may include biased political opinions, NSFW content, rude language, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Iker/Reddit-Post-Translation."},
  {"name":"synthetic_pii_finance_multilingual","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/gretelai/synthetic_pii_finance_multilingual","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","description":"\\n  \\n  Image generated by DALL-E. See prompt for more details\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tüíº üìä Synthetic Financial Domain Documents with PII Labels\\n\\t\\n\\ngretelai/synthetic_pii_finance_multilingual is a dataset of full length synthetic financial documents containing Personally Identifiable Information (PII), generated using Gretel Navigator and released under Apache 2.0.\\nThis dataset is designed to assist with the following use cases:\\n\\nüè∑Ô∏è Training NER (Named Entity Recognition) models to detect and label PII in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_pii_finance_multilingual."},
  {"name":"nomiracl-instruct","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/miracl/nomiracl-instruct","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NoMIRACL (EMNLP 2024 Findings Track)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Overview\\n\\t\\n\\nThis repository contains the fine-tuning (training & development split) of the NoMIRACL instruct dataset for fine-tuning LLMs on multilingual relevance assessment.\\nThe training dataset is a binary classification task; they need to explicitly output either Yes, answer is present or I don't know. \\nThe dataset contains training pairs from all 18 languages for both splits: relevant & non-relevant.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miracl/nomiracl-instruct."},
  {"name":"BIRDeep_AudioAnnotations","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/GrunCrow/BIRDeep_AudioAnnotations","creator_name":"Alba M√°rquez-Rodr√≠guez","creator_url":"https://huggingface.co/GrunCrow","description":"\\n\\t\\n\\t\\t\\n\\t\\tBIRDeep Audio Annotations\\n\\t\\n\\n\\n\\nThe BIRDeep Audio Annotations dataset is a collection of bird vocalizations from Do√±ana National Park, Spain. It was created as part of the BIRDeep project, which aims to optimize the detection and classification of bird species in audio recordings using deep learning techniques. The dataset is intended for use in training and evaluating models for bird vocalization detection and identification.\\nThe research code and further information is available at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GrunCrow/BIRDeep_AudioAnnotations."},
  {"name":"wikipedia-2024-06-bge-m3","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3","creator_name":"Upstash","creator_url":"https://huggingface.co/Upstash","description":"\\n\\t\\n\\t\\t\\n\\t\\tWikipedia Embeddings with BGE-M3\\n\\t\\n\\nThis dataset contains embeddings from the\\nJune 2024 Wikipedia dump\\nfor the 11 most popular languages.\\nThe embeddings are generated with the multilingual\\nBGE-M3 model.\\nThe dataset consists of Wikipedia articles split into paragraphs,\\nand embedded with the aforementioned model.\\nTo enhance search quality, the paragraphs are prefixed with their\\nrespective article titles before embedding.\\nAdditionally, paragraphs containing fewer than 100 characters‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3."},
  {"name":"text_ratings","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"Todo - Write dataset card\\n"},
  {"name":"openbookqa-es","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/BSC-LT/openbookqa-es","creator_name":"Language Technologies Unit @ Barcelona Supercomputing Center","creator_url":"https://huggingface.co/BSC-LT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for openbookqa_es\\n\\t\\n\\n\\n\\nopenbookqa_es is a question answering dataset in Spanish, professionally translated from the main version of the OpenBookQA dataset in English. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nopenbookqa_es (Open Book Question Answering - Spanish) is designed to simulate open book exams and assess human-like understanding of a subject. The dataset comprises 500 instances in the validation split and another 500 instances in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BSC-LT/openbookqa-es."},
  {"name":"MMMLU","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLU‚Äôs test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU."},
  {"name":"fake_news_corpus_spanish","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mariagrandury/fake_news_corpus_spanish","creator_name":"Mar√≠a Grandury","creator_url":"https://huggingface.co/mariagrandury","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFake News Corpus Spanish\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nG√≥mez-Adorno, H., Posadas-Dur√°n, J. P., Enguix, G. B., & Capetillo, C. P. (2021). Overview of FakeDeS at IberLEF 2021: Fake News Detection in Spanish Shared Task. Procesamiento del Lenguaje Natural, 67, 223-231.\\n\\nArag√≥n, M. E., Jarqu√≠n, H., G√≥mez, M. M. Y., Escalante, H. J., Villase√±or-Pineda, L., G√≥mez-Adorno, H., ... & Posadas-Dur√°n, J. P. (2020, September). Overview of mex-a3t at iberlef 2020: Fake news and aggressiveness‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mariagrandury/fake_news_corpus_spanish."},
  {"name":"muri-it","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it."},
  {"name":"mgsm","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/jbross-ibm-research/mgsm","creator_name":"J Bross","creator_url":"https://huggingface.co/jbross-ibm-research","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MGSM\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCopy and merge of this MGSM Dataset, Catalan version, Basque version, Galician version, but in training samples we removed the prompt formatting, e.g. removed Question: ... in question field or Answer: ... in answer field.\\nMultilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper Language models are multilingual chain-of-thought reasoners.\\nThe same 250 problems from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jbross-ibm-research/mgsm."},
  {"name":"MultiSimV2","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MichaelR207/MultiSimV2","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiSim Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe MultiSim benchmark is a growing collection of text simplification datasets targeted at sentence simplification in several languages.  Currently, the benchmark spans 12 languages.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nSentence Simplification\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"MichaelR207/MultiSimV2\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you use this benchmark, please cite our‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MichaelR207/MultiSimV2."},
  {"name":"vqa","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/worldcuisines/vqa","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\\n\\t\\n\\n\\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 October‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa."},
  {"name":"atlassian-qna","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/youngmon/atlassian-qna","creator_name":"youngseo","creator_url":"https://huggingface.co/youngmon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìÑ Question and Answer for Atlassian Products\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nAtlassian Community\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Description\\n\\t\\n\\nThe dataset primarily includes questions, answers, tags, and URLs.\\n\\nQuestions contain the author, title, and content of the post.\\nAnswers include usage instructions, solutions, and other information provided by engineers and users.\\nTags represent the categories or topics of the post.\\nURLs provide links to the original documents.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/youngmon/atlassian-qna."},
  {"name":"wikipedia","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/OpenLLM-France/wikipedia","creator_name":"OpenLLM France","creator_url":"https://huggingface.co/OpenLLM-France","description":"\\n\\t\\n\\t\\t\\n\\t\\tPlain text of Wikipedia\\n\\t\\n\\n\\nDataset Description\\nSize\\nExample use (python)\\nData fields\\nNotes on data formatting\\n\\n\\nLicense\\nAknowledgements\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a plain text version of pages from wikipedia.org spaces for several languages\\n(English,\\nGerman,\\nFrench,\\nSpanish,\\nItalian).\\nThe text is without HTML tags nor wiki templates.\\nIt just includes markdown syntax for headers, lists and tables.\\nSee Notes on data formatting for more details.\\nIt was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenLLM-France/wikipedia."},
  {"name":"HPLT2.0_cleaned","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned."},
  {"name":"Razonamiento_noticias_v2","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NickyNicky/Razonamiento_noticias_v2","creator_name":"Nicky","creator_url":"https://huggingface.co/NickyNicky","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel inference.\\n\\t\\n\\n* https://huggingface.co/KingNish/Reasoning-Llama-3b-v0.1\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcolumnas.\\n\\t\\n\\n** news: **\\n- contiene solo la noticia sin procesar\\n\\n\\n** query: **\\ncontiene\\n - user: consulta del usuario\\n - assinstant: respuesta de la IA\\n\\n{\\\"user\\\": user, \\\"assistant\\\": IA}\\n\\n\\n** messages: **\\n- contiene una lista de json\\n\\n[\\n  {\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt},\\n  {\\\"role\\\": \\\"reasoning\\\", \\\"content\\\": reasoning_output},\\n  {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": response}\\n]\\n\\n"},
  {"name":"m-ArenaHard","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/m-ArenaHard","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-ArenaHard\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-ArenaHard."},
  {"name":"ToxicCommons","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/PleIAs/ToxicCommons","creator_name":"PleIAs","creator_url":"https://huggingface.co/PleIAs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tToxic Commons\\n\\t\\n\\nToxic Commons is a release of 2 million samples of annotated, public domain, multilingual text that was used to train Celadon. \\nIt is being released alongside Celadon, in order to better understand multilingual and multicultural toxicity. \\nEach sample was classified across 5 axes of toxicity:\\n\\nRace and origin-based bias: includes racism as well as bias against someone‚Äôs country or region of origin or immigration status, especially immigrant or refugee status.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PleIAs/ToxicCommons."},
  {"name":"P-MMEval","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Qwen/P-MMEval","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tP-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce a multilingual benchmark, P-MMEval, covering effective fundamental and capability-specialized datasets. We extend the existing benchmarks, ensuring consistent language coverage across all datasets and providing parallel samples among multiple languages, supporting up to 10 languages from 8 language families (i.e., en, zh, ar, es, ja, ko, th, fr, pt‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Qwen/P-MMEval."},
  {"name":"belebele-fleurs","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBelebele-Fleurs\\n\\t\\n\\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\\n\\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs."},
  {"name":"include-base-44","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/include-base-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-base (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-base-44."},
  {"name":"unlabelled-sti-corpus","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SIRIS-Lab/unlabelled-sti-corpus","creator_name":"SIRIS Lab, Research Division of SIRIS Academic","creator_url":"https://huggingface.co/SIRIS-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe unlabelled-sti-corpus is a diverse dataset designed for developing information extraction datasets (i.e. text classification or NER) for Science, Technology, and Innovation (STI) records. The corpus contains approximately 35,000 records sourced from four major repositories:\\n\\n22,500 publications from OpenAlex\\n10,000 European research projects from CORDIS\\n5,000 regional projects from Interreg and Kohesio\\n7,000 patents from Lens.org\\n\\nThe dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SIRIS-Lab/unlabelled-sti-corpus."},
  {"name":"open-dict-words-ipa","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-dict Words IPA\\n\\t\\n\\nThis dataset is a copy of https://github.com/open-dict-data/ipa-dict\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nIPA data is currently available for the following languages:\\n\\n\\t\\n\\t\\t\\nLanguage\\nCode\\n\\n\\n\\t\\t\\nar\\nArabic (Modern Standard)\\n\\n\\nde\\nGerman\\n\\n\\nen_UK\\nEnglish (Received Pronunciation)\\n\\n\\nen_US\\nEnglish (General American)\\n\\n\\neo\\nEsperanto\\n\\n\\nes_ES\\nSpanish (Spain)\\n\\n\\nes_MX\\nSpanish (Mexico)\\n\\n\\nfa\\nPersian\\n\\n\\nfi\\nFinnish\\n\\n\\nfr_FR\\nFrench (France)\\n\\n\\nfr_QC\\nFrench (Qu√©bec)\\n\\n\\nis\\nIcelandic\\n\\n\\nja\\nJapanese\\n\\n\\njam‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa."},
  {"name":"include-lite-44","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/include-lite-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-lite (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-lite-44."},
  {"name":"sib-fleurs","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs."},
  {"name":"yourbench_fairytales","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sumuks/yourbench_fairytales","creator_name":"Sumuk Shashidhar","creator_url":"https://huggingface.co/sumuks","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFairytales ü¶Ñ Dataset\\n\\t\\n\\n\\n    \\n\\n\\nThis dataset contains a collection of fairytales from various origins, processed and organized for easy access. The stories are sourced from the FairytaleQA Dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset contains 278 stories from 15 different categories/origins. Each story entry includes:\\n\\ntitle: The name of the story\\ncategory: The origin/category of the story\\ncontent: The full text content of the story\\nsummary: Summary of the story‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sumuks/yourbench_fairytales."},
  {"name":"Global-MMLU-Lite","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 15 languages, including English. It is \\\"lite\\\" version of the original Global-MMLU dataset üåç.\\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \\n\\nCurated by: Professional annotators and contributors of Cohere For‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite."},
  {"name":"2M-Belebele","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2M-Belebele\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\\n\\t\\n\\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \\nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele."},
  {"name":"reranker_continuous_filt_max7_train","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReranker training data\\n\\t\\n\\nThis data was generated using 4 steps:\\n\\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \\\"1\\\", \\\"2\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train."},
  {"name":"reranking-datasets-light","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"unkown","creator_url":"https://huggingface.co/abdoelsayed","description":"\\n\\t\\n\\t\\t\\n\\t\\tüî• Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation üî•\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\\n\\t\\n\\n\\n    \\n    \\n    \\n    \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n    \\n\\n\\n\\nA curated collection of ready-to-use datasets for retrieval and reranking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light."},
  {"name":"MultiLingualSentiment","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/clapAI/MultiLingualSentiment","creator_name":"clapAI","creator_url":"https://huggingface.co/clapAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nMultilingualSentiment is a sentiment classification dataset that encompasses three sentiment labels: Positive, Neutral, Negative\\nThe dataset spans multiple languages and covers a wide range of domains, making it ideal for multilingual sentiment analysis tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\nThe dataset was meticulously collected and aggregated from various sources, including Hugging Face and Kaggle. These sources provide diverse languages and domains to ensure a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clapAI/MultiLingualSentiment."},
  {"name":"CoT-XLang","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Egor-AI/CoT-XLang","creator_name":"Egor AI","creator_url":"https://huggingface.co/Egor-AI","description":"RU:CoT-XLang ‚Äî —ç—Ç–æ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç, —Å–æ—Å—Ç–æ—è—â–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ —Å –ø–æ—à–∞–≥–æ–≤—ã–º–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º–∏ (Chain-of-Thought, CoT) –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —è–∑—ã–∫–∞—Ö, –≤–∫–ª—é—á–∞—è –∞–Ω–≥–ª–∏–π—Å–∫–∏–π, —Ä—É—Å—Å–∫–∏–π, —è–ø–æ–Ω—Å–∫–∏–π –∏ –¥—Ä—É–≥–∏–µ. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π –≤ –∑–∞–¥–∞—á–∞—Ö, —Ç—Ä–µ–±—É—é—â–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π —Ä–µ—à–µ–Ω–∏–π —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤. –î–∞—Ç–∞—Å–µ—Ç –≤–∫–ª—é—á–∞–µ—Ç –æ–∫–æ–ª–æ 2,419,912 –ø—Ä–∏–º–µ—Ä–æ–≤, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª–∏, —Å–ø–æ—Å–æ–±–Ω—ã–µ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ—à–∞–≥–æ–≤—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è.\\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Egor-AI/CoT-XLang."},
  {"name":"BoundingDocs","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/letxbe/BoundingDocs","creator_name":"Letxbe","creator_url":"https://huggingface.co/letxbe","description":"\\n\\nBoundingDocs\\n\\nüîç The largest spatially-annotated dataset for Document Question Answering\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBoundingDocs is a unified dataset for Document Question Answering (QA) that includes spatial annotations. It consolidates multiple public datasets from Document AI and Visually Rich Document Understanding (VRDU) domains. The dataset reformulates Information Extraction (IE) tasks into QA tasks, making it a valuable resource for training and evaluating Large Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/letxbe/BoundingDocs."},
  {"name":"vdr-multilingual-train","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/llamaindex/vdr-multilingual-train","creator_name":"LlamaIndex","creator_url":"https://huggingface.co/llamaindex","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Visual Document Retrieval Dataset\\n\\t\\n\\n\\n\\nThis dataset consists of 500k multilingual query image samples, collected and generated from scratch using public internet pdfs. The queries are synthetic and generated using VLMs (gemini-1.5-pro and Qwen2-VL-72B).\\n\\nIt was used to train the vdr-2b-multi-v1 retrieval multimodal, multilingual embedding model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow it was created\\n\\t\\n\\nThis is the entire data pipeline used to create the Italian subset of this dataset. Each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llamaindex/vdr-multilingual-train."},
  {"name":"vdr-multilingual-test","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/llamaindex/vdr-multilingual-test","creator_name":"LlamaIndex","creator_url":"https://huggingface.co/llamaindex","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Visual Document Retrieval Benchmarks\\n\\t\\n\\n\\nThis dataset consists of 15 different benchmarks used to initially evaluate the vdr-2b-multi-v1 multimodal retrieval embedding model. These benchmarks allow the testing of multilingual, multimodal retrieval capabilities on text-only, visual-only and mixed page screenshots.\\nEach language subset contains queries and images in that language and is divided into three different categories by the \\\"pagetype\\\" column. Each category‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llamaindex/vdr-multilingual-test."},
  {"name":"unal-repository-dataset-instruct","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/JulianVelandia/unal-repository-dataset-instruct","creator_name":"Juli√°n Camilo Velandia","creator_url":"https://huggingface.co/JulianVelandia","description":"T√≠tulo: Grade Works UNAL Dataset InstructDescripci√≥n: Este dataset contiene un formato estructurado de Pregunta: Respuesta generado a partir del contenido de los trabajos de grado del repositorio de la Universidad Nacional de Colombia. Cada registro incluye un fragmento del contenido del trabajo, una pregunta generada a partir de este y su respuesta correspondiente. Este dataset es ideal para tareas de fine-tuning en modelos de lenguaje para tareas de preguntas y respuestas.  \\nColumnas:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JulianVelandia/unal-repository-dataset-instruct."},
  {"name":"iabdsapa_dataset","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fbarragan/iabdsapa_dataset","creator_name":"Francesc Barragan","creator_url":"https://huggingface.co/fbarragan","description":"fbarragan/iabdsapa_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"degeneration-html-multilingual","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe Degeneration of the Nation Multilingual Dataset\\n\\t\\n\\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual."},
  {"name":"syntethic-data-gen","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Miguelpef/syntethic-data-gen","creator_name":"Miguel","creator_url":"https://huggingface.co/Miguelpef","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Name\\n\\t\\n\\nGeneracion de datos sinteticos a partir de Facebook/llama-3.1-405b\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEl dataset es creado autom√°ticamente bas√°ndose en un tema principal proporcionado. A partir de este, se generan un n√∫mero variable de subtemas seg√∫n la especificaci√≥n del usuario. Cada subtema incluye una serie de preguntas y sus respectivas respuestas. Todo el contenido textual es generado usando el modelo de lenguaje Facebook/llama-3.1-405b.\\n\\nCurated by: MiguelPeFr‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Miguelpef/syntethic-data-gen."},
  {"name":"Numbers","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Tamazight/Numbers","creator_name":"Standard Moroccan Tamazight (ZGH)","creator_url":"https://huggingface.co/Tamazight","description":"\\n\\t\\n\\t\\t\\n\\t\\tTamazight Numbers Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains numbers from 1 to 1,000,000 translated into:\\n\\nEnglish.\\nFrench.\\nSpanish.\\nTamazight (Berber).\\n\\nThe dataset is designed to assist researchers and developers in building machine learning models for understanding and converting numbers into words in multiple languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains the following columns:\\n\\n\\t\\n\\t\\t\\nColumn\\nDescription\\nExample\\n\\n\\n\\t\\t\\nNumber\\nThe numeric‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tamazight/Numbers."},
  {"name":"imatrix-calibration","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/eaddario/imatrix-calibration","creator_name":"Ed Addario","creator_url":"https://huggingface.co/eaddario","description":"\\n\\t\\n\\t\\t\\n\\t\\tImportance Matrix (imatrix) calibration datasets\\n\\t\\n\\nThis dataset consists of over 10M tokens of cleaned and de-duplicated text files for 13 different languages. Each language file is available in five sizes, ranging from large (~ 26,000 lines equivalent to approx. 750K tokens), to micro (~ 1,625 lines and 125K tokens avg).\\nOriginal data sourced from HuggingFaceFW/fineweb and HuggingFaceFW/fineweb-2\\n\\n\\t\\n\\t\\t\\nFile\\nLanguage\\nLines\\nSize\\n\\n\\n\\t\\t\\ncalibration_ar_large\\nArabic\\n26,000\\n3.1M‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eaddario/imatrix-calibration."},
  {"name":"open_government","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AgentPublic/open_government","creator_name":"AgentPublic","creator_url":"https://huggingface.co/AgentPublic","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Government Dataset\\n\\t\\n\\nOpen Government is the largest agregation of governement text and data made available as part of open data programs. \\nIn total, the dataset contains approximately 380B tokens. While Open Government aims to become a global resource, in its current state it mostly features open datasets from the US, France, European and international organizations.\\nThe dataset comprises 16 collections curated through two different initiaties: Finance commons and Legal commons.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AgentPublic/open_government."},
  {"name":"Synthdog-Multilingual-100","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthdog Multilingual\\n\\t\\n\\n\\n\\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100."},
  {"name":"BenchMAX_Math","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Math","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Math is a dataset of BenchMAX, sourcing from MGSM.\\nWe extend the original dataset to 6 more languages.\\nThe data is first translated by Google Translate, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Math."},
  {"name":"BenchMAX_Science","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Science","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Science is a dataset of BenchMAX, sourcing from GPQA.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by Google Translate, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Science."},
  {"name":"BenchMAX_Function_Completion","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from humanevalplus.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by GPT-4o, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion."},
  {"name":"BenchMAX_Problem_Solving","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Problem_Solving is a dataset of BenchMAX, sourcing from LiveCodeBench.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by GPT-4o, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving."},
  {"name":"smol","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tSMOL\\n\\t\\n\\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\\ntranslations into 221 Low-Resource Languages, for the purpose of training\\ntranslation models, and otherwise increasing the representations of said\\nlanguages in NLP and technology.\\nPlease read the SMOL Paper and the\\nGATITOS Paper for a much more\\nthorough description!\\nThere are four resources in this directory:\\n\\nSmolDoc: document-level translations into 100 languages\\nSmolSent: sentence-level translations into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/smol."},
  {"name":"DATA-AI_Chat","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","description":"\\n\\t\\n\\t\\t\\n\\t\\tDATA-AI: Il Modello di IA di M.INC.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tüìå Introduzione\\n\\t\\n\\nDATA-AI √® un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello √® basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \\nDATA-AI √® stato addestrato su un‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat."},
  {"name":"ea-mt-benchmark","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark","creator_name":"Sapienza NLP, Sapienza University of Rome","creator_url":"https://huggingface.co/sapienzanlp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for EA-MT\\n\\t\\n\\nEA-MT (Entity-Aware Machine Translation) is a multilingual benchmark for evaluating the capabilities of Large Language Models (LLMs) and Machine Translation (MT) models in translating simple sentences with potentially challenging entity mentions, e.g., entities for which a word-for-word translation may not be accurate.\\nHere is an example of a simple sentence with a challenging entity mention:\\n\\nEnglish: \\\"What is the plot of The Catcher in the Rye?\\\"\\nItalian:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark."},
  {"name":"u-sticker","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/metchee/u-sticker","creator_name":"Metilda Chee","creator_url":"https://huggingface.co/metchee","description":"\\n\\t\\n\\t\\t\\n\\t\\tU-Sticker\\n\\t\\n\\nUser-Sticker is a stickers dataset with multi-domain conversations.\\nFeatures of U-Sticker:\\n\\nMulti-domain interactions ‚úÖ\\nTemporal ‚úÖ\\nUser information ‚úÖ\\n370.2k stickers ‚úÖ (104k unique)\\n22.6k users ‚úÖ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nU-Sticker contains three files:\\n\\nConversation files: 1 to 67.json\\nDomain mapping files idx_to_domain.txt.\\nSticker files.\\n\\n\\nSticker files are available here and Baidu Cloud.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tConversation file\\n\\t\\n\\n\\nEmpty lines are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/metchee/u-sticker."},
  {"name":"head_qa_v2","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/alesi12/head_qa_v2","creator_name":"Alexis Correa Guillen","creator_url":"https://huggingface.co/alesi12","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nHEAD-QA v2 is an updated version of the HEAD-QA dataset, which is a multi-choice HEAlthcare Dataset. The questions come from exams to access a specialized position in the Spanish healthcare system, and are challenging even for highly specialized humans. They are designed by the Ministerio de Sanidad, Consumo y Bienestar Social, who also provides direct access to the exams of the last 5 years (in Spanish).\\nHEAD-QA V2 expands on the original dataset by including‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alesi12/head_qa_v2."},
  {"name":"high-quality-multilingual-sentences","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tHigh Quality Multilingual Sentences\\n\\t\\n\\n\\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\\n\\nExample row (from the all config):\\n{\\n    \\\"text\\\": \\\"ÿßŸÖÿßŸÖ ÿ¨ŸÖÿπŸá ÿßÿµŸÅŸáÿßŸÜ ⁄ØŸÅÿ™: ŸÖ€åÿ≤ÿßŸÜ ŸÜ€åÿßÿ≤ ÿ¢ÿ® ÿ¥ÿ±ÿ® ÿßÿµŸÅŸáÿßŸÜ €±€±.€µ ŸÖÿ™ÿ± ŸÖ⁄©ÿπÿ® ÿßÿ≥ÿ™ ⁄©Ÿá ÿ™ŸÖÿßŸÖ ÿßÿ≥ÿ™ÿßŸÜ ÿßÿµŸÅŸáÿßŸÜ ÿ±ÿß ŸæŸàÿ¥ÿ¥ ŸÖ€åÿØŸáÿØ Ÿà ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸÇÿ®ŸÑ ÿßÿ≤ ÿßŸÜŸÇŸÑÿßÿ® €å⁄©€å ÿßÿ≤ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿáÿß ÿØÿ± ÿ≠Ÿàÿ≤Ÿá ÿ¢ÿ® ÿ®ŸàÿØŸá ÿßÿ≥ÿ™.\\\",\\n    \\\"fasttext\\\": \\\"fa\\\",\\n    \\\"gcld3\\\": \\\"fa\\\"\\n}\\n\\nFields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences."},
  {"name":"Open-R1-Mulitlingual-SFT","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT","creator_name":"GUIJIN SON","creator_url":"https://huggingface.co/amphora","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-R1-Mulitlingual-SFT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nOpen-R1-Mulitlingual-SFT is a curated dataset designed for multilingual supervised fine-tuning.\\nThe source data comprises multiple datasets containing original prompts and responses, which were subsequently translated into 14 languages using GPT-4o.\\n\\n\\t\\n\\t\\t\\n\\t\\tSources\\n\\t\\n\\nThe dataset is derived from:\\n\\nopen-thoughts/OpenThoughts-114kHugging Face: open-thoughts/OpenThoughts-114k\\nbespokelabs/Bespoke-Stratos-17kHugging Face:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT."},
  {"name":"wikis","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/nyuuzyou/wikis","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Public MediaWiki Collection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 1,662,448 articles harvested from 930 random public MediaWiki instances found across the Internet. The collection was created by extracting current page content from these wikis, preserving article text, metadata, and structural information. The dataset represents a diverse cross-section of public wiki content spanning multiple domains, topics, and languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wikis."},
  {"name":"wikipedia_quality_wikirank","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy It‚Äôs Important\\n\\t\\n\\n\\nEnhances Trust: For readers and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank."},
  {"name":"Thinking-multilingual-big-10k-sft","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\\nenjoy üëç\\n"},
  {"name":"story_writing_benchmark","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lars1234/story_writing_benchmark","creator_name":"Lars Nieradzik","creator_url":"https://huggingface.co/lars1234","description":"\\n\\t\\n\\t\\t\\n\\t\\tStory Evaluation Dataset\\n\\t\\n\\n\\nThis dataset contains stories generated by Large Language Models (LLMs) across multiple languages, with comprehensive quality evaluations. It was created to train and benchmark models specifically on creative writing tasks.\\nThis benchmark evaluates an LLM's ability to generate high-quality short stories based on simple prompts like \\\"write a story about X with n words.\\\" It is similar to TinyStories but targets longer-form and more complex content, focusing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lars1234/story_writing_benchmark."},
  {"name":"multilingual_translation_sft","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"100k-raz-es","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/sintergica/100k-raz-es","creator_name":"Sint√©rgica AI","creator_url":"https://huggingface.co/sintergica","description":"sintergica/100k-raz-es dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"m-WildVision","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/m-WildVision","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-WildVision\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \\nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \\nThe authors demonstrated that these prompts enable automatic LLM judge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-WildVision."},
  {"name":"OpenHumanreasoning-multilingual-2.2k","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\\nnote: translations are not human generated.\\n"},
  {"name":"BRIGHTER-emotion-categories","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\tBRIGHTER Emotion Categories Dataset\\n\\t\\n\\nThis dataset contains the emotion categories data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe BRIGHTER Emotion Categories dataset is a comprehensive multi-language, multi-label emotion classification dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories."},
  {"name":"reasoning-conversations","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/syntaxsynth/reasoning-conversations","creator_name":"SyntaxSynth","creator_url":"https://huggingface.co/syntaxsynth","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Reasoning Dataset\\n\\t\\n\\n\\nInclude languages from German, Korean, Spanish, Japanese, French, Simplified Chinese, Traditional Chinese\\n\\nReasoning traces from Deepseek-v3-R1, Deepseek-v3-R1-Zero\\n\\n\\nCredits sponsored by Currents API\\n"},
  {"name":"MLAAD","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/mueller91/MLAAD","creator_name":"Nicolas M√ºller","creator_url":"https://huggingface.co/mueller91","description":"\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWelcome to MLAAD: The Multi-Language Audio Anti-Spoofing Dataset -- a dataset to train, test and evaluate audio deepfake detection. See\\nthe paper for more information.\\n\\n\\t\\n\\t\\t\\n\\t\\tStructure\\n\\t\\n\\nThe dataset is based on the M-AILABS dataset.\\nMLAAD is structured as follows:\\nfake\\n|-language_1\\n|-language_2\\n|- ....\\n|- language_K\\n    | - model_1_K\\n    | - model_2_K\\n    | - ....\\n    | - model_L_K\\n        | - meta.csv\\n        | - audio_L_K_1.wav\\n        | - audio_L_K_2.wav‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mueller91/MLAAD."},
  {"name":"aya_redteaming","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_redteaming","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Aya Red-teaming\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe Aya Red-teaming dataset is a human-annotated multilingual red-teaming dataset consisting of harmful prompts in 8 languages across 9 different categories of harm with explicit labels for \\\"global\\\" and \\\"local\\\" harm.\\n\\n\\n\\n\\n\\n\\nCurated by: Professional compensated annotators\\nLanguages: Arabic, English, Filipino, French, Hindi, Russian, Serbian and Spanish\\nLicense: Apache 2.0\\nPaper: arxiv link\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHarm Categories:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_redteaming."},
  {"name":"europa_eac_tm","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/community-datasets/europa_eac_tm","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Europa Education and Culture Translation Memory (EAC-TM)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a corpus of manually produced translations from english to up to 25 languages, released in 2012 by the European Union's Directorate General for Education and Culture (EAC).\\nTo load a language pair that is not part of the config, just specify the language code as language pair. For example, if you want to translate Czech to Greek:\\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/europa_eac_tm."},
  {"name":"europa_ecdc_tm","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/community-datasets/europa_ecdc_tm","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn October 2012, the European Union (EU) agency 'European Centre for Disease Prevention and Control' (ECDC) released a translation memory (TM), i.e. a collection of sentences and their professionally produced translations, in twenty-five languages.\\nECDC-TM covers 25 languages: the 23 official languages of the EU plus Norwegian (Norsk) and Icelandic. ECDC-TM was created by translating from English into the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/europa_ecdc_tm."},
  {"name":"opus_dogc","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_dogc","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for OPUS DOGC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nOPUS DOGC is a collection of documents from the Official Journal of the Government of Catalonia, in Catalan and Spanish languages, provided by Antoni Oliver Gonzalez from the Universitat Oberta de Catalunya.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nDataset is multilingual with parallel text in:\\n\\nCatalan\\nSpanish\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_dogc."},
  {"name":"opus_infopankki","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_infopankki","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for infopankki\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA parallel corpus of 12 languages, 66 bitexts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe underlying task is machine translation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_infopankki."},
  {"name":"opus_paracrawl","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for OpusParaCrawl\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nParallel corpora from Web Crawls collected in the ParaCrawl project.\\nTha dataset contains:\\n\\n42 languages, 43 bitexts\\ntotal number of files: 59,996\\ntotal number of tokens: 56.11G\\ntotal number of sentence fragments: 3.13G\\n\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs,\\ne.g.\\ndataset = load_dataset(\\\"opus_paracrawl\\\", lang1=\\\"en\\\", lang2=\\\"so\\\")\\n\\nYou can find‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl."},
  {"name":"opus_ubuntu","keyword":"spanish","license":"BSD 3-Clause \"New\" or \"Revised\" License","language":"en","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu."},
  {"name":"xcsr","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/INK-USC/xcsr","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for X-CSR\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTo evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr."},
  {"name":"xquad_r","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/google-research-datasets/xquad_r","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nXQuAD-R is a retrieval version of the XQuAD dataset (a cross-lingual extractive\\nQA dataset). Like XQuAD, XQUAD-R is an 11-way parallel dataset,  where each\\nquestion appears in 11 different languages and has 11 parallel correct answers\\nacross the languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset can be found with the following languages:\\n\\nArabic:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/xquad_r."},
  {"name":"CC-NEWS-ES-titles","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES-titles","creator_name":"Leonardo Ignacio C√≥rdoba","creator_url":"https://huggingface.co/LeoCordoba","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CC-NEWS-ES-titles\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCC-NEWS-ES-titles is a Spanish-language dataset for news titles generation. The text and titles comes from 2019 and 2020 CC-NEWS data (which is part of Common Crawl).\\nIt contains 402.310 pairs of news title and body, splitted in :\\n\\nTrain: 370.125\\n\\nEval: 16.092\\n\\nTest: 16.092\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntext-classification, sentiment-classification: The dataset can be used to train a model for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES-titles."},
  {"name":"pharmaconer","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PlanTL-GOB-ES/pharmaconer","creator_name":"Plan de Tecnolog√≠as del Lenguaje - Gobierno de Espa√±a","creator_url":"https://huggingface.co/PlanTL-GOB-ES","description":"PharmaCoNER: Pharmacological Substances, Compounds and Proteins Named Entity Recognition track\\n\\nThis dataset is designed for the PharmaCoNER task, sponsored by Plan de Impulso de las Tecnolog√≠as del Lenguaje (Plan TL).\\n\\nIt is a manually classified collection of clinical case studies derived from the Spanish Clinical Case Corpus (SPACCC), an\\nopen access electronic library that gathers Spanish medical publications from SciELO (Scientific Electronic Library Online).\\n\\nThe annotation of the entire set of entity mentions was carried out by medicinal chemistry experts\\nand it includes the following 4 entity types: NORMALIZABLES, NO_NORMALIZABLES, PROTEINAS and UNCLEAR.\\n\\nThe PharmaCoNER corpus contains a total of 396,988 words and 1,000 clinical cases that have been randomly sampled into 3 subsets.\\nThe training set contains 500 clinical cases, while the development and test sets contain 250 clinical cases each.\\nIn terms of training examples, this translates to a total of 8074, 3764 and 3931 annotated sentences in each set.\\nThe original dataset was distributed in Brat format (https://brat.nlplab.org/standoff.html).\\n\\nFor further information, please visit https://temu.bsc.es/pharmaconer/ or send an email to encargo-pln-life@bsc.es"},
  {"name":"pharmaconer","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PlanTL-GOB-ES/pharmaconer","creator_name":"Plan de Tecnolog√≠as del Lenguaje - Gobierno de Espa√±a","creator_url":"https://huggingface.co/PlanTL-GOB-ES","description":"PharmaCoNER: Pharmacological Substances, Compounds and Proteins Named Entity Recognition track\\n\\nThis dataset is designed for the PharmaCoNER task, sponsored by Plan de Impulso de las Tecnolog√≠as del Lenguaje (Plan TL).\\n\\nIt is a manually classified collection of clinical case studies derived from the Spanish Clinical Case Corpus (SPACCC), an\\nopen access electronic library that gathers Spanish medical publications from SciELO (Scientific Electronic Library Online).\\n\\nThe annotation of the entire set of entity mentions was carried out by medicinal chemistry experts\\nand it includes the following 4 entity types: NORMALIZABLES, NO_NORMALIZABLES, PROTEINAS and UNCLEAR.\\n\\nThe PharmaCoNER corpus contains a total of 396,988 words and 1,000 clinical cases that have been randomly sampled into 3 subsets.\\nThe training set contains 500 clinical cases, while the development and test sets contain 250 clinical cases each.\\nIn terms of training examples, this translates to a total of 8074, 3764 and 3931 annotated sentences in each set.\\nThe original dataset was distributed in Brat format (https://brat.nlplab.org/standoff.html).\\n\\nFor further information, please visit https://temu.bsc.es/pharmaconer/ or send an email to encargo-pln-life@bsc.es"},
  {"name":"flores_101","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
  {"name":"Axolotl-Spanish-Nahuatl","keyword":"spanish","license":"Mozilla Public License 2.0","language":"en","url":"https://huggingface.co/datasets/somosnlp-hackathon-2022/Axolotl-Spanish-Nahuatl","creator_name":"I Hackathon Somos NLP: PLN en Espa√±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2022","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAxolotl-Spanish-Nahuatl : Parallel corpus for Spanish-Nahuatl machine translation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Collection\\n\\t\\n\\nIn order to get a good translator, we collected and cleaned two of the most complete Nahuatl-Spanish parallel corpora available. Those are Axolotl collected by an expert team at UNAM and Bible UEDIN Nahuatl Spanish crawled by Christos Christodoulopoulos and Mark Steedman from Bible Gateway site.\\nAfter this, we ended with 12,207 samples from Axolotl due to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2022/Axolotl-Spanish-Nahuatl."},
  {"name":"readability-es-caes","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/somosnlp-hackathon-2022/readability-es-caes","creator_name":"I Hackathon Somos NLP: PLN en Espa√±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2022","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [readability-es-caes]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a compilation of short articles from websites dedicated to learn Spanish as a second language. These articles have been compiled from the following sources:\\n\\nCAES corpus (Mart√≠nez et al., 2019): the \\\"Corpus de Aprendices del Espa√±ol\\\" is a collection of texts produced by Spanish L2 learners from Spanish learning centers and universities. These text are produced‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2022/readability-es-caes."},
  {"name":"unam_tesis","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/somosnlp-hackathon-2022/unam_tesis","creator_name":"I Hackathon Somos NLP: PLN en Espa√±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2022","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card of \\\"unam_tesis\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nEl dataset unam_tesis cuenta con 1000 tesis de 5 carreras de la Universidad Nacional Aut√≥noma de M√©xico (UNAM), 200 por carrera. Se pretende seguir incrementando este dataset con las dem√°s carreras y m√°s tesis.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\ntext-classification\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEspa√±ol (es)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nLas instancias del dataset son de la‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2022/unam_tesis."},
  {"name":"readability-es-hackathon-pln-public","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/somosnlp-hackathon-2022/readability-es-hackathon-pln-public","creator_name":"I Hackathon Somos NLP: PLN en Espa√±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2022","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [readability-es-sentences]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCompilation of short Spanish articles for readability assessment.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a compilation of short articles from websites dedicated to learn Spanish as a second language. These articles have been compiled from the following sources: \\n\\nCoh-Metrix-Esp corpus (Quispesaravia, et al., 2016): collection of 100 parallel texts with simple and complex variants in Spanish.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2022/readability-es-hackathon-pln-public."},
  {"name":"xlel_wd_dictionary","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles."},
  {"name":"xlel_wd","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles."},
  {"name":"shades_nationality","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/bigscience-catalogue-data/shades_nationality","creator_name":"BigScience Catalogue Data","creator_url":"https://huggingface.co/bigscience-catalogue-data","description":"Possibly a placeholder dataset for the original here: https://huggingface.co/datasets/bigscience-catalogue-data/bias-shades\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Statement for SHADES\\n\\t\\n\\n\\nHow to use this document:\\nFill in each section according to the instructions. Give as much detail as you can, but there's no need to extrapolate. The goal is to help people understand your data when they approach it. This could be someone looking at it in ten years, or it could be you yourself looking back at the data in two‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bigscience-catalogue-data/shades_nationality."},
  {"name":"wit_base","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base."},
  {"name":"qg_esquad","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/lmqg/qg_esquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"[SQuAD-es](https://huggingface.co/datasets/squad_es) dataset for question generation (QG) task."},
  {"name":"ctebmsp","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/lcampillos/ctebmsp","creator_name":"Leonardo Campillos-Llanos","creator_url":"https://huggingface.co/lcampillos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCT-EBM-SP (Clinical Trials for Evidence-based Medicine in Spanish)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Clinical Trials for Evidence-Based-Medicine in Spanish corpus is a collection of 1200 texts about clinical trials studies and clinical trials announcements:\\n\\n500 abstracts from journals published under a Creative Commons license, e.g. available in PubMed or the Scientific Electronic Library Online (SciELO)\\n700 clinical trials announcements published in the European Clinical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lcampillos/ctebmsp."},
  {"name":"hatecheck-spanish","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Paul/hatecheck-spanish","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-spanish."},
  {"name":"FR_NFR_Spanish_requirements_classification","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/MariaIsabel/FR_NFR_Spanish_requirements_classification","creator_name":"Maria Isabel Limaylla Lunarejo","creator_url":"https://huggingface.co/MariaIsabel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nReSpa: Published version of dataset used for paper 'Towards an automatic requirements classification in a new Spanish dataset'\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nSpanish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nProject: Project's Identifier from which the requirements were obtained.\\nRequirement: Description of the software requirement.\\nFinal label: Label of the requirement: F (functional requirement) and NF (non-functional requirement).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MariaIsabel/FR_NFR_Spanish_requirements_classification."},
  {"name":"mapa","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/mapa","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset consists of 12 documents (9 for Spanish due to parsing errors) taken from EUR-Lex, a multilingual corpus of court\\ndecisions and legal dispositions in the 24 official languages of the European Union. The documents have been annotated\\nfor named entities following the guidelines of the MAPA project which foresees two\\nannotation level, a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mapa."},
  {"name":"sbb-dc-ocr","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/SBB/sbb-dc-ocr","creator_name":"Staatsbibliothek zu Berlin - Preu√üischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Berlin State Library OCR data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nThe digital collections of the SBB contain 153,942 digitized works from the time period of 1470 to 1945.\\n\\n\\nAt the time of publication, 28,909 works have been OCR-processed resulting in 4,988,099 full-text pages.\\nFor each page with OCR text, the language has been determined by langid (Lui/Baldwin 2012).\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nlanguage-modeling: this dataset has the potential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SBB/sbb-dc-ocr."},
  {"name":"xP3all","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot."},
  {"name":"lextreme","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/lextreme","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"The LEXTREME Benchmark is a collection of multilingual datasets for evaluating model performance \\nacross a diverse set of legal NLU tasks."},
  {"name":"una-fraza-al-diya","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/collectivat/una-fraza-al-diya","creator_name":"Col¬∑lectivaT","creator_url":"https://huggingface.co/collectivat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUna fraza al diya\\n\\t\\n\\nLadino language learning sentences prepared by Karen Sarhon of Sephardic Center of Istanbul. Each sentence has translations in Turkish, English, Spanish. Includes audio and image. 307 sentences in total.\\nSource: https://sefarad.com.tr/judeo-espanyolladino/frazadeldia/\\nImages and audio: http://collectivat.cat/share/judeoespanyol_audio_image.zip \\nOffical link on Ladino Data Hub\\nPaper on ArXiv\\nCitation:\\nPreparing an endangered language for the digital age: The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/collectivat/una-fraza-al-diya."},
  {"name":"splittedspanish3bwc","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/vialibre/splittedspanish3bwc","creator_name":"Via Libre","creator_url":"https://huggingface.co/vialibre","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Unannotated Spanish 3 Billion Words Corpora\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nNumber of lines: 300904000 (300M)\\nNumber of tokens: 2996016962 (3B)\\nNumber of chars: 18431160978 (18.4B)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nSpanish\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\n\\nAvailable to download here: Zenodo\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Subset\\n\\t\\n\\n\\nSpanish Wikis: Wich include Wikipedia, Wikinews, Wikiquotes and more. These were first processed with wikiextractor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vialibre/splittedspanish3bwc."},
  {"name":"xP3mt","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot."},
  {"name":"mc4_legal","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/mc4_legal","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MC4_Legal: A Corpus Covering the Legal Part of MC4 for European Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains large text resources (~133GB in total) from mc4 filtered for legal data that can be used for pretraining language models.\\nUse the dataset like this:\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"joelito/mc4_legal\\\", \\\"de\\\", split='train', streaming=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset supports the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mc4_legal."},
  {"name":"miracl-corpus","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/miracl/miracl-corpus","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MIRACL Corpus\\n\\t\\n\\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\\nThis dataset contains the collection data of the 16 \\\"known languages\\\". The remaining 2 \\\"surprise languages\\\" will not be released until later.\\nThe corpus for each language is prepared from a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus."},
  {"name":"meddocan","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/GuiGel/meddocan","creator_name":"Guillaume Gelabert","creator_url":"https://huggingface.co/GuiGel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"meddocan\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA personal upload of the SPACC_MEDDOCAN corpus. The tokenization is made with the help of a custom spaCy pipeline.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nName Entity Recognition\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields are the same among all splits.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GuiGel/meddocan."},
  {"name":"inferes","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/venelin/inferes","creator_name":"Venelin Kovatchev","creator_url":"https://huggingface.co/venelin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for InferES\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nNatural Language Inference dataset for European Spanish\\nPaper accepted and (to be) presented at COLING 2022\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nNatural Language Inference\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nSpanish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains two texts inputs (Premise and Hypothesis), Label for three-way classification, and annotation data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\ntrain size = 6444 \\ntest‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/venelin/inferes."},
  {"name":"inferes","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/venelin/inferes","creator_name":"Venelin Kovatchev","creator_url":"https://huggingface.co/venelin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for InferES\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nNatural Language Inference dataset for European Spanish\\nPaper accepted and (to be) presented at COLING 2022\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nNatural Language Inference\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nSpanish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains two texts inputs (Premise and Hypothesis), Label for three-way classification, and annotation data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\ntrain size = 6444 \\ntest‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/venelin/inferes."},
  {"name":"HashtagPrediction","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\\n\\t\\n\\n  \\nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \\n[arXiv]\\n[HuggingFace Models]\\n[Github repo]\\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDownload\\n\\t\\n\\nUse the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction."},
  {"name":"TyDiP","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Genius1237/TyDiP","creator_name":"Genius1237","creator_url":"https://huggingface.co/Genius1237","description":"The TyDiP dataset is a dataset of requests in conversations between wikipedia editors\\nthat have been annotated for politeness. The splits available below consists of only\\nrequests from the top 25 percentile (polite) and bottom 25 percentile (impolite) of\\npoliteness scores. The English train set and English test set that are\\nadapted from the Stanford Politeness Corpus, and test data in 9 more languages\\n(Hindi, Korean, Spanish, Tamil, French, Vietnamese, Russian, Afrikaans, Hungarian) \\nwas annotated by us."},
  {"name":"bioasq_2021_mesinesp","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/bigbio/bioasq_2021_mesinesp","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The main aim of MESINESP2 is to promote the development of practically relevant semantic indexing tools for biomedical content in non-English language. We have generated a manually annotated corpus, where domain experts have labeled a set of scientific literature, clinical trials, and patent abstracts. All the documents were labeled with DeCS descriptors, which is a structured controlled vocabulary created by BIREME to index scientific publications on BvSalud, the largest database of scientific documents in Spanish, which hosts records from the databases LILACS, MEDLINE, IBECS, among others.\\n\\nMESINESP track at BioASQ9 explores the efficiency of systems for assigning DeCS to different types of biomedical documents. To that purpose, we have divided the task into three subtracks depending on the document type. Then, for each one we generated an annotated corpus which was provided to participating teams:\\n\\n- [Subtrack 1 corpus] MESINESP-L ‚Äì Scientific Literature: It contains all   Spanish records from LILACS and IBECS databases at the Virtual Health Library   (VHL) with non-empty abstract written in Spanish.\\n- [Subtrack 2 corpus] MESINESP-T- Clinical Trials contains records from Registro   Espa√±ol de Estudios Cl√≠nicos (REEC). REEC doesn't provide documents with the   structure title/abstract needed in BioASQ, for that reason we have built   artificial abstracts based on the content available in the data crawled using   the REEC API.\\n- [Subtrack 3 corpus] MESINESP-P ‚Äì Patents: This corpus includes patents in   Spanish extracted from Google Patents which have the IPC code ‚ÄúA61P‚Äù and   ‚ÄúA61K31‚Äù. In addition, we also provide a set of complementary data such as:   the DeCS terminology file, a silver standard with the participants' predictions   to the task background set and the entities of medications, diseases, symptoms   and medical procedures extracted from the BSC NERs documents."},
  {"name":"meddocan","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/bigbio/meddocan","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"MEDDOCAN: Medical Document Anonymization Track\\n\\nThis dataset is designed for the MEDDOCAN task, sponsored by Plan de Impulso de las Tecnolog√≠as del Lenguaje.\\n\\nIt is a manually classified collection of 1,000 clinical case reports derived from the Spanish Clinical Case Corpus (SPACCC), enriched with PHI expressions.\\n\\nThe annotation of the entire set of entity mentions was carried out by experts annotatorsand it includes 29 entity types relevant for the annonymiation of medical documents.22 of these annotation types are actually present in the corpus: TERRITORIO, FECHAS, EDAD_SUJETO_ASISTENCIA, NOMBRE_SUJETO_ASISTENCIA, NOMBRE_PERSONAL_SANITARIO, SEXO_SUJETO_ASISTENCIA, CALLE, PAIS, ID_SUJETO_ASISTENCIA, CORREO, ID_TITULACION_PERSONAL_SANITARIO,ID_ASEGURAMIENTO, HOSPITAL, FAMILIARES_SUJETO_ASISTENCIA, INSTITUCION, ID_CONTACTO ASISTENCIAL,NUMERO_TELEFONO, PROFESION, NUMERO_FAX, OTROS_SUJETO_ASISTENCIA, CENTRO_SALUD, ID_EMPLEO_PERSONAL_SANITARIO\\n    \\nFor further information, please visit https://temu.bsc.es/meddocan/ or send an email to encargo-pln-life@bsc.es"},
  {"name":"pharmaconer","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/bigbio/pharmaconer","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"PharmaCoNER: Pharmacological Substances, Compounds and Proteins Named Entity Recognition track\\n\\nThis dataset is designed for the PharmaCoNER task, sponsored by Plan de Impulso de las Tecnolog√≠as del Lenguaje.\\n\\nIt is a manually classified collection of clinical case studies derived from the Spanish Clinical Case Corpus (SPACCC), an open access electronic library that gathers Spanish medical publications from SciELO (Scientific Electronic Library Online).\\n\\nThe annotation of the entire set of entity mentions was carried out by medicinal chemistry experts and it includes the following 4 entity types: NORMALIZABLES, NO_NORMALIZABLES, PROTEINAS and UNCLEAR.\\n\\nThe PharmaCoNER corpus contains a total of 396,988 words and 1,000 clinical cases that have been randomly sampled into 3 subsets. The training set contains 500 clinical cases, while the development and test sets contain 250 clinical cases each.\\n\\nFor further information, please visit https://temu.bsc.es/pharmaconer/ or send an email to encargo-pln-life@bsc.es"},
  {"name":"toy_corpus_asr_es","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlosdanielhernandezmena/toy_corpus_asr_es","creator_name":"Carlos Daniel Hern√°ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository with a standard data loader. The audio files are compressed in tar format. Since this repository contains very few audio files, it can be used to test certain scripts in local machines.\\n"},
  {"name":"toy_corpus_asr_es","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/carlosdanielhernandezmena/toy_corpus_asr_es","creator_name":"Carlos Daniel Hern√°ndez Mena","creator_url":"https://huggingface.co/carlosdanielhernandezmena","description":"This is an example of a repository with a standard data loader. The audio files are compressed in tar format. Since this repository contains very few audio files, it can be used to test certain scripts in local machines.\\n"},
  {"name":"MultiLegalPile_Wikipedia_Filtered","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPile_Wikipedia_Filtered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles."},
  {"name":"EU_Wikipedias","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/EU_Wikipedias","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"Wikipedia dataset containing cleaned articles of all languages.\\nThe datasets are built from the Wikipedia dump\\n(https://dumps.wikimedia.org/) with one split per language. Each example\\ncontains the content of one full Wikipedia article with cleaning to strip\\nmarkdown and unwanted sections (references, etc.)."},
  {"name":"ciempiess_test","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ciempiess/ciempiess_test","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"The CIEMPIESS TEST Corpus is a gender balanced corpus destined to test acoustic models for the speech recognition task. The corpus was manually transcribed and it contains audio recordings from 10 male and 10 female speakers. The CIEMPIESS TEST is one of the three corpora included at the LDC's \\\\\\\"CIEMPIESS Experimentation\\\\\\\" (LDC2019S07)."},
  {"name":"ciempiess_test","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ciempiess/ciempiess_test","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"The CIEMPIESS TEST Corpus is a gender balanced corpus destined to test acoustic models for the speech recognition task. The corpus was manually transcribed and it contains audio recordings from 10 male and 10 female speakers. The CIEMPIESS TEST is one of the three corpora included at the LDC's \\\\\\\"CIEMPIESS Experimentation\\\\\\\" (LDC2019S07)."},
  {"name":"qag_esquad","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/lmqg/qag_esquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Question & answer generation dataset based on SQuAD."},
  {"name":"multilingual-gec","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/juancavallotti/multilingual-gec","creator_name":"Juan Alberto Lopez Cavallotti","creator_url":"https://huggingface.co/juancavallotti","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual Grammar Error Correction\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset can be used to train a transformer model (we used T5) to correct grammar errors in simple sentences written in English, Spanish, French, or German. \\nThis dataset was developed as a component for the Squidigies platform.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nGrammar Error Correction: By appending the prefix fix grammar: to the prrompt.\\nLanguage Detection: By appending the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/juancavallotti/multilingual-gec."},
  {"name":"humset","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nlp-thedeep/humset","creator_name":"TheDEEP NLP","creator_url":"https://huggingface.co/nlp-thedeep","description":"HumSet is a novel and rich multilingual dataset of humanitarian response documents annotated by experts in the humanitarian response community. HumSet is curated by humanitarian analysts and covers various disasters around the globe that occurred from 2018 to 2021 in 46 humanitarian response projects. The dataset consists of approximately 17K annotated documents in three languages of English, French, and Spanish, originally taken from publicly-available resources. For each document, analysts have identified informative snippets (entries) in respect to common humanitarian frameworks, and assigned one or many classes to each entry. See the our paper for details."},
  {"name":"wikipedia-22-12-es-embeddings","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-es-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikipedia (es) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded Wikipedia (es) using the cohere.ai multilingual-22-12 embedding model.\\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEmbeddings\\n\\t\\n\\nWe compute for title+\\\" \\\"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-es-embeddings."},
  {"name":"operations","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nlpservicebots/operations","creator_name":"David Pe√±a","creator_url":"https://huggingface.co/nlpservicebots","description":"nlpservicebots/operations dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"xstory_cloze","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/juletxara/xstory_cloze","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","description":"XStoryCloze consists of the professionally translated version of the [English StoryCloze dataset](https://cs.rochester.edu/nlp/rocstories/) (Spring 2016 version) to 10 non-English languages. This dataset is released by Meta AI."},
  {"name":"miracl-es-corpus-22-12","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Cohere/miracl-es-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (es) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-es-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-es-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-es-corpus-22-12."},
  {"name":"miracl-es-queries-22-12","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Cohere/miracl-es-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (es) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-es-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-es-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-es-queries-22-12."},
  {"name":"MultiLegalPileWikipediaFiltered","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPileWikipediaFiltered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles."},
  {"name":"pwesuite-eval","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zouharvi/pwesuite-eval","creator_name":"Vil√©m Zouhar","creator_url":"https://huggingface.co/zouharvi","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tPWESuite-Eval\\n\\t\\n\\nDataset composed of multiple smaller datasets used for the evaluation of phonetic word embeddings.\\nSee code for evaluation here.\\nIf you use this dataset/evaluation, please cite the paper at LREC-COLING 2024:\\n@inproceedings{zouhar-etal-2024-pwesuite,\\n    title = \\\"{PWES}uite: Phonetic Word Embeddings and Tasks They Facilitate\\\",\\n    author = \\\"Zouhar, Vil{\\\\'e}m  and\\n      Chang, Kalvin  and\\n      Cui, Chenxuan  and\\n      Carlson, Nate B.  and\\n      Robinson, Nathaniel‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/pwesuite-eval."},
  {"name":"mconala","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/neulab/mconala","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"MCoNaLa is a Multilingual Code/Natural Language Challenge dataset with \\n896 NL-Code pairs in three languages: Spanish, Japanese, and Russian."},
  {"name":"petro-tweets","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jhonparra18/petro-tweets","creator_name":"Jhon Parra","creator_url":"https://huggingface.co/jhonparra18","description":"jhonparra18/petro-tweets dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"SpanishBFF","keyword":"spanish","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/MMG/SpanishBFF","creator_name":"dezzai","creator_url":"https://huggingface.co/MMG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nSpanish-BFF is the first Spanish AI-generated dictionary using GPT3.\\n\\nPaper: Spanish Built Factual Freectianary (Spanish-BFF): the first IA-generated free dictionary\\nPoint of Contact: oscar.garcia@dezzai.com , alfonso.ardoiz@dezzai.com\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpanish-BFF contains a total of 66353 lemmas with its definitions (only one definiton per lemma).\\nThese lemmas correspond to nominal, adjetival, verbal and adverbial classes.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MMG/SpanishBFF."},
  {"name":"uy22","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/pln-udelar/uy22","creator_name":"NLP Group, UdelaR, Uruguay","creator_url":"https://huggingface.co/pln-udelar","description":"pln-udelar/uy22 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"gutenberg_multilang","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/sedthh/gutenberg_multilang","creator_name":"Richard Nagyfi","creator_url":"https://huggingface.co/sedthh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Project Gutenber - Multilanguage eBooks\\n\\t\\n\\nA collection of non-english language eBooks (7907, about 75-80% of all the ES, DE, FR, NL, IT, PT, HU books available on the site) from the Project Gutenberg site with metadata removed. \\nOriginally colected for https://github.com/LAION-AI/Open-Assistant\\n\\n\\t\\n\\t\\t\\nLANG\\nEBOOKS\\n\\n\\n\\t\\t\\nES\\n717\\n\\n\\nDE\\n1735\\n\\n\\nFR\\n2863\\n\\n\\nNL\\n904\\n\\n\\nIT\\n692\\n\\n\\nPT\\n501\\n\\n\\nHU\\n495\\n\\n\\n\\t\\n\\nThe METADATA column contains catalogue meta information on each book as a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sedthh/gutenberg_multilang."},
  {"name":"human_assistant_conversation","keyword":"spanish","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/Isotonic/human_assistant_conversation","creator_name":"Isotonic","creator_url":"https://huggingface.co/Isotonic","description":"Isotonic/human_assistant_conversation dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"ikitracs-qa","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/alessio-vertemati/ikitracs-qa","creator_name":"Alessio Vertemati","creator_url":"https://huggingface.co/alessio-vertemati","description":"This dataset is curated by GIZ Data Service Center in the form of Sqaud dataset with features question, answer, answer_start, context and language.\\nThe source dataset for this comes from Changing Transport Tracker,\\nwhere partners analyze Intended nationally determined contribution (INDC), NDC and Revised/Updated NDC of countries to understand transport related climate mitigation actions.\\nSpecifications\\n\\nDataset size: 3194\\nLanguage: English, Spanish, French\\n\\n"},
  {"name":"spanish-chinese","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Deysi/spanish-chinese","creator_name":"Caraballo","creator_url":"https://huggingface.co/Deysi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"spanish-chinese\\\"\\n\\t\\n\\nAll sensences extracted from the United Nations Parallel Corpus v1.0.\\nThe parallel corpus consists of manually translated United Nations documents for the six\\nofficial UN languages, Arabic, Chinese, English, French, Russian, and Spanish.\\nThe corpus is freely available for download at https://conferences.unite.un.org/UNCorpus\\nunder the terms of use outlined in the attached DISCLAIMER.\\nThe original individual documents are available at the United‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Deysi/spanish-chinese."},
  {"name":"spanish-chinese","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Deysi/spanish-chinese","creator_name":"Caraballo","creator_url":"https://huggingface.co/Deysi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"spanish-chinese\\\"\\n\\t\\n\\nAll sensences extracted from the United Nations Parallel Corpus v1.0.\\nThe parallel corpus consists of manually translated United Nations documents for the six\\nofficial UN languages, Arabic, Chinese, English, French, Russian, and Spanish.\\nThe corpus is freely available for download at https://conferences.unite.un.org/UNCorpus\\nunder the terms of use outlined in the attached DISCLAIMER.\\nThe original individual documents are available at the United‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Deysi/spanish-chinese."},
  {"name":"Ald_Mexican_Spanish_speech_dataset","keyword":"spanish","license":"The Unlicense","language":"en","url":"https://huggingface.co/datasets/rmcpantoja/Ald_Mexican_Spanish_speech_dataset","creator_name":"Rene Mateo Cedillo Pantoja","creator_url":"https://huggingface.co/rmcpantoja","description":"This dataset can be used to fine-tune Speech To Text models as Text To Speech.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdataset information\\n\\t\\n\\n\\nSpeaker: Aldo\\nDataset size: 535 audio files\\naudio duration of 4-15 seconds (1:33:15)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset structure\\n\\t\\n\\nThis dataset has been structured in the LJSpeech format:\\n\\nwavs/\\n1.wav\\n2.wav\\n3.wav\\n\\n\\n535.wav\\n\\n\\ntranscript.csv\\n\\n"},
  {"name":"CelebA_Sent2Vect_Sp","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/oeg/CelebA_Sent2Vect_Sp","creator_name":"Ontology Engineering Group","creator_url":"https://huggingface.co/oeg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpus Summary\\n\\t\\n\\nThis corpus has 192050 entries made up of descriptive sentences of the faces of the CelebA dataset.\\nThe preprocessing of the corpus has been to translate into Spanish the captions of the CelebA dataset with the algorithm used in Text2FaceGAN. \\nIn particular, all sentences are combined to generate a larger corpus. Additionally, a data preprocessing was applied that consists of eliminating stopwords, separation symbols and complementary elements that are not useful‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oeg/CelebA_Sent2Vect_Sp."},
  {"name":"CelebA_Sent2Vect_Sp","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/oeg/CelebA_Sent2Vect_Sp","creator_name":"Ontology Engineering Group","creator_url":"https://huggingface.co/oeg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpus Summary\\n\\t\\n\\nThis corpus has 192050 entries made up of descriptive sentences of the faces of the CelebA dataset.\\nThe preprocessing of the corpus has been to translate into Spanish the captions of the CelebA dataset with the algorithm used in Text2FaceGAN. \\nIn particular, all sentences are combined to generate a larger corpus. Additionally, a data preprocessing was applied that consists of eliminating stopwords, separation symbols and complementary elements that are not useful‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oeg/CelebA_Sent2Vect_Sp."},
  {"name":"CelebA_RoBERTa_Sp","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/oeg/CelebA_RoBERTa_Sp","creator_name":"Ontology Engineering Group","creator_url":"https://huggingface.co/oeg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpus Summary\\n\\t\\n\\nThis corpus contains 250000 entries made up of a pair of sentences in Spanish and their respective similarity value in the range 0 to 1. This corpus was used in the training of the \\nsentence-transformer library to improve the efficiency of the RoBERTa-large-bne base model.\\nEach of the pairs of sentences are textual descriptions of the faces of the CelebA dataset, which were previously translated into Spanish. The process followed to generate it was:\\n\\nFirst, a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oeg/CelebA_RoBERTa_Sp."},
  {"name":"CelebA_RoBERTa_Sp","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/oeg/CelebA_RoBERTa_Sp","creator_name":"Ontology Engineering Group","creator_url":"https://huggingface.co/oeg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpus Summary\\n\\t\\n\\nThis corpus contains 250000 entries made up of a pair of sentences in Spanish and their respective similarity value in the range 0 to 1. This corpus was used in the training of the \\nsentence-transformer library to improve the efficiency of the RoBERTa-large-bne base model.\\nEach of the pairs of sentences are textual descriptions of the faces of the CelebA dataset, which were previously translated into Spanish. The process followed to generate it was:\\n\\nFirst, a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oeg/CelebA_RoBERTa_Sp."},
  {"name":"Fact-Completion","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion","creator_name":"Polyglot-or-Not","creator_url":"https://huggingface.co/Polyglot-or-Not","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\nHomepage: https://bit.ly/ischool-berkeley-capstone\\nRepository: https://github.com/daniel-furman/Capstone\\nPoint of Contact: daniel_furman@berkeley.edu\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the dataset for Polyglot or Not?: Measuring Multilingual Encyclopedic Knowledge Retrieval from Foundation Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTest Description\\n\\t\\n\\n Given a factual association such as The capital of France is Paris, we determine whether a model adequately \\\"knows\\\" this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion."},
  {"name":"lingnli-multi-mt","keyword":"spanish","license":"BSD 2-Clause \"Simplified\" License","language":"en","url":"https://huggingface.co/datasets/maximoss/lingnli-multi-mt","creator_name":"Maximos Skandalis","creator_url":"https://huggingface.co/maximoss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis repository contains a collection of machine translations of LingNLI dataset \\ninto 9 different languages (Bulgarian, Finnish, French, Greek, Italian, Korean, Lithuanian, Portuguese, Spanish). The goal is to predict textual entailment (does sentence A \\nimply/contradict/neither sentence B), which is a classification task (given two sentences, \\npredict one of three labels). It is here formatted in the same manner as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maximoss/lingnli-multi-mt."},
  {"name":"letras-carnaval-cadiz","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/IES-Rafael-Alberti/letras-carnaval-cadiz","creator_name":"IES Rafael Alberti","creator_url":"https://huggingface.co/IES-Rafael-Alberti","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Letras Carnaval C√°diz\\n\\t\\n\\n\\n\\n    \\n        English |\\n        Espa√±ol\\n    \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChangelog\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nRelease\\nDescription\\n\\n\\n\\t\\t\\nv1.0\\nInitial release of the dataset. Included more than 1K lyrics. It is necessary to verify the accuracy of the data, especially the subset midaccurate.\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a comprehensive collection of lyrics from the Carnaval de C√°diz, a significant cultural heritage of the city of C√°diz, Spain. Despite‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IES-Rafael-Alberti/letras-carnaval-cadiz."},
  {"name":"DiagTrast","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/somosnlp-hackathon-2023/DiagTrast","creator_name":"Hackathon Somos NLP 2023: Los LLMs hablan Espa√±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2023","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"DiagTrast\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTable of Content\\n\\t\\n\\n\\nTable of Contents\\nDataset Description\\nDataset Summary\\nSupported Tasks and Leaderboards\\nLanguages\\n\\n\\nDataset Structure\\nData Instances\\nData Fields\\nData Splits\\n\\n\\nDataset Creation\\nCuration Rationale\\nSource Data\\nAnnotations\\n\\n\\nConsiderations for Using the Data\\nSocial Impact of Dataset\\nDiscussion of Biases\\nOther Known Limitations\\n\\n\\nTeam members\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFor the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2023/DiagTrast."},
  {"name":"informes_discriminacion_gitana","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/somosnlp-hackathon-2023/informes_discriminacion_gitana","creator_name":"Hackathon Somos NLP 2023: Los LLMs hablan Espa√±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2023","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tResumen del dataset\\n\\t\\n\\nSe trata de un dataset en espa√±ol, extra√≠do del centro de documentaci√≥n de la Fundaci√≥n Secretariado Gitano, en el que se presentan distintas situaciones discriminatorias acontecidas por el pueblo gitano. Puesto que el objetivo del modelo es crear un sistema de generaci√≥n de actuaciones que permita minimizar el impacto de una situaci√≥n discriminatoria, se hizo un scrappeo y se extrajeron todos los PDFs que contuvieron casos de discriminaci√≥n con el formato‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2023/informes_discriminacion_gitana."},
  {"name":"suicide-comments-es","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/somosnlp-hackathon-2023/suicide-comments-es","creator_name":"Hackathon Somos NLP 2023: Los LLMs hablan Espa√±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2023","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset consists of comments on Reddit, Twitter, and inputs/outputs of the Alpaca dataset translated to Spanish language and classified as suicidal ideation/behavior and non-suicidal.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset has 10050 rows (777 considered as Suicidal Ideation/Behavior and 9273 considered Not Suicidal).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset fields\\n\\t\\n\\n\\nText: User comment.\\nLabel: 1 if suicidal ideation/behavior; 0 if not suicidal comment.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2023/suicide-comments-es."},
  {"name":"podcasts-ner-es","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/somosnlp-hackathon-2023/podcasts-ner-es","creator_name":"Hackathon Somos NLP 2023: Los LLMs hablan Espa√±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2023","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"podcasts-ner-es\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset comprises of small text snippets extracted from the \\\"Deforme Semanal\\\" podcast,\\naccompanied by annotations that identify the presence of a predetermined set of entities.\\nThe purpose of this dataset is to facilitate Named Entity Recognition (NER) tasks.\\nThe dataset was created to aid in the identification of entities such as famous people, books, or films in podcasts.\\nThe transcription of the audio was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2023/podcasts-ner-es."},
  {"name":"Habilidades_Agente_v1","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/somosnlp-hackathon-2023/Habilidades_Agente_v1","creator_name":"Hackathon Somos NLP 2023: Los LLMs hablan Espa√±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2023","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nEspa√±ol:\\nPresentamos un conjunto de datos que presenta tres partes principales:\\n1. Dataset sobre habilidades blandas.\\n2. Dataset de conversaciones empresariales entre agentes y clientes. \\n3. Dataset curado de Alpaca en espa√±ol: Este dataset toma como base el dataset https://huggingface.co/datasets/somosnlp/somos-alpaca-es,\\ny fue curado con la herramienta Argilla, alcanzando 9400 registros curados.\\n\\nLos datos est√°n estructurados en torno a un m√©todo que se describe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2023/Habilidades_Agente_v1."},
  {"name":"human_assistant_conversation_deduped","keyword":"spanish","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/Isotonic/human_assistant_conversation_deduped","creator_name":"Isotonic","creator_url":"https://huggingface.co/Isotonic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDeduplicated version of Isotonic/human_assistant_conversation\\n\\t\\n\\n\\nDeduped with max jaccard similarity of 0.75\\n\\n"},
  {"name":"spinetta","keyword":"spanish","license":"Artistic License 2.0","language":"en","url":"https://huggingface.co/datasets/santifiorino/spinetta","creator_name":"Santiago Fiorino","creator_url":"https://huggingface.co/santifiorino","description":"Samples de ~10-15 segundos de Luis Alberto Spinetta cantando.\\nLimpio, sin instrumentos y sin silencios.\\nCanciones de Pescado Rabioso, Almendra, Invisible y como solista.\\n"},
  {"name":"spinetta","keyword":"spanish","license":"Artistic License 2.0","language":"en","url":"https://huggingface.co/datasets/santifiorino/spinetta","creator_name":"Santiago Fiorino","creator_url":"https://huggingface.co/santifiorino","description":"Samples de ~10-15 segundos de Luis Alberto Spinetta cantando.\\nLimpio, sin instrumentos y sin silencios.\\nCanciones de Pescado Rabioso, Almendra, Invisible y como solista.\\n"},
  {"name":"winogrande_train_s_spanish","keyword":"spanish","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/somosnlp-hackathon-2023/winogrande_train_s_spanish","creator_name":"Hackathon Somos NLP 2023: Los LLMs hablan Espa√±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2023","description":"This is the Spanish version of Winogrande Small (640 instances) for training only.\\nThe translation was done manually by a group of experts. The dataset will still be improved in the future.\\nwe also acknowledge Somos-NLP for this achievement.\\n"},
  {"name":"oasst1-es","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dariolopez/oasst1-es","creator_name":"Dario Lopez Padial","creator_url":"https://huggingface.co/dariolopez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Spanish Dataset (OASST1-es)\\n\\t\\n\\nSubset of the original OpenAssistant Conversations Dataset (OASST) filtered by lang=es.\\n"},
  {"name":"gpt-j-oasst1-es","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dariolopez/gpt-j-oasst1-es","creator_name":"Dario Lopez Padial","creator_url":"https://huggingface.co/dariolopez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Spanish Dataset (OASST1-es) for GPT-j\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSubset of the original OpenAssistant Conversations Dataset (OASST).\\n\\nFiltered by lang=es.\\nFormatted according to the \\\"instruction - output\\\" pattern.\\nSelect the best ranked output (Some instructions have multiple outputs ranked by humans).\\nSelect only the first level of the tree conversation.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset has 3909 rows of tuples (instructions and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dariolopez/gpt-j-oasst1-es."},
  {"name":"LoLLMS-Open-Community-discussions","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ParisNeo/LoLLMS-Open-Community-discussions","creator_name":"Saifeddine ALOUI","creator_url":"https://huggingface.co/ParisNeo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GPT4All-Community-Discussions\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains ethically gathered discussions from the community, who shared their experiences with various open source discussion models using the GPT4All-ui tool. The dataset is open for any use, including commercial use, as long as proper citation is given to acknowledge the contributions of the community. \\nThe GPT4All-ui tool allows users to have conversations with various open source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ParisNeo/LoLLMS-Open-Community-discussions."},
  {"name":"recetas-cocina","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Frorozcol/recetas-cocina","creator_name":"Fredy Alberto Orozco Loaiza","creator_url":"https://huggingface.co/Frorozcol","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tResumen del dataset\\n\\t\\n\\nSe trata de un dataset de recetas de comidas en espa√±ol. Se hizo un scrapy de diferentes p√°ginas de internet sobre recetas de comidas que estuvieran en espa√±ol, se logr√≥ extraer alrededor de 30 k valores, que se dividen en train, test y valid.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTareas admitidas y tablas de clasificaci√≥n\\n\\t\\n\\ntask-generation: Dado los ingredientes, generar la receta.\\nIdioma\\nEs un dataset que cuenta con un espa√±ol de diferentes partes del mundo, especial de latino‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Frorozcol/recetas-cocina."},
  {"name":"iva_mt_wslot-exp","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/cartesinus/iva_mt_wslot-exp","creator_name":"Marcin Sowanski","creator_url":"https://huggingface.co/cartesinus","description":""},
  {"name":"ms-marco-es","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dariolopez/ms-marco-es","creator_name":"Dario Lopez Padial","creator_url":"https://huggingface.co/dariolopez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"ms-marco-es\\\"\\n\\t\\n\\nQA asymmetric Spanish dataset filtered from multilingual version of MS Marco\\nimport datasets\\n\\n\\nms_marco_es = datasets.load_dataset('unicamp-dl/mmarco', name='spanish', split='train')\\nms_marco_es.push_to_hub(\\\"dariolopez/ms-marco-es\\\", token=os.environ['hg_token'])\\n\\n"},
  {"name":"ms-marco-es-500k","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dariolopez/ms-marco-es-500k","creator_name":"Dario Lopez Padial","creator_url":"https://huggingface.co/dariolopez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"ms-marco-es-500k\\\"\\n\\t\\n\\nQA asymmetric Spanish dataset filtered from multilingual version of MS Marco and sampled on 500k rows.\\nimport datasets\\n\\n\\nms_marco_es = datasets.load_dataset('unicamp-dl/mmarco', name='spanish', split='train')\\nms_marco_es.select(range(500_000)).push_to_hub(\\\"dariolopez/ms-marco-es-500k\\\", token=os.environ['hg_token'])\\n\\n"},
  {"name":"ShareGPT-Processed","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/zetavg/ShareGPT-Processed","creator_name":"Pokai Chang","creator_url":"https://huggingface.co/zetavg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShareGPT-Processed\\n\\t\\n\\nThe RyokoAI/ShareGPT52K dataset, converted to Markdown and labeled with the language used.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgements\\n\\t\\n\\n\\nvinta/pangu.js ‚Äî To insert whitespace between CJK (Chinese, Japanese, Korean) and half-width characters (alphabetical letters, numerical digits and symbols).\\nmatthewwithanm/python-markdownify ‚Äî Provides a starting point to convert HTML to Markdown.\\nBYVoid/OpenCC ‚Äî Conversions between Traditional Chinese and Simplified Chinese.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zetavg/ShareGPT-Processed."},
  {"name":"xOA22","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sambanovasystems/xOA22","creator_name":"SambaNova Systems","creator_url":"https://huggingface.co/sambanovasystems","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xOA22 - Multilingual Prompts from OpenAssistant\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nxOA22 consists of 22 prompts originally shown in Appendix E, page 25 of the OpenAssistant Conversations paper. These 22 prompts were then manually translated by volunteers into 5 languages: Arabic, Simplified Chinese, French, Hindi and Spanish. \\nThese prompts were originally created for human evaluations of the multilingual abilities of BLOOMChat. Since not all prompts could be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sambanovasystems/xOA22."},
  {"name":"x-self-instruct-seed-32","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sambanovasystems/x-self-instruct-seed-32","creator_name":"SambaNova Systems","creator_url":"https://huggingface.co/sambanovasystems","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xOA22 - Multilingual Prompts from OpenAssistant\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nx-self-instruct-seed-32 consists of 32 prompts chosen out of the 252 prompts in the self-instruct-seed dataset from the Self-Instruct paper. These 32 prompts were filtered out according to the following criteria:\\n\\nShould be natural in a chat setting\\nTherefore, we filter out any prompts with \\\"few-shot examples\\\", as these are all instruction prompts that we consider unnatural in a chat‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sambanovasystems/x-self-instruct-seed-32."},
  {"name":"rsd-ists-2016","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016","creator_name":"University of Zurich, Department of Computational Linguistics","creator_url":"https://huggingface.co/ZurichNLP","description":"Training and test data for the task of Recognizing Semantic Differences (RSD).\\nSee the paper for details on how the dataset was created, and see our code at https://github.com/ZurichNLP/recognizing-semantic-differences for an example of how to use the data for evaluation.\\nThe data are derived from the SemEval-2016 Task 2 for Interpretable Semantic Textual Similarity organized by Agirre et al. (2016).\\nThe original URLs of the data are:\\n\\nTrain:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016."},
  {"name":"es2bash","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dev2bit/es2bash","creator_name":"dev2bit","creator_url":"https://huggingface.co/dev2bit","description":"This dataset consisting of natural language requests (in Spanish) and the bash command that resolves it."},
  {"name":"prueba","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/nicosalama/prueba","creator_name":"Nicol√°s Salama","creator_url":"https://huggingface.co/nicosalama","description":"nicosalama/prueba dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"instruct-aira-dataset","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset","creator_name":"Nicholas Kluge Corr√™a","creator_url":"https://huggingface.co/nicholasKluge","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInstruct-Aira Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains a collection of prompts and responses to those prompts. All completions were generated by querying already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc.). The dataset is available in Portuguese, English, and Spanish.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:\\n\\nLanguage modeling.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset."},
  {"name":"python-pb","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/iarejula/python-pb","creator_name":"√ç√±igo ar√©jula a√≠sa","creator_url":"https://huggingface.co/iarejula","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHola\\n\\t\\n\\n"},
  {"name":"REDFM","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Babelscape/REDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\\\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\\nFirst, we present SRED\\\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \\nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \\nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\\\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}."},
  {"name":"SREDFM","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Babelscape/SREDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\\\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\\nFirst, we present SRED\\\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \\nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \\nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\\\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}."},
  {"name":"flores_101","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
  {"name":"livingner1","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/IIC/livingner1","creator_name":"Instituto de Ingenier√≠a del Conocimiento","creator_url":"https://huggingface.co/IIC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLivingNER\\n\\t\\n\\nThis is a third party reupload of the LivingNER task 1 dataset.\\nIt only contains the task 1 for the Spanish language. It does not include the multilingual data nor the background data.\\nThis dataset is part of a benchmark in the paper A comparative analysis of Spanish Clinical encoder-based models on NER and classification tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n@article{10.1093/jamia/ocae054,\\n    author = {Garc√≠a Subies, Guillem and Barbero Jim√©nez, √Ålvaro and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IIC/livingner1."},
  {"name":"livingner1","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/IIC/livingner1","creator_name":"Instituto de Ingenier√≠a del Conocimiento","creator_url":"https://huggingface.co/IIC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLivingNER\\n\\t\\n\\nThis is a third party reupload of the LivingNER task 1 dataset.\\nIt only contains the task 1 for the Spanish language. It does not include the multilingual data nor the background data.\\nThis dataset is part of a benchmark in the paper A comparative analysis of Spanish Clinical encoder-based models on NER and classification tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n@article{10.1093/jamia/ocae054,\\n    author = {Garc√≠a Subies, Guillem and Barbero Jim√©nez, √Ålvaro and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IIC/livingner1."},
  {"name":"livingner3","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/IIC/livingner3","creator_name":"Instituto de Ingenier√≠a del Conocimiento","creator_url":"https://huggingface.co/IIC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLivingNER\\n\\t\\n\\nThis is a third party reupload of the LivingNER task 3 dataset.\\nIt only contains the task 3 for the Spanish language. It does not include the multilingual data nor the background data.\\nThis dataset is part of a benchmark in the paper A comparative analysis of Spanish Clinical encoder-based models on NER and classification tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n@article{10.1093/jamia/ocae054,\\n    author = {Garc√≠a Subies, Guillem and Barbero Jim√©nez, √Ålvaro and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IIC/livingner3."},
  {"name":"livingner3","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/IIC/livingner3","creator_name":"Instituto de Ingenier√≠a del Conocimiento","creator_url":"https://huggingface.co/IIC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLivingNER\\n\\t\\n\\nThis is a third party reupload of the LivingNER task 3 dataset.\\nIt only contains the task 3 for the Spanish language. It does not include the multilingual data nor the background data.\\nThis dataset is part of a benchmark in the paper A comparative analysis of Spanish Clinical encoder-based models on NER and classification tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n@article{10.1093/jamia/ocae054,\\n    author = {Garc√≠a Subies, Guillem and Barbero Jim√©nez, √Ålvaro and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IIC/livingner3."},
  {"name":"socialdisner","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/IIC/socialdisner","creator_name":"Instituto de Ingenier√≠a del Conocimiento","creator_url":"https://huggingface.co/IIC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSocialDisNER\\n\\t\\n\\nThis is a third party reupload of the SocialDisNER dataset.\\nThis dataset is part of a benchmark in the paper A comparative analysis of Spanish Clinical encoder-based models on NER and classification tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n@article{10.1093/jamia/ocae054,\\n    author = {Garc√≠a Subies, Guillem and Barbero Jim√©nez, √Ålvaro and Mart√≠nez Fern√°ndez, Paloma},\\n    title = {A comparative analysis of Spanish Clinical encoder-based models on NER and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IIC/socialdisner."},
  {"name":"socialdisner","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/IIC/socialdisner","creator_name":"Instituto de Ingenier√≠a del Conocimiento","creator_url":"https://huggingface.co/IIC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSocialDisNER\\n\\t\\n\\nThis is a third party reupload of the SocialDisNER dataset.\\nThis dataset is part of a benchmark in the paper A comparative analysis of Spanish Clinical encoder-based models on NER and classification tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n@article{10.1093/jamia/ocae054,\\n    author = {Garc√≠a Subies, Guillem and Barbero Jim√©nez, √Ålvaro and Mart√≠nez Fern√°ndez, Paloma},\\n    title = {A comparative analysis of Spanish Clinical encoder-based models on NER and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IIC/socialdisner."},
  {"name":"demo-salaries","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Einstellung/demo-salaries","creator_name":"David Jimenez Melo","creator_url":"https://huggingface.co/Einstellung","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBriefly summarize the dataset, its intended use and the supported tasks. Give an overview of how and why the dataset was created. The summary should explicitly mention the languages present in the dataset (possibly in broad terms, e.g. translations between several pairs of European languages), and describe the domain, topic, or genre covered.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nFor each of the tasks tagged for this dataset, give a brief description of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Einstellung/demo-salaries."},
  {"name":"calls_10k_v1","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CICLAB-Comillas/calls_10k_v1","creator_name":"CICLAB Comillas ICAI","creator_url":"https://huggingface.co/CICLAB-Comillas","description":"CICLAB-Comillas/calls_10k_v1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"all-scam-spam","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\\n1040 rows of balanced data, consisting of casual conversations and scam emails in ‚âà10 languages, were manually collected and annotated by me, with some help from ChatGPT.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSome preprcoessing algorithms\\n\\t\\n\\n\\nspam_assassin.js, followed by spam_assassin.py\\nenron_spam.py\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData composition\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam."},
  {"name":"xP3x-sample","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities."},
  {"name":"policy_qa_v0_1","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/GIZ/policy_qa_v0_1","creator_name":"Deutsche Gesellschaft f√ºr internationale Zusammenarbeit","creator_url":"https://huggingface.co/GIZ","description":"This dataset is curated by GIZ Data Service Center. The source dataset for this\\ncomes from Internal GIZ team (IKI_Tracs) and Climatewatchdata,\\nwhere Climatewatch has analysed Intended nationally determined contribution (INDC), NDC and Revised/Updated NDC of the countries to answer some important questions related to Climate change.\\nSpecifications\\n\\nDataset size: ~85k\\nLanguage: English, French, Spanish\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nindex (type:int): Unique Response ID\\nResponseText (type:str):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GIZ/policy_qa_v0_1."},
  {"name":"malicious-website-features-2.4M","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"Important Notice:\\n\\nA subset of the URL dataset is from Kaggle, and the Kaggle datasets contained 10%-15% mislabelled data. See this dicussion I opened for some false positives. I have contacted Kaggle regarding their erroneous \\\"Usability\\\" score calculation for these unreliable datasets.\\nThe feature extraction methods shown here are not robust at all in 2023, and there're even silly mistakes in 3 functions: not_indexed_by_google, domain_registration_length, and age_of_domain.\\n\\n\\n\\nThe features‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M."},
  {"name":"blbooks-parquet","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/biglam/blbooks-parquet","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for British Library Books\\n\\t\\n\\nThis dataset is the same as https://huggingface.co/datasets/TheBritishLibrary/blbooks, however, this version is stored as parquet to avoid needing to run a datasets script. This also makes loading this dataset much quicker. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of books digitised by the British Library in partnership with Microsoft. The dataset includes ~25 million pages of out of copyright texts. The majority of the texts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/blbooks-parquet."},
  {"name":"blbooks-parquet-embedded","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/davanstrien/blbooks-parquet-embedded","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"blbooks-parquet-embedded\\\"\\n\\t\\n\\nMore Information needed\\n"},
  {"name":"professor_heideltime_en","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hugosousa/professor_heideltime_en","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProfessor HeidelTime\\n\\t\\n\\n\\n\\nProfessor HeidelTime is a project to create a multilingual corpus weakly labeled with HeidelTime, a temporal tagger.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpus Details\\n\\t\\n\\nThe weak labeling was performed in six languages. Here are the specifics of the corpus for each language:\\n\\n\\t\\n\\t\\t\\nDataset\\nLanguage\\nDocuments\\nFrom\\nTo\\nTokens\\nTimexs\\n\\n\\n\\t\\t\\nAll the News 2.0\\nEN\\n24,642\\n2016-01-01\\n2020-04-02\\n18,755,616\\n254,803\\n\\n\\nItalian Crime News\\nIT\\n9,619\\n2011-01-01\\n2021-12-31\\n3,296,898\\n58,823\\n\\n\\nGerman‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hugosousa/professor_heideltime_en."},
  {"name":"ggml-vicuna-v0-quantized","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","description":"These are quantized ggml binary files for vicuna 7B and 13B models. The version of vicuna for these models are v0.\\nThese files can be used in conjunction with minigpt4 ggml models 7B and 13B in minigpt4.cpp\\nRecommended are the Q5_K and Q6_K implementations. If there are any issues, use Q4_1 or Q4_0.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVicuna Model Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel details\\n\\t\\n\\nModel type:\\nVicuna is an open-source chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT.\\nIt is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized."},
  {"name":"MMLU_Spanish","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/MMLU_Spanish","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"Spanish version of MMLU dataset tranlasted by gpt-3.5-turbo.The dataset is used in the research related to MultilingualSIFT. \\n"},
  {"name":"LibriSpeech-Synthesizer-TTS","keyword":"spanish","license":"The Unlicense","language":"en","url":"https://huggingface.co/datasets/rmcpantoja/LibriSpeech-Synthesizer-TTS","creator_name":"Rene Mateo Cedillo Pantoja","creator_url":"https://huggingface.co/rmcpantoja","description":"rmcpantoja/LibriSpeech-Synthesizer-TTS dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"LibriSpeech-Synthesizer-TTS","keyword":"spanish","license":"The Unlicense","language":"en","url":"https://huggingface.co/datasets/rmcpantoja/LibriSpeech-Synthesizer-TTS","creator_name":"Rene Mateo Cedillo Pantoja","creator_url":"https://huggingface.co/rmcpantoja","description":"rmcpantoja/LibriSpeech-Synthesizer-TTS dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"test_llm_dataset","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/youssefoud/test_llm_dataset","creator_name":"Youssef Oudghiri","creator_url":"https://huggingface.co/youssefoud","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Card for Mixtral-8x7B\\n\\t\\n\\nThe Mixtral-8x7B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts. The Mixtral-8x7B outperforms Llama 2 70B on most benchmarks we tested.\\nFor full details of this model please read our release blog post.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWarning\\n\\t\\n\\nThis repo contains weights that are compatible with vLLM serving of the model as well as Hugging Face transformers library. It is based on the original Mixtral torrent release, but the file format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/youssefoud/test_llm_dataset."},
  {"name":"ciempiess_light","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ciempiess/ciempiess_light","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ciempiess_light\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CIEMPIESS LIGHT is a Radio Corpus designed to create acoustic models for automatic speech recognition and it is made up by recordings of spontaneous conversations in Mexican Spanish between a radio moderator and his guests. It is an enhanced version of the CIEMPIESS Corpus (LDC item LDC2015S07).\\nCIEMPIESS LIGHT is \\\"light\\\" because it doesn't include much of the files of the first version of CIEMPIESS and it is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_light."},
  {"name":"ciempiess_light","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ciempiess/ciempiess_light","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ciempiess_light\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CIEMPIESS LIGHT is a Radio Corpus designed to create acoustic models for automatic speech recognition and it is made up by recordings of spontaneous conversations in Mexican Spanish between a radio moderator and his guests. It is an enhanced version of the CIEMPIESS Corpus (LDC item LDC2015S07).\\nCIEMPIESS LIGHT is \\\"light\\\" because it doesn't include much of the files of the first version of CIEMPIESS and it is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_light."},
  {"name":"ciempiess_balance","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ciempiess/ciempiess_balance","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ciempiess_balance\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CIEMPIESS BALANCE Corpus is designed to match with the CIEMPIESS LIGHT Corpus (LDC2017S23). So, \\\"Balance\\\" means that if the CIEMPIESS BALANCE is combined with the CIEMPIESS LIGHT, one will get a gender balanced corpus. To appreciate this, one need to know that the CIEMPIESS LIGHT is by itself, a gender unbalanced corpus of approximately 25% of female speakers and 75% of male speakers. So, the CIEMPIESS BALANCE‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_balance."},
  {"name":"ciempiess_balance","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ciempiess/ciempiess_balance","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ciempiess_balance\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CIEMPIESS BALANCE Corpus is designed to match with the CIEMPIESS LIGHT Corpus (LDC2017S23). So, \\\"Balance\\\" means that if the CIEMPIESS BALANCE is combined with the CIEMPIESS LIGHT, one will get a gender balanced corpus. To appreciate this, one need to know that the CIEMPIESS LIGHT is by itself, a gender unbalanced corpus of approximately 25% of female speakers and 75% of male speakers. So, the CIEMPIESS BALANCE‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_balance."},
  {"name":"ciempiess_fem","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ciempiess/ciempiess_fem","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ciempiess_fem\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSince the publication of the CIEMPIESS Corpus (LDC2015S07) in 2015 we have noticed that there is a lack of female speakers in the sources where we traditionally take audio to create new CIEMPIESS datasets. That is why we decided to create a corpus that helps to balance future gender unbalanced datasets.\\nThe CIEMPIESS FEM Corpus was created by recordings and human transcripts of 21 different women. 16 of these women‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_fem."},
  {"name":"ciempiess_fem","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ciempiess/ciempiess_fem","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ciempiess_fem\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSince the publication of the CIEMPIESS Corpus (LDC2015S07) in 2015 we have noticed that there is a lack of female speakers in the sources where we traditionally take audio to create new CIEMPIESS datasets. That is why we decided to create a corpus that helps to balance future gender unbalanced datasets.\\nThe CIEMPIESS FEM Corpus was created by recordings and human transcripts of 21 different women. 16 of these women‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_fem."},
  {"name":"ciempiess_complementary","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ciempiess/ciempiess_complementary","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ciempiess_complementary\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CIEMPIESS COMPLEMENTARY is a phonetically balanced corpus of isolated Spanish words spoken by people of Central Mexico. It was designed to solve one particular issue when training automatic speech recognition (ASR) systems in the Spanish of Central Mexico. This problem appears when someone collects some training data, but the system complains because it does not find enough instances of one or more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_complementary."},
  {"name":"ciempiess_complementary","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ciempiess/ciempiess_complementary","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ciempiess_complementary\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CIEMPIESS COMPLEMENTARY is a phonetically balanced corpus of isolated Spanish words spoken by people of Central Mexico. It was designed to solve one particular issue when training automatic speech recognition (ASR) systems in the Spanish of Central Mexico. This problem appears when someone collects some training data, but the system complains because it does not find enough instances of one or more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_complementary."},
  {"name":"openassistant-guanaco-unfiltered","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Fredithefish/openassistant-guanaco-unfiltered","creator_name":"Fredi","creator_url":"https://huggingface.co/Fredithefish","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGuanaco-Unfiltered\\n\\t\\n\\n\\nAny language other than English, German, French, or Spanish has been removed.\\nRefusals of assistance have been removed.\\nThe identification as OpenAssistant has been removed.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2 is out\\n\\t\\n\\n\\nIdentification as OpenAssistant is now fully removed\\nother improvements\\n\\n"},
  {"name":"CCOpenBooks","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Daniel-P-Gonzalez/CCOpenBooks","creator_name":"Daniel Gonzalez","creator_url":"https://huggingface.co/Daniel-P-Gonzalez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CC OpenBooks\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n CC OpenBooks is a curated collection of high quality non-fiction books. All texts are from CC-By-4.0 sources, with no license ambiguity.\\nThe documents are normalized to markdown, and care is taken to ensure most formatting (e.g. inline LaTeX) remains intact. Files are manually inspected and cleaned of all defects wherever possible.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\nThe following Openstax collections were used in creating‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Daniel-P-Gonzalez/CCOpenBooks."},
  {"name":"borges","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/adleme94/borges","creator_name":"Alberto L√≥pez","creator_url":"https://huggingface.co/adleme94","description":"adleme94/borges dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"RyokoAI_ShareGPT52K","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/botp/RyokoAI_ShareGPT52K","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ShareGPT52K90K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a collection of approximately 52,00090,000 conversations scraped via the ShareGPT API before it was shut down.\\nThese conversations include both user prompts and responses from OpenAI's ChatGPT.\\nThis repository now contains the new 90K conversations version. The previous 52K may\\nbe found in the old/ directory.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntext-generation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/botp/RyokoAI_ShareGPT52K."},
  {"name":"poemas","keyword":"spanish","license":"GNU Lesser General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/mapama247/poemas","creator_name":"Marc P√†mies","creator_url":"https://huggingface.co/mapama247","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpanish poems for GPT finetuning\\n\\t\\n\\nCollection of Spanish poems from www.poemas-del-alma.com.\\n"},
  {"name":"Llama-2-oasst1-es","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dariolopez/Llama-2-oasst1-es","creator_name":"Dario Lopez Padial","creator_url":"https://huggingface.co/dariolopez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Spanish Dataset (OASST1-es) for Llama-2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSubset of the original OpenAssistant Conversations Dataset (OASST).\\n\\nFiltered by lang=es.\\nFormatted according to the Llama-2 pattern: \\\"<s> [INST] user prompt [/INST] output model </s>\\\"\\nSelect the best ranked output (Some instructions had multiple outputs ranked by humans).\\nSelect only the first level of the tree conversation.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset has 3909‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dariolopez/Llama-2-oasst1-es."},
  {"name":"wikianc","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc."},
  {"name":"entity_cs","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EntityCS\\n\\t\\n\\n\\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \\nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \\nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \\nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs."},
  {"name":"HRECPW-Hispanic_Responses_for_Emotional_Classification_based_on_Plutchik_Wheel","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/BrunoGR/HRECPW-Hispanic_Responses_for_Emotional_Classification_based_on_Plutchik_Wheel","creator_name":"Bruno Gil Ramirez","creator_url":"https://huggingface.co/BrunoGR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHRECPW Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe HRECPW (Hispanic Responses for Emotional Classification based on Plutchik Wheel) dataset is designed for training models in the task of emotional classification. This dataset allows models to identify and classify various emotional categories based on the Plutchik wheel, with a particular focus on the Spanish language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Origin\\n\\t\\n\\nThe HRECPW dataset was compiled from multiple sources, including social media‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BrunoGR/HRECPW-Hispanic_Responses_for_Emotional_Classification_based_on_Plutchik_Wheel."},
  {"name":"dstc11.t4","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/mario-rc/dstc11.t4","creator_name":"Mario Rodr√≠guez-Cantelar","creator_url":"https://huggingface.co/mario-rc","description":"\\n\\t\\n\\t\\t\\n\\t\\tDSTC11: Dialogue System Technology Challenge 11Track 4: Robust and Multilingual Automatic Evaluation Metrics for Open-Domain Dialogue Systems\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDirectory Structure Scheme\\n\\t\\n\\nRepresentation of the directory tree structure:\\n.\\n‚îî‚îÄ‚îÄ DSTC_11_Track_4             # DSTC11 data\\n    ‚îú‚îÄ‚îÄ task1                   # Multilingual metrics data\\n    ‚îÇ       ‚îú‚îÄ‚îÄ train           # Train data (CHANEL/CDIAL datasets)\\n    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ en_es       # English/Spanish data\\n    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ en_zh‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mario-rc/dstc11.t4."},
  {"name":"text_coordinates_seasons","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/yachay/text_coordinates_seasons","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Geo-Tagged Social Media Posts with Timestamps\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Seasons\\\" dataset is a collection of over 600,000 social media posts spanning 12 months and encompassing 15 distinct time zones. It focuses on six countries: Cuba, Iran, Russia, North Korea, Syria, and Venezuela, with each post containing textual content, timestamps, and geographical coordinates. The dataset's primary objective is to investigate the correlation between the timing of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_seasons."},
  {"name":"text_coordinates_regions","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Regions\\\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\\nKey Features:\\n\\nTextual Data: The dataset contains 500,000 text samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions."},
  {"name":"thesis-chile","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/vgaraujov/thesis-chile","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThesis Chile Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThesis Chile is the dataset partially used to create the DiscoEval in Spanish benchmark. \\nThis dataset was created by scraping titles and abstracts of Chilean thesis from public repositories of the Pontificia Universidad Catolica de Chile (repositorio.uc.cl), Universidad de Chile (repositorio.uchile.cl) and Universidad T√©cnica Federico Santa Mar√≠a (biblioteca.usm.cl).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\nWe see the potential utility‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/thesis-chile."},
  {"name":"MultiCoNER","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/tomaarsen/MultiCoNER","creator_name":"Tom Aarsen","creator_url":"https://huggingface.co/tomaarsen","description":"We present MultiCoNER, a large multilingual dataset for Named Entity Recognition that covers 3 domains (Wiki sentences, questions, and search queries) across 11 languages, as well as multilingual and code-mixing subsets. This dataset is designed to represent contemporary challenges in NER, including low-context scenarios (short and uncased text), syntactically complex entities like movie titles, and long-tail entity distributions. The 26M token dataset is compiled from public resources using techniques such as heuristic-based sentence sampling, template extraction and slotting, and machine translation. We applied two NER models on our dataset: a baseline XLM-RoBERTa model, and a state-of-the-art GEMNET model that leverages gazetteers. The baseline achieves moderate performance (macro-F1=54%), highlighting the difficulty of our data. GEMNET, which uses gazetteers, improvement significantly (average improvement of macro-F1=+30%). MultiCoNER poses challenges even for large pre-trained language models, and we believe that it can help further research in building robust NER systems. MultiCoNER is publicly available at https://registry.opendata.aws/multiconer/ and we hope that this resource will help advance research in various aspects of NER."},
  {"name":"openassistant-guanaco-EOS","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Guanaco Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using \\\"### Human:\\\" AND \\\"### Assistant\\\" as the beginning and end of sequence tokens.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then slightly adjusted to:\\n\\n\\nif a row of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS."},
  {"name":"sharegpt-deduplicated","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated","creator_name":"Caterina Lacerra","creator_url":"https://huggingface.co/CaterinaLac","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a deduplicated version of sharegpt4. \\nThe deduplication process has two steps:\\n\\nThe literal duplicates (both input and outputs) are removed\\nThe remaining (5749) instances are embedded with the SentenceTransformer library (\\\"paraphrase-multilingual-mpnet-base-v2\\\" model).\\nThen, we compute the cosine similarity among all the possible pairs, and consider paraphrases those‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated."},
  {"name":"openassistant-llama-style","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Llama 2 Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then filtered to:\\n\\n\\nreplace instances of '### Human:' with '[INST]'\\nreplace‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style."},
  {"name":"spanish-suicide-intent","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PrevenIA/spanish-suicide-intent","creator_name":"PrevenIA","creator_url":"https://huggingface.co/PrevenIA","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset consists of comments from several sources translated to Spanish language and classified as suicidal ideation/behavior and non-suicidal.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset has 175010 rows (77223 considered as Suicidal Ideation/Behavior and 97787 considered Not Suicidal).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset fields\\n\\t\\n\\n\\nText: User comment.\\nLabel: 1 if suicidal ideation/behavior; 0 if not suicidal comment.\\nDataset: Source of the comment\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PrevenIA/spanish-suicide-intent."},
  {"name":"EusExams","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/HiTZ/EusExams","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EusExams\\n\\t\\n\\nEusExams is a collection of tests designed to prepare individuals for Public Service examinations conducted by several Basque institutions, including the public health system Osakidetza, the Basque Government, the City Councils of Bilbao and Gasteiz, and the University of the Basque Country (UPV/EHU). Within each of these groups, there are different exams for public positions, such as administrative and assistant roles. Each multiple-choice question‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/EusExams."},
  {"name":"mqnli","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SachinPatel248/mqnli","creator_name":"Patel","creator_url":"https://huggingface.co/SachinPatel248","description":"SachinPatel248/mqnli dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Secop2_documents","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Santp98/Secop2_documents","creator_name":"santiago prado","creator_url":"https://huggingface.co/Santp98","description":"Santp98/Secop2_documents dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"MSVAMP","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Mathoctopus/MSVAMP","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","description":"Mathoctopus/MSVAMP dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Multi-EuP","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/unimelb-nlp/Multi-EuP","creator_name":"The University of Melbourne","creator_url":"https://huggingface.co/unimelb-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNOTES FOR DOWNLOAD!\\n\\t\\n\\n\\nHighly recommend downloading it via the API:\\n\\ncurl -X GET \\\\\\n     \\\"https://datasets-server.huggingface.co/first-rows?dataset=unimelb-nlp%2FMulti-EuP&config=default&split=full\\\"\\n\\n\\nIf you are using the HuggingFace library, please follow these steps:\\n\\npip install datasets\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"unimelb-nlp/Multi-EuP\\\", keep_default_na=False)\\n\\nNote: It's crucial to use keep_default_na=False because some datasets contain 'null'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unimelb-nlp/Multi-EuP."},
  {"name":"DRAL","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jonavila/DRAL","creator_name":"Jonathan Avila","creator_url":"https://huggingface.co/jonavila","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDialogs Re-enacted Across Languages (DRAL) corpus\\n\\t\\n\\nDRAL is a bilingual speech corpus of parallel utterances, using recorded conversations and fragments re-enacted in a different language. It is intended as a resource for research, especially for training and evaluating speech-to-speech translation models and systems. We dedicate this corpus to the public domain; there is no copyright (CC 0).\\nDRAL is described in a new technical report: Dialogs Re-enacted Across Languages, Version‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jonavila/DRAL."},
  {"name":"HEAR-Hispanic_Emotional_Accompaniment_Responses","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/BrunoGR/HEAR-Hispanic_Emotional_Accompaniment_Responses","creator_name":"Bruno Gil Ramirez","creator_url":"https://huggingface.co/BrunoGR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHEAR Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe HEAR (Hispanic Emotional Accompaniment Responses) dataset is designed to train language models in the task of emotionally accompanying users. This dataset enables models to generate empathetic and appropriate responses in Spanish, understanding and responding to different emotional situations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Origin\\n\\t\\n\\nThe HEAR dataset was created using elements from the HRECPW dataset, which contains 11 emotional categories with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BrunoGR/HEAR-Hispanic_Emotional_Accompaniment_Responses."},
  {"name":"software_benchmark_v2","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/oeg/software_benchmark_v2","creator_name":"Ontology Engineering Group","creator_url":"https://huggingface.co/oeg","description":"The corpus have been built using two corpora in software mentions.\\n\\nSoMESCi [1]. We have used the corpus uploaded to Github, more specifically, the corpus created with sentences.\\nSoftcite [2]. This project has published another corpus for software mentions, which is also available on Github. We have used the annotations from bio and economics domain.\\nPapers with code. We have downloaded a list of publications from the Papers with Code site. You can find there publications and software from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oeg/software_benchmark_v2."},
  {"name":"guanaco-spanish-dataset","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/hlhdatscience/guanaco-spanish-dataset","creator_name":"H√©ctor L√≥pez Hidalgo","creator_url":"https://huggingface.co/hlhdatscience","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"guanaco-spanish-dataset\\\"\\n\\t\\n\\nCLEANING AND CURATION OF THE DATASET HAS BEEN PERFORMED. NOW IT IS FULLY IN SPANISH (Date:12/01/2024)\\nThis dataset is a subset of original timdettmers/openassistant-guanaco,which is also a subset o/f the Open Assistant dataset .You can find here: https://huggingface.co/datasets/OpenAssistant/oasst1/tree/main/\\nThis subset of the data only contains the highest-rated paths in the conversation tree, with a total of 2,369 samples, translated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hlhdatscience/guanaco-spanish-dataset."},
  {"name":"udhr-lid","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUDHR-LID\\n\\t\\n\\nWhy UDHR-LID?\\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \\\"missing\\\" or \\\"?\\\". Also, about 1/3 of the sentences consist only of \\\"articles 1-30\\\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid."},
  {"name":"WEATHub","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/iamshnoo/WEATHub","creator_name":"Anjishnu Mukherjee","creator_url":"https://huggingface.co/iamshnoo","description":"\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"WEATHub\\\"\\n\\t\\n\\nThis dataset corresponds to the data described in the paper \\\"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\\\"\\naccepted to EMNLP 2023.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)\\nto measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub."},
  {"name":"Twitter-COVID-19","keyword":"spanish","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/citiusLTL/Twitter-COVID-19","creator_name":"CiTIUS Language Technologies Lab","creator_url":"https://huggingface.co/citiusLTL","description":"General description:\\nThis dataset comprisses a set of tweets crawled during the COVID-19 pandemic (from March 2020 to June 2021). Tweets are located in two different regions: Spain and USA. This adds value to the collection, as it contains data in two languages.\\nThis data was used as part of a broader study that aimed to determine the evolution of different personality traits and disorders during the pandemic. Thus, weak labels for different dimensions, such as sentiment, personality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/citiusLTL/Twitter-COVID-19."},
  {"name":"openassistant-falcon","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant Falcon\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using '\\\\Human:' AND '\\\\nAssistant:' to wrap user messages.\\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\\nSample \\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon."},
  {"name":"chilean_touristic_data","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/RaulSalinasHerr/chilean_touristic_data","creator_name":"Raul Salinas","creator_url":"https://huggingface.co/RaulSalinasHerr","description":"RaulSalinasHerr/chilean_touristic_data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Multilingual-Opinion-Target-Extraction","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HiTZ/Multilingual-Opinion-Target-Extraction","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"This repository contains the English 'SemEval-2014 Task 4: Aspect Based Sentiment Analysis'. translated with DeepL into Spanish, French, Russian, and Turkish. The labels have been manually projected. For more details, read this paper:  Model and Data Transfer for Cross-Lingual Sequence Labelling in Zero-Resource Settings. \\nIntended Usage: Since the datasets are parallel across languages, they are ideal for evaluating annotation projection algorithms, such as T-Projection. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLabel‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/Multilingual-Opinion-Target-Extraction."},
  {"name":"mapa-eur-lex","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/dglover1/mapa-eur-lex","creator_name":"D Glover","creator_url":"https://huggingface.co/dglover1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a completed version of the MAPA EUR-LEX dataset, originally converted to Huggingface format by joelniklaus. See the dataset card for more information about MAPA.\\n3 of the (Spanish) EUR-LEX WebAnno TSV files in the source MAPA repository are malformed, so they were omitted from the original conversion, causing under-representation of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dglover1/mapa-eur-lex."},
  {"name":"lr-sum","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LR-Sum\\n\\t\\n\\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \\nThe data is based on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum."},
  {"name":"megawika-report-generation","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika for Report Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. \\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation."},
  {"name":"preguntas-respuestas-RAG","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/hythyt/preguntas-respuestas-RAG","creator_name":"hyt","creator_url":"https://huggingface.co/hythyt","description":"hythyt/preguntas-respuestas-RAG dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"ProfessorHeidelTime","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hugosousa/ProfessorHeidelTime","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProfessor HeidelTime\\n\\t\\n\\nPaper    GitHub\\nProfessor HeidelTime is a project to create a multilingual corpus weakly labeled with HeidelTime, a temporal tagger.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpus Details\\n\\t\\n\\nThe weak labeling was performed in six languages. Here are the specifics of the corpus for each language:\\n\\n\\t\\n\\t\\t\\nDataset\\nLanguage\\nDocuments\\nFrom\\nTo\\nTokens\\nTimexs\\n\\n\\n\\t\\t\\nAll the News 2.0\\nEN\\n24,642\\n2016-01-01\\n2020-04-02\\n18,755,616\\n254,803\\n\\n\\nItalian Crime News\\nIT\\n9,619\\n2011-01-01\\n2021-12-31\\n3,296,898\\n58‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hugosousa/ProfessorHeidelTime."},
  {"name":"llama2-unsaac","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/vanesa1221/llama2-unsaac","creator_name":"Vanesa Lavilla","creator_url":"https://huggingface.co/vanesa1221","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n"},
  {"name":"punta-cana-spanish-reviews","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/beltrewilton/punta-cana-spanish-reviews","creator_name":"Wilton Beltre","creator_url":"https://huggingface.co/beltrewilton","description":"This data set was collected for academic purposes, suitable for some NLP tasks including sentiment analysis.\\n"},
  {"name":"menuwriter_alimentos_dt_1.2k","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Isaac45/menuwriter_alimentos_dt_1.2k","creator_name":"Isaac Solis","creator_url":"https://huggingface.co/Isaac45","description":"Isaac45/menuwriter_alimentos_dt_1.2k dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"chico_prompts_generate_story","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/snats/chico_prompts_generate_story","creator_name":"snats","creator_url":"https://huggingface.co/snats","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThis dataset provides around 8,000 prompts in Spanish about short stories.\\nThe following is the prompt in english:\\nprompt:\\nWrite a short story based on the following title:\\n{{titles}}\\n\\ncompletion:\\n{{contents}}\\n\\nIn spanish:\\nprompt:\\nEscribe una historia corta basada en el siguiente t√≠tulo {{titles}}\\n\\ncompletion:\\n{{contents}}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMore Information\\n\\t\\n\\nThis dataset is a sub-version of the original chico dataset.\\n"},
  {"name":"chico_prompts_suggest_title","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/snats/chico_prompts_suggest_title","creator_name":"snats","creator_url":"https://huggingface.co/snats","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThis dataset provides around 8,000 prompts in Spanish to suggest titles from snippets of short stories.\\nThe following is the prompt in english:\\nprompt:\\nSuggest a title for the following story:\\n{{contents}}\\n\\ncompletion:\\nSure, here's a suitable title for the given story {{titles}}.\\n\\nIn spanish:\\nprompt:\\nSugiere un t√≠tulo para la siguiente historia: {{contents}}\\n\\ncompletion:\\nUn t√≠tulo posible para la siguiente historia podr√≠a ser: {{titles}}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/snats/chico_prompts_suggest_title."},
  {"name":"retrieval_qa","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lnwang/retrieval_qa","creator_name":"Luning Wang","creator_url":"https://huggingface.co/lnwang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRetrieval_QA: A Simple Multilingual Benchmark For Retrieval Encoder Models\\n\\t\\n\\n\\n\\nThe purpose of this dataset is to provide a simple and easy-to-use benchmark for retrieval encoder models, which helps researchers quickly select the most effective retrieval encoder for text extraction and achieve optimal results in subsequent retrieval tasks such as retrieval-augmented-generation (RAG). The dataset contains multiple document-question pairs, where each document is a short text about‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lnwang/retrieval_qa."},
  {"name":"reciclauto","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/RyuBcn/reciclauto","creator_name":"Ryu de Miac","creator_url":"https://huggingface.co/RyuBcn","description":"RyuBcn/reciclauto dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"google-chilean-spanish","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ylacombe/google-chilean-spanish","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tamil Speech\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of 7 hours of transcribed high-quality audio of Chilean Spanish sentences recorded by 31 volunteers. The dataset is intended for speech technologies. \\nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\ntext-to-speech, text-to-audio: The dataset can be used to train a model for Text-To-Speech (TTS).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/google-chilean-spanish."},
  {"name":"Pontoon-Translations","keyword":"spanish","license":"Mozilla Public License 2.0","language":"en","url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations."},
  {"name":"multilingual_qa","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/crodri/multilingual_qa","creator_name":"Carlos Rodr√≠guez","creator_url":"https://huggingface.co/crodri","description":"Multilingual instructional dataset for extractive QA finetunning for Catalan, Spanish and English, using SQAD, SQAC, CatalanQA and COQCAT datasets.\\nContains almost 55K questions, answers and contexts, with development and train splits.\\n"},
  {"name":"cszs_es_en","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ky552/cszs_es_en","creator_name":"speech552_ky","creator_url":"https://huggingface.co/ky552","description":"This dataset contains the Spanish-English track of the benchmark from ICASSP 2024: Zero Resource Code-Switched Speech Benchmark Using Speech Utterance Pairs for Multiple Spoken Languages.Though the benchmark is originally designed to assess the semantic and syntactic abilities of the speech foundation models, you can also use this dataset for code-switching ASR.\\nIf you find this dataset helpful, please consider to cite the following paper:\\n@INPROCEEDINGS{10446737,\\n  author={Huang, Kuan-Po and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ky552/cszs_es_en."},
  {"name":"SemEval2024-STR","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/kietnt0603/SemEval2024-STR","creator_name":"Nguy·ªÖn Tu·∫•n Ki·ªát","creator_url":"https://huggingface.co/kietnt0603","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nEach instance in the training, development, and test sets is a sentence pair. The instance is labeled with a score representing the degree of semantic textual relatedness between the two sentences. The scores can range from 0 (maximally unrelated) to 1 (maximally related). These gold label scores have been determined through manual annotation. Specifically, a comparative annotation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kietnt0603/SemEval2024-STR."},
  {"name":"BOGDANKOZLOV1","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/leoarias12/BOGDANKOZLOV1","creator_name":"Leo Arias","creator_url":"https://huggingface.co/leoarias12","description":"leoarias12/BOGDANKOZLOV1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"mswc_fscil_subset","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset","creator_name":"NeuroBench","creator_url":"https://huggingface.co/NeuroBench","description":"This is a subset of the Multilingual Spoken Word Corpus dataset, which is built specifically for the Few-shot Class-incremental Learning (FSCIL) task. \\nA total of 15 languages are chosen, split into 5 base languages (English, German, Catalan, French, Kinyarwanda) and 10 incrementally learned languages (Persian, Spanish, Russian, Welsh, Italian, Basque, Polish, Esparanto, Portuguese, Dutch).\\nThe FSCIL task entails first training a model using abundant training data on words from the 5 base‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset."},
  {"name":"ntx_llm_instructions","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format\\n\\t\\n\\nThis dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license and conditions.\\nIt contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you utilize this dataset version, feel free to cite/footnote this huggingface dataset repo, but please also cite the original dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions."},
  {"name":"ntx_llm_inst_spanish","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_spanish","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format - Spanish subset\\n\\t\\n\\nThis dataset is a format conversion for the Spanish data from the original NTX into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nFor the original NTX dataset, the conversion to the Aya instructions format, or more details, please refer to the full dataset in instruction form (https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions) or to the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_spanish."},
  {"name":"ml-kge","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/davanstrien/ml-kge","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMKGE: Multilingual Knowledge Graph Enhancement\\n\\t\\n\\nnote this dataset card was copied from this GitHub Repository\\nTask Description |\\nWikiKGE-10 |\\nEvaluation |\\nPaper |\\nCitation |\\nLicense\\nRecent work in Natural Language Processing and Computer Vision has been leveraging textual information -- e.g., entity names and descriptions -- available in knowledge graphs to ground neural models to high-quality structured data.\\nHowever, when it comes to non-English languages, both quantity and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davanstrien/ml-kge."},
  {"name":"oasst_top1_es","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/dbuos/oasst_top1_es","creator_name":"Daniel Bustamante Ospina","creator_url":"https://huggingface.co/dbuos","description":"OpenAssistant TOP-1 Conversation Threads\\nGuanacco style export of the best conversation threads from the open-assistant.io database\\nexported August 25, 2023\\njsonl files with chatml formatted conversations\\ntrain: 4,295 samples\\nOnly Spanish examples\\nAdd colum to count number of messages\\n\\n"},
  {"name":"es.wiktionary.org","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/carloscapote/es.wiktionary.org","creator_name":"Carlos Capote","creator_url":"https://huggingface.co/carloscapote","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpanish Wiktionary\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMotivation\\n\\t\\n\\nMultilingual datasets based in Wikimedia Foundation's Wiktionary tend to use its translation system to fetch non English words, what causes a lot of words and definitions being discarded.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDevelopment\\n\\t\\n\\nIn order to solve this, I wrote a custom parser that obtains the definitions straight from a dump of the Spanish Wiktionary. Both the parser and the dataset will be developed in harmony.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStage\\n\\t\\n\\nBoth the parser‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carloscapote/es.wiktionary.org."},
  {"name":"InstrucatQA","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/BSC-LT/InstrucatQA","creator_name":"Language Technologies Unit @ Barcelona Supercomputing Center","creator_url":"https://huggingface.co/BSC-LT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nInstructional dataset to finetune models used for RAG applications\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a merge from QA instructions from InstruCAT (ca), SQUAC (es), SQUAD (en), plus generalists CA and ES MENTOR datasets to provide a cognitive background for generating responses.\\nContains splits of 66139 (train) and 11674  (validation) instructions\\n\\nCurated by: [More Information Needed]\\nFunded by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BSC-LT/InstrucatQA."},
  {"name":"prompt_injections","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/yanismiraoui/prompt_injections","creator_name":"Yanis Miraoui","creator_url":"https://huggingface.co/yanismiraoui","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Prompt Injections by  Yanis Miraoui  üëã\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset of prompt injections enriches Large Language Models (LLMs) by providing task-specific examples and prompts, helping improve LLMs' performance and control their behavior.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains over 1000 rows of prompt injections in multiple languages. It contains examples of prompt injections using different techniques such as: prompt leaking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yanismiraoui/prompt_injections."},
  {"name":"WikidataLabels","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/rayliuca/WikidataLabels","creator_name":"Ray Liu","creator_url":"https://huggingface.co/rayliuca","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikidata Labels\\n\\t\\n\\nLarge parallel corpus for machine translation\\n\\nEntity label data extracted from Wikidata (2022-01-03), filtered for item entities only  \\nOnly download the languages you need with datasets>=2.14.0\\nSimilar dataset: https://huggingface.co/datasets/wmt/wikititles (18 Wikipedia titles pairs instead of all Wikidata entities)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nWikidata JSON dump (wikidata-20220103-all.json.gz)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rayliuca/WikidataLabels."},
  {"name":"oasst2_top1_chat_format","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\\n\\t\\n\\nExport of oasst2 only top 1 threads in huggingface chat format\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScript\\n\\t\\n\\nThe convert script can be find here\\n"},
  {"name":"language_tags","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"Fran√ßais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog convention‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags."},
  {"name":"linguistica_assist","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SiguienteGlobal/linguistica_assist","creator_name":"Siguiente","creator_url":"https://huggingface.co/SiguienteGlobal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SiguienteGlobal/linguistica_assist."},
  {"name":"oasst2_es","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/xaviviro/oasst2_es","creator_name":"Xavi","creator_url":"https://huggingface.co/xaviviro","description":"xaviviro/oasst2_es dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"oasst2_es_gpt","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/xaviviro/oasst2_es_gpt","creator_name":"Xavi","creator_url":"https://huggingface.co/xaviviro","description":"xaviviro/oasst2_es_gpt dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"databricks-dolly-15k-es","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/daqc/databricks-dolly-15k-es","creator_name":"David Quispe","creator_url":"https://huggingface.co/daqc","description":"Translated with googletrans==3.1.0a0 from original dataset\\n*part of the data (up to 600) was lost during the translation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlicense: apache-2.0\\n\\t\\n\\n"},
  {"name":"borges_plain_text_dataset","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lucasbiagettia/borges_plain_text_dataset","creator_name":"Lucas Biagetti","creator_url":"https://huggingface.co/lucasbiagettia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset: Borges en texto plano\\n\\t\\n\\nEl objetivo de este repositorio es construir un dataset del gran autor argentino que pueda usarse para el entrenamiento de modelos de lenguaje.\\nInicialmente part√≠ de libros en formato EPUB y √∫nicamente en espa√±ol\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCarpetas\\n\\t\\n\\nInicialmente planteo tres carpetas\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEpub\\n\\t\\n\\nLibros en este formato\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEpub_a_txt\\n\\t\\n\\nLibros convertidos con el sencillo script disponible en \\nhttps://github.com/lucasbiagettia/epub2txt‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lucasbiagettia/borges_plain_text_dataset."},
  {"name":"FEDERICO-GARCIA-LORCA-canciones-poemas-romances","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/xaviviro/FEDERICO-GARCIA-LORCA-canciones-poemas-romances","creator_name":"Xavi","creator_url":"https://huggingface.co/xaviviro","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFederico Garc√≠a Lorca. Canciones, Poemas y Romances\\n\\t\\n\\n"},
  {"name":"oaast_rm_full_jieba","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"Â∞ùËØïËß£ÂÜ≥\\\"llm repetition problem\\\"Ôºå‰ΩøÁî®ÂàÜËØçÊ®°ÂûãÂØπoaastËØ≠ÊñôËøõË°å‚ÄúÁªìÂ∑¥Âåñ‚ÄùÊï∞ÊçÆÂ¢ûÂº∫ÔºåÊèê‰æõÊõ¥Âº∫ÁöÑÈáçÂ§çÂÜÖÂÆπÊãíÁªùÊïàÊûú„ÄÇ\\nAttempts to solve the \\\"llm repetition problem\\\" by using a segmentation model to enhance the oaast corpus with \\\"stuttering\\\" data to provide stronger rejection of duplicate content.\\nÂÖ∂Ê¨°ÔºåËøòËøáÊª§Êéâ‰∫ÜÊâÄÊúâËá™ÊàëËÆ§Áü•ÁöÑÂæÆË∞ÉÊ†∑Êú¨„ÄÇ\\nSecond, it also filters out all the fine-tuned samples of self-cognition.\\nfiles:\\n\\noaast_rm_full_jieba.jsonl : word level repeat\\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\\n\\n"},
  {"name":"escagleu-64k","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/projecte-aina/escagleu-64k","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for escagleu-64K corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nescagleu-64k is a parallel corpus comprising 64091 sentences translated among Spanish, Catalan, Valencian Catalan, Galician, and Basque.\\nThe original sentences are in Spanish and come from the Spanish Common Voice Corpus.\\nWe prepared this corpus with the aim of creating a parallel speech dataset among these languages using the Common Voice platform between the frame of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/escagleu-64k."},
  {"name":"oasst2_dpo_pairs","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/alexredna/oasst2_dpo_pairs","creator_name":"Alexander Gruhl","creator_url":"https://huggingface.co/alexredna","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"oasst2_dpo_pairs\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nDataset transferred into the structure for trainig with DPO and can be used with the Alignment Handbook\\nThe structure follows mostly the same scheme as HuggingFaceH4/ultrafeedback_binarized\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nTo load the dataset, run:\\nfrom datasets import load_dataset\\n\\nds = load_dataset(\\\"alexredna/oasst2_dpo_pairs\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nBase dataset filtered to only contain: German, English, Spanish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexredna/oasst2_dpo_pairs."},
  {"name":"language-dataset","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","description":"\\n"},
  {"name":"seamless-align-expressive","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jhu-clsp/seamless-align-expressive","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Seamless-Align-Expressive (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was created based on metadata for mined expressive Speech-to-Speech(S2S) released by Meta AI.  The S2S contains data for 5 language pairs. The S2S dataset is ~228GB compressed.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to use the data\\n\\t\\n\\nThere are two ways to access the data:\\n\\nVia the Hugging Face Python datasets library\\n\\nScripts coming soon\\n\\n\\nClone the git repo\\n\\ngit‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align-expressive."},
  {"name":"Deltacorpus_1.1","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, Portoro≈æ, Slovenia).\\nChanges in version 1.1: \\n\\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \\n\\nSVM classifier trained on Universal Dependencies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1."},
  {"name":"MM-Eval","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/prometheus-eval/MM-Eval","creator_name":"prometheus-eval","creator_url":"https://huggingface.co/prometheus-eval","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Meta-EVALuation benchmark (MM-Eval)\\n\\t\\n\\n\\nüë®‚ÄçüíªCode\\n|\\nüìÑPaper\\n|\\nü§ó MMQA\\n\\n\\nMM-Eval is a multilingual meta-evaluation benchmark consisting of five core subsets‚ÄîChat, Reasoning, Safety, Language Hallucination, and Linguistics‚Äîspanning 18 languages and a Language Resource subset spanning 122 languages for a broader analysis of language effects. \\n\\nDesign ChoiceIn this work, we minimize the inclusion of translated samples, as mere translation may alter existing preferences due‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prometheus-eval/MM-Eval."},
  {"name":"cie-10","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/dmartingarcia/cie-10","creator_name":"david martin garcia","creator_url":"https://huggingface.co/dmartingarcia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset was collected from the eCIE10Maps page, from the Spanish government.\\nhttps://www.eciemaps.sanidad.gob.es/browser/metabuscador\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dmartingarcia/cie-10."},
  {"name":"Saka-Alpaca-v1","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Sakalti/Saka-Alpaca-v1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"https://chatgpt.com\\n"},
  {"name":"unal-repository-dataset-uris","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/JulianVelandia/unal-repository-dataset-uris","creator_name":"Juli√°n Camilo Velandia","creator_url":"https://huggingface.co/JulianVelandia","description":"T√≠tulo: URIs de Tesis del Repositorio UNALDescripci√≥n: Este dataset contiene 1908 URIs de tesis descargadas del repositorio de la Universidad Nacional de Colombia, con su estado de procesamiento. Todas las URIs est√°n marcadas como \\\"complete\\\", indicando que los PDFs asociados fueron procesados exitosamente.\\nColumnas:\\n\\nURI: Ruta √∫nica del PDF en el repositorio UNAL.\\nEstado: Estado del procesamiento (\\\"complete\\\", \\\"pending\\\" o \\\"error\\\").\\n\\nEjemplo:\\n\\n\\t\\n\\t\\t\\nURI\\nEstado‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JulianVelandia/unal-repository-dataset-uris."},
  {"name":"unal-repository-dataset-raw_dataset","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/JulianVelandia/unal-repository-dataset-raw_dataset","creator_name":"Juli√°n Camilo Velandia","creator_url":"https://huggingface.co/JulianVelandia","description":"T√≠tulo: Contenido de Tesis del Repositorio UNALDescripci√≥n: Este dataset contiene el texto extra√≠do de 1908 tesis descargadas del repositorio de la Universidad Nacional de Colombia. Cada entrada incluye la URI asociada al PDF y su contenido textual procesado.  \\nColumnas:\\n\\nURI: Ruta √∫nica del PDF en el repositorio UNAL.  \\nraw_content: Texto extra√≠do del PDF.\\n\\nEjemplo:\\n\\n\\t\\n\\t\\t\\nURI\\nraw_content\\n\\n\\n\\t\\t\\n/bitstream/handle/unal/84638/46386566.2023.pdf?sequence=2&isAllowed=y\\nIntroducci√≥n a los sistemas‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JulianVelandia/unal-repository-dataset-raw_dataset."},
  {"name":"linkedin-industry-list","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/fantastic-jobs/linkedin-industry-list","creator_name":"Fantastic.jobs","creator_url":"https://huggingface.co/fantastic-jobs","description":"fantastic-jobs/linkedin-industry-list dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"MMMLU","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLU‚Äôs test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU."},
  {"name":"MX-CHAT","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/berwart/MX-CHAT","creator_name":"Berwart","creator_url":"https://huggingface.co/berwart","description":"MX-CHAT 01\\n"},
  {"name":"virc","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/oeg/virc","creator_name":"Ontology Engineering Group","creator_url":"https://huggingface.co/oeg","description":"\\n\\t\\n\\t\\t\\n\\t\\tVulnerable Identities Recognition Corpus (VIRC) for Hate Speech Analysis\\n\\t\\n\\nWelcome to the Vulnerable Identities Recognition Corpus (VIRC), a dataset created to enhance hate speech analysis in Italian and Spanish news headlines. VIRC provides annotated headlines aimed at identifying vulnerable identities, dangerous discourse, derogatory mentions, and entities. This corpus contributes to developing more sophisticated hate speech detection tools and policies for creating a safer online‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oeg/virc."},
  {"name":"devops","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bichito69/devops","creator_name":"Dario Ag√ºero","creator_url":"https://huggingface.co/bichito69","description":"bichito69/devops dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"BenchMAX_Rule-based","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Rule-based is a dataset of BenchMAX, sourcing from IFEval, which is a rule-based benchmark for evaluating the instruction following capabilities.\\nWe extend the original dataset to 16 non-English languages by first translating and then manual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based."},
  {"name":"BenchMAX_Model-based","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Model-based is a dataset of BenchMAX, sourcing from m-ArenaHard.\\nWe extend the original English dataset to 16 non-English languages by first translating and then manual post-editing.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based."},
  {"name":"BenchMAX_Multiple_Functions","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Multiple_Functions is a dataset of BenchMAX, sourcing from Nexus.\\nWe translate the standardized queries from English to 16 non-English languages by google Translate.\\nSome special function arguments remain English since the APIs are in English.\\nAll‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions."},
  {"name":"BenchMAX_General_Translation","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_General_Translation is a dataset of BenchMAX.\\nWe collect parallel test data from Flore-200, TED-talk, and WMT24.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech, English, French, German, Hungarian, Japanese, Korean, Serbian, Spanish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation."},
  {"name":"BenchMAX_Domain_Translation","keyword":"spanish","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Domain_Translation is a dataset of BenchMAX.\\nWe collect the domain parallel data from other tasks in BenchMAX.\\nEach sample contains one or three human-annotated translations.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech, English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation."},
  {"name":"EusParallel","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HiTZ/EusParallel","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t[WorkInProgress] English, Spanish, Basque Document Level Parallel Corpus\\n\\t\\n\\nEusParallel is an English, Spanish, and Basque multi-parallel document-level corpus. The Basque documents have been written by humans, while the English and Spanish texts have been machine-translated from Basque using meta-llama/Meta-Llama-3-70B-Instruct. The corpus is intended to train high-quality machine translation models that can translate documents from English and Spanish into Basque.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/EusParallel."},
  {"name":"my-sql-commands","keyword":"spanish","license":"PostgreSQL License","language":"en","url":"https://huggingface.co/datasets/ddedaniel02/my-sql-commands","creator_name":"Daniel Moreno","creator_url":"https://huggingface.co/ddedaniel02","description":"ddedaniel02/my-sql-commands dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"unal-repository-dataset-train-instruct","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/JulianVelandia/unal-repository-dataset-train-instruct","creator_name":"Juli√°n Camilo Velandia","creator_url":"https://huggingface.co/JulianVelandia","description":"T√≠tulo: Grade Works UNAL Dataset Instruct Train (split 75/25)\\nDescripci√≥n: Split 75% del dataset original. \\nEste dataset contiene un formato estructurado de Pregunta: Respuesta generado a partir del contenido de los trabajos de grado del repositorio de la Universidad Nacional de Colombia. Cada registro incluye un fragmento del contenido del trabajo, una pregunta generada a partir de este y su respuesta correspondiente. Este dataset es ideal para tareas de fine-tuning en modelos de lenguaje‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JulianVelandia/unal-repository-dataset-train-instruct."},
  {"name":"3d-prompt","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Miguelpef/3d-prompt","creator_name":"Miguel","creator_url":"https://huggingface.co/Miguelpef","description":"Miguelpef/3d-prompt dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"multilingual-task-oriented-dialog","keyword":"spanish","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/edmdias/multilingual-task-oriented-dialog","creator_name":"Eduardo Dias","creator_url":"https://huggingface.co/edmdias","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Task-Oriented Dialog Data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDirectory structure\\n\\t\\n\\nThis dataset consists of 3 directories:\\n\\nen contains the English data\\nes contains the Spanish data\\nth contains the Thai data\\n\\nIn each directory, you'll find a file for each of the train/dev/test splits as used in our paper.\\n\\n\\t\\n\\t\\t\\n\\t\\tFile format\\n\\t\\n\\nPYTEXT parquet FORMAT\\nEach parquet file contains following 5 columns: intent label, the slot annotations in a comma-separated list with the format <start token>:<end‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/edmdias/multilingual-task-oriented-dialog."},
  {"name":"violence-and-conflict-events-in-colombia","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/3iS/violence-and-conflict-events-in-colombia","creator_name":"3iS","creator_url":"https://huggingface.co/3iS","description":"\\n\\t\\n\\t\\t\\n\\t\\tHumanitarian Dataset: Violence and IHL Violations in Colombia (2024)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains records of violence and infractions to international humanitarian law (IHL) in Colombia during 2024. The dataset was compiled by OCHA Colombia from reports by key informants and news sources. The data has been structured and categorized according to IHL standards, including the extraction of the number of victims and events.\\n\\n\\t\\n\\t\\t\\n\\t\\tContent\\n\\t\\n\\nThe dataset includes the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/3iS/violence-and-conflict-events-in-colombia."},
  {"name":"violence-and-conflict-events-in-colombia","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/3iS/violence-and-conflict-events-in-colombia","creator_name":"3iS","creator_url":"https://huggingface.co/3iS","description":"\\n\\t\\n\\t\\t\\n\\t\\tHumanitarian Dataset: Violence and IHL Violations in Colombia (2024)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains records of violence and infractions to international humanitarian law (IHL) in Colombia during 2024. The dataset was compiled by OCHA Colombia from reports by key informants and news sources. The data has been structured and categorized according to IHL standards, including the extraction of the number of victims and events.\\n\\n\\t\\n\\t\\t\\n\\t\\tContent\\n\\t\\n\\nThe dataset includes the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/3iS/violence-and-conflict-events-in-colombia."},
  {"name":"V1Q","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q."},
  {"name":"Roleplay-Oscuro-Sintetico_L3.2","keyword":"spanish","license":"Artistic License 2.0","language":"en","url":"https://huggingface.co/datasets/Novaciano/Roleplay-Oscuro-Sintetico_L3.2","creator_name":"Novaciano","creator_url":"https://huggingface.co/Novaciano","description":"\\n\\t\\n\\t\\t\\n\\t\\tRoleplay Oscuro Sint√©tico L3.2\\n\\t\\n\\nVersi√≥n en espa√±ol del dataset Synthetic_Dark_RP de ChaoticNeutrals. \\nEl mismo fue traducido y convertido al formato Llama 3.2.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCambios respecto a la versi√≥n en ingl√©s\\n\\t\\n\\nLa Habitaci√≥n Roja [The Red Room]\\n\\n\\\"The Red Room\\\" fue traducido a \\\"La Habitaci√≥n Roja\\\".\\nSe ha eliminado la linea que dice que el usuario es \\\"Araragi\\\".\\n\\\"Araragi\\\" fue reemplazado por {{user}}.\\n\\\"Usuario\\\" fue reemplazado por {{user}}.\\n\\\"Asistente\\\" fue reemplazado por {{char}}.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Novaciano/Roleplay-Oscuro-Sintetico_L3.2."},
  {"name":"PleIAs-ToxicCommons","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tPleIAs/ToxicCommons\\n\\t\\n\\nThis dataset is a refined version of the PleIAs/ToxicCommons collection, focusing on historical texts labeled for content that may be considered objectionable by modern standards (what the authors of the dataset deem \\\"toxic\\\"). \\nThe cleaned dataset contains 1‚Äâ051‚Äâ027 rows, each representing a text sample with associated toxicity scores across five dimensions:\\n\\nRace and origin-based bias\\nGender and sexuality-based bias\\nReligious bias\\nAbility bias\\nViolence and abuse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons."},
  {"name":"gn-humor-detection","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mmaguero/gn-humor-detection","creator_name":"Marvin M. Ag√ºero-Torales","creator_url":"https://huggingface.co/mmaguero","description":"\\n\\t\\n\\t\\t\\n\\t\\tText-based afective computing\\n\\t\\n\\nWe collected a dataset of tweets primarily written in Guarani (and Jopara, a code-switching language that combines Guarani and Spanish) and annotated them for three widely-used dimensions in sentiment analysis: \\n\\nemotion recognition (https://huggingface.co/datasets/mmaguero/gn-emotion-recognition),  \\nhumor detection (this repo, https://huggingface.co/datasets/mmaguero/gn-humor-detection), and\\noffensive language identification‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mmaguero/gn-humor-detection."},
  {"name":"MOL","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/franciellevargas/MOL","creator_name":"Francielle Vargas","creator_url":"https://huggingface.co/franciellevargas","description":"\\n\\t\\n\\t\\t\\n\\t\\tMOL - Context-Aware Multilingual Offensive Lexicon\\n\\t\\n\\nThe MOL is the first specialized lexicon for hate speech detection, annotated with contextual information.\\nIt consists of 1,000 explicit and implicit (clue-based) human-annotated rationales used with pejorative connotations, manually identified by a linguist and annotated by three experts regarding their contextual dependency (context-dependent or context-independent).\\nFor example, the term \\\"stupid\\\" is classified as a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/franciellevargas/MOL."},
  {"name":"FinOpsQuery","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/cjch1979/FinOpsQuery","creator_name":"carlos carreno","creator_url":"https://huggingface.co/cjch1979","description":"cjch1979/FinOpsQuery dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"multilingual_translation_gen_binarized","keyword":"spanish","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"gsm8k-translated","keyword":"spanish","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Sara237/gsm8k-translated","creator_name":"Sara Rajaee","creator_url":"https://huggingface.co/Sara237","description":"Sara237/gsm8k-translated dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Resident-Evil-Roleplay-ALPACA","keyword":"spanish","license":"Artistic License 2.0","language":"en","url":"https://huggingface.co/datasets/Novaciano/Resident-Evil-Roleplay-ALPACA","creator_name":"Novaciano","creator_url":"https://huggingface.co/Novaciano","description":"\\n\\n¬°Descubre el oscuro mundo de Resident Evil con nuestro exclusivo dataset!\\nSum√©rgete en la Era de Umbrella, donde los horrores de Raccoon City y los secretos de la corporaci√≥n m√°s temida del mundo cobran vida. Nuestro dataset abarca los eventos cruciales desde Resident Evil 1 hasta Resident Evil: Code Ver√≥nica, ofreciendo una rica colecci√≥n de datos que te permitir√° entrenar modelos de lenguaje (LLM) con un enfoque √∫nico en esta ic√≥nica saga de survival horror.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t¬øQu√© incluye este‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Novaciano/Resident-Evil-Roleplay-ALPACA."},
  {"name":"HPLT2.0_cleaned","keyword":"spanish","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned."}
];
