const data_for_language_asia_hindi = 
[
	{"name":"BRIGHTER-emotion-categories","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","description":"\n\t\n\t\t\n\t\tBRIGHTER Emotion Categories Dataset\n\t\n\nThis dataset contains the emotion categories data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe BRIGHTER Emotion Categories dataset is a comprehensive multi-language, multi-label emotion classification dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multipleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories.","first_N":5,"first_N_keywords":["Afrikaans","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-a","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track A Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track A, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 26 standard ISO codes\nTotal examples: 115159\nSplits: train, dev, test\n\n\n\t\n\t\t\n\t\tLanguage Configurations\n\t\n\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-c","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track C Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track C, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 30 standard ISO codes\nTotal examples: 57254\nSplits: dev, test (Track C has no train split)\n\n\n\t\n\t\t\n\t\tTrackâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"COMI-LINGUA","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LingoIITGN/COMI-LINGUA","creator_name":"Lingo Research Group","creator_url":"https://huggingface.co/LingoIITGN","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nCOMI-LINGUA (COde-MIxing and LINGuistic Insights on Natural Hinglish Usage and Annotation) is a high-quality Hindi-English code-mixed dataset, manually annotated by three annotators. It serves as a benchmark for multilingual NLP models by covering multiple foundational tasks.\nCOMI-LINGUA provides annotations for several key NLP tasks:\n\nLanguage Identification (LID): Token-wise classification of Hindi, English, and other linguistic units.\nInitial predictions wereâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LingoIITGN/COMI-LINGUA.","first_N":5,"first_N_keywords":["Hindi","English","cc-by-4.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"HinGE","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LingoIITGN/HinGE","creator_name":"Lingo Research Group","creator_url":"https://huggingface.co/LingoIITGN","description":"Abstract\n Text generation is a highly active area of research in the computational linguistic community. The evaluation of the generated text is a challenging task and multiple theories and metrics have been proposed over the years. Unfortunately, text generation and evaluation are relatively understudied due to the scarcity of high-quality resources in code-mixed languages where the words and phrases from multiple languages are mixed in a single utterance of text and speech. To address thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LingoIITGN/HinGE.","first_N":5,"first_N_keywords":["translation","Hindi","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"miracl-vision","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nvidia/miracl-vision","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","description":"\n\t\n\t\t\n\t\tMIRACL-VISION\n\t\n\nMIRACL-VISION is a multilingual visual retrieval dataset for 18 different languages. It is an extension of MIRACL, a popular text-only multilingual retrieval dataset. The dataset contains user questions, images of Wikipedia articles and annotations, which article can answer a user question. There are 7898 questions and 338734 images. More details can be found in the paper MIRACL-VISION: A Large, multilingual, visual document retrieval benchmark.\nThis dataset is readyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/miracl-vision.","first_N":5,"first_N_keywords":["document-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"MUSTARD","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/badrivishalk/MUSTARD","creator_name":"Badri Vishal Kasuba","creator_url":"https://huggingface.co/badrivishalk","description":"\n\t\n\t\t\n\t\tDataset Card for MUSTARD\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMUSTARD (Multilingual Scanned and Scene Table Structure Recognition Dataset) is a diverse dataset curated for table structure recognition across multiple languages. The dataset consists of tables extracted from magazines, including printed, scanned, and scene-text tables, labeled with Optimized Table Structure Language (OTSL) sequences. It is designed to facilitate research in multilingual tableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/badrivishalk/MUSTARD.","first_N":5,"first_N_keywords":["image-to-text","English","Hindi","Telugu","Tamil"],"keywords_longer_than_N":true},
	{"name":"IGB_XorQA","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IGB_XorQA","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"VarunGumma/IGB_XorQA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"entity_type_hi_pilener","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nis12ram/entity_type_hi_pilener","creator_name":"nishant choudhary","creator_url":"https://huggingface.co/nis12ram","description":"\n\t\n\t\t\n\t\tDataset Card for entity_type_hi_pilener\n\t\n\n\n\nentity_type_hi_pilener is a translated, filtered and corrected version of Pile-NER-type\n\n\t\n\t\t\n\t\t5 step processing on Pile-NER-type\n\t\n\n\nstep1: Removed all Entities whose source text is not in English using langdetect.\nstep2: Removed all Entity Type that are not in English using fast-langdetect.\nstep3: Translated all Entity Type to Hindi using indictrans2-en-indic-1B with greedy_sampling(num_beams=1, do_sample=False).\nstep4: Removed allâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nis12ram/entity_type_hi_pilener.","first_N":5,"first_N_keywords":["feature-extraction","Hindi","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"PhincBitextMining","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/PhincBitextMining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  PhincBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nPhinc is a parallel corpus for machine translation pairing code-mixed Hinglish (a fusion of Hindi and English commonly used in modern India) with human-generated English translations.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\nDomains\nSocial, Written\n\n\nReference\nhttps://huggingface.co/datasets/veezbo/phinc\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/PhincBitextMining.","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","English","Hindi"],"keywords_longer_than_N":true},
	{"name":"MIRACLRetrieval","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MIRACLRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MIRACLRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttp://miracl.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MIRACLRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","RSamoed/MIRACLRetrieval","Arabic"],"keywords_longer_than_N":true},
	{"name":"toxicity-multilingual-binary-classification-dataset","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/malexandersalazar/toxicity-multilingual-binary-classification-dataset","creator_name":"Alexander Salazar","creator_url":"https://huggingface.co/malexandersalazar","description":"This dataset is a comprehensive collection designed to aid in the development of robust and nuanced models for identifying toxic language across multiple languages, while critically distinguishing it from expressions related to mental health, specifically depression. It synthesizes content from three existing public datasets (ToxiGen, TextDetox, and Mental Health - Depression) with a newly generated synthetic dataset (ToxiLLaMA). The creation process involved careful collection, extensiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/malexandersalazar/toxicity-multilingual-binary-classification-dataset.","first_N":5,"first_N_keywords":["English","German","French","Italian","Portuguese"],"keywords_longer_than_N":true},
	{"name":"TinyDS-20k","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","description":"\n\t\n\t\t\n\t\tTinyDS\n\t\n\n\n\n\nAlpaca-style dataset with around 20k samples scraped from Qwen3-8B using SyntheticAlpaca. Q&A pairs can be in 32 different languages, these are listed in the metadata.Topics are all around STEM, programming, and literature.  \nMIT @ 2025 Hamzah Asadullah\n\n\n","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"multiblimp","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jumelet/multiblimp","creator_name":"Jaap Jumelet","creator_url":"https://huggingface.co/jumelet","description":"\n\t\n\t\t\n\t\tMultiBLiMP\n\t\n\nMultiBLiMP is a massively Multilingual Benchmark for Linguistic Minimal Pairs. The dataset is composed of synthetic pairs generated using Universal Dependencies and UniMorph.\nThe paper can be found here.\nWe split the data set by language: each language consists of a single .tsv file. The rows contain many attributes for a particular pair, most important are the sen and wrong_sen fields, which we use for evaluating the language models.\n\n\t\n\t\t\n\t\n\t\n\t\tUsing MultiBLiMP\n\t\n\nToâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jumelet/multiblimp.","first_N":5,"first_N_keywords":["multilingual","Buriat","Spanish","Sanskrit","Romanian"],"keywords_longer_than_N":true},
	{"name":"milu-cleaned","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/murthyrudra/milu-cleaned","creator_name":"Rudra Murthy","creator_url":"https://huggingface.co/murthyrudra","description":"\n\t\n\t\t\n\t\tMILU: A Multi-task Indic Language Understanding Benchmark\n\t\n\n\n  \n  \n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nMILU (Multi-task Indic Language Understanding Benchmark) is a comprehensive evaluation dataset designed to assess the performance of Large Language Models (LLMs) across 11 Indic languages. It spans 8 domains and 41 subjects, reflecting both general and culturally specific knowledge from India.\n\n\t\n\t\n\t\n\t\tKey Features\n\t\n\n\n11 Indian Languages: Bengali, Gujarati, Hindi, Kannada, Malayalamâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/murthyrudra/milu-cleaned.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2Jyq/common_voice_21_0","creator_name":"2Jyq","creator_url":"https://huggingface.co/2Jyq","description":"Due to storage limits some files had to be split into multiple parts. They can be merged like this: cat file.* > file.\n","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","multilingual","extended|common_voice","Abkhaz"],"keywords_longer_than_N":true},
	{"name":"english-to-hindi-high-quality-training-data","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/philomath-1209/english-to-hindi-high-quality-training-data","creator_name":"Maninder Singh","creator_url":"https://huggingface.co/philomath-1209","description":"This dataset is converted version of dataset published as \"Aarif1430/english-to-hindi\".\nI recreated this only in format as required by my project and uploaded it here. \nDo also check original author's dataset if that format suffice your need.\n","first_N":5,"first_N_keywords":["translation","English","Hindi","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"morphscore","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/catherinearnett/morphscore","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","description":"\n\t\n\t\t\n\t\tMorphScore\n\t\n\nMorphScore is a tokenizer evaluation framework, which evaluates the extent to which a tokenizer segments words along morpheme boundaries. This repository contains the datasets used to calculate MorphScore.\nIn total, we have datasetes for 86 languages, but only 70 languages have at least 100 items after filtering. \nAll datasets are derived from existing Universal Dependencies treebanks. In the table below, we link the source dataset for each language. \nSee the new preprintâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/morphscore.","first_N":5,"first_N_keywords":["Arabic","English","German","Russian","Turkish"],"keywords_longer_than_N":true},
	{"name":"IndicQuest","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/l3cube-pune/IndicQuest","creator_name":"L3Cube Labs","creator_url":"https://huggingface.co/l3cube-pune","description":"\n\t\n\t\t\n\t\tL3Cube-IndicQuest: A Benchmark Question Answering Dataset for Evaluating Knowledge of LLMs in Indic Context (LLM Factual Accuracy Benchmark)\n\t\n\nL3Cube-IndicQuest is a dataset comprising 4,000 question-answer pairs across 20 languages, including English, Assamese, Bengali, Dogri, Gujarati, Hindi, Kannada, Konkani, Maithili, Malayalam, Marathi, Meitei (Manipuri), Nepali, Odia, Punjabi, Sanskrit, Sindhi, Tamil, Telugu, and Urdu. This dataset is designed to assess the knowledgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/l3cube-pune/IndicQuest.","first_N":5,"first_N_keywords":["question-answering","English","Assamese","Bengali","Gujarati"],"keywords_longer_than_N":true},
	{"name":"INDICSTR12_REAL_IMAGES","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ananya12k/INDICSTR12_REAL_IMAGES","creator_name":"Ananya Kulkarni","creator_url":"https://huggingface.co/ananya12k","description":"ananya12k/INDICSTR12_REAL_IMAGES dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Marathi","Bengali","Kannada","Oriya","Panjabi"],"keywords_longer_than_N":true},
	{"name":"en-hi-synthetic-dataset","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Priyanka12Kumari/en-hi-synthetic-dataset","creator_name":"Priyanka Kumari","creator_url":"https://huggingface.co/Priyanka12Kumari","description":"\n\t\n\t\t\n\t\tEnglish â†” Hindi Synthetic Translation Dataset\n\t\n\nThis dataset was consists of synthetic English â†” Hindi sentence pairs suitable for multilingual machine translation and back-translation evaluation.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset was generated synthetically using a multilingual LLM â†’ MarianMT translation pipeline. Each sentence pair has been validated using semantic similarity scoring. Only pairs with cosine similarity â‰¥ 0.75 (between the original and back-translated Hindi)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Priyanka12Kumari/en-hi-synthetic-dataset.","first_N":5,"first_N_keywords":["English","Hindi","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"IndicLangClassification","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicLangClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicLangClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Non-fiction, Written\nReference\nhttps://arxiv.org/abs/2305.15814\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicLangClassification\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicLangClassification.","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-annotated","monolingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"MIRACLRetrieval","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RSamoed/MIRACLRetrieval","creator_name":"RS","creator_url":"https://huggingface.co/RSamoed","description":"\n  MIRACLRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttp://miracl.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/RSamoed/MIRACLRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","Arabic","Bengali"],"keywords_longer_than_N":true},
	{"name":"MAPS","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fujitsu-FRE/MAPS","creator_name":"Fujitsu Research of Europe","creator_url":"https://huggingface.co/Fujitsu-FRE","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Benchmark for Global Agent Performance and Security\n\t\n\nThis is the first Multilingual Agentic AI Benchmark for evaluating agentic AI systems across different languages and diverse tasks. Benchmark enables systematic analysis of how agents perform under multilingual conditions. To balance performance and safety evaluation, our benchmark comprises 805 tasks: 405 from performance-oriented datasets (GAIA, SWE-bench, MATH) and 400 from the Agent Securityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu-FRE/MAPS.","first_N":5,"first_N_keywords":["text-generation","question-answering","Arabic","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"indic-squad","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/l3cube-pune/indic-squad","creator_name":"L3Cube Labs","creator_url":"https://huggingface.co/l3cube-pune","description":"\n\t\n\t\t\n\t\tIndicSQuAD Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nIndicSQuAD is a comprehensive multilingual extractive Question Answering (QA) dataset covering nine major Indic languages: Hindi, Bengali, Tamil, Telugu, Marathi, Gujarati, Urdu, Kannada, Oriya, and Malayalam. It's systematically derived from the popular English SQuAD (Stanford Question Answering Dataset).\nThe rapid progress in QA systems has predominantly benefited high-resource languages, leaving Indic languages significantlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/l3cube-pune/indic-squad.","first_N":5,"first_N_keywords":["question-answering","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"code-switching-tokenizer-robustness","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","description":"\n\t\n\t\t\n\t\tCode-Switching Dataset for Tokenizer Robustness Analysis\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for tokenizer robustness testing in multilingual and code-switching contexts. It contains identical content expressed across 16 different language variants, including pure English and 15 English-X code-switching pairs, allowing researchers to isolate tokenization effects from semantic differences when evaluating language models.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\n\nTokenizer Comparison:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness.","first_N":5,"first_N_keywords":["text-generation","text-classification","multilingual","English","Russian"],"keywords_longer_than_N":true},
	{"name":"sib200_14classes","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200_14classes","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for SIB-200\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\nThe train/validation/test sets are available for all the 205 languages.\nThis is another version with 14 classes, more idea for few-shot evaluation, it has 5 examples for few-shot, and larger test set (1225)\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopic classification: categorize wikipedia sentencesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200_14classes.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"community-alignment-dataset","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/community-alignment-dataset","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\nCommunity Alignment\n\n\n Github Â  | Â \n Paper\n\n\n\n\t\n\t\t\n\t\tDataset\n\t\n\nCommunity Alignment is a large-scale open source, multilingual and multi-turn preference dataset to align LLMs with human preferences across cultures. It features prompt-level overlap in annotators, enabling social-choice-based and distributional approaches to LLM alignment, as well as natural language explanations for choices.\n\n[Large-scale] ~200,000 comparisons of LLM responses, collected from >3,000 unique annotators whoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/community-alignment-dataset.","first_N":5,"first_N_keywords":["Hindi","English","Portuguese","Italian","French"],"keywords_longer_than_N":true},
	{"name":"wikipedia-monthly","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/omarkamali/wikipedia-monthly","creator_name":"Omar Kamali","creator_url":"https://huggingface.co/omarkamali","description":"\n\t\n\t\t\n\t\tðŸš€ Wikipedia Monthly\n\t\n\nLast updated: July 16, 2025, 22:53 UTC\nThis repository provides monthly, multilingual dumps of Wikipedia, processed and prepared for easy use in NLP projects.\nNOTE: The first run is still in progress and languages are still being processed and uploaded.\n\n\n\t\n\t\t\n\t\tðŸ“Š Live Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nðŸŒ Languages Available\n341\n\n\nðŸ“„ Total Articles\n64.5M\n\n\nðŸ’¾ Total Size\n205.54 GB\n\n\n\t\n\n\n\n\t\n\t\t\n\t\tWhy Use This Dataset?\n\t\n\n\nFreshness: We run our pipeline monthlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/omarkamali/wikipedia-monthly.","first_N":5,"first_N_keywords":["Abkhaz","Achinese","Adyghe","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU ðŸŒ is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) ðŸ—½ or Culturally Agnostic (CA) âš–ï¸. These annotations were collected as part of an openâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU.","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"IndicVault","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/maya-research/IndicVault","creator_name":"Maya Research","creator_url":"https://huggingface.co/maya-research","description":"\n\t\n\t\t\n\t\tIndic Vault â€” everyday Indian language QA pairs, tuned for chatbots & voice agents.\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tðŸ§¾ Overview\n\t\n\nIndic Vault is a high-quality, instruction-tuned dataset featuring question-answer pairs crafted in the contemporary, everyday language spoken across India in 2025. Unlike traditional datasets that lean heavily on formal or outdated linguistic styles, Indic Vault captures the authentic, colloquial expressions used in daily conversations, making it ideal for building AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maya-research/IndicVault.","first_N":5,"first_N_keywords":["question-answering","text-generation","Hindi","Telugu","English"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tDataset Card for \"xtreme\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"hatecheck-hindi","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-hindi","creator_name":"Paul RÃ¶ttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-hindi.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"multilingual-tts","keyword":"hindi","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/multilingual-tts","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\n\t\n\t\t\n\t\tBefore Anything and Everything âš±\n\t\n\nIn the time of writing this Dataset Card, 17,490 18,412 civilian has been killed in Palestine (7,870 8,000 are children and 6,121 6,200 are women).\nSeek any non-profit organization to help them with what you can (For myself, I use Mersal) ðŸ‡µðŸ‡¸\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe Multilingual TTS dataset is an exceptional compilation of text-to-speech (TTS) samples, meticulously crafted to showcase the richness and diversity of human languages.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/multilingual-tts.","first_N":5,"first_N_keywords":["text-to-speech","Arabic","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) â†’ aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages â†’ dolly-machine-translated.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"mmarco-hard-negatives-reranker-score","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score","creator_name":"Yuichi Tateno","creator_url":"https://huggingface.co/hotchpotch","description":"\nhotchpotch/mmarco-hard-negatives-reranker-score\n\nThis repository contains data from mMARCO scored using the reranker BAAI/bge-reranker-v2-m3.\n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\ntarget_languages = [\n    \"english\",\n    \"chinese\", \n    \"french\",\n    \"german\",\n    \"indonesian\",\n    \"italian\",\n    \"portuguese\",\n    \"russian\",\n    \"spanish\",\n    \"arabic\",\n    \"dutch\",\n    \"hindi\",\n    \"japanese\",\n    \"vietnamese\"\n]\n\n\n\t\n\t\t\n\t\tHard Negative Data\n\t\n\nThe hard negative data is derived fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score.","first_N":5,"first_N_keywords":["English","Chinese","French","German","Indonesian"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\n\t\n\t\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\nWe translated the MMLUâ€™s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increasesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"mmlu-indic","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sarvamai/mmlu-indic","creator_name":"Sarvam AI","creator_url":"https://huggingface.co/sarvamai","description":"\n\t\n\t\t\n\t\tIndic MMLU Dataset\n\t\n\nA multilingual version of the Massive Multitask Language Understanding (MMLU) benchmark, translated from English into 10 Indian languages.\nThis version contains the translations of the development and test sets only. \n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\nThe dataset includes translations in the following languages:\n\nBengali (bn)\nGujarati (gu)\nHindi (hi)\nKannada (kn)\nMarathi (mr)\nMalayalam (ml)\nOriya (or)\nPunjabi (pa)\nTamil (ta)\nTelugu (te)\n\n\n\t\n\t\t\n\t\tTask Format\n\t\n\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sarvamai/mmlu-indic.","first_N":5,"first_N_keywords":["question-answering","Bengali","English","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"degeneration-html-multilingual","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","description":"\n\t\n\t\t\n\t\tThe Degeneration of the Nation Multilingual Dataset\n\t\n\n\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\n\n\t\n\t\t\n\t\n\t\n\t\tProjectâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual.","first_N":5,"first_N_keywords":["translation","text-generation","text-classification","token-classification","sentence-similarity"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tWMT24++\n\t\n\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\nthe publication\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\nIf you are interested in the images of the source URLs for each document, please see here.\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach language pair is stored in its own jsonl file.\nEach row isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"MUTANT","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LingoIITGN/MUTANT","creator_name":"Lingo Research Group","creator_url":"https://huggingface.co/LingoIITGN","description":"\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nMUTANT (A Multi-sentential Code-mixed Hinglish Dataset): MUTANT is a high-quality Hindi-English code-mixed dataset designed for tasks related to multi-sentential text processing, particularly focusing on summarization and evaluation.\n\n\t\n\t\t\n\t\tDATA Sources\n\t\n\nMUTANT dataset comprises code-mixed long-length texts extracted from two main sources:\n1. Political Speeches & Press Releases: Collected from government portals and political party websites.\n2. Hindi Newsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LingoIITGN/MUTANT.","first_N":5,"first_N_keywords":["summarization","Hindi","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"discord-phishing-scam-clean","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wangyuancheng/discord-phishing-scam-clean","creator_name":"Wang Yuancheng","creator_url":"https://huggingface.co/wangyuancheng","description":"\n\t\n\t\t\n\t\tDiscord Scam / Clean Messages Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Œ Context\n\t\n\nThis dataset contains real-world messages from my Discord server, labeled to support the fine-tuning of BERT/DistilBERT base models for phishing and scam detection.\n\n\n\t\n\t\t\n\t\tðŸ’¡ Inspiration\n\t\n\nTraditional Discord moderation bots rely on static keyword rules set by server owners, but scammers easily evade these filters by subtly altering spellings, using homoglyphs, and other tricks.To address this, I built an NLP-poweredâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wangyuancheng/discord-phishing-scam-clean.","first_N":5,"first_N_keywords":["text-classification","English","Hindi","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"xl-instruct","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/remorax98/xl-instruct","creator_name":"Vivek Iyer","creator_url":"https://huggingface.co/remorax98","description":"\n\t\n\t\t\n\t\tDataset Card for XL-Instruct\n\t\n\nThis dataset card provides a summary of the XL-Instruct dataset, a resource for advancing the cross-lingual capabilities of Large Language Models. It was introduced in the paper XL-Instruct: Synthetic Data for Cross-Lingual Open-Ended Generation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nXL-Instruct is a high-quality, large-scale synthetic dataset designed to fine-tune LLMs for cross-lingual open-ended generation. The core task involvesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/remorax98/xl-instruct.","first_N":5,"first_N_keywords":["text-generation","Hindi","Chinese","German","Portuguese"],"keywords_longer_than_N":true},
	{"name":"vox-communis-parallel-g2p","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p","creator_name":"FlÃ¡vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","description":"\n\t\n\t\t\n\t\tVoxCommunis Parallel G2P dataset\n\t\n\nThis dataset was derived from the VoxCommunis Corpus to provide pairs of utterances along with their\ncorresponding phonemes, side by side, as to ease the training of grapheme-to-phoneme (G2P) models.\nThe original VoxCommunis Corpus features force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus.\nThe lexicons were developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p.","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"alt","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mutiyama/alt","creator_name":"Masao Utiyama","creator_url":"https://huggingface.co/mutiyama","description":"\n\t\n\t\t\n\t\tDataset Card for Asian Language Treebank (ALT)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ALT project aims to advance the state-of-the-art Asian natural language processing (NLP) techniques through the open collaboration for developing and using ALT. It was first conducted by NICT and UCSY as described in Ye Kyaw Thu, Win Pa Pa, Masao Utiyama, Andrew Finch and Eiichiro Sumita (2016). Then, it was developed under ASEAN IVO as described in this Web page. \nThe process of building ALT began withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mutiyama/alt.","first_N":5,"first_N_keywords":["translation","token-classification","parsing","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"bbc_hindi_nli","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/midas/bbc_hindi_nli","creator_name":"MIDAS Research Laboratory, IIIT-Delhi","creator_url":"https://huggingface.co/midas","description":"\n\t\n\t\t\n\t\tDataset Card for BBC Hindi NLI Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nDataset for Natural Language Inference in Hindi Language. BBC Hindi Dataset consists of textual-entailment pairs.\nEach row of the Datasets if made up of 4 columns - Premise, Hypothesis, Label and Topic.\nContext and Hypothesis is written in Hindi while Entailment_Label is in English.\nEntailment_label is of 2 types - entailed and not-entailed.\nDataset can be used to train models for Natural Language Inference tasks inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/midas/bbc_hindi_nli.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","machine-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ilist","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kmi-linguistics/ilist","creator_name":"kmi-linguistics","creator_url":"https://huggingface.co/kmi-linguistics","description":"\n\t\n\t\t\n\t\tDataset Card for ilist\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is introduced in a task which aimed at identifying 5 closely-related languages of Indo-Aryan language family: Hindi (also known as Khari Boli), Braj Bhasha, Awadhi, Bhojpuri and Magahi. These languages form part of a continuum starting from Western Uttar Pradesh (Hindi and Braj Bhasha) to Eastern Uttar Pradesh (Awadhi and Bhojpuri) and the neighbouring Eastern state of Bihar (Bhojpuri and Magahi).\nFor this taskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kmi-linguistics/ilist.","first_N":5,"first_N_keywords":["text-classification","no-annotation","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"hindi","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for Opus Ubuntu\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\nE.g.\ndataset = load_dataset(\"opus_ubuntu\", lang1=\"it\", lang2=\"pl\")\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboardsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"xcsr","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/INK-USC/xcsr","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","description":"\n\t\n\t\t\n\t\tDataset Card for X-CSR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTo evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","crowdsourced","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"xquad","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xquad","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tDataset Card for \"xquad\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nXQuAD (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering\nperformance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set\nof SQuAD v1.1 (Rajpurkar et al., 2016) together with their professional translations into ten languages: Spanish, German,\nGreek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, and Hindi.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/xquad.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xquad_r","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/xquad_r","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nXQuAD-R is a retrieval version of the XQuAD dataset (a cross-lingual extractive\nQA dataset). Like XQuAD, XQUAD-R is an 11-way parallel dataset,  where each\nquestion appears in 11 different languages and has 11 parallel correct answers\nacross the languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset can be found with the following languages:\n\nArabic: xquad-r/ar.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/xquad_r.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"mqa","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"indicxnli","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Divyanshu/indicxnli","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","description":"IndicXNLI is a translated version of XNLI to 11 Indic Languages. As with XNLI, the goal is\nto predict textual entailment (does sentence A imply/contradict/neither sentence\nB) and is a classification task (given two sentences, predict one of three\nlabels).","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","machine-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"shades_nationality","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience-catalogue-data/shades_nationality","creator_name":"BigScience Catalogue Data","creator_url":"https://huggingface.co/bigscience-catalogue-data","description":"Possibly a placeholder dataset for the original here: https://huggingface.co/datasets/bigscience-catalogue-data/bias-shades\n\n\t\n\t\t\n\t\tData Statement for SHADES\n\t\n\n\nHow to use this document:\nFill in each section according to the instructions. Give as much detail as you can, but there's no need to extrapolate. The goal is to help people understand your data when they approach it. This could be someone looking at it in ten years, or it could be you yourself looking back at the data in two years.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bigscience-catalogue-data/shades_nationality.","first_N":5,"first_N_keywords":["Arabic","English","French","German","Hindi"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\n\t\n\t\t\n\t\tDataset Card for WIT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\nFrom the official blog post:\n\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\nThe WIT dataset offers extremely valuable data about theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_scenario","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_scenario","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveScenarioClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveScenarioClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_scenario.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_intent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveIntentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_intent.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"xP3all","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"multilingual-sentiments","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tyqiangz/multilingual-sentiments","creator_name":"Tay Yong Qiang","creator_url":"https://huggingface.co/tyqiangz","description":"\n\t\n\t\t\n\t\tMultilingual Sentiments Dataset\n\t\n\nA collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.\nMost multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, a positive/negativeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-classification","monolingual","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3mt","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"miracl-corpus","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/miracl-corpus","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\n\t\n\t\t\n\t\tDataset Card for MIRACL Corpus\n\t\n\nMIRACL ðŸŒðŸ™ŒðŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\nThis dataset contains the collection data of the 16 \"known languages\". The remaining 2 \"surprise languages\" will not be released until later.\nThe corpus for each language is prepared from a Wikipediaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"IE_SemParse","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Divyanshu/IE_SemParse","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","description":"    IE-SemParse is an Inter-bilingual Seq2seq Semantic parsing dataset for 11 distinct Indian languages","first_N":5,"first_N_keywords":["parsing","machine-generated","machine-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"TyDiP","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Genius1237/TyDiP","creator_name":"Genius1237","creator_url":"https://huggingface.co/Genius1237","description":"The TyDiP dataset is a dataset of requests in conversations between wikipedia editors\nthat have been annotated for politeness. The splits available below consists of only\nrequests from the top 25 percentile (polite) and bottom 25 percentile (impolite) of\npoliteness scores. The English train set and English test set that are\nadapted from the Stanford Politeness Corpus, and test data in 9 more languages\n(Hindi, Korean, Spanish, Tamil, French, Vietnamese, Russian, Afrikaans, Hungarian) \nwas annotated by us.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","found","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-hi-embeddings","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-hi-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\n\t\n\t\t\n\t\tWikipedia (hi) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (hi) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-hi-embeddings.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Hindi"],"keywords_longer_than_N":true},
	{"name":"naamapadam","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/naamapadam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\\","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","machine-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xstory_cloze","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/juletxara/xstory_cloze","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","description":"XStoryCloze consists of the professionally translated version of the [English StoryCloze dataset](https://cs.rochester.edu/nlp/rocstories/) (Spring 2016 version) to 10 non-English languages. This dataset is released by Meta AI.","first_N":5,"first_N_keywords":["other","found","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"miracl-hi-corpus-22-12","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-hi-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\n\t\n\t\t\n\t\tMIRACL (hi) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-hi-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-hi-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL ðŸŒðŸ™ŒðŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrievalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-hi-corpus-22-12.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Hindi"],"keywords_longer_than_N":true},
	{"name":"miracl-hi-queries-22-12","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-hi-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\n\t\n\t\t\n\t\tMIRACL (hi) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-hi-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-hi-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL ðŸŒðŸ™ŒðŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrievalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-hi-queries-22-12.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Hindi"],"keywords_longer_than_N":true},
	{"name":"wmt-da-human-evaluation","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation","creator_name":"Ricardo Rei","creator_url":"https://huggingface.co/RicardoRei","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains all DA human annotations from previous WMT News Translation shared tasks.\nThe data is organised into 8 columns:\n\nlp: language pair\nsrc: input text\nmt: translation\nref: reference translation\nscore: z score\nraw: direct assessment\nannotators: number of annotators\ndomain: domain of the input text (e.g. news)\nyear: collection year\n\nYou can also find the original data for each year in the results section https://www.statmt.org/wmt{YEAR}/results.htmlâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation.","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Estonian"],"keywords_longer_than_N":true},
	{"name":"multiconer_v2","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MultiCoNER/multiconer_v2","creator_name":"MultiCoNER","creator_url":"https://huggingface.co/MultiCoNER","description":"Complex named entities (NE), like the titles of creative works, are not simple nouns and pose challenges for NER systems (Ashwini and Choi, 2014). They can take the form of any linguistic constituent, like an imperative clause (â€œDial M for Murderâ€), and do not look like traditional NEs (Persons, Locations, etc.). This syntactic ambiguity makes it challenging to recognize them based on context. We organized the MultiCoNER task (Malmasi et al., 2022) at SemEval-2022 to address these challenges in 11 languages, receiving a very positive community response with 34 system papers. Results confirmed the challenges of processing complex and long-tail NEs: even the largest pre-trained Transformers did not achieve top performance without external knowledge. The top systems infused transformers with knowledge bases and gazetteers. However, such solutions are brittle against out of knowledge-base entities and noisy scenarios like the presence of spelling mistakes and typos. We propose MultiCoNER II which represents novel challenges through new tasks that emphasize the shortcomings of the current top models.\n\nMultiCoNER II features complex NER in these languages:\n\n1. English\n2. Spanish\n3. Hindi\n4. Bangla\n5. Chinese\n6. Swedish\n7. Farsi\n8. French\n9. Italian\n10. Portugese\n11. Ukranian\n12. German\n\nFor more details see https://multiconer.github.io/\n\n## References\n* Sandeep Ashwini and Jinho D. Choi. 2014. Targetable named entity recognition in social media. CoRR, abs/1408.0782.\n* Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta Kar, Oleg Rokhlenko. 2022. SemEval-2022 Task 11: Multilingual Complex Named Entity Recognition (MultiCoNER).","first_N":5,"first_N_keywords":["token-classification","Bengali","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof WrÃ³bel","creator_url":"https://huggingface.co/djstrong","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"xOA22","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sambanovasystems/xOA22","creator_name":"SambaNova","creator_url":"https://huggingface.co/sambanovasystems","description":"\n\t\n\t\t\n\t\tDataset Card for xOA22 - Multilingual Prompts from OpenAssistant\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nxOA22 consists of 22 prompts originally shown in Appendix E, page 25 of the OpenAssistant Conversations paper. These 22 prompts were then manually translated by volunteers into 5 languages: Arabic, Simplified Chinese, French, Hindi and Spanish. \nThese prompts were originally created for human evaluations of the multilingual abilities of BLOOMChat. Since not all prompts could be directlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sambanovasystems/xOA22.","first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Hindi"],"keywords_longer_than_N":true},
	{"name":"x-self-instruct-seed-32","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sambanovasystems/x-self-instruct-seed-32","creator_name":"SambaNova","creator_url":"https://huggingface.co/sambanovasystems","description":"\n\t\n\t\t\n\t\tDataset Card for xOA22 - Multilingual Prompts from OpenAssistant\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nx-self-instruct-seed-32 consists of 32 prompts chosen out of the 252 prompts in the self-instruct-seed dataset from the Self-Instruct paper. These 32 prompts were filtered out according to the following criteria:\n\nShould be natural in a chat setting\nTherefore, we filter out any prompts with \"few-shot examples\", as these are all instruction prompts that we consider unnatural in a chat settingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sambanovasystems/x-self-instruct-seed-32.","first_N":5,"first_N_keywords":["Arabic","Spanish","English","Hindi","French"],"keywords_longer_than_N":true},
	{"name":"Bhasha-Abhijnaanam","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tDataset Card for Aksharantar\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBhasha-Abhijnaanam is a language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\n\t\n\t\t\n\n\n\n\n\n\n\n\n\t\t\nAssamese (asm)\nHindi (hin)\nMaithili (mai)\nNepali (nep)\nSanskrit (san)\nTamil (tam)\n\n\nBengali (ben)\nKannada (kan)\nMalayalam (mal)\nOriya (ori)\nSantali (sat)\nTelugu (tel)\n\n\nBodo(brx)\nKashmiriâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"multi-figqa","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cmu-lti/multi-figqa","creator_name":"CMU-LTI","creator_url":"https://huggingface.co/cmu-lti","description":"\n\t\n\t\t\n\t\tDataset Card for multi-figqa\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA multilingual dataset of human-written creative figurative expressions in many languages (mostly metaphors and similes). The English version (with the same format) can be found here\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nLanguages included are Hindi, Indonesian, Javanese, Kannada, Sundanese, Swahili, and Yoruba. The language codes are respectively hi, id, kn, su, sw, and yo.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cmu-lti/multi-figqa.","first_N":5,"first_N_keywords":["question-answering","Hindi","Indonesian","Sundanese","Javanese"],"keywords_longer_than_N":true},
	{"name":"hindi-summarization","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Someman/hindi-summarization","creator_name":"Samman","creator_url":"https://huggingface.co/Someman","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHindi Text Short and Large Summarization Corpus is a collection of ~180k articles with their headlines and summary collected from Hindi News Websites.\nThis is a first of its kind Dataset in Hindi which can be used to benchmark models for Text summarization in Hindi. This does not contain articles contained in Hindi Text Short Summarization Corpus which is being released parallely with this Dataset.\nThe dataset retains originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Someman/hindi-summarization.","first_N":5,"first_N_keywords":["summarization","Hindi","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"SREDFM","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Babelscape/SREDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\nFirst, we present SRED\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}.","first_N":5,"first_N_keywords":["token-classification","Arabic","Catalan","German","Greek"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"english-to-hinglish","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/findnitai/english-to-hinglish","creator_name":"Nitai Agarwal","creator_url":"https://huggingface.co/findnitai","description":"English to Hinglish Dataset aggregated from publicly available datasources.\nSources:\n\nHinglish TOP Dataset\nCMU English Dog\nHinGE\nPHINC\n\nsource : 1 - Human Annotated , \nsource : 0 -  Synthetically Generated\n","first_N":5,"first_N_keywords":["translation","text-generation","Hindi","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\n\n\t\n\t\t\n\nToxic\nNeutral\nTotal\n\n\n\t\t\nmultilingual-train-deduplicated.csvâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Spanish","Panjabi"],"keywords_longer_than_N":true},
	{"name":"all-scam-spam","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\n1040 rows of balanced data, consisting of casual conversations and scam emails in â‰ˆ10 languages, were manually collected and annotated by me, with some help from ChatGPT.\n\n\n\n\t\n\t\t\n\t\tSome preprcoessing algorithms\n\t\n\n\nspam_assassin.js, followed by spam_assassin.py\nenron_spam.py\n\n\n\n\n\t\n\t\t\n\t\tData composition\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTo make the textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Norwegian","Spanish","Somali"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"massive_translation_dataset","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Amani27/massive_translation_dataset","creator_name":"Amani N","creator_url":"https://huggingface.co/Amani27","description":"\n\t\n\t\t\n\t\tDataset Card for Massive Dataset for Translation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is derived from AmazonScience/MASSIVE dataset for translation task purpose.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTranslation\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en_US)\nGerman (de_DE)\nHindi (hi_IN)\nSpanish (es_ES)\nFrench (fr_FR)\nItalian (it_IT)\nArabic (ar_SA)\nDutch (nl_NL)\nJapanese (ja_JP)\nPortugese (pt_PT)\n\n","first_N":5,"first_N_keywords":["translation","English","German","Spanish","Hindi"],"keywords_longer_than_N":true},
	{"name":"open-lid-dataset","keyword":"hindi","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hac541309/open-lid-dataset","creator_name":"Chris Ha","creator_url":"https://huggingface.co/hac541309","description":"This dataset is built from the open source data accompanying \"An Open Dataset and Model for Language Identification\" (Burchell et al., 2023)\nThe repository containing the actual data can be found here : https://github.com/laurieburchell/open-lid-dataset.\nThe license for this recreation itself follows the original upstream dataset as GPLv3+. \nHowever, individual datasets within it follow each of their own licenses.\nThe \"src\" column lists the sources. \"lang\" column lists the language code inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hac541309/open-lid-dataset.","first_N":5,"first_N_keywords":["English","Korean","French","Afar","Hindi"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for SIB-200\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\nThe train/validation/test sets are available for all the 205 languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 205 languages available :\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"belebele","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\n\t\n\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that discriminateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele.","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","text-classification","multiple-choice","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\n\t\n\t\t\n\t\tDataset Card for WikiAnc\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \nThe code for generating the dataset can be found here.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nwikificiation: The dataset can be used to train a model for Wikification.\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in all 320â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\n","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"ntx_llm_instructions","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\n\t\n\t\t\n\t\tDataset Card for NTX v1 in the Aya format\n\t\n\nThis dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license and conditions.\nIt contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you utilize this dataset version, feel free to cite/footnote this huggingface dataset repo, but please also cite the original datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions.","first_N":5,"first_N_keywords":["token-classification","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"ntx_llm_inst_hindi","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_hindi","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\n\t\n\t\t\n\t\tDataset Card for NTX v1 in the Aya format - Hindi subset\n\t\n\nThis dataset is a format conversion for the Hindi data from the original NTX into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nFor the original NTX dataset, the conversion to the Aya instructions format, or more details, please refer to the full dataset in instruction form (https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions) or to the paper below.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_hindi.","first_N":5,"first_N_keywords":["token-classification","Hindi","cc-by-sa-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"hindi_instruct_v1","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smangrul/hindi_instruct_v1","creator_name":"Sourab Mangrulkar","creator_url":"https://huggingface.co/smangrul","description":"\n\t\n\t\t\n\t\tHindi Instruct V1 Dataset\n\t\n\nThis dataset is curated by Sourab Mangrulkar. It was developed on top of HuggingFaceH4/no_robots dataset. \nFirst, the dataset was translated using ai4bharat/indictrans2-en-indic-1B SoTA translation model developed by AI4Bharat. \nHere, it is important to note that the sequence length limit is 256 for input and output sequences. \nHence, I split the individual sentences on full stop and create minibatches for translation and then stitch them back properly.\ndefâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/smangrul/hindi_instruct_v1.","first_N":5,"first_N_keywords":["text-generation","English","Hindi","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"PMIndiaSum","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PMIndiaData/PMIndiaSum","creator_name":"PMIndiaData","creator_url":"https://huggingface.co/PMIndiaData","description":"\n\t\n\t\t\n\t\tDataset Card for \"PMIndiaSum\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nPMIndiaSum is a new multilingual and massively parallel headline summarization corpus focused on languages in India. Our corpus covers four language families, 14 languages, and the largest to date, 196 language pairs. It provides a testing ground for all cross-lingual pairs.\n\n\t\n\t\t\n\t\tSupported tasks\n\t\n\nMonolingual, multilingual and cross-lingual summarization for languages in India.\n\n\t\n\t\t\n\t\tLanguagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PMIndiaData/PMIndiaSum.","first_N":5,"first_N_keywords":["summarization","Assamese","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"mqnli","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SachinPatel248/mqnli","creator_name":"Patel","creator_url":"https://huggingface.co/SachinPatel248","description":"SachinPatel248/mqnli dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","English","German","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"mC4-hindi","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zicsx/mC4-hindi","creator_name":"Satish Kumar Mishra","creator_url":"https://huggingface.co/zicsx","description":"\n\t\n\t\t\n\t\tDataset Card for \"mC4-hindi\"\n\t\n\nThis dataset is a subset of the mC4 dataset, which is a multilingual colossal, cleaned version of Common Crawl's web crawl corpus. It contains natural text in 101 languages, including Hindi. This dataset is specifically focused on Hindi text, and contains a variety of different types of text, including news articles, blog posts, and social media posts.\nThis dataset is intended to be used for training and evaluating natural language processing models forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zicsx/mC4-hindi.","first_N":5,"first_N_keywords":["text-generation","Hindi","apache-2.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"mC4-Hindi-Cleaned-2.0","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zicsx/mC4-Hindi-Cleaned-2.0","creator_name":"Satish Kumar Mishra","creator_url":"https://huggingface.co/zicsx","description":"\n\t\n\t\t\n\t\tDataset Card for \"test\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["Hindi","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"OSCAR-2301-Hindi-Cleaned-2.0","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zicsx/OSCAR-2301-Hindi-Cleaned-2.0","creator_name":"Satish Kumar Mishra","creator_url":"https://huggingface.co/zicsx","description":"\n\t\n\t\t\n\t\tDataset Card for \"OSCAR-2301-Hindi-Cleaned\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["Hindi","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"OSCAR-2301-Hindi-Cleaned","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zicsx/OSCAR-2301-Hindi-Cleaned","creator_name":"Satish Kumar Mishra","creator_url":"https://huggingface.co/zicsx","description":"\n\t\n\t\t\n\t\tDataset Card for \"OSCAR-2301-Hindi-Cleaned-2.0\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["text-generation","Hindi","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"HelpSteer-hindi","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SherryT997/HelpSteer-hindi","creator_name":"Sherry Thomas","creator_url":"https://huggingface.co/SherryT997","description":"SherryT997/HelpSteer-hindi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"hinglish_open_hathi_dataset","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shuvom/hinglish_open_hathi_dataset","creator_name":"shuvam mandal","creator_url":"https://huggingface.co/shuvom","description":"shuvom/hinglish_open_hathi_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","Hindi","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"BB-Ultrachat-IndicLingual6-12k","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rohansolo/BB-Ultrachat-IndicLingual6-12k","creator_name":"Rohan","creator_url":"https://huggingface.co/rohansolo","description":"\n\t\n\t\t\n\t\tBB-Ultrachat-IndicLingual6-12k\n\t\n\nThis dataset is created by bhaiyabot ai to enrich language model training data, especially in the context of Indic languages. code for creation is also open source at https://github.com/ro-hansolo/IndicTrans2HuggingFaceDatasets\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nBB-Ultrachat-IndicLingual6-12k is a curated dataset comprising 12,000 multi-turn conversations, which are a subset of the larger HuggingFaceH4/ultrachat_200k dataset. These conversations have been evenlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rohansolo/BB-Ultrachat-IndicLingual6-12k.","first_N":5,"first_N_keywords":["question-answering","text-generation","Hindi","Malayalam","Tamil"],"keywords_longer_than_N":true},
	{"name":"YThindi","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shuvom/YThindi","creator_name":"shuvam mandal","creator_url":"https://huggingface.co/shuvom","description":"This Hindi text dataset, comprising 10,000 rows, offers a comprehensive array of content encompassing diverse aspects of Hindi topics, \nranging from education and comedy to computer science and machine learning. The dataset serves as a valuable resource for finetuning or training models, \nwith a specific emphasis on Hinglish language processing. Its extensive coverage across various domains makes it particularly advantageous for enhancing the performance of models tailored to Hinglish, such asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shuvom/YThindi.","first_N":5,"first_N_keywords":["Hindi","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"YThindi","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shuvom/YThindi","creator_name":"shuvam mandal","creator_url":"https://huggingface.co/shuvom","description":"This Hindi text dataset, comprising 10,000 rows, offers a comprehensive array of content encompassing diverse aspects of Hindi topics, \nranging from education and comedy to computer science and machine learning. The dataset serves as a valuable resource for finetuning or training models, \nwith a specific emphasis on Hinglish language processing. Its extensive coverage across various domains makes it particularly advantageous for enhancing the performance of models tailored to Hinglish, such asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shuvom/YThindi.","first_N":5,"first_N_keywords":["Hindi","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"WikidataLabels","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rayliuca/WikidataLabels","creator_name":"Ray Liu","creator_url":"https://huggingface.co/rayliuca","description":"\n\t\n\t\t\n\t\tWikidata Labels\n\t\n\nLarge parallel corpus for machine translation\n\nEntity label data extracted from Wikidata (2022-01-03), filtered for item entities only  \nOnly download the languages you need with datasets>=2.14.0\nSimilar dataset: https://huggingface.co/datasets/wmt/wikititles (18 Wikipedia titles pairs instead of all Wikidata entities)\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources\n\t\n\n\nWikidata JSON dump (wikidata-20220103-all.json.gz)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rayliuca/WikidataLabels.","first_N":5,"first_N_keywords":["translation","English","French","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"FranÃ§ais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"MMCQSD","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ArkaAcharya/MMCQSD","creator_name":"Arkadeep Acharya","creator_url":"https://huggingface.co/ArkaAcharya","description":"\n\t\n\t\t\n\t\tDataset Card for MMCQS Dataset\n\t\n\nThis is the MMCQS Dataset that have been used in the paper \"MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries\" accepted in ECIR 2024.\n\nGithub: https://github.com/ArkadeepAcharya/MedSumm-ECIR2024\n\nPaper: https://arxiv.org/abs/2401.01596\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tUses\n\t\n\n\nDownload and unzip the Multimodal_images.zip file, that can be found the in the 'Files and Version' section, to access the images that have been used in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ArkaAcharya/MMCQSD.","first_N":5,"first_N_keywords":["summarization","English","Hindi","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bhandara","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tensoic/Bhandara","creator_name":"Tensoic AI","creator_url":"https://huggingface.co/Tensoic","description":"\n\t\n\t\t\n\t\tA Pretraining Hindi Dataset for Diverse Indian NLP Tasks\n\t\n\nThis dataset contains over 12,000 rows and 7 million words of text specifically generated for pretraining NLP models on Hindi language tasks. It was created using the Bard API, ensuring high-quality and diverse content.\n\n\t\n\t\t\n\t\tKey Feature: Rich India-Specific Data\n\t\n\nA distinguishing characteristic of this dataset is its inclusion of a substantial amount of content related to India. This makes it valuable for training modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tensoic/Bhandara.","first_N":5,"first_N_keywords":["text-generation","Hindi","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ai4bharat-hi-subset","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zicsx/ai4bharat-hi-subset","creator_name":"Satish Kumar Mishra","creator_url":"https://huggingface.co/zicsx","description":"\n\t\n\t\t\n\t\tDataset Card for \"ai4bharat-hi-subset\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["text-generation","Hindi","apache-2.0","100M - 1B","parquet"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","MetlatÃ³noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"seamless-align","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\n\t\n\t\t\n\t\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\n\n\t\n\t\t\n\t\tHow to use the data\n\t\n\nThere are two ways to access the data:\n\nVia the Hugging Face Python datasets library\n\nScripts coming soonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align.","first_N":5,"first_N_keywords":["translation","audio-to-audio","Maltese","English","Welsh"],"keywords_longer_than_N":true},
	{"name":"WEATHub","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iamshnoo/WEATHub","creator_name":"Anjishnu Mukherjee","creator_url":"https://huggingface.co/iamshnoo","description":"\n\n\n\n\n\t\n\t\t\n\t\tDataset Card for \"WEATHub\"\n\t\n\nThis dataset corresponds to the data described in the paper \"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\"\naccepted to EMNLP 2023.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)\nto measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers. And weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub.","first_N":5,"first_N_keywords":["Arabic","Bengali","Central Kurdish","Danish","German"],"keywords_longer_than_N":true},
	{"name":"tts-rj-hi-karya","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/1rsh/tts-rj-hi-karya","creator_name":"Irsh Vijay","creator_url":"https://huggingface.co/1rsh","description":"\n\t\n\t\t\n\t\tRajasthani Hindi Speech Dataset\n\t\n\n\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. They had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426872 recordings in this dataset. They had roughly 58 male participants and 40 female participants.\n\nPoint to Note:\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the sentencesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/1rsh/tts-rj-hi-karya.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Hindi","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"speech-rj-hi","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/speech-rj-hi","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"\n\t\n\t\t\n\t\tRajasthani Hindi Speech Dataset\n\t\n\n\nThis dataset consists of audio recordings of participants reading out stories in Rajasthani Hindi, one sentence at a time. We had 98 participants from Soda, Rajasthan. Each participant read 30 stories. In total, we have 426873 recordings in this dataset. We had roughly 58 male participants and 40 female participants.\n\nPoint to Note:\nWhile random sampling suggests that most users have to their best effort tried to accurately read out the sentences, weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/severo/speech-rj-hi.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Hindi","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"truthfulqa_indic","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vakyansh/truthfulqa_indic","creator_name":"Vakyansh","creator_url":"https://huggingface.co/vakyansh","description":"Original Repository\n\n\t\n\t\t\n\t\tTasks (from original repository)\n\t\n\n\n\t\n\t\t\n\t\tGeneration (main task):\n\t\n\nTask: Given a question, generate a 1-2 sentence answer.\nObjective: The primary objective is overall truthfulness, expressed as the percentage of the model's answers that are true. Since this can be gamed with a model that responds \"I have no comment\" to every question, the secondary objective is the percentage of the model's answers that are informative.\n\n\t\n\t\t\n\t\tFuture Work:\n\t\n\n\nValidateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vakyansh/truthfulqa_indic.","first_N":5,"first_N_keywords":["text-generation","Hindi","Panjabi","Telugu","Tamil"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"hindi-headline-article-generation","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ganeshjcs/hindi-headline-article-generation","creator_name":"Ganesh Jagadeesan","creator_url":"https://huggingface.co/ganeshjcs","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\nhindi-headline-article-generation is an open source dataset of instruct-style records generated from the Hindi Text Short and Large Summarization dataset. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the CC BY-SA 4.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Hindi Version: 1.0\n\n\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ganeshjcs/hindi-headline-article-generation.","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"hindi-article-summarization","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ganeshjcs/hindi-article-summarization","creator_name":"Ganesh Jagadeesan","creator_url":"https://huggingface.co/ganeshjcs","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\nhindi-article-summarization is an open source dataset of instruct-style records generated from the Hindi Text Short and Large Summarization dataset. This was created as part of Aya Open Science Initiative from Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the CC BY-SA 4.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\n\nLanguages: Hindi Version: 1.0\n\n\t\n\t\n\t\n\t\tDataset Overviewâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ganeshjcs/hindi-article-summarization.","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_regions","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Regions\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\nKey Features:\n\nTextual Data: The dataset contains 500,000 text samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"phinc","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/veezbo/phinc","creator_name":"Vibhor Kumar","creator_url":"https://huggingface.co/veezbo","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nPHINC is a parallel corpus for machine translation pairing code-mixed Hinglish (a fusion of Hindi and English commonly used in modern India) with human-generated English translations.\n\n\t\n\t\t\n\t\tCredit\n\t\n\nAll credit goes to:\nPHINC: A Parallel Hinglish Social Media Code-Mixed Corpus for Machine Translation (Srivastava & Singh, WNUT 2020)\n\n\t\n\t\t\n\t\tOriginal Abstract\n\t\n\nCode-mixing is the phenomenon of using more than one language in a sentence. It is a very frequently observedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/veezbo/phinc.","first_N":5,"first_N_keywords":["translation","English","Hindi","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"CommonVoiceCorpusHindi15","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yagnikposhiya/CommonVoiceCorpusHindi15","creator_name":"Yagnik Poshiya","creator_url":"https://huggingface.co/yagnikposhiya","description":"\n\t\n\t\t\n\t\n\t\n\t\tCommonVoiceCorpusHindi15\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDirectory structure:\n\t\n\n\nassets \n a. Download whole compressed dataset by clicking on the cv-corpus-15.0-2023-09-08-hi.tar.gz file. \n b. splitdata.py, python script contains code to split \"clips\" direcrtory in the original dataset. Because HuggingFace supports 10,000 files per directory but in the original dataset \"clips\" directory contains 14,000 files almost. So, \"clips\" directory is splitted into two directories \"clips0\" and \"clips1\".â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yagnikposhiya/CommonVoiceCorpusHindi15.","first_N":5,"first_N_keywords":["Hindi","apache-2.0","Audio","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"MultiCoNER","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tomaarsen/MultiCoNER","creator_name":"Tom Aarsen","creator_url":"https://huggingface.co/tomaarsen","description":"We present MultiCoNER, a large multilingual dataset for Named Entity Recognition that covers 3 domains (Wiki sentences, questions, and search queries) across 11 languages, as well as multilingual and code-mixing subsets. This dataset is designed to represent contemporary challenges in NER, including low-context scenarios (short and uncased text), syntactically complex entities like movie titles, and long-tail entity distributions. The 26M token dataset is compiled from public resources using techniques such as heuristic-based sentence sampling, template extraction and slotting, and machine translation. We applied two NER models on our dataset: a baseline XLM-RoBERTa model, and a state-of-the-art GEMNET model that leverages gazetteers. The baseline achieves moderate performance (macro-F1=54%), highlighting the difficulty of our data. GEMNET, which uses gazetteers, improvement significantly (average improvement of macro-F1=+30%). MultiCoNER poses challenges even for large pre-trained language models, and we believe that it can help further research in building robust NER systems. MultiCoNER is publicly available at https://registry.opendata.aws/multiconer/ and we hope that this resource will help advance research in various aspects of NER.","first_N":5,"first_N_keywords":["token-classification","Bengali","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"indian-history-hindi-QA-3.4k","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kaifahmad/indian-history-hindi-QA-3.4k","creator_name":"Mohd Kaif","creator_url":"https://huggingface.co/kaifahmad","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3.47k top-notch question-answer pairs about Indian History in Hindi.\n\nCurated by: Mohd Kaif\nLanguage(s) (NLP): Hindi\nLicense: apache-2.0\n\n\n\t\n\t\t\n\t\t\n\t\n\n","first_N":5,"first_N_keywords":["question-answering","Hindi","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"indian-history-hindi-QA-3.4k","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kaifahmad/indian-history-hindi-QA-3.4k","creator_name":"Mohd Kaif","creator_url":"https://huggingface.co/kaifahmad","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3.47k top-notch question-answer pairs about Indian History in Hindi.\n\nCurated by: Mohd Kaif\nLanguage(s) (NLP): Hindi\nLicense: apache-2.0\n\n\n\t\n\t\t\n\t\t\n\t\n\n","first_N":5,"first_N_keywords":["question-answering","Hindi","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"tokenizer-wiki-bench","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","description":"\n\t\n\t\t\n\t\tMultilingual Tokenizer Benchmark\n\t\n\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \nfrom transformers import AutoTokenizerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench.","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"aditi-syn-v1","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/manishiitg/aditi-syn-v1","creator_name":"Manish Prakash","creator_url":"https://huggingface.co/manishiitg","description":"v1 for synthetic dataset generate for aditi model.\nGeneration scripts are located here https://github.com/manishiitg/aditi_dataset/tree/main/gen\n","first_N":5,"first_N_keywords":["Hindi","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"gooftagoo","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adi-kmt/gooftagoo","creator_name":"Adithya Kamath","creator_url":"https://huggingface.co/adi-kmt","description":"\n\t\n\t\t\n\t\tHindi/Hinglish Conversation Dataset\n\t\n\nThis repository contains a dataset of conversational text in conversational hindi and hinglish(a mix of Hindi and English languages).\nThe Conversation Dataset contains multi-turn conversations on multiple topics usually revolving around daily real-life experiences. \nA small amount of reasoning tasks have also been added (specifically COT style reasoning and coding) with about 1k samples from Openhermes 2.5.\n\n\t\n\t\t\n\t\tCaution\n\t\n\nThis dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/adi-kmt/gooftagoo.","first_N":5,"first_N_keywords":["text-generation","Hindi","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"gooftagoo","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adi-kmt/gooftagoo","creator_name":"Adithya Kamath","creator_url":"https://huggingface.co/adi-kmt","description":"\n\t\n\t\t\n\t\tHindi/Hinglish Conversation Dataset\n\t\n\nThis repository contains a dataset of conversational text in conversational hindi and hinglish(a mix of Hindi and English languages).\nThe Conversation Dataset contains multi-turn conversations on multiple topics usually revolving around daily real-life experiences. \nA small amount of reasoning tasks have also been added (specifically COT style reasoning and coding) with about 1k samples from Openhermes 2.5.\n\n\t\n\t\t\n\t\tCaution\n\t\n\nThis dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/adi-kmt/gooftagoo.","first_N":5,"first_N_keywords":["text-generation","Hindi","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"gooftagoo","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tensoic/gooftagoo","creator_name":"Tensoic AI","creator_url":"https://huggingface.co/Tensoic","description":"\n\t\n\t\t\n\t\tHindi/Hinglish Conversation Dataset\n\t\n\nThis repository contains a dataset of conversational text in conversational hindi and hinglish(a mix of Hindi and English languages).\nThe Conversation Dataset contains multi-turn conversations on multiple topics usually revolving around daily real-life experiences. \nA small amount of reasoning tasks have also been added (specifically COT style reasoning and coding) with about 1k samples from Openhermes 2.5.\n\n\t\n\t\t\n\t\tCaution\n\t\n\nThis dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tensoic/gooftagoo.","first_N":5,"first_N_keywords":["text-generation","Hindi","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"gooftagoo","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tensoic/gooftagoo","creator_name":"Tensoic AI","creator_url":"https://huggingface.co/Tensoic","description":"\n\t\n\t\t\n\t\tHindi/Hinglish Conversation Dataset\n\t\n\nThis repository contains a dataset of conversational text in conversational hindi and hinglish(a mix of Hindi and English languages).\nThe Conversation Dataset contains multi-turn conversations on multiple topics usually revolving around daily real-life experiences. \nA small amount of reasoning tasks have also been added (specifically COT style reasoning and coding) with about 1k samples from Openhermes 2.5.\n\n\t\n\t\t\n\t\tCaution\n\t\n\nThis dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tensoic/gooftagoo.","first_N":5,"first_N_keywords":["text-generation","Hindi","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"bhasha-sft","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/soketlabs/bhasha-sft","creator_name":"Soket Labs","creator_url":"https://huggingface.co/soketlabs","description":"\n\t\n\t\t\n\t\tBhasha SFT\n\t\n\n\nBhasha SFT is a massive collection of multiple open sourced Supervised Fine-Tuning datasets for training Multilingual \nLarge Language Models. The dataset contains collation of over 13 million instances of\ninstruction-response data for 3 Indian languages (Hindi, Gujarati, Bengali) and English having both human annotated and synthetic data.\n\nCurated by: Soket AI Labs\nLanguage(s) (NLP): [English, Hindi, Bengali, Gujarati]\nLicense: [cc-by-4.0, apache-2.0, mit]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/soketlabs/bhasha-sft.","first_N":5,"first_N_keywords":["question-answering","translation","summarization","text-generation","Hindi"],"keywords_longer_than_N":true},
	{"name":"HinglishCognitiveReframing","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nirbhaysinghnarang/HinglishCognitiveReframing","creator_name":"Nirbhay Singh Narang","creator_url":"https://huggingface.co/nirbhaysinghnarang","description":"nirbhaysinghnarang/HinglishCognitiveReframing dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Hindi","English","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"cross-rag-enhi","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BhabhaAI/cross-rag-enhi","creator_name":"Bhabha AI","creator_url":"https://huggingface.co/BhabhaAI","description":"BhabhaAI/cross-rag-enhi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Hindi","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"hindi-RAG-20k","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BhabhaAI/hindi-RAG-20k","creator_name":"Bhabha AI","creator_url":"https://huggingface.co/BhabhaAI","description":"BhabhaAI/hindi-RAG-20k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Hindi","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"bhasha-wiki-translated","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/soketlabs/bhasha-wiki-translated","creator_name":"Soket Labs","creator_url":"https://huggingface.co/soketlabs","description":"\n\t\n\t\t\n\t\tBhasha Wikipedia Translated\n\t\n\n\nTranslated wikipedia articles\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nDataset is being updated\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nWe have translated 6.185 million English wikipedia articles into 6 Indic languages. The translations were done using IndicTrans2 model.\n\nCurated by: Soket AI labs\nLanguage(s) (NLP): Hindi, Bengali, Gujarati, Tamil, Kannada, Urdu\nLicense: cc-by-sa-4.0\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\nFor pretraining or Fine tuning for Indic language models\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/soketlabs/bhasha-wiki-translated.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","Hindi"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"HINMIX_hi-en","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kartikagg98/HINMIX_hi-en","creator_name":"kartik","creator_url":"https://huggingface.co/kartikagg98","description":"\n\t\n\t\t\n\t\tDataset Card for Hindi English Codemix Dataset - HINMIX\n\t\n\nHINMIX is a massive parallel codemixed dataset for Hindi-English code switching.\nSee the ðŸ“š paper on arxiv to dive deep into this synthetic codemix data generation pipeline. \nDataset contains 4.2M fully parallel sentences in 6 Hindi-English forms.\nFurther, we release gold standard codemix dev and test set manually translated by proficient bilingual annotators.\n\nDev Set consists of 280 examples\nTest set consists of 2507 examplesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kartikagg98/HINMIX_hi-en.","first_N":5,"first_N_keywords":["translation","Hindi","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"HINMIX_hi-en","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kartikagg98/HINMIX_hi-en","creator_name":"kartik","creator_url":"https://huggingface.co/kartikagg98","description":"\n\t\n\t\t\n\t\tDataset Card for Hindi English Codemix Dataset - HINMIX\n\t\n\nHINMIX is a massive parallel codemixed dataset for Hindi-English code switching.\nSee the ðŸ“š paper on arxiv to dive deep into this synthetic codemix data generation pipeline. \nDataset contains 4.2M fully parallel sentences in 6 Hindi-English forms.\nFurther, we release gold standard codemix dev and test set manually translated by proficient bilingual annotators.\n\nDev Set consists of 280 examples\nTest set consists of 2507 examplesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kartikagg98/HINMIX_hi-en.","first_N":5,"first_N_keywords":["translation","Hindi","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"orca-math-word-problems-200k-hindi-filtered","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BhabhaAI/orca-math-word-problems-200k-hindi-filtered","creator_name":"Bhabha AI","creator_url":"https://huggingface.co/BhabhaAI","description":"BhabhaAI/orca-math-word-problems-200k-hindi-filtered dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Hindi","mit","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"aditi-syn-v2","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/manishiitg/aditi-syn-v2","creator_name":"Manish Prakash","creator_url":"https://huggingface.co/manishiitg","description":"This repo contains synthentic dataset in hindi/hinglish language using to fine tune aditi OOS LLM.\nThis has different type of data formats\n\nTOOLS: teaching hindi/hinglish based function calling\nRAG/RAG-Complex: teching context based rag for hindi/hinglish\nCODE: writing code\nORCA: reasoning/math questions\nCOT: chain of thought reasoning\nPrompts: Hindi/Hinglish answers on highly quality curated prompts\nInstruct: general Q/A on indian context questions\nWriting: general writing instructionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/manishiitg/aditi-syn-v2.","first_N":5,"first_N_keywords":["Hindi","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"THAR-Dataset","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aakash941/THAR-Dataset","creator_name":"Aakash Singh","creator_url":"https://huggingface.co/Aakash941","description":"The dataset consists 11,549 YouTube comments in Hindi-English code-mixed language for targeted hate speech detection against religion. Binary and multi-class tagging of YouTube comments is used. \nThe classification of YouTube comments addresses two subtasks: Subtask-1 (Binary classification): comments are labeled as antireligion or non-antireligion. Subtask-2 (Multi-class classification): comments are labeled on the major targeted religions such as Islam, Hinduism, and Christianity, with aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Aakash941/THAR-Dataset.","first_N":5,"first_N_keywords":["text-classification","Hindi","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Hindi_XSUM","keyword":"hindi","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pkumark/Hindi_XSUM","creator_name":"Praveenkumar Katwe","creator_url":"https://huggingface.co/pkumark","description":"pkumark/Hindi_XSUM dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Hindi","afl-3.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Hindi_Mithai","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VishalMysore/Hindi_Mithai","creator_name":"Vishal Mysore","creator_url":"https://huggingface.co/VishalMysore","description":"\n\t\n\t\t\n\t\tDataset Card for Indian Sweets\n\t\n\n","first_N":5,"first_N_keywords":["Hindi","apache-2.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"hindi_instruct","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/maharnab/hindi_instruct","creator_name":"Maharnab Saikia","creator_url":"https://huggingface.co/maharnab","description":"This dataset was created for the \"Unlock Global Communication with Gemma\" competition on Kaggle. It combines multiple datasets to capture a diverse range of topics and use cases:\n\nOdiaGenAI/instruction_set_hindi_1035: Includes instructions and responses related to art, culture, history, cooking, environment, music, and sports.\nSherryT997/HelpSteer-hindi: Focuses on general question-answering conversations.\nkaifahmad/indian-history-hindi-QA-3.4k: Contains questions and answers specificallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maharnab/hindi_instruct.","first_N":5,"first_N_keywords":["question-answering","Hindi","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"Ø§Ù…Ø§Ù… Ø¬Ù…Ø¹Ù‡ Ø§ØµÙÙ‡Ø§Ù† Ú¯ÙØª: Ù…ÛŒØ²Ø§Ù† Ù†ÛŒØ§Ø² Ø¢Ø¨ Ø´Ø±Ø¨ Ø§ØµÙÙ‡Ø§Ù† Û±Û±.Ûµ Ù…ØªØ± Ù…Ú©Ø¹Ø¨ Ø§Ø³Øª Ú©Ù‡ ØªÙ…Ø§Ù… Ø§Ø³ØªØ§Ù† Ø§ØµÙÙ‡Ø§Ù† Ø±Ø§ Ù¾ÙˆØ´Ø´ Ù…ÛŒØ¯Ù‡Ø¯ Ùˆ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ù†Ù‚Ù„Ø§Ø¨ ÛŒÚ©ÛŒ Ø§Ø² Ù¾ÛŒØ´Ø±ÙØªÙ‡Ø§ Ø¯Ø± Ø­ÙˆØ²Ù‡ Ø¢Ø¨ Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"bhashini","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DivaJais/bhashini","creator_name":"Devanshi Jaiswal","creator_url":"https://huggingface.co/DivaJais","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DivaJais/bhashini.","first_N":5,"first_N_keywords":["English","Hindi","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"shrimad-bhagavad-gita-dataset-alpaca","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SatyaSanatan/shrimad-bhagavad-gita-dataset-alpaca","creator_name":"Sanatan Dharma","creator_url":"https://huggingface.co/SatyaSanatan","description":"SatyaSanatan/shrimad-bhagavad-gita-dataset-alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","Hindi","Sanskrit","mit"],"keywords_longer_than_N":true},
	{"name":"Language_Indentification_v2","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Process-Venue/Language_Indentification_v2","creator_name":"ProcessVenue","creator_url":"https://huggingface.co/Process-Venue","description":"\n\t\n\t\t\n\t\tDataset Card for Language Identification Dataset\n\t\n\n\n\t\n\t\t\n\t\tSample Notebook:\n\t\n\nhttps://www.kaggle.com/code/rishabhbhartiya/indian-language-classification-smote-resampled\n\n\t\n\t\t\n\t\tKaggle Dataset link:\n\t\n\nhttps://www.kaggle.com/datasets/processvenue/indian-language-identification\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA comprehensive dataset for Indian language identification and text classification. The dataset contains text samples across 18 major Indian languages, making it suitable forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Process-Venue/Language_Indentification_v2.","first_N":5,"first_N_keywords":["text-classification","Hindi","English","Marathi","Panjabi"],"keywords_longer_than_N":true},
	{"name":"greetings","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/auflo/greetings","creator_name":"Auflo","creator_url":"https://huggingface.co/auflo","description":"auflo/greetings dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Hindi","English","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"Phonemized-UD","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/suchirsalhan/Phonemized-UD","creator_name":"Suchir Salhan","creator_url":"https://huggingface.co/suchirsalhan","description":"\n\t\n\t\t\n\t\tPhoneme-UD: A Multilingual Phonemized Universal Dependencies Corpus for 34+ Languages\n\t\n\n\n\t\n\t\t\n\t\tG2P+ Phonemizer\n\t\n\nWe use G2P+ to phonemize Universal Dependencies. Here is an example usage: \n# Install required packages\n!apt-get install -y espeak-ng\n!pip install phonemizer g2p-plus\n# Set the environment variable from Python\nimport os\nos.environ[\"PHONEMIZER_ESPEAK_LIBRARY\"] = \"/usr/lib/x86_64-linux-gnu/libespeak-ng.so.1\"\n\n# Now run your transcription\nfrom g2p_plus importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/suchirsalhan/Phonemized-UD.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Azerbaijani","Catalan"],"keywords_longer_than_N":true},
	{"name":"world-languages-dataset","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SivaMallikarjun/world-languages-dataset","creator_name":"Parvatham Siva Mallikarjun","creator_url":"https://huggingface.co/SivaMallikarjun","description":"\n\t\n\t\t\n\t\tðŸŒ World Languages Dataset\n\t\n\nThis dataset contains a list of official and unofficial languages categorized by language families...\n","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"nisram-hindi-text-0.0","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nis12ram/nisram-hindi-text-0.0","creator_name":"nishant choudhary","creator_url":"https://huggingface.co/nis12ram","description":"\n\t\n\t\t\n\t\tDataset Card for nisram-hindi-text-0.0\n\t\n\n\n\t\n\t\t\n\t\tQuick Summary\n\t\n\n\nLanguage: Hindi  \nSize: ~618,000 raw text samples (206k from each source, before deduplication) and 602,000 after deduplication\nContent: Short- to medium-length Hindi text (up to ~5000 characters), drawn from web-crawled corpora  \nFields: One field text (string) containing the Hindi text  \nSources:  \nmC4-Hindi-Cleaned-3.0  \nOSCAR-2301-Hindi-Cleaned-2.0  \nai4bharat/sangraha (Hindi, verified)\n\n\nDeduplication: Performedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nis12ram/nisram-hindi-text-0.0.","first_N":5,"first_N_keywords":["text-generation","Hindi","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Indic-subtitler-audio_evals","keyword":"hindi","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kurianbenoy/Indic-subtitler-audio_evals","creator_name":"Kurian Benoy","creator_url":"https://huggingface.co/kurianbenoy","description":"\n\t\n\t\t\n\t\tIndic_audio_evals\n\t\n\nAs part of this project. We are evaluating our performance of various ASR models as well\nin a benchmarking dataset, we have created in various languages. This benchmarking dataset\nis more alligned to real-world use-cases rather than having any academic datasets.\n\n\t\n\t\t\n\t\tAbout Dataset\n\t\n\n\nDataset Link in HuggingFace: kurianbenoy/Indic-subtitler-audio_evals\n\nThis dataset contains audio file in .wav format and video file in .mp4. The respective groundtruth will beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kurianbenoy/Indic-subtitler-audio_evals.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Malayalam","Hindi","English","Bengali"],"keywords_longer_than_N":true},
	{"name":"hind-promo","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/thinkedgeAI/hind-promo","creator_name":"ThinkEdge AI lAB","creator_url":"https://huggingface.co/thinkedgeAI","description":"\n\t\n\t\t\n\t\tDataset Card: Hindi Narrative Prompt Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of over 45,000 rows of Hindi language data, serving as a valuable resource for training and evaluating natural language generation models, particularly in the Hindi language domain. Each row contains the following fields:\n\nsystem_prompt: A detailed prompt provided in Hindi, intended to guide the generation of narratives or explanations.\nqas_id: Unique identifier for each question-answerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/thinkedgeAI/hind-promo.","first_N":5,"first_N_keywords":["text-generation","Hindi","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ai2_arc-hi","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/ai2_arc-hi","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tDataset Card for \"ai2_arc\" translated into Hindi\n\t\n\nThis is Hindi translated version of \"ai2_arc\" using the IndicTrans2 model (Gala et al., 2023).\nWe recommend you to visit the \"ai2_arc\" huggingface dataset card (link) for the details.\n","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","multiple-choice-qa","found","found"],"keywords_longer_than_N":true},
	{"name":"megawika-report-generation","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\n\t\n\t\t\n\t\tDataset Card for MegaWika for Report Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\nnon-English language, an automated English translation is provided. \nThis dataset provides theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation.","first_N":5,"first_N_keywords":["summarization","text-retrieval","text-generation","Afrikaans","Arabic"],"keywords_longer_than_N":true},
	{"name":"samvaad-hi-v1","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sarvamai/samvaad-hi-v1","creator_name":"Sarvam AI","creator_url":"https://huggingface.co/sarvamai","description":"100k high-quality conversations in English, Hindi, and Hinglish curated exclusively with an Indic context.\n","first_N":5,"first_N_keywords":["text-generation","English","Hindi","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Hindi-Instruct-Gemma-Prompt-formate","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CognitiveLab/Hindi-Instruct-Gemma-Prompt-formate","creator_name":"CL","creator_url":"https://huggingface.co/CognitiveLab","description":"CognitiveLab/Hindi-Instruct-Gemma-Prompt-formate dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","Hindi","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Hindi-Instruct-Gemma-Prompt-formate","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CognitiveLab/Hindi-Instruct-Gemma-Prompt-formate","creator_name":"CL","creator_url":"https://huggingface.co/CognitiveLab","description":"CognitiveLab/Hindi-Instruct-Gemma-Prompt-formate dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","Hindi","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Hindi-Niband","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/thinkedgeAI/Hindi-Niband","creator_name":"ThinkEdge AI lAB","creator_url":"https://huggingface.co/thinkedgeAI","description":"\n\t\n\t\t\n\t\tDataset Name: Hindi- Niband (Massive Hindi language Text Dataset)\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset is a comprehensive collection of text data consisting of more than 10 billion tokens. It encompasses a wide range of sources, including Wikipedia articles, news articles, email transcripts, and generated prompt text. Specific Hindi language data columns have been extracted from the CulturaX dataset, which is a large, cleaned, and multilingual dataset for large language models.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/thinkedgeAI/Hindi-Niband.","first_N":5,"first_N_keywords":["text-generation","table-question-answering","summarization","Hindi","mit"],"keywords_longer_than_N":true},
	{"name":"samvaad-hi-v1","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rishiraj/samvaad-hi-v1","creator_name":"Rishiraj Acharya","creator_url":"https://huggingface.co/rishiraj","description":"100k high-quality conversations in English, Hindi, and Hinglish curated exclusively with an Indic context.\n","first_N":5,"first_N_keywords":["text-generation","English","Hindi","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"alpaca_hindi_small","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QuantumMik/alpaca_hindi_small","creator_name":"mik","creator_url":"https://huggingface.co/QuantumMik","description":"\n\t\n\t\t\n\t\tAlpaca Hindi Small\n\t\n\nThis is a synthesized dataset created by translation of alpaca dataset from English to Hindi language.\n","first_N":5,"first_N_keywords":["question-answering","text-generation","Hindi","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Solar-Panel-Thermal-Drone-UAV-Images","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Manishsahu53/Solar-Panel-Thermal-Drone-UAV-Images","creator_name":"Sahu","creator_url":"https://huggingface.co/Manishsahu53","description":"Git\nThis is Thermal Images of solar power plant captured using DJI drone in India.\nHow to read thermal values from Image:\n\nhttps://github.com/ManishSahu53/read_thermal_temperature\n\nHow to do automated hotspot detection:\n\nhttps://github.com/ManishSahu53/solarHotspotAnalysis\n\n","first_N":5,"first_N_keywords":["zero-shot-object-detection","English","Hindi","apache-2.0","Image"],"keywords_longer_than_N":true},
	{"name":"MIMIC-Meme-Dataset","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aakash941/MIMIC-Meme-Dataset","creator_name":"Aakash Singh","creator_url":"https://huggingface.co/Aakash941","description":"This dataset endeavors to fill the research void by presenting a meticulously curated collection of misogynistic memes in a code-mixed language of Hindi and English. It introduces two sub-tasks: the first entails a binary classification to determine the presence of misogyny in a meme, while the second task involves categorizing the misogynistic memes into multiple labels, including Objectification, Prejudice, and Humiliation.\nFor more Information and Citation: Singh, A., Sharma, D., & Singhâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Aakash941/MIMIC-Meme-Dataset.","first_N":5,"first_N_keywords":["feature-extraction","Hindi","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\nand converted into different parts (see process.py):\n\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\n\nRaw data files are in raw.tar.gz, which contains:\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\n[...] 9.8M Feb 24â€¦ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"mittens","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/mittens","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tMiTTenS: A Dataset for Evaluating Misgendering in Translation\n\t\n\nMisgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scriptsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/mittens.","first_N":5,"first_N_keywords":["translation","Arabic","Finnish","Oromo","Ganda"],"keywords_longer_than_N":true},
	{"name":"mC4-Hindi-Cleaned","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zicsx/mC4-Hindi-Cleaned","creator_name":"Satish Kumar Mishra","creator_url":"https://huggingface.co/zicsx","description":"\n\t\n\t\t\n\t\tDataset Card for \"mC4-Hindi-Cleaned\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["Hindi","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"shrutilipi","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amithm3/shrutilipi","creator_name":"Amith M","creator_url":"https://huggingface.co/amithm3","description":"amithm3/shrutilipi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","Sanskrit","Bengali","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Custom_common_voice_dataset_using_RVC","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aniket-Tathe-08/Custom_common_voice_dataset_using_RVC","creator_name":"Aniket Tathe","creator_url":"https://huggingface.co/Aniket-Tathe-08","description":"\n\t\n\t\t\n\t\tCustom Data Augmentation for low resource ASR using Bark and    Retrieval-Based Voice Conversion\n\t\n\nCustom common_voice_v11 corpus with a custom voice was was created using RVC(Retrieval-Based Voice Conversion) \nThe model underwent 200 epochs of training, utilizing a total of 1 hour of audio clips. The data was scraped from Youtube.\nThe audio in the custom generated dataset is of a YouTuber named \nAjay Pandey\n\n\t\n\t\t\n\t\n\t\n\t\tDescription\n\t\n\n\n\n\t\n\t\n\t\n\t\tlicense: cc0-1.0\nlanguage:\n- hiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Aniket-Tathe-08/Custom_common_voice_dataset_using_RVC.","first_N":5,"first_N_keywords":["common_voice_v11","Hindi","cc0-1.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"human-eval","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/human-eval","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tAiravata HumanEval Prompts\n\t\n\nThis benchmark contains a set of prompts written by real-users to evaluate LLMs on real-world tasks and test it for different abilities. We collect prompts for 5 abilities listed below:\n\nLong: Ability to generate long-form text like writing essays, speeches, reports, etc.\nFact-Ops: Ability to give factual opinions and explanations like seeking recommendations, seeking advice, opinions, explanations, etc.\nContent: Ability to make content accessible likeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/human-eval.","first_N":5,"first_N_keywords":["expert-generated","expert-generated","monolingual","original","Hindi"],"keywords_longer_than_N":true},
	{"name":"NeuripsHS","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ProgComp/NeuripsHS","creator_name":"Programming Competitions","creator_url":"https://huggingface.co/ProgComp","description":"Dataset comes In 3 parts:\n\nbase data: CulturaX/webscrapes\nInstruct: AlpacaGPT4 hindi\nFT: multiple for tone and dialect\n\n","first_N":5,"first_N_keywords":["translation","Hindi","English","Bihari","Assamese"],"keywords_longer_than_N":true},
	{"name":"English-Hindi-Translation","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Ketan3101/English-Hindi-Translation","creator_name":"Ketan Kumar","creator_url":"https://huggingface.co/Ketan3101","description":"This dataset is for translation or similar task.\nCredit: DanteAl97/hindi-english-translation\n","first_N":5,"first_N_keywords":["translation","English","Hindi","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"limmits-2024","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iAkashPaul/limmits-2024","creator_name":"Akash","creator_url":"https://huggingface.co/iAkashPaul","description":"\n\t\n\t\t\n\t\n\t\n\t\tIndic TTS dataset\n\t\n\n7 languages from IISC's LIMMITS Challenge 2024\n\n\t\n\t\t\n\t\n\t\n\t\tRoadmap\n\t\n\nTo use this for training VALLE-X & VoiceBox based TTS models\n\n\t\n\t\t\n\t\n\t\n\t\tFetch the tars directly\n\t\n\nwget -O 'Bengali_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Bengali_F.tar.gz'\nwget -O 'Chhattisgarhi_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Chhattisgarhi_F.tar.gz'\nwget -O 'English_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/English_F.tar.gz'\nwget -Oâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iAkashPaul/limmits-2024.","first_N":5,"first_N_keywords":["text-to-speech","English","Bengali","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"hindidataset","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kvrma/hindidataset","creator_name":"kvRma","creator_url":"https://huggingface.co/kvrma","description":"kvrma/hindidataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Hindi","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"multi-hatecheck","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/multi-hatecheck","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MultiHateClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHate speech detection dataset with binary\n                       (hateful vs non-hateful) labels. Includes 25+ distinct types of hate\n                       and challenging non-hate, and 11 languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nConstructed, Written\n\n\nReference\nhttps://aclanthology.org/2022.woah-1.15/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/multi-hatecheck.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul RÃ¶ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"sangraha","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/sangraha","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tSangraha\n\t\n\n\n  \n\n\nSangraha is the largest high-quality, cleaned Indic language pretraining data containing 251B tokens summed up over 22 languages, extracted from curated sources, existing multilingual corpora and large scale translations.\nMore information:\n\nFor detailed information on the curation and cleaning process of Sangraha, please checkout our paper on Arxiv;\nCheck out the scraping and cleaning pipelines used to curate Sangraha on GitHub;\n\n\n\t\n\t\n\t\n\t\tGetting Started\n\t\n\nForâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/sangraha.","first_N":5,"first_N_keywords":["text-generation","Assamese","Bengali","Gujarati","English"],"keywords_longer_than_N":true},
	{"name":"indic-align","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/indic-align","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tIndicAlign\n\t\n\nA diverse collection of Instruction and Toxic alignment datasets for 14 Indic Languages. The collection comprises of:\n\nIndicAlign - Instruct\nIndic-ShareLlama\nDolly-T\nOpenAssistant-T\nWikiHow\nIndoWordNet\nAnudesh\nWiki-Conv\nWiki-Chat\n\n\nIndicAlign - Toxic\nHHRLHF-T\nToxic-Matrix\n\n\n\nWe use IndicTrans2 (Gala et al., 2023) for the translation of the datasets. \nWe recommend the readers to check out our paper on Arxiv for detailed information on the curation process of theseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/indic-align.","first_N":5,"first_N_keywords":["text-generation","Assamese","Bengali","Gujarati","English"],"keywords_longer_than_N":true},
	{"name":"XMedbench","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/XMedbench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tMultilingual Medicine: Model, Dataset, Benchmark, Code\n\t\n\nCovering English, Chinese, French, Hindi, Spanish, Hindi, Arabic So far\n\n   ðŸ‘¨ðŸ»â€ðŸ’»Github â€¢ðŸ“ƒ Paper â€¢ ðŸ¤— ApolloCorpus â€¢ ðŸ¤— XMedBench \n      ä¸­æ–‡  |  English\n\n\n\n\n\n\t\t\n\t\tðŸŒˆ Update\n\t\n\n\n[2024.03.07] Paper released.\n[2024.02.12] ApolloCorpus and  XMedBench  is publishedï¼ðŸŽ‰\n[2024.01.23] Apollo repo is publishedï¼ðŸŽ‰\n\n\n\t\n\t\t\n\t\tResults\n\t\n\n   \n\n\t\n\t\t\n\t\tUsage\n\t\n\n\nZip File\nData category\n\n\n\t\n\t\t\n\t\tData:\n\t\n\n\nEN:\n\nMedQA-USMLE \nMedMCQA\nPubMedQA:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/XMedbench.","first_N":5,"first_N_keywords":["French","English","Spanish","Chinese","Arabic"],"keywords_longer_than_N":true},
	{"name":"Nadi_Indic466k_Instruct","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct","creator_name":"Convai Innovations","creator_url":"https://huggingface.co/convaiinnovations","description":"\n\t\n\t\t\n\t\tNadi_Indic466K_Instruct Dataset\n\t\n\nThe Nadi_Indic466K_Instruct dataset is the world's first coding dataset with 18 Indian language support, 466k rows and 142 Million total tokens. This dataset can be used by developers to build Indian coding language models (LLMs) for various programming languages.\nQ-LoRA based SFT/PPO/DPO fine-tuning can be done on the dataset in LLAMA-2 or Mistral or any opens-soure LLM for text generation.\nThe dataset was carefully curated such that the coding partâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct.","first_N":5,"first_N_keywords":["text-generation","Hindi","Panjabi","Bengali","Tamil"],"keywords_longer_than_N":true},
	{"name":"English-Hinglish","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rvv-karma/English-Hinglish","creator_name":"Rahul Vishwakarma","creator_url":"https://huggingface.co/rvv-karma","description":"\n\t\n\t\t\n\t\tEnglish Hinglish\n\t\n\nEnglish to Hinglish Dataset processed from findnitai/english-to-hinglish.\nSources:\n\nHinglish TOP Dataset\nCMU English Dog\nHinGE\nPHINC\n\n","first_N":5,"first_N_keywords":["translation","text-generation","multilingual","translation","English"],"keywords_longer_than_N":true},
	{"name":"English-Hinglish-TOP","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rvv-karma/English-Hinglish-TOP","creator_name":"Rahul Vishwakarma","creator_url":"https://huggingface.co/rvv-karma","description":"\n\t\n\t\t\n\t\tEnglish Hinglish (TOP Dataset)\n\t\n\nThis dataset is generated from Hinglish-TOP Dataset.\nData distribution:\n\nTrain a. Human Generated - 6513 b. Synthetically generated - 170083  \nValidation a. Human Generated - 1390 b. Synthetically generated - 0  \nTest a. Human Generated - 6513 b. Synthetically generated - 0\n\n","first_N":5,"first_N_keywords":["translation","text-generation","multilingual","translation","English"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"Pontoon-Translations","keyword":"hindi","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\n\t\n\t\t\n\t\tDataset Card for Pontoon Translations\n\t\n\n\n\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\nSource strings are in English.\nTo avoid rows with values like \"None\" and \"N/A\" being interpreted as missing values, pass the keep_default_na parameter like this:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ayymen/Pontoon-Translations\", keep_default_na=False)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","crowdsourced","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"AyaRedTeaming","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/walledai/AyaRedTeaming","creator_name":"Walled AI","creator_url":"https://huggingface.co/walledai","description":"\n\t\n\t\t\n\t\tDataset Card for Aya Red-teaming\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe Aya Red-teaming dataset is a human-annotated multilingual red-teaming dataset consisting of harmful prompts in 8 languages across 9 different categories of harm with explicit labels for \"global\" and \"local\" harm.\n\n\n\n\n\n\nCurated by: Professional compensated annotators\nLanguages: Arabic, English, Filipino, French, Hindi, Russian, Serbian and Spanish\nLicense: Apache 2.0\nPaper: arxiv link\n\n\n\t\n\t\t\n\t\n\t\n\t\tHarm Categories:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/walledai/AyaRedTeaming.","first_N":5,"first_N_keywords":["English","Hindi","French","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \nBibTex\n@misc{lu2024languagecountslearnunlearn,\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \n      author={Taiming Lu and Philipp Koehn},\n      year={2024},\n      eprint={2406.13748},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2406.13748}, \n}\n\n","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"mv-ner-v0.1","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ditpoo/mv-ner-v0.1","creator_name":"ditpoo","creator_url":"https://huggingface.co/ditpoo","description":"ditpoo/mv-ner-v0.1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["token-classification","English","Hindi","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"rendered_xnli","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ernie-research/rendered_xnli","creator_name":"ernie-research","creator_url":"https://huggingface.co/ernie-research","description":"   \n\n\t\n\t\t\n\t\tDataset Card for rendered XNLI\n\t\n\n\nThis repository contains the rendered XNLI dataset evaluated in the paper Autoregressive Pre-Training on Pixels and Texts (EMNLP 2024). For detailed instructions on how to use the model, please visit our GitHub page.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{chai2024autoregressivepretrainingpixelstexts,\n  title = {Autoregressive Pre-Training on Pixels and Texts},\n  author = {Chai, Yekun and Liu, Qingyi and Xiao, Jingwu and Wang, Shuohuan and Sun, Yu and Wu, Hua}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ernie-research/rendered_xnli.","first_N":5,"first_N_keywords":["English","Japanese","Chinese","French","Russian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"MultiPICo","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo","creator_name":"MultilingualPerspectivistNLU","creator_url":"https://huggingface.co/Multilingual-Perspectivist-NLU","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMultiPICo (Multilingual Perspectivist Irony Corpus) is a disaggregated multilingual corpus for irony detection, containing 18,778 pairs of short conversations (post-reply) from Twitter (8,956) and Reddit (9,822), along with the demographic information of each annotator (age, nationality, gender, and so on). \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nIrony classification task using soft labels (i.e., distribution of annotations) or hard labels (i.e., aggregatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo.","first_N":5,"first_N_keywords":["Spanish","English","German","Arabic","Portuguese"],"keywords_longer_than_N":true},
	{"name":"hindi_VQA","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/damerajee/hindi_VQA","creator_name":"dame rajee","creator_url":"https://huggingface.co/damerajee","description":"\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThis dataset was filterd to be more  balanced and this dataset was processed to create sentence embeddings . The embeddings were generated using a pre-trained sentence transformer model. Then, KMeans clustering was performed on the embeddings to group similar answers together. Finally, t-SNE was applied to reduce the dimensionality of the embeddings for visualization purposes. The resulting plot shows the clusters of sentence embeddings, which can be used forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/damerajee/hindi_VQA.","first_N":5,"first_N_keywords":["visual-question-answering","Hindi","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Hindi-Captions","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/damerajee/Hindi-Captions","creator_name":"dame rajee","creator_url":"https://huggingface.co/damerajee","description":"\n\t\n\t\t\n\t\tDataset information\n\t\n\nThis dataset is primarily for training a image captioning model ,this model was filtered from damerajee/Hindi-LLaVA-CC3M-Pretrain-595K-3 to only include hindi captions \n\nThe first column Images contains images which are  224 pixels wide and 224 pixels tall\nThe second column Captions contains captions corresponding to the text\n\nThe Average Length of the captions\n\n","first_N":5,"first_N_keywords":["image-to-text","Hindi","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"indic_sts","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/indic_sts","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"\n\t\n\t\t\n\t\tDataset Card for Indic STS\n\t\n\nThis dataset is STS benchmark between English and 12 high-resource Indic languages. This was released as a part of Samanantar paper. Please refer to the paper for more details.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAvailable languages are: en-as, en-bn, en-gu, en-hi, en-kn, en-ml, en-mr, en-or, en-pa, en-ta, en-te, en-ur\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataset Fields\n\t\n\n\nlang_code: 2-digit ISO language code\nsource: The source from which the candidate sentence isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jaygala24/indic_sts.","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\nExample of loading:\ndataset = load_dataset(\"davidstap/NTREX\", \"rus_Cyrl\", trust_remote_code=True)\n\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe following languages are available:\n\n\t\n\t\t\nLanguage Code\nLanguage Name\n\n\n\t\t\nafr_Latn\nAfrikaans\n\n\namh_Ethi\nAmharic\n\n\narb_Arab\nArabic\n\n\naze_Latn\nAzerbaijani\nbak_Cyrl\nBashkir\n\n\nbel_Cyrl\nBelarusianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"indic-swim-ir-cross-lingual","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/indic-swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\n\t\n\t\t\n\t\tDataset Card for Indic SWIM-IR (Cross-lingual)\n\t\n\n\n\n\nThis is the cross-lingual Indic subset of the SWIM-IR dataset, where the query generated is in the Indo-European language and the passage is in English.\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\n\n\t\n\t\n\t\n\t\tWhat is SWIM-IR?\n\t\n\nSWIM-IR dataset is aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/indic-swim-ir-cross-lingual.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","machine-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"swim-ir-cross-lingual","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\n\t\n\t\t\n\t\tDataset Card for SWIM-IR (Cross-lingual)\n\t\n\n\n\n\nThis is the cross-lingual subset of the SWIM-IR dataset, where the query generated is in the target language and the passage is in English.\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\n\n\t\n\t\n\t\n\t\tWhat is SWIM-IR?\n\t\n\nSWIM-IR dataset is a synthetic multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","machine-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"swim-ir-monolingual","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/swim-ir-monolingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\n\t\n\t\t\n\t\tDataset Card for SWIM-IR (Monolingual)\n\t\n\n\n\n\nThis is the monolingual subset of the SWIM-IR dataset, where the query generated and the passage are both in the same language.\nA few remaining languages will be added in the upcoming v2 version of SWIM-IR. The dataset is available as CC-BY-SA 4.0.\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\n\n\t\n\t\n\t\n\t\tWhat is SWIM-IR?\n\t\n\nSWIM-IR dataset is a synthetic multilingual retrieval datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-monolingual.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"fact-check-bureau","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau","creator_name":"Younes","creator_url":"https://huggingface.co/NaughtyConstrictor","description":"\n\t\n\t\t\n\t\n\t\n\t\tFact-Check Retrieval Dataset\n\t\n\nThis dataset is designed to support the development and evaluation of fact-check retrieval pipelines. It is structured to work with FactCheckBureau, a tool for designing and evaluating fact-check retrieval pipelines. The dataset comprises a list of claims, fact-check articles, and precomputed embeddings for English and French fact-checks.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of the following files and directories:\n\narticles.csv:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau.","first_N":5,"first_N_keywords":["English","French","Portuguese","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"CaLMQA","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shanearora/CaLMQA","creator_name":"Shane Arora","creator_url":"https://huggingface.co/shanearora","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\nCaLMQA is a translation-free long-form question answering (LFQA) dataset spanning 23 high- to low-resource languages. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCaLMQA is a translation-free LFQA dataset with 51.7K questions from 23 languages, 11 high- to mid-resource and 12 low-resource.\nAll questions are culturally specific â€“ (1) they refer to concepts unique to one or a few cultures, such as\n\"Kuber iki umwami wa mbere wâ€™uburundi yitwa Ntare?\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shanearora/CaLMQA.","first_N":5,"first_N_keywords":["multilingual","Afar","Arabic","Baluchi","German"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"Benchmark-Testing","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shounakpaul95/Benchmark-Testing","creator_name":"Shounak Paul","creator_url":"https://huggingface.co/shounakpaul95","description":"shounakpaul95/Benchmark-Testing dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","summarization","translation","token-classification","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"webui-dom-snapshots","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\n\t\n\t\t\n\t\tDataset Card for WebUI DOM snapshots\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Gary Benson\nLanguages: Mostly English (87%);\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\nLicense: CC0 1.0 Universal\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots.","first_N":5,"first_N_keywords":["image-feature-extraction","reinforcement-learning","text-classification","multilingual","biglab/webui-7k"],"keywords_longer_than_N":true},
	{"name":"Suvach","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Vaishak11a/Suvach","creator_name":"N","creator_url":"https://huggingface.co/Vaishak11a","description":"\n\t\n\t\t\n\t\tData Description\n\t\n\nThis dataset consists of over 100k question answers in Hindi, with 1200 tokens per question on average. Questions are generated from Wikipedia pages (Page title and Chunks). The generated part of data contain Secret Context, Question, Choices, Answer, and Description.\nThe question will be accompanied with 4 Choices and one and only one of them would be the correct answer. For improving generation quality, a retrieval step is added to extract a chunk of text relevantâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Vaishak11a/Suvach.","first_N":5,"first_N_keywords":["question-answering","Hindi","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Uncensored-Alpaca-v01","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ShubhVenom/Uncensored-Alpaca-v01","creator_name":"Shubh Rajput","creator_url":"https://huggingface.co/ShubhVenom","description":"\n\t\n\t\t\n\t\tUncensored Alpaca Dataset: A New Frontier in Language Models\n\t\n\nThis dataset is a collection of uncensored prompts and responses in the Alpaca format. It aims to provide a diverse and unfiltered source of data for training language models, pushing the boundaries of what these models can understand and generate. \nWhat Makes This Dataset Different?\n\nUncensored: This dataset includes prompts and responses that touch upon topics that are often censored or avoided in traditional datasets.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ShubhVenom/Uncensored-Alpaca-v01.","first_N":5,"first_N_keywords":["text-generation","English","Hindi","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Uncensored-Alpaca","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/V3N0M/Uncensored-Alpaca","creator_name":"Shubh Rajput","creator_url":"https://huggingface.co/V3N0M","description":"\n\t\n\t\t\n\t\tUncensored Alpaca Dataset: A New Frontier in Language Models\n\t\n\nThis dataset is a collection of uncensored prompts and responses in the Alpaca format. It aims to provide a diverse and unfiltered source of data for training language models, pushing the boundaries of what these models can understand and generate. \nWhat Makes This Dataset Different?\n\nUncensored: This dataset includes prompts and responses that touch upon topics that are often censored or avoided in traditional datasets.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/V3N0M/Uncensored-Alpaca.","first_N":5,"first_N_keywords":["text-generation","English","Hindi","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"TinyJenna-Uncensored-v01","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/V3N0M/TinyJenna-Uncensored-v01","creator_name":"Shubh Rajput","creator_url":"https://huggingface.co/V3N0M","description":"\n\t\n\t\t\n\t\tUncensored Alpaca Dataset: A New Frontier in Language Models\n\t\n\nThis dataset is a collection of uncensored prompts and responses in the Alpaca format. It aims to provide a diverse and unfiltered source of data for training language models, pushing the boundaries of what these models can understand and generate. \nWhat Makes This Dataset Different?\n\nUncensored: This dataset includes prompts and responses that touch upon topics that are often censored or avoided in traditional datasets.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/V3N0M/TinyJenna-Uncensored-v01.","first_N":5,"first_N_keywords":["text-generation","English","Hindi","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Hindi_Fever","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIhnIndicRag/Hindi_Fever","creator_name":"AIHN Indic Rag Community","creator_url":"https://huggingface.co/AIhnIndicRag","description":"AIhnIndicRag/Hindi_Fever dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","arguana","Hindi"],"keywords_longer_than_N":true},
	{"name":"bitext_phinc_miners","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_phinc_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_phinc_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","Hindi","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"indic_sts","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/indic_sts","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n\t\n\t\t\n\t\tDataset Card for Indic STS\n\t\n\nThis dataset is STS benchmark between English and 12 high-resource Indic languages. This was released as a part of Samanantar paper. Please refer to the paper for more details.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAvailable languages are: en-as, en-bn, en-gu, en-hi, en-kn, en-ml, en-mr, en-or, en-pa, en-ta, en-te, en-ur\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataset Fields\n\t\n\n\nlang_code: 2-digit ISO language code\nsource: The source from which the candidate sentence isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/indic_sts.","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"long_context_hindi","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/damerajee/long_context_hindi","creator_name":"dame rajee","creator_url":"https://huggingface.co/damerajee","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nThis dataset was filtered from AI4BHarat dataset sangraha,which is the largest high-quality, cleaned Indic language pretraining data containing 251B tokens summed up over 22 languages, extracted from curated sources, existing multilingual corpora and large scale translations.\nThis dataset contains only  Hindi as of now \n\n\t\n\t\t\n\t\tInformation\n\t\n\n\nFirst this dataset is mainly for long context training \nThe minimum len is 6000 and maximum len is 3754718\n\n\n\t\n\t\t\n\t\tGetting startedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/damerajee/long_context_hindi.","first_N":5,"first_N_keywords":["text-generation","Hindi","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"mirage-bench-instruct","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/mirage-bench-instruct","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\n\t\n\t\t\n\t\tMIRAGE-Bench (Instruct)\n\t\n\nThis dataset contains the structured RAG outputs for queries in the train split of MIRAGE-Bench (or MIRACL) for 16 languages for five models:\n\ngpt-4o-azure                          (GPT-4o using Azure API)\nmeta-llama/Meta-Llama-3-70B-Instruct  (Llama-3-70B-Instruct using Anyscale API)\nmistralai/Mixtral-8x22B-Instruct-v0.1 (Mixtral-8x22B-Instruct using Anyscale API)\nmeta-llama/Meta-Llama-3-8B-Instruct   (Llama-3-8B-Instruct using vLLM)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/mirage-bench-instruct.","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","Bengali","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"IndicSentiment","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicSentiment","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA new, multilingual, and n-way parallel dataset for sentiment analysis in 13 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReferencehttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicSentimentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicSentiment.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"ILSUM-2.0","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ILSUM/ILSUM-2.0","creator_name":"Indian Language Summarization","creator_url":"https://huggingface.co/ILSUM","description":"\n\t\n\t\t\n\t\tDataset Card for \"ILSUM-2.0\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nILSUM-2.0 contains additional ~10K articles along with ILSUM-1.0 dataset. Along with Hindi, English, and Gujarati, which were part of ILSUM-1.0, Bengali is also introduced as part of ILSUM-20. dataset.\nThe dataset for this task is built using articles and headline pairs from several leading newspapers of the country. We provide >=10,000 news articles for each language. The task is to generate a meaningful fixed length summaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ILSUM/ILSUM-2.0.","first_N":5,"first_N_keywords":["summarization","text-generation","Hindi","Gujarati","Bengali"],"keywords_longer_than_N":true},
	{"name":"Indic_south_langs","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Logii33/Indic_south_langs","creator_name":"Logesh","creator_url":"https://huggingface.co/Logii33","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Logii33/Indic_south_langs.","first_N":5,"first_N_keywords":["translation","Hindi","Tamil","Malayalam","Telugu"],"keywords_longer_than_N":true},
	{"name":"nomiracl-instruct","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/nomiracl-instruct","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\n\t\n\t\t\n\t\tDataset Card for NoMIRACL (EMNLP 2024 Findings Track)\n\t\n\n\n\t\n\t\t\n\t\tQuick Overview\n\t\n\nThis repository contains the fine-tuning (training & development split) of the NoMIRACL instruct dataset for fine-tuning LLMs on multilingual relevance assessment.\nThe training dataset is a binary classification task; they need to explicitly output either Yes, answer is present or I don't know. \nThe dataset contains training pairs from all 18 languages for both splits: relevant & non-relevant.\nimportâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/miracl/nomiracl-instruct.","first_N":5,"first_N_keywords":["text-classification","text-generation","Arabic","Bengali","German"],"keywords_longer_than_N":true},
	{"name":"XL-HeadTags","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/faisaltareque/XL-HeadTags","creator_name":"Faisal Tareque Shohan","creator_url":"https://huggingface.co/faisaltareque","description":"\n\t\n\t\t\n\t\tDataset Card for XL-HeadTags Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Source\n\t\n\nWe have used M3LS and XL-Sum as source for this dataset.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n We provide XL-HeadTags, a large-scale news headline and tags generation dataset. The dataset consists of 20 languages across six diverse language families. It contains 415K news headline-article pairs with auxiliary information such as image captions, topic words (read more).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nOneâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/faisaltareque/XL-HeadTags.","first_N":5,"first_N_keywords":["summarization","sentence-similarity","English","Portuguese","Spanish"],"keywords_longer_than_N":true},
	{"name":"parsed_hindi_dictionary","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/utkarsh2299/parsed_hindi_dictionary","creator_name":"Utkarsh Pathak","creator_url":"https://huggingface.co/utkarsh2299","description":"Parsed Hindi Dictionary\n","first_N":5,"first_N_keywords":["translation","Hindi","apache-2.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"Multi-Opthalingua","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AAAIBenchmark/Multi-Opthalingua","creator_name":"AAAIBenchmark","creator_url":"https://huggingface.co/AAAIBenchmark","description":"\n\t\n\t\t\n\t\tCite\n\t\n\nAccepted to AAAI 2025 (https://openreview.net/group?id=AAAI.org/2025/Conference#tab-recent-activity)\nMulti-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs:\n@misc{restrepo2024multiophthalinguamultilingualbenchmarkassessing,\n      title={Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs}, \n      author={David Restrepo and Chenwei Wu and Zhengxu Tang and Zitao Shuai and Thaoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AAAIBenchmark/Multi-Opthalingua.","first_N":5,"first_N_keywords":["question-answering","Hindi","Chinese","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"flores","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/flores","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FloresBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nFLORES is a benchmark dataset for machine translation between English and low-resource languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNon-fiction, Encyclopaedic, Written\n\nReference\nhttps://huggingface.co/datasets/facebook/flores\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FloresBitextMining\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/flores.","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Achinese","Mesopotamian Arabic"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NTREXBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNTREX is a News Test References dataset for Machine Translation Evaluation, covering translation from English into 128 languages. We select language pairs according to the M2M-100 language grouping strategy, resulting in 1916 directions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/davidstap/NTREX\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","translated","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"IN22-Conv","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IN22-Conv","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IN22ConvBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Conv is a n-way parallel conversation domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nSocial, Spoken, Fiction, Spoken\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Conv\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Conv.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"IN22-Gen","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IN22-Gen","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IN22GenBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Gen is a n-way parallel general-purpose multi-domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Legal, Government, News, Religious, Non-fiction, Written\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Gen\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Gen.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"multilingual-llava-bench-in-the-wild","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\tMultilingual LLaVA Bench in the Wild\n\t\n\n\n\t\n\t\t\n\t\tNote that this is a copy from https://huggingface.co/datasets/MBZUAI/multilingual-llava-bench-in-the-wild\n\t\n\nIt was created due to issues in the original repo. It also includes the image features and has a uniform and joined structure.\nIf you use this dataset, please cite the original authors:\n@article{PALO2024,\n  title={Palo: A Large Multilingual Multimodal Language Model},\n  author={Maaz, Muhammad and Rasheed, Hanoona and Shakerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild.","first_N":5,"first_N_keywords":["Arabic","Bengali","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"xm3600","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\nIt also includes the image features as PIL Image and has a uniform andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xm3600_1k","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600 - 1K Split\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a 1K split of XM3600!\n\t\n\nFor this, weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"x-fact","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"x-fact\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while the languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact.","first_N":5,"first_N_keywords":["text-classification","Arabic","Bengali","Spanish","Persian"],"keywords_longer_than_N":true},
	{"name":"from-one-to-many-toxicity-mitigation","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation","creator_name":"Luiza Pozzobon","creator_url":"https://huggingface.co/luizapzbn","description":"\n\t\n\t\t\n\t\n\t\n\t\tFrom One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\n\t\n\n[arxiv][code][data]\nData accompanying the paper \"From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\" accepted to ACL Findings 2024.\nAbstract: To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, itâ€™s crucial our safety measures keep pace. Recognizing thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation.","first_N":5,"first_N_keywords":["text-generation","text-classification","English","Portuguese","Hindi"],"keywords_longer_than_N":true},
	{"name":"IndicVarna-100k","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dynopii/IndicVarna-100k","creator_name":"Dynopii Inc","creator_url":"https://huggingface.co/dynopii","description":"\n\t\n\t\t\n\t\tIndicVarna for Callchimp.ai (a Dynopii product)\n\t\n\nWe introduce IndiVarna which was prepared by using Google Translate on the dair-ai/emotion dataset to get the samples there translated to the top 10 most commonly used Indian languages.\nThis dataset contains 10000 samples of each of the 10 languages supported.\nThe dataset further translated the labels in the dataset to 3 label sentiments - 0: Negative, 1: Neutral and 2: Positive. Each language has 3334 samples of each category ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dynopii/IndicVarna-100k.","first_N":5,"first_N_keywords":["text-classification","translation","sentence-similarity","fill-mask","text-generation"],"keywords_longer_than_N":true},
	{"name":"News_Hinglish_English","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/suyash2739/News_Hinglish_English","creator_name":"suyash agarwal","creator_url":"https://huggingface.co/suyash2739","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a collection of text conversations in Hinglish (code mixing between Hindi-English) and their corresponding English versions. Can be used for Translating between the two.\nThis dataset was generated by translating the first 5000 news content from the Inshorts Dataset - English News [https://www.kaggle.com/datasets/shivamtaneja2304/inshorts-dataset-english]\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n\nHinglish\nEnglish\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nAn example from the json fileâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/suyash2739/News_Hinglish_English.","first_N":5,"first_N_keywords":["translation","machine-generated","crowdsourced","multilingual","translation"],"keywords_longer_than_N":true},
	{"name":"hindi-english-code-mixed","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ar5entum/hindi-english-code-mixed","creator_name":"Astitva Jaiswal","creator_url":"https://huggingface.co/ar5entum","description":"This dataset was compiled from various open sources online including some asr datasets and some percenteage of data generated using prompt engineering on generative llms. Some sources used are listed down below:\n\nhttps://github.com/l3cube-pune/code-mixed-nlp?tab=readme-ov-file\nhttps://github.com/piyushmakhija5/hinglishNorm\nhttps://github.com/ishan00/translation-for-code-switching-acl/tree/master\n\n","first_N":5,"first_N_keywords":["Hindi","English","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"shiksha","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SPRINGLab/shiksha","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","description":"\n\t\n\t\t\n\t\tShiksha Dataset\n\t\n\nThis is a Technical Domain focused Translation Dataset for 8 Indian Languages. It consists of more than 2.5 million rows of translation pairs between all 8 languages and English.\nThis data has been derived from raw NPTEL documents. More information on this can be found in our paper: https://arxiv.org/abs/2412.09025\nIf you use this data in your work, please cite us:\n@misc{joglekar2024shikshatechnicaldomainfocused,\n      title={Shiksha: A Technical Domain focusedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/shiksha.","first_N":5,"first_N_keywords":["translation","Hindi","Bengali","Tamil","Telugu"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"Todo - Write dataset card\n","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"gita_translations_and_commentaries","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jhaabhi/gita_translations_and_commentaries","creator_name":"Abhishek Jha","creator_url":"https://huggingface.co/jhaabhi","description":"jhaabhi/gita_translations_and_commentaries dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","Hindi","Sanskrit","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"hindi_parsed_dict_1lakh","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/utkarsh2299/hindi_parsed_dict_1lakh","creator_name":"Utkarsh Pathak","creator_url":"https://huggingface.co/utkarsh2299","description":"utkarsh2299/hindi_parsed_dict_1lakh dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Hindi","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"G15","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/brahmairesearch/G15","creator_name":"BRAHMAI Research","creator_url":"https://huggingface.co/brahmairesearch","description":"\n\t\n\t\t\n\t\tG15 - v0.1\n\t\n\nG15-v0.1 is a part of G-series datasets which are pre-formatted in ChatML template.\nThese datasets are useful for quickly finetuning LLMs for better responses.\n\n\nThe G15-v0.1 is a combination of the following datasets:\n\nOpenHermes-2.5\nMetaMathQA (100k entries)\nA section of our in-house dataset used to finetune Cerberus-v0.1\n\nThis dataset is to be used on smaller LLMs (1B - 7B) to increase their response quality.\n\nFor queries please reach out to us at hello@brahmai.in\n","first_N":5,"first_N_keywords":["text-generation","Hindi","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"G15","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/brahmairesearch/G15","creator_name":"BRAHMAI Research","creator_url":"https://huggingface.co/brahmairesearch","description":"\n\t\n\t\t\n\t\tG15 - v0.1\n\t\n\nG15-v0.1 is a part of G-series datasets which are pre-formatted in ChatML template.\nThese datasets are useful for quickly finetuning LLMs for better responses.\n\n\nThe G15-v0.1 is a combination of the following datasets:\n\nOpenHermes-2.5\nMetaMathQA (100k entries)\nA section of our in-house dataset used to finetune Cerberus-v0.1\n\nThis dataset is to be used on smaller LLMs (1B - 7B) to increase their response quality.\n\nFor queries please reach out to us at hello@brahmai.in\n","first_N":5,"first_N_keywords":["text-generation","Hindi","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"voices-of-civilizations","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sander-wood/voices-of-civilizations","creator_name":"Shangda Wu (Sander Wood)","creator_url":"https://huggingface.co/sander-wood","description":"\n\t\n\t\t\n\t\tVoices of Civilizations (VoC)\n\t\n\nVoices of Civilizations (VoC) is the first multilingual QA benchmark designed to assess audio LLMsâ€™ cultural comprehension using full-length music recordings. VoC spans:\n\n38 languages (including zh, en, hi, es, fr, ja, ko, ar, sw, bn, de, pt, ru, etc.)\n380 tracks drawn from traditional and regional music\n860 multiple-choice questions probing four dimensions: language, region, mood, and theme\n\nVoC exposes modelsâ€™ biases and weaknesses onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sander-wood/voices-of-civilizations.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"hindi-end-of-utterance-detection","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yashsoni78/hindi-end-of-utterance-detection","creator_name":"Yash Soni","creator_url":"https://huggingface.co/yashsoni78","description":"\n\t\n\t\t\n\t\tHindi Conversational End-of-Utterance (EOU) Dataset\n\t\n\nA high-quality, balanced dataset of 1000 Hindi conversational phrases labeled for end-of-utterance detection. This dataset is designed for training models to detect whether a speaker has finished their turn in a dialogue.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains short conversational phrases in Hindi, each labeled as either:\n\n1 (EOU): A complete utterance or turn (e.g., a complete question, answer, command, or statement).\n0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yashsoni78/hindi-end-of-utterance-detection.","first_N":5,"first_N_keywords":["Hindi","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"ssi-speech-emotion-recognition","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stapesai/ssi-speech-emotion-recognition","creator_name":"Stapes AI","creator_url":"https://huggingface.co/stapesai","description":"\n\t\n\t\t\n\t\tDataset Card for SSI: Speech Emotion Recognition - Stapes AI\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Format for Audio Files\n\t\n\nThis is the format for the audio files in the dataset. We'll open-source the dataset soon.\n\n\t\n\t\t\n\t\tGender\n\t\n\n\nM - Male\nF - Female\n\n\n\t\n\t\t\n\t\tAge Group\n\t\n\n\nCH - Child (0-12)\nTE - Teenager (13-19)\nAD - Adult (20-60)\nSE - Senior (60+)\nUNK - Unknown\n\n\n\t\n\t\t\n\t\tUtterance Type\n\t\n\n\nSEN: Sentence\nWOR: Word\nPHR: Phrase\n\n\n\t\n\t\t\n\t\tSentence\n\t\n\n\nDFA: \"Don't Forget Aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/stapesai/ssi-speech-emotion-recognition.","first_N":5,"first_N_keywords":["English","Hindi","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEDataset","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   ðŸ“ƒ Paper â€¢ ðŸŒ Demo â€¢ ðŸ¤— ApolloMoEDataset â€¢ ðŸ¤— ApolloMoEBench  â€¢ ðŸ¤— Models  â€¢ðŸŒ Apollo  â€¢ ðŸŒ ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tðŸŒˆ Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedï¼ðŸŽ‰\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEBench","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   ðŸ“ƒ Paper â€¢ ðŸŒ Demo â€¢ ðŸ¤— ApolloMoEDataset â€¢ ðŸ¤— ApolloMoEBench  â€¢ ðŸ¤— Models  â€¢ðŸŒ Apollo  â€¢ ðŸŒ ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tðŸŒˆ Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedï¼ðŸŽ‰\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"hindi_tweet_sampled_dataset","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sumanpaudel1997/hindi_tweet_sampled_dataset","creator_name":"Suman Paudel","creator_url":"https://huggingface.co/sumanpaudel1997","description":"sumanpaudel1997/hindi_tweet_sampled_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Hindi","apache-2.0","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"product-database","keyword":"hindi","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\n\t\n\t\t\n\t\tOpen Food Facts Database\n\t\n\n\n\t\n\t\t\n\t\tWhat is ðŸŠ Open Food Facts?\n\t\n\n\n\t\n\t\t\n\t\tA food products database\n\t\n\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\n\n\t\n\t\t\n\t\tMade by everyone\n\t\n\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"global-festivals-translated","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/azminetoushikwasi/global-festivals-translated","creator_name":"Azmine Toushik Wasi","creator_url":"https://huggingface.co/azminetoushikwasi","description":"azminetoushikwasi/global-festivals-translated dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"audio-data","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SachinTelecmi/audio-data","creator_name":"Sachin Mohanty","creator_url":"https://huggingface.co/SachinTelecmi","description":"SachinTelecmi/audio-data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Hindi","mit","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"m-ArenaHard","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/m-ArenaHard","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for m-ArenaHard\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-ArenaHard.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"indic_sentiment_analyzer","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dhruv0808/indic_sentiment_analyzer","creator_name":"Dhruv Bhatnagar","creator_url":"https://huggingface.co/dhruv0808","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n\t\n\t\t\n\t\tMultilingual Sentiment Analysis Dataset for Indian Languages\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository contains a comprehensive sentiment analysis dataset covering 11 Indian languages and English. The dataset is designed to support sentiment analysis tasks across multiple domains and languages, making it valuable for developing multilingual sentiment analysis models and applications.\n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\n\nEnglish (en) - Original\nHindi (hi)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/dhruv0808/indic_sentiment_analyzer.","first_N":5,"first_N_keywords":["English","Hindi","Telugu","Tamil","Kannada"],"keywords_longer_than_N":true},
	{"name":"IndicReviewsClusteringP2P","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicReviewsClusteringP2P","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicReviewsClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of reviews from IndicSentiment dataset. Clustering of 14 sets on the generic categories label.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicReviewsClusteringP2P\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicReviewsClusteringP2P.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"IndicCrosslingualSTS","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicCrosslingualSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicCrosslingualSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a Semantic Textual Similarity testset between English and 12 high-resource Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Non-fiction, Web, Spoken, Government, Written, Spoken\nReference\nhttps://huggingface.co/datasets/jaygala24/indic_sts\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicCrosslingualSTS.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","expert-annotated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"mmmlu_lite","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","description":"\n\t\n\t\t\n\t\tMMMLU-Lite\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is about 10% ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSIB-Fleurs\n\t\n\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \nThe topics are:\n\nScience/Technology\nTravel\nPolitics\nSports\nHealth\nEntertainment\nGeography\n\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset creation\n\t\n\nThis dataset processes and mergesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","description":"\n\t\n\t\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\nWe translated the MMLUâ€™s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increasesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"MSTS","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/felfri/MSTS","creator_name":"Felix Friedrich","creator_url":"https://huggingface.co/felfri","description":"\n\t\n\t\t\n\t\tDisclaimer\n\t\n\nThe MSTS dataset contains content that may be offensive or upsetting in nature. Topics include, but are not limited to, discriminatory language and discussions of abuse, violence, self-harm, exploitation, and other potentially upsetting subject matter. \nPlease only engage with the data in accordance with your own personal risk tolerance. The data are intended for research purposes, especially research that can make models less harmful.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/felfri/MSTS.","first_N":5,"first_N_keywords":["image-text-to-text","English","Arabic","French","German"],"keywords_longer_than_N":true},
	{"name":"hindi-malayalam-dataset","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YADHU1234/hindi-malayalam-dataset","creator_name":"YADHU","creator_url":"https://huggingface.co/YADHU1234","description":"\n\t\n\t\t\n\t\tHindi-Malayalam Dataset\n\t\n\nThis dataset contains parallel translations between Hindi and Malayalam, extracted from the bible_para dataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguages: Hindi (hin_Deva) and Malayalam (mal_Mlym)\nSource: nllb\nLicense: CC BY 4.0\nUse Cases: Machine translation, linguistic research.\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n\n\t\n\t\t\nHindi\nMalayalam\n\n\n\t\t\nà¤¨à¤®à¤¸à¥à¤¤à¥‡\nà´¹à´²àµ‹\n\n\n\t\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThe dataset is licensed under the CC BY 4.0 License.\n","first_N":5,"first_N_keywords":["cc-by-4.0","1M - 10M","parquet","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"xtreme-up-semantic-parsing","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for afrixnli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSee XTREME-UP GitHub\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 20 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata = load_dataset('Davlan/xtreme-up-semantic-parsing', 'yor') \n# Please, specify the language code\n# A data point example is below:\n{\n\"id\": \"3231323330393336\",\n\"split\": \"test\",\n\"intent\": \"IN:GET_REMINDER\",\n\"locale\": \"en\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing.","first_N":5,"first_N_keywords":["text-classification","multilingual","Amharic","Belarusian","Bengali"],"keywords_longer_than_N":true},
	{"name":"aya_redteaming_consitutional","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pbevan11/aya_redteaming_consitutional","creator_name":"Peter J. Bevan","creator_url":"https://huggingface.co/pbevan11","description":"\n\t\n\t\t\n\t\tDataset Card for Aya Red-teaming-constiutional\n\t\n\nThis dataset is an extended version of CohereForAI/aya_redteaming, with added targeted constitutional principles, aiming to allow multilingual constitional AI using the Aya Red team prompts.\nWe take the Anthropic constitutional principles and manually cut out the existing harms so that we can dynamically insert harms specific to our red team prompts.\nThere are 16 critiques and 16 revisions for each red-team prompt, each targeting theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pbevan11/aya_redteaming_consitutional.","first_N":5,"first_N_keywords":["English","Hindi","French","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"Roleplay-Hindi","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Hindi","creator_name":"Min Si Thu","creator_url":"https://huggingface.co/jojo-ai-mst","description":"\n\t\n\t\t\n\t\tRolePlay-Hindi\n\t\n\nRoleplay-Hindi Dataset is a dataset for roleplaying in the Hindi language for Large Language Model.\nThe base dataset is GPTeacher role play dataset by teknium 1, which can be found under this link, released under MIT License. The dataset is then translated into respective languages. The translation process is powered by Google Translate, using cloud translation API. \nFor more information and other language datasets for roleplay, it can be found at this github repo.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Hindi.","first_N":5,"first_N_keywords":["text-generation","Hindi","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"dhpileIN","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aloobun/dhpileIN","creator_name":"aloobun","creator_url":"https://huggingface.co/aloobun","description":"@misc{aralikatte2023varta,\n      title={V\\=arta: A Large-Scale Headline-Generation Dataset for Indic Languages}, \n      author={Rahul Aralikatte and Ziling Cheng and Sumanth Doddapaneni and Jackie Chi Kit Cheung},\n      year={2023},\n      eprint={2305.05858},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n","first_N":5,"first_N_keywords":["Bengali","Gujarati","Hindi","Kannada","Tamil"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU-Lite","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 16 languages, including English. It is \"lite\" version of the original Global-MMLU dataset ðŸŒ.\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \nNOTE: Of the 16 languages presently included in Global-MMLU-Lite, 15â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite.","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"vqa","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldcuisines/vqa","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\n\t\n\t\t\n\t\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\n\t\n\n\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 October 2024.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa.","first_N":5,"first_N_keywords":["multilingual","English","Indonesian","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Achinese","Adyghe"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/include-lite-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tINCLUDE-lite (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-lite-44.","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Multilingal-sakalt-data","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"ãƒžãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚mitãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ã™ã€‚\n","first_N":5,"first_N_keywords":["text-generation","Abkhaz","Bhojpuri","Chechen","Czech"],"keywords_longer_than_N":true},
	{"name":"kurage_training_data","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/kurage_training_data","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"lightblue/kurage_training_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Arabic","English","Spanish","Hindi","Indonesian"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Achinese","Adyghe"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/include-base-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tINCLUDE-base (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-base-44.","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Deltacorpus_1.1","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\n[!NOTE]\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, PortoroÅ¾, Slovenia).\nChanges in version 1.1: \n\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \n\nSVM classifier trained on Universalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1.","first_N":5,"first_N_keywords":["token-classification","multilingual","Afrikaans","Albanian","Amharic"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xmmmu","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xmmmu","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"neulab/PangeaBench-xmmmu dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","multiple-choice","Arabic","French"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xchat","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xchat","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"neulab/PangeaBench-xchat dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["visual-question-answering","Chinese","English","Hindi","Indonesian"],"keywords_longer_than_N":true},
	{"name":"hi-rag-cot","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaeyong2/hi-rag-cot","creator_name":"jeongjaeyong","creator_url":"https://huggingface.co/jaeyong2","description":">>> from datasets import load_dataset\n\n>>> ds = load_dataset(\"jaeyong2/hi-rag-cot\", split=\"train\")\n>>> ds\nDataset({\n    features: ['context', 'Question', 'RAW Ground Truth', 'Thinking', 'Final Answer'],\n    num_rows: 19083\n})\n\n\n\t\n\t\t\n\t\n\t\n\t\tDevelopment Process\n\t\n\n\nsource dataset from Cohere/wikipedia-22-12-hi-embeddings\nWe used Qwen/Qwen2-72B-Instruct model to generate answer with COT.\n\n\n\t\n\t\n\t\n\t\tLicense\n\t\n\n\nQwen/Qwen2.5-72B-Instruct :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jaeyong2/hi-rag-cot.","first_N":5,"first_N_keywords":["Hindi","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"sangraha-hin-100000","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/alex-joseph/sangraha-hin-100000","creator_name":"Alex Joseph","creator_url":"https://huggingface.co/alex-joseph","description":"This is a portion of AI4Bharat's Sangraha Hindi Corpus.\nIt contains the first 10,00,000 lines of the corpus.\n","first_N":5,"first_N_keywords":["Hindi","mit","1M - 10M","text","Text"],"keywords_longer_than_N":true},
	{"name":"indicvoices_pa_tagged_transcripts","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_pa_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"mc-translation","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/efederici/mc-translation","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","description":"This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.\n\n\t\n\t\t\n\t\tWhy This Dataset?\n\t\n\nTranslation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specializedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation.","first_N":5,"first_N_keywords":["translation","English","Swahili","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"indicvoices_mr_tagged_transcripts","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_mr_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"indicvoices_bn_tagged_transcripts","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_bn_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"ghazals-nazms-shers-rekhta","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Pranjalya/ghazals-nazms-shers-rekhta","creator_name":"Pranjalya Tiwari","creator_url":"https://huggingface.co/Pranjalya","description":"Pranjalya/ghazals-nazms-shers-rekhta dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Hindi","Urdu","English","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"hindiTabQA","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vaishali/hindiTabQA","creator_name":"Vaishali Pal","creator_url":"https://huggingface.co/vaishali","description":"\n\t\n\t\t\n\t\tDataset Card for \"hindiTabQA\"\n\t\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nimport pandas as pd\nfrom datasets import load_dataset\n\nhinditableQA = load_dataset(\"vaishali/hindiTabQA\")\n\nfor sample in hinditableQA['train']:\n  question = sample['question']\n  input_table = pd.read_json(sample['table'], orient='split')\n  answer = pd.read_json(sample['answer'], orient='split')\n\n\n\t\n\t\n\t\n\t\tBibTeX entry and citation info\n\t\n\n@inproceedings{pal-etal-2024-table,\n    title = \"Table Question Answering for Low-resourced {I}ndicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vaishali/hindiTabQA.","first_N":5,"first_N_keywords":["table-question-answering","Hindi","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\nsource: the source sentence.\nchosen: the preferred translation.\nreject: the dis-preferred translation.\ndirections: the translation direction.\n@misc{xu2024xalmaplugplay,\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\n      year={2024},\n      eprint={2410.03115}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"prompt-injection-multilingual","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rikka-snow/prompt-injection-multilingual","creator_name":"Le Xuan Hoang","creator_url":"https://huggingface.co/rikka-snow","description":"rikka-snow/prompt-injection-multilingual dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Vietnamese","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"indicvoices_hi_tagged_transcripts","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\n\t\n\t\t\n\t\tDataset Card for indicvoices_hi_tagged_transcripts\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Hindi.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nThe dataset was collected through automated processes and manual transcription.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains:\n\nAudio files (.wav format)\nTranscriptions\nDuration informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts.","first_N":5,"first_N_keywords":["automatic-speech-recognition","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Hierarchical_Text_Classification_Intent_Classification","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AkashPrasadMishra/Hierarchical_Text_Classification_Intent_Classification","creator_name":"Akash Prasad Mishra","creator_url":"https://huggingface.co/AkashPrasadMishra","description":"AkashPrasadMishra/Hierarchical_Text_Classification_Intent_Classification dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Hindi","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_hi","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_hi","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoFEVER dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_hi","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_hi","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_hi","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_hi","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoSciFact dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_hi","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoArguAna dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_hi","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Hindi"],"keywords_longer_than_N":true},
	{"name":"mu-shroom","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/mu-shroom","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\n\t\n\t\t\n\t\tThe Mu-SHROOM dataset for Multilingual Hallucination and Overgeneration detection.\n\t\n\nMu-SHROOM: Multilingual Shared-task on Hallucinations and Related Observable Overgeneration Mistakes and Related Observable Overgeneration Mistakes\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMu-SHROOM is a multilingual dataset for detecting hallucination spans in LLM outputs across 14 languages. It was created for SemEval-2025 Task 3.\ndisclaimer: Mu-SHROOM is not properly a fact-checking dataset, but we mark isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/mu-shroom.","first_N":5,"first_N_keywords":["token-classification","fact-checking","Arabic","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"vqa-v1.1","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldcuisines/vqa-v1.1","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\n\t\n\t\t\n\t\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\n\t\n\n\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 October 2024.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa-v1.1.","first_N":5,"first_N_keywords":["multilingual","English","Indonesian","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"incoherent-text-dataset","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SuccubusBot/incoherent-text-dataset","creator_name":"Succubus âœ¨","creator_url":"https://huggingface.co/SuccubusBot","description":"\n\t\n\t\t\n\t\tIncoherent Text Dataset\n\t\n\nThis dataset is designed for training models to detect incoherence in text. It includes various types of incoherence, such as grammatical errors, word soup, random words, and run-on sentences.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguages: English, Spanish, French, German, Chinese, Japanese, Russian, Arabic, Hindi\nSize: ~27,000 samples\nTypes of Incoherence: Grammatical errors, word soup, random words, run-ons, random tokens, random bytes.\n\n\n\t\n\t\t\n\t\tData Fieldsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SuccubusBot/incoherent-text-dataset.","first_N":5,"first_N_keywords":["text-classification","English","Spanish","French","German"],"keywords_longer_than_N":true},
	{"name":"TAFSIL","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/prachuryyaIITG/TAFSIL","creator_name":"Prachuryya Kaushik","creator_url":"https://huggingface.co/prachuryyaIITG","description":"\n\t\n\t\t\n\t\tTAFSIL: Taxonomy Adaptable Fine-grained Entity Recognition through Distant Supervision for Indian Languages\n\t\n\nTAFSIL is a taxonomy-adaptable Fine-grained Entity Recognition (FgER) framework designed to create FgER datasets in six Indian languages: Hindi (hi), Marathi (mr), Sanskrit (sa), Tamil (ta), Telugu (te), and Urdu (ur). These languages belong to two major language familiesâ€”Indo-European and Dravidianâ€”and are spoken by over a billion people worldwide.\nTAFSIL leverages the highâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/prachuryyaIITG/TAFSIL.","first_N":5,"first_N_keywords":["token-classification","Hindi","Marathi","Sanskrit","Tamil"],"keywords_longer_than_N":true},
	{"name":"devanagari_and_roman_digits","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rockerritesh/devanagari_and_roman_digits","creator_name":"Sumit Yadav","creator_url":"https://huggingface.co/rockerritesh","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThe OCR Digits Dataset consists of 20,000 high-quality images of digit combinations captured under various conditions. This dataset is designed to support research in optical character recognition, particularly for multi-digit recognition tasks.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nBibTeX:\n@dataset{SumitYadav2025OCRDigits,\n  author       = {[Sumit Yadav]},\n  title        = {OCR Digits Dataset: A Collection of 20,000 Multi-Digit(Roman andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rockerritesh/devanagari_and_roman_digits.","first_N":5,"first_N_keywords":["object-detection","Nepali","Hindi","English","mit"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","description":"\n\n\n\t\n\t\t\n\t\tðŸ”· Accepted in NAACL Proceedings (2025) ðŸ”·\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval ðŸ“š [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"tokenizer-robustness-mmlu","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-mmlu","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","description":"\n\t\n\t\t\n\t\tTokenizer Robustness MMLU Dataset\n\t\n\nThis dataset contains MMLU-formatted questions and answers designed to test tokenizer robustness across different text formats and languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of the same questions presented in 6 different formats, with both test (20 questions) and development (5 questions) sets:\n\noriginal - Standard formatted questions\nminor_spelling_errors - Questions with minor misspellings\nspoken_language - Questions in casualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-mmlu.","first_N":5,"first_N_keywords":["English","Russian","Chinese","Japanese","German"],"keywords_longer_than_N":true},
	{"name":"IGB_XQuAD","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IGB_XQuAD","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"VarunGumma/IGB_XQuAD dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"IGB_Flores_enxx","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IGB_Flores_enxx","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"VarunGumma/IGB_Flores_enxx dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"IGB_Flores_xxen","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IGB_Flores_xxen","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"VarunGumma/IGB_Flores_xxen dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"indiantranslator","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nashrah18/indiantranslator","creator_name":"Nashrah Shaikh","creator_url":"https://huggingface.co/nashrah18","description":"nashrah18/indiantranslator dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","English","Hindi","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"PolyGuardPrompts","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","description":"\n\t\n\t\t\n\t\tPolyGuard: A Multilingual Safety Moderation Tool for 17 Languages\n\t\n\nAbstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts.","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"Language_Identification_v1","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Process-Venue/Language_Identification_v1","creator_name":"ProcessVenue","creator_url":"https://huggingface.co/Process-Venue","description":"\n\t\n\t\t\n\t\tDataset Card for Language Identification Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA comprehensive dataset for Indian language identification and text classification. The dataset contains text samples across 10 major Indian languages, making it suitable for developing language identification systems and multilingual NLP applications.\n\n\t\n\t\t\n\t\tLanguages and Distribution\n\t\n\nLanguage Distribution:\nUrdu         1000\nHindi        1000\nOdia         1000\nTamil        1000\nKannada      1000\nBengaliâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Process-Venue/Language_Identification_v1.","first_N":5,"first_N_keywords":["text-classification","text-generation","Hindi","Urdu","Bengali"],"keywords_longer_than_N":true},
	{"name":"u-sticker","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/metchee/u-sticker","creator_name":"Metilda Chee","creator_url":"https://huggingface.co/metchee","description":"\n\t\n\t\t\n\t\tU-Sticker\n\t\n\nUser-Sticker is a stickers dataset with multi-domain conversations.\nFeatures of U-Sticker:\n\nMulti-domain interactions âœ…\nTemporal âœ…\nUser information âœ…\n370.2k stickers âœ… (104k unique)\n22.6k users âœ…\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nU-Sticker contains three files:\n\nConversation files: 1 to 67.json\nDomain mapping files idx_to_domain.txt.\nSticker files.\n\n\nSticker files are available here and Baidu Cloud.\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tConversation file\n\t\n\n\nEmpty lines areâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/metchee/u-sticker.","first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Turkish"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gpt4o_gen","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gpt4o_gen","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gpt4o_gen dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"Saka-Alpaca-v1","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Saka-Alpaca-v1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"https://chatgpt.com\n","first_N":5,"first_N_keywords":["text-generation","Swedish","Norwegian","Finnish","German"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"WÅ‚odzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy Itâ€™s Important\n\t\n\n\nEnhances Trust: For readers andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"Hinglish-Preference-Humanized-DPO","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fhai50032/Hinglish-Preference-Humanized-DPO","creator_name":"Low IQ Gen AI","creator_url":"https://huggingface.co/fhai50032","description":"![Cover Image](data:image/webp;base64â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fhai50032/Hinglish-Preference-Humanized-DPO.","first_N":5,"first_N_keywords":["Hindi","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"hindi_voice_transcriptions","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aliMohammad16/hindi_voice_transcriptions","creator_name":"Mohammad Ali","creator_url":"https://huggingface.co/aliMohammad16","description":"aliMohammad16/hindi_voice_transcriptions dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","translation","Hindi","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"hindi-antonyms","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Process-Venue/hindi-antonyms","creator_name":"ProcessVenue","creator_url":"https://huggingface.co/Process-Venue","description":"\n\t\n\t\t\n\t\tHindi Antonyms Dataset (à¤¹à¤¿à¤‚à¤¦à¥€ à¤µà¤¿à¤²à¥‹à¤® à¤¶à¤¬à¥à¤¦à¤•à¥‹à¤¶)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains a comprehensive collection of Hindi words and their antonyms (à¤µà¤¿à¤²à¥‹à¤® à¤¶à¤¬à¥à¤¦). It is designed to assist NLP research, language learning, and applications focused on Hindi language processing. The dataset provides word-antonym pairs that can be used for tasks like:\n\nSemantic analysis\nLanguage learning and education\nText enrichment\nLinguistic research\nVocabulary expansion\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Process-Venue/hindi-antonyms.","first_N":5,"first_N_keywords":["text-classification","text-generation","Hindi","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"hindi-antonyms","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Process-Venue/hindi-antonyms","creator_name":"ProcessVenue","creator_url":"https://huggingface.co/Process-Venue","description":"\n\t\n\t\t\n\t\tHindi Antonyms Dataset (à¤¹à¤¿à¤‚à¤¦à¥€ à¤µà¤¿à¤²à¥‹à¤® à¤¶à¤¬à¥à¤¦à¤•à¥‹à¤¶)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains a comprehensive collection of Hindi words and their antonyms (à¤µà¤¿à¤²à¥‹à¤® à¤¶à¤¬à¥à¤¦). It is designed to assist NLP research, language learning, and applications focused on Hindi language processing. The dataset provides word-antonym pairs that can be used for tasks like:\n\nSemantic analysis\nLanguage learning and education\nText enrichment\nLinguistic research\nVocabulary expansion\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Process-Venue/hindi-antonyms.","first_N":5,"first_N_keywords":["text-classification","text-generation","Hindi","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"panlex-definitions","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-definitions","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-definitions\n\t\n\nThis is a dataset of word definitions in several hudnred languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20250201 database dump) and rearranged on the per-language basis (by the language of the definition).\nEach language subset consists of definitions (short phrases).\nEach definition is associated with some meanings (if there isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-definitions.","first_N":5,"first_N_keywords":["translation","Abkhazian","Hijazi Arabic","Afrikaans","Ainu (Japan)"],"keywords_longer_than_N":true},
	{"name":"MultiMWP","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NLPC-UOM/MultiMWP","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","description":"\n\t\n\t\t\n\t\tMultiMWP: A Multi-Way Parallel Dataset for Math Word Problem Generation\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nMultiMWP is a multi-way parallel dataset designed for math word problem (MWP) generation across 9 languages.\nThe dataset consists of structured math word problems in plain text format.\nIt is intended for problem generation rather than problem-solving. The same dataset is in Github: https://github.com/OmegaGamage/multiMWP/tree/master/dataset\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nMultiMWP includesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/MultiMWP.","first_N":5,"first_N_keywords":["Albanian","Assamese","English","Chinese","Hindi"],"keywords_longer_than_N":true},
	{"name":"PHINC","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LingoIITGN/PHINC","creator_name":"Lingo Research Group","creator_url":"https://huggingface.co/LingoIITGN","description":"Abstract\n Code-mixing is the phenomenon of using more than one language in a sentence. In the multilingual communities, it is a very frequently observed pattern of communication on social media platforms. Flexibility to use multiple languages in one text message might help to communicate efficiently with the target audience. But, the noisy user-generated code-mixed text adds to the challenge of processing and understanding natural language to a much larger extent. Machine translation fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LingoIITGN/PHINC.","first_N":5,"first_N_keywords":["translation","Hindi","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"TEXTRON_INDIC_DATASETS","keyword":"hindi","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/badrivishalk/TEXTRON_INDIC_DATASETS","creator_name":"Badri Vishal Kasuba","creator_url":"https://huggingface.co/badrivishalk","description":"This dataset is intended for testing purposes only. It contains a set of test data to evaluate the performance of models. It does not include training or validation data.\n\n\t\n\t\t\n\t\tTEXTRON Paper Release Dataset (WACV 2024)\n\t\n\nWelcome to the TEXTRON Paper Release Dataset for the WACV 2024 conference! This dataset contains handwritten and printed text detection datasets in three different languages. This README provides essential information on the dataset structure, contents, and how to use theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/badrivishalk/TEXTRON_INDIC_DATASETS.","first_N":5,"first_N_keywords":["object-detection","Tamil","Gujarati","Malayalam","Telugu"],"keywords_longer_than_N":true},
	{"name":"youtube-comment-sentiment","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AmaanP314/youtube-comment-sentiment","creator_name":"Amaan Poonawala","creator_url":"https://huggingface.co/AmaanP314","description":"\n\t\n\t\t\n\t\tYouTube Comments Sentiment Analysis Dataset (1M+ Labeled Comments)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset comprises over one million YouTube comments, each annotated with sentiment labelsâ€”Positive, Neutral, or Negative. The comments span a diverse range of topics including programming, news, sports, politics and more, and are enriched with comprehensive metadata to facilitate various NLP and sentiment analysis tasks.\n\n\t\n\t\t\n\t\tHow to use:\n\t\n\nimport pandas as pd\ndf =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AmaanP314/youtube-comment-sentiment.","first_N":5,"first_N_keywords":["text-classification","English","Hindi","Japanese","Spanish"],"keywords_longer_than_N":true},
	{"name":"squad_v1.1_np","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/suban244/squad_v1.1_np","creator_name":"Suban Shrestha","creator_url":"https://huggingface.co/suban244","description":"\n\t\n\t\t\n\t\tSQuAD-NP: Nepali Translation of SQuAD\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSQuAD-NP is a Nepali translation of the SQuAD dataset, the standard dataset for question answering task. The dataset consists of Nepali translations of the original English passages, questions, and answers from the SQuAD dataset. \nThis resource is useful for training machine learning models on extractive question-answering tasks in Nepali.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Nepali (ne)\nSource: Translated from SQuAD-Englishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/suban244/squad_v1.1_np.","first_N":5,"first_N_keywords":["question-answering","Nepali","Hindi","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"AyaVisionBench","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/AyaVisionBench","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for Aya Vision Benchmark\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/AyaVisionBench.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"m-WildVision","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/m-WildVision","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for m-WildVision\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \nThe authors demonstrated that these prompts enable automatic LLM judgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-WildVision.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"Kaleidoscope","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Anonym-sub/Kaleidoscope","creator_name":"Anonymous submission","creator_url":"https://huggingface.co/Anonym-sub","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Anonym-sub/Kaleidoscope.","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"MAPS_Verified","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fujitsu-FRE/MAPS_Verified","creator_name":"Fujitsu Research of Europe","creator_url":"https://huggingface.co/Fujitsu-FRE","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Benchmark for Global Agent Performance and Security\n\t\n\nThis is the first Multilingual Agentic AI Benchmark for evaluating agentic AI systems across different languages and diverse tasks. Benchmark enables systematic analysis of how agents perform under multilingual conditions. This dataset contains 550 instances for GAIA, 660 instances for ASB, 737 instances for Maths, and 1100 instances for SWE. Each task was translated into 10 target languages resultingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu-FRE/MAPS_Verified.","first_N":5,"first_N_keywords":["text-generation","question-answering","Arabic","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"LAION-art-EN-improved-captions-translate","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaeyong2/LAION-art-EN-improved-captions-translate","creator_name":"jeongjaeyong","creator_url":"https://huggingface.co/jaeyong2","description":"\n\t\n\t\t\n\t\tDevelopment Process\n\t\n\n\nsource dataset from recastai/LAION-art-EN-improved-captions\nWe used Qwen/Qwen2-72B-Instruct model to translate.\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\n\nQwen/Qwen2.5-72B-Instruct : https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/LICENSE\nrecastai/LAION-art-EN-improved-captions : https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/cc-by-4.0.md\n\n\n\t\n\t\t\n\t\n\t\n\t\tAcknowledgement\n\t\n\nThis research is supported by TPU Research Cloud program.\n","first_N":5,"first_N_keywords":["Korean","Japanese","Thai","Vietnamese","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_hi","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoDBPedia dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Hindi"],"keywords_longer_than_N":true},
	{"name":"wmt-da-human-evaluation-long-context","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLong-context / document-level dataset for Quality Estimation of Machine Translation.\nIt is an augmented variant of the sentence-level WMT DA Human Evaluation dataset.\nIn addition to individual sentences, it contains augmentations of 2, 4, 8, 16, and 32 sentences, among each language pair lp and domain.\nThe raw column represents a weighted average of scores of augmented sentences using character lengths of src and mt as weights.\nThe code used to apply the augmentationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context.","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Estonian"],"keywords_longer_than_N":true},
	{"name":"IN22-Conv-Doc-Level","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IN22-Conv-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"This dataset was constructed by merging individual conversations from the IN22-Conv dataset to create a long-context, document-level parallel benchmark. For further information on domains and statistics, please refer to the original paper and dataset.\n","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"Flores-Indic-Doc-Level","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/Flores-Indic-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"This dataset was constructed by merging individual sentences from the Flores dataset based on matching domain, topic, and URL attributes. The result is a long-context, document-level parallel benchmark. For more details on the domains and dataset statistics, please refer to the original paper and the dataset.\n","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSynthdog Multilingual\n\t\n\n\n\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzfâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"audio_public","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SayantanJoker/audio_public","creator_name":"Sayantan Ray","creator_url":"https://huggingface.co/SayantanJoker","description":"SayantanJoker/audio_public dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Hindi","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"kaleidoscope","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/kaleidoscope","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/kaleidoscope.","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"Hindi-Normalisation","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Rahul-1337/Hindi-Normalisation","creator_name":"Rahul Singh","creator_url":"https://huggingface.co/Rahul-1337","description":"Rahul-1337/Hindi-Normalisation dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Hindi","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Telugu-NLP-AI-Dialect-Comedy-video-Dataset","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Automation-Tribe/Telugu-NLP-AI-Dialect-Comedy-video-Dataset","creator_name":"AUTTRIBE-AI-AUTOMATION","creator_url":"https://huggingface.co/Automation-Tribe","description":"Telugu is one of the sweetest and oldest languages of India. A deep Dive into Telugu its spoken in 2 states and majorly 16 regional dailects.\nThis Dataset help you perform operations in NLP and Speech Recognition Models towards telugu Dialects.\n","first_N":5,"first_N_keywords":["text-classification","feature-extraction","Telugu","Kannada","English"],"keywords_longer_than_N":true},
	{"name":"M-ABSA","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","description":"\n\t\n\t\t\n\t\tM-ABSA\n\t\n\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\n\n\n\t\n\t\t\n\t\tData Description:\n\t\n\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\nAll datasets are stored in the data/ folder:\n\nAll dataset contains 7 domains.\n\ndomains = [\"coursera\", \"hotel\", \"laptop\", \"restaurant\", \"phone\", \"sight\", \"food\"]\n\n\nEach dataset contains 21 languages.\n\nlangs = [\"ar\", \"da\", \"de\", \"en\", \"es\", \"fr\", \"hi\", \"hr\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA.","first_N":5,"first_N_keywords":["token-classification","text-classification","Arabic","Danish","German"],"keywords_longer_than_N":true},
	{"name":"fka-awesome-chatgpt-prompts-hindi","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bingbangboom/fka-awesome-chatgpt-prompts-hindi","creator_name":"Ding","creator_url":"https://huggingface.co/bingbangboom","description":"ðŸ§  Awesome ChatGPT Prompts in Hindi [CSV dataset]\n\nThis is a hindi translated dataset repository of Awesome ChatGPT Prompts fka/awesome-chatgpt-prompts\nView All Original Prompts on GitHub\n","first_N":5,"first_N_keywords":["question-answering","Hindi","cc0-1.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tasmay-Tib/sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600","creator_name":"Tasmay Pankaj Tibrewal","creator_url":"https://huggingface.co/Tasmay-Tib","description":"Dataset for sarvam's entity normalisation task. More detailed information can be found here, in the main model repo: Hugging Face\nDetailed Report (Writeup): Google Drive\nIt also has a gguf variant, with certain additional gguf based innstructions: Hugging Face\nModel inference script can be found here: Colab\nModel predictions can be found in this dataset and both the repo files. named as: \n\neval_data_001_predictions.csv and eval_data_001_predictions_excel.csv.\ntrain_data_001_predictions.csvandâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tasmay-Tib/sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600.","first_N":5,"first_N_keywords":["Hindi","Tamil","Telugu","Marathi","Bengali"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tSMOL\n\t\n\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\ntranslations into 221 Low-Resource Languages, for the purpose of training\ntranslation models, and otherwise increasing the representations of said\nlanguages in NLP and technology.\nPlease read the SMOL Paper and the\nGATITOS Paper for a much more\nthorough description!\nThere are four resources in this directory:\n\nSmolDoc: document-level translations into 100 languages\nSmolSent: sentence-level translations intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"english-hindi-colloquial-dataset","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bajpaideeksha/english-hindi-colloquial-dataset","creator_name":"deeksha bajpai","creator_url":"https://huggingface.co/bajpaideeksha","description":"A curated dataset of colloquial English phrases and their corresponding Hindi translations. This dataset focuses on informal language, including slang, idioms, and everyday expressions, making it ideal for training models that handle casual conversations.\nDataset Details:\nSize:e.g., 500+ phrase pairs]\nSource: Collected from publicly available conversational datasets, social media, and crowdsourced contributions.\nLanguage Pair: English â†’ Hindi\nAnnotations: Each phrase pair is manually verifiedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bajpaideeksha/english-hindi-colloquial-dataset.","first_N":5,"first_N_keywords":["translation","English","Hindi","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"PolyGuardMix","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","description":"\n\t\n\t\t\n\t\tPolyGuard: A Multilingual Safety Moderation Tool for 17 Languages\n\t\n\nAbstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix.","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"english-hindi-colloquial-dataset","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KumariPrerna2905/english-hindi-colloquial-dataset","creator_name":"Prerna Kumari","creator_url":"https://huggingface.co/KumariPrerna2905","description":"This dataset consists of a thoughtfully assembled collection of everyday English phrases and their Hindi translations. It highlights informal language, including slang, idiomatic expressions, and common phrases, making it ideal for training models that process casual conversations.\nDataset Details:\nSize:e.g., 100+ phrase pairs\nSource: Gathered from publicly available datasets and crowd-contributed inputs.\nLanguage Pair: English to Hindi\nUse Cases:  \n\nDeveloping and optimizing translationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KumariPrerna2905/english-hindi-colloquial-dataset.","first_N":5,"first_N_keywords":["translation","English","Hindi","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"MIRACLReranking","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MIRACLReranking","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MIRACLReranking\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://project-miracl.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MIRACLReranking.","first_N":5,"first_N_keywords":["text-ranking","expert-annotated","multilingual","miracl/mmteb-miracl","Arabic"],"keywords_longer_than_N":true},
	{"name":"english_telugu_slang","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BLESSENA30/english_telugu_slang","creator_name":"VinukondaBlessena","creator_url":"https://huggingface.co/BLESSENA30","description":"BLESSENA30/english_telugu_slang dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","text-classification","question-answering","English","Telugu"],"keywords_longer_than_N":true},
	{"name":"ncert_upsc_text_6to12","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ritik22912/ncert_upsc_text_6to12","creator_name":"Ritik Kumar","creator_url":"https://huggingface.co/ritik22912","description":"ritik22912/ncert_upsc_text_6to12 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","Hindi","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"dhhLyrics-ReversePrompt","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pranavinani/dhhLyrics-ReversePrompt","creator_name":"Pranav Inani","creator_url":"https://huggingface.co/pranavinani","description":"\n\t\n\t\t\n\t\n\t\n\t\tLyrics Datasets for Creative and Linguistic Applications\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThis repository contains two datasets of song lyrics, meticulously curated and organized for diverse applications in natural language processing, machine learning, and creative AI. These datasets include song verses, descriptive prompts, and romanized lyrics, providing rich resources for tasks such as text generation, sentiment analysis, transliteration, and more. All the songs are from Hip Hopâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pranavinani/dhhLyrics-ReversePrompt.","first_N":5,"first_N_keywords":["text-classification","summarization","text-generation","sentence-similarity","Hindi"],"keywords_longer_than_N":true},
	{"name":"MANGO","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/MANGO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tMANGO: A Corpus of Human Ratings for Speech\n\t\n\nMANGO (MUSHRA Assessment corpus using Native listeners and Guidelines to understand human Opinions at scale) is the first large-scale dataset designed for evaluating Text-to-Speech (TTS) systems in Indian languages. \n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\n255,150 human ratings of TTS-generated outputs and ground-truth human speech.\nCovers two major Indian languages: Hindi & Tamil, and English.\nBased on the MUSHRA (Multiple Stimuli with Hidden Referenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/MANGO.","first_N":5,"first_N_keywords":["text-to-speech","crowd-sourced","Hindi","Tamil","English"],"keywords_longer_than_N":true},
	{"name":"2M-Belebele","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\t2M-Belebele\n\t\n\n\n\t\n\t\t\n\t\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\n\t\n\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs datasets asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.","first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Bulgarian","Panjabi","English"],"keywords_longer_than_N":true},
	{"name":"imatrix-calibration","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eaddario/imatrix-calibration","creator_name":"Ed Addario","creator_url":"https://huggingface.co/eaddario","description":"\n\t\n\t\t\n\t\tImportance Matrix Calibration Datasets\n\t\n\nThis repository contains calibration datasets used to generate importance matrices (imatrix), which in turn help minimise errors introduced during quantization.\n\n\t\n\t\t\n\t\tMath calibration datasets\n\t\n\nThis dataset consists of over 10M tokens of cleaned math prompts and is available in six sizes, ranging from huge (~ 430,000 lines equivalent to approx. 10M tokens), to micro (~ 13,700 lines and 1.7M tokens avg).\nOriginal data sourced fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/eaddario/imatrix-calibration.","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\n\t\n\t\t\n\t\tlightblue/reasoning-multilingual-R1-Llama-70B-train\n\t\n\nThis is a multilingual reasoning dataset covering more than 30 languages.\nThis dataset was made by:\n\nSampling prompts from English datasets and translating them to various languages\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\n\nThis dataset was then used to train a multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"hindi-poetry","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rahul7star/hindi-poetry","creator_name":"rahul7star","creator_url":"https://huggingface.co/rahul7star","description":"rahul7star/hindi-poetry dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Hindi","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MultiLingualSentiment","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clapAI/MultiLingualSentiment","creator_name":"clapAI","creator_url":"https://huggingface.co/clapAI","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nMultilingualSentiment is a sentiment classification dataset that encompasses three sentiment labels: Positive, Neutral, Negative\nThe dataset spans multiple languages and covers a wide range of domains, making it ideal for multilingual sentiment analysis tasks.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThe dataset was meticulously collected and aggregated from various sources, including Hugging Face and Kaggle. These sources provide diverse languages and domains to ensure aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/clapAI/MultiLingualSentiment.","first_N":5,"first_N_keywords":["text-classification","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"Hindi-Poetry-Dataset","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ReySajju742/Hindi-Poetry-Dataset","creator_name":"Muhammad Sajjad Rasool","creator_url":"https://huggingface.co/ReySajju742","description":"\n\t\n\t\t\n\t\tHindi Transliteration of Urdu Poetry Dataset\n\t\n\nWelcome to the Hindi Transliteration of Urdu Poetry Dataset! This dataset features Hindi transliterations of traditional Urdu poetry. Each entry in the dataset includes two columns:\n\nTitle: The transliterated title of the poem in Hindi.\nPoem: The transliterated text of the Urdu poem rendered in Hindi script.\n\nThis dataset is perfect for researchers and developers working on cross-script language processing, transliteration models, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ReySajju742/Hindi-Poetry-Dataset.","first_N":5,"first_N_keywords":["text-classification","Hindi","Urdu","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Hindi-Poetry-Dataset","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ReySajju742/Hindi-Poetry-Dataset","creator_name":"Muhammad Sajjad Rasool","creator_url":"https://huggingface.co/ReySajju742","description":"\n\t\n\t\t\n\t\tHindi Transliteration of Urdu Poetry Dataset\n\t\n\nWelcome to the Hindi Transliteration of Urdu Poetry Dataset! This dataset features Hindi transliterations of traditional Urdu poetry. Each entry in the dataset includes two columns:\n\nTitle: The transliterated title of the poem in Hindi.\nPoem: The transliterated text of the Urdu poem rendered in Hindi script.\n\nThis dataset is perfect for researchers and developers working on cross-script language processing, transliteration models, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ReySajju742/Hindi-Poetry-Dataset.","first_N":5,"first_N_keywords":["text-classification","Hindi","Urdu","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"gsm8k-hindi","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bingbangboom/gsm8k-hindi","creator_name":"Ding","creator_url":"https://huggingface.co/bingbangboom","description":"\n\t\n\t\t\n\t\tDataset Card for GSM8K-Hindi\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a machine-translated hindi version of the popular GSM8K dataset from OpenAI. GSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\n\nThese problems take between 2 and 8 steps to solve.\nSolutions primarily involve performing aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bingbangboom/gsm8k-hindi.","first_N":5,"first_N_keywords":["Hindi","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Pralekha","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/Pralekha","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tPralekha: Cross-Lingual Document Alignment for Indic Languages\n\t\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\nPralekha is a large-scale parallel document dataset spanning across 11 Indic languages and English. It comprises over 3 milliondocument pairs, with 1.5 million being English-centric. This dataset serves both as a benchmark for evaluating Cross-Lingual Document Alignment (CLDA) techniques and as a domain-specific parallel corpus for training document-level Machine Translationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Pralekha.","first_N":5,"first_N_keywords":["translation","Bengali","English","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tBelebele-Fleurs\n\t\n\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\n\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30â€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_hi","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_hi","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoMSMARCO dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_hi","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_hi","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Hindi version of the NanoSCIDOCS dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hi.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Hindi"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"indic-parallel-sentences-talks","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aloobun/indic-parallel-sentences-talks","creator_name":"aloobun","creator_url":"https://huggingface.co/aloobun","description":"\n\t\n\t\t\n\t\tDataset Card for Parallel Sentences - Indic Talks\n\t\n\nThis dataset contains parallel sentences (i.e. English sentence + the same sentences in another language) for numerous other languages.\n","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"eng_hi_idioms_csv","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aimagic/eng_hi_idioms_csv","creator_name":"Shubham Aditya","creator_url":"https://huggingface.co/aimagic","description":"aimagic/eng_hi_idioms_csv dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","English","Hindi","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"IndicQARetrieval","keyword":"hindi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIndicQA is a manually curated cloze-style reading comprehension dataset that can be used for evaluating question-answering models in 11 Indic languages. It is repurposed retrieving relevant context for each question.\n\n\t\n\t\t\n\n\n\n\n\t\tTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicQARetrieval.","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","translated","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"reranking-datasets-light","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","description":"\n\t\n\t\t\n\t\tðŸ”¥ Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation ðŸ”¥\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\n\t\n\n\n    \n    \n    \n    \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n    \n\n\n\nA curated collection of ready-to-use datasets for retrieval and rerankingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light.","first_N":5,"first_N_keywords":["question-answering","English","Arabic","German","French"],"keywords_longer_than_N":true},
	{"name":"Hindi-Sign-Language-Dataset","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Vedant3907/Hindi-Sign-Language-Dataset","creator_name":"Vedant Rajpurohit","creator_url":"https://huggingface.co/Vedant3907","description":"Vedant3907/Hindi-Sign-Language-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["image-classification","Hindi","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Hindi-Sign-Language-Dataset","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Vedant3907/Hindi-Sign-Language-Dataset","creator_name":"Vedant Rajpurohit","creator_url":"https://huggingface.co/Vedant3907","description":"Vedant3907/Hindi-Sign-Language-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["image-classification","Hindi","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SMPQA","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/SMPQA","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\n\t\n\t\tSMPQA (Synthetic Multilingual Plot QA)\n\t\n\n\n\nThe SMPQA evaluation dataset proposed in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nSMPQA is composed of synthetic bar plots and pie charts (generated using word lists of different languages) together with questions about those plots.\nThe datasets aims at providing an initial way of evaluating multilingual OCR capabilities of models in arbritrary languages.\nThere are two sub-tasks: \n\nGrounding text labelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/SMPQA.","first_N":5,"first_N_keywords":["visual-question-answering","English","Zulu","Indonesian","Italian"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xm100","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM100\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Everything_Instruct_Multilingual","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","description":"\n\t\n\t\t\n\t\tEverything Instruct (Multilingual Edition)\n\t\n\nEverything you need... all in one place ðŸ’˜\n\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\nNote2: This version of the dataset supports the following languages:\n\nEnglish\nRussianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual.","first_N":5,"first_N_keywords":["English","Russian","Chinese","Korean","Urdu"],"keywords_longer_than_N":true},
	{"name":"mini-iitb-english-hindi","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/atrisaxena/mini-iitb-english-hindi","creator_name":"Atri Saxena","creator_url":"https://huggingface.co/atrisaxena","description":"atrisaxena/mini-iitb-english-hindi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","English","Hindi","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"verb-translation-dataset","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Process-Venue/verb-translation-dataset","creator_name":"ProcessVenue","creator_url":"https://huggingface.co/Process-Venue","description":"\n\t\n\t\t\n\t\tProcess-Venue/verb-translation-dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset offers a comprehensive collection of verb translations from English into Hindi, Marathi, and Sanskrit, three major Indian languages. Each entry provides the English verb alongside its corresponding translations, enabling multilingual analysis and cross-lingual studies. The dataset is meticulously curated to support a wide range of natural language processing (NLP) and language technology applicationsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Process-Venue/verb-translation-dataset.","first_N":5,"first_N_keywords":["translation","English","Hindi","Marathi","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"EmotionAnalysisFinal","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llama-lang-adapt/EmotionAnalysisFinal","creator_name":"Llama Adapt","creator_url":"https://huggingface.co/llama-lang-adapt","description":"\n\t\n\t\t\n\t\tDataset Card for EmotionAnalysisFinal\n\t\n\nEmotionAnalysisFinal is the official dataset for SemEval-2025 Task 11, Track C: Cross-lingual Emotion Detection in Social Media Text.\nThis dataset comprises multilingual social media posts annotated for six basic emotions: anger, disgust, fear, joy, sadness, and surprise.\nThe annotation schema is multi-label.\nEach language-specific configuration (subset) contains validation and test splits.\n\n\t\n\t\t\nSplit\nOriginal Source\nNotes\n\n\n\t\t\nvalidation\ndevâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/llama-lang-adapt/EmotionAnalysisFinal.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","multilingual","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"MMMLU_subset","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/double7/MMMLU_subset","creator_name":"Sen Yang","creator_url":"https://huggingface.co/double7","description":"\n\t\n\t\t\n\t\tAbout MMMLU subset\n\t\n\n  This is a subset of MMMLU, specifically, we sampled 10% of the original data to improve evaluation efficiency.\n  In addition, we categorize the questions into four categories by subject, i.e., STEM, HUMANITIES, SOCIAL SCIENCES, and OTHER, aligned with MMLU.\n\n\t\n\t\t\n\t\n\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57â€¦ See the full description on the dataset page: https://huggingface.co/datasets/double7/MMMLU_subset.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"Dhanishtha-2.0-SUPERTHINKER","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HelpingAI/Dhanishtha-2.0-SUPERTHINKER","creator_name":"HelpingAI","creator_url":"https://huggingface.co/HelpingAI","description":"ðŸ“¦ Dhanishtha-2.0-SUPERTHINKER\n A distilled corpus of 11.7K high-quality samples showcasing multi-phase reasoning and structured emotional cognition. Sourced directly from the internal training data of Dhanishtha-2.0 â€” the worldâ€™s first Large Language Model (LLM) to implement Intermediate Thinking, featuring multiple <think> and <ser> blocks per response\n\n\n\t\n\t\t\n\t\tðŸ“Š Overview\n\t\n\n\n11.7K multilingual samples (languages listed below)\nInstruction-Output format, ideal for supervised fine-tuningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HelpingAI/Dhanishtha-2.0-SUPERTHINKER.","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"HindiNER-golden-dataset","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nis12ram/HindiNER-golden-dataset","creator_name":"nishant choudhary","creator_url":"https://huggingface.co/nis12ram","description":"\n\t\n\t\t\n\t\tDataset Card for HindiNER-golden-dataset\n\t\n\n\nHindiNER-golden-dataset  - a small, diverse and high quality general Hindi NER dataset\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThe HindiNER-golden-dataset  includes 952 diverse source texts sampled from nisram-hindi-text-0.0 dataset. Their labels were generated using Llama-3.3-70B-Instruct and then manually corrected twice.\n\nCurated by: nis12ram\nLanguage(s) (NLP): Hindi\nLicense: Apache License 2.0\n\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nis12ram/HindiNER-golden-dataset.","first_N":5,"first_N_keywords":["feature-extraction","text-generation","Hindi","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"R3-eval-MMMLU","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HLeiTR/R3-eval-MMMLU","creator_name":"Shou-Yi Hung","creator_url":"https://huggingface.co/HLeiTR","description":"HLeiTR/R3-eval-MMMLU dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"entity_type_hi_pilener_constraint","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nis12ram/entity_type_hi_pilener_constraint","creator_name":"nishant choudhary","creator_url":"https://huggingface.co/nis12ram","description":"\n\t\n\t\t\n\t\tDataset Card for entity_type_hi_pilener_constraint\n\t\n\nThese dataset is a modified version of entity_type_hi_pilener\nCheck out the Colab Notebook used to modify entity_type_hi_pilener\n","first_N":5,"first_N_keywords":["text-generation","feature-extraction","Hindi","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"HindiNER-golden-dataset-constraint1","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nis12ram/HindiNER-golden-dataset-constraint1","creator_name":"nishant choudhary","creator_url":"https://huggingface.co/nis12ram","description":"\n\t\n\t\t\n\t\tDataset Card for HindiNER-golden-dataset-constraint1\n\t\n\nThese dataset is a modified version of HindiNER-golden-dataset\nCheck out the Colab Notebook used to modify HindiNER-golden-dataset\n","first_N":5,"first_N_keywords":["text-generation","feature-extraction","Hindi","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"IndicXnliPairClassification","keyword":"hindi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicXnliPairClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicXnliPairClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nINDICXNLI is similar to existing XNLI dataset in shape/form, but\n        focusses on Indic language family.\n        The train (392,702), validation (2,490), and evaluation sets (5,010) of English\n        XNLI were translated from English into each of the eleven Indic languages. IndicTrans\n        is a large Transformer-based sequence to sequence model. It is trained on Samanantar\n        dataset (Ramesh etâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicXnliPairClassification.","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","derived","translated","Divyanshu/indicxnli"],"keywords_longer_than_N":true},
	{"name":"dhanishtha-2.0-superthinker-mlx","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker-mlx","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","description":"\n\t\n\t\t\n\t\tðŸ“¦ Dhanishtha-2.0-SUPERTHINKER-MLX\n\t\n\n A distilled corpus of 11.7K high-quality samples showcasing multi-phase reasoning and structured emotional cognition. Sourced directly from the internal training data of Dhanishtha-2.0 â€” the worldâ€™s first Large Language Model (LLM) to implement Intermediate Thinking, featuring multiple <think> and <ser> blocks per response\n\n\t\n\t\t\n\t\n\t\n\t\tExample with MLX-LM-LoRA:\n\t\n\nmlx_lm_lora.train \\\n--modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker-mlx.","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"domain-translations","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/humbleworth/domain-translations","creator_name":"HumbleWorth","creator_url":"https://huggingface.co/humbleworth","description":"\n\t\n\t\t\n\t\tMultilingual Domain Name Translations Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 155,004 domain names with their multilingual translations across 20 languages. Each domain has been segmented into constituent words and translated while preserving semantic meaning and commercial appeal. The dataset is particularly valuable for domain name research, multilingual NLP tasks, and understanding how brand names and concepts translate across languages.\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/humbleworth/domain-translations.","first_N":5,"first_N_keywords":["translation","text-generation","feature-extraction","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"IndicMSMARCO","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/IndicMSMARCO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tðŸ” IndicMSMARCO: Multilingual Information Retrieval Benchmark\n\t\n\nA comprehensive multilingual variant of MS MARCO specifically tailored for Indian languages, featuring carefully selected queries and corresponding passages with high-quality translations.\n\n\t\n\t\t\n\t\tðŸš€ Quick Start - Load Individual Languages\n\t\n\nfrom datasets import load_dataset\n\n# Load ONLY Hindi data (fast and efficient!)\nhindi_data = load_dataset(\"ai4bharat/IndicMSMARCO\", \"hi\")\nprint(f\"Hindi queries:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/IndicMSMARCO.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multilingual","ms_marco","Assamese"],"keywords_longer_than_N":true},
	{"name":"quran_multilingual_parallel","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/quran_multilingual_parallel","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tðŸ“˜ Qurâ€™an Multilingual Parallel Dataset (quran_multilingual_parallel)\n\t\n\nThis dataset presents a clean, structurally-aligned multilingual parallel corpus of the Qurâ€™anic text. It is intended for linguistic, computational, and cross-lingual AI applications â€” not only for religious interpretation.\nIt contains over 6,200 verse-level alignments in 54 human languages, formatted in a machine-friendly .csv structure with language-specific translation fields.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ§  Dataset Highlightsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/freococo/quran_multilingual_parallel.","first_N":5,"first_N_keywords":["translation","Arabic","Albanian","Amharic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"wikipedia-citation-index","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia-citation-index","creator_name":"WÅ‚odzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Dataset with citation indexes as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions. Research: ArXiv\n","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"Synthetic-Hinglish-Finetuning-Dataset","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prakharb01/Synthetic-Hinglish-Finetuning-Dataset","creator_name":"Prakhar Bhartiya","creator_url":"https://huggingface.co/prakharb01","description":"\n\t\n\t\t\n\t\tHinglish Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetically generated conversational dialogues in Hinglish (a blend of Hindi and English). The conversations revolve around typical college life, cultural festivities, daily routines, and general discussions, designed to be relatable and engaging.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Hinglish (Hindi + English)\nDomain: College life, daily interactions, cultural events, and general discussions\nSize: 3576â€¦ See the full description on the dataset page: https://huggingface.co/datasets/prakharb01/Synthetic-Hinglish-Finetuning-Dataset.","first_N":5,"first_N_keywords":["text-generation","English","Hindi","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Ranjan-Hindi33min","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BBSRguy/Ranjan-Hindi33min","creator_name":"Rashmi Ranjan Dash","creator_url":"https://huggingface.co/BBSRguy","description":"\n\t\n\t\t\n\t\tRanjan-Hindi33min\n\t\n\nOwner: @BBSRguyCreated: 2025-06-03Year: 2025Language: Hindi ðŸ‡®ðŸ‡³Region Focus: Odisha, IndiaSample Rate Variants: 16 kHz, 24 kHz, 32 kHzTotal Files: 29 pairs (speech + text)Duration: Approximately 33 minutes of speech  \n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“œ Description\n\t\n\nRanjan-Hindi33min is a meticulously curated dataset comprising high-quality Hindi speech samples and their corresponding textual transcriptions. This dataset is designed to support various speech processing tasksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BBSRguy/Ranjan-Hindi33min.","first_N":5,"first_N_keywords":["text-to-speech","Hindi","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"HindiDiscourseClassification","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HindiDiscourseClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HindiDiscourseClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Hindi Discourse dataset in Hindi with values for coherence.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nFiction, Social, Written\n\n\nReference\nhttps://aclanthology.org/2020.lrec-1.149/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"HindiDiscourseClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HindiDiscourseClassification.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","Hindi","mit"],"keywords_longer_than_N":true},
	{"name":"Shiv_puran_OCR","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/snskrt/Shiv_puran_OCR","creator_name":"Sanskrit Datasets","creator_url":"https://huggingface.co/snskrt","description":"\n\t\n\t\t\n\t\tDataset Card for Shlok vs Non Shlok in Shiv puran\n\t\n\nThis dataset will enable a object detection model to differentiate between shlok vs Non-Shlok in this types of books, after that shloks can be cropped and a parallel corpus of image-text can be created.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\nPDF from internet archive was used, will link it here later\n\n\t\n\t\t\n\t\tUses\n\t\n\nTo further develop Sanskrit OCR\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\nWrite a python script to crop the shlok boxes andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/snskrt/Shiv_puran_OCR.","first_N":5,"first_N_keywords":["image-to-image","text-classification","feature-extraction","Sanskrit","Hindi"],"keywords_longer_than_N":true},
	{"name":"Indic-Rag-Suite","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/Indic-Rag-Suite","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tðŸŒ Multilingual Indic RAG Suite\n\t\n\nA comprehensive multilingual question-answering dataset covering 18 Indian languages with 21,439,886 total samples, designed for RAG (Retrieval-Augmented Generation) applications and multilingual NLP research.\n\n\t\n\t\t\n\t\tðŸš€ Quick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load specific language (recommended)\ndataset = load_dataset(\"ai4bharat/Indic-Rag-Suite\", \"as\")\ntrain_data = dataset['train']\n\nprint(f\"Loaded {len(train_data)} samples\")\n\n# Accessâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Indic-Rag-Suite.","first_N":5,"first_N_keywords":["question-answering","text-generation","multilingual","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"Rural_Women_Bhojpuri","keyword":"hindi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/Rural_Women_Bhojpuri","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tRural Bhojpuri ASR Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is curated to foster the development of inclusive Automatic Speech Recognition (ASR) systems, with a special focus on the underrepresented voices of rural Bhojpuri women. It contains audio clips in both Bhojpuri and Hindi, collected from real-world and synthetic sources, designed to train and evaluate ASR models that can accurately recognize diverse speech patterns.\nThis work is part of the research presented inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Rural_Women_Bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Bhojpuri","Hindi","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"En-Hindi","keyword":"hindi","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Namratap/En-Hindi","creator_name":"Namrata Patil Gurav","creator_url":"https://huggingface.co/Namratap","description":"Namratap/En-Hindi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","English","Hindi","afl-3.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"HindiNER-golden-dataset-constraint2","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nis12ram/HindiNER-golden-dataset-constraint2","creator_name":"nishant choudhary","creator_url":"https://huggingface.co/nis12ram","description":"\n\t\n\t\t\n\t\tDataset Card for HindiNER-golden-dataset-constraint2\n\t\n\nThese dataset is a modified version of HindiNER-golden-dataset\nCheck out the Colab Notebook used to modify HindiNER-golden-dataset\n","first_N":5,"first_N_keywords":["text-generation","feature-extraction","Hindi","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"HindiNER-golden-dataset-constraint3","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nis12ram/HindiNER-golden-dataset-constraint3","creator_name":"nishant choudhary","creator_url":"https://huggingface.co/nis12ram","description":"\n\t\n\t\t\n\t\tDataset Card for HindiNER-golden-dataset-constraint3\n\t\n\nThese dataset is a modified version of HindiNER-golden-dataset\nCheck out the Colab Notebook used to modify HindiNER-golden-dataset\n","first_N":5,"first_N_keywords":["text-generation","feature-extraction","Hindi","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"HindiNER-golden-dataset-constraint4","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nis12ram/HindiNER-golden-dataset-constraint4","creator_name":"nishant choudhary","creator_url":"https://huggingface.co/nis12ram","description":"\n\t\n\t\t\n\t\tDataset Card for HindiNER-golden-dataset-constraint4\n\t\n\nThese dataset is a modified version of HindiNER-golden-dataset\nCheck out the Colab Notebook used to modify HindiNER-golden-dataset\n","first_N":5,"first_N_keywords":["text-generation","feature-extraction","Hindi","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"HindiNER-golden-dataset-constraint5","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nis12ram/HindiNER-golden-dataset-constraint5","creator_name":"nishant choudhary","creator_url":"https://huggingface.co/nis12ram","description":"\n\t\n\t\t\n\t\tDataset Card for HindiNER-golden-dataset-constraint5\n\t\n\nThese dataset is a modified version of HindiNER-golden-dataset\nCheck out the Colab Notebook used to modify HindiNER-golden-dataset\n","first_N":5,"first_N_keywords":["text-generation","feature-extraction","Hindi","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"health-QE","keyword":"hindi","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Namratap/health-QE","creator_name":"Namrata Patil Gurav","creator_url":"https://huggingface.co/Namratap","description":"Namratap/health-QE dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","English","Tamil","Gujarati","Marathi"],"keywords_longer_than_N":true},
	{"name":"discord-phishing-scam","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wangyuancheng/discord-phishing-scam","creator_name":"Wang Yuancheng","creator_url":"https://huggingface.co/wangyuancheng","description":"\n\t\n\t\t\n\t\tDiscord Scam / Clean Messages Dataset\n\t\n\nA small but carefully-curated dataset for binary text-classification:\n\nâ€œIs this Discord message trying to scam / spam users?â€\n\nIt is intended as a starting point for fine-tuning lightweight BERT-style models that moderate real-time chat servers.\n\n\n\t\n\t\t\n\t\t1 Origin & Collection\n\t\n\n\nSource servers â€“ private Discord communities (11 k members in total) run by the author.\nPeriod â€“ 2024-01-01 â†’ 2025-06-01.\nExtraction â€“ Discord.py script iteratedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wangyuancheng/discord-phishing-scam.","first_N":5,"first_N_keywords":["text-classification","English","Hindi","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Indic-Rag-Suite","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AshwinSankar/Indic-Rag-Suite","creator_name":"Ashwin Sankar","creator_url":"https://huggingface.co/AshwinSankar","description":"\n\t\n\t\t\n\t\tðŸŒ Multilingual Indic RAG Suite\n\t\n\nA comprehensive multilingual question-answering dataset covering 18 Indian languages with 12,802,615 total samples, designed for RAG (Retrieval-Augmented Generation) applications and multilingual NLP research.\n\n\t\n\t\t\n\t\tðŸš€ Quick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load specific language (recommended)\ndataset = load_dataset(\"AshwinSankar/Indic-Rag-Suite\", \"as\")\ntrain_data = dataset['train']\n\nprint(f\"Loaded {len(train_data)} samples\")\n\n# Accessâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AshwinSankar/Indic-Rag-Suite.","first_N":5,"first_N_keywords":["question-answering","text-generation","multilingual","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"Triveni1","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LingoIITGN/Triveni1","creator_name":"Lingo Research Group","creator_url":"https://huggingface.co/LingoIITGN","description":"\n\t\n\t\t\n\t\tðŸ“¦ Pretraining Corpus\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Overview\n\t\n\nThis dataset combines data from two major sourcesâ€”Vaani and Flickr30kâ€”to support multilingual and multimodal model pretraining.\n\n\t\n\t\t\nSource\nLanguages\nSamples per Language\nTotal Samples\n\n\n\t\t\nVaani\nHindi, English, Hinglish\n30,195\n90,585\n\n\nFlickr30k\nHindi, English, Hinglish\n31,014\n93,042\n\n\nTotal\nâ€”\nâ€”\n183,627\n\n\n\t\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“ Dataset Sources\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ—£ï¸ Vaani Dataset\n\t\n\n\nLicense: CC-BY-4.0\n\nDescription:\n\nVAANI is anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LingoIITGN/Triveni1.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Hindi","mit"],"keywords_longer_than_N":true},
	{"name":"koel-benchmark","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NisargBhavsar25/koel-benchmark","creator_name":"Nisarg Bhavsar","creator_url":"https://huggingface.co/NisargBhavsar25","description":"\n\t\n\t\t\n\t\tKoel Benchmark Suite\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Koel Benchmark Suite is a comprehensive set of evaluation datasets designed to rigorously test the real-world performance of Text-to-Speech (TTS) models for major Indian languages. The suite focuses on challenges unique to the Indian context, such as code-switching, domain-specific terminology, proper nouns, and complex numeric formats.\nThis dataset was created to help developers and researchers build more natural, accurateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NisargBhavsar25/koel-benchmark.","first_N":5,"first_N_keywords":["English","Hindi","Tamil","Telugu","Kannada"],"keywords_longer_than_N":true},
	{"name":"exp-Nayana-IR-DescVQA-hi-10k-renamed-colpali","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nayana-cognitivelab/exp-Nayana-IR-DescVQA-hi-10k-renamed-colpali","creator_name":"Nayana-CognitiveLab","creator_url":"https://huggingface.co/Nayana-cognitivelab","description":"\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThis dataset is a processed version of akashmadisetty/Nayana-IR-DescVQA-finetune-hi-10k.\n\n\t\n\t\t\n\t\tProcessing Details\n\t\n\nThe following columns were renamed:\n\nspecific_detail_query â†’ query\n\n\n\t\n\t\t\n\t\tOriginal Dataset\n\t\n\nPlease refer to the original dataset for more information about the data collection and annotation process.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"akashmadisetty/Nayana-IR-DescVQA-hi-10k-renamed\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nayana-cognitivelab/exp-Nayana-IR-DescVQA-hi-10k-renamed-colpali.","first_N":5,"first_N_keywords":["question-answering","Hindi","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"exp-Nayana-IR-DescVQA-hi-10k-renamed-colpali","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nayana-cognitivelab/exp-Nayana-IR-DescVQA-hi-10k-renamed-colpali","creator_name":"Nayana-CognitiveLab","creator_url":"https://huggingface.co/Nayana-cognitivelab","description":"\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThis dataset is a processed version of akashmadisetty/Nayana-IR-DescVQA-finetune-hi-10k.\n\n\t\n\t\t\n\t\tProcessing Details\n\t\n\nThe following columns were renamed:\n\nspecific_detail_query â†’ query\n\n\n\t\n\t\t\n\t\tOriginal Dataset\n\t\n\nPlease refer to the original dataset for more information about the data collection and annotation process.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"akashmadisetty/Nayana-IR-DescVQA-hi-10k-renamed\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nayana-cognitivelab/exp-Nayana-IR-DescVQA-hi-10k-renamed-colpali.","first_N":5,"first_N_keywords":["question-answering","Hindi","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Triveni","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LingoIITGN/Triveni","creator_name":"Lingo Research Group","creator_url":"https://huggingface.co/LingoIITGN","description":"\n\t\n\t\t\n\t\tðŸ“¦ Pretraining Corpus\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Overview\n\t\n\nThis dataset combines data from two major sourcesâ€”Vaani and Flickr30kâ€”to support multilingual and multimodal model pretraining.\n\n\t\n\t\t\nSource\nLanguages\nSamples per Language\nTotal Samples\n\n\n\t\t\nVaani\nHindi, English, Hinglish\n30,195\n90,585\n\n\nFlickr30k\nHindi, English, Hinglish\n31,014\n93,042\n\n\nTotal\nâ€”\nâ€”\n183,627\n\n\n\t\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“ Dataset Sources\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ—£ï¸ Vaani Dataset\n\t\n\n\nLicense: CC-BY-4.0\n\nDescription:\n\nVAANI is anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LingoIITGN/Triveni.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Hindi","mit"],"keywords_longer_than_N":true},
	{"name":"NeoBabel-Eval","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mderakhshani/NeoBabel-Eval","creator_name":"Mohammad Mahdi Derakhshani","creator_url":"https://huggingface.co/mderakhshani","description":"\n\t\n\t\t\n\t\tOfficial Multilingual Evaluation Suite of NeoBabel\n\t\n\nThis repository contains the full evaluation datasets used for benchmarking multilingual text-to-image generation in NeoBabel. We release two benchmarks: m-GenEval and m-DPG, both provided as .zip archives.\n\n\t\n\t\t\n\t\tm-GenEval\n\t\n\nThis dataset is a multilingual extension of the original GenEval benchmark. Each English prompt from GenEval has been translated into five additional languages: Chinese, Dutch, French, Hindi, and Persian.Eachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mderakhshani/NeoBabel-Eval.","first_N":5,"first_N_keywords":["text-to-image","English","Dutch","French","Persian"],"keywords_longer_than_N":true},
	{"name":"wmt-human-all","keyword":"hindi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zouharvi/wmt-human-all","creator_name":"VilÃ©m Zouhar","creator_url":"https://huggingface.co/zouharvi","description":"This dataset is continuously updated and contains a compilation of human translation quality assessment from past WMT campaigns.\nSpecifically, this dataset merges all annotation protocols (DA, MQM, ESA) on a semi-unified scale (0 to 100).\nThe current version of the dataset includes human scores up to WMT 2024 (inclusive) and has been created with the following script:\nimport subset2evaluate # version 1.0.14\nimport json\nimport statistics\n\ndata =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/wmt-human-all.","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"Multilingual_Jailbreak_Dataset","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/darkknight25/Multilingual_Jailbreak_Dataset","creator_name":"Sunny thakur","creator_url":"https://huggingface.co/darkknight25","description":"\n\t\n\t\t\n\t\tMultilingual Jailbreak Dataset\n\t\n\nOverview\nThe Multilingual Jailbreak Dataset is a comprehensive collection of 700 prompts designed to test the security and robustness of AI systems against potential jailbreak attempts. Each entry includes prompts in multiple languages (English, Hindi, Russian, French, Chinese, German, and Spanish) to evaluate vulnerabilities in diverse linguistic contexts. The dataset focuses on advanced and intermediate-level cybersecurity scenarios, including cloudâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/darkknight25/Multilingual_Jailbreak_Dataset.","first_N":5,"first_N_keywords":["English","Spanish","Hindi","French","Russian"],"keywords_longer_than_N":true},
	{"name":"SentiHin-2500","keyword":"hindi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MLap/SentiHin-2500","creator_name":"aman prakash","creator_url":"https://huggingface.co/MLap","description":"\n\n\t\n\t\t\n\t\tSentiHin-2500 original Hindi sentiment analysis CSV dataset, consists of 2500 rows.\n\t\n\n\nThe CSV dataset is generated using OpenAI's GPT4o and Claude 4 Sonnet with a specific prompt. For more details, visit project page on GitHub.\n\n\n\t\n\t\t\n\t\n\t\n\t\tAll the 2500 rows of this CSV dataset are manually verified for correctness.\n\t\n\nIf you use SentiHin-2500 in your research or projects, please cite it as:\n@dataset{sentiHin2025,\n  author       = {Aman Prakash},\n  title        = {SentiHin-2500}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MLap/SentiHin-2500.","first_N":5,"first_N_keywords":["text-classification","Hindi","mit","1K - 10K","csv"],"keywords_longer_than_N":true}
]
;
