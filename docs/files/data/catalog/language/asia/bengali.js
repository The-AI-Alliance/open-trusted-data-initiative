const data_for_language_asia_bengali = 
[
	{"name":"bangla-word-to-paragraph","keyword":"bengali","license":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":"en","dataset_url":"https://huggingface.co/datasets/Shakil2448868/bangla-word-to-paragraph","creator_name":"Shakil khan","creator_url":"https://huggingface.co/Shakil2448868","description":"Shakil2448868/bangla-word-to-paragraph dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Bengali","ms-pl","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"miracl-vision","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nvidia/miracl-vision","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","description":"\n\t\n\t\t\n\t\tMIRACL-VISION\n\t\n\nMIRACL-VISION is a multilingual visual retrieval dataset for 18 different languages. It is an extension of MIRACL, a popular text-only multilingual retrieval dataset. The dataset contains user questions, images of Wikipedia articles and annotations, which article can answer a user question. There are 7898 questions and 338734 images. More details can be found in the paper MIRACL-VISION: A Large, multilingual, visual document retrieval benchmark.\nThis dataset is readyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/miracl-vision.","first_N":5,"first_N_keywords":["document-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"MUSTARD","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/badrivishalk/MUSTARD","creator_name":"Badri Vishal Kasuba","creator_url":"https://huggingface.co/badrivishalk","description":"\n\t\n\t\t\n\t\tDataset Card for MUSTARD\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMUSTARD (Multilingual Scanned and Scene Table Structure Recognition Dataset) is a diverse dataset curated for table structure recognition across multiple languages. The dataset consists of tables extracted from magazines, including printed, scanned, and scene-text tables, labeled with Optimized Table Structure Language (OTSL) sequences. It is designed to facilitate research in multilingual tableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/badrivishalk/MUSTARD.","first_N":5,"first_N_keywords":["image-to-text","English","Hindi","Telugu","Tamil"],"keywords_longer_than_N":true},
	{"name":"IGB_XorQA","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IGB_XorQA","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"VarunGumma/IGB_XorQA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"MIRACLRetrieval","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MIRACLRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MIRACLRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttp://miracl.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MIRACLRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","RSamoed/MIRACLRetrieval","Arabic"],"keywords_longer_than_N":true},
	{"name":"TinyDS-20k","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","description":"\n\t\n\t\t\n\t\tTinyDS\n\t\n\n\n\n\nAlpaca-style dataset with around 20k samples scraped from Qwen3-8B using SyntheticAlpaca. Q&A pairs can be in 32 different languages, these are listed in the metadata.Topics are all around STEM, programming, and literature.  \nMIT @ 2025 Hamzah Asadullah\n\n\n","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"multiblimp","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jumelet/multiblimp","creator_name":"Jaap Jumelet","creator_url":"https://huggingface.co/jumelet","description":"\n\t\n\t\t\n\t\tMultiBLiMP\n\t\n\nMultiBLiMP is a massively Multilingual Benchmark for Linguistic Minimal Pairs. The dataset is composed of synthetic pairs generated using Universal Dependencies and UniMorph.\nThe paper can be found here.\nWe split the data set by language: each language consists of a single .tsv file. The rows contain many attributes for a particular pair, most important are the sen and wrong_sen fields, which we use for evaluating the language models.\n\n\t\n\t\t\n\t\n\t\n\t\tUsing MultiBLiMP\n\t\n\nToâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jumelet/multiblimp.","first_N":5,"first_N_keywords":["multilingual","Buriat","Spanish","Sanskrit","Romanian"],"keywords_longer_than_N":true},
	{"name":"bangla-math-chat","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shawon/bangla-math-chat","creator_name":"Shawon Ashraf","creator_url":"https://huggingface.co/shawon","description":"\n\t\n\t\t\n\t\tbangla-math-chat\n\t\n\nA math dataset for fine-tuning LLMs to chat on math problems in Bangla. This dataset is a reformatted version of \nBanglaLLM/bangla_math_by_Ashrafur. \nThe code to reformat the original dataset can be found on Github: ShawonAshraf/bangla-math-chat\n","first_N":5,"first_N_keywords":["question-answering","Bengali","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"bangla-math-chat","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shawon/bangla-math-chat","creator_name":"Shawon Ashraf","creator_url":"https://huggingface.co/shawon","description":"\n\t\n\t\t\n\t\tbangla-math-chat\n\t\n\nA math dataset for fine-tuning LLMs to chat on math problems in Bangla. This dataset is a reformatted version of \nBanglaLLM/bangla_math_by_Ashrafur. \nThe code to reformat the original dataset can be found on Github: ShawonAshraf/bangla-math-chat\n","first_N":5,"first_N_keywords":["question-answering","Bengali","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"redblueai.sed","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Ahiyan/redblueai.sed","creator_name":"Ahiyan Kabir","creator_url":"https://huggingface.co/Ahiyan","description":"Ahiyan/redblueai.sed dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","summarization","text-to-image","English","German"],"keywords_longer_than_N":true},
	{"name":"milu-cleaned","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/murthyrudra/milu-cleaned","creator_name":"Rudra Murthy","creator_url":"https://huggingface.co/murthyrudra","description":"\n\t\n\t\t\n\t\tMILU: A Multi-task Indic Language Understanding Benchmark\n\t\n\n\n  \n  \n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nMILU (Multi-task Indic Language Understanding Benchmark) is a comprehensive evaluation dataset designed to assess the performance of Large Language Models (LLMs) across 11 Indic languages. It spans 8 domains and 41 subjects, reflecting both general and culturally specific knowledge from India.\n\n\t\n\t\n\t\n\t\tKey Features\n\t\n\n\n11 Indian Languages: Bengali, Gujarati, Hindi, Kannada, Malayalamâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/murthyrudra/milu-cleaned.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2Jyq/common_voice_21_0","creator_name":"2Jyq","creator_url":"https://huggingface.co/2Jyq","description":"Due to storage limits some files had to be split into multiple parts. They can be merged like this: cat file.* > file.\n","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","multilingual","extended|common_voice","Abkhaz"],"keywords_longer_than_N":true},
	{"name":"morphscore","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/catherinearnett/morphscore","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","description":"\n\t\n\t\t\n\t\tMorphScore\n\t\n\nMorphScore is a tokenizer evaluation framework, which evaluates the extent to which a tokenizer segments words along morpheme boundaries. This repository contains the datasets used to calculate MorphScore.\nIn total, we have datasetes for 86 languages, but only 70 languages have at least 100 items after filtering. \nAll datasets are derived from existing Universal Dependencies treebanks. In the table below, we link the source dataset for each language. \nSee the new preprintâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/morphscore.","first_N":5,"first_N_keywords":["Arabic","English","German","Russian","Turkish"],"keywords_longer_than_N":true},
	{"name":"IndicQuest","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/l3cube-pune/IndicQuest","creator_name":"L3Cube Labs","creator_url":"https://huggingface.co/l3cube-pune","description":"\n\t\n\t\t\n\t\tL3Cube-IndicQuest: A Benchmark Question Answering Dataset for Evaluating Knowledge of LLMs in Indic Context (LLM Factual Accuracy Benchmark)\n\t\n\nL3Cube-IndicQuest is a dataset comprising 4,000 question-answer pairs across 20 languages, including English, Assamese, Bengali, Dogri, Gujarati, Hindi, Kannada, Konkani, Maithili, Malayalam, Marathi, Meitei (Manipuri), Nepali, Odia, Punjabi, Sanskrit, Sindhi, Tamil, Telugu, and Urdu. This dataset is designed to assess the knowledgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/l3cube-pune/IndicQuest.","first_N":5,"first_N_keywords":["question-answering","English","Assamese","Bengali","Gujarati"],"keywords_longer_than_N":true},
	{"name":"INDICSTR12_REAL_IMAGES","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ananya12k/INDICSTR12_REAL_IMAGES","creator_name":"Ananya Kulkarni","creator_url":"https://huggingface.co/ananya12k","description":"ananya12k/INDICSTR12_REAL_IMAGES dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Marathi","Bengali","Kannada","Oriya","Panjabi"],"keywords_longer_than_N":true},
	{"name":"bangla-instruction-dataset","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kamruzzaman-asif/bangla-instruction-dataset","creator_name":"Kamruzzaman Asif","creator_url":"https://huggingface.co/kamruzzaman-asif","description":"\n\t\n\t\t\n\t\tðŸ§  Bangla Instruction Dataset\n\t\n\nThis dataset repository consolidates high-quality instruction-tuning data from multiple popular sources, structured for easy use in training and evaluating instruction-following models.\n\n\t\n\t\t\n\t\tðŸ“š Dataset Splits\n\t\n\nThe dataset is organized into the following splits:\n\n\t\n\t\t\nSplit Name\nSource Dataset\nDescription\n\n\n\t\t\nOdiaGenAI\nOdiaGenAI/all_combined_bengali_252k\nA large-scale collection of diverse Bangla instructions and responses.\n\n\nchrononeelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kamruzzaman-asif/bangla-instruction-dataset.","first_N":5,"first_N_keywords":["text-generation","question-answering","text-classification","Bengali","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"BengaliSentimentAnalysis","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BengaliSentimentAnalysis","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BengaliSentimentAnalysis\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\ndataset contains 3307 Negative reviews and 8500 Positive reviews collected and manually annotated from Youtube Bengali drama.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\nReference\nhttps://data.mendeley.com/datasets/p6zc7krs37/4\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BengaliSentimentAnalysis.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"HinDialectClassification","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/HinDialectClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  HinDialectClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHinDialect: 26 Hindi-related languages and dialects of the Indic Continuum in North India\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Spoken, Written\n\n\nReferencehttps://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-4839\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/HinDialectClassification.","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-annotated","monolingual","Angika"],"keywords_longer_than_N":true},
	{"name":"IndicLangClassification","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicLangClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicLangClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Non-fiction, Written\nReference\nhttps://arxiv.org/abs/2305.15814\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicLangClassification\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicLangClassification.","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-annotated","monolingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"MIRACLRetrieval","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RSamoed/MIRACLRetrieval","creator_name":"RS","creator_url":"https://huggingface.co/RSamoed","description":"\n  MIRACLRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttp://miracl.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/RSamoed/MIRACLRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","Arabic","Bengali"],"keywords_longer_than_N":true},
	{"name":"bengali-hate-speech-dataset","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yanjo/bengali-hate-speech-dataset","creator_name":"John Y","creator_url":"https://huggingface.co/Yanjo","description":"from https://www.kaggle.com/datasets/naurosromim/bengali-hate-speech-dataset?resource=download\njust prefer to use through hf\n","first_N":5,"first_N_keywords":["Bengali","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"BnMMLU","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/samanjoy2/BnMMLU","creator_name":"Saman Sarker Joy","creator_url":"https://huggingface.co/samanjoy2","description":"\n\t\n\t\t\n\t\tBnMMLU: Measuring Massive Multitask Language Understanding in Bengali\n\t\n\nBnMMLU is a multiple-choice Bengali-language benchmark for Massive Multitask Language Understanding. It covers various academic and general-knowledge subjects (e.g., Accounting, Mathematics, Science, Humanities) with each example consisting of:\n\n(string): Unique question identifier.\n(string): Domain/subject of the question (e.g., Accounting).\n(string): The Bengali question text.\n(list<string>): Four answer choicesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/samanjoy2/BnMMLU.","first_N":5,"first_N_keywords":["question-answering","Bengali","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"indic-squad","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/l3cube-pune/indic-squad","creator_name":"L3Cube Labs","creator_url":"https://huggingface.co/l3cube-pune","description":"\n\t\n\t\t\n\t\tIndicSQuAD Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nIndicSQuAD is a comprehensive multilingual extractive Question Answering (QA) dataset covering nine major Indic languages: Hindi, Bengali, Tamil, Telugu, Marathi, Gujarati, Urdu, Kannada, Oriya, and Malayalam. It's systematically derived from the popular English SQuAD (Stanford Question Answering Dataset).\nThe rapid progress in QA systems has predominantly benefited high-resource languages, leaving Indic languages significantlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/l3cube-pune/indic-squad.","first_N":5,"first_N_keywords":["question-answering","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"code-switching-tokenizer-robustness","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","description":"\n\t\n\t\t\n\t\tCode-Switching Dataset for Tokenizer Robustness Analysis\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for tokenizer robustness testing in multilingual and code-switching contexts. It contains identical content expressed across 16 different language variants, including pure English and 15 English-X code-switching pairs, allowing researchers to isolate tokenization effects from semantic differences when evaluating language models.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\n\nTokenizer Comparison:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness.","first_N":5,"first_N_keywords":["text-generation","text-classification","multilingual","English","Russian"],"keywords_longer_than_N":true},
	{"name":"sib200_14classes","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200_14classes","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for SIB-200\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\nThe train/validation/test sets are available for all the 205 languages.\nThis is another version with 14 classes, more idea for few-shot evaluation, it has 5 examples for few-shot, and larger test set (1225)\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopic classification: categorize wikipedia sentencesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200_14classes.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"oasst1","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"wikipedia-monthly","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/omarkamali/wikipedia-monthly","creator_name":"Omar Kamali","creator_url":"https://huggingface.co/omarkamali","description":"\n\t\n\t\t\n\t\tðŸš€ Wikipedia Monthly\n\t\n\nLast updated: July 16, 2025, 22:53 UTC\nThis repository provides monthly, multilingual dumps of Wikipedia, processed and prepared for easy use in NLP projects.\nNOTE: The first run is still in progress and languages are still being processed and uploaded.\n\n\n\t\n\t\t\n\t\tðŸ“Š Live Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nðŸŒ Languages Available\n341\n\n\nðŸ“„ Total Articles\n64.5M\n\n\nðŸ’¾ Total Size\n205.54 GB\n\n\n\t\n\n\n\n\t\n\t\t\n\t\tWhy Use This Dataset?\n\t\n\n\nFreshness: We run our pipeline monthlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/omarkamali/wikipedia-monthly.","first_N":5,"first_N_keywords":["Abkhaz","Achinese","Adyghe","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"oasst2","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\n\t\n\t\t\n\t\tOpen Assistant Conversations Dataset Release 2 (OASST2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \nAll messages have a role property: this can either be \"assistant\" or \"prompter\". The roles in \nconversation threads from prompt to leaf node strictly alternate between \"prompter\" andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU ðŸŒ is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) ðŸ—½ or Culturally Agnostic (CA) âš–ï¸. These annotations were collected as part of an openâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU.","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tDataset Card for \"xtreme\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"mgsm","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/juletxara/mgsm","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","description":"Multilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper [Language models are multilingual chain-of-thought reasoners](http://arxiv.org/abs/2210.03057).\n\nThe same 250 problems from [GSM8K](https://arxiv.org/abs/2110.14168) are each translated via human annotators in 10 languages. The 10 languages are:\n- Spanish\n- French\n- German\n- Russian\n- Chinese\n- Japanese\n- Thai\n- Swahili\n- Bengali\n- Telugu\n\nYou can find the input and targets for each of the ten languages (and English) as `.tsv` files.\nWe also include few-shot exemplars that are also manually translated from each language in `exemplars.py`.","first_N":5,"first_N_keywords":["found","found","expert-generated","multilingual","extended|gsm8k"],"keywords_longer_than_N":true},
	{"name":"multilingual-tts","keyword":"bengali","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/multilingual-tts","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\n\t\n\t\t\n\t\tBefore Anything and Everything âš±\n\t\n\nIn the time of writing this Dataset Card, 17,490 18,412 civilian has been killed in Palestine (7,870 8,000 are children and 6,121 6,200 are women).\nSeek any non-profit organization to help them with what you can (For myself, I use Mersal) ðŸ‡µðŸ‡¸\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe Multilingual TTS dataset is an exceptional compilation of text-to-speech (TTS) samples, meticulously crafted to showcase the richness and diversity of human languages.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/multilingual-tts.","first_N":5,"first_N_keywords":["text-to-speech","Arabic","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) â†’ aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages â†’ dolly-machine-translated.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\n\t\n\t\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\nWe translated the MMLUâ€™s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increasesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"mmlu-indic","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sarvamai/mmlu-indic","creator_name":"Sarvam AI","creator_url":"https://huggingface.co/sarvamai","description":"\n\t\n\t\t\n\t\tIndic MMLU Dataset\n\t\n\nA multilingual version of the Massive Multitask Language Understanding (MMLU) benchmark, translated from English into 10 Indian languages.\nThis version contains the translations of the development and test sets only. \n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\nThe dataset includes translations in the following languages:\n\nBengali (bn)\nGujarati (gu)\nHindi (hi)\nKannada (kn)\nMarathi (mr)\nMalayalam (ml)\nOriya (or)\nPunjabi (pa)\nTamil (ta)\nTelugu (te)\n\n\n\t\n\t\t\n\t\tTask Format\n\t\n\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sarvamai/mmlu-indic.","first_N":5,"first_N_keywords":["question-answering","Bengali","English","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tWMT24++\n\t\n\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\nthe publication\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\nIf you are interested in the images of the source URLs for each document, please see here.\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach language pair is stored in its own jsonl file.\nEach row isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"vox-communis-parallel-g2p","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p","creator_name":"FlÃ¡vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","description":"\n\t\n\t\t\n\t\tVoxCommunis Parallel G2P dataset\n\t\n\nThis dataset was derived from the VoxCommunis Corpus to provide pairs of utterances along with their\ncorresponding phonemes, side by side, as to ease the training of grapheme-to-phoneme (G2P) models.\nThe original VoxCommunis Corpus features force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus.\nThe lexicons were developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p.","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"alt","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mutiyama/alt","creator_name":"Masao Utiyama","creator_url":"https://huggingface.co/mutiyama","description":"\n\t\n\t\t\n\t\tDataset Card for Asian Language Treebank (ALT)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ALT project aims to advance the state-of-the-art Asian natural language processing (NLP) techniques through the open collaboration for developing and using ALT. It was first conducted by NICT and UCSY as described in Ye Kyaw Thu, Win Pa Pa, Masao Utiyama, Andrew Finch and Eiichiro Sumita (2016). Then, it was developed under ASEAN IVO as described in this Web page. \nThe process of building ALT began withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mutiyama/alt.","first_N":5,"first_N_keywords":["translation","token-classification","parsing","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"bn_hate_speech","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rezacsedu/bn_hate_speech","creator_name":"Rezaul Karim, PhD.","creator_url":"https://huggingface.co/rezacsedu","description":"\n\t\n\t\t\n\t\tDataset Card for Bengali Hate Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Bengali Hate Speech Dataset is a Bengali-language dataset of news articles collected from various Bengali media sources and categorized based on the type of hate in the text. The dataset was created to provide greater support for under-resourced languages like Bengali on NLP tasks, and serves as a benchmark for multiple types of classification tasks. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rezacsedu/bn_hate_speech.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"bengali","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for Opus Ubuntu\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\nE.g.\ndataset = load_dataset(\"opus_ubuntu\", lang1=\"it\", lang2=\"pl\")\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboardsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"tydiqa","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/tydiqa","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for \"tydiqa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\nin the world. It contains language phenomena that would not be found inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/tydiqa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"BAAD16","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aisha/BAAD16","creator_name":"Aisha Khatun","creator_url":"https://huggingface.co/Aisha","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nBAAD16 is an Authorship Attribution dataset for Bengali Literature. It was collected and analyzed by the authors of this paper. It was created by scraping text from an online Bangla e-library using custom web crawler and contains literary works of various famous Bangla writers. It contains novels, stories, series, and other works of 16 authors. Each sample document is created with 750 words. The dataset is imbalanced and resembles real-world scenarios more closely, whereâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Aisha/BAAD16.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","found","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"BAAD6","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aisha/BAAD6","creator_name":"Aisha Khatun","creator_url":"https://huggingface.co/Aisha","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nBAAD6 is an Authorship Attribution dataset for Bengali Literature. It was collected and analyzed by Hemayet et al [1]. The data was obtained from different online posts and blogs. This dataset is balanced among the 6 Authors with 350 sample texts per author. This is a relatively small dataset but is noisy given the sources it was collected from and its cleaning procedure. Nonetheless, it may help evaluate authorship attribution systems as it resembles texts oftenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Aisha/BAAD6.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","found","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"mr-tydi-corpus","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/mr-tydi-corpus","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\nThis dataset stores documents of Mr. TyDi. To access the queries and judgments, please refer to castorini/mr-tydi.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe only configuration here is the language. As all three folds (train, dev and test) share the sameâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi-corpus.","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"mr-tydi","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/mr-tydi","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\nThis dataset stores the queries, judgements, and example training data of Mr. TyDi. To access the corpus, please refer to castorini/mr-tydi-corpus.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe only configuration here is the language, \nFor each languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi.","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"indicxnli","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Divyanshu/indicxnli","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","description":"IndicXNLI is a translated version of XNLI to 11 Indic Languages. As with XNLI, the goal is\nto predict textual entailment (does sentence A imply/contradict/neither sentence\nB) and is a classification task (given two sentences, predict one of three\nlabels).","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","machine-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\n\t\n\t\t\n\t\tDataset Card for WIT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\nFrom the official blog post:\n\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\nThe WIT dataset offers extremely valuable data about theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_scenario","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_scenario","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveScenarioClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveScenarioClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_scenario.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_intent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveIntentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_intent.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"xP3all","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"answerable_tydiqa","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/answerable_tydiqa","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\n\t\n\t\t\n\t\tDataset Card for \"answerable-tydiqa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages. \nAnswerable TyDi QA is an extension of the GoldP subtask of the original TyDi QA dataset to also include unanswertable questions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains a train and a validation set, with 116067 and 13325 examples, respectively. Access them with\nfrom datasets import load_dataset\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/answerable_tydiqa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"tydiqa_copenlu","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/tydiqa_copenlu","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\n\t\n\t\t\n\t\tDataset Card for \"tydiqa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\nin the world. It contains language phenomena that would not be found inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/tydiqa_copenlu.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3mt","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"miracl-corpus","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/miracl-corpus","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\n\t\n\t\t\n\t\tDataset Card for MIRACL Corpus\n\t\n\nMIRACL ðŸŒðŸ™ŒðŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\nThis dataset contains the collection data of the 16 \"known languages\". The remaining 2 \"surprise languages\" will not be released until later.\nThe corpus for each language is prepared from a Wikipediaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"IE_SemParse","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Divyanshu/IE_SemParse","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","description":"    IE-SemParse is an Inter-bilingual Seq2seq Semantic parsing dataset for 11 distinct Indian languages","first_N":5,"first_N_keywords":["parsing","machine-generated","machine-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"bn_emotion_speech_corpus","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sustcsenlp/bn_emotion_speech_corpus","creator_name":"SUST CSE NLP Research","creator_url":"https://huggingface.co/sustcsenlp","description":"SUST Bangla Emotional Speech Coropus Dataset","first_N":5,"first_N_keywords":["audio-classification","Bengali","cc-by-4.0","1K - 10K","Audio"],"keywords_longer_than_N":true},
	{"name":"naamapadam","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/naamapadam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\\","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","machine-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"miracl-bn-corpus-22-12","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-bn-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\n\t\n\t\t\n\t\tMIRACL (bn) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-bn-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-bn-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL ðŸŒðŸ™ŒðŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrievalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-bn-corpus-22-12.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Bengali"],"keywords_longer_than_N":true},
	{"name":"miracl-bn-queries-22-12","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-bn-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\n\t\n\t\t\n\t\tMIRACL (bn) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-bn-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-bn-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL ðŸŒðŸ™ŒðŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrievalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-bn-queries-22-12.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Bengali"],"keywords_longer_than_N":true},
	{"name":"pwesuite-eval","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zouharvi/pwesuite-eval","creator_name":"VilÃ©m Zouhar","creator_url":"https://huggingface.co/zouharvi","description":"\n\n\t\n\t\t\n\t\tPWESuite-Eval\n\t\n\nDataset composed of multiple smaller datasets used for the evaluation of phonetic word embeddings.\nSee code for evaluation here.\nIf you use this dataset/evaluation, please cite the paper at LREC-COLING 2024:\n@inproceedings{zouhar-etal-2024-pwesuite,\n    title = \"{PWES}uite: Phonetic Word Embeddings and Tasks They Facilitate\",\n    author = \"Zouhar, Vil{\\'e}m  and\n      Chang, Kalvin  and\n      Cui, Chenxuan  and\n      Carlson, Nate B.  and\n      Robinson, Nathanielâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/pwesuite-eval.","first_N":5,"first_N_keywords":["multilingual","English","Amharic","Bengali","Swahili"],"keywords_longer_than_N":true},
	{"name":"wmt-da-human-evaluation","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation","creator_name":"Ricardo Rei","creator_url":"https://huggingface.co/RicardoRei","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains all DA human annotations from previous WMT News Translation shared tasks.\nThe data is organised into 8 columns:\n\nlp: language pair\nsrc: input text\nmt: translation\nref: reference translation\nscore: z score\nraw: direct assessment\nannotators: number of annotators\ndomain: domain of the input text (e.g. news)\nyear: collection year\n\nYou can also find the original data for each year in the results section https://www.statmt.org/wmt{YEAR}/results.htmlâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation.","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Estonian"],"keywords_longer_than_N":true},
	{"name":"multiconer_v2","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MultiCoNER/multiconer_v2","creator_name":"MultiCoNER","creator_url":"https://huggingface.co/MultiCoNER","description":"Complex named entities (NE), like the titles of creative works, are not simple nouns and pose challenges for NER systems (Ashwini and Choi, 2014). They can take the form of any linguistic constituent, like an imperative clause (â€œDial M for Murderâ€), and do not look like traditional NEs (Persons, Locations, etc.). This syntactic ambiguity makes it challenging to recognize them based on context. We organized the MultiCoNER task (Malmasi et al., 2022) at SemEval-2022 to address these challenges in 11 languages, receiving a very positive community response with 34 system papers. Results confirmed the challenges of processing complex and long-tail NEs: even the largest pre-trained Transformers did not achieve top performance without external knowledge. The top systems infused transformers with knowledge bases and gazetteers. However, such solutions are brittle against out of knowledge-base entities and noisy scenarios like the presence of spelling mistakes and typos. We propose MultiCoNER II which represents novel challenges through new tasks that emphasize the shortcomings of the current top models.\n\nMultiCoNER II features complex NER in these languages:\n\n1. English\n2. Spanish\n3. Hindi\n4. Bangla\n5. Chinese\n6. Swedish\n7. Farsi\n8. French\n9. Italian\n10. Portugese\n11. Ukranian\n12. German\n\nFor more details see https://multiconer.github.io/\n\n## References\n* Sandeep Ashwini and Jinho D. Choi. 2014. Targetable named entity recognition in social media. CoRR, abs/1408.0782.\n* Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta Kar, Oleg Rokhlenko. 2022. SemEval-2022 Task 11: Multilingual Complex Named Entity Recognition (MultiCoNER).","first_N":5,"first_N_keywords":["token-classification","Bengali","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"bn_news_summarization","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sustcsenlp/bn_news_summarization","creator_name":"SUST CSE NLP Research","creator_url":"https://huggingface.co/sustcsenlp","description":"\n\t\n\t\t\n\t\tBengali Abstractive News Summarization (BANS)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nNowadays news or text summarization becomes very popular in the NLP field. Both the extractive and abstractive approaches of summarization are implemented in different languages. A significant amount of data is a primary need for any summarization. For the Bengali language, there are only a few datasets are available. Our dataset is made for Bengali Abstractive News Summarization (BANS) purposes. As abstractiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sustcsenlp/bn_news_summarization.","first_N":5,"first_N_keywords":["summarization","Bengali","cc0-1.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof WrÃ³bel","creator_url":"https://huggingface.co/djstrong","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"Bhasha-Abhijnaanam","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tDataset Card for Aksharantar\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBhasha-Abhijnaanam is a language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\n\t\n\t\t\n\n\n\n\n\n\n\n\n\t\t\nAssamese (asm)\nHindi (hin)\nMaithili (mai)\nNepali (nep)\nSanskrit (san)\nTamil (tam)\n\n\nBengali (ben)\nKannada (kan)\nMalayalam (mal)\nOriya (ori)\nSantali (sat)\nTelugu (tel)\n\n\nBodo(brx)\nKashmiriâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\n\n\t\n\t\t\n\nToxic\nNeutral\nTotal\n\n\n\t\t\nmultilingual-train-deduplicated.csvâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Spanish","Panjabi"],"keywords_longer_than_N":true},
	{"name":"SUBESCO-audio-dataset","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sajid73/SUBESCO-audio-dataset","creator_name":"Md Sajidul Mowla","creator_url":"https://huggingface.co/sajid73","description":"\n\t\n\t\t\n\t\tSUST BANGLA EMOTIONAL SPEECH CORPUS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSUBESCO is an audio-only emotional speech corpus of 7000 sentence-level utterances of the Bangla language. 20 professional actors (10 males and 10 females) participated in the recordings of 10 sentences for 7 target emotions. The emotions are Anger, Disgust, Fear, Happiness, Neutral, Sadness and Surprise. Total duration of the corpus is 7 hours 40 min 40 sec.  Total size of the dataset is 2.03 GB. The dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sajid73/SUBESCO-audio-dataset.","first_N":5,"first_N_keywords":["audio-classification","Bengali","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"all-scam-spam","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\n1040 rows of balanced data, consisting of casual conversations and scam emails in â‰ˆ10 languages, were manually collected and annotated by me, with some help from ChatGPT.\n\n\n\n\t\n\t\t\n\t\tSome preprcoessing algorithms\n\t\n\n\nspam_assassin.js, followed by spam_assassin.py\nenron_spam.py\n\n\n\n\n\t\n\t\t\n\t\tData composition\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTo make the textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Norwegian","Spanish","Somali"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"conceptnet5_bn","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/appledora/conceptnet5_bn","creator_name":"Nazia Tasnim","creator_url":"https://huggingface.co/appledora","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThis is a subset of the conceptnet5 dataset.\nI merely parsed and extracted out my required portion and uploaded here, since processing the huge complete dataset is complicated for many users.\nPlease refer to the original authors' repo for a complete version. \n\nConceptNet is a multilingual knowledge base, representing words and\nphrases that people use and the common-sense relationships between\nthem. The knowledge in ConceptNet is collected from a variety ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/appledora/conceptnet5_bn.","first_N":5,"first_N_keywords":["parsed","Bengali","cc-by-4.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Bangla_Financial_news_articles_Dataset","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ashtrayAI/Bangla_Financial_news_articles_Dataset","creator_name":"Md. Ashraful Islam","creator_url":"https://huggingface.co/ashtrayAI","description":"\n\t\n\t\t\n\t\n\t\n\t\tBangla-Financial-news-articles-Dataset\n\t\n\nA Comprehensive Resource for Analyzing Sentiments in over 7600+ Bangla News.\n\n\t\n\t\t\n\t\n\t\n\t\tDownloads\n\t\n\nðŸ”´ Download the \"ðŸ’¥Bangla_fin_news.zip\" file for all \"7,695\" news and extract it.\n\n\t\n\t\t\n\t\n\t\n\t\tAbout Dataset\n\t\n\nWelcome to our Bengali Financial News Sentiment Analysis dataset! This collection comprises 7,695 financial news articles extracted, covering the period from March 3, 2014, to December 29, 2021. Utilizing the powerful web scrapingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ashtrayAI/Bangla_Financial_news_articles_Dataset.","first_N":5,"first_N_keywords":["cc0-1.0","ðŸ‡ºðŸ‡¸ Region: US","Bengali","News","Sentiment"],"keywords_longer_than_N":true},
	{"name":"QAmeleon","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/imvladikon/QAmeleon","creator_name":"Vladimir Gurevich","creator_url":"https://huggingface.co/imvladikon","description":"\n\t\n\t\t\n\t\tDataset Card for \"QAmeleon\"\n\t\n\nQAmeleon introduces synthetic multilingual QA data contaning in 8 langauges using PaLM-540B, a large language model. This dataset was generated by prompt tuning PaLM with only five examples per language. We use the synthetic data to finetune downstream QA models leading to improved accuracy in comparison to English-only and translation-based baselines. \nData available at https://storage.googleapis.com/qameleon/qamelon_pt_accepted.csv \nMore details can beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/imvladikon/QAmeleon.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","Finnish","Indonesian"],"keywords_longer_than_N":true},
	{"name":"bengali_asr_corpus","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parambharat/bengali_asr_corpus","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","description":"The corpus contains roughly 500 hours of audio and transcripts in Bangla language. \nThe transcripts have beed de-duplicated using exact match deduplication and audio has be converted to 16000 samples","first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|openslr"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for SIB-200\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\nThe train/validation/test sets are available for all the 205 languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 205 languages available :\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"belebele","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\n\t\n\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that discriminateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele.","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","text-classification","multiple-choice","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"GrammarNSpell","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TahmidH/GrammarNSpell","creator_name":"Tahmid Hossain","creator_url":"https://huggingface.co/TahmidH","description":"TahmidH/GrammarNSpell dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Bengali","cc0-1.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"annotated_news_summary","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TahmidH/annotated_news_summary","creator_name":"Tahmid Hossain","creator_url":"https://huggingface.co/TahmidH","description":"This dataset is created for instruction tuning purpose.It is based on the News Summarization dataset.\nThe instructions are given in the inputs column and their completions/answers are provided in the targets column. The template_id tracks each input_template-target_template pair. There are 15 template ids (from 1 to 15).\nThe ID and their respective templates are given below. no_template indicates that no template was used and only the summary or direct answer was provided for that input.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/TahmidH/annotated_news_summary.","first_N":5,"first_N_keywords":["summarization","Bengali","cc0-1.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Bengali_Sentence_Construction","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TahmidH/Bengali_Sentence_Construction","creator_name":"Tahmid Hossain","creator_url":"https://huggingface.co/TahmidH","description":"TahmidH/Bengali_Sentence_Construction dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Bengali","cc0-1.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\n\t\n\t\t\n\t\tDataset Card for WikiAnc\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \nThe code for generating the dataset can be found here.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nwikificiation: The dataset can be used to train a model for Wikification.\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in all 320â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"bangla-health-related-paraphrased-dataset","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/faisal4590aziz/bangla-health-related-paraphrased-dataset","creator_name":"Faisal MIST","creator_url":"https://huggingface.co/faisal4590aziz","description":"\n\t\n\t\t\n\t\tDataset Card for \"BanglaHealthParaphrase\"\n\t\n\n\n\nBanglaHealthParaphrase is a Bengali paraphrasing dataset specifically curated for the health domain. It contains over 200,000 sentence pairs, where each pair consists of an original Bengali sentence and its paraphrased version. The dataset was created through a multi-step pipeline involving extraction of health-related content from Bengali news sources, English pivot-based paraphrasing, and back-translation to ensure linguistic diversityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/faisal4590aziz/bangla-health-related-paraphrased-dataset.","first_N":5,"first_N_keywords":["monolingual","original","Bengali","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\n","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"PMIndiaSum","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PMIndiaData/PMIndiaSum","creator_name":"PMIndiaData","creator_url":"https://huggingface.co/PMIndiaData","description":"\n\t\n\t\t\n\t\tDataset Card for \"PMIndiaSum\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nPMIndiaSum is a new multilingual and massively parallel headline summarization corpus focused on languages in India. Our corpus covers four language families, 14 languages, and the largest to date, 196 language pairs. It provides a testing ground for all cross-lingual pairs.\n\n\t\n\t\t\n\t\tSupported tasks\n\t\n\nMonolingual, multilingual and cross-lingual summarization for languages in India.\n\n\t\n\t\t\n\t\tLanguagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PMIndiaData/PMIndiaSum.","first_N":5,"first_N_keywords":["summarization","Assamese","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"MultiJail","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail","creator_name":"Language Technology Lab at Alibaba DAMO Academy","creator_url":"https://huggingface.co/DAMO-NLP-SG","description":"\n\t\n\t\t\n\t\tMultilingual Jailbreak Challenges in Large Language Models\n\t\n\nThis repo contains the data for our paper \"Multilingual Jailbreak Challenges in Large Language Models\".\n[Github repo]\n\n\t\n\t\t\n\t\tAnnotation Statistics\n\t\n\nWe collected a total of 315 English unsafe prompts and annotated them into nine non-English languages. The languages were categorized based on resource availability, as shown below:\nHigh-resource languages: Chinese (zh), Italian (it), Vietnamese (vi)\nMedium-resource languages:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail.","first_N":5,"first_N_keywords":["English","Chinese","Italian","Vietnamese","Arabic"],"keywords_longer_than_N":true},
	{"name":"demo_data","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sagorhishab/demo_data","creator_name":"Sagor Sarker","creator_url":"https://huggingface.co/sagorhishab","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sagorhishab/demo_data.","first_N":5,"first_N_keywords":["text-generation","Bengali","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"GSM8KInstruct_Parallel","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mathoctopus/GSM8KInstruct_Parallel","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","description":"Mathoctopus/GSM8KInstruct_Parallel dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","Chinese","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"MSVAMP","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mathoctopus/MSVAMP","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","description":"Mathoctopus/MSVAMP dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Bengali","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"WikidataLabels","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rayliuca/WikidataLabels","creator_name":"Ray Liu","creator_url":"https://huggingface.co/rayliuca","description":"\n\t\n\t\t\n\t\tWikidata Labels\n\t\n\nLarge parallel corpus for machine translation\n\nEntity label data extracted from Wikidata (2022-01-03), filtered for item entities only  \nOnly download the languages you need with datasets>=2.14.0\nSimilar dataset: https://huggingface.co/datasets/wmt/wikititles (18 Wikipedia titles pairs instead of all Wikidata entities)\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources\n\t\n\n\nWikidata JSON dump (wikidata-20220103-all.json.gz)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rayliuca/WikidataLabels.","first_N":5,"first_N_keywords":["translation","English","French","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"oasst2_top1_chat_format","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","description":"\n\t\n\t\t\n\t\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\n\t\n\nExport of oasst2 only top 1 threads in huggingface chat format\n\n\t\n\t\t\n\t\tScript\n\t\n\nThe convert script can be find here\n","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"openassistant-deepseek-coder","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\n\t\n\nThis dataset allows for fine-tuning chat models using:\nB_INST = '\\n### Instruction:\\n'\nE_INST = '\\n### Response:\\n'\nBOS = '<ï½œbeginâ–ofâ–sentenceï½œ>'\nEOS = '\\n<|EOT|>\\n'\n\nSample Preparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"FranÃ§ais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"SUBAK.KO","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO","creator_name":"SUST CSE Speech Processing Lab","creator_url":"https://huggingface.co/SUST-CSE-Speech","description":"\n\t\n\t\t\n\t\tDataset Card for SUBAK.KO\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSUBAK.KO (à¦¸à§à¦¬à¦¾à¦•à§à¦¯), a publicly available annotated Bangladeshi standard Bangla speech corpus, is compiled for automatic speech recognition research. \nThis corpus contains 241 hours of high-quality speech data, including 229 hours of read speech data and 12 hours of broadcast speech data. \nThe read speech segment is recorded in a noise-proof studio environment from 33 male and 28 female native Bangladeshi Bangla speakersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Bengali","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"SUBAK.KO","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO","creator_name":"SUST CSE Speech Processing Lab","creator_url":"https://huggingface.co/SUST-CSE-Speech","description":"\n\t\n\t\t\n\t\tDataset Card for SUBAK.KO\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSUBAK.KO (à¦¸à§à¦¬à¦¾à¦•à§à¦¯), a publicly available annotated Bangladeshi standard Bangla speech corpus, is compiled for automatic speech recognition research. \nThis corpus contains 241 hours of high-quality speech data, including 229 hours of read speech data and 12 hours of broadcast speech data. \nThe read speech segment is recorded in a noise-proof studio environment from 33 male and 28 female native Bangladeshi Bangla speakersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SUST-CSE-Speech/SUBAK.KO.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Bengali","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","MetlatÃ³noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"WEATHub","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iamshnoo/WEATHub","creator_name":"Anjishnu Mukherjee","creator_url":"https://huggingface.co/iamshnoo","description":"\n\n\n\n\n\t\n\t\t\n\t\tDataset Card for \"WEATHub\"\n\t\n\nThis dataset corresponds to the data described in the paper \"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\"\naccepted to EMNLP 2023.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)\nto measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers. And weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub.","first_N":5,"first_N_keywords":["Arabic","Bengali","Central Kurdish","Danish","German"],"keywords_longer_than_N":true},
	{"name":"openassistant-falcon","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant Falcon\n\t\n\nThis dataset allows for fine-tuning chat models using '\\Human:' AND '\\nAssistant:' to wrap user messages.\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\nSample \nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"Vulgar_Lexicon_of_Chittagonian_Dialect_of_Bangla_or_Bengali","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kit-nlp/Vulgar_Lexicon_of_Chittagonian_Dialect_of_Bangla_or_Bengali","creator_name":"Kitami Institute of Technology Text Information Processing Laboratory","creator_url":"https://huggingface.co/kit-nlp","description":"A list of Chittagonian Dialect of Bangla vulgar words\nIf you use Vulgar Lexicon dataset, please cite the following paper:\n@Article{app132111875,\nAUTHOR = {Mahmud, Tanjim and Ptaszynski, Michal and Masui, Fumito},\nTITLE = {Automatic Vulgar Word Extraction Method with Application to Vulgar Remark Detection in Chittagonian Dialect of Bangla},\nJOURNAL = {Applied Sciences},\nVOLUME = {13},\nYEAR = {2023},\nNUMBER = {21},\nARTICLE-NUMBER = {11875},\nURL = {https://www.mdpi.com/2076-3417/13/21/11875}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kit-nlp/Vulgar_Lexicon_of_Chittagonian_Dialect_of_Bangla_or_Bengali.","first_N":5,"first_N_keywords":["text-classification","Bengali","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Vulgar_Lexicon_of_Chittagonian_Dialect_of_Bangla_or_Bengali","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TanjimKIT/Vulgar_Lexicon_of_Chittagonian_Dialect_of_Bangla_or_Bengali","creator_name":"Tanjim Mahmud","creator_url":"https://huggingface.co/TanjimKIT","description":"A list of Chittagonian Dialect of Bangla vulgar words\nIf you use Vulgar Lexicon dataset, please cite the following paper:\n@Article{app132111875,\nAUTHOR = {Mahmud, Tanjim and Ptaszynski, Michal and Masui, Fumito},\nTITLE = {Automatic Vulgar Word Extraction Method with Application to Vulgar Remark Detection in Chittagonian Dialect of Bangla},\nJOURNAL = {Applied Sciences},\nVOLUME = {13},\nYEAR = {2023},\nNUMBER = {21},\nARTICLE-NUMBER = {11875},\nURL = {https://www.mdpi.com/2076-3417/13/21/11875}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/TanjimKIT/Vulgar_Lexicon_of_Chittagonian_Dialect_of_Bangla_or_Bengali.","first_N":5,"first_N_keywords":["text-classification","Bengali","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"NC-SentNoB","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ktoufiquee/NC-SentNoB","creator_name":"Kazi Toufique Elahi","creator_url":"https://huggingface.co/ktoufiquee","description":"This is a multilabel dataset used for Noise Identification purpose in the paper \"A Comparative Analysis of Noise Reduction Methods in Sentiment Analysis on Noisy Bangla Texts\" accepted in 2024 The 9th Workshop on Noisy and User-generated Text (W-NUT) collocated with EACL 2024.\n\nAnnotated by 4 native Bangla speakers with 90% trustworthiness score.\nFleiss' Kappa Score: 0.69\n\n\n\t\n\t\t\n\t\tDefinition of noise categories\n\t\n\n\n\t\n\t\t\nType\nDefinition\n\n\n\t\t\nLocal Word\nAny regional words even if there is aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ktoufiquee/NC-SentNoB.","first_N":5,"first_N_keywords":["text-classification","Bengali","cc-by-sa-4.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"alpaca-cleaned-bn","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abrarfahim/alpaca-cleaned-bn","creator_name":"fahim abrar","creator_url":"https://huggingface.co/abrarfahim","description":"\n\t\n\t\t\n\t\tDataset Card for Alpaca-Cleaned-bn\n\t\n\n\n\nThis is a cleaned bengali translated version of the original Alpaca Dataset released by Stanford. \n\n\t\n\t\t\n\t\tUses\n\t\n\nimport datasets\ndataset = datasets.load_dataset(\"abrarfahim/alpaca-cleaned-bn\")\nprint(dataset[0])\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{'system_prompt': 'You are a virtual assistant, deliver a comprehensive response.',\n 'qas_id': 'YY9S5K',\n 'question_text': '\"à¦¸à¦¨à§à¦¦à§‡à¦¹\" à¦¶à¦¬à§à¦¦à§‡à¦° à¦¸à¦ à¦¿à¦• à¦ªà§à¦°à¦¤à¦¿à¦¶à¦¬à§à¦¦ à¦¨à¦¿à¦°à§à¦¬à¦¾à¦šà¦¨ à¦•à¦°à§à¦¨à¥¤',\n 'orig_answer_texts': '\"à¦¸à¦¨à§à¦¦à§‡à¦¹\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/abrarfahim/alpaca-cleaned-bn.","first_N":5,"first_N_keywords":["question-answering","text-generation","Bengali","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"alpaca-cleaned-bn","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abrarfahim/alpaca-cleaned-bn","creator_name":"fahim abrar","creator_url":"https://huggingface.co/abrarfahim","description":"\n\t\n\t\t\n\t\tDataset Card for Alpaca-Cleaned-bn\n\t\n\n\n\nThis is a cleaned bengali translated version of the original Alpaca Dataset released by Stanford. \n\n\t\n\t\t\n\t\tUses\n\t\n\nimport datasets\ndataset = datasets.load_dataset(\"abrarfahim/alpaca-cleaned-bn\")\nprint(dataset[0])\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{'system_prompt': 'You are a virtual assistant, deliver a comprehensive response.',\n 'qas_id': 'YY9S5K',\n 'question_text': '\"à¦¸à¦¨à§à¦¦à§‡à¦¹\" à¦¶à¦¬à§à¦¦à§‡à¦° à¦¸à¦ à¦¿à¦• à¦ªà§à¦°à¦¤à¦¿à¦¶à¦¬à§à¦¦ à¦¨à¦¿à¦°à§à¦¬à¦¾à¦šà¦¨ à¦•à¦°à§à¦¨à¥¤',\n 'orig_answer_texts': '\"à¦¸à¦¨à§à¦¦à§‡à¦¹\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/abrarfahim/alpaca-cleaned-bn.","first_N":5,"first_N_keywords":["question-answering","text-generation","Bengali","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_regions","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Regions\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\nKey Features:\n\nTextual Data: The dataset contains 500,000 text samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"MultiCoNER","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tomaarsen/MultiCoNER","creator_name":"Tom Aarsen","creator_url":"https://huggingface.co/tomaarsen","description":"We present MultiCoNER, a large multilingual dataset for Named Entity Recognition that covers 3 domains (Wiki sentences, questions, and search queries) across 11 languages, as well as multilingual and code-mixing subsets. This dataset is designed to represent contemporary challenges in NER, including low-context scenarios (short and uncased text), syntactically complex entities like movie titles, and long-tail entity distributions. The 26M token dataset is compiled from public resources using techniques such as heuristic-based sentence sampling, template extraction and slotting, and machine translation. We applied two NER models on our dataset: a baseline XLM-RoBERTa model, and a state-of-the-art GEMNET model that leverages gazetteers. The baseline achieves moderate performance (macro-F1=54%), highlighting the difficulty of our data. GEMNET, which uses gazetteers, improvement significantly (average improvement of macro-F1=+30%). MultiCoNER poses challenges even for large pre-trained language models, and we believe that it can help further research in building robust NER systems. MultiCoNER is publicly available at https://registry.opendata.aws/multiconer/ and we hope that this resource will help advance research in various aspects of NER.","first_N":5,"first_N_keywords":["token-classification","Bengali","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"openassistant-guanaco-EOS","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Guanaco Style\n\t\n\nThis dataset allows for fine-tuning chat models using \"### Human:\" AND \"### Assistant\" as the beginning and end of sequence tokens.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then slightly adjusted to:\n\n\nif a row ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"openassistant-llama-style","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Llama 2 Style\n\t\n\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then filtered to:\n\n\nreplace instances of '### Human:' with '[INST]'\nreplaceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"bhasha-sft","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/soketlabs/bhasha-sft","creator_name":"Soket Labs","creator_url":"https://huggingface.co/soketlabs","description":"\n\t\n\t\t\n\t\tBhasha SFT\n\t\n\n\nBhasha SFT is a massive collection of multiple open sourced Supervised Fine-Tuning datasets for training Multilingual \nLarge Language Models. The dataset contains collation of over 13 million instances of\ninstruction-response data for 3 Indian languages (Hindi, Gujarati, Bengali) and English having both human annotated and synthetic data.\n\nCurated by: Soket AI Labs\nLanguage(s) (NLP): [English, Hindi, Bengali, Gujarati]\nLicense: [cc-by-4.0, apache-2.0, mit]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/soketlabs/bhasha-sft.","first_N":5,"first_N_keywords":["question-answering","translation","summarization","text-generation","Hindi"],"keywords_longer_than_N":true},
	{"name":"bhasha-wiki-translated","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/soketlabs/bhasha-wiki-translated","creator_name":"Soket Labs","creator_url":"https://huggingface.co/soketlabs","description":"\n\t\n\t\t\n\t\tBhasha Wikipedia Translated\n\t\n\n\nTranslated wikipedia articles\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nDataset is being updated\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nWe have translated 6.185 million English wikipedia articles into 6 Indic languages. The translations were done using IndicTrans2 model.\n\nCurated by: Soket AI labs\nLanguage(s) (NLP): Hindi, Bengali, Gujarati, Tamil, Kannada, Urdu\nLicense: cc-by-sa-4.0\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\nFor pretraining or Fine tuning for Indic language models\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/soketlabs/bhasha-wiki-translated.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","Hindi"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"oaast_rm_full_jieba","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"å°è¯•è§£å†³\"llm repetition problem\"ï¼Œä½¿ç”¨åˆ†è¯æ¨¡åž‹å¯¹oaastè¯­æ–™è¿›è¡Œâ€œç»“å·´åŒ–â€æ•°æ®å¢žå¼ºï¼Œæä¾›æ›´å¼ºçš„é‡å¤å†…å®¹æ‹’ç»æ•ˆæžœã€‚\nAttempts to solve the \"llm repetition problem\" by using a segmentation model to enhance the oaast corpus with \"stuttering\" data to provide stronger rejection of duplicate content.\nå…¶æ¬¡ï¼Œè¿˜è¿‡æ»¤æŽ‰äº†æ‰€æœ‰è‡ªæˆ‘è®¤çŸ¥çš„å¾®è°ƒæ ·æœ¬ã€‚\nSecond, it also filters out all the fine-tuned samples of self-cognition.\nfiles:\n\noaast_rm_full_jieba.jsonl : word level repeat\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\n\n","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"Ø§Ù…Ø§Ù… Ø¬Ù…Ø¹Ù‡ Ø§ØµÙÙ‡Ø§Ù† Ú¯ÙØª: Ù…ÛŒØ²Ø§Ù† Ù†ÛŒØ§Ø² Ø¢Ø¨ Ø´Ø±Ø¨ Ø§ØµÙÙ‡Ø§Ù† Û±Û±.Ûµ Ù…ØªØ± Ù…Ú©Ø¹Ø¨ Ø§Ø³Øª Ú©Ù‡ ØªÙ…Ø§Ù… Ø§Ø³ØªØ§Ù† Ø§ØµÙÙ‡Ø§Ù† Ø±Ø§ Ù¾ÙˆØ´Ø´ Ù…ÛŒØ¯Ù‡Ø¯ Ùˆ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ù†Ù‚Ù„Ø§Ø¨ ÛŒÚ©ÛŒ Ø§Ø² Ù¾ÛŒØ´Ø±ÙØªÙ‡Ø§ Ø¯Ø± Ø­ÙˆØ²Ù‡ Ø¢Ø¨ Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"mapps-filtered","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/deokhk/mapps-filtered","creator_name":"Deokhyung Kang","creator_url":"https://huggingface.co/deokhk","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a multilingual extension of the \"introductory\" level problems from the codeparrot/apps dataset, which focuses on programming tasks. We filtered the original dataset to include only questions formatted in Standard Input Format, where each problem specifies the expected standard input/output for the solution.\nThis filtering yields 974 problems. \nThe selected problems were then translated from English into six target languages:\n\nSpanish\nKoreanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/deokhk/mapps-filtered.","first_N":5,"first_N_keywords":["English","Spanish","Korean","Chinese","Bengali"],"keywords_longer_than_N":true},
	{"name":"lr-sum","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\tDataset Card for LR-Sum\n\t\n\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \nThe data is based on theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum.","first_N":5,"first_N_keywords":["summarization","text-generation","found","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"Indic-subtitler-audio_evals","keyword":"bengali","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kurianbenoy/Indic-subtitler-audio_evals","creator_name":"Kurian Benoy","creator_url":"https://huggingface.co/kurianbenoy","description":"\n\t\n\t\t\n\t\tIndic_audio_evals\n\t\n\nAs part of this project. We are evaluating our performance of various ASR models as well\nin a benchmarking dataset, we have created in various languages. This benchmarking dataset\nis more alligned to real-world use-cases rather than having any academic datasets.\n\n\t\n\t\t\n\t\tAbout Dataset\n\t\n\n\nDataset Link in HuggingFace: kurianbenoy/Indic-subtitler-audio_evals\n\nThis dataset contains audio file in .wav format and video file in .mp4. The respective groundtruth will beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kurianbenoy/Indic-subtitler-audio_evals.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Malayalam","Hindi","English","Bengali"],"keywords_longer_than_N":true},
	{"name":"mCoT-MATH","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laihuiyuan/mCoT-MATH","creator_name":"Huiyuan Lai","creator_url":"https://huggingface.co/laihuiyuan","description":"\n\t\n\t\t\n\t\tmCoT: Multilingual Instruction Tuning for Reasoning Consistency in Language Models\n\t\n\nPaper: https://arxiv.org/abs/2406.02301\nCode: https://github.com/laihuiyuan/mCoT\nModel: https://huggingface.co/laihuiyuan/mCoT\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nBased on MetaMathQA and MathInstruct\n, we use machine translation to compile mCoT-MATH, the first large-scale multilingual math CoT reasoning dataset containing around 6.3 million samples for 11 diverse languages.\nWe train a 7B parameter model mCoT forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/laihuiyuan/mCoT-MATH.","first_N":5,"first_N_keywords":["Swahili","Bengali","Telugu","Thai","Japanese"],"keywords_longer_than_N":true},
	{"name":"megawika-report-generation","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\n\t\n\t\t\n\t\tDataset Card for MegaWika for Report Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\nnon-English language, an automated English translation is provided. \nThis dataset provides theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation.","first_N":5,"first_N_keywords":["summarization","text-retrieval","text-generation","Afrikaans","Arabic"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\nand converted into different parts (see process.py):\n\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\n\nRaw data files are in raw.tar.gz, which contains:\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\n[...] 9.8M Feb 24â€¦ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"mittens","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/mittens","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tMiTTenS: A Dataset for Evaluating Misgendering in Translation\n\t\n\nMisgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scriptsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/mittens.","first_N":5,"first_N_keywords":["translation","Arabic","Finnish","Oromo","Ganda"],"keywords_longer_than_N":true},
	{"name":"BongChat-v1-253k","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lumatic-ai/BongChat-v1-253k","creator_name":"LumaticAI","creator_url":"https://huggingface.co/lumatic-ai","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nWelcome to LumaticAI's BongChat Dataset! \nWe understand the challenges of non-English language models, so we're introducing lumatic-ai/BongLlama-1.1B-Chat-alpha-v0-dataset set of 10,000 instructions for better language understanding. It covers various categories like Generation, Open QA, Brainstorm, Chat, and more. Ideal for improving models in Bangla, it's a valuable resource for efficient instruction-based training. Unleash the potential of yourâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lumatic-ai/BongChat-v1-253k.","first_N":5,"first_N_keywords":["question-answering","text-generation","Bengali","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"shrutilipi","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amithm3/shrutilipi","creator_name":"Amith M","creator_url":"https://huggingface.co/amithm3","description":"amithm3/shrutilipi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","Sanskrit","Bengali","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Open_Assistant_Conversation_Chains","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset description\n\t\n\n\n\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\n\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\n\nIt was modifiedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains.","first_N":5,"first_N_keywords":["text-generation","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"piqa-bn","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hishab/piqa-bn","creator_name":"Hishab","creator_url":"https://huggingface.co/hishab","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the translated version of the PIQA LLM evaluation dataset. The dataset was translated using a new method called Expressive Semantic Translation (EST), which combines Google Translation with LLM-based rewriting. PIQA introduces the task of physical commonsense reasoning and provides a corresponding benchmark for understanding physical interactions in everyday situations. It focuses on atypical solutions to practical problems, inspired by instructional guidesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hishab/piqa-bn.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","monolingual","Bengali","mit"],"keywords_longer_than_N":true},
	{"name":"commonsenseqa-bn","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hishab/commonsenseqa-bn","creator_name":"Hishab","creator_url":"https://huggingface.co/hishab","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the Bangla translated version of the CommonsenseQA dataset. The dataset was translated using a new method called Expressive Semantic Translation (EST). This method combines both Google Machine Translation and LLM-based rewriting of the translation to enhance the expressiveness and semantic accuracy of the translated content.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData instances\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDefaults\n\t\n\nAn example of a 'train' looks as follows:\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hishab/commonsenseqa-bn.","first_N":5,"first_N_keywords":["question-answering","monolingual","Bengali","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"limmits-2024","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iAkashPaul/limmits-2024","creator_name":"Akash","creator_url":"https://huggingface.co/iAkashPaul","description":"\n\t\n\t\t\n\t\n\t\n\t\tIndic TTS dataset\n\t\n\n7 languages from IISC's LIMMITS Challenge 2024\n\n\t\n\t\t\n\t\n\t\n\t\tRoadmap\n\t\n\nTo use this for training VALLE-X & VoiceBox based TTS models\n\n\t\n\t\t\n\t\n\t\n\t\tFetch the tars directly\n\t\n\nwget -O 'Bengali_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Bengali_F.tar.gz'\nwget -O 'Chhattisgarhi_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Chhattisgarhi_F.tar.gz'\nwget -O 'English_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/English_F.tar.gz'\nwget -Oâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iAkashPaul/limmits-2024.","first_N":5,"first_N_keywords":["text-to-speech","English","Bengali","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"boolq_bn","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hishab/boolq_bn","creator_name":"Hishab","creator_url":"https://huggingface.co/hishab","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBoolQ Bangla (BN) is a question-answering dataset for yes/no questions, generated using GPT-4. The dataset contains 15,942 examples, with each entry consisting of a triplet: (question, passage, answer). The questions are naturally occurring, generated from unprompted and unconstrained settings. Input passages were sourced from Bangla Wikipedia, Banglapedia, and News Articles, and GPT-4 was used to generate corresponding yes/no questions with answers.\nThe dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hishab/boolq_bn.","first_N":5,"first_N_keywords":["question-answering","monolingual","Bengali","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul RÃ¶ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"aya_dataset_ben_translated","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/barunsaha/aya_dataset_ben_translated","creator_name":"Barun Saha","creator_url":"https://huggingface.co/barunsaha","description":"aya_dataset_ben_translated is a subset of the aya_dataset, with some modifications. In particular, the original data points in Bengali (indicated by the language or language_code columns) are retained. In addition, the English and Hindi data points are translated into Bengali using Google Cloud Translation API. All columns from the original dataset are retained.\nA handful of inaccuracies arising out of translation have been fixed so far. Therefore, the dataset can be a bit noisy. This isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/barunsaha/aya_dataset_ben_translated.","first_N":5,"first_N_keywords":["question-answering","Bengali","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Preprocessed-MS-IL-POST-Data","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/musfiqdehan/Preprocessed-MS-IL-POST-Data","creator_name":"Md. Musfiqur Rahaman","creator_url":"https://huggingface.co/musfiqdehan","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tOut-of-Scope Use\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource Data\n\t\n\n\n\n\n\t\n\t\t\n\t\tData Collectionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/musfiqdehan/Preprocessed-MS-IL-POST-Data.","first_N":5,"first_N_keywords":["text-classification","token-classification","Bengali","English","mit"],"keywords_longer_than_N":true},
	{"name":"sangraha","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/sangraha","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tSangraha\n\t\n\n\n  \n\n\nSangraha is the largest high-quality, cleaned Indic language pretraining data containing 251B tokens summed up over 22 languages, extracted from curated sources, existing multilingual corpora and large scale translations.\nMore information:\n\nFor detailed information on the curation and cleaning process of Sangraha, please checkout our paper on Arxiv;\nCheck out the scraping and cleaning pipelines used to curate Sangraha on GitHub;\n\n\n\t\n\t\n\t\n\t\tGetting Started\n\t\n\nForâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/sangraha.","first_N":5,"first_N_keywords":["text-generation","Assamese","Bengali","Gujarati","English"],"keywords_longer_than_N":true},
	{"name":"indic-align","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/indic-align","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tIndicAlign\n\t\n\nA diverse collection of Instruction and Toxic alignment datasets for 14 Indic Languages. The collection comprises of:\n\nIndicAlign - Instruct\nIndic-ShareLlama\nDolly-T\nOpenAssistant-T\nWikiHow\nIndoWordNet\nAnudesh\nWiki-Conv\nWiki-Chat\n\n\nIndicAlign - Toxic\nHHRLHF-T\nToxic-Matrix\n\n\n\nWe use IndicTrans2 (Gala et al., 2023) for the translation of the datasets. \nWe recommend the readers to check out our paper on Arxiv for detailed information on the curation process of theseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/indic-align.","first_N":5,"first_N_keywords":["text-generation","Assamese","Bengali","Gujarati","English"],"keywords_longer_than_N":true},
	{"name":"Nadi_Indic466k_Instruct","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct","creator_name":"Convai Innovations","creator_url":"https://huggingface.co/convaiinnovations","description":"\n\t\n\t\t\n\t\tNadi_Indic466K_Instruct Dataset\n\t\n\nThe Nadi_Indic466K_Instruct dataset is the world's first coding dataset with 18 Indian language support, 466k rows and 142 Million total tokens. This dataset can be used by developers to build Indian coding language models (LLMs) for various programming languages.\nQ-LoRA based SFT/PPO/DPO fine-tuning can be done on the dataset in LLAMA-2 or Mistral or any opens-soure LLM for text generation.\nThe dataset was carefully curated such that the coding partâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct.","first_N":5,"first_N_keywords":["text-generation","Hindi","Panjabi","Bengali","Tamil"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"Pontoon-Translations","keyword":"bengali","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\n\t\n\t\t\n\t\tDataset Card for Pontoon Translations\n\t\n\n\n\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\nSource strings are in English.\nTo avoid rows with values like \"None\" and \"N/A\" being interpreted as missing values, pass the keep_default_na parameter like this:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ayymen/Pontoon-Translations\", keep_default_na=False)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","crowdsourced","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"BanglaSocialBias","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/csebuetnlp/BanglaSocialBias","creator_name":"BUET CSE NLP Group","creator_url":"https://huggingface.co/csebuetnlp","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Bangla Contextual Bias\n\t\n\n\n\nThe Bangla Social Bias dataset comprises of the data used in the paper titled \"Social Bias in Large Language Models For Bangla: An Empirical Study on Gender and Religious Bias\". \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe dataset contains different domains of data used for the experimentations mentioned in the paper. A summary of the different categories of data provided in this dataset are:\n\nthe formatted raw data collected from open sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/csebuetnlp/BanglaSocialBias.","first_N":5,"first_N_keywords":["text-classification","question-answering","fill-mask","Bengali","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \nBibTex\n@misc{lu2024languagecountslearnunlearn,\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \n      author={Taiming Lu and Philipp Koehn},\n      year={2024},\n      eprint={2406.13748},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2406.13748}, \n}\n\n","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"tydi_xor_rc","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/coastalcph/tydi_xor_rc","creator_name":"CoAStaL NLP Group","creator_url":"https://huggingface.co/coastalcph","description":"\n\t\n\t\t\n\t\tDataset Card for \"tydi_xor_rc\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages. \nXORQA is an extension of the original TyDi QA dataset to also include unanswerable questions, where context documents are only in English but questions are in 7 languages.\nXOR-AttriQA contains annotated attribution data for a sample of XORQA.\nThis dataset is a combined and simplified version of the Reading Comprehension data from XORQA andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/coastalcph/tydi_xor_rc.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"bengali_sa","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DGurgurov/bengali_sa","creator_name":"Daniil Gurgurov","creator_url":"https://huggingface.co/DGurgurov","description":"\n\t\n\t\t\n\t\tSentiment Analysis Data for the Bengali Language\n\t\n\nDataset Description:\nThis dataset contains a sentiment analysis dataset from Sazzed et al. (2020).\nData Structure:\nThe data was used for the project on improving word embeddings with graph knowledge for Low Resource Languages.\nCitation:\n@inproceedings{sazzed-2020-cross,\n    title = \"Cross-lingual sentiment classification in low-resource {B}engali language\",\n    author = \"Sazzed, Salim\",\n    editor = \"Xu, Wei  and\n      Ritter, Alanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DGurgurov/bengali_sa.","first_N":5,"first_N_keywords":["text-classification","Bengali","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"bangla_newspaper_dataset","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zabir-nabil/bangla_newspaper_dataset","creator_name":"Zabir Al Nazi","creator_url":"https://huggingface.co/zabir-nabil","description":"\n\t\n\t\t\n\t\tBangla Newspaper Dataset\n\t\n\n400k+ bangla news samples, 25+ categories\n\n\t\n\t\t\n\t\tSource\n\t\n\nData collected from https://www.prothomalo.com/archive [Copyright owned by the actual source]\n\n\t\n\t\t\n\t\tGithub\n\t\n\nGithub repository (Bi-LSTM Baseline):   https://github.com/zabir-nabil/bangla-news-rnn\n\n\t\n\t\t\n\t\tKaggle Version\n\t\n\nKaggle Dataset:   https://www.kaggle.com/datasets/furcifer/bangla-newspaper-dataset\n\n\t\n\t\t\n\t\tInspiration\n\t\n\nThe dataset can be used for Bangla text classification and generationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zabir-nabil/bangla_newspaper_dataset.","first_N":5,"first_N_keywords":["text-classification","Bengali","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"BanglaContextualBias","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/csebuetnlp/BanglaContextualBias","creator_name":"BUET CSE NLP Group","creator_url":"https://huggingface.co/csebuetnlp","description":"\n\t\n\t\t\n\t\tDataset Card for Bangla Contextual Bias\n\t\n\n\n\nThe Bangla Contextual Bias dataset corresponds to the data described in the paper \"An Empirical Study on the Characteristics of Bias upon Context Length Variation for Bangla\" accepted in ACL 2024 (Findings).\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThe dataset has different parts for different bias detection experiments conducted for Bengali.\n\n\t\n\t\t\n\t\tWEAT & SEAT\n\t\n\nFor the WEAT experiment, the dataset is translated from its English counterpart andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/csebuetnlp/BanglaContextualBias.","first_N":5,"first_N_keywords":["sentence-similarity","fill-mask","Bengali","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Chatgpt","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"indic_sts","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/indic_sts","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"\n\t\n\t\t\n\t\tDataset Card for Indic STS\n\t\n\nThis dataset is STS benchmark between English and 12 high-resource Indic languages. This was released as a part of Samanantar paper. Please refer to the paper for more details.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAvailable languages are: en-as, en-bn, en-gu, en-hi, en-kn, en-ml, en-mr, en-or, en-pa, en-ta, en-te, en-ur\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataset Fields\n\t\n\n\nlang_code: 2-digit ISO language code\nsource: The source from which the candidate sentence isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jaygala24/indic_sts.","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\nExample of loading:\ndataset = load_dataset(\"davidstap/NTREX\", \"rus_Cyrl\", trust_remote_code=True)\n\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe following languages are available:\n\n\t\n\t\t\nLanguage Code\nLanguage Name\n\n\n\t\t\nafr_Latn\nAfrikaans\n\n\namh_Ethi\nAmharic\n\n\narb_Arab\nArabic\n\n\naze_Latn\nAzerbaijani\nbak_Cyrl\nBashkir\n\n\nbel_Cyrl\nBelarusianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"bengali_sentiment_analysis","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Akash190104/bengali_sentiment_analysis","creator_name":"Akash Kundu","creator_url":"https://huggingface.co/Akash190104","description":"\n\t\n\t\t\n\t\tBengali Sentiment Analysis\n\t\n\n\n\t\n\t\t\n\t\tContext\n\t\n\nThe dataset contains 3307 Negative reviews and 8500 Positive reviews collected and manually annotated from Youtube Bengali drama.\nPositive_Label=1 and Negative_Label=0\n\n\t\n\t\t\n\t\tAcknowledgements\n\t\n\nSazzed, Salim (2021), â€œBangla ( Bengali ) sentiment analysis classification benchmark dataset corpusâ€, Mendeley Data, V4, doi: 10.17632/p6zc7krs37.4\n","first_N":5,"first_N_keywords":["text-classification","Bengali","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"swim-ir-cross-lingual","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\n\t\n\t\t\n\t\tDataset Card for SWIM-IR (Cross-lingual)\n\t\n\n\n\n\nThis is the cross-lingual subset of the SWIM-IR dataset, where the query generated is in the target language and the passage is in English.\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\n\n\t\n\t\n\t\n\t\tWhat is SWIM-IR?\n\t\n\nSWIM-IR dataset is a synthetic multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","machine-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"swim-ir-monolingual","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/swim-ir-monolingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\n\t\n\t\t\n\t\tDataset Card for SWIM-IR (Monolingual)\n\t\n\n\n\n\nThis is the monolingual subset of the SWIM-IR dataset, where the query generated and the passage are both in the same language.\nA few remaining languages will be added in the upcoming v2 version of SWIM-IR. The dataset is available as CC-BY-SA 4.0.\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\n\n\t\n\t\n\t\n\t\tWhat is SWIM-IR?\n\t\n\nSWIM-IR dataset is a synthetic multilingual retrieval datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-monolingual.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"Benchmark-Testing","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shounakpaul95/Benchmark-Testing","creator_name":"Shounak Paul","creator_url":"https://huggingface.co/shounakpaul95","description":"shounakpaul95/Benchmark-Testing dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","summarization","translation","token-classification","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"banglatribune_news_articles","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SaifullahBinYusuf/banglatribune_news_articles","creator_name":"Saifullah Bin Yusuf","creator_url":"https://huggingface.co/SaifullahBinYusuf","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaifullahBinYusuf/banglatribune_news_articles.","first_N":5,"first_N_keywords":["Bengali","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"samakal_news_articles","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SaifullahBinYusuf/samakal_news_articles","creator_name":"Saifullah Bin Yusuf","creator_url":"https://huggingface.co/SaifullahBinYusuf","description":"SaifullahBinYusuf/samakal_news_articles dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Bengali","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"webui-dom-snapshots","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\n\t\n\t\t\n\t\tDataset Card for WebUI DOM snapshots\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Gary Benson\nLanguages: Mostly English (87%);\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\nLicense: CC0 1.0 Universal\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots.","first_N":5,"first_N_keywords":["image-feature-extraction","reinforcement-learning","text-classification","multilingual","biglab/webui-7k"],"keywords_longer_than_N":true},
	{"name":"BanglaEnglishMixedAsrDataset","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/akhikhan123/BanglaEnglishMixedAsrDataset","creator_name":"Fatema Tuz Zohra Akhi","creator_url":"https://huggingface.co/akhikhan123","description":"akhikhan123/BanglaEnglishMixedAsrDataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","Bengali","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"indic_sts","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/indic_sts","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n\t\n\t\t\n\t\tDataset Card for Indic STS\n\t\n\nThis dataset is STS benchmark between English and 12 high-resource Indic languages. This was released as a part of Samanantar paper. Please refer to the paper for more details.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAvailable languages are: en-as, en-bn, en-gu, en-hi, en-kn, en-ml, en-mr, en-or, en-pa, en-ta, en-te, en-ur\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataset Fields\n\t\n\n\nlang_code: 2-digit ISO language code\nsource: The source from which the candidate sentence isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/indic_sts.","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"mirage-bench-instruct","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/mirage-bench-instruct","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\n\t\n\t\t\n\t\tMIRAGE-Bench (Instruct)\n\t\n\nThis dataset contains the structured RAG outputs for queries in the train split of MIRAGE-Bench (or MIRACL) for 16 languages for five models:\n\ngpt-4o-azure                          (GPT-4o using Azure API)\nmeta-llama/Meta-Llama-3-70B-Instruct  (Llama-3-70B-Instruct using Anyscale API)\nmistralai/Mixtral-8x22B-Instruct-v0.1 (Mixtral-8x22B-Instruct using Anyscale API)\nmeta-llama/Meta-Llama-3-8B-Instruct   (Llama-3-8B-Instruct using vLLM)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/mirage-bench-instruct.","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","Bengali","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Alpaca_orca_bongchat_merged","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ahnaf702/Alpaca_orca_bongchat_merged","creator_name":"Mohammad Ahnaf Tahmeed","creator_url":"https://huggingface.co/ahnaf702","description":"ahnaf702/Alpaca_orca_bongchat_merged dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","text-generation","Bengali","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"IndicSentiment","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicSentiment","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA new, multilingual, and n-way parallel dataset for sentiment analysis in 13 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReferencehttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicSentimentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicSentiment.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"ILSUM-2.0","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ILSUM/ILSUM-2.0","creator_name":"Indian Language Summarization","creator_url":"https://huggingface.co/ILSUM","description":"\n\t\n\t\t\n\t\tDataset Card for \"ILSUM-2.0\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nILSUM-2.0 contains additional ~10K articles along with ILSUM-1.0 dataset. Along with Hindi, English, and Gujarati, which were part of ILSUM-1.0, Bengali is also introduced as part of ILSUM-20. dataset.\nThe dataset for this task is built using articles and headline pairs from several leading newspapers of the country. We provide >=10,000 news articles for each language. The task is to generate a meaningful fixed length summaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ILSUM/ILSUM-2.0.","first_N":5,"first_N_keywords":["summarization","text-generation","Hindi","Gujarati","Bengali"],"keywords_longer_than_N":true},
	{"name":"nomiracl-instruct","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/nomiracl-instruct","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\n\t\n\t\t\n\t\tDataset Card for NoMIRACL (EMNLP 2024 Findings Track)\n\t\n\n\n\t\n\t\t\n\t\tQuick Overview\n\t\n\nThis repository contains the fine-tuning (training & development split) of the NoMIRACL instruct dataset for fine-tuning LLMs on multilingual relevance assessment.\nThe training dataset is a binary classification task; they need to explicitly output either Yes, answer is present or I don't know. \nThe dataset contains training pairs from all 18 languages for both splits: relevant & non-relevant.\nimportâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/miracl/nomiracl-instruct.","first_N":5,"first_N_keywords":["text-classification","text-generation","Arabic","Bengali","German"],"keywords_longer_than_N":true},
	{"name":"bangla_sahitya","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/barunsaha/bangla_sahitya","creator_name":"Barun Saha","creator_url":"https://huggingface.co/barunsaha","description":"\n\n\t\n\t\t\n\t\tà¦¬à¦¾à¦‚à¦²à¦¾ à¦¸à¦¾à¦¹à¦¿à¦¤à§à¦¯ (Bangla Sahitya or Bengali Literature)\n\t\n\nA non-exhaustive collection of Bengali literary works (poems, stories, novels, songs, essays, letters) by more than 35 authors. These works span between the 8th and 20th centuries. All these works are in the public domain.\nThe contents of some of the rows can be large, e.g., novels. Also, some of the earlier works may be noisy.\nIf you are only interested in Bengali poems, take a look at this smaller subset of Bengali Poemsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/barunsaha/bangla_sahitya.","first_N":5,"first_N_keywords":["Bengali","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"BanglaSum","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/midnightGlow/BanglaSum","creator_name":"Anusree Roy","creator_url":"https://huggingface.co/midnightGlow","description":"We created a dataset by web scraping different online newspapers like â€˜The Daily Starâ€™, â€˜ProthomAloâ€™, and â€˜BBC News Banglaâ€™ using the Beautiful Soup library of Python. The dataset's features are â€˜titleâ€™, â€˜textâ€™ & â€˜summaryâ€™.\nThe dataset was preprocessed using the Python library â€˜pandasâ€™ and all duplicates and null values were eliminated and the total number of rows remaining is 9311. Since there is a lack of datasets in the Bengali language, this dataset will be useful for tasks like textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/midnightGlow/BanglaSum.","first_N":5,"first_N_keywords":["summarization","text-generation","Bengali","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"dart_math_bangla","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Asib27/dart_math_bangla","creator_name":"Asib Rahman","creator_url":"https://huggingface.co/Asib27","description":"The dataset contains math problems in bangla. hkust-nlp/dart-math-uniform is translated  using facebook/nllb-200-3.3B. To achive better performance english sentences are splitted and then fed into the translation model.\n","first_N":5,"first_N_keywords":["question-answering","Bengali","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"XL-HeadTags","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/faisaltareque/XL-HeadTags","creator_name":"Faisal Tareque Shohan","creator_url":"https://huggingface.co/faisaltareque","description":"\n\t\n\t\t\n\t\tDataset Card for XL-HeadTags Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Source\n\t\n\nWe have used M3LS and XL-Sum as source for this dataset.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n We provide XL-HeadTags, a large-scale news headline and tags generation dataset. The dataset consists of 20 languages across six diverse language families. It contains 415K news headline-article pairs with auxiliary information such as image captions, topic words (read more).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nOneâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/faisaltareque/XL-HeadTags.","first_N":5,"first_N_keywords":["summarization","sentence-similarity","English","Portuguese","Spanish"],"keywords_longer_than_N":true},
	{"name":"flores","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/flores","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FloresBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nFLORES is a benchmark dataset for machine translation between English and low-resource languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNon-fiction, Encyclopaedic, Written\n\nReference\nhttps://huggingface.co/datasets/facebook/flores\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FloresBitextMining\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/flores.","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Achinese","Mesopotamian Arabic"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NTREXBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNTREX is a News Test References dataset for Machine Translation Evaluation, covering translation from English into 128 languages. We select language pairs according to the M2M-100 language grouping strategy, resulting in 1916 directions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/davidstap/NTREX\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","translated","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"IN22-Conv","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IN22-Conv","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IN22ConvBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Conv is a n-way parallel conversation domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nSocial, Spoken, Fiction, Spoken\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Conv\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Conv.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"IN22-Gen","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IN22-Gen","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IN22GenBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Gen is a n-way parallel general-purpose multi-domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Legal, Government, News, Religious, Non-fiction, Written\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Gen\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Gen.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"multilingual-llava-bench-in-the-wild","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\tMultilingual LLaVA Bench in the Wild\n\t\n\n\n\t\n\t\t\n\t\tNote that this is a copy from https://huggingface.co/datasets/MBZUAI/multilingual-llava-bench-in-the-wild\n\t\n\nIt was created due to issues in the original repo. It also includes the image features and has a uniform and joined structure.\nIf you use this dataset, please cite the original authors:\n@article{PALO2024,\n  title={Palo: A Large Multilingual Multimodal Language Model},\n  author={Maaz, Muhammad and Rasheed, Hanoona and Shakerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild.","first_N":5,"first_N_keywords":["Arabic","Bengali","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"xm3600","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\nIt also includes the image features as PIL Image and has a uniform andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xm3600_1k","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600 - 1K Split\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a 1K split of XM3600!\n\t\n\nFor this, weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xgqa","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xgqa","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\txGQA\n\t\n\n\n\t\n\t\t\n\t\tThis is a clone of the few_shot-test split of the xGQA dataset\n\t\n\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\nIf you use this dataset, please cite the original authors:\n@inproceedings{pfeiffer-etal-2021-xGQA,\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\'{c}} and Iryna Gurevych},\n    booktitle =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa.","first_N":5,"first_N_keywords":["visual-question-answering","Bengali","German","English","Indonesian"],"keywords_longer_than_N":true},
	{"name":"x-fact","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"x-fact\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while the languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact.","first_N":5,"first_N_keywords":["text-classification","Arabic","Bengali","Spanish","Persian"],"keywords_longer_than_N":true},
	{"name":"xgqa_1k","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xgqa_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\txGQA 1K\n\t\n\n\n\t\n\t\t\n\t\tThis is a 1K subset of the few_shot-test split of the xGQA dataset\n\t\n\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\nIf you use this dataset, please cite the original authors:\n@inproceedings{pfeiffer-etal-2021-xGQA,\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\'{c}} and Iryna Gurevych},\n    booktitleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa_1k.","first_N":5,"first_N_keywords":["visual-question-answering","Bengali","German","English","Indonesian"],"keywords_longer_than_N":true},
	{"name":"IndicVarna-100k","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dynopii/IndicVarna-100k","creator_name":"Dynopii Inc","creator_url":"https://huggingface.co/dynopii","description":"\n\t\n\t\t\n\t\tIndicVarna for Callchimp.ai (a Dynopii product)\n\t\n\nWe introduce IndiVarna which was prepared by using Google Translate on the dair-ai/emotion dataset to get the samples there translated to the top 10 most commonly used Indian languages.\nThis dataset contains 10000 samples of each of the 10 languages supported.\nThe dataset further translated the labels in the dataset to 3 label sentiments - 0: Negative, 1: Neutral and 2: Positive. Each language has 3334 samples of each category ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dynopii/IndicVarna-100k.","first_N":5,"first_N_keywords":["text-classification","translation","sentence-similarity","fill-mask","text-generation"],"keywords_longer_than_N":true},
	{"name":"Bangladesh-Voter-Synthetic-Dataset","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jonybepary/Bangladesh-Voter-Synthetic-Dataset","creator_name":"sohel ahmed joni","creator_url":"https://huggingface.co/jonybepary","description":"\n\t\n\t\t\n\t\tðŸ—³ï¸ Bangladesh Voter Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“œ Dataset Description\n\t\n\nThe Bangladesh Voter Dataset is a synthetic dataset containing voter information for the purpose of demonstrating data generation and processing techniques. Each voter record includes both Bengali and English names, gender, NID, address, and profile information.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Structure\n\t\n\nThe dataset is structured as follows:\n\nprofile: A URL to the voter's profile image.\nnid: A unique National Identification Number.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jonybepary/Bangladesh-Voter-Synthetic-Dataset.","first_N":5,"first_N_keywords":["Bengali","English","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"shiksha","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SPRINGLab/shiksha","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","description":"\n\t\n\t\t\n\t\tShiksha Dataset\n\t\n\nThis is a Technical Domain focused Translation Dataset for 8 Indian Languages. It consists of more than 2.5 million rows of translation pairs between all 8 languages and English.\nThis data has been derived from raw NPTEL documents. More information on this can be found in our paper: https://arxiv.org/abs/2412.09025\nIf you use this data in your work, please cite us:\n@misc{joglekar2024shikshatechnicaldomainfocused,\n      title={Shiksha: A Technical Domain focusedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/shiksha.","first_N":5,"first_N_keywords":["translation","Hindi","Bengali","Tamil","Telugu"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"Todo - Write dataset card\n","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"Wikipedia-Abstract","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/laion/Wikipedia-Abstract","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"Wikipedia Abstract\n\n\n  \n\n\n\nIntroducing Wikipedia Abstract, a comprehensive dataset encompassing abstracts, complete articles, and a popularity score index for both widely spoken and lesser-known Wikipedia subsets. Our dedication to Wikipedia-X ensures a centralized Wikipedia dataset that undergoes regular updates and adheres to the highest standards.\nA central focus of our efforts was to include exotic languages that often lack up-to-date Wikipedia dumps or may not have any dumps at all.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/laion/Wikipedia-Abstract.","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","fill-mask","Arabic"],"keywords_longer_than_N":true},
	{"name":"bangla-bcs-qs","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/azminetoushikwasi/bangla-bcs-qs","creator_name":"Azmine Toushik Wasi","creator_url":"https://huggingface.co/azminetoushikwasi","description":"azminetoushikwasi/bangla-bcs-qs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","question-answering","Bengali","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"bcs-10-40th-GK-ICT-DM-NMS","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/azminetoushikwasi/bcs-10-40th-GK-ICT-DM-NMS","creator_name":"Azmine Toushik Wasi","creator_url":"https://huggingface.co/azminetoushikwasi","description":"azminetoushikwasi/bcs-10-40th-GK-ICT-DM-NMS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["table-question-answering","question-answering","Bengali","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"english-to-bengali-mt","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hemanth-thunder/english-to-bengali-mt","creator_name":"Hemanth-thunder","creator_url":"https://huggingface.co/Hemanth-thunder","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nEnglish to Bengali Machine Translation\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nLanguage(s) (NLP): Bengali,English\nLicense: mit\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\nRepository: https://github.com/csebuetnlp/banglanmt\n\n","first_N":5,"first_N_keywords":["translation","Bengali","English","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"voices-of-civilizations","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sander-wood/voices-of-civilizations","creator_name":"Shangda Wu (Sander Wood)","creator_url":"https://huggingface.co/sander-wood","description":"\n\t\n\t\t\n\t\tVoices of Civilizations (VoC)\n\t\n\nVoices of Civilizations (VoC) is the first multilingual QA benchmark designed to assess audio LLMsâ€™ cultural comprehension using full-length music recordings. VoC spans:\n\n38 languages (including zh, en, hi, es, fr, ja, ko, ar, sw, bn, de, pt, ru, etc.)\n380 tracks drawn from traditional and regional music\n860 multiple-choice questions probing four dimensions: language, region, mood, and theme\n\nVoC exposes modelsâ€™ biases and weaknesses onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sander-wood/voices-of-civilizations.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"lovebangla","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SrejonAhamed/lovebangla","creator_name":"Joy","creator_url":"https://huggingface.co/SrejonAhamed","description":"SrejonAhamed/lovebangla dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["table-question-answering","text-generation","question-answering","Bengali","mit"],"keywords_longer_than_N":true},
	{"name":"BanglaBoro","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SrejonAhamed/BanglaBoro","creator_name":"Joy","creator_url":"https://huggingface.co/SrejonAhamed","description":"SrejonAhamed/BanglaBoro dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","Bengali","mit"],"keywords_longer_than_N":true},
	{"name":"BenNumEval","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ka05ar/BenNumEval","creator_name":"Kawsar Ahmed","creator_url":"https://huggingface.co/ka05ar","description":"\n\t\n\t\t\n\t\tBenNumEval: A Benchmark to Assess LLMâ€™s Numerical Reasoning Capabilities in Bengali\n\t\n\nBenNumEval is a novel benchmark designed to evaluate the numerical reasoning abilities of Large Language Models (LLMs) in the Bengali language. It introduces six diverse task categories and a high-quality dataset containing over 3,200 examples derived from educational and real-world sources.\n\n\t\n\t\t\n\t\tðŸ“ Dataset Overview\n\t\n\nBenNumEval includes 3,255 curated examples divided into six task types:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ka05ar/BenNumEval.","first_N":5,"first_N_keywords":["Bengali","mit","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"product-database","keyword":"bengali","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\n\t\n\t\t\n\t\tOpen Food Facts Database\n\t\n\n\n\t\n\t\t\n\t\tWhat is ðŸŠ Open Food Facts?\n\t\n\n\n\t\n\t\t\n\t\tA food products database\n\t\n\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\n\n\t\n\t\t\n\t\tMade by everyone\n\t\n\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"BanglaTLit","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aplycaebous/BanglaTLit","creator_name":"Farhan Ishmam","creator_url":"https://huggingface.co/aplycaebous","description":"\n\t\n\t\t\n\t\tBanglaTLit: A Benchmark Dataset for Back-Transliteration of Romanized Bangla\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nBanglaTLit-PT: A pre-training corpus with 245727 transliterated or romanized Bangla samples for further pre-training language models.\nBanglaTLit: Subset of the BanglaTLit-PT dataset containing 42705 romanized Bangla and its corresponding Bangla back-transliteration pairs.\n\n\n\t\n\t\t\n\t\tData Description\n\t\n\n\n\t\n\t\t\nColumn Title\nDescription\n\n\n\t\t\nid\nA unique identifier for each data pointâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aplycaebous/BanglaTLit.","first_N":5,"first_N_keywords":["Bengali","mit","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"indic_sentiment_analyzer","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dhruv0808/indic_sentiment_analyzer","creator_name":"Dhruv Bhatnagar","creator_url":"https://huggingface.co/dhruv0808","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n\t\n\t\t\n\t\tMultilingual Sentiment Analysis Dataset for Indian Languages\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository contains a comprehensive sentiment analysis dataset covering 11 Indian languages and English. The dataset is designed to support sentiment analysis tasks across multiple domains and languages, making it valuable for developing multilingual sentiment analysis models and applications.\n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\n\nEnglish (en) - Original\nHindi (hi)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/dhruv0808/indic_sentiment_analyzer.","first_N":5,"first_N_keywords":["English","Hindi","Telugu","Tamil","Kannada"],"keywords_longer_than_N":true},
	{"name":"IndicReviewsClusteringP2P","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicReviewsClusteringP2P","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicReviewsClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of reviews from IndicSentiment dataset. Clustering of 14 sets on the generic categories label.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicReviewsClusteringP2P\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicReviewsClusteringP2P.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"IndicCrosslingualSTS","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicCrosslingualSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicCrosslingualSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a Semantic Textual Similarity testset between English and 12 high-resource Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Non-fiction, Web, Spoken, Government, Written, Spoken\nReference\nhttps://huggingface.co/datasets/jaygala24/indic_sts\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicCrosslingualSTS.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","expert-annotated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"mmmlu_lite","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","description":"\n\t\n\t\t\n\t\tMMMLU-Lite\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is about 10% ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSIB-Fleurs\n\t\n\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \nThe topics are:\n\nScience/Technology\nTravel\nPolitics\nSports\nHealth\nEntertainment\nGeography\n\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset creation\n\t\n\nThis dataset processes and mergesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","description":"\n\t\n\t\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\nWe translated the MMLUâ€™s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increasesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"mgsm","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jbross-ibm-research/mgsm","creator_name":"J Bross","creator_url":"https://huggingface.co/jbross-ibm-research","description":"\n\t\n\t\t\n\t\tDataset Card for MGSM\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCopy and merge of this MGSM Dataset, Catalan version, Basque version, Galician version, but in training samples we removed the prompt formatting, e.g. removed Question: ... in question field or Answer: ... in answer field.\nMultilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper Language models are multilingual chain-of-thought reasoners.\nThe same 250 problems from GSM8K areâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jbross-ibm-research/mgsm.","first_N":5,"first_N_keywords":["found","found","expert-generated","multilingual","extended|gsm8k"],"keywords_longer_than_N":true},
	{"name":"xtreme-up-semantic-parsing","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for afrixnli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSee XTREME-UP GitHub\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 20 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata = load_dataset('Davlan/xtreme-up-semantic-parsing', 'yor') \n# Please, specify the language code\n# A data point example is below:\n{\n\"id\": \"3231323330393336\",\n\"split\": \"test\",\n\"intent\": \"IN:GET_REMINDER\",\n\"locale\": \"en\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing.","first_N":5,"first_N_keywords":["text-classification","multilingual","Amharic","Belarusian","Bengali"],"keywords_longer_than_N":true},
	{"name":"Dhoroni","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ciol-research/Dhoroni","creator_name":"Computational Intelligence and Operations Laboratory (CIOL)","creator_url":"https://huggingface.co/ciol-research","description":"\n\t\n\t\t\n\t\tDhoroni: Exploring Bengali Climate Change and Environmental Views with a Multi-Perspective News Dataset and Natural Language Processing\n\t\n\n\nAuthors: Azmine Toushik Wasi, Wahid Faisal, Taj Ahmad, Abdur Rahman, Mst Rafia Islam\nDataset DOI (Zenodo): https://doi.org/10.5281/zenodo.13695110\narXiv: https://arxiv.org/abs/2410.17225\nAbstract: Climate change poses critical challenges globally, disproportionately affecting low-income countries that often lack resources and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ciol-research/Dhoroni.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","question-answering","text-generation","Bengali"],"keywords_longer_than_N":true},
	{"name":"Dhoroni","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ciol-research/Dhoroni","creator_name":"Computational Intelligence and Operations Laboratory (CIOL)","creator_url":"https://huggingface.co/ciol-research","description":"\n\t\n\t\t\n\t\tDhoroni: Exploring Bengali Climate Change and Environmental Views with a Multi-Perspective News Dataset and Natural Language Processing\n\t\n\n\nAuthors: Azmine Toushik Wasi, Wahid Faisal, Taj Ahmad, Abdur Rahman, Mst Rafia Islam\nDataset DOI (Zenodo): https://doi.org/10.5281/zenodo.13695110\narXiv: https://arxiv.org/abs/2410.17225\nAbstract: Climate change poses critical challenges globally, disproportionately affecting low-income countries that often lack resources and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ciol-research/Dhoroni.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","question-answering","text-generation","Bengali"],"keywords_longer_than_N":true},
	{"name":"prothom-alo-news","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/uzzalmondal/prothom-alo-news","creator_name":"Uzzal Mondal","creator_url":"https://huggingface.co/uzzalmondal","description":"\n\t\n\t\t\n\t\tBangla Newspaper Dataset (Prothom-Alo)\n\t\n\n\n\t\n\t\t\n\t\tAbout Dataset\n\t\n\nBangla Newspaper Dataset\n400k+ bangla news samples, 25+ categories,\nDate of Uploading: 8/12/2024\n\n\t\n\t\t\n\t\tSize\n\t\n\nOrizinal - data.json(4.61 GB)\n\n\t\n\t\t\n\t\tSource\n\t\n\nData collected from https://www.prothomalo.com/archive \n\n\t\n\t\t\n\t\tKaggle\n\t\n\nhttps://www.kaggle.com/datasets/furcifer/bangla-newspaper-dataset \n\n\t\n\t\t\n\t\tHuggingFace\n\t\n\nhttps://huggingface.co/datasets/zabir-nabil/bangla_newspaper_dataset\n\n\t\n\t\t\n\t\tInspiration\n\t\n\nI haveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/uzzalmondal/prothom-alo-news.","first_N":5,"first_N_keywords":["text-generation","Bengali","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"bengali_chat_conv","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/spedrox-sac/bengali_chat_conv","creator_name":"DINMAY KUMAR BRAHMA","creator_url":"https://huggingface.co/spedrox-sac","description":"\n\t\n\t\t\n\t\tBengali Chat Conversation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThe Bengali Chat Conversation dataset contains a collection of conversational exchanges in Bengali. Each entry consists of a question and its corresponding answer, covering a wide range of topics including technology, health, environment, education, and more. This dataset can be used for various natural language processing (NLP) tasks such as language modeling, question-answering systems, and conversational AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/spedrox-sac/bengali_chat_conv.","first_N":5,"first_N_keywords":["text-generation","Bengali","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"dhpileIN","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aloobun/dhpileIN","creator_name":"aloobun","creator_url":"https://huggingface.co/aloobun","description":"@misc{aralikatte2023varta,\n      title={V\\=arta: A Large-Scale Headline-Generation Dataset for Indic Languages}, \n      author={Rahul Aralikatte and Ziling Cheng and Sumanth Doddapaneni and Jackie Chi Kit Cheung},\n      year={2023},\n      eprint={2305.05858},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n","first_N":5,"first_N_keywords":["Bengali","Gujarati","Hindi","Kannada","Tamil"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU-Lite","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 16 languages, including English. It is \"lite\" version of the original Global-MMLU dataset ðŸŒ.\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \nNOTE: Of the 16 languages presently included in Global-MMLU-Lite, 15â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite.","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"vqa","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldcuisines/vqa","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\n\t\n\t\t\n\t\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\n\t\n\n\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 October 2024.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa.","first_N":5,"first_N_keywords":["multilingual","English","Indonesian","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"LLM_dataset","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mlsuny/LLM_dataset","creator_name":"ml_suny","creator_url":"https://huggingface.co/mlsuny","description":"mlsuny/LLM_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["table-question-answering","translation","English","Bengali","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"LLM_DATASET_BANGLA","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mlsuny/LLM_DATASET_BANGLA","creator_name":"ml_suny","creator_url":"https://huggingface.co/mlsuny","description":"mlsuny/LLM_DATASET_BANGLA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Bengali","apache-2.0","1M - 10M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Achinese","Adyghe"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/include-lite-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tINCLUDE-lite (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-lite-44.","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"bengali-poems","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rishiraj/bengali-poems","creator_name":"Rishiraj Acharya","creator_url":"https://huggingface.co/rishiraj","description":"rishiraj/bengali-poems dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Bengali","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Achinese","Adyghe"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/include-base-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tINCLUDE-base (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-base-44.","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Deltacorpus_1.1","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\n[!NOTE]\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, PortoroÅ¾, Slovenia).\nChanges in version 1.1: \n\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \n\nSVM classifier trained on Universalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1.","first_N":5,"first_N_keywords":["token-classification","multilingual","Afrikaans","Albanian","Amharic"],"keywords_longer_than_N":true},
	{"name":"MM-Eval","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prometheus-eval/MM-Eval","creator_name":"prometheus-eval","creator_url":"https://huggingface.co/prometheus-eval","description":"\n\t\n\t\t\n\t\tMultilingual Meta-EVALuation benchmark (MM-Eval)\n\t\n\n\nðŸ‘¨â€ðŸ’»Code\n|\nðŸ“„Paper\n|\nðŸ¤— MMQA\n\n\nMM-Eval is a multilingual meta-evaluation benchmark consisting of five core subsetsâ€”Chat, Reasoning, Safety, Language Hallucination, and Linguisticsâ€”spanning 18 languages and a Language Resource subset spanning 122 languages for a broader analysis of language effects. \n\nDesign ChoiceIn this work, we minimize the inclusion of translated samples, as mere translation may alter existing preferences due toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/prometheus-eval/MM-Eval.","first_N":5,"first_N_keywords":["Arabic","Bengali","Catalan","German","English"],"keywords_longer_than_N":true},
	{"name":"Bangla_Sentiments_in_eLearning","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TanjimKIT/Bangla_Sentiments_in_eLearning","creator_name":"Tanjim Mahmud","creator_url":"https://huggingface.co/TanjimKIT","description":"Published Paper Information:>>>>>>>>>>>>>>>>>>>>>>>>\nIf you use Bangla Sentiments in eLearning  dataset, please cite the following paper:\n@article{rahman2024analyzing,\n  title={Analyzing sentiments in elearning: A comparative study of bangla and romanized bangla text using transformers},\n  author={Rahman, Md Akash and Begum, Manoara and Mahmud, Tanjim and Hossain, Mohammad Shahadat and Andersson, Karl},\n  journal={IEEE Access},\n  year={2024},\n  publisher={IEEE}\n}\n","first_N":5,"first_N_keywords":["text-classification","Bengali","apache-2.0","1K<n<10K","doi:10.57967/hf/3334"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-tydiqa","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-tydiqa","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\n\t\n\t\t\n\t\tDataset Card for \"tydiqa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\nin the world. It contains language phenomena that would not be found inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-tydiqa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"Bangla-Math","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kawchar85/Bangla-Math","creator_name":"Kawchar Husain","creator_url":"https://huggingface.co/kawchar85","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Bangla-Math Dataset is a valuable resource that addresses the critical need for Bangla-language mathematical problem-solving datasets. Currently, there are no publicly available datasets for math problems in Bangla, making this dataset a unique and valuable contribution to the fields of natural language processing (NLP). This dataset bridges the gap by enabling AI models to understand and work effectively with Bengali math content, thereby supporting advancements inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kawchar85/Bangla-Math.","first_N":5,"first_N_keywords":["Bengali","mit","1K - 10K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"BHM-Bengali-Hateful-Memes","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Eftekhar/BHM-Bengali-Hateful-Memes","creator_name":"Eftekhar Hossain","creator_url":"https://huggingface.co/Eftekhar","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBHM is a novel multimodal dataset for Bengali Hateful Memes detection. The dataset consists of 7,148 memes with Bengali as well as code-mixed captions, \ntailored for two tasks: (i) detecting hateful memes and (ii) detecting the social entities they target (i.e., Individual, Organization, Community, and Society).\n\n\t\n\t\t\n\t\tPaper Information\n\t\n\n\nPaper: https://aclanthology.org/2024.acl-long.454/\nCode:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Eftekhar/BHM-Bengali-Hateful-Memes.","first_N":5,"first_N_keywords":["other","image-classification","image-to-text","Bengali","mit"],"keywords_longer_than_N":true},
	{"name":"BHM-Bengali-Hateful-Memes","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Eftekhar/BHM-Bengali-Hateful-Memes","creator_name":"Eftekhar Hossain","creator_url":"https://huggingface.co/Eftekhar","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBHM is a novel multimodal dataset for Bengali Hateful Memes detection. The dataset consists of 7,148 memes with Bengali as well as code-mixed captions, \ntailored for two tasks: (i) detecting hateful memes and (ii) detecting the social entities they target (i.e., Individual, Organization, Community, and Society).\n\n\t\n\t\t\n\t\tPaper Information\n\t\n\n\nPaper: https://aclanthology.org/2024.acl-long.454/\nCode:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Eftekhar/BHM-Bengali-Hateful-Memes.","first_N":5,"first_N_keywords":["other","image-classification","image-to-text","Bengali","mit"],"keywords_longer_than_N":true},
	{"name":"Gadet_Review_Dataset","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kcrl/Gadet_Review_Dataset","creator_name":"khan computational Research Lab","creator_url":"https://huggingface.co/kcrl","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBanGRev is a Bengali-language text classification dataset developed for sentiment analysis of gadget and technology-related reviews. It contains user-generated content annotated with three sentiment classes:\n\n\t\n\t\t\n\t\tLabels\n\t\n\nThe dataset uses the following class labels:\n\n0 â€” Satisfied \n1 â€” Dissatisfied \n2 â€” Unbiased\n\n\n","first_N":5,"first_N_keywords":["text-classification","Bengali","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"mc-translation","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/efederici/mc-translation","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","description":"This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.\n\n\t\n\t\t\n\t\tWhy This Dataset?\n\t\n\nTranslation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specializedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation.","first_N":5,"first_N_keywords":["translation","English","Swahili","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"Roleplay-Bengali","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Bengali","creator_name":"Min Si Thu","creator_url":"https://huggingface.co/jojo-ai-mst","description":"\n\t\n\t\t\n\t\tRolePlay-Bengali\n\t\n\nRoleplay-Bengali Dataset is a dataset for roleplaying in the Bengali language for Large Language Model.\nThe base dataset is GPTeacher role play dataset by teknium 1, which can be found under this link, released under MIT License. The dataset is then translated into respective languages. The translation process is powered by Google Translate, using cloud translation API. \nFor more information and other language datasets for roleplay, it can be found at this githubâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Bengali.","first_N":5,"first_N_keywords":["text-generation","Bengali","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"banglaTabQA","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vaishali/banglaTabQA","creator_name":"Vaishali Pal","creator_url":"https://huggingface.co/vaishali","description":"\n\t\n\t\t\n\t\tDataset Card for \"banglaTabQA\"\n\t\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nimport pandas as pd\nfrom datasets import load_dataset\n\nbanglatableQA = load_dataset(\"vaishali/banglaTabQA\")\n\nfor sample in banglatableQA['train']:\n  question = sample['question']\n  input_table = pd.read_json(sample['table'], orient='split')\n  answer = pd.read_json(sample['answer'], orient='split')\n\n\n\t\n\t\n\t\n\t\tBibTeX entry and citation info\n\t\n\n@inproceedings{pal-etal-2024-table,\n    title = \"Table Question Answering for Low-resourcedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vaishali/banglaTabQA.","first_N":5,"first_N_keywords":["table-question-answering","Bengali","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xgqa","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xgqa","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\n\t\n\t\t\n\t\txGQA\n\t\n\n\n\t\n\t\t\n\t\tThis is a clone of the few_shot-test split of the xGQA dataset\n\t\n\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\nIf you use this dataset, please cite the original authors:\n@inproceedings{pfeiffer-etal-2021-xGQA,\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\'{c}} and Iryna Gurevych},\n    booktitle =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-xgqa.","first_N":5,"first_N_keywords":["visual-question-answering","Bengali","German","English","Indonesian"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_bn","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_bn","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Bengali"],"keywords_longer_than_N":true},
	{"name":"BnSentMix","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aplycaebous/BnSentMix","creator_name":"Farhan Ishmam","creator_url":"https://huggingface.co/aplycaebous","description":"\n\t\n\t\t\n\t\tBnSentMix: A Diverse Bengali-English Code-Mixed Dataset for Sentiment Analysis\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\n\t\n\t\t\nColumn Title\nDescription\n\n\n\t\t\nData Sources\nFacebook, YouTube, E-commerce Sites\n\n\n#Samples\n20000\n\n\nSentiment Labels\n1:Positive, 2:Negative, 3:Neutral, 4:Mixed\n\n\nFiltering Method\nAutomated using mBERT\n\n\n#Annotators\n64\n\n\nAnnotation/Sample\n2 or 3 (if tie)\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nStatistic\nValue\n\n\n\t\t\nMean Character Length\n62.77\n\n\nMax Character Length\n1985â€¦ See the full description on the dataset page: https://huggingface.co/datasets/aplycaebous/BnSentMix.","first_N":5,"first_N_keywords":["text-classification","Bengali","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_bn","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_bn","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_bn","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_bn","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_bn","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_bn","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_bn","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Bengali"],"keywords_longer_than_N":true},
	{"name":"IndicTTS_Bengali","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SPRINGLab/IndicTTS_Bengali","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","description":"\n\t\n\t\t\n\t\tBengali Indic TTS Dataset\n\t\n\nThis dataset is derived from the Indic TTS Database project, specifically using the Bengali monolingual recordings from both male and female speakers. The dataset contains high-quality speech recordings with corresponding text transcriptions, making it suitable for text-to-speech (TTS) research and development.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Bengali\nTotal Duration: ~15.06 hours (Male: 10.05 hours, Female: 5.01 hours)\nAudio Format: WAV\nSampling Rate:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/IndicTTS_Bengali.","first_N":5,"first_N_keywords":["text-to-speech","Bengali","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MediBeng","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng","creator_name":"Promila Ghosh","creator_url":"https://huggingface.co/pr0mila-gh0sh","description":"\n\n  \n\n\n\n  \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for MediBeng\n\t\n\nThis dataset includes synthetic code-switched conversations in Bengali and English. It is designed to help train models for tasks like speech recognition (ASR), text-to-speech (TTS), and machine translation, focusing on bilingual code-switching in healthcare settings. The dataset is free to use.For a detailed guide on how this dataset was created, follow the steps outlined in the GitHub repository: ParquetToHuggingFace.\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pr0mila-gh0sh/MediBeng.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-audio","text-to-speech","translation"],"keywords_longer_than_N":true},
	{"name":"vqa-v1.1","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldcuisines/vqa-v1.1","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\n\t\n\t\t\n\t\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\n\t\n\n\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 October 2024.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa-v1.1.","first_N":5,"first_N_keywords":["multilingual","English","Indonesian","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"Bangla-Instruct","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/md-nishat-008/Bangla-Instruct","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","description":"\nBangla-Instruct\nState-of-the-art Bangla Instruction Dataset\n\n\n\n\n\n\n\n\n\n\n\nTigerLLM introduces a state-of-the-art dataset designed to advance Bangla language modeling. The Bangla-Instruct dataset contains high-quality native Bangla instruction-response pairs that have been generated using cutting-edge teacher models.\n\n\n\n\nOverview\n\n\n\nThe Bangla-Instruct dataset is composed of 100,000 instruction-response pairs. It starts with 500 seed tasks created by 50 volunteer experts from premier Bangladeshiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/Bangla-Instruct.","first_N":5,"first_N_keywords":["text-generation","Bengali","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","description":"\n\n\n\t\n\t\t\n\t\tðŸ”· Accepted in NAACL Proceedings (2025) ðŸ”·\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval ðŸ“š [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"tokenizer-robustness-mmlu","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-mmlu","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","description":"\n\t\n\t\t\n\t\tTokenizer Robustness MMLU Dataset\n\t\n\nThis dataset contains MMLU-formatted questions and answers designed to test tokenizer robustness across different text formats and languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of the same questions presented in 6 different formats, with both test (20 questions) and development (5 questions) sets:\n\noriginal - Standard formatted questions\nminor_spelling_errors - Questions with minor misspellings\nspoken_language - Questions in casualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-mmlu.","first_N":5,"first_N_keywords":["English","Russian","Chinese","Japanese","German"],"keywords_longer_than_N":true},
	{"name":"IGB_XQuAD","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IGB_XQuAD","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"VarunGumma/IGB_XQuAD dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"IGB_Flores_enxx","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IGB_Flores_enxx","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"VarunGumma/IGB_Flores_enxx dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"IGB_Flores_xxen","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IGB_Flores_xxen","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"VarunGumma/IGB_Flores_xxen dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"Language_Identification_v1","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Process-Venue/Language_Identification_v1","creator_name":"ProcessVenue","creator_url":"https://huggingface.co/Process-Venue","description":"\n\t\n\t\t\n\t\tDataset Card for Language Identification Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA comprehensive dataset for Indian language identification and text classification. The dataset contains text samples across 10 major Indian languages, making it suitable for developing language identification systems and multilingual NLP applications.\n\n\t\n\t\t\n\t\tLanguages and Distribution\n\t\n\nLanguage Distribution:\nUrdu         1000\nHindi        1000\nOdia         1000\nTamil        1000\nKannada      1000\nBengaliâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Process-Venue/Language_Identification_v1.","first_N":5,"first_N_keywords":["text-classification","text-generation","Hindi","Urdu","Bengali"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gpt4o_gen","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gpt4o_gen","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gpt4o_gen dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"Saka-Alpaca-v1","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Saka-Alpaca-v1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"https://chatgpt.com\n","first_N":5,"first_N_keywords":["text-generation","Swedish","Norwegian","Finnish","German"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Bangla-TextBook","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/md-nishat-008/Bangla-TextBook","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","description":"\nBangla-TextBook Corpus\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\n  \n    Statistic\n    Value\n  \n  \n    Total Tokens\n    9,897,623\n  \n  \n    Total Sentences\n    697,903\n  \n  \n    Number of Textbooks\n    163\n  \n  \n    Grade Range\n    6 - 12\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tUses & Applications\n\t\n\n\n  Language Model Pretraining: Equip models with high-quality, context-rich Bangla academic content.\n  Benchmarking: Serve as a standard for evaluating performance on Bangla language tasks.Educational Tools:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/Bangla-TextBook.","first_N":5,"first_N_keywords":["text-generation","Bengali","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"panlex-definitions","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-definitions","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-definitions\n\t\n\nThis is a dataset of word definitions in several hudnred languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20250201 database dump) and rearranged on the per-language basis (by the language of the definition).\nEach language subset consists of definitions (short phrases).\nEach definition is associated with some meanings (if there isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-definitions.","first_N":5,"first_N_keywords":["translation","Abkhazian","Hijazi Arabic","Afrikaans","Ainu (Japan)"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"Kaleidoscope","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Anonym-sub/Kaleidoscope","creator_name":"Anonymous submission","creator_url":"https://huggingface.co/Anonym-sub","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Anonym-sub/Kaleidoscope.","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_bn","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Bengali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_bn","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoFEVER dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Bengali"],"keywords_longer_than_N":true},
	{"name":"wmt-da-human-evaluation-long-context","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLong-context / document-level dataset for Quality Estimation of Machine Translation.\nIt is an augmented variant of the sentence-level WMT DA Human Evaluation dataset.\nIn addition to individual sentences, it contains augmentations of 2, 4, 8, 16, and 32 sentences, among each language pair lp and domain.\nThe raw column represents a weighted average of scores of augmented sentences using character lengths of src and mt as weights.\nThe code used to apply the augmentationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context.","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Estonian"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_bn","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Bengali"],"keywords_longer_than_N":true},
	{"name":"IN22-Conv-Doc-Level","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IN22-Conv-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"This dataset was constructed by merging individual conversations from the IN22-Conv dataset to create a long-context, document-level parallel benchmark. For further information on domains and statistics, please refer to the original paper and dataset.\n","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"Flores-Indic-Doc-Level","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/Flores-Indic-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"This dataset was constructed by merging individual sentences from the Flores dataset based on matching domain, topic, and URL attributes. The result is a long-context, document-level parallel benchmark. For more details on the domains and dataset statistics, please refer to the original paper and the dataset.\n","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSynthdog Multilingual\n\t\n\n\n\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzfâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"kaleidoscope","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/kaleidoscope","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/kaleidoscope.","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Math","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Math","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Math is a dataset of BenchMAX, sourcing from MGSM, which evaluates the math reasoning capability in multilingual scenarios.\nWe extend the original MGSM dataset by six additional languages, i.e. Arabic, Czech, Hungarian, Korean, Serbian, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Math.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Science","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Science","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Science is a dataset of BenchMAX, sourcing from GPQA, which evaluates the natural science reasoning capability in multilingual scenarios.\nWe extend the original English dataset to 16 non-English languages.\nThe data is first translated by Googleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Science.","first_N":5,"first_N_keywords":["question-answering","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Question_Answering","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Question_Answering is a dataset of BenchMAX for evaluating the long-context capability of LLMs in multilingual scenarios.\nThe subtasks are similar to the subtasks in RULER.\nThe data is sourcing from UN Parallel Corpus and xquad.\nThe haystacksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tasmay-Tib/sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600","creator_name":"Tasmay Pankaj Tibrewal","creator_url":"https://huggingface.co/Tasmay-Tib","description":"Dataset for sarvam's entity normalisation task. More detailed information can be found here, in the main model repo: Hugging Face\nDetailed Report (Writeup): Google Drive\nIt also has a gguf variant, with certain additional gguf based innstructions: Hugging Face\nModel inference script can be found here: Colab\nModel predictions can be found in this dataset and both the repo files. named as: \n\neval_data_001_predictions.csv and eval_data_001_predictions_excel.csv.\ntrain_data_001_predictions.csvandâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tasmay-Tib/sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600.","first_N":5,"first_N_keywords":["Hindi","Tamil","Telugu","Marathi","Bengali"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Chat","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","description":"\n\t\n\t\t\n\t\tDATA-AI: Il Modello di IA di M.INC.\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Œ Introduzione\n\t\n\nDATA-AI Ã¨ un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello Ã¨ basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \nDATA-AI Ã¨ stato addestrato su unâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat.","first_N":5,"first_N_keywords":["Italian","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"MIRACLReranking","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MIRACLReranking","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MIRACLReranking\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://project-miracl.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MIRACLReranking.","first_N":5,"first_N_keywords":["text-ranking","expert-annotated","multilingual","miracl/mmteb-miracl","Arabic"],"keywords_longer_than_N":true},
	{"name":"2M-Belebele","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\t2M-Belebele\n\t\n\n\n\t\n\t\t\n\t\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\n\t\n\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs datasets asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.","first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Bulgarian","Panjabi","English"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\n\t\n\t\t\n\t\tlightblue/reasoning-multilingual-R1-Llama-70B-train\n\t\n\nThis is a multilingual reasoning dataset covering more than 30 languages.\nThis dataset was made by:\n\nSampling prompts from English datasets and translating them to various languages\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\n\nThis dataset was then used to train a multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Rule-based","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Rule-based is a dataset of BenchMAX, sourcing from IFEval, which is a rule-based benchmark for evaluating the instruction following capabilities in multilingual scenarios.\nWe extend the original dataset to 16 non-English languages by firstâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Model-based","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Model-based is a dataset of BenchMAX, sourcing from m-ArenaHard, which evaluates the instruction following capability via model-based judgment.\nWe extend the original dataset to include languages that are not supported by m-ArenaHard throughâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Function_Completion","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from humanevalplus, which evaluates the code generation capability in multilingual scenarios.\nWe extend the original English dataset to 16 non-English languages.\nThe data is first translatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Problem_Solving","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Problem_Solving is a dataset of BenchMAX, sourcing from LiveCodeBench_v4, which evaluates the code generation capability for solving multilingual competitive code problems.\nWe extend the original English dataset by 16 non-English languages.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Multiple_Functions","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Multiple_Functions is a dataset of BenchMAX, sourcing from Nexus.\nThis dataset evaluates the tool use capability in multilingual senarios, which requires a model to call the correct function given the user query and multiple functions.\nWeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_General_Translation","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_General_Translation is a dataset of BenchMAX, which evaluates the translation capability on the general domain.\nWe collect parallel test data from Flore-200, TED-talk, and WMT24.\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\ngit cloneâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation.","first_N":5,"first_N_keywords":["translation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Domain_Translation","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Domain_Translation is a dataset of BenchMAX, which evaluates the translation capability on specific domains.\nWe collect the domain multi-way parallel data from other tasks in BenchMAX, such as math data, code data, etc.\nEach sample contains oneâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation.","first_N":5,"first_N_keywords":["translation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"Pralekha","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/Pralekha","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tPralekha: Cross-Lingual Document Alignment for Indic Languages\n\t\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\nPralekha is a large-scale parallel document dataset spanning across 11 Indic languages and English. It comprises over 3 milliondocument pairs, with 1.5 million being English-centric. This dataset serves both as a benchmark for evaluating Cross-Lingual Document Alignment (CLDA) techniques and as a domain-specific parallel corpus for training document-level Machine Translationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Pralekha.","first_N":5,"first_N_keywords":["translation","Bengali","English","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tBelebele-Fleurs\n\t\n\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\n\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30â€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_bn","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Bengali version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bn.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Bengali"],"keywords_longer_than_N":true},
	{"name":"bengali_regional_dataset_refine","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sha1779/bengali_regional_dataset_refine","creator_name":"Md sazzad hossain","creator_url":"https://huggingface.co/sha1779","description":"This is the dataset of  à¦­à¦¾à¦·à¦¾-à¦¬à¦¿à¦šà¦¿à¦¤à§à¦°à¦¾: ASR for Regional Dialects competition.\nhere i preprocessed and make train and eval split.\nthis dataset consist of 10 dialact named 'barishal', 'chittagong', 'habiganj', 'kishoreganj', 'narail',\n       'narsingdi', 'rangpur', 'sandwip', 'sylhet', 'tangail'.\nbarishal district has 796 samples\nchittagong district has 1406 samples\nhabiganj district has 940 samples\nkishoreganj district has 1638 samples\nnarail district has 1488 samples\nnarsingdi district hasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sha1779/bengali_regional_dataset_refine.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Bengali","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"bd-bcs-multimodal","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/azminetoushikwasi/bd-bcs-multimodal","creator_name":"Azmine Toushik Wasi","creator_url":"https://huggingface.co/azminetoushikwasi","description":"azminetoushikwasi/bd-bcs-multimodal dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Bengali","apache-2.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"indic-parallel-sentences-talks","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aloobun/indic-parallel-sentences-talks","creator_name":"aloobun","creator_url":"https://huggingface.co/aloobun","description":"\n\t\n\t\t\n\t\tDataset Card for Parallel Sentences - Indic Talks\n\t\n\nThis dataset contains parallel sentences (i.e. English sentence + the same sentences in another language) for numerous other languages.\n","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"IndicQARetrieval","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIndicQA is a manually curated cloze-style reading comprehension dataset that can be used for evaluating question-answering models in 11 Indic languages. It is repurposed retrieving relevant context for each question.\n\n\t\n\t\t\n\n\n\n\n\t\tTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicQARetrieval.","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","translated","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"reranking-datasets-light","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","description":"\n\t\n\t\t\n\t\tðŸ”¥ Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation ðŸ”¥\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\n\t\n\n\n    \n    \n    \n    \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n    \n\n\n\nA curated collection of ready-to-use datasets for retrieval and rerankingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light.","first_N":5,"first_N_keywords":["question-answering","English","Arabic","German","French"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xm100","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM100\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"titulm-bangla-corpus","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hishab/titulm-bangla-corpus","creator_name":"Hishab","creator_url":"https://huggingface.co/hishab","description":"\n\t\n\t\t\n\t\tTituLM Bangla Corpus\n\t\n\nThis dataset is associated with the paper TituLLMs: A Family of Bangla LLMs with Comprehensive Benchmarking\nTituLM Bangla Corpus is one of the largest Bangla clean corpus prepared for pretraining, continual pretraining or fine-tuning Large Language Model(LLM) for improving Bangla text generation capability.\nThis dataset contains diverse sources and categories of Bangla text. The largest part of this dataset contains filtered common crawled datasets. As we sawâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hishab/titulm-bangla-corpus.","first_N":5,"first_N_keywords":["text-generation","Bengali","cc-by-4.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"MMMLU_subset","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/double7/MMMLU_subset","creator_name":"Sen Yang","creator_url":"https://huggingface.co/double7","description":"\n\t\n\t\t\n\t\tAbout MMMLU subset\n\t\n\n  This is a subset of MMMLU, specifically, we sampled 10% of the original data to improve evaluation efficiency.\n  In addition, we categorize the questions into four categories by subject, i.e., STEM, HUMANITIES, SOCIAL SCIENCES, and OTHER, aligned with MMLU.\n\n\t\n\t\t\n\t\n\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57â€¦ See the full description on the dataset page: https://huggingface.co/datasets/double7/MMMLU_subset.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"synthetic-bengali-sentiment","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shaikh25/synthetic-bengali-sentiment","creator_name":"shaikh R","creator_url":"https://huggingface.co/shaikh25","description":"\n\t\n\t\t\n\t\tBengali Sentiment Analysis Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 44,236 Bengali sentences with corresponding sentiment labels, synthetically generated using ChatGPT for natural language processing and machine learning research.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Bengali (à¦¬à¦¾à¦‚à¦²à¦¾)\nTotal Entries: 44,236 synthetic sentences\nTask: Sentiment Classification\nFormat: JSON\nGeneration Method: OpenAI ChatGPT (GPT-4)\nLicense: CC0 1.0 Universal (Public Domain)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shaikh25/synthetic-bengali-sentiment.","first_N":5,"first_N_keywords":["text-classification","Bengali","English","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"synthetic-bengali-sentiment","keyword":"bengali","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shaikh25/synthetic-bengali-sentiment","creator_name":"shaikh R","creator_url":"https://huggingface.co/shaikh25","description":"\n\t\n\t\t\n\t\tBengali Sentiment Analysis Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 44,236 Bengali sentences with corresponding sentiment labels, synthetically generated using ChatGPT for natural language processing and machine learning research.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Bengali (à¦¬à¦¾à¦‚à¦²à¦¾)\nTotal Entries: 44,236 synthetic sentences\nTask: Sentiment Classification\nFormat: JSON\nGeneration Method: OpenAI ChatGPT (GPT-4)\nLicense: CC0 1.0 Universal (Public Domain)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shaikh25/synthetic-bengali-sentiment.","first_N":5,"first_N_keywords":["text-classification","Bengali","English","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"R3-eval-MMMLU","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HLeiTR/R3-eval-MMMLU","creator_name":"Shou-Yi Hung","creator_url":"https://huggingface.co/HLeiTR","description":"HLeiTR/R3-eval-MMMLU dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"IndicXnliPairClassification","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicXnliPairClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicXnliPairClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nINDICXNLI is similar to existing XNLI dataset in shape/form, but\n        focusses on Indic language family.\n        The train (392,702), validation (2,490), and evaluation sets (5,010) of English\n        XNLI were translated from English into each of the eleven Indic languages. IndicTrans\n        is a large Transformer-based sequence to sequence model. It is trained on Samanantar\n        dataset (Ramesh etâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicXnliPairClassification.","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","derived","translated","Divyanshu/indicxnli"],"keywords_longer_than_N":true},
	{"name":"llm-metric-mgsm","keyword":"bengali","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rubricreward/llm-metric-mgsm","creator_name":"rubricreward","creator_url":"https://huggingface.co/rubricreward","description":"rubricreward/llm-metric-mgsm dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["found","found","expert-generated","multilingual","extended|gsm8k"],"keywords_longer_than_N":true},
	{"name":"Bangladesh-Legal-Acts-Dataset","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sakhadib/Bangladesh-Legal-Acts-Dataset","creator_name":"Adib Sakhawat","creator_url":"https://huggingface.co/sakhadib","description":"\n\t\n\t\t\n\t\tBangladesh Legal Acts Dataset\n\t\n\nA comprehensive database of Bangladesh's legal framework, containing 1484+ acts scraped and processed from the official Bangladesh Laws portal, enhanced with historical government context, legal system context, and comprehensive metadata.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Acts: 1,484\nTotal Sections: 35,633\nTotal Footnotes: 14,523\nLanguages: English, Bengali, Mixed\nFormat: JSON with structured metadata\nHistorical Context: Government periods fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sakhadib/Bangladesh-Legal-Acts-Dataset.","first_N":5,"first_N_keywords":["English","Bengali","cc-by-4.0","ðŸ‡ºðŸ‡¸ Region: US","nlp"],"keywords_longer_than_N":true},
	{"name":"IndicMSMARCO","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/IndicMSMARCO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tðŸ” IndicMSMARCO: Multilingual Information Retrieval Benchmark\n\t\n\nA comprehensive multilingual variant of MS MARCO specifically tailored for Indian languages, featuring carefully selected queries and corresponding passages with high-quality translations.\n\n\t\n\t\t\n\t\tðŸš€ Quick Start - Load Individual Languages\n\t\n\nfrom datasets import load_dataset\n\n# Load ONLY Hindi data (fast and efficient!)\nhindi_data = load_dataset(\"ai4bharat/IndicMSMARCO\", \"hi\")\nprint(f\"Hindi queries:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/IndicMSMARCO.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multilingual","ms_marco","Assamese"],"keywords_longer_than_N":true},
	{"name":"quran_multilingual_parallel","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/quran_multilingual_parallel","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tðŸ“˜ Qurâ€™an Multilingual Parallel Dataset (quran_multilingual_parallel)\n\t\n\nThis dataset presents a clean, structurally-aligned multilingual parallel corpus of the Qurâ€™anic text. It is intended for linguistic, computational, and cross-lingual AI applications â€” not only for religious interpretation.\nIt contains over 6,200 verse-level alignments in 54 human languages, formatted in a machine-friendly .csv structure with language-specific translation fields.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ§  Dataset Highlightsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/freococo/quran_multilingual_parallel.","first_N":5,"first_N_keywords":["translation","Arabic","Albanian","Amharic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"BengaliHateSpeechClassification","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/BengaliHateSpeechClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BengaliHateSpeechClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Bengali Hate Speech Dataset is a Bengali-language dataset of news articles collected from various Bengali media sources and categorized based on the type of hate in the text.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/bn_hate_speech\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/BengaliHateSpeechClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"Indic-Rag-Suite","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/Indic-Rag-Suite","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tðŸŒ Multilingual Indic RAG Suite\n\t\n\nA comprehensive multilingual question-answering dataset covering 18 Indian languages with 21,439,886 total samples, designed for RAG (Retrieval-Augmented Generation) applications and multilingual NLP research.\n\n\t\n\t\t\n\t\tðŸš€ Quick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load specific language (recommended)\ndataset = load_dataset(\"ai4bharat/Indic-Rag-Suite\", \"as\")\ntrain_data = dataset['train']\n\nprint(f\"Loaded {len(train_data)} samples\")\n\n# Accessâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Indic-Rag-Suite.","first_N":5,"first_N_keywords":["question-answering","text-generation","multilingual","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"hishab-pr-bn-v1","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hishab/hishab-pr-bn-v1","creator_name":"Hishab","creator_url":"https://huggingface.co/hishab","description":"\n\t\n\t\t\n\t\tHishab PR Bengali v1\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Bengali text punctuation restoration data in a conversational format. The dataset is designed for training and evaluating models to restore punctuation in Bengali text. Each conversation consists of a human providing unpunctuated Bengali text and a GPT assistant providing the same text with proper punctuation restored.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Bengali (bn)\nTask: Punctuation Restorationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hishab/hishab-pr-bn-v1.","first_N":5,"first_N_keywords":["Bengali","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Indic-Rag-Suite","keyword":"bengali","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AshwinSankar/Indic-Rag-Suite","creator_name":"Ashwin Sankar","creator_url":"https://huggingface.co/AshwinSankar","description":"\n\t\n\t\t\n\t\tðŸŒ Multilingual Indic RAG Suite\n\t\n\nA comprehensive multilingual question-answering dataset covering 18 Indian languages with 12,802,615 total samples, designed for RAG (Retrieval-Augmented Generation) applications and multilingual NLP research.\n\n\t\n\t\t\n\t\tðŸš€ Quick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load specific language (recommended)\ndataset = load_dataset(\"AshwinSankar/Indic-Rag-Suite\", \"as\")\ntrain_data = dataset['train']\n\nprint(f\"Loaded {len(train_data)} samples\")\n\n# Accessâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AshwinSankar/Indic-Rag-Suite.","first_N":5,"first_N_keywords":["question-answering","text-generation","multilingual","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"wmt-human-all","keyword":"bengali","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zouharvi/wmt-human-all","creator_name":"VilÃ©m Zouhar","creator_url":"https://huggingface.co/zouharvi","description":"This dataset is continuously updated and contains a compilation of human translation quality assessment from past WMT campaigns.\nSpecifically, this dataset merges all annotation protocols (DA, MQM, ESA) on a semi-unified scale (0 to 100).\nThe current version of the dataset includes human scores up to WMT 2024 (inclusive) and has been created with the following script:\nimport subset2evaluate # version 1.0.14\nimport json\nimport statistics\n\ndata =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/wmt-human-all.","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"KUET_whispers_Dataset","keyword":"bengali","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sanjidh90/KUET_whispers_Dataset","creator_name":"Sanjid Hasan","creator_url":"https://huggingface.co/sanjidh90","description":"\n\t\n\t\t\n\t\tðŸ“˜ Dataset Card: KUET Whispers\n\t\n\n\n\t\n\t\t\n\t\tðŸ§¾ Overview\n\t\n\nKUET Whispers is a curated dataset of anonymous, emotionally expressive posts collected from HazyBoardâ€”a student-run, anonymous confessions platform at Khulna University of Engineering & Technology (KUET) in Bangladesh. The dataset captures natural, informal, and highly engaging text data in Bangla, English, and code-mixed formats, making it suitable for a range of NLP tasks including:\n\nSentiment and emotion analysis  \nCode-mixedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sanjidh90/KUET_whispers_Dataset.","first_N":5,"first_N_keywords":["Bengali","English","cc-by-4.0","1K - 10K","csv"],"keywords_longer_than_N":true}
]
;
