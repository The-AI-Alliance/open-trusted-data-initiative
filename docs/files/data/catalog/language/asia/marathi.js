const data_for_language_asia_marathi = 
[
	{"name":"panlex","keyword":"marathi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arb√´resh√´ Albanian"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = [\\n        {\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": columns[\\\"inputs\\\"].strip(),\\n        },\\n        {‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"indic-align","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/indic-align","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIndicAlign\\n\\t\\n\\nA diverse collection of Instruction and Toxic alignment datasets for 14 Indic Languages. The collection comprises of:\\n\\nIndicAlign - Instruct\\nIndic-ShareLlama\\nDolly-T\\nOpenAssistant-T\\nWikiHow\\nIndoWordNet\\nAnudesh\\nWiki-Conv\\nWiki-Chat\\n\\n\\nIndicAlign - Toxic\\nHHRLHF-T\\nToxic-Matrix\\n\\n\\n\\nWe use IndicTrans2 (Gala et al., 2023) for the translation of the datasets. \\nWe recommend the readers to check out our paper on Arxiv for detailed information on the curation process of these‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/indic-align.","first_N":5,"first_N_keywords":["text-generation","Assamese","Bengali","Gujarati","English"],"keywords_longer_than_N":true},
	{"name":"Nadi_Indic466k_Instruct","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct","creator_name":"Convai Innovations","creator_url":"https://huggingface.co/convaiinnovations","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNadi_Indic466K_Instruct Dataset\\n\\t\\n\\nThe Nadi_Indic466K_Instruct dataset is the world's first coding dataset with 18 Indian language support, 466k rows and 142 Million total tokens. This dataset can be used by developers to build Indian coding language models (LLMs) for various programming languages.\\nQ-LoRA based SFT/PPO/DPO fine-tuning can be done on the dataset in LLAMA-2 or Mistral or any opens-soure LLM for text generation.\\nThe dataset was carefully curated such that the coding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct.","first_N":5,"first_N_keywords":["text-generation","Hindi","Panjabi","Bengali","Tamil"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\\nand converted into different parts (see process.py):\\n\\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\\n\\nRaw data files are in raw.tar.gz, which contains:\\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\\n[...] 9.8M Feb 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiQ\\n\\t\\n\\nThis is the dataset corresponding to the paper \\\"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\\\". \\nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \\ntranslated into 137 typologically diverse languages. \\n\\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"limmits-2024","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iAkashPaul/limmits-2024","creator_name":"Akash","creator_url":"https://huggingface.co/iAkashPaul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIndic TTS dataset\\n\\t\\n\\n7 languages from IISC's LIMMITS Challenge 2024\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRoadmap\\n\\t\\n\\nTo use this for training VALLE-X & VoiceBox based TTS models\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFetch the tars directly\\n\\t\\n\\nwget -O 'Bengali_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Bengali_F.tar.gz'\\nwget -O 'Chhattisgarhi_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Chhattisgarhi_F.tar.gz'\\nwget -O 'English_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/English_F.tar.gz'\\nwget -O‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iAkashPaul/limmits-2024.","first_N":5,"first_N_keywords":["text-to-speech","English","Bengali","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"marathi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"indic_sts","keyword":"marathi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/indic_sts","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Indic STS\\n\\t\\n\\nThis dataset is STS benchmark between English and 12 high-resource Indic languages. This was released as a part of Samanantar paper. Please refer to the paper for more details.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nAvailable languages are: en-as, en-bn, en-gu, en-hi, en-kn, en-ml, en-mr, en-or, en-pa, en-ta, en-te, en-ur\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Fields\\n\\t\\n\\n\\nlang_code: 2-digit ISO language code\\nsource: The source from which the candidate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jaygala24/indic_sts.","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"indic-swim-ir-cross-lingual","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/indic-swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Indic SWIM-IR (Cross-lingual)\\n\\t\\n\\n\\n\\n\\nThis is the cross-lingual Indic subset of the SWIM-IR dataset, where the query generated is in the Indo-European language and the passage is in English.\\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/indic-swim-ir-cross-lingual.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","machine-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"marathi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"indic_sts","keyword":"marathi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/indic_sts","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Indic STS\\n\\t\\n\\nThis dataset is STS benchmark between English and 12 high-resource Indic languages. This was released as a part of Samanantar paper. Please refer to the paper for more details.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nAvailable languages are: en-as, en-bn, en-gu, en-hi, en-kn, en-ml, en-mr, en-or, en-pa, en-ta, en-te, en-ur\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Fields\\n\\t\\n\\n\\nlang_code: 2-digit ISO language code\\nsource: The source from which the candidate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/indic_sts.","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"shrutilipi","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amithm3/shrutilipi","creator_name":"Amith M","creator_url":"https://huggingface.co/amithm3","description":"amithm3/shrutilipi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","Sanskrit","Bengali","Panjabi"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"marathi-orca-v05","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/amitagh/marathi-orca-v05","creator_name":"Amit","creator_url":"https://huggingface.co/amitagh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card for Marathi OpenOrca\\n\\t\\n\\nTranslated subset of Open-Orca/1million-gpt-4 to marathi language.\\n","first_N":5,"first_N_keywords":["text-generation","question-answering","Marathi","English","mit"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"IN22-Conv","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IN22-Conv","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIN22-Conv\\n\\t\\n\\nIN-22 is a newly created comprehensive benchmark for evaluating machine translation performance in multi-domain, n-way parallel contexts across 22 Indic languages. IN22-Conv is the conversation domain subset of IN22. It is designed to assess translation quality in typical day-to-day conversational-style applications. The evaluation subset consists of 1503 sentences translated across 22 Indic languages enabling evaluation of MT systems across 506 directions.\\nCurrently‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Conv.","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"IN22-Gen","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IN22-Gen","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIN22-Gen\\n\\t\\n\\nIN22 is a newly created comprehensive benchmark for evaluating machine translation performance in multi-domain, n-way parallel contexts across 22 Indic languages. IN22-Gen is a general-purpose multi-domain evaluation subset of IN22. It has been created from two sources: Wikipedia and Web Sources offering diverse content spanning news, entertainment, culture, legal, and India-centric topics. The evaluation subset consists of 1024 sentences translated across 22 Indic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Gen.","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"x-fact","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"x-fact\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact.","first_N":5,"first_N_keywords":["text-classification","Arabic","Bengali","Spanish","Persian"],"keywords_longer_than_N":true},
	{"name":"marathi_sa","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DGurgurov/marathi_sa","creator_name":"Daniil Gurgurov","creator_url":"https://huggingface.co/DGurgurov","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentiment Analysis Data for the Marathi Language\\n\\t\\n\\nDataset Description:\\nThis dataset contains a sentiment analysis dataset from Pingle et al. (2023).\\nData Structure:\\nThe data was used for the project on improving word embeddings with graph knowledge for Low Resource Languages.\\nCitation:\\n@article{pingle2023l3cube,\\n  title={L3Cube-MahaSent-MD: A Multi-domain Marathi Sentiment Analysis Dataset and Transformer Models},\\n  author={Pingle, Aabha and Vyawahare, Aditya and Joshi, Isha and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DGurgurov/marathi_sa.","first_N":5,"first_N_keywords":["text-classification","Marathi","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Benchmark-Testing","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shounakpaul95/Benchmark-Testing","creator_name":"Shounak Paul","creator_url":"https://huggingface.co/shounakpaul95","description":"shounakpaul95/Benchmark-Testing dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","summarization","translation","token-classification","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \\nBibTex\\n@misc{lu2024languagecountslearnunlearn,\\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \\n      author={Taiming Lu and Philipp Koehn},\\n      year={2024},\\n      eprint={2406.13748},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2406.13748}, \\n}\\n\\n","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\\nChanges:\\n\\nUsed archive.org metadata API to annotate rows with \\\"duration\\\" column\\n\\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"XL-HeadTags","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/faisaltareque/XL-HeadTags","creator_name":"Faisal Tareque Shohan","creator_url":"https://huggingface.co/faisaltareque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for XL-HeadTags Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Source\\n\\t\\n\\nWe have used M3LS and XL-Sum as source for this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n We provide XL-HeadTags, a large-scale news headline and tags generation dataset. The dataset consists of 20 languages across six diverse language families. It contains 415K news headline-article pairs with auxiliary information such as image captions, topic words (read more).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/faisaltareque/XL-HeadTags.","first_N":5,"first_N_keywords":["summarization","text2text-generation","sentence-similarity","English","Portuguese"],"keywords_longer_than_N":true},
	{"name":"shiksha","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SPRINGLab/shiksha","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShiksha Dataset\\n\\t\\n\\nThis is a Technical Domain focused Translation Dataset for 8 Indian Languages. It consists of more than 2.5 million rows of translation pairs between all 8 languages and English.\\nThis data has been derived from raw NPTEL documents. More information on this can be found in our paper: https://arxiv.org/abs/2412.09025\\nIf you use this data in your work, please cite us:\\n@misc{joglekar2024shikshatechnicaldomainfocused,\\n      title={Shiksha: A Technical Domain focused‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/shiksha.","first_N":5,"first_N_keywords":["translation","Hindi","Bengali","Tamil","Telugu"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"MegaWika","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/conceptofmind/MegaWika","creator_name":"Enrico Shippole","creator_url":"https://huggingface.co/conceptofmind","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. Furthermore, nearly 130 million English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/conceptofmind/MegaWika.","first_N":5,"first_N_keywords":["summarization","question-answering","text-generation","text2text-generation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"RoundTripOCR-marathi","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cfilt/RoundTripOCR-marathi","creator_name":"Computation for Indian Language Technology","creator_url":"https://huggingface.co/cfilt","description":"Post-OCR error correction dataset (train, test and validation set) for Marathi language generated using RoundTripOCR technique.\\nCode: https://github.com/harshvivek14/RoundTripOCR\\n","first_N":5,"first_N_keywords":["Marathi","apache-2.0","1M - 10M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_mr","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_mr","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_mr","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_mr","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_mr","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_mr","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_mr","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Marathi"],"keywords_longer_than_N":true},
	{"name":"IN22-Conv-Doc-Level","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IN22-Conv-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"This dataset was constructed by merging individual conversations from the IN22-Conv dataset to create a long-context, document-level parallel benchmark. For further information on domains and statistics, please refer to the original paper and dataset.\\n","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"Flores-Indic-Doc-Level","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/Flores-Indic-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"This dataset was constructed by merging individual sentences from the Flores dataset based on matching domain, topic, and URL attributes. The result is a long-context, document-level parallel benchmark. For more details on the domains and dataset statistics, please refer to the original paper and the dataset.\\n","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tasmay-Tib/sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600","creator_name":"Tasmay Pankaj Tibrewal","creator_url":"https://huggingface.co/Tasmay-Tib","description":"Dataset for sarvam's entity normalisation task. More detailed information can be found here, in the main model repo: Hugging Face\\nDetailed Report (Writeup): Google Drive\\nIt also has a gguf variant, with certain additional gguf based innstructions: Hugging Face\\nModel inference script can be found here: Colab\\nModel predictions can be found in this dataset and both the repo files. named as: \\n\\neval_data_001_predictions.csv and eval_data_001_predictions_excel.csv.\\ntrain_data_001_predictions.csvand‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tasmay-Tib/sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600.","first_N":5,"first_N_keywords":["Hindi","Tamil","Telugu","Marathi","Bengali"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\\nsource: the source sentence.\\nchosen: the preferred translation.\\nreject: the dis-preferred translation.\\ndirections: the translation direction.\\n@misc{xu2024xalmaplugplay,\\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \\n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\\n      year={2024},\\n      eprint={2410.03115}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-a","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track A Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track A, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 26 standard ISO codes\\nTotal examples: 115159\\nSplits: train, dev, test\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguage Configurations\\n\\t\\n\\nEach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-c","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track C Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track C, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 30 standard ISO codes\\nTotal examples: 57254\\nSplits: dev, test (Track C has no train split)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTrack‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"english-to-marathi-mt","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hemanth-thunder/english-to-marathi-mt","creator_name":"Hemanth-thunder","creator_url":"https://huggingface.co/Hemanth-thunder","description":"Hemanth-thunder/english-to-marathi-mt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Marathi","English","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"mmlu-indic","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sarvamai/mmlu-indic","creator_name":"Sarvam AI","creator_url":"https://huggingface.co/sarvamai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIndic MMLU Dataset\\n\\t\\n\\nA multilingual version of the Massive Multitask Language Understanding (MMLU) benchmark, translated from English into 10 Indian languages.\\nThis version contains the translations of the development and test sets only. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Covered\\n\\t\\n\\nThe dataset includes translations in the following languages:\\n\\nBengali (bn)\\nGujarati (gu)\\nHindi (hi)\\nKannada (kn)\\nMarathi (mr)\\nMalayalam (ml)\\nOriya (or)\\nPunjabi (pa)\\nTamil (ta)\\nTelugu (te)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTask Format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sarvamai/mmlu-indic.","first_N":5,"first_N_keywords":["question-answering","Bengali","English","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"indic-parallel-sentences-talks","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aloobun/indic-parallel-sentences-talks","creator_name":"aloobun","creator_url":"https://huggingface.co/aloobun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Parallel Sentences - Indic Talks\\n\\t\\n\\nThis dataset contains parallel sentences (i.e. English sentence + the same sentences in another language) for numerous other languages.\\n","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"Pralekha","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/Pralekha","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\\n\\t\\n\\t\\t\\n\\t\\tPralekha: Cross-Lingual Document Alignment for Indic Languages\\n\\t\\n\\n\\n  \\n    \\n  \\n  \\n    \\n  \\n  \\n    \\n  \\n  \\n    \\n  \\n\\n\\nPralekha is a large-scale parallel document dataset spanning across 11 Indic languages and English. It comprises over 3 milliondocument pairs, with 1.5 million being English-centric. This dataset serves both as a benchmark for evaluating Cross-Lingual Document Alignment (CLDA) techniques and as a domain-specific parallel corpus for training document-level Machine Translation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Pralekha.","first_N":5,"first_N_keywords":["translation","Bengali","English","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"arc-challenge-indic","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sarvamai/arc-challenge-indic","creator_name":"Sarvam AI","creator_url":"https://huggingface.co/sarvamai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIndic ARC Dataset\\n\\t\\n\\nA multilingual version of the ARC Challenge Set Challenge Set, translated from English into 10 Indian languages. ARC is a collection of grade-school science questions that require complex reasoning to solve.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Covered\\n\\t\\n\\nThe dataset includes translations in the following languages:\\n\\nBengali (bn)\\nGujarati (gu)\\nHindi (hi)\\nKannada (kn)\\nMarathi (mr)\\nMalayalam (ml)\\nOriya (or)\\nPunjabi (pa)\\nTamil (ta)\\nTelugu (te)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Format\\n\\t\\n\\nEach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sarvamai/arc-challenge-indic.","first_N":5,"first_N_keywords":["Bengali","English","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\\n\\n   \\n       Overview |\\n       Details  |\\n       Structure  |\\n       Examples |\\n       Considerations |\\n       License |\\n       Citation |\\n       Contact |\\n       Acknowledgement\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\tlightblue/reasoning-multilingual-R1-Llama-70B-train\\n\\t\\n\\nThis is a multilingual reasoning dataset covering more than 30 languages.\\nThis dataset was made by:\\n\\nSampling prompts from English datasets and translating them to various languages\\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\\n\\nThis dataset was then used to train a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tWMT24++\\n\\t\\n\\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\\nthe publication\\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\\nIf you are interested in the images of the source URLs for each document, please see here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema\\n\\t\\n\\nEach language pair is stored in its own jsonl file.\\nEach row is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xtreme\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\\n\\n\\t\\n\\t\\t\\n\\nToxic\\nNeutral\\nTotal\\n\\n\\n\\t\\t\\nmultilingual-train-deduplicated.csv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","first_N":5,"first_N_keywords":["text-classification","token-classification","zero-shot-classification","Arabic","Spanish"],"keywords_longer_than_N":true},
	{"name":"belebele","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\\n\\t\\n\\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele.","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","text-classification","multiple-choice","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"PMIndiaSum","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PMIndiaData/PMIndiaSum","creator_name":"PMIndiaData","creator_url":"https://huggingface.co/PMIndiaData","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"PMIndiaSum\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nPMIndiaSum is a new multilingual and massively parallel headline summarization corpus focused on languages in India. Our corpus covers four language families, 14 languages, and the largest to date, 196 language pairs. It provides a testing ground for all cross-lingual pairs.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported tasks\\n\\t\\n\\nMonolingual, multilingual and cross-lingual summarization for languages in India.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PMIndiaData/PMIndiaSum.","first_N":5,"first_N_keywords":["summarization","Assamese","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\\n","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_dataset","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\n\\nCurated by: Contributors of Aya Open Science Intiative.\\n\\nLanguage(s): 65 languages (71 including dialects &‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_dataset.","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection.","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\\n\\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\\nmachine-translations of handpicked examples into 101 languages ‚Üí‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \\nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \\nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"sangraha","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/sangraha","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\\n\\t\\n\\t\\t\\n\\t\\tSangraha\\n\\t\\n\\n\\n  \\n\\n\\nSangraha is the largest high-quality, cleaned Indic language pretraining data containing 251B tokens summed up over 22 languages, extracted from curated sources, existing multilingual corpora and large scale translations.\\nMore information:\\n\\nFor detailed information on the curation and cleaning process of Sangraha, please checkout our paper on Arxiv;\\nCheck out the scraping and cleaning pipelines used to curate Sangraha on GitHub;\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tGetting Started\\n\\t\\n\\nFor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/sangraha.","first_N":5,"first_N_keywords":["text-generation","Assamese","Bengali","Gujarati","English"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection_language_split","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection_language_split.","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"tokenizer-wiki-bench","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Tokenizer Benchmark\\n\\t\\n\\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \\nfrom transformers import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench.","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"marathi-hh-rlhf-v02","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/amitagh/marathi-hh-rlhf-v02","creator_name":"Amit","creator_url":"https://huggingface.co/amitagh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card for Marathi HH-RLHF\\n\\t\\n\\nTranslated subset of HH-RLHF version for Marathi language.\\n","first_N":5,"first_N_keywords":["reinforcement-learning","Marathi","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"IndicVarna-100k","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dynopii/IndicVarna-100k","creator_name":"Dynopii Inc","creator_url":"https://huggingface.co/dynopii","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIndicVarna for Callchimp.ai (a Dynopii product)\\n\\t\\n\\nWe introduce IndiVarna which was prepared by using Google Translate on the dair-ai/emotion dataset to get the samples there translated to the top 10 most commonly used Indian languages.\\nThis dataset contains 10000 samples of each of the 10 languages supported.\\nThe dataset further translated the labels in the dataset to 3 label sentiments - 0: Negative, 1: Neutral and 2: Positive. Each language has 3334 samples of each category of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dynopii/IndicVarna-100k.","first_N":5,"first_N_keywords":["text-classification","translation","sentence-similarity","fill-mask","text-generation"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"marathi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"marathi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"Todo - Write dataset card\\n","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"vqa","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldcuisines/vqa","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\\n\\t\\n\\n\\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 October‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa.","first_N":5,"first_N_keywords":["multilingual","English","Indonesian","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"marathi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"marathi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBelebele-Fleurs\\n\\t\\n\\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\\n\\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReranker training data\\n\\t\\n\\nThis data was generated using 4 steps:\\n\\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \\\"1\\\", \\\"2\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"All-about-Peshwes","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Devavrat28/All-about-Peshwes","creator_name":"Devavrat Samak","creator_url":"https://huggingface.co/Devavrat28","description":"Devavrat28/All-about-Peshwes dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Marathi","apache-2.0","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"reranking-datasets-light","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"unkown","creator_url":"https://huggingface.co/abdoelsayed","description":"\\n\\t\\n\\t\\t\\n\\t\\tüî• Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation üî•\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\\n\\t\\n\\n\\n    \\n    \\n    \\n    \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n    \\n\\n\\n\\nA curated collection of ready-to-use datasets for retrieval and reranking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light.","first_N":5,"first_N_keywords":["question-answering","English","Arabic","German","French"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthdog Multilingual\\n\\t\\n\\n\\n\\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tHigh Quality Multilingual Sentences\\n\\t\\n\\n\\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\\n\\nExample row (from the all config):\\n{\\n    \\\"text\\\": \\\"ÿßŸÖÿßŸÖ ÿ¨ŸÖÿπŸá ÿßÿµŸÅŸáÿßŸÜ ⁄ØŸÅÿ™: ŸÖ€åÿ≤ÿßŸÜ ŸÜ€åÿßÿ≤ ÿ¢ÿ® ÿ¥ÿ±ÿ® ÿßÿµŸÅŸáÿßŸÜ €±€±.€µ ŸÖÿ™ÿ± ŸÖ⁄©ÿπÿ® ÿßÿ≥ÿ™ ⁄©Ÿá ÿ™ŸÖÿßŸÖ ÿßÿ≥ÿ™ÿßŸÜ ÿßÿµŸÅŸáÿßŸÜ ÿ±ÿß ŸæŸàÿ¥ÿ¥ ŸÖ€åÿØŸáÿØ Ÿà ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸÇÿ®ŸÑ ÿßÿ≤ ÿßŸÜŸÇŸÑÿßÿ® €å⁄©€å ÿßÿ≤ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿáÿß ÿØÿ± ÿ≠Ÿàÿ≤Ÿá ÿ¢ÿ® ÿ®ŸàÿØŸá ÿßÿ≥ÿ™.\\\",\\n    \\\"fasttext\\\": \\\"fa\\\",\\n    \\\"gcld3\\\": \\\"fa\\\"\\n}\\n\\nFields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"BRIGHTER-emotion-categories","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\tBRIGHTER Emotion Categories Dataset\\n\\t\\n\\nThis dataset contains the emotion categories data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe BRIGHTER Emotion Categories dataset is a comprehensive multi-language, multi-label emotion classification dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories.","first_N":5,"first_N_keywords":["Afrikaans","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"marathi","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"indicxnli","keyword":"marathi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Divyanshu/indicxnli","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","description":"IndicXNLI is a translated version of XNLI to 11 Indic Languages. As with XNLI, the goal is\\nto predict textual entailment (does sentence A imply/contradict/neither sentence\\nB) and is a classification task (given two sentences, predict one of three\\nlabels).","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","machine-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"xP3all","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"xP3mt","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"IE_SemParse","keyword":"marathi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Divyanshu/IE_SemParse","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","description":"    IE-SemParse is an Inter-bilingual Seq2seq Semantic parsing dataset for 11 distinct Indian languages","first_N":5,"first_N_keywords":["text2text-generation","parsing","machine-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\\n\\t\\n\\n  \\nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \\n[arXiv]\\n[HuggingFace Models]\\n[Github repo]\\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDownload\\n\\t\\n\\nUse the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"naamapadam","keyword":"marathi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/naamapadam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","machine-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"Bhasha-Abhijnaanam","keyword":"marathi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Aksharantar\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBhasha-Abhijnaanam is a language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\nAssamese (asm)\\nHindi (hin)\\nMaithili (mai)\\nNepali (nep)\\nSanskrit (san)\\nTamil (tam)\\n\\n\\nBengali (ben)\\nKannada (kan)\\nMalayalam (mal)\\nOriya (ori)\\nSantali (sat)\\nTelugu (tel)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"all-scam-spam","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\\n1040 rows of balanced data, consisting of casual conversations and scam emails in ‚âà10 languages, were manually collected and annotated by me, with some help from ChatGPT.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSome preprcoessing algorithms\\n\\t\\n\\n\\nspam_assassin.js, followed by spam_assassin.py\\nenron_spam.py\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData composition\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Norwegian","Spanish","Somali"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"MarEng_TransLoom","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anujsahani01/MarEng_TransLoom","creator_name":"Anuj Sahani","creator_url":"https://huggingface.co/anujsahani01","description":"anujsahani01/MarEng_TransLoom dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","English","Marathi","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EntityCS\\n\\t\\n\\n\\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \\nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \\nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \\nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_regions","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Regions\\\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\\nKey Features:\\n\\nTextual Data: The dataset contains 500,000 text samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"marathi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUDHR-LID\\n\\t\\n\\nWhy UDHR-LID?\\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \\\"missing\\\" or \\\"?\\\". Also, about 1/3 of the sentences consist only of \\\"articles 1-30\\\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","Metlat√≥noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"WEATHub","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iamshnoo/WEATHub","creator_name":"Anjishnu Mukherjee","creator_url":"https://huggingface.co/iamshnoo","description":"\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"WEATHub\\\"\\n\\t\\n\\nThis dataset corresponds to the data described in the paper \\\"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\\\"\\naccepted to EMNLP 2023.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)\\nto measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub.","first_N":5,"first_N_keywords":["Arabic","Bengali","Central Kurdish","Danish","German"],"keywords_longer_than_N":true},
	{"name":"megawika-report-generation","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika for Report Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. \\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation.","first_N":5,"first_N_keywords":["summarization","text-retrieval","text-generation","text2text-generation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"Pontoon-Translations","keyword":"marathi","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","text2text-generation","crowdsourced","Abkhaz","Achinese"],"keywords_longer_than_N":true},
	{"name":"BB-Ultrachat-IndicLingual6-12k","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rohansolo/BB-Ultrachat-IndicLingual6-12k","creator_name":"Rohan","creator_url":"https://huggingface.co/rohansolo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBB-Ultrachat-IndicLingual6-12k\\n\\t\\n\\nThis dataset is created by bhaiyabot ai to enrich language model training data, especially in the context of Indic languages. code for creation is also open source at https://github.com/ro-hansolo/IndicTrans2HuggingFaceDatasets\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nBB-Ultrachat-IndicLingual6-12k is a curated dataset comprising 12,000 multi-turn conversations, which are a subset of the larger HuggingFaceH4/ultrachat_200k dataset. These conversations have been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rohansolo/BB-Ultrachat-IndicLingual6-12k.","first_N":5,"first_N_keywords":["question-answering","text-generation","Hindi","Malayalam","Tamil"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"Fran√ßais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog convention‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"Deltacorpus_1.1","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, Portoro≈æ, Slovenia).\\nChanges in version 1.1: \\n\\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \\n\\nSVM classifier trained on Universal Dependencies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1.","first_N":5,"first_N_keywords":["token-classification","multilingual","Afrikaans","Albanian","Amharic"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_mr","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_mr","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_mr","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_mr","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_mr","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Marathi"],"keywords_longer_than_N":true},
	{"name":"indic_sentiment_analyzer","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dhruv0808/indic_sentiment_analyzer","creator_name":"Dhruv Bhatnagar","creator_url":"https://huggingface.co/dhruv0808","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Sentiment Analysis Dataset for Indian Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis repository contains a comprehensive sentiment analysis dataset covering 11 Indian languages and English. The dataset is designed to support sentiment analysis tasks across multiple domains and languages, making it valuable for developing multilingual sentiment analysis models and applications.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages Covered\\n\\t\\n\\n\\nEnglish (en) - Original\\nHindi (hi)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dhruv0808/indic_sentiment_analyzer.","first_N":5,"first_N_keywords":["English","Hindi","Telugu","Tamil","Kannada"],"keywords_longer_than_N":true},
	{"name":"Marathi_Handwritten","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Process-Venue/Marathi_Handwritten","creator_name":"ProcessVenue","creator_url":"https://huggingface.co/Process-Venue","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Marathi Handwritten OCR Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Marathi Handwritten Text Dataset is a collection of handwritten text images in Marathi (‡§¶‡•á‡§µ‡§®‡§æ‡§ó‡§∞‡•Ä ‡§≤‡§ø‡§™‡•Ä),\\naimed at supporting the development of Optical Character Recognition (OCR) systems, handwriting analysis tools,\\nand language research.The dataset was curated from native Marathi speakers to ensure a variety of handwriting styles and character variations.\\nThe dataset contains 2520 images with two‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Process-Venue/Marathi_Handwritten.","first_N":5,"first_N_keywords":["image-classification","image-to-text","image-feature-extraction","Marathi","mit"],"keywords_longer_than_N":true},
	{"name":"Marathi_Handwritten","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Process-Venue/Marathi_Handwritten","creator_name":"ProcessVenue","creator_url":"https://huggingface.co/Process-Venue","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Marathi Handwritten OCR Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Marathi Handwritten Text Dataset is a collection of handwritten text images in Marathi (‡§¶‡•á‡§µ‡§®‡§æ‡§ó‡§∞‡•Ä ‡§≤‡§ø‡§™‡•Ä),\\naimed at supporting the development of Optical Character Recognition (OCR) systems, handwriting analysis tools,\\nand language research.The dataset was curated from native Marathi speakers to ensure a variety of handwriting styles and character variations.\\nThe dataset contains 2520 images with two‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Process-Venue/Marathi_Handwritten.","first_N":5,"first_N_keywords":["image-classification","image-to-text","image-feature-extraction","Marathi","mit"],"keywords_longer_than_N":true},
	{"name":"Language_Identification_v1","keyword":"marathi","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Process-Venue/Language_Identification_v1","creator_name":"ProcessVenue","creator_url":"https://huggingface.co/Process-Venue","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Language Identification Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA comprehensive dataset for Indian language identification and text classification. The dataset contains text samples across 10 major Indian languages, making it suitable for developing language identification systems and multilingual NLP applications.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages and Distribution\\n\\t\\n\\nLanguage Distribution:\\nUrdu         1000\\nHindi        1000\\nOdia         1000\\nTamil        1000\\nKannada      1000\\nBengali‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Process-Venue/Language_Identification_v1.","first_N":5,"first_N_keywords":["text-classification","text2text-generation","text-generation","Hindi","Urdu"],"keywords_longer_than_N":true},
	{"name":"Marathi-matrix","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sonyvakode/Marathi-matrix","creator_name":"sonyvakode","creator_url":"https://huggingface.co/sonyvakode","description":"sonyvakode/Marathi-matrix dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["table-question-answering","Marathi","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"marathi","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_mr","keyword":"marathi","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mr.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Marathi"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"marathi_voice_data","keyword":"marathi","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/milind0415/marathi_voice_data","creator_name":"Milind Ahirkar","creator_url":"https://huggingface.co/milind0415","description":"milind0415/marathi_voice_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Marathi","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"marathi","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true}
]
;
