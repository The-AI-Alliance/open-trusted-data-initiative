const data_for_language_asia_thai = 
[
	{"name":"my-distiset-38ebca4b","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kritsanan/my-distiset-38ebca4b","creator_name":"namoang","creator_url":"https://huggingface.co/kritsanan","description":"\n  \n    \n  \n\n\n\n\t\n\t\t\n\t\tDataset Card for my-distiset-38ebca4b\n\t\n\nThis dataset has been created with distilabel.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a pipeline.yaml which can be used to reproduce the pipeline that generated it in distilabel using the distilabel CLI:\ndistilabel pipeline run --config \"https://huggingface.co/datasets/kritsanan/my-distiset-38ebca4b/raw/main/pipeline.yaml\"\n\nor explore the configuration:\ndistilabel pipeline info --config‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kritsanan/my-distiset-38ebca4b.","first_N":5,"first_N_keywords":["text-classification","Thai","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"my-distiset-2248f47e","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kritsanan/my-distiset-2248f47e","creator_name":"namoang","creator_url":"https://huggingface.co/kritsanan","description":"kritsanan/my-distiset-2248f47e dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["feature-extraction","Thai","English","mit","parquet"],"keywords_longer_than_N":true},
	{"name":"miracl-vision","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nvidia/miracl-vision","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","description":"\n\t\n\t\t\n\t\tMIRACL-VISION\n\t\n\nMIRACL-VISION is a multilingual visual retrieval dataset for 18 different languages. It is an extension of MIRACL, a popular text-only multilingual retrieval dataset. The dataset contains user questions, images of Wikipedia articles and annotations, which article can answer a user question. There are 7898 questions and 338734 images. More details can be found in the paper MIRACL-VISION: A Large, multilingual, visual document retrieval benchmark.\nThis dataset is ready‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/miracl-vision.","first_N":5,"first_N_keywords":["document-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"OpenSpeech-Dataset-by-Wang","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VIZINTZOR/OpenSpeech-Dataset-by-Wang","creator_name":"VYNCX","creator_url":"https://huggingface.co/VIZINTZOR","description":"Dataset ‡∏´‡∏•‡∏±‡∏Å : https://www.wang.in.th/\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Dataset : \n\n‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 8,450 ‡πÑ‡∏ü‡∏•‡πå\n\n‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 10 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á\n\nSampling Rate 48,000 hz(‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡∏ö‡∏Å‡∏ß‡∏ô‡∏î‡πâ‡∏ß‡∏¢ AI)\n\n‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå Zip\n\nmetadata.csv\n\n\n00001.wav|‡∏Ç‡∏≠‡πÄ‡∏õ‡∏¥‡∏î‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏Ñ‡∏£‡∏±‡∏ö\n00002.wav|‡∏â‡∏±‡∏ô‡∏ß‡πà‡∏≤‡πÑ‡∏õ‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤\n00003.wav|‡πÉ‡∏ä‡πâ‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÑ‡∏´‡∏°‡∏Ñ‡πà‡∏∞\n....\n\n","first_N":5,"first_N_keywords":["text-to-speech","Thai","cc-by-sa-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"tdce-example-simple-dataset","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/theethawats98/tdce-example-simple-dataset","creator_name":"Theethawat Savastham","creator_url":"https://huggingface.co/theethawats98","description":"\n\t\n\t\t\n\t\tExample Dataset For Time-Driven Cost Estimation Learning Model\n\t\n\nThis dataset is the inspired-simulated data (the actual data is removed). This data is related to the Time-Driven Activity-Based Costing (TDABC) Principle. \n\n\t\n\t\t\n\t\tSimple Dataset\n\t\n\nIt include the data with low variation and low dimension.\nIt includes 4 files that bring from the manufacturing management system, which can be listed as.\n\nProcess Data (generated_process_data) it contains the manufacturing process data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/theethawats98/tdce-example-simple-dataset.","first_N":5,"first_N_keywords":["Thai","English","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"thai-license-plate-ocr","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/morsetechlab/thai-license-plate-ocr","creator_name":"Nuttapong Chimwai","creator_url":"https://huggingface.co/morsetechlab","description":"\n\t\n\t\t\n\t\tThai License Plate OCR Dataset üáπüá≠\n\t\n\nüá∫üá∏ English Version\n\nTask: Optical Character Recognition (OCR)\nLanguage: Thai üáπüá≠  \n\nOCR dataset ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PaddleOCR-rec ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞\n‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏£‡∏π‡πâ‡∏à‡∏≥‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏õ‡πâ‡∏≤‡∏¢‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå‡πÑ‡∏ó‡∏¢ ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î\n\n\n‚ö†Ô∏è ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏±‡∏ö PaddleOCR-rec (‡πÑ‡∏°‡πà‡∏°‡∏µ detection / classification)\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nthai-license-ocr-dataset/\n‚îú‚îÄ‚îÄ images/           # ‡∏£‡∏ß‡∏°‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n‚îú‚îÄ‚îÄ train.txt         # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô\n‚îú‚îÄ‚îÄ val.txt‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/morsetechlab/thai-license-plate-ocr.","first_N":5,"first_N_keywords":["image-to-text","manual","monolingual","Thai","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"thai-license-plate-ocr","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/morsetechlab/thai-license-plate-ocr","creator_name":"Nuttapong Chimwai","creator_url":"https://huggingface.co/morsetechlab","description":"\n\t\n\t\t\n\t\tThai License Plate OCR Dataset üáπüá≠\n\t\n\nüá∫üá∏ English Version\n\nTask: Optical Character Recognition (OCR)\nLanguage: Thai üáπüá≠  \n\nOCR dataset ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PaddleOCR-rec ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞\n‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏£‡∏π‡πâ‡∏à‡∏≥‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏õ‡πâ‡∏≤‡∏¢‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå‡πÑ‡∏ó‡∏¢ ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î\n\n\n‚ö†Ô∏è ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏±‡∏ö PaddleOCR-rec (‡πÑ‡∏°‡πà‡∏°‡∏µ detection / classification)\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nthai-license-ocr-dataset/\n‚îú‚îÄ‚îÄ images/           # ‡∏£‡∏ß‡∏°‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n‚îú‚îÄ‚îÄ train.txt         # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô\n‚îú‚îÄ‚îÄ val.txt‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/morsetechlab/thai-license-plate-ocr.","first_N":5,"first_N_keywords":["image-to-text","manual","monolingual","Thai","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"MIRACLRetrieval","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MIRACLRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MIRACLRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttp://miracl.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MIRACLRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","RSamoed/MIRACLRetrieval","Arabic"],"keywords_longer_than_N":true},
	{"name":"toxicity-multilingual-binary-classification-dataset","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/malexandersalazar/toxicity-multilingual-binary-classification-dataset","creator_name":"Alexander Salazar","creator_url":"https://huggingface.co/malexandersalazar","description":"This dataset is a comprehensive collection designed to aid in the development of robust and nuanced models for identifying toxic language across multiple languages, while critically distinguishing it from expressions related to mental health, specifically depression. It synthesizes content from three existing public datasets (ToxiGen, TextDetox, and Mental Health - Depression) with a newly generated synthetic dataset (ToxiLLaMA). The creation process involved careful collection, extensive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malexandersalazar/toxicity-multilingual-binary-classification-dataset.","first_N":5,"first_N_keywords":["English","German","French","Italian","Portuguese"],"keywords_longer_than_N":true},
	{"name":"TinyDS-20k","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","description":"\n\t\n\t\t\n\t\tTinyDS\n\t\n\n\n\n\nAlpaca-style dataset with around 20k samples scraped from Qwen3-8B using SyntheticAlpaca. Q&A pairs can be in 32 different languages, these are listed in the metadata.Topics are all around STEM, programming, and literature.  \nMIT @ 2025 Hamzah Asadullah\n\n\n","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2Jyq/common_voice_21_0","creator_name":"2Jyq","creator_url":"https://huggingface.co/2Jyq","description":"Due to storage limits some files had to be split into multiple parts. They can be merged like this: cat file.* > file.\n","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","multilingual","extended|common_voice","Abkhaz"],"keywords_longer_than_N":true},
	{"name":"MIRACLRetrieval","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RSamoed/MIRACLRetrieval","creator_name":"RS","creator_url":"https://huggingface.co/RSamoed","description":"\n  MIRACLRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttp://miracl.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RSamoed/MIRACLRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","Arabic","Bengali"],"keywords_longer_than_N":true},
	{"name":"code-switching-tokenizer-robustness","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","description":"\n\t\n\t\t\n\t\tCode-Switching Dataset for Tokenizer Robustness Analysis\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for tokenizer robustness testing in multilingual and code-switching contexts. It contains identical content expressed across 16 different language variants, including pure English and 15 English-X code-switching pairs, allowing researchers to isolate tokenization effects from semantic differences when evaluating language models.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\n\nTokenizer Comparison:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness.","first_N":5,"first_N_keywords":["text-generation","text-classification","multilingual","English","Russian"],"keywords_longer_than_N":true},
	{"name":"sib200_14classes","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200_14classes","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for SIB-200\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\nThe train/validation/test sets are available for all the 205 languages.\nThis is another version with 14 classes, more idea for few-shot evaluation, it has 5 examples for few-shot, and larger test set (1225)\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopic classification: categorize wikipedia sentences‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200_14classes.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"wai-handwrite-lotto","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Koreniac/wai-handwrite-lotto","creator_name":"koreniac","creator_url":"https://huggingface.co/Koreniac","description":"Koreniac/wai-handwrite-lotto dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Thai","apache-2.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"reeval","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stair-lab/reeval","creator_name":"STAIR","creator_url":"https://huggingface.co/stair-lab","description":"This repository implements the paper Reliable and Efficient Amortized Model-based Evaluation.\nWe transfer the original HELM data into long format, as in the long.pkl, which is then transferred into the response matrix, as in resmat.pkl.\nWe then obtain the embedding of each question from two language models: Llama-3.1-8B-Instruct and Mistral-7B-Instruct-v0.3, as in the embed_meta-llama_Llama-3.1-8B-Instruct.pkl  and embed_mistralai_Mistral-7B-Instruct-v0.3.pkl.\nThe files in folder‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stair-lab/reeval.","first_N":5,"first_N_keywords":["English","Thai","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"oasst1","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"wikipedia-monthly","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/omarkamali/wikipedia-monthly","creator_name":"Omar Kamali","creator_url":"https://huggingface.co/omarkamali","description":"\n\t\n\t\t\n\t\tüöÄ Wikipedia Monthly\n\t\n\nLast updated: July 16, 2025, 22:53 UTC\nThis repository provides monthly, multilingual dumps of Wikipedia, processed and prepared for easy use in NLP projects.\nNOTE: The first run is still in progress and languages are still being processed and uploaded.\n\n\n\t\n\t\t\n\t\tüìä Live Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nüåç Languages Available\n341\n\n\nüìÑ Total Articles\n64.5M\n\n\nüíæ Total Size\n205.54 GB\n\n\n\t\n\n\n\n\t\n\t\t\n\t\tWhy Use This Dataset?\n\t\n\n\nFreshness: We run our pipeline monthly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/omarkamali/wikipedia-monthly.","first_N":5,"first_N_keywords":["Abkhaz","Achinese","Adyghe","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"oasst2","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\n\t\n\t\t\n\t\tOpen Assistant Conversations Dataset Release 2 (OASST2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \nAll messages have a role property: this can either be \"assistant\" or \"prompter\". The roles in \nconversation threads from prompt to leaf node strictly alternate between \"prompter\" and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tDataset Card for \"xtreme\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"mgsm","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/juletxara/mgsm","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","description":"Multilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper [Language models are multilingual chain-of-thought reasoners](http://arxiv.org/abs/2210.03057).\n\nThe same 250 problems from [GSM8K](https://arxiv.org/abs/2110.14168) are each translated via human annotators in 10 languages. The 10 languages are:\n- Spanish\n- French\n- German\n- Russian\n- Chinese\n- Japanese\n- Thai\n- Swahili\n- Bengali\n- Telugu\n\nYou can find the input and targets for each of the ten languages (and English) as `.tsv` files.\nWe also include few-shot exemplars that are also manually translated from each language in `exemplars.py`.","first_N":5,"first_N_keywords":["found","found","expert-generated","multilingual","extended|gsm8k"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages ‚Üí dolly-machine-translated.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"WangchanX-Legal-ThaiCCL-RAG","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/airesearch/WangchanX-Legal-ThaiCCL-RAG","creator_name":"VISTEC-depa AI Research Institute of Thailand","creator_url":"https://huggingface.co/airesearch","description":"\n\t\n\t\t\n\t\tüèõÔ∏è WangchanX-Legal-ThaiCCL-RAG\n\t\n\n[Technical Report]\nThe WangchanX-Legal-ThaiCCL-RAG dataset supports the development Retrieval-Augmented Generation (RAG) for Thai Legal question answering. This dataset is allows developers to finetune both retrieval model - to better retrieve relevant law section, and Large Language Model (LLM) - for instruction tuning. Our dataset supports Corporate and Commercial Law (thus ThaiCCL name). See legislation section for more details on supported‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/airesearch/WangchanX-Legal-ThaiCCL-RAG.","first_N":5,"first_N_keywords":["text-generation","sentence-similarity","Thai","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tWMT24++\n\t\n\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\nthe publication\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\nIf you are interested in the images of the source URLs for each document, please see here.\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach language pair is stored in its own jsonl file.\nEach row is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"vox-communis-parallel-g2p","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p","creator_name":"Fl√°vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","description":"\n\t\n\t\t\n\t\tVoxCommunis Parallel G2P dataset\n\t\n\nThis dataset was derived from the VoxCommunis Corpus to provide pairs of utterances along with their\ncorresponding phonemes, side by side, as to ease the training of grapheme-to-phoneme (G2P) models.\nThe original VoxCommunis Corpus features force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus.\nThe lexicons were developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p.","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"alt","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mutiyama/alt","creator_name":"Masao Utiyama","creator_url":"https://huggingface.co/mutiyama","description":"\n\t\n\t\t\n\t\tDataset Card for Asian Language Treebank (ALT)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ALT project aims to advance the state-of-the-art Asian natural language processing (NLP) techniques through the open collaboration for developing and using ALT. It was first conducted by NICT and UCSY as described in Ye Kyaw Thu, Win Pa Pa, Masao Utiyama, Andrew Finch and Eiichiro Sumita (2016). Then, it was developed under ASEAN IVO as described in this Web page. \nThe process of building ALT began with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mutiyama/alt.","first_N":5,"first_N_keywords":["translation","token-classification","parsing","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"thai","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for Opus Ubuntu\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\nE.g.\ndataset = load_dataset(\"opus_ubuntu\", lang1=\"it\", lang2=\"pl\")\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"tydiqa","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/tydiqa","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for \"tydiqa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\nin the world. It contains language phenomena that would not be found in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/tydiqa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"wisesight_sentiment","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/wisesight_sentiment","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for wisesight_sentiment\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWisesight Sentiment Corpus: Social media messages in Thai language with sentiment label (positive, neutral, negative, question)\n\nReleased to public domain under Creative Commons Zero v1.0 Universal license.\nLabels: {\"pos\": 0, \"neu\": 1, \"neg\": 2, \"q\": 3}\nSize: 26,737 messages\nLanguage: Central Thai\nStyle: Informal and conversational. With some news headlines and advertisement.\nTime period: Around 2016 to early 2019. With‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/wisesight_sentiment.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"wongnai_reviews","keyword":"thai","license":"GNU Lesser General Public License v3.0","license_url":"https://choosealicense.com/licenses/lgpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Wongnai/wongnai_reviews","creator_name":"Wongnai","creator_url":"https://huggingface.co/Wongnai","description":"\n\t\n\t\t\n\t\tDataset Card for Wongnai_Reviews\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Wongnai Review dataset contains restaurant reviews and ratings, almost entirely in Thai language.\nThe reviews are in 5 classes ranging from 1 to 5 stars.\nThis dataset was featured in a Kaggle challenge https://www.kaggle.com/c/wongnai-challenge-review-rating-prediction/overview\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThai\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nreview_body - text of review\nstar_rating - an integer star rating‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Wongnai/wongnai_reviews.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"xcopa","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cambridgeltl/xcopa","creator_name":"Language Technology Lab @University of Cambridge","creator_url":"https://huggingface.co/cambridgeltl","description":"\n\t\n\t\t\n\t\tDataset Card for \"xcopa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n  XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning\nThe Cross-lingual Choice of Plausible Alternatives dataset is a benchmark to evaluate the ability of machine learning models to transfer commonsense reasoning across\nlanguages. The dataset is the translation and reannotation of the English COPA (Roemmele et al. 2011) and covers 11 languages from 11 families and several areas around\nthe globe. The dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cambridgeltl/xcopa.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xquad","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xquad","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tDataset Card for \"xquad\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nXQuAD (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering\nperformance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set\nof SQuAD v1.1 (Rajpurkar et al., 2016) together with their professional translations into ten languages: Spanish, German,\nGreek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, and Hindi.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/xquad.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xquad_r","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/xquad_r","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nXQuAD-R is a retrieval version of the XQuAD dataset (a cross-lingual extractive\nQA dataset). Like XQuAD, XQUAD-R is an 11-way parallel dataset,  where each\nquestion appears in 11 different languages and has 11 parallel correct answers\nacross the languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset can be found with the following languages:\n\nArabic: xquad-r/ar.json‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/xquad_r.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"mr-tydi-corpus","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/mr-tydi-corpus","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\nThis dataset stores documents of Mr. TyDi. To access the queries and judgments, please refer to castorini/mr-tydi.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe only configuration here is the language. As all three folds (train, dev and test) share the same‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi-corpus.","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"mr-tydi","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/mr-tydi","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\nThis dataset stores the queries, judgements, and example training data of Mr. TyDi. To access the corpus, please refer to castorini/mr-tydi-corpus.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe only configuration here is the language, \nFor each language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi.","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"mqa","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\n\t\n\t\t\n\t\tDataset Card for WIT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\nFrom the official blog post:\n\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\nThe WIT dataset offers extremely valuable data about the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_scenario","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_scenario","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveScenarioClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveScenarioClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_scenario.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_intent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveIntentClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_intent.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"answerable_tydiqa","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/answerable_tydiqa","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\n\t\n\t\t\n\t\tDataset Card for \"answerable-tydiqa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages. \nAnswerable TyDi QA is an extension of the GoldP subtask of the original TyDi QA dataset to also include unanswertable questions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains a train and a validation set, with 116067 and 13325 examples, respectively. Access them with\nfrom datasets import load_dataset\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/answerable_tydiqa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"tydiqa_copenlu","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/tydiqa_copenlu","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\n\t\n\t\t\n\t\tDataset Card for \"tydiqa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\nin the world. It contains language phenomena that would not be found in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/tydiqa_copenlu.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"miracl-corpus","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/miracl-corpus","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\n\t\n\t\t\n\t\tDataset Card for MIRACL Corpus\n\t\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\nThis dataset contains the collection data of the 16 \"known languages\". The remaining 2 \"surprise languages\" will not be released until later.\nThe corpus for each language is prepared from a Wikipedia‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"miracl-th-corpus-22-12","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-th-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\n\t\n\t\t\n\t\tMIRACL (th) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-th-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-th-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-th-corpus-22-12.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Thai"],"keywords_longer_than_N":true},
	{"name":"miracl-th-queries-22-12","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-th-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\n\t\n\t\t\n\t\tMIRACL (th) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-th-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-th-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-th-queries-22-12.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Thai"],"keywords_longer_than_N":true},
	{"name":"iapp_wiki_qa_squad_oa","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wannaphong/iapp_wiki_qa_squad_oa","creator_name":"Wannaphong Phatthiyaphaibun","creator_url":"https://huggingface.co/wannaphong","description":"This dataset is fork from https://huggingface.co/datasets/iapp_wiki_qa_squad that made for Open Assistant.\nPull request: Add iapp_wiki_qa_squad to datasets #1903 \n","first_N":5,"first_N_keywords":["Thai","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"tlcv2.0_oa","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/tlcv2.0_oa","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"tlcv2.0_oa\"\n\t\n\nThai Literature Corpora (TLC): Corpora of machine-ingestible Thai classical literature texts by Jitkapat Sawatphol (Faculty of Arts, Chulalongkorn University).\nThis project use Thai Literature Corpora (TLC) v2.0. All text are from old Thai book that out of copyright (or public domain).\nThis dataset was build for Open Assistant.\n\n\t\n\t\t\n\t\n\t\n\t\tColumns\n\t\n\nThe dataset was following columns:\n\nTEXT (string)\nSOURCE (string)\nMETADATA (JSON string, optional)\n\n","first_N":5,"first_N_keywords":["text-generation","Thai","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof Wr√≥bel","creator_url":"https://huggingface.co/djstrong","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"thaigov-v2-corpus-22032023","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thaigov-v2-corpus-22032023","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"thaigov-v2-corpus-22032023\"\n\t\n\nThis corpus made from Thaigov v2 corpus in 22 Mar 2023. https://github.com/PyThaiNLP/thaigov-v2-corpus/releases/tag/22032023\nCorups: https://github.com/PyThaiNLP/thaigov-v2-corpus\n\n\t\n\t\t\n\t\tEnglish\n\t\n\n\nData from Thai government website. https://www.thaigov.go.th\nThis part of PyThaiNLP Project.\nCompiled by Mr.Wannaphong Phatthiyaphaibun\nLicense Dataset is public domain.\n\n\n\t\n\t\t\n\t\tData format\n\t\n\n\n1 file, 1 news, which is extracted from 1 url.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/thaigov-v2-corpus-22032023.","first_N":5,"first_N_keywords":["Thai","cc0-1.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"thailaw","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thailaw","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"thailaw\"\n\t\n\n\n\t\n\t\t\n\t\tEnglish\n\t\n\nThai Law Dataset (Act of Parliament)\n\nData source from Office of the Council of State, Thailand. https://www.krisdika.go.th/\nThis part of PyThaiNLP Project.\nLicense Dataset is public domain.\n\nDownload https://github.com/PyThaiNLP/thai-law/releases\nThis hub based on Thailaw v0.2.\n\n\t\n\t\t\n\t\n\t\n\t\tThai\n\t\n\n‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÑ‡∏ó‡∏¢ (‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏ö‡∏±‡∏ç‡∏ç‡∏±‡∏ï‡∏¥)\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ñ‡∏ì‡∏∞‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏§‡∏©‡∏é‡∏µ‡∏Å‡∏≤ https://www.krisdika.go.th/‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/thailaw.","first_N":5,"first_N_keywords":["text-generation","Thai","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"klongklon","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/klongklon","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tklongklon Dataset Summary\n\t\n\nThis dataset was created from collecting poems in various literature.\nIt contains more than 50000 poems.Which consists of poems that are ' ‡∏Å‡∏•‡∏≠‡∏ô8 ' and ' ‡πÇ‡∏Ñ‡∏•‡∏á‡∏™‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û '  \nPrepared to create a model for composing Thai poems.\n\n\t\n\t\t\n\t\tHow to use\n\t\n\nIn Huggingface you just do this\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"pythainlp/klongklon\")\n\nto use the dataset.\nMore Information needed\n","first_N":5,"first_N_keywords":["text-generation","Thai","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"hh-rlhf-th","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Thaweewat/hh-rlhf-th","creator_name":"Thaweewat","creator_url":"https://huggingface.co/Thaweewat","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\nThis is a üáπüá≠ Thai-translated dataset based on Anthropic/hh-rlhf using Google Cloud Translation. \nThis repository provides access to:\n\n161K Train dataset Anthropic/hh-rlhf (Thai-translated)\n(Soon) 8K Test dataset Anthropic/hh-rlhf (Thai-translated)\n\nDisclaimer: The data contain content that may be offensive or upsetting. Topics include, but are not limited to, discriminatory language and discussions of abuse, violence, self-harm, exploitation, and other potentially‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Thaweewat/hh-rlhf-th.","first_N":5,"first_N_keywords":["Thai","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"mC4-th-clean","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Wiritpol/mC4-th-clean","creator_name":"Sangchan","creator_url":"https://huggingface.co/Wiritpol","description":"mC4 - Thai (Clean) - Size(ss) 187M Tokens (6.67% of mC4-th-clean, ~2.8B Tokens)\n\n\n\t\n\t\t\n\t\n\t\n\t\tlicense: apache-2.0\ndataset_info:\n  features:\n  - name: text\n    dtype: string\n  - name: timestamp\n    dtype: string\n  - name: url\n    dtype: string\n  splits:\n  - name: train\n    num_bytes: 1881070925\n    num_examples: 494539\n  download_size: 739477768\n  dataset_size: 1881070925\n\t\n\n","first_N":5,"first_N_keywords":["Thai","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"copa_th","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Patt/copa_th","creator_name":"Patteera","creator_url":"https://huggingface.co/Patt","description":"\n\t\n\t\t\n\t\tDataset Card for copa_th\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is Thai translated version of copa using google translate with Multilingual Universal Sentence Encoder to calculate score for Thai translation. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEN\nTH\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{copa_th,\n  author = {Triamamornwooth Patteera},\n  title = {copa_th},\n  year = {2023},\n  publisher = {Hugging Face},\n  note = {v1.0},\n  url = {https://huggingface.co/datasets/Patt/copa_th}\n}\n\n","first_N":5,"first_N_keywords":["Thai","English","cc-by-sa-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"MultiRC_TH","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Patt/MultiRC_TH","creator_name":"Patteera","creator_url":"https://huggingface.co/Patt","description":"\n\t\n\t\t\n\t\tDataset Card for MultiRC_TH\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is Thai translated version of multirc using google translate with Multilingual Universal Sentence Encoder to calculate score for Thai translation.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{MultiRC_TH,\n  author = {Triamamornwooth Patteera},\n  title = {MultiRC_TH},\n  year = {2023},\n  publisher = {Hugging Face},\n  note = {v1.0},\n  url = {https://huggingface.co/datasets/Patt/MultiRC_TH}\n}\n\n","first_N":5,"first_N_keywords":["text-classification","English","Thai","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"RTE_TH","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Patt/RTE_TH","creator_name":"Patteera","creator_url":"https://huggingface.co/Patt","description":"\n\t\n\t\t\n\t\tDataset Card for RTE_TH\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is Thai translated version of RTE using google translate with Multilingual Universal Sentence Encoder to calculate score for Thai translation.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{RTE_TH,\n  author = {Triamamornwooth Patteera},\n  title = {RTE_TH},\n  year = {2023},\n  publisher = {Hugging Face},\n  note = {v1.0},\n  url = {https://huggingface.co/datasets/Patt/RTE_TH}\n}\n\n","first_N":5,"first_N_keywords":["text-classification","English","Thai","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ReCoRD_TH","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Patt/ReCoRD_TH","creator_name":"Patteera","creator_url":"https://huggingface.co/Patt","description":"\n\t\n\t\t\n\t\tDataset Card for ReCoRD_TH\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is Thai translated version of ReCoRD using google translate with Multilingual Universal Sentence Encoder to calculate score for Thai translation.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{ReCoRD_TH,\n  author = {Triamamornwooth Patteera},\n  title = {ReCoRD_TH},\n  year = {2023},\n  publisher = {Hugging Face},\n  note = {v1.0},\n  url = {https://huggingface.co/datasets/Patt/ReCoRD_TH}\n}\n\n","first_N":5,"first_N_keywords":["text-classification","English","Thai","cc-by-sa-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"PongSawaML","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Copninixh/PongSawaML","creator_name":"Copninixh","creator_url":"https://huggingface.co/Copninixh","description":"\n\t\n\t\t\n\t\tPongSawaML\n\t\n\nPongsawaM(L) is a Thai annal Ayutthaya, Thonburi, and Rattakosin (Rama I). This annal writed by Dan Beach Bradley an American Protestant missionary\n","first_N":5,"first_N_keywords":["summarization","Thai","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"RTE_TH_cleanned","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Patt/RTE_TH_cleanned","creator_name":"Patteera","creator_url":"https://huggingface.co/Patt","description":"\n\t\n\t\t\n\t\tDataset Card for RTE_TH_cleanned\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is Thai translated version of RTE using google translate with Multilingual Universal Sentence Encoder to calculate score for Thai translation.\nSome line which score_hypothesis <= 0.5 or score_premise <= 0.7 had been droped.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{RTE_TH_cleanned,\n  author = {Triamamornwooth Patteera},\n  title = {RTE_TH_cleanned},\n  year = {2023},\n  publisher = {Hugging Face},\n  note = {v1.0},\n  url =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Patt/RTE_TH_cleanned.","first_N":5,"first_N_keywords":["text-classification","English","Thai","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"HellaSwag_TH_cleanned","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Patt/HellaSwag_TH_cleanned","creator_name":"Patteera","creator_url":"https://huggingface.co/Patt","description":"\n\t\n\t\t\n\t\tDataset Card for HellaSwag_TH_cleanned\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is Thai translated version of hellaswag using google translate with Multilingual Universal Sentence Encoder to calculate score for Thai translation. \nThe score was penalized by the length of original text compare to translated text. The row that any score < 0.5 was dropped.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEN\nTH\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{HellaSwag_TH_cleanned,\n  author = {Triamamornwooth Patteera},\n  title =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Patt/HellaSwag_TH_cleanned.","first_N":5,"first_N_keywords":["Thai","English","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MultiRC_TH_cleanned","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Patt/MultiRC_TH_cleanned","creator_name":"Patteera","creator_url":"https://huggingface.co/Patt","description":"\n\t\n\t\t\n\t\tDataset Card for MultiRC_TH_cleanned\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is Thai translated version of multirc using google translate with Multilingual Universal Sentence Encoder to calculate score for Thai translation.\nThe score was penalized by the length of original text compare to translated text. The row that any score < 0.66 was dropped.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\n@misc{MultiRC_TH_cleanned,\n  author = {Triamamornwooth Patteera},\n  title = {MultiRC_TH_cleanned},\n  year =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Patt/MultiRC_TH_cleanned.","first_N":5,"first_N_keywords":["text-classification","English","Thai","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ReCoRD_TH_cleanned","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Patt/ReCoRD_TH_cleanned","creator_name":"Patteera","creator_url":"https://huggingface.co/Patt","description":"\n\t\n\t\t\n\t\tDataset Card for ReCoRD_TH_cleanned\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is Thai translated version of ReCoRD using google translate with Multilingual Universal Sentence Encoder to calculate score for Thai translation.\nDrop every row that score_answers < 0.8 and every row that score < 0.5 after penalty.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{ReCoRD_TH_cleanned,\n  author = {Triamamornwooth Patteera},\n  title = {ReCoRD_TH_cleanned},\n  year = {2023},\n  publisher = {Hugging Face},\n  note =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Patt/ReCoRD_TH_cleanned.","first_N":5,"first_N_keywords":["text-classification","English","Thai","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\n\n\t\n\t\t\n\nToxic\nNeutral\nTotal\n\n\n\t\t\nmultilingual-train-deduplicated.csv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Spanish","Panjabi"],"keywords_longer_than_N":true},
	{"name":"edited_common_voice","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lunarlist/edited_common_voice","creator_name":"taetiya taechamatavorn","creator_url":"https://huggingface.co/lunarlist","description":"\n\t\n\t\t\n\t\tDataset Card for \"edited_common_voice\"\n\t\n\nMore Information needed\nThis dataset is a Thai TTS dataset that use the voice from Common Voice dataset and modify the voice to not to sound like the original.\nMedium: Text-To-Speech ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏î‡πâ‡∏ß‡∏¢ Tacotron2\n","first_N":5,"first_N_keywords":["text-to-speech","Thai","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"malicious-website-features-2.4M","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"Important Notice:\n\nA subset of the URL dataset is from Kaggle, and the Kaggle datasets contained 10%-15% mislabelled data. See this dicussion I opened for some false positives. I have contacted Kaggle regarding their erroneous \"Usability\" score calculation for these unreliable datasets.\nThe feature extraction methods shown here are not robust at all in 2023, and there're even silly mistakes in 3 functions: not_indexed_by_google, domain_registration_length, and age_of_domain.\n\n\n\nThe features‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M.","first_N":5,"first_N_keywords":["text-classification","feature-extraction","tabular-classification","Norwegian","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for SIB-200\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\nThe train/validation/test sets are available for all the 205 languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 205 languages available :\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"belebele","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\n\t\n\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that discriminate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele.","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","text-classification","multiple-choice","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\n\t\n\t\t\n\t\tDataset Card for WikiAnc\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \nThe code for generating the dataset can be found here.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nwikificiation: The dataset can be used to train a model for Wikification.\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in all 320‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"goethe-website","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/goethe-website","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"goethe-website\"\n\t\n\nThis dataset collect the article from https://www.goethe.de/ins/th. (CC BY-SA only)\n","first_N":5,"first_N_keywords":["text-generation","Thai","cc-by-sa-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"thaisum","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thaisum","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for ThaiSum\n\t\n\nThis dataset was forked from thaisum to HF hub.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThaiSum is a large-scale corpus for Thai text summarization obtained from several online news websites namely Thairath, ThaiPBS, Prachathai, and The Standard. This dataset consists of over 350,000 article and summary pairs written by journalists.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nsummarization, language modeling\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThai\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/thaisum.","first_N":5,"first_N_keywords":["summarization","text-generation","fill-mask","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\n","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"MultiJail","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail","creator_name":"Language Technology Lab at Alibaba DAMO Academy","creator_url":"https://huggingface.co/DAMO-NLP-SG","description":"\n\t\n\t\t\n\t\tMultilingual Jailbreak Challenges in Large Language Models\n\t\n\nThis repo contains the data for our paper \"Multilingual Jailbreak Challenges in Large Language Models\".\n[Github repo]\n\n\t\n\t\t\n\t\tAnnotation Statistics\n\t\n\nWe collected a total of 315 English unsafe prompts and annotated them into nine non-English languages. The languages were categorized based on resource availability, as shown below:\nHigh-resource languages: Chinese (zh), Italian (it), Vietnamese (vi)\nMedium-resource languages:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail.","first_N":5,"first_N_keywords":["English","Chinese","Italian","Vietnamese","Arabic"],"keywords_longer_than_N":true},
	{"name":"thai_usembassy","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thai_usembassy","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"thai_usembassy\"\n\t\n\nMore Information needed\nThis dataset collect all Thai & English news from U.S. Embassy Bangkok.\n","first_N":5,"first_N_keywords":["text-generation","translation","Thai","English","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"thai_food_v1.0","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thai_food_v1.0","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tThai Food Recipe dataset v1.0\n\t\n\nThe Thai Food Recipe dataset is a collection of Thai recipes from old Thai books and social networks.\nList Book\n\n‡∏ï‡∏≥‡∏£‡∏±‡∏ö‡∏≠‡∏≤‡∏´‡∏≤‡∏£ - ‡πÄ‡∏ï‡∏∑‡πâ‡∏≠‡∏á ‡∏™‡∏ô‡∏¥‡∏ó‡∏ß‡∏á‡∏®‡πå, ‡∏°.‡∏£.‡∏ß., 2426-2510 - Work in process (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö) in v2.0\n‡∏ú‡∏±‡∏î‡∏Å‡∏∞‡πÄ‡∏û‡∏£‡∏≤ - ‚Äú‡∏ó‡∏µ‡∏°‡∏Ñ‡∏£‡∏±‡∏ß‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≠‡∏°‚Äù ‡∏à.‡∏•‡∏≥‡∏õ‡∏≤‡∏á\n‡∏™‡∏π‡∏ï‡∏£ \"‡πÄ‡∏Å‡∏µ‡πä‡∏¢‡∏ß‡∏Å‡∏∏‡πâ‡∏á\"\n\nLicense: cc0-1.0\n","first_N":5,"first_N_keywords":["text-generation","Thai","cc0-1.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"GSM8KInstruct_Parallel","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mathoctopus/GSM8KInstruct_Parallel","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","description":"Mathoctopus/GSM8KInstruct_Parallel dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","Chinese","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"MSVAMP","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mathoctopus/MSVAMP","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","description":"Mathoctopus/MSVAMP dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Bengali","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"han-instruct-dataset-v1.0","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/han-instruct-dataset-v1.0","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"han-instruct-dataset-v1.0\"\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nü™ø Han (‡∏´‡πà‡∏≤‡∏ô or goose) Instruct Dataset is a Thai instruction dataset by PyThaiNLP. It collect the instruction following in Thai from many source.\nMany question are collect from Reference desk at Thai wikipedia.\nData sources:\n\nReference desk at Thai wikipedia.\nLaw from justicechannel.org\npythainlp/final_training_set_v1_enth: Human checked and edited.\nSelf-instruct from WangChanGLM\nWannaphong.com\nHuman‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/han-instruct-dataset-v1.0.","first_N":5,"first_N_keywords":["text-generation","Thai","cc-by-sa-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"oasst2_top1_chat_format","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","description":"\n\t\n\t\t\n\t\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\n\t\n\nExport of oasst2 only top 1 threads in huggingface chat format\n\n\t\n\t\t\n\t\tScript\n\t\n\nThe convert script can be find here\n","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"openassistant-deepseek-coder","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\n\t\n\nThis dataset allows for fine-tuning chat models using:\nB_INST = '\\n### Instruction:\\n'\nE_INST = '\\n### Response:\\n'\nBOS = '<ÔΩúbegin‚ñÅof‚ñÅsentenceÔΩú>'\nEOS = '\\n<|EOT|>\\n'\n\nSample Preparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Fran√ßais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"thai-onet-m6-exam","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openthaigpt/thai-onet-m6-exam","creator_name":"OpenThaiGPT","creator_url":"https://huggingface.co/openthaigpt","description":"\n\t\n\t\t\n\t\n\t\n\t\tThai O-Net Exams Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe Thai O-Net Exams dataset is a comprehensive collection of exam questions and answers from the Thai Ordinary National Educational Test (O-Net). This dataset covers various subjects for Grade 12 (M6) level, designed to assist in educational research and development of question-answering systems.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Source\n\t\n\nThai National Institute of Educational Testing Service (NIETS)\n\n\t\n\t\t\n\t\n\t\n\t\tMaintainer\n\t\n\nDr. Kobkrit‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openthaigpt/thai-onet-m6-exam.","first_N":5,"first_N_keywords":["question-answering","Thai","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"thai-onet-m6-exam","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openthaigpt/thai-onet-m6-exam","creator_name":"OpenThaiGPT","creator_url":"https://huggingface.co/openthaigpt","description":"\n\t\n\t\t\n\t\n\t\n\t\tThai O-Net Exams Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe Thai O-Net Exams dataset is a comprehensive collection of exam questions and answers from the Thai Ordinary National Educational Test (O-Net). This dataset covers various subjects for Grade 12 (M6) level, designed to assist in educational research and development of question-answering systems.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Source\n\t\n\nThai National Institute of Educational Testing Service (NIETS)\n\n\t\n\t\t\n\t\n\t\n\t\tMaintainer\n\t\n\nDr. Kobkrit‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openthaigpt/thai-onet-m6-exam.","first_N":5,"first_N_keywords":["question-answering","Thai","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"thai-investment-consultant-licensing-exams","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openthaigpt/thai-investment-consultant-licensing-exams","creator_name":"OpenThaiGPT","creator_url":"https://huggingface.co/openthaigpt","description":"\n\t\n\t\t\n\t\tThai Public Investment Consultant (IC) Exams Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset comprises a collection of exam questions and answers from the Thai Public Investment Consultant (IC) Examinations. It's a valuable resource for developing and evaluating question-answering systems in the finance sector.\n\n\t\n\t\t\n\t\tDataset Source\n\t\n\nThe Stock Exchange of Thailand (SET)\n\n\t\n\t\t\n\t\tMaintainer\n\t\n\nDr. Kobkrit Viriyayudhakorn\nEmail: kobkrit@iapp.co.th\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openthaigpt/thai-investment-consultant-licensing-exams.","first_N":5,"first_N_keywords":["question-answering","Thai","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","Metlat√≥noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"seamless-align","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\n\t\n\t\t\n\t\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\n\n\t\n\t\t\n\t\tHow to use the data\n\t\n\nThere are two ways to access the data:\n\nVia the Hugging Face Python datasets library\n\nScripts coming soon‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align.","first_N":5,"first_N_keywords":["translation","audio-to-audio","Maltese","English","Welsh"],"keywords_longer_than_N":true},
	{"name":"WEATHub","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iamshnoo/WEATHub","creator_name":"Anjishnu Mukherjee","creator_url":"https://huggingface.co/iamshnoo","description":"\n\n\n\n\n\t\n\t\t\n\t\tDataset Card for \"WEATHub\"\n\t\n\nThis dataset corresponds to the data described in the paper \"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\"\naccepted to EMNLP 2023.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)\nto measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers. And we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub.","first_N":5,"first_N_keywords":["Arabic","Bengali","Central Kurdish","Danish","German"],"keywords_longer_than_N":true},
	{"name":"BMA_Fondue_Images","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AeraX-Valley/BMA_Fondue_Images","creator_name":"AeraX Valley","creator_url":"https://huggingface.co/AeraX-Valley","description":"\n\t\n\t\t\n\t\tBangkok Metropolitan Urban Issue Image (Traffy Fondue Issue Buckets)\n\t\n\nBMA_Fondue_Image Dataset is an original raw dataset without frame labels.\n","first_N":5,"first_N_keywords":["Thai","English","apache-2.0","Image","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"wisesight_sentiment_prompt","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/wisesight_sentiment_prompt","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"wisesight_sentiment_prompt is the instruct fellow dataset for sentiment Thai text by prompt. It can use fine-tuning model.\n\ninputs: Prompt\ntargets: Text targets that AI should answer.\n\nTemplate\nInputs: ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏ß‡∏Å/‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á/‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏ö:\\n{text}\n\ntargets: ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°{category}\n\ncategory\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: question\n‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏ß‡∏Å: positive\n‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á: neutral\n‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏ö: negative\n\nNotebook that used create this dataset:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/wisesight_sentiment_prompt.","first_N":5,"first_N_keywords":["text-generation","Thai","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"openassistant-falcon","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant Falcon\n\t\n\nThis dataset allows for fine-tuning chat models using '\\Human:' AND '\\nAssistant:' to wrap user messages.\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\nSample \nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"scb_mt_2020_en2th_prompt","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/scb_mt_2020_en2th_prompt","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"scb_mt_2020_en2th_prompt\"\n\t\n\nThis dataset made from scb_mt_enth_2020 that removed nus_sms and paracrawl from source.\nSource code for create dataset: https://github.com/PyThaiNLP/support-aya-datasets/blob/main/translation/scb_mt.ipynb\n\n\t\n\t\t\n\t\tTemplate\n\t\n\nInputs: ‡πÅ‡∏õ‡∏•‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢:\\n{en}\n\nTargets: Thai sentence\n\n","first_N":5,"first_N_keywords":["text-classification","Thai","cc-by-sa-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"scb_mt_2020_th2en_prompt","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/scb_mt_2020_th2en_prompt","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"scb_mt_2020_th2en_prompt\"\n\t\n\nThis dataset made from scb_mt_enth_2020 that removed nus_sms and paracrawl from source.\nSource code for create dataset: https://github.com/PyThaiNLP/support-aya-datasets/blob/main/translation/scb_mt.ipynb\n\n\t\n\t\t\n\t\tTemplate\n\t\n\nInputs: ‡πÅ‡∏õ‡∏•‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©:\\n{th}\n\nTargets: English sentence\n\n","first_N":5,"first_N_keywords":["text-generation","Thai","cc-by-sa-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"thai_usembassy_en2th_prompt","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thai_usembassy_en2th_prompt","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"thai_usembassy_en2th_prompt\"\n\t\n\nThis dataset made from pythainlp/thai_usembassy.\nSource code for create dataset: https://github.com/PyThaiNLP/support-aya-datasets/blob/main/translation/thai_usembassy.ipynb\n\n\t\n\t\t\n\t\tTemplate\n\t\n\nInputs: ‡πÅ‡∏õ‡∏•‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢:\\n{en}\n\nTargets: Thai sentence\n\n","first_N":5,"first_N_keywords":["text-generation","Thai","cc0-1.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"thai_usembassy_th2en_prompt","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thai_usembassy_th2en_prompt","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"thai_usembassy_th2en_prompt\"\n\t\n\nThis dataset made from pythainlp/thai_usembassy.\nSource code for create dataset: https://github.com/PyThaiNLP/support-aya-datasets/blob/main/translation/thai_usembassy.ipynb\n\n\t\n\t\t\n\t\tTemplate\n\t\n\nInputs: ‡πÅ‡∏õ‡∏•‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©:\\n{th}\n\nTargets: English sentence\n\n","first_N":5,"first_N_keywords":["text-generation","Thai","cc0-1.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"oasst2_thai_top1_chat_format","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/oasst2_thai_top1_chat_format","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tOpen Assistant 2 Top-1 Thai\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA top-1 Thai dataset taken from the top scoring https://huggingface.co/datasets/OpenAssistant/oasst2 conversations. Saved in HF Chat format.\nLicense: Apache 2.0\nScript: https://github.com/wannaphong/deep_4_all/tree/main/datasets/oasst\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nWe structure the dataset using the format commonly used as input into Hugging Face Chat Templates:\n[\n   {'content':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/oasst2_thai_top1_chat_format.","first_N":5,"first_N_keywords":["question-answering","Thai","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"ThaiIDCardSynt","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Float16-cloud/ThaiIDCardSynt","creator_name":"Float16.cloud","creator_url":"https://huggingface.co/Float16-cloud","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: Matichon Maneegard\nShared by [optional]: Matichon Maneegard\nLanguage(s) (NLP): image-to-text\nLicense: apache-2.0\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\nThe dataset was entirely synthetic. It does not contain real information or pertain to any specific person.\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\nUsing for tranning OCR or Multimodal.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nThis dataset contains 98 x 6 = 588 samples, and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Float16-cloud/ThaiIDCardSynt.","first_N":5,"first_N_keywords":["image-to-text","Thai","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_regions","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Regions\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\nKey Features:\n\nTextual Data: The dataset contains 500,000 text samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"openassistant-guanaco-EOS","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Guanaco Style\n\t\n\nThis dataset allows for fine-tuning chat models using \"### Human:\" AND \"### Assistant\" as the beginning and end of sequence tokens.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then slightly adjusted to:\n\n\nif a row of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"openassistant-llama-style","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Llama 2 Style\n\t\n\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then filtered to:\n\n\nreplace instances of '### Human:' with '[INST]'\nreplace‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"pcshsbr-music-request","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Patsagorn/pcshsbr-music-request","creator_name":"Yuenyong","creator_url":"https://huggingface.co/Patsagorn","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nRequest history from PCSHSBR Music Queue include timestamp, song's name, and artist.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\nHuman input from PCSHSBR Music Queue.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nIt's CSV file originally 4 columns; timestamp, song's name, artist, and note (for disambiguation as we use YouTube to play music). In this dataset\nthe note column is removed bacause we also use this field to announce who's this song for. By‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Patsagorn/pcshsbr-music-request.","first_N":5,"first_N_keywords":["Thai","English","cc-by-4.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"prd_news_30112023","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/prd_news_30112023","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tPRD News 30112023\n\t\n\nThai News from  The Government Public Relations Department, Office of the Prime Minister. We are collect Thai News from Open Data.\nSources:\n\n‡∏Ç‡πà‡∏≤‡∏ß‡∏Ñ‡∏•‡∏±‡∏™‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ñ‡∏•‡∏≠‡∏á‡πÄ‡∏ï‡∏¢ https://gdcatalog.go.th/dataset/gdpublish-klongtoei\n‡∏Ç‡πà‡∏≤‡∏ß‡∏´‡∏°‡∏≠‡∏û‡∏£‡πâ‡∏≠‡∏° https://gdcatalog.go.th/dataset/gdpublish-morprom\n‡∏Ç‡πà‡∏≤‡∏ßPM 2.5 https://gdcatalog.go.th/dataset/gdpublish-pm-2-5\n‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£ https://gdcatalog.go.th/dataset/gdpublish-kaset0564\n‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î 19 (Covid -19)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/prd_news_30112023.","first_N":5,"first_N_keywords":["text-generation","Thai","cc0-1.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"thai-financial-dataset","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thai-financial-dataset","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"This dataset is the cleaned version of the airesearch/CMDF_VISTEC datasets for pretrining model.\nIt is financial domain for Thai language.\nlicense: cc-by-4.0\n","first_N":5,"first_N_keywords":["text-generation","Thai","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"thailand-policy-statements","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thailand-policy-statements","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tThailand Policy Statements\n\t\n\nCollect all Thailand policy statements from Thailand government\nLicense: CC-0\nThis project is a part of PyThaiNLP project.\nGithub: https://github.com/PyThaiNLP/thailand-policy-statements\n\n\t\n\t\t\n\t\tCitation\n\t\n\n\nPhatthiyaphaibun, W. (2024). Thailand Policy Statements (1.0) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.10842589\n\nor \n@dataset{phatthiyaphaibun_2024_10842589,\n  author       = {Phatthiyaphaibun, Wannaphong},\n  title        = {Thailand Policy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/thailand-policy-statements.","first_N":5,"first_N_keywords":["text-generation","Thai","cc0-1.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"thaigov-corpus","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thaigov-corpus","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tThaiGov corpus\n\t\n\nGitHub: https://github.com/PyThaiNLP/thaigov-corpus\n\n\t\n\t\t\n\t\tEnglish\n\t\n\n\nData from Thai government website. https://www.thaigov.go.th\nThis part of PyThaiNLP Project.\nCompiled by Mr.Wannaphong Phatthiyaphaibun\nLicense Dataset is public domain.\n\n\n\t\n\t\t\n\t\tData format\n\t\n\n\n1 file, 1 news, which is extracted from 1 url.\n\ntopic\n(Blank line)\ncontent\ncontent\ncontent\ncontent\ncontent\n(Blank line)\n‡∏ó‡∏µ‡πà‡∏°‡∏≤ (URL source) : http://www.thaigov.go.th/news/contents/details/NNN\n\n\n\t\n\t\t\n\t\tThai‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/thaigov-corpus.","first_N":5,"first_N_keywords":["text-generation","Thai","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"thaigov-v2-corpus-31032024","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thaigov-v2-corpus-31032024","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tThaiGov V2 Corpus\n\t\n\nGitHub: https://github.com/PyThaiNLP/thaigov-v2-corpus\n\n\t\n\t\t\n\t\tEnglish\n\t\n\n\nData from Thai government website. https://www.thaigov.go.th\nThis part of PyThaiNLP Project.\nCompiled by Mr.Wannaphong Phatthiyaphaibun\nLicense Dataset is public domain.\n\n\n\t\n\t\t\n\t\tData format\n\t\n\n\n1 file, 1 news, which is extracted from 1 url.\n\ntopic\n(Blank line)\ncontent\ncontent\ncontent\ncontent\ncontent\n(Blank line)\n‡∏ó‡∏µ‡πà‡∏°‡∏≤ (URL source) : http://www.thaigov.go.th/news/contents/details/NNN‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/thaigov-v2-corpus-31032024.","first_N":5,"first_N_keywords":["text-generation","Thai","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"oaast_rm_full_jieba","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"Â∞ùËØïËß£ÂÜ≥\"llm repetition problem\"Ôºå‰ΩøÁî®ÂàÜËØçÊ®°ÂûãÂØπoaastËØ≠ÊñôËøõË°å‚ÄúÁªìÂ∑¥Âåñ‚ÄùÊï∞ÊçÆÂ¢ûÂº∫ÔºåÊèê‰æõÊõ¥Âº∫ÁöÑÈáçÂ§çÂÜÖÂÆπÊãíÁªùÊïàÊûú„ÄÇ\nAttempts to solve the \"llm repetition problem\" by using a segmentation model to enhance the oaast corpus with \"stuttering\" data to provide stronger rejection of duplicate content.\nÂÖ∂Ê¨°ÔºåËøòËøáÊª§Êéâ‰∫ÜÊâÄÊúâËá™ÊàëËÆ§Áü•ÁöÑÂæÆË∞ÉÊ†∑Êú¨„ÄÇ\nSecond, it also filters out all the fine-tuned samples of self-cognition.\nfiles:\n\noaast_rm_full_jieba.jsonl : word level repeat\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\n\n","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"ÿßŸÖÿßŸÖ ÿ¨ŸÖÿπŸá ÿßÿµŸÅŸáÿßŸÜ ⁄ØŸÅÿ™: ŸÖ€åÿ≤ÿßŸÜ ŸÜ€åÿßÿ≤ ÿ¢ÿ® ÿ¥ÿ±ÿ® ÿßÿµŸÅŸáÿßŸÜ €±€±.€µ ŸÖÿ™ÿ± ŸÖ⁄©ÿπÿ® ÿßÿ≥ÿ™ ⁄©Ÿá ÿ™ŸÖÿßŸÖ ÿßÿ≥ÿ™ÿßŸÜ ÿßÿµŸÅŸáÿßŸÜ ÿ±ÿß ŸæŸàÿ¥ÿ¥ ŸÖ€åÿØŸáÿØ Ÿà ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸÇÿ®ŸÑ ÿßÿ≤ ÿßŸÜŸÇŸÑÿßÿ® €å⁄©€å ÿßÿ≤ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿáÿß ÿØÿ± ÿ≠Ÿàÿ≤Ÿá ÿ¢ÿ® ÿ®ŸàÿØŸá ÿßÿ≥ÿ™.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"LLaVA-Instruct-Thai","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worapob/LLaVA-Instruct-Thai","creator_name":"Worapob Keatkongsang","creator_url":"https://huggingface.co/worapob","description":"\n\t\n\t\t\n\t\tThai-Translated LLaVA-Instruct-150K Dataset\n\t\n\nThis repository contains a Thai translation of the LLaVA-Instruct-150K dataset, originally created by Haotian Liu, Chunyuan Li, Yuheng Li, and Yong Jae Lee.\n\n\t\n\t\t\n\t\tOriginal Dataset\n\t\n\nThe LLaVA-Instruct-150K dataset is a large-scale multimodal instruction-following dataset designed for training large multimodal models. The original English dataset is available on Hugging Face Datasets.\n\nDataset Name: LLaVA-Instruct-150K  \nOriginal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worapob/LLaVA-Instruct-Thai.","first_N":5,"first_N_keywords":["visual-question-answering","Thai","English","cc-by-4.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"gsm8k-thai","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VISAI-AI/gsm8k-thai","creator_name":"VISAI AI","creator_url":"https://huggingface.co/VISAI-AI","description":"\n\t\n\t\t\n\t\tgsm8k-thai\n\t\n\nThis dataset is a Thai translation of the GSM8k benchmark (https://huggingface.co/datasets/openai/gsm8k), a dataset of grade school math word problems. The translation was performed using Claude 3.5 Sonnet.  It is intended for evaluating the performance of language models on mathematical reasoning in the Thai language. The split of training and test data follows the original GSM8k dataset.\n\n\t\n\t\t\n\t\n\t\n\t\tAnnotations\n\t\n\n\nsource: claude-3.5-sonnet\nlanguage: en -> th‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VISAI-AI/gsm8k-thai.","first_N":5,"first_N_keywords":["Thai","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MagiciteBabel","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iarcanar/MagiciteBabel","creator_name":"teerapat","creator_url":"https://huggingface.co/iarcanar","description":"\n\t\n\t\t\n\t\tAPI Key Configuration\n\t\n\n\nRename file open for edit api key.env to .env\nEdit .env file and paste your API key:ANTHROPIC_API_KEY='your_claude_api_key'\nOPENAI_API_KEY='your_openai_api_key'\n\n\n\n\n\t\n\t\t\n\t\tMagicBabel for FFXIV\n\t\n\n[th] ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÅ‡∏õ‡∏•‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏ô‡πÄ‡∏Å‡∏°‡∏™‡πå FFXIV ‡πÅ‡∏ö‡∏ö realtime ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏î‡∏¢‡∏Ñ‡∏ô‡πÑ‡∏ó‡∏¢\n\n\t\n\t\t\n\t\tDescription\n\t\n\nMagicBabel is a real-time translation tool specifically designed for Final Fantasy XIV (FFXIV), created by a non-native English speaker to enhance the storytelling experience. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iarcanar/MagiciteBabel.","first_N":5,"first_N_keywords":["translation","Thai","English","Korean","mit"],"keywords_longer_than_N":true},
	{"name":"Phonemized-UD","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/suchirsalhan/Phonemized-UD","creator_name":"Suchir Salhan","creator_url":"https://huggingface.co/suchirsalhan","description":"\n\t\n\t\t\n\t\tPhoneme-UD: A Multilingual Phonemized Universal Dependencies Corpus for 34+ Languages\n\t\n\n\n\t\n\t\t\n\t\tG2P+ Phonemizer\n\t\n\nWe use G2P+ to phonemize Universal Dependencies. Here is an example usage: \n# Install required packages\n!apt-get install -y espeak-ng\n!pip install phonemizer g2p-plus\n# Set the environment variable from Python\nimport os\nos.environ[\"PHONEMIZER_ESPEAK_LIBRARY\"] = \"/usr/lib/x86_64-linux-gnu/libespeak-ng.so.1\"\n\n# Now run your transcription\nfrom g2p_plus import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suchirsalhan/Phonemized-UD.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Azerbaijani","Catalan"],"keywords_longer_than_N":true},
	{"name":"lr-sum","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\tDataset Card for LR-Sum\n\t\n\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \nThe data is based on the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum.","first_N":5,"first_N_keywords":["summarization","text-generation","found","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"mCoT-MATH","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laihuiyuan/mCoT-MATH","creator_name":"Huiyuan Lai","creator_url":"https://huggingface.co/laihuiyuan","description":"\n\t\n\t\t\n\t\tmCoT: Multilingual Instruction Tuning for Reasoning Consistency in Language Models\n\t\n\nPaper: https://arxiv.org/abs/2406.02301\nCode: https://github.com/laihuiyuan/mCoT\nModel: https://huggingface.co/laihuiyuan/mCoT\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nBased on MetaMathQA and MathInstruct\n, we use machine translation to compile mCoT-MATH, the first large-scale multilingual math CoT reasoning dataset containing around 6.3 million samples for 11 diverse languages.\nWe train a 7B parameter model mCoT for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laihuiyuan/mCoT-MATH.","first_N":5,"first_N_keywords":["Swahili","Bengali","Telugu","Thai","Japanese"],"keywords_longer_than_N":true},
	{"name":"megawika-report-generation","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\n\t\n\t\t\n\t\tDataset Card for MegaWika for Report Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\nnon-English language, an automated English translation is provided. \nThis dataset provides the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation.","first_N":5,"first_N_keywords":["summarization","text-retrieval","text-generation","Afrikaans","Arabic"],"keywords_longer_than_N":true},
	{"name":"dolly-rag-instruct-th","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ping98k/dolly-rag-instruct-th","creator_name":"ping","creator_url":"https://huggingface.co/ping98k","description":"ping98k/dolly-rag-instruct-th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","Thai","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"language-dataset","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","description":"\n","first_N":5,"first_N_keywords":["text-classification","English","Chinese","French","Russian"],"keywords_longer_than_N":true},
	{"name":"thailaw-v1.0","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thailaw-v1.0","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"ThaiLaw v1.0\"\n\t\n\n\n\t\n\t\t\n\t\tEnglish\n\t\n\nThai Law Dataset (Act of Parliament) v1.0\n\nData source from Office of the Council of State, Thailand https://www.krisdika.go.th/ and law.go.th.\nThis part of PyThaiNLP Project.\nLicense Dataset is public domain.\n\n\n\t\n\t\t\n\t\tThai\n\t\n\n‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÑ‡∏ó‡∏¢ (‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏ö‡∏±‡∏ç‡∏ç‡∏±‡∏ï‡∏¥) ‡∏£‡∏∏‡πà‡∏ô 1.0\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ñ‡∏ì‡∏∞‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏§‡∏©‡∏é‡∏µ‡∏Å‡∏≤ https://www.krisdika.go.th/ ‡πÅ‡∏•‡∏∞ law.go.th\n‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô‡πÅ‡∏ú‡∏ô‡∏û‡∏±‡∏í‡∏ô‡∏≤ PyThaiNLP‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/thailaw-v1.0.","first_N":5,"first_N_keywords":["Thai","cc0-1.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\nand converted into different parts (see process.py):\n\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\n\nRaw data files are in raw.tar.gz, which contains:\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\n[...] 9.8M Feb 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"mittens","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/mittens","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tMiTTenS: A Dataset for Evaluating Misgendering in Translation\n\t\n\nMisgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scripts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/mittens.","first_N":5,"first_N_keywords":["translation","Arabic","Finnish","Oromo","Ganda"],"keywords_longer_than_N":true},
	{"name":"winograd_th","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pakphum/winograd_th","creator_name":"phakphum artkaew","creator_url":"https://huggingface.co/pakphum","description":"\n\t\n\t\t\n\t\tA collection of Thai Winograd Schemas\n\t\n\nWe present a collection of Winograd Schemas in the Thai language. These schemas are adapted from the original set of English Winograd Schemas proposed by Levesque et al., which was based on Ernest Davis's collection.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Translation\n\t\n\nTwo professional translators, who were native Thai speakers fluent in English and had experience translating from English to Thai, were hired. In a pilot translation phase, one native speaker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pakphum/winograd_th.","first_N":5,"first_N_keywords":["multiple-choice","Thai","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"HellaSwag_TH","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Patt/HellaSwag_TH","creator_name":"Patteera","creator_url":"https://huggingface.co/Patt","description":"\n\t\n\t\t\n\t\tDataset Card for HellaSwag_TH\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is Thai translated version of hellaswag using google translate with Multilingual Universal Sentence Encoder to calculate score for Thai translation. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEN\nTH\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{HellaSwag_TH,\n  author = {Triamamornwooth Patteera},\n  title = {HellaSwag_TH},\n  year = {2023},\n  publisher = {Hugging Face},\n  note = {v1.0},\n  url = {https://huggingface.co/datasets/Patt/HellaSwag_TH}\n}\n\n","first_N":5,"first_N_keywords":["Thai","English","cc-by-sa-4.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Open_Assistant_Conversation_Chains","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset description\n\t\n\n\n\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\n\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\n\nIt was modified‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains.","first_N":5,"first_N_keywords":["text-generation","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arb√´resh√´ Albanian"],"keywords_longer_than_N":true},
	{"name":"SeaExam","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SeaLLMs/SeaExam","creator_name":"SeaLLMs - Language Models for Southeast Asian Languages","creator_url":"https://huggingface.co/SeaLLMs","description":"\nCheck the üèÜ leaderboard constructed with this dataset and the corresponding üë®üèª‚Äçüíª evaluation code.\n\n\n\t\n\t\t\n\t\tSeaExam dataset\n\t\n\nThe SeaExam dataset aims to evaluate Large Language Models (LLMs) on a diverse set of Southeast Asian (SEA) languages including English, Chinese, Indonesian, Thai, and Vietnamese. \nOur goal is to ensure a fair and consistent comparison across different LLMs on those languages while mitigating the risk of data contamination. \nIt consists of the following two parts:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SeaLLMs/SeaExam.","first_N":5,"first_N_keywords":["multiple-choice","English","Indonesian","Vietnamese","Thai"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"han-instruct-dataset-v2.0","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/han-instruct-dataset-v2.0","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for Han Instruct Dataset v2.0\n\t\n\nü™ø Han (‡∏´‡πà‡∏≤‡∏ô or goose) Instruct Dataset is a Thai instruction dataset by PyThaiNLP. This dataset collect all Thai instruct dataset that made by human and our old model. The dataset can use to train Instruction Following model like ChatGPT or other.\nMany question are collect from Reference desk at Thai wikipedia.\nData sources:\n\nReference desk at Thai wikipedia.\nLaw from justicechannel.org\npythainlp/final_training_set_v1_enth: Human checked‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/han-instruct-dataset-v2.0.","first_N":5,"first_N_keywords":["text-generation","Thai","cc-by-sa-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"thai-oldbooks","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thai-oldbooks","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tThai Old Books dataset\n\t\n\nThis dataset collect books from Vajirayana library. All books are copyright expired in Thai law (50 years after the author's death).\nAll books: 75 books.\nLicense: CC-0\n\nNews: I created a new dataset named Thai TNHC2 Books that was cleaned from the TNHC2 corpus but this dataset is clear than Thai TNHC2 Books dataset. If you want to train a model. I suggest you mix the two datasets and delete duplicate books.\n\nList Books\n\n‡∏ö‡∏ó‡∏•‡∏∞‡∏Ñ‡∏£‡∏ô‡∏≠‡∏Å‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏±‡∏á‡∏Ç‡πå‡∏ó‡∏≠‡∏á\n‡∏Ç‡∏∏‡∏ô‡∏ä‡πâ‡∏≤‡∏á‡∏Ç‡∏∏‡∏ô‡πÅ‡∏ú‡∏ô‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/thai-oldbooks.","first_N":5,"first_N_keywords":["text-generation","Thai","cc0-1.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"thai-constitution-corpus","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thai-constitution-corpus","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tThai Constitution Corpus\n\t\n\nThai Constitution Corpus\nGitHub: https://github.com/PyThaiNLP/Thai-constitution-corpus\n\n\t\n\t\t\n\t\tEnglish\n\t\n\nThe Constitution of Thailand Dataset Since 1932\n\nData from Office of the Council of State\nThis part of PyThaiNLP Project.\nLicense Dataset is public domain.\n\n\n\t\n\t\t\n\t\tThai\n\t\n\n‡∏Ñ‡∏•‡∏±‡∏á‡∏£‡∏±‡∏ê‡∏ò‡∏£‡∏£‡∏°‡∏ô‡∏π‡∏ç‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢ ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏õ‡∏µ ‡∏û.‡∏®.2475\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏°‡∏≤‡∏à‡∏≤‡∏Å ‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ñ‡∏ì‡∏∞‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏§‡∏©‡∏é‡∏µ‡∏Å‡∏≤\n‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô‡πÅ‡∏ú‡∏ô‡∏û‡∏±‡∏í‡∏ô‡∏≤ PyThaiNLP‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/thai-constitution-corpus.","first_N":5,"first_N_keywords":["text-generation","Thai","cc0-1.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"thai-cc-license","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thai-cc-license","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tThai CC License\n\t\n\nThe dataset collect all Thai Creative Commons License.\nLicense Dataset is public domain.\n","first_N":5,"first_N_keywords":["text-generation","Thai","cc0-1.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"thai-tnhc2-books","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thai-tnhc2-books","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tThai TNHC2 Books\n\t\n\nThis dataset collect all books from TNHC2 corpus.\nWe clean the dataset to use text to pretraining model and nlp task.\nAll books: 353 books\nLicense: CC-0\n\nTNHC2 Dataset (Original) have many a lots of details (chapter, author's detail and more). The dataset is clean to pretraining model and nlp task.\n\nTNHC2 coepus is a Thai old books corpus that all books are copyright expired in Thai law (50 years after the author's death).\nTNHC2 Dataset (Original):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/thai-tnhc2-books.","first_N":5,"first_N_keywords":["text-generation","Thai","cc0-1.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Pontoon-Translations","keyword":"thai","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\n\t\n\t\t\n\t\tDataset Card for Pontoon Translations\n\t\n\n\n\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\nSource strings are in English.\nTo avoid rows with values like \"None\" and \"N/A\" being interpreted as missing values, pass the keep_default_na parameter like this:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ayymen/Pontoon-Translations\", keep_default_na=False)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","crowdsourced","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"WangchanThaiInstruct","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/airesearch/WangchanThaiInstruct","creator_name":"VISTEC-depa AI Research Institute of Thailand","creator_url":"https://huggingface.co/airesearch","description":"100% Human-Annotated Thai Instruction Dataset (Batch 1-5 Release, v0.4_beta)\nWe have both NC and SA licenses. Please adhere to the license terms. Each row has its license according to its source.\nWe will continue updating licenses as we receive permission from the respective license sources.\n4 Domains:\n\nMedical\nFinance\nRetail\nLegal\n\n7 Tasks:\n\nSummarization\nOpen QA\nClose QA\nClassification\nCreative Writing\nBrainstorming\nMultiple Choice QA\n\n","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","text-classification","Thai"],"keywords_longer_than_N":true},
	{"name":"han-instruct-dataset-v3.0","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/han-instruct-dataset-v3.0","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for Han Instruct Dataset v3.0\n\t\n\n\nü™ø Han (‡∏´‡πà‡∏≤‡∏ô or goose) Instruct Dataset is a Thai instruction dataset by PyThaiNLP. This dataset collects all Thai instruct datasets that were made by humans and our old model. The dataset can be used to train Instruction Following models like ChatGPT or others.\nMany questions are collect from Reference desk at Thai wikipedia.\nData sources:\n\nReference desk at Thai wikipedia.\nLaw from justicechannel.org\npythainlp/final_training_set_v1_enth:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/han-instruct-dataset-v3.0.","first_N":5,"first_N_keywords":["text-generation","Thai","cc-by-sa-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \nBibTex\n@misc{lu2024languagecountslearnunlearn,\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \n      author={Taiming Lu and Philipp Koehn},\n      year={2024},\n      eprint={2406.13748},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2406.13748}, \n}\n\n","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"Z-coref-dataset","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/psuwannapich/Z-coref-dataset","creator_name":"Poomphob Suwannapichat","creator_url":"https://huggingface.co/psuwannapich","description":"\n\t\n\t\t\n\t\tZ-coref: Thai Coreference and Zero Pronoun Resolution\n\t\n\n\n\nThis is a dataset for Thai Coreference and Zero Pronoun Resolution.\nRaw textual data was retrieved from Han-Coref.\nThe coreferece labels were re-annotate to include zero pronoun resolution to coreference resolution.\n\n\t\n\t\t\n\t\tData Format\n\t\n\nThe dataset contains 4 columns:\n\ntext: Raw text data\nclusters: Coreference labels in nested list format. The outter list contains lists of clusters (coreference chains). Each cluster list‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/psuwannapich/Z-coref-dataset.","first_N":5,"first_N_keywords":["Thai","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"TH-EN-dataset","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pek111/TH-EN-dataset","creator_name":"Nathach Bunamornsiri","creator_url":"https://huggingface.co/pek111","description":"pek111/TH-EN-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Thai","English","mit","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"WangchanThaiInstruct_Multi-turn_Conversation_Dataset","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ThaiSyntheticQA/WangchanThaiInstruct_Multi-turn_Conversation_Dataset","creator_name":"Thai Synthetic QA","creator_url":"https://huggingface.co/ThaiSyntheticQA","description":"\n\t\n\t\t\n\t\tWangchanThaiInstruct Multi-turn Conversation Dataset\n\t\n\nWe create a Thai multi-turn conversation dataset from airesearch/WangchanThaiInstruct (Batch 1) by LLM. It was created from synthetic method using open source LLM in Thai language.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n\nThammaleelakul, S., & Phatthiyaphaibun, W. (2024). WangchanThaiInstruct Multi-turn Conversation Dataset [Data set]. Zenodo. https://doi.org/10.5281/zenodo.13132633\n\nor BibTeX\n@dataset{thammaleelakul_2024_13132633,\n  author       =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ThaiSyntheticQA/WangchanThaiInstruct_Multi-turn_Conversation_Dataset.","first_N":5,"first_N_keywords":["text-generation","Thai","cc-by-sa-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"thai_sa","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DGurgurov/thai_sa","creator_name":"Daniil Gurgurov","creator_url":"https://huggingface.co/DGurgurov","description":"\n\t\n\t\t\n\t\tSentiment Analysis Data for the Thai Language\n\t\n\nDataset Description:\nThis dataset contains a sentiment analysis dataset from Suriyawongkul et al. (2019).\nData Structure:\nThe data was used for the project on improving word embeddings with graph knowledge for Low Resource Languages.\nCitation:\n@software{bact_2019_3457447,\n  author       = {Suriyawongkul, Arthit and\n                  Chuangsuwanich, Ekapol and\n                  Chormai, Pattarawat and\n                  Polpanumas, Charin}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DGurgurov/thai_sa.","first_N":5,"first_N_keywords":["text-classification","Thai","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Sailcompass_data","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sail/Sailcompass_data","creator_name":"Sea AI Lab","creator_url":"https://huggingface.co/sail","description":"\n\t\n\t\t\n\t\n\t\n\t\tSailCompass: Towards Reproducible and Robust Evaluation for Southeast Asian Languages\n\t\n\nThis repository provides the dataset for evaluation SEA large language model.\n\nProject Website: sailorllm.github.io\nCodebase: https://github.com/sail-sg/sailcompass\n\n\n\t\n\t\t\n\t\n\t\n\t\tAcknowledgment\n\t\n\nThanks to the contributors of the opencompass.\n\n\t\n\t\t\n\t\n\t\n\t\tCiting this work\n\t\n\nIf you use this repository or sailor models, please cite\n@misc{sailcompass,\n      title={SailCompass: Towards Reproducible‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sail/Sailcompass_data.","first_N":5,"first_N_keywords":["text-classification","translation","summarization","table-question-answering","multiple-choice"],"keywords_longer_than_N":true},
	{"name":"Chatgpt","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"Thai_Nutrition_Dataset","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BaoWio/Thai_Nutrition_Dataset","creator_name":"BaoWio","creator_url":"https://huggingface.co/BaoWio","description":"\n\t\n\t\t\n\t\tDataset Card \"Thai Food Nutrition\"\n\t\n\nThai Food Nutrition\n\nData source from Thai Food Composition Tables 2015 Institute of Nutrition, Mahidol University (INMU), Thailand THAIFOODS and ASEANFOODS Regional Centre https://inmu2.mahidol.ac.th/thaifcd/.\n\n","first_N":5,"first_N_keywords":["table-question-answering","text-generation","multilingual","original","Thai"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\nExample of loading:\ndataset = load_dataset(\"davidstap/NTREX\", \"rus_Cyrl\", trust_remote_code=True)\n\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe following languages are available:\n\n\t\n\t\t\nLanguage Code\nLanguage Name\n\n\n\t\t\nafr_Latn\nAfrikaans\n\n\namh_Ethi\nAmharic\n\n\narb_Arab\nArabic\n\n\naze_Latn\nAzerbaijani\nbak_Cyrl\nBashkir\n\n\nbel_Cyrl\nBelarusian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"IMF-Subtitle-TH","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kraitans21/IMF-Subtitle-TH","creator_name":"Kriangkrai Tan","creator_url":"https://huggingface.co/kraitans21","description":"kraitans21/IMF-Subtitle-TH dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Thai","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"swim-ir-cross-lingual","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\n\t\n\t\t\n\t\tDataset Card for SWIM-IR (Cross-lingual)\n\t\n\n\n\n\nThis is the cross-lingual subset of the SWIM-IR dataset, where the query generated is in the target language and the passage is in English.\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\n\n\t\n\t\n\t\n\t\tWhat is SWIM-IR?\n\t\n\nSWIM-IR dataset is a synthetic multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","machine-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"sql-create-context-thai","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saksornr/sql-create-context-thai","creator_name":"Saksorn Ruangtanusak","creator_url":"https://huggingface.co/saksornr","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset builds from sql-create-context.\n@misc{b-mc2_2023_sql-create-context,\n  title   = {sql-create-context Dataset},\n  author  = {b-mc2}, \n  year    = {2023},\n  url     = {https://huggingface.co/datasets/b-mc2/sql-create-context},\n  note    = {This dataset was created by modifying data from the following sources: \\cite{zhongSeq2SQL2017, yu2018spider}.},\n}\n\n","first_N":5,"first_N_keywords":["text-generation","question-answering","table-question-answering","Thai","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"webui-dom-snapshots","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\n\t\n\t\t\n\t\tDataset Card for WebUI DOM snapshots\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Gary Benson\nLanguages: Mostly English (87%);\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\nLicense: CC0 1.0 Universal\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots.","first_N":5,"first_N_keywords":["image-feature-extraction","reinforcement-learning","text-classification","multilingual","biglab/webui-7k"],"keywords_longer_than_N":true},
	{"name":"oasst2_dpo_pairs_enth","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/oasst2_dpo_pairs_enth","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tOASST2 DPO Pairs English and Thai\n\t\n\nThis dataset contains message ChatML. It was create from Open Assistant Conversations Dataset Release 2 (OASST2). You can use to do human preference optimization (DPO, ORPO, and other).\n\n\t\n\t\t\n\t\tSelect Thai only\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"pythainlp/oasst2_dpo_pairs_enth\",split=\"train\")\nthai_dataset = dataset.filter(lambda example: example['lang']==\"th\") # if you want to use English only, change to \"en\".\n\nlicense:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/oasst2_dpo_pairs_enth.","first_N":5,"first_N_keywords":["text-generation","English","Thai","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"EXP-thai2sql","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIAT/EXP-thai2sql","creator_name":"Artificial Intelligence Association of Thailand","creator_url":"https://huggingface.co/AIAT","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AIAT/EXP-thai2sql.","first_N":5,"first_N_keywords":["text-generation","Thai","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Machima-applydataset","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIAT/Machima-applydataset","creator_name":"Artificial Intelligence Association of Thailand","creator_url":"https://huggingface.co/AIAT","description":"AIAT/Machima-applydataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["table-question-answering","Thai","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Machima-humangendataset","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIAT/Machima-humangendataset","creator_name":"Artificial Intelligence Association of Thailand","creator_url":"https://huggingface.co/AIAT","description":"AIAT/Machima-humangendataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["table-question-answering","Thai","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Pangpuriye-public_alpaca-cleaned","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIAT/Pangpuriye-public_alpaca-cleaned","creator_name":"Artificial Intelligence Association of Thailand","creator_url":"https://huggingface.co/AIAT","description":"\n\t\n\t\t\n\t\tü§ñ Super AI Engineer Development Program Season 4 - Pangpuriye House - Alpaca-Cleaned\n\t\n\n\n\n\t\n\t\t\n\t\tOriginal Dataset\n\t\n\nWe adopt this alpaca-cleaned dataset from https://huggingface.co/datasets/yahma/alpaca-cleaned the original repository. We used this dataset during the fine-tuning of Panguriye's LLM. The dataset is available under the Creative Commons Non Commercial (CC BY-NC 4.0). \nThe original dataset consists of 51,760 rows of input, instruction, and output in English. \nWe think‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AIAT/Pangpuriye-public_alpaca-cleaned.","first_N":5,"first_N_keywords":["Thai","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"mt-bench-thai","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ThaiLLM-Leaderboard/mt-bench-thai","creator_name":"ThaiLLM Leaderboard","creator_url":"https://huggingface.co/ThaiLLM-Leaderboard","description":"\n\t\n\t\t\n\t\tMT-Bench Thai\n\t\n\nMT-Bench Thai is a dataset for multi-turn benchmarking that covers 9 categories.\n\nWriting\nRoleplay\nExtraction\nReasoning\nMath\nCoding\nSTEM\nSocial Science\nKnowledge III\n\nWe introduce the final category, Knowledge III, which evaluates understanding of Thai cultural context.\n\n\t\n\t\t\n\t\tDataset Loading\n\t\n\nfrom datasets import load_dataset\nds = load_dataset(\"ThaiLLM-Leaderboard/mt-bench-thai\")\nprint(ds)\n\noutput\nDatasetDict({\n    train: Dataset({\n        features: ['question_id'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ThaiLLM-Leaderboard/mt-bench-thai.","first_N":5,"first_N_keywords":["text-generation","Thai","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"wangchanx-seed-free-synthetic-instruct-thai-120k","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/airesearch/wangchanx-seed-free-synthetic-instruct-thai-120k","creator_name":"VISTEC-depa AI Research Institute of Thailand","creator_url":"https://huggingface.co/airesearch","description":"\n\t\n\t\t\n\t\tDataset Card for WangchanX Seed-Free Synthetic Instruct Thai 120k\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains about 120k synthetic instruction-following samples in Thai, generated using a novel seed-free approach. It covers a wide range of domains derived from Wikipedia, including both general knowledge and Thai-specific cultural topics. The dataset is designed for instruction-tuning Thai language models to improve their ability to understand and generate Thai text in various‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/airesearch/wangchanx-seed-free-synthetic-instruct-thai-120k.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Thai","English"],"keywords_longer_than_N":true},
	{"name":"mirage-bench-instruct","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/mirage-bench-instruct","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\n\t\n\t\t\n\t\tMIRAGE-Bench (Instruct)\n\t\n\nThis dataset contains the structured RAG outputs for queries in the train split of MIRAGE-Bench (or MIRACL) for 16 languages for five models:\n\ngpt-4o-azure                          (GPT-4o using Azure API)\nmeta-llama/Meta-Llama-3-70B-Instruct  (Llama-3-70B-Instruct using Anyscale API)\nmistralai/Mixtral-8x22B-Instruct-v0.1 (Mixtral-8x22B-Instruct using Anyscale API)\nmeta-llama/Meta-Llama-3-8B-Instruct   (Llama-3-8B-Instruct using vLLM)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/mirage-bench-instruct.","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","Bengali","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"thai_exam","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/scb10x/thai_exam","creator_name":"SCB 10X","creator_url":"https://huggingface.co/scb10x","description":"\n\t\n\t\t\n\t\tDataset Card for Thai_Exam\n\t\n\nThaiExam is a Thai knowledge benchmarking dataset, consisting of multiple-choice questions from examinations in Thailand. The dataset was originally developed for evaluating Typhoon (Thai LLM). This dataset contains 5 splits corresponding to 5 examinations as follows:\n\nONET: The Ordinary National Educational Test (ONET) is an examination for students in Thailand. This dataset is based on the grade-12 ONET exam, comprising 4 subjects and each question has 5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/scb10x/thai_exam.","first_N":5,"first_N_keywords":["question-answering","Thai","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ThaiQA-v1","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ThaiSyntheticQA/ThaiQA-v1","creator_name":"Thai Synthetic QA","creator_url":"https://huggingface.co/ThaiSyntheticQA","description":"\n\t\n\t\t\n\t\tThaiQA v1\n\t\n\nThaiQA v1 is a Thai Synthetic QA dataset. It was created from synthetic method using open source LLM in Thai language.\nWe used Nvidia Nemotron 4 (340B) to create this dataset.\nTopics:\nTechnology and Gadgets 100\nTravel and Tourism 91\nFood and Cooking 99\nSports and Fitness 50\nArts and Entertainment 24\nHome and Garden 72\nFashion and Beauty 99\nScience and Nature 100\nHistory and Culture 91\nEducation and Learning 99\nPets and Animals 83\nRelationships and Family 78\nPersonal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ThaiSyntheticQA/ThaiQA-v1.","first_N":5,"first_N_keywords":["text-generation","question-answering","Thai","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"nomiracl-instruct","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/nomiracl-instruct","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\n\t\n\t\t\n\t\tDataset Card for NoMIRACL (EMNLP 2024 Findings Track)\n\t\n\n\n\t\n\t\t\n\t\tQuick Overview\n\t\n\nThis repository contains the fine-tuning (training & development split) of the NoMIRACL instruct dataset for fine-tuning LLMs on multilingual relevance assessment.\nThe training dataset is a binary classification task; they need to explicitly output either Yes, answer is present or I don't know. \nThe dataset contains training pairs from all 18 languages for both splits: relevant & non-relevant.\nimport‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miracl/nomiracl-instruct.","first_N":5,"first_N_keywords":["text-classification","text-generation","Arabic","Bengali","German"],"keywords_longer_than_N":true},
	{"name":"seed-free-synthetic-instruct-thai-v1","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/parinzee/seed-free-synthetic-instruct-thai-v1","creator_name":"Parinthapat Pengpun","creator_url":"https://huggingface.co/parinzee","description":"\n\t\n\t\t\n\t\tSeed-Free Synthetic Instruct Thai v1 (F+C+D+)\n\t\n\nThis dataset is part of the research paper \"Seed-Free Synthetic Data Generation Framework for Instruction-Tuning LLMs: A Case Study in Thai\" submitted to ACL SRW 2024. It represents the best-performing synthetic dataset (F+C+D+) generated using our novel seed-free framework for low-resource languages, specifically Thai.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSize: 5,000 instructions\nLanguage: Thai\nTask: Instruction-tuning for Large Language Models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/parinzee/seed-free-synthetic-instruct-thai-v1.","first_N":5,"first_N_keywords":["text-generation","Thai","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"han-instruct-dataset-v4.0","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/han-instruct-dataset-v4.0","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tDataset Card for Han Instruct Dataset v4.0 ü™øü™øü™øü™ø\n\t\n\nü™ø Han (‡∏´‡πà‡∏≤‡∏ô or goose) Instruct Dataset is a Thai instruction dataset by PyThaiNLP. This dataset collects all Thai instruct datasets that were made by humans and our old model. The dataset can be used to train Instruction Following models like ChatGPT or others.\nData sources:\n\nReference desk at Thai wikipedia.\nLaw from justicechannel.org\npythainlp/final_training_set_v1_enth: Human checked and edited.\nSelf-instruct from WangChanGLM‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/han-instruct-dataset-v4.0.","first_N":5,"first_N_keywords":["text-generation","Thai","cc-by-sa-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"thai-local-language-translation-dataset","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thai-local-language-translation-dataset","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\n\t\n\t\t\n\t\tThai Local Language Translation Dataset\n\t\n\nThai Local Language Translation Dataset is a translation dataset for translate Thai Local Language to Thai Central Language. We create the dataset from Thai Dialect Corpus (Thai dialects ASR corpus). We select train set only from Thai Dialect Corpus.\nThe dataset support Khummuang, Korat, and Pattani.\n\n\t\n\t\t\n\t\tReference\n\t\n\nSuwanbandit, A., Naowarat, B., Sangpetch, O., Chuangsuwanich, E. (2023) Thai Dialect Corpus and Transfer-based Curriculum‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/thai-local-language-translation-dataset.","first_N":5,"first_N_keywords":["translation","Thai","cc-by-sa-4.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"zenless_zone_zero_interknots_v1.0","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\n\t\n\t\t\n\t\n\t\n\t\tZZZ Interknots\n\t\n\nThis datasets contains extracted Interknot posts and comments (Áª≥ÁΩëÁöÑÂçöÂÆ¢‰∏éËØÑËÆ∫) in multi-language.\nUp to game version: 1.0\n\nInterknot posts and comments examples\n\n{\n  \"id\": \"1021\",\n  \"poster\": \"Sorrowful Intern\",\n  \"title\": \"[Commission] Missing Bangboo merchants\",\n  \"text\": \"Hello, pros... Some of the senior Bangboo of our merchant association have gone missing! We urgently need an expert to help find them!!\\nLet me explain, I recently joined a very prestigious‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","Japanese","German"],"keywords_longer_than_N":true},
	{"name":"flores","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/flores","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FloresBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nFLORES is a benchmark dataset for machine translation between English and low-resource languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNon-fiction, Encyclopaedic, Written\n\nReference\nhttps://huggingface.co/datasets/facebook/flores\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FloresBitextMining\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/flores.","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Achinese","Mesopotamian Arabic"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NTREXBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNTREX is a News Test References dataset for Machine Translation Evaluation, covering translation from English into 128 languages. We select language pairs according to the M2M-100 language grouping strategy, resulting in 1916 directions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/davidstap/NTREX\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","translated","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"thailand-cities","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AAhad/thailand-cities","creator_name":"Abdul Ahad","creator_url":"https://huggingface.co/AAhad","description":"\n\t\n\t\t\n\t\tDataset Card for Thailand-Cities\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThailand-Cities Contains list of Thailand Cities in both English and Thai languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTranslation\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThai\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n  1,Amnat Charoen,‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç\n  2,Ang Sila,‡∏≠‡πà‡∏≤‡∏á‡∏®‡∏¥‡∏•‡∏≤\n  3,Ang Thong,‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á\n  4,Aranyaprathet,‡∏≠‡∏£‡∏±‡∏ç‡∏ç‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®\n  5,Aranyik,‡∏≠‡∏£‡∏±‡∏ç‡∏ç‡∏¥‡∏Å\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThe data fields are the same among all configurations:\n\nSNO (str): ID of the record‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AAhad/thailand-cities.","first_N":5,"first_N_keywords":["translation","English","Thai","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"thailand-provinces","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AAhad/thailand-provinces","creator_name":"Abdul Ahad","creator_url":"https://huggingface.co/AAhad","description":"\n\t\n\t\t\n\t\tDataset Card for Thailand-Provinces\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThailand-Provinces Contains list of Thailand Provinces in both Engligh and Thai languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTranslation\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThai\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n  1,Bangkok,‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£\n  2,Amnat Charoen,‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç\n  3,Ang Thong,‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á\n  4,Bueng Kan,‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨\n  5,Buriram,‡∏ö‡∏∏‡∏£‡∏µ‡∏£‡∏±‡∏°‡∏¢‡πå\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThe data fields are the same among all configurations:\n\nSNO (str): ID of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AAhad/thailand-provinces.","first_N":5,"first_N_keywords":["translation","English","Thai","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"countries-names-in-thai","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AAhad/countries-names-in-thai","creator_name":"Abdul Ahad","creator_url":"https://huggingface.co/AAhad","description":"\n\t\n\t\t\n\t\tDataset Card for Countries Names in Thai\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCountries Names in Thai Contains list of world countries names in both Engligh & Thai languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTranslation\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThai\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n  1,‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏≠‡∏±‡∏ü‡∏Å‡∏≤‡∏ô‡∏¥‡∏™‡∏ñ‡∏≤‡∏ô,Afghanistan\n  2,‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÅ‡∏≠‡∏•‡πÄ‡∏ö‡πÄ‡∏ô‡∏µ‡∏¢,Albania\n  3,‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÅ‡∏≠‡∏•‡∏à‡∏µ‡πÄ‡∏£‡∏µ‡∏¢,Algeria\n  4,‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏≠‡∏±‡∏ô‡∏î‡∏≠‡∏£‡πå‡∏£‡∏≤,Andorra\n  5,‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏≠‡∏≤‡∏£‡πå‡πÄ‡∏à‡∏ô‡∏ï‡∏¥‡∏ô‡∏≤,Argentina\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThe data fields are the same among all‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AAhad/countries-names-in-thai.","first_N":5,"first_N_keywords":["translation","English","Thai","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"xm3600","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\nIt also includes the image features as PIL Image and has a uniform and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xm3600_1k","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600 - 1K Split\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a 1K split of XM3600!\n\t\n\nFor this, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"KhanomTanLLM-pretrained-dataset","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wannaphong/KhanomTanLLM-pretrained-dataset","creator_name":"Wannaphong Phatthiyaphaibun","creator_url":"https://huggingface.co/wannaphong","description":"\n\t\n\t\t\n\t\tKhanomTanLLM pretrained dataset\n\t\n\nThis daataset collect all raw text for pretraining LLM.\nCodename: numfa v2\nRepository: https://github.com/pythainlp/KhanomTanLLM\n\n\t\n\t\t\n\t\tTokens\n\t\n\n53,376,211,711 Tokens\n\nEnglish: 31,629,984,243 Tokens\nThai: 12,785,565,497 Tokens\nCode: 8,913,084,300 Toekns\nParallel data: 190,310,686 Tokens\n\nBased on Typhoon-7B (https://huggingface.co/scb10x/typhoon-7b) tokenizer\n\n\t\n\t\t\n\t\tAll subset\n\t\n\n\n\t\n\t\t\n\t\tThai\n\t\n\n\npythainlp/thai_food_v1.0\npythainlp/thailaw-v1.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wannaphong/KhanomTanLLM-pretrained-dataset.","first_N":5,"first_N_keywords":["text-generation","Thai","English","cc0-1.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"sea_translationese_resampled","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SEACrowd/sea_translationese_resampled","creator_name":"SEACrowd","creator_url":"https://huggingface.co/SEACrowd","description":"\n\nThis is our SEA translationese vs. natural classification dataset for the \"SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages\" paper.\nSEACrowd is a collaborative initiative that consolidates a comprehensive resource hub that fills the resource gap by providing standardized corpora in nearly 1,000 Southeast Asian (SEA) languages across three modalities.\n\n\t\n\t\n\t\n\t\tData Card\n\t\n\nTo analyze the generation quality of LLMs in SEA languages, we build a text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SEACrowd/sea_translationese_resampled.","first_N":5,"first_N_keywords":["text-classification","English","Indonesian","Malay","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"Porjai-Thai-voice-dataset-central","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMKL/Porjai-Thai-voice-dataset-central","creator_name":"CMKL University","creator_url":"https://huggingface.co/CMKL","description":"\n\t\n\t\t\n\t\tPorjai-Thai-voice-dataset-central\n\t\n\nThis corpus contains a officially split of 700 hours for Central Thai, and 40 hours for the three dialect each. The corpus is designed such that there are some parallel sentences between the dialects, making it suitable for Speech and Machine translation research.\nOur demo ASR model can be found at https://www.cmkl.ac.th/research/porjai. The Thai Central data was collected using Wang Data Market.\nSince parts of this corpus are in the ML-SUPERB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CMKL/Porjai-Thai-voice-dataset-central.","first_N":5,"first_N_keywords":["Thai","cc-by-sa-4.0","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"thai_synthetic_math","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wannaphong/thai_synthetic_math","creator_name":"Wannaphong Phatthiyaphaibun","creator_url":"https://huggingface.co/wannaphong","description":"wannaphong/thai_synthetic_math dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Thai","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"token_awareness-enth","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chompk/token_awareness-enth","creator_name":"Chompakorn","creator_url":"https://huggingface.co/chompk","description":"\n\t\n\t\t\n\t\tToken Awareness Dataset\n\t\n\nBuilt from \"strawberry\" meme üçì, most LLM can't count the character of the word. Since this dataset is very easy to generate, we create a dataset for this benchmark just for fun.\nFor this dataset, we support only Thai (th) and English (en) language.\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nWe sample words for each language from these sources:\n\nThai: pythainlp's Thai words\nEnglish: dwyl's English words\n\nWe then sample 500 word each weigted by the word score, which was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chompk/token_awareness-enth.","first_N":5,"first_N_keywords":["Thai","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Porjai-Thai-voice-dataset-korat","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMKL/Porjai-Thai-voice-dataset-korat","creator_name":"CMKL University","creator_url":"https://huggingface.co/CMKL","description":"\n\t\n\t\t\n\t\tPorjai-Thai-voice-dataset-korat\n\t\n\nThis corpus contains a officially split of 700 hours for Central Thai, and 40 hours for the three dialect each. The corpus is designed such that there are some parallel sentences between the dialects, making it suitable for Speech and Machine translation research.\nOur demo ASR model can be found at https://www.cmkl.ac.th/research/porjai. The Thai Central data was collected using Wang Data Market.\nSince parts of this corpus are in the ML-SUPERB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CMKL/Porjai-Thai-voice-dataset-korat.","first_N":5,"first_N_keywords":["Thai","cc-by-sa-4.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"Todo - Write dataset card\n","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"voices-of-civilizations","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sander-wood/voices-of-civilizations","creator_name":"Shangda Wu (Sander Wood)","creator_url":"https://huggingface.co/sander-wood","description":"\n\t\n\t\t\n\t\tVoices of Civilizations (VoC)\n\t\n\nVoices of Civilizations (VoC) is the first multilingual QA benchmark designed to assess audio LLMs‚Äô cultural comprehension using full-length music recordings. VoC spans:\n\n38 languages (including zh, en, hi, es, fr, ja, ko, ar, sw, bn, de, pt, ru, etc.)\n380 tracks drawn from traditional and regional music\n860 multiple-choice questions probing four dimensions: language, region, mood, and theme\n\nVoC exposes models‚Äô biases and weaknesses on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sander-wood/voices-of-civilizations.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"ThaiExam","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EIRTHAIMED/ThaiExam","creator_name":"EIR Thaimed LLM","creator_url":"https://huggingface.co/EIRTHAIMED","description":"Finetune Multiple-Choice Question Dataset in Thai\n\nDetails:\n\nThis dataset is designed for fine-tuning Thai language models, focusing on the Chain-of-Thought (COT) process, which aids in analyzing questions and deriving correct answers step by step. The dataset consists of multiple-choice questions divided into five categories:\n\n\n    O-NET: Ordinary National Educational Test\n    IC: Investment Consultant \n    TGAT: Thai General Aptitude Test\n    TPAT: Thai Professional Aptitude Test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EIRTHAIMED/ThaiExam.","first_N":5,"first_N_keywords":["question-answering","Thai","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"thai_famous_people_images_dataset","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iapp/thai_famous_people_images_dataset","creator_name":"iApp Technology","creator_url":"https://huggingface.co/iapp","description":"\n\t\n\t\t\n\t\tThai Famous People Image Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Thai Famous People Image Dataset is a collection of images and descriptions of famous Thai personalities. This dataset is designed to provide a comprehensive resource for researchers, developers, and enthusiasts interested in Thai culture, history, and notable figures. The data was extracted from the Thai Wikipedia dump in September 2024, ensuring up-to-date and relevant information.\n\n\t\n\t\t\n\t\tMaintainer\n\t\n\nKobkrit‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iapp/thai_famous_people_images_dataset.","first_N":5,"first_N_keywords":["question-answering","Thai","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEDataset","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tüåà Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEBench","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tüåà Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"product-database","keyword":"thai","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\n\t\n\t\t\n\t\tOpen Food Facts Database\n\t\n\n\n\t\n\t\t\n\t\tWhat is üçä Open Food Facts?\n\t\n\n\n\t\n\t\t\n\t\tA food products database\n\t\n\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\n\n\t\n\t\t\n\t\tMade by everyone\n\t\n\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"who-en-th","keyword":"thai","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/Tsunnami/who-en-th","creator_name":"Tsunn","creator_url":"https://huggingface.co/Tsunnami","description":"Tsunnami/who-en-th dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","English","Thai","unlicense","< 1K"],"keywords_longer_than_N":true},
	{"name":"multilingual-coco","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/romrawinjp/multilingual-coco","creator_name":"Romrawin Chumpu","creator_url":"https://huggingface.co/romrawinjp","description":"\n\t\n\t\t\n\t\tMultilingual Common Objects in Context (COCO) Dataset\n\t\n\nThis dataset is a collection of multiple language open-source captions of COCO dataset. \nThe split in this dataset is set according to Andrej Karpathy's split from dataset_coco.json file. The collection was created specifically for simplicity of use in training and evaluation pipeline by non-commercial and research purposes. The COCO images dataset is licensed under a Creative Commons Attribution 4.0 License.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/romrawinjp/multilingual-coco.","first_N":5,"first_N_keywords":["image-to-text","English","Thai","Russian","Japanese"],"keywords_longer_than_N":true},
	{"name":"multilingual-task-oriented-dialog","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/edmdias/multilingual-task-oriented-dialog","creator_name":"Eduardo Dias","creator_url":"https://huggingface.co/edmdias","description":"\n\t\n\t\t\n\t\tMultilingual Task-Oriented Dialog Data\n\t\n\n\n\t\n\t\t\n\t\tDirectory structure\n\t\n\nThis dataset consists of 3 directories:\n\nen contains the English data\nes contains the Spanish data\nth contains the Thai data\n\nIn each directory, you'll find a file for each of the train/dev/test splits as used in our paper.\n\n\t\n\t\t\n\t\tFile format\n\t\n\nPYTEXT parquet FORMAT\nEach parquet file contains following 5 columns: intent label, the slot annotations in a comma-separated list with the format <start token>:<end‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/edmdias/multilingual-task-oriented-dialog.","first_N":5,"first_N_keywords":["text-classification","English","Thai","Spanish","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"bible-en-th","keyword":"thai","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/Tsunnami/bible-en-th","creator_name":"Tsunn","creator_url":"https://huggingface.co/Tsunnami","description":"\n\t\n\t\t\n\t\tbible-en-th\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe bible-en-th dataset is a bilingual corpus containing English and Thai translations of the Bible, specifically the King James Version (KJV) translated into Thai. This dataset is designed for various natural language processing tasks, including translation, language modeling, and text analysis.\n\nLanguages: English (en) and Thai (th)\nTotal Rows: 31,102\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of two main features:\n\nen: English text from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tsunnami/bible-en-th.","first_N":5,"first_N_keywords":["translation","text-generation","text-classification","English","Thai"],"keywords_longer_than_N":true},
	{"name":"bible-en-th","keyword":"thai","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/Tsunnami/bible-en-th","creator_name":"Tsunn","creator_url":"https://huggingface.co/Tsunnami","description":"\n\t\n\t\t\n\t\tbible-en-th\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe bible-en-th dataset is a bilingual corpus containing English and Thai translations of the Bible, specifically the King James Version (KJV) translated into Thai. This dataset is designed for various natural language processing tasks, including translation, language modeling, and text analysis.\n\nLanguages: English (en) and Thai (th)\nTotal Rows: 31,102\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of two main features:\n\nen: English text from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tsunnami/bible-en-th.","first_N":5,"first_N_keywords":["translation","text-generation","text-classification","English","Thai"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSIB-Fleurs\n\t\n\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \nThe topics are:\n\nScience/Technology\nTravel\nPolitics\nSports\nHealth\nEntertainment\nGeography\n\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset creation\n\t\n\nThis dataset processes and merges‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"mgsm","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jbross-ibm-research/mgsm","creator_name":"J Bross","creator_url":"https://huggingface.co/jbross-ibm-research","description":"\n\t\n\t\t\n\t\tDataset Card for MGSM\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCopy and merge of this MGSM Dataset, Catalan version, Basque version, Galician version, but in training samples we removed the prompt formatting, e.g. removed Question: ... in question field or Answer: ... in answer field.\nMultilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper Language models are multilingual chain-of-thought reasoners.\nThe same 250 problems from GSM8K are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jbross-ibm-research/mgsm.","first_N":5,"first_N_keywords":["found","found","expert-generated","multilingual","extended|gsm8k"],"keywords_longer_than_N":true},
	{"name":"xtreme-up-semantic-parsing","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for afrixnli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSee XTREME-UP GitHub\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 20 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata = load_dataset('Davlan/xtreme-up-semantic-parsing', 'yor') \n# Please, specify the language code\n# A data point example is below:\n{\n\"id\": \"3231323330393336\",\n\"split\": \"test\",\n\"intent\": \"IN:GET_REMINDER\",\n\"locale\": \"en\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing.","first_N":5,"first_N_keywords":["text-classification","multilingual","Amharic","Belarusian","Bengali"],"keywords_longer_than_N":true},
	{"name":"web-content","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neverland-th/web-content","creator_name":"Neverlandweedshop","creator_url":"https://huggingface.co/neverland-th","description":"neverland-th/web-content dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["summarization","translation","question-answering","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"MMMU-Thai","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iapp/MMMU-Thai","creator_name":"iApp Technology","creator_url":"https://huggingface.co/iapp","description":"\n\t\n\t\t\n\t\tMMMU Thai (MMMU Benchmark Translated to Thai)\n\t\n\nMMMU Thai is a dataset for evaluating multimodal models on massive multi-discipline tasks requiring college-level knowledge and deliberate reasoning. This dataset is translated from MMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI) into Thai.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nMMMU Thai consists of 11,500 meticulously collected multimodal questions from college exams, quizzes, and textbooks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iapp/MMMU-Thai.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","Thai","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"parallel_corpus_game","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bot-yaya/parallel_corpus_game","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","description":"https://github.com/mnbvc-parallel-corpus-team/parallel_corpus_mnbvc\nGame Corpus Collected by MNBVC Parallel Corpus Team.\n\n\t\n\t\t\n\t\t07/10/2025 Updated\n\t\n\nAdd 4 new corpus from games:\n\nDisco Elysium\nSCP Secret Laboratory\nStar Wars: Jedi Fallen Order\nStellar Blade\n\n\n\t\n\t\t\n\t\t06/13/2025 Rename and Reupload Dataset\n\t\n\n47 Games are Included:\n\nAnonymous Hacker Simulator\nBorderlands 2\nBorderlands 3\nBaldur's Gate 3\nCultist Simulator\nCyberpunk 2077\nDark Souls 3\nDetroit Become Human\nDisaster Band\nDo Not‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bot-yaya/parallel_corpus_game.","first_N":5,"first_N_keywords":["translation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"Instruction-Following-IFEval","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisingapore/Instruction-Following-IFEval","creator_name":"AI Singapore","creator_url":"https://huggingface.co/aisingapore","description":"\n\t\n\t\t\n\t\tSEA-IFEval\n\t\n\nSEA-IFEval evaluates a model's ability to adhere to constraints provided in the prompt, for example beginning a response with a specific word/phrase or answering with a certain number of sections. It is based on IFEval and was manually translated by native speakers for Indonesian, Javanese, Sundanese, Thai, Tagalog, and Vietnamese.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nSEA-IFEval is designed for evaluating chat or instruction-tuned large language models (LLMs).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aisingapore/Instruction-Following-IFEval.","first_N":5,"first_N_keywords":["text-generation","Indonesian","Javanese","Sundanese","Thai"],"keywords_longer_than_N":true},
	{"name":"NLR-Causal-Reasoning","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisingapore/NLR-Causal-Reasoning","creator_name":"AI Singapore","creator_url":"https://huggingface.co/aisingapore","description":"\n\t\n\t\t\n\t\tSEA Causal Reasoning\n\t\n\nSEA Causal Reasoning evaluates a model's ability to choose the correct cause or effect given a premise. It is sampled from XCOPA for Indonesian, Tamil, Thai, and Vietnamese.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nSEA Causal Reasoning is designed for evaluating chat or instruction-tuned large language models (LLMs). It is part of the SEA-HELM leaderboard from AI Singapore.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nIndonesian (id)\nTamil (ta)\nThai (th)\nVietnamese (vi)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aisingapore/NLR-Causal-Reasoning.","first_N":5,"first_N_keywords":["text-generation","text-classification","Indonesian","Tamil","Thai"],"keywords_longer_than_N":true},
	{"name":"NLR-NLI","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisingapore/NLR-NLI","creator_name":"AI Singapore","creator_url":"https://huggingface.co/aisingapore","description":"\n\t\n\t\t\n\t\tSEA Abstractive Summarization\n\t\n\nSEA Abstractive Summarization evaluates a model's ability to read a document, identify the key points within, and summarize them into a coherent and fluent text while paraphrasing the document. It is sampled from IndoNLI for Indonesian, IndicXNLI for Tamil, and XNLI for Thai and Vietnamese.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nSEA Abstractive Summarization is designed for evaluating chat or instruction-tuned large language models (LLMs). It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aisingapore/NLR-NLI.","first_N":5,"first_N_keywords":["text-generation","Indonesian","Tamil","Thai","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"vqa","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldcuisines/vqa","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\n\t\n\t\t\n\t\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\n\t\n\n\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 October 2024.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa.","first_N":5,"first_N_keywords":["multilingual","English","Indonesian","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"openthaigpt_eval","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openthaigpt/openthaigpt_eval","creator_name":"OpenThaiGPT","creator_url":"https://huggingface.co/openthaigpt","description":"\n\t\n\t\t\n\t\n\t\n\t\tOpenThaiGPT Evaluation Dataset\n\t\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe OpenThaiGPT Evaluation Dataset is a collection of curated datasets designed for evaluating Thai-language question-answering models. The dataset is focused on benchmark exams, offering a comprehensive set of evaluation resources for various educational and professional domains in Thailand.\n\n\t\n\t\t\n\t\n\t\n\t\tAvailable Benchmark Datasets\n\t\n\nThis dataset includes multiple benchmark exams, covering both general academic and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openthaigpt/openthaigpt_eval.","first_N":5,"first_N_keywords":["question-answering","Thai","apache-2.0","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Achinese","Adyghe"],"keywords_longer_than_N":true},
	{"name":"STT-v1","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FILM6912/STT-v1","creator_name":"FILM","creator_url":"https://huggingface.co/FILM6912","description":"FILM6912/STT-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Thai","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"kurage_training_data","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/kurage_training_data","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"lightblue/kurage_training_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Arabic","English","Spanish","Hindi","Indonesian"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Achinese","Adyghe"],"keywords_longer_than_N":true},
	{"name":"thai_buddhist_studies_exam","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biodatlab/thai_buddhist_studies_exam","creator_name":"Biomedical and Data Lab, Mahidol University","creator_url":"https://huggingface.co/biodatlab","description":"\n\t\n\t\t\n\t\tThai Buddhist Studies Examination (Nak Tham)\n\t\n\nThis repository contains multiple-choice questions from the Thai Buddhist Studies\n(Nak Tham) examination (2020, 2022, 2023). This dataset can be used for a benchmark for evaluating Large Language Models'\nunderstanding of Thai Buddhist concepts and teachings.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nYear\nNumber of Multiple Choice Questions\n\n\n\t\t\n2020\n1,350\n\n\n2022\n1,400\n\n\n2023\n1,350\n\n\n\t\n\nPhra Udom thought on the exam: We have reviewed the Nak‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biodatlab/thai_buddhist_studies_exam.","first_N":5,"first_N_keywords":["question-answering","Thai","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"thai_buddhist_studies_exam","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biodatlab/thai_buddhist_studies_exam","creator_name":"Biomedical and Data Lab, Mahidol University","creator_url":"https://huggingface.co/biodatlab","description":"\n\t\n\t\t\n\t\tThai Buddhist Studies Examination (Nak Tham)\n\t\n\nThis repository contains multiple-choice questions from the Thai Buddhist Studies\n(Nak Tham) examination (2020, 2022, 2023). This dataset can be used for a benchmark for evaluating Large Language Models'\nunderstanding of Thai Buddhist concepts and teachings.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nYear\nNumber of Multiple Choice Questions\n\n\n\t\t\n2020\n1,350\n\n\n2022\n1,400\n\n\n2023\n1,350\n\n\n\t\n\nPhra Udom thought on the exam: We have reviewed the Nak‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biodatlab/thai_buddhist_studies_exam.","first_N":5,"first_N_keywords":["question-answering","Thai","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"MM-Eval","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prometheus-eval/MM-Eval","creator_name":"prometheus-eval","creator_url":"https://huggingface.co/prometheus-eval","description":"\n\t\n\t\t\n\t\tMultilingual Meta-EVALuation benchmark (MM-Eval)\n\t\n\n\nüë®‚ÄçüíªCode\n|\nüìÑPaper\n|\nü§ó MMQA\n\n\nMM-Eval is a multilingual meta-evaluation benchmark consisting of five core subsets‚ÄîChat, Reasoning, Safety, Language Hallucination, and Linguistics‚Äîspanning 18 languages and a Language Resource subset spanning 122 languages for a broader analysis of language effects. \n\nDesign ChoiceIn this work, we minimize the inclusion of translated samples, as mere translation may alter existing preferences due to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prometheus-eval/MM-Eval.","first_N":5,"first_N_keywords":["Arabic","Bengali","Catalan","German","English"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-tydiqa","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-tydiqa","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\n\t\n\t\t\n\t\tDataset Card for \"tydiqa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\nin the world. It contains language phenomena that would not be found in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-tydiqa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"thai_handwriting_dataset","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iapp/thai_handwriting_dataset","creator_name":"iApp Technology","creator_url":"https://huggingface.co/iapp","description":"\n\t\n\t\t\n\t\tThai Handwriting Dataset\n\t\n\nThis dataset combines two major Thai handwriting datasets:\n\nBEST 2019 Thai Handwriting Recognition dataset (train-0000.parquet)\nThai Handwritten Free Dataset by Wang (train-0001.parquet onwards)\n\n\n\t\n\t\t\n\t\tMaintainer\n\t\n\nkobkrit@iapp.co.th\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tBEST 2019 Dataset\n\t\n\nContains handwritten Thai text images along with their ground truth transcriptions. The images have been processed and standardized for machine learning tasks.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iapp/thai_handwriting_dataset.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","Thai","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"rag_thai_laws","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iapp/rag_thai_laws","creator_name":"iApp Technology","creator_url":"https://huggingface.co/iapp","description":"\n\t\n\t\t\n\t\tThai Laws Dataset\n\t\n\nThis dataset contains Thai law texts from the Office of the Council of State, Thailand.\nThe dataset has been cleaned and processed by the iApp Team to improve data quality and accessibility. The cleaning process included:\n\nConverting system IDs to integer format\nRemoving leading/trailing whitespace from titles and text\nNormalizing newlines to maintain consistent formatting\nRemoving excessive blank lines\n\nThe cleaned dataset is now available on Hugging Face for easy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iapp/rag_thai_laws.","first_N":5,"first_N_keywords":["text-generation","Thai","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"alpaca_law_documents_qa_v_synthetic","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PaxwellPaxwell/alpaca_law_documents_qa_v_synthetic","creator_name":"Nathapon ponnakarn","creator_url":"https://huggingface.co/PaxwellPaxwell","description":"PaxwellPaxwell/alpaca_law_documents_qa_v_synthetic dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Thai","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"Roleplay-Thai","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Thai","creator_name":"Min Si Thu","creator_url":"https://huggingface.co/jojo-ai-mst","description":"\n\t\n\t\t\n\t\tRolePlay-Thai\n\t\n\nRoleplay-Thai Dataset is a dataset for roleplaying in the Thai language for Large Language Model.\nThe base dataset is GPTeacher role play dataset by teknium 1, which can be found under this link, released under MIT License. The dataset is then translated into respective languages. The translation process is powered by Google Translate, using cloud translation API. \nFor more information and other language datasets for roleplay, it can be found at this github repo.\nFor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Thai.","first_N":5,"first_N_keywords":["text-generation","Thai","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"thai-ocr-evaluation","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openthaigpt/thai-ocr-evaluation","creator_name":"OpenThaiGPT","creator_url":"https://huggingface.co/openthaigpt","description":"\n\t\n\t\t\n\t\tThai OCR Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Thai OCR Evaluation Dataset is designed for evaluating Optical Character Recognition (OCR) models across various domains. It includes images and textual data derived from various open-source websites.\nThis dataset aims to provide a comprehensive evaluation resource for researchers and developers working on OCR systems, particularly in Thai language processing.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach sample in the dataset contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openthaigpt/thai-ocr-evaluation.","first_N":5,"first_N_keywords":["Thai","English","cc-by-sa-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"thaitrocr-eval-dataset-beta","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/suchut/thaitrocr-eval-dataset-beta","creator_name":"Suchut Sapsathien","creator_url":"https://huggingface.co/suchut","description":"\n\t\n\t\t\n\t\tThaiTROCR Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe ThaiTROCR Evaluation Dataset is designed for evaluating Optical Character Recognition (OCR) models across various domains. It includes images and textual data derived from various open-source websites.\nThis dataset aims to provide a comprehensive evaluation resource for researchers and developers working on OCR systems, particularly in Thai language processing.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach sample in the dataset contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suchut/thaitrocr-eval-dataset-beta.","first_N":5,"first_N_keywords":["Thai","English","cc-by-sa-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\nsource: the source sentence.\nchosen: the preferred translation.\nreject: the dis-preferred translation.\ndirections: the translation direction.\n@misc{xu2024xalmaplugplay,\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\n      year={2024},\n      eprint={2410.03115}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"prompt-injection-multilingual","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rikka-snow/prompt-injection-multilingual","creator_name":"Le Xuan Hoang","creator_url":"https://huggingface.co/rikka-snow","description":"rikka-snow/prompt-injection-multilingual dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Vietnamese","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"lexitron2_prompt_finetune","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iapp/lexitron2_prompt_finetune","creator_name":"iApp Technology","creator_url":"https://huggingface.co/iapp","description":"\n\t\n\t\t\n\t\tLexitron 2.0 Prompt Finetuning Dataset\n\t\n\nThis dataset is derived from Lexitron 2.0, a Thai-English dictionary developed by NECTEC. It has been processed and formatted for prompt finetuning tasks. The original dataset is from: https://opend-portal.nectec.or.th/dataset/lexitron-2-0\n\n\t\n\t\t\n\t\tMaintainer\n\t\n\nKobkrit Viriyayudhakorn (kobkrit@iapp.co.th)\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of two main files:\n\nlexitron2_telex_finetune.qwen2.txt - Thai to English lexicon entries‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iapp/lexitron2_prompt_finetune.","first_N":5,"first_N_keywords":["question-answering","Thai","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"thai-ser","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/airesearch/thai-ser","creator_name":"VISTEC-depa AI Research Institute of Thailand","creator_url":"https://huggingface.co/airesearch","description":"\n\t\n\t\t\n\t\tüáπüá≠ THAI-SER Dataset üé≠\n\t\n\n[üìù Paper (preprint)]\nPublished by: AI Research Institute of Thailand (AIResearch)\nIn collaboration with:  \n\nVidyasirimedhi Institute of Science and Technology (VISTEC)  \nDigital Economy Promotion Agency (depa)  \nDepartment of Computer Engineering, Faculty of Engineering, Chulalongkorn University  \nDepartment of Dramatic Arts, Faculty of Arts, Chulalongkorn University\n\nSponsored by: Advanced Info Services Public Company Limited (AIS), and Siam Commercial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/airesearch/thai-ser.","first_N":5,"first_N_keywords":["audio-classification","Thai","cc-by-sa-4.0","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"vqa-v1.1","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldcuisines/vqa-v1.1","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\n\t\n\t\t\n\t\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\n\t\n\n\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 October 2024.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa-v1.1.","first_N":5,"first_N_keywords":["multilingual","English","Indonesian","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"test-plan-lpm","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/naimikky/test-plan-lpm","creator_name":"Suradath Puyati","creator_url":"https://huggingface.co/naimikky","description":"naimikky/test-plan-lpm dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","question-answering","Thai","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"gsm8k-translated","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sara237/gsm8k-translated","creator_name":"Sara Rajaee","creator_url":"https://huggingface.co/Sara237","description":"Sara237/gsm8k-translated dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","German","Spanish","French","Japanese"],"keywords_longer_than_N":true},
	{"name":"g2p_thai_ipa","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Gregniuki/g2p_thai_ipa","creator_name":"Suchow","creator_url":"https://huggingface.co/Gregniuki","description":"\n\t\n\t\t\n\t\tOptional card data\n\t\n\ncardData:\n  tag: audio # Or speech-recognition, speech-processing, etc.\n  language: en # Or the appropriate language code\n  license: apache-2.0 # Or your chosen license\n\n\t\n\t\t\n\t\t--- Crucial Dataset Loading Info ---\n\t\n\n\n\t\n\t\n\t\n\t\tdatasets:\n- dataset_info:\n    # Configuration name\n    config_name: default\n    # How to load the data file(s)\n    data_files:\n    - split: train # Assuming this is your main/training data\n      path: dataset.csv # Path to your CSV file in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gregniuki/g2p_thai_ipa.","first_N":5,"first_N_keywords":["translation","Thai","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","description":"\n\n\n\t\n\t\t\n\t\tüî∑ Accepted in NAACL Proceedings (2025) üî∑\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval üìö [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"tokenizer-robustness-mmlu","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-mmlu","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","description":"\n\t\n\t\t\n\t\tTokenizer Robustness MMLU Dataset\n\t\n\nThis dataset contains MMLU-formatted questions and answers designed to test tokenizer robustness across different text formats and languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of the same questions presented in 6 different formats, with both test (20 questions) and development (5 questions) sets:\n\noriginal - Standard formatted questions\nminor_spelling_errors - Questions with minor misspellings\nspoken_language - Questions in casual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-mmlu.","first_N":5,"first_N_keywords":["English","Russian","Chinese","Japanese","German"],"keywords_longer_than_N":true},
	{"name":"PolyGuardPrompts","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","description":"\n\t\n\t\t\n\t\tPolyGuard: A Multilingual Safety Moderation Tool for 17 Languages\n\t\n\nAbstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts.","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"PM4Bench","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/songjhPKU/PM4Bench","creator_name":"Jiahe Song","creator_url":"https://huggingface.co/songjhPKU","description":"\n\t\n\t\t\n\t\tPM4Bench: A Parallel Multilingual Multi-Modal Multi-task Benchmark for Large Vision Language Model\n\t\n\n\n\n\nüåê Homepage | ü§ó Dataset | üìñ Paper \n\n\t\n\t\t\n\t\tüì¢ News\n\t\n\n\nüî•[2025-03-25]: Dataset available on HuggingFace. Paper available on  arXiv.\n\n\n\n\t\n\t\t\n\t\tüßë‚Äçüíª How to Run?\n\t\n\n\n\n\t\n\t\t\n\t\tüè† Set Up\n\t\n\n\n\t\n\t\t\n\t\tDataset Download\n\t\n\nDownload tsv files from HuggingFace and store them in data/tsv/. The directory should be like data/tsv/{DATASET}_{SETTING}_{LANGUAGE}.tsv.\n\n\t\n\t\t\n\t\tEnvironment‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/songjhPKU/PM4Bench.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"ea-mt-benchmark","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark","creator_name":"Sapienza NLP, Sapienza University of Rome","creator_url":"https://huggingface.co/sapienzanlp","description":"\n\t\n\t\t\n\t\tDataset Card for EA-MT\n\t\n\nEA-MT (Entity-Aware Machine Translation) is a multilingual benchmark for evaluating the capabilities of Large Language Models (LLMs) and Machine Translation (MT) models in translating simple sentences with potentially challenging entity mentions, e.g., entities for which a word-for-word translation may not be accurate.\nHere is an example of a simple sentence with a challenging entity mention:\n\nEnglish: \"What is the plot of The Catcher in the Rye?\"\nItalian:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark.","first_N":5,"first_N_keywords":["text-generation","English","Arabic","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gpt4o_gen","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gpt4o_gen","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gpt4o_gen dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"WanJuan-Thai","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opendatalab/WanJuan-Thai","creator_name":"OpenDataLab","creator_url":"https://huggingface.co/opendatalab","description":"\n\t\n\t\t\n\t\tüí° Introduction\n\t\n\nWanJuan-Thai (‰∏áÂç∑‰∏ùË∑Ø-Ê≥∞ËØ≠) corpus, with a volume exceeding 155GB, comprises 7 major categories and 34 subcategories. It covers a wide range of local-specific content, including history, politics, culture, real estate, shopping, weather, dining, encyclopedias, and professional knowledge. The rich thematic classification not only facilitates researchers in retrieving data according to specific needs but also ensures that the corpus can adapt to diverse research‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opendatalab/WanJuan-Thai.","first_N":5,"first_N_keywords":["text-generation","Thai","cc-by-4.0","arxiv:2501.14506","arxiv:2407.13773"],"keywords_longer_than_N":true},
	{"name":"linkedin-industry-list","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fantastic-jobs/linkedin-industry-list","creator_name":"Fantastic.jobs","creator_url":"https://huggingface.co/fantastic-jobs","description":"fantastic-jobs/linkedin-industry-list dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","translation","English","Korean","Spanish"],"keywords_longer_than_N":true},
	{"name":"thai_exam-reformatted","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RJTPP/thai_exam-reformatted","creator_name":"Rajata Thamcharoensatit","creator_url":"https://huggingface.co/RJTPP","description":"Reformatted version of scb10x/thai_exam\nAdditional Changes:\n\nFix math incorrect answer\n\n‡∏ñ‡πâ‡∏≤ \\log_{\\frac{1}{4}} 256 + \\frac{2\\log 625}{\\log 5} = 3^a ‡πÄ‡∏°‡∏∑‡πà‡∏≠ a ‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á a ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡πÄ‡∏ó‡πà‡∏≤‡πÉ‡∏î?\na. \\log_{3} 2\nb. \\log_{3} 4\nc. \\log_{3} \\frac{33}{4}\nd. \\log_{3} 10\ne. \\log_{3} 12\n\n# Original answer: d (\\log_{3} 10)\n# Correction     : b (\\log_{3} 4)\n\n","first_N":5,"first_N_keywords":["question-answering","Thai","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy It‚Äôs Important\n\t\n\n\nEnhances Trust: For readers and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"thinking-multilingual-30-23-small-690","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \nOr use the \"big\" version: big 10k rows version\n","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Thinking-multilingual-big-10k-sft","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\nenjoy üëç\n","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"jobs_dataset","keyword":"thai","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/vmal/jobs_dataset","creator_name":"Vimal Chaudhari","creator_url":"https://huggingface.co/vmal","description":"vmal/jobs_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","Thai","Japanese","unlicense","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"panlex-definitions","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-definitions","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-definitions\n\t\n\nThis is a dataset of word definitions in several hudnred languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20250201 database dump) and rearranged on the per-language basis (by the language of the definition).\nEach language subset consists of definitions (short phrases).\nEach definition is associated with some meanings (if there is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-definitions.","first_N":5,"first_N_keywords":["translation","Abkhazian","Hijazi Arabic","Afrikaans","Ainu (Japan)"],"keywords_longer_than_N":true},
	{"name":"my-distiset-620d36eb","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kritsanan/my-distiset-620d36eb","creator_name":"namoang","creator_url":"https://huggingface.co/kritsanan","description":"\n  \n    \n  \n\n\n\n\t\n\t\t\n\t\tDataset Card for my-distiset-620d36eb\n\t\n\nThis dataset has been created with distilabel.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a pipeline.yaml which can be used to reproduce the pipeline that generated it in distilabel using the distilabel CLI:\ndistilabel pipeline run --config \"https://huggingface.co/datasets/kritsanan/my-distiset-620d36eb/raw/main/pipeline.yaml\"\n\nor explore the configuration:\ndistilabel pipeline info --config‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kritsanan/my-distiset-620d36eb.","first_N":5,"first_N_keywords":["text-classification","Thai","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"medical-o1-reasoning-SFT-TH","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RJTPP/medical-o1-reasoning-SFT-TH","creator_name":"Rajata Thamcharoensatit","creator_url":"https://huggingface.co/RJTPP","description":"\n\t\n\t\t\n\t\tTranslated medical-o1-reasoning-SFT (TH)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository contains a translated version of the medical-o1-reasoning-SFT.\n\n\t\n\t\t\n\t\tChanges in This Version\n\t\n\n\nFull translation of all Question, Complex_CoT, and Response fields from English to Thai.\nPreserved original dataset structure.\nUsing Gemini 2.0 Flash for translation.\nSome data has been excluded due to translation limitations.\n\n\n\t\n\t\t\n\t\n\t\n\t\tOriginal Dataset Source\n\t\n\nThe original dataset was released under an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RJTPP/medical-o1-reasoning-SFT-TH.","first_N":5,"first_N_keywords":["question-answering","text-generation","Thai","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"datasets","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Athipan01/datasets","creator_name":"C.","creator_url":"https://huggingface.co/Athipan01","description":"\n\t\n\t\t\n\t\tGotdata\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nGotdata ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏° metadata ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏ä‡∏∑‡πà‡∏≠‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏• NLP ‡πÄ‡∏û‡∏∑‡πà‡∏≠:\n\n‡πÅ‡∏¢‡∏Å‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°\n‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏Ñ‡πâ‡∏î (Code Classification)\n‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÇ‡∏Ñ‡πâ‡∏î‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (Code Summarization)\n\n\n\t\n\t\t\n\t\tMetadata\n\t\n\n\nLicense: MIT  \nLanguage: ‡πÑ‡∏ó‡∏¢ (th), ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© (en), ‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô (ja)  \nSize: 10K < n < 100K ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á  \nTags: code, biology\n\n\n\t\n\t\t\n\t\tExample Structure\n\t\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ä‡∏∏‡∏î‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:\n{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Athipan01/datasets.","first_N":5,"first_N_keywords":["text-generation","text-classification","translation","Thai","English"],"keywords_longer_than_N":true},
	{"name":"OpenHumanreasoning-multilingual-2.2k","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\nnote: translations are not human generated.\n","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"LLaVA-CC3M-Pretrain-595K-Thai","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worapob/LLaVA-CC3M-Pretrain-595K-Thai","creator_name":"Worapob Keatkongsang","creator_url":"https://huggingface.co/worapob","description":"\n\t\n\t\t\n\t\tThai-Translated LLaVA-CC3M-Pretrain-595K Dataset\n\t\n\n(LLaVA-CC3M-Pretrain-Thai)\nThis repository contains a Thai translation of the LLaVA-CC3M-Pretrain-595K dataset, originally created by Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. This Thai translation is intended for pre-training large multimodal models with Thai language capabilities.\n\n\t\n\t\t\n\t\tOriginal Dataset\n\t\n\nThe LLaVA-CC3M-Pretrain-595K dataset is a large-scale multimodal pre-training dataset designed to train large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worapob/LLaVA-CC3M-Pretrain-595K-Thai.","first_N":5,"first_N_keywords":["visual-question-answering","Thai","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"SeaBench","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SeaLLMs/SeaBench","creator_name":"SeaLLMs - Language Models for Southeast Asian Languages","creator_url":"https://huggingface.co/SeaLLMs","description":"\nCheck the üèÜ leaderboard constructed with this dataset and the corresponding üë®üèª‚Äçüíª evaluation code.\n\n\n\t\n\t\t\n\t\tSeaBench: Benchmarking LLMs for Southeast Aisa languages with Open-ended Questions\n\t\n\nThis dataset is designed to assess the capabilities of large language models (LLMs) in Southeast Asian (SEA) languages. Specifically, SeaBench evaluates models' multi-turn and instruction-following abilities across Indonesian, Thai, and Vietnamese languages through carefully crafted evaluation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SeaLLMs/SeaBench.","first_N":5,"first_N_keywords":["text-generation","Vietnamese","Indonesian","Thai","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"LAION-art-EN-improved-captions-translate","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaeyong2/LAION-art-EN-improved-captions-translate","creator_name":"jeongjaeyong","creator_url":"https://huggingface.co/jaeyong2","description":"\n\t\n\t\t\n\t\tDevelopment Process\n\t\n\n\nsource dataset from recastai/LAION-art-EN-improved-captions\nWe used Qwen/Qwen2-72B-Instruct model to translate.\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\n\nQwen/Qwen2.5-72B-Instruct : https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/LICENSE\nrecastai/LAION-art-EN-improved-captions : https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/cc-by-4.0.md\n\n\n\t\n\t\t\n\t\n\t\n\t\tAcknowledgement\n\t\n\nThis research is supported by TPU Research Cloud program.\n","first_N":5,"first_N_keywords":["Korean","Japanese","Thai","Vietnamese","Hindi"],"keywords_longer_than_N":true},
	{"name":"MultiTurn-Chat-MT-Bench","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisingapore/MultiTurn-Chat-MT-Bench","creator_name":"AI Singapore","creator_url":"https://huggingface.co/aisingapore","description":"\n\t\n\t\t\n\t\tSEA-MTBench\n\t\n\nSEA-MTBench evaluates a model's ability to engage in multi-turn (2 turns) conversations and respond in ways that align with human needs. We use gpt-4-1106-preview as the judge model and compare against gpt-3.5-turbo-0125 as the baseline model. It is based on MT-Bench and was manually translated by native speakers for Indonesian (id), Javanese (jv), Sundanese (su), and Vietnamese (vi). The Thai split of this dataset uses MT-Bench Thai from the ThaiLLM leaderboard.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aisingapore/MultiTurn-Chat-MT-Bench.","first_N":5,"first_N_keywords":["text-generation","English","Indonesian","Javanese","Sundanese"],"keywords_longer_than_N":true},
	{"name":"NLG-Machine-Translation","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisingapore/NLG-Machine-Translation","creator_name":"AI Singapore","creator_url":"https://huggingface.co/aisingapore","description":"\n\t\n\t\t\n\t\tSEA Machine Translation\n\t\n\nSEA Machine Translation evaluates a model's ability to translate a document from a source language into a target language coherently and fluently. It is sampled from FLORES 200 for Burmese, Chinese, English, Indonesian, Khmer, Malay, Tamil, Thai, and Vietnamese, and NusaX for Indonesian, Javanese, and Sundanese.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nSEA Machine Translation is designed for evaluating chat or instruction-tuned large language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aisingapore/NLG-Machine-Translation.","first_N":5,"first_N_keywords":["text-generation","English","Indonesian","Javanese","Khmer"],"keywords_longer_than_N":true},
	{"name":"NLU-Question-Answering","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisingapore/NLU-Question-Answering","creator_name":"AI Singapore","creator_url":"https://huggingface.co/aisingapore","description":"\n\t\n\t\t\n\t\tSEA Question Answering\n\t\n\nSEA Question Answering evaluates a model's ability to predict a contiguous span of characters that answers the question about a given passage. It is sampled from TyDi QA-GoldP for Indonesian, IndicQA for Tamil, and XQuaD for Thai and Vietnamese.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nSEA Question Answering is designed for evaluating chat or instruction-tuned large language models (LLMs). It is part of the SEA-HELM leaderboard from AI Singapore.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aisingapore/NLU-Question-Answering.","first_N":5,"first_N_keywords":["text-generation","question-answering","Indonesian","Tamil","Thai"],"keywords_longer_than_N":true},
	{"name":"NLU-Sentiment-Analysis","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisingapore/NLU-Sentiment-Analysis","creator_name":"AI Singapore","creator_url":"https://huggingface.co/aisingapore","description":"\n\t\n\t\t\n\t\tSEA Sentiment Analysis\n\t\n\nSEA Sentiment Analysis evaluates a model's ability to identify the sentiment polarity of a text. It is sampled from NusaX for Indonesian, Javanese, and Sundanese, IndicSentiment for Tamil, Wisesight Sentiment for Thai, and UIT-VSFC for Vietnamese.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nSEA Sentiment Analysis is designed for evaluating chat or instruction-tuned large language models (LLMs). It is part of the SEA-HELM leaderboard from AI Singapore.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aisingapore/NLU-Sentiment-Analysis.","first_N":5,"first_N_keywords":["text-generation","text-classification","Indonesian","Javanese","Sundanese"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSynthdog Multilingual\n\t\n\n\n\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Math","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Math","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Math is a dataset of BenchMAX, sourcing from MGSM, which evaluates the math reasoning capability in multilingual scenarios.\nWe extend the original MGSM dataset by six additional languages, i.e. Arabic, Czech, Hungarian, Korean, Serbian, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Math.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Science","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Science","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Science is a dataset of BenchMAX, sourcing from GPQA, which evaluates the natural science reasoning capability in multilingual scenarios.\nWe extend the original English dataset to 16 non-English languages.\nThe data is first translated by Google‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Science.","first_N":5,"first_N_keywords":["question-answering","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Question_Answering","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Question_Answering is a dataset of BenchMAX for evaluating the long-context capability of LLMs in multilingual scenarios.\nThe subtasks are similar to the subtasks in RULER.\nThe data is sourcing from UN Parallel Corpus and xquad.\nThe haystacks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"M-ABSA","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","description":"\n\t\n\t\t\n\t\tM-ABSA\n\t\n\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\n\n\n\t\n\t\t\n\t\tData Description:\n\t\n\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\nAll datasets are stored in the data/ folder:\n\nAll dataset contains 7 domains.\n\ndomains = [\"coursera\", \"hotel\", \"laptop\", \"restaurant\", \"phone\", \"sight\", \"food\"]\n\n\nEach dataset contains 21 languages.\n\nlangs = [\"ar\", \"da\", \"de\", \"en\", \"es\", \"fr\", \"hi\", \"hr\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA.","first_N":5,"first_N_keywords":["token-classification","text-classification","Arabic","Danish","German"],"keywords_longer_than_N":true},
	{"name":"thai-firstname-corpus","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/suchut/thai-firstname-corpus","creator_name":"Suchut Sapsathien","creator_url":"https://huggingface.co/suchut","description":"\n\t\n\t\t\n\t\tThai Firstname Corpus\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Thai Firstname Corpus is a collection of 8,273 unique Thai first names, designed for various linguistic and technological applications. While comprehensive, this dataset may not cover all Thai names in existence.\n\n\t\n\t\t\n\t\tFeatures & Structure\n\t\n\n\nLanguage: Thai (th-TH)\nTotal Names: 8,273\nFormat: Single-field dataset containing only Thai first names\nField:\nname (string) ‚Äì A Thai first name\n\n\n\n\n\t\n\t\t\n\t\tPotential Applications\n\t\n\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suchut/thai-firstname-corpus.","first_N":5,"first_N_keywords":["Thai","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"thai-firstname-corpus","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/suchut/thai-firstname-corpus","creator_name":"Suchut Sapsathien","creator_url":"https://huggingface.co/suchut","description":"\n\t\n\t\t\n\t\tThai Firstname Corpus\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Thai Firstname Corpus is a collection of 8,273 unique Thai first names, designed for various linguistic and technological applications. While comprehensive, this dataset may not cover all Thai names in existence.\n\n\t\n\t\t\n\t\tFeatures & Structure\n\t\n\n\nLanguage: Thai (th-TH)\nTotal Names: 8,273\nFormat: Single-field dataset containing only Thai first names\nField:\nname (string) ‚Äì A Thai first name\n\n\n\n\n\t\n\t\t\n\t\tPotential Applications\n\t\n\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suchut/thai-firstname-corpus.","first_N":5,"first_N_keywords":["Thai","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Chat","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","description":"\n\t\n\t\t\n\t\tDATA-AI: Il Modello di IA di M.INC.\n\t\n\n\n\t\n\t\t\n\t\tüìå Introduzione\n\t\n\nDATA-AI √® un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello √® basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \nDATA-AI √® stato addestrato su un‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat.","first_N":5,"first_N_keywords":["Italian","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"PolyGuardMix","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","description":"\n\t\n\t\t\n\t\tPolyGuard: A Multilingual Safety Moderation Tool for 17 Languages\n\t\n\nAbstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix.","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"MIRACLReranking","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MIRACLReranking","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MIRACLReranking\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://project-miracl.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MIRACLReranking.","first_N":5,"first_N_keywords":["text-ranking","expert-annotated","multilingual","miracl/mmteb-miracl","Arabic"],"keywords_longer_than_N":true},
	{"name":"2M-Belebele","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\t2M-Belebele\n\t\n\n\n\t\n\t\t\n\t\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\n\t\n\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs datasets as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.","first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Bulgarian","Panjabi","English"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\n\t\n\t\t\n\t\tlightblue/reasoning-multilingual-R1-Llama-70B-train\n\t\n\nThis is a multilingual reasoning dataset covering more than 30 languages.\nThis dataset was made by:\n\nSampling prompts from English datasets and translating them to various languages\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\n\nThis dataset was then used to train a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"CoT-XLang","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Egor-AI/CoT-XLang","creator_name":"Egor AI","creator_url":"https://huggingface.co/Egor-AI","description":"RU:CoT-XLang ‚Äî —ç—Ç–æ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç, —Å–æ—Å—Ç–æ—è—â–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ —Å –ø–æ—à–∞–≥–æ–≤—ã–º–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º–∏ (Chain-of-Thought, CoT) –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —è–∑—ã–∫–∞—Ö, –≤–∫–ª—é—á–∞—è –∞–Ω–≥–ª–∏–π—Å–∫–∏–π, —Ä—É—Å—Å–∫–∏–π, —è–ø–æ–Ω—Å–∫–∏–π –∏ –¥—Ä—É–≥–∏–µ. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π –≤ –∑–∞–¥–∞—á–∞—Ö, —Ç—Ä–µ–±—É—é—â–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π —Ä–µ—à–µ–Ω–∏–π —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤. –î–∞—Ç–∞—Å–µ—Ç –≤–∫–ª—é—á–∞–µ—Ç –æ–∫–æ–ª–æ 2,419,912 –ø—Ä–∏–º–µ—Ä–æ–≤, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª–∏, —Å–ø–æ—Å–æ–±–Ω—ã–µ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ—à–∞–≥–æ–≤—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è.\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Egor-AI/CoT-XLang.","first_N":5,"first_N_keywords":["text-generation","question-answering","Russian","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Rule-based","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Rule-based is a dataset of BenchMAX, sourcing from IFEval, which is a rule-based benchmark for evaluating the instruction following capabilities in multilingual scenarios.\nWe extend the original dataset to 16 non-English languages by first‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Model-based","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Model-based is a dataset of BenchMAX, sourcing from m-ArenaHard, which evaluates the instruction following capability via model-based judgment.\nWe extend the original dataset to include languages that are not supported by m-ArenaHard through‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Function_Completion","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from humanevalplus, which evaluates the code generation capability in multilingual scenarios.\nWe extend the original English dataset to 16 non-English languages.\nThe data is first translated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Problem_Solving","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Problem_Solving is a dataset of BenchMAX, sourcing from LiveCodeBench_v4, which evaluates the code generation capability for solving multilingual competitive code problems.\nWe extend the original English dataset by 16 non-English languages.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Multiple_Functions","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Multiple_Functions is a dataset of BenchMAX, sourcing from Nexus.\nThis dataset evaluates the tool use capability in multilingual senarios, which requires a model to call the correct function given the user query and multiple functions.\nWe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_General_Translation","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_General_Translation is a dataset of BenchMAX, which evaluates the translation capability on the general domain.\nWe collect parallel test data from Flore-200, TED-talk, and WMT24.\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\ngit clone‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation.","first_N":5,"first_N_keywords":["translation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Domain_Translation","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Domain_Translation is a dataset of BenchMAX, which evaluates the translation capability on specific domains.\nWe collect the domain multi-way parallel data from other tasks in BenchMAX, such as math data, code data, etc.\nEach sample contains one‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation.","first_N":5,"first_N_keywords":["translation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"P-MMEval","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Qwen/P-MMEval","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","description":"\n\t\n\t\t\n\t\tP-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWe introduce a multilingual benchmark, P-MMEval, covering effective fundamental and capability-specialized datasets. We extend the existing benchmarks, ensuring consistent language coverage across all datasets and providing parallel samples among multiple languages, supporting up to 10 languages from 8 language families (i.e., en, zh, ar, es, ja, ko, th, fr, pt, vi). As a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Qwen/P-MMEval.","first_N":5,"first_N_keywords":["Arabic","Spanish","French","Japanese","Korean"],"keywords_longer_than_N":true},
	{"name":"thai-gov-procurement_regulation-17-amend-21","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amornpan/thai-gov-procurement_regulation-17-amend-21","creator_name":"Amornpan Phornchaicharoen","creator_url":"https://huggingface.co/amornpan","description":"\n\t\n\t\t\n\t\tüáπüá≠ Dataset Card for Thai Government Procurement Dataset\n\t\n\n\n\t\n\t\t\n\t\t‚ÑπÔ∏è This dataset is optimized for procurement-related NLP tasks in Thai.\n\t\n\nThis dataset contains a collection of procurement regulations, instructions, and responses focused on public sector purchasing, contract management, and compliance with Thai government standards. It aims to support natural language processing tasks involving procurement assistance, such as chatbot development, procurement dialogue generation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/amornpan/thai-gov-procurement_regulation-17-amend-21.","first_N":5,"first_N_keywords":["question-answering","text-classification","Thai","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"thai-gov-procurement_regulation-17-amend-21","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amornpan/thai-gov-procurement_regulation-17-amend-21","creator_name":"Amornpan Phornchaicharoen","creator_url":"https://huggingface.co/amornpan","description":"\n\t\n\t\t\n\t\tüáπüá≠ Dataset Card for Thai Government Procurement Dataset\n\t\n\n\n\t\n\t\t\n\t\t‚ÑπÔ∏è This dataset is optimized for procurement-related NLP tasks in Thai.\n\t\n\nThis dataset contains a collection of procurement regulations, instructions, and responses focused on public sector purchasing, contract management, and compliance with Thai government standards. It aims to support natural language processing tasks involving procurement assistance, such as chatbot development, procurement dialogue generation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/amornpan/thai-gov-procurement_regulation-17-amend-21.","first_N":5,"first_N_keywords":["question-answering","text-classification","Thai","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tBelebele-Fleurs\n\t\n\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\n\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"WisesightSentimentClassification","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/WisesightSentimentClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  WisesightSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nWisesight Sentiment Corpus: Social media messages in Thai language with sentiment label (positive, neutral, negative, question)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, News, Written\nReference\nhttps://github.com/PyThaiNLP/wisesight-sentiment\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/WisesightSentimentClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"shp_translations","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/david9dragon9/shp_translations","creator_name":"David Wu","creator_url":"https://huggingface.co/david9dragon9","description":"This dataset contains translations of three splits (askscience, explainlikeimfive, legaladvice) of the Stanford Human Preference (SHP) dataset, used for training domain-invariant reward models.\nThe translation was conducted using the No Language Left Behind (NLLB) 3.3 B 200 model.\nReferences:\nStanford Human Preference Dataset: https://huggingface.co/datasets/stanfordnlp/SHP\nNLLB: https://huggingface.co/facebook/nllb-200-3.3B\n","first_N":5,"first_N_keywords":["question-answering","English","Korean","Chinese","Thai"],"keywords_longer_than_N":true},
	{"name":"Dataset_com_Laws_1039","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Avocaduu14/Dataset_com_Laws_1039","creator_name":"Nuttapong Wongchai","creator_url":"https://huggingface.co/Avocaduu14","description":"\n\t\n\t\t\n\t\tDataset Card act of legislation in Thailand.\n\t\n\nThe dataset contains problem act of legislation in Thailand.\nThis dataset is taken from (https://www.drthawip.com/), comes from the government website.\n","first_N":5,"first_N_keywords":["question-answering","Thai","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"SMPQA","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/SMPQA","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\n\t\n\t\tSMPQA (Synthetic Multilingual Plot QA)\n\t\n\n\n\nThe SMPQA evaluation dataset proposed in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nSMPQA is composed of synthetic bar plots and pie charts (generated using word lists of different languages) together with questions about those plots.\nThe datasets aims at providing an initial way of evaluating multilingual OCR capabilities of models in arbritrary languages.\nThere are two sub-tasks: \n\nGrounding text labels‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/SMPQA.","first_N":5,"first_N_keywords":["visual-question-answering","English","Zulu","Indonesian","Italian"],"keywords_longer_than_N":true},
	{"name":"wongnai-restaurant-review","keyword":"thai","license":"GNU Lesser General Public License v3.0","license_url":"https://choosealicense.com/licenses/lgpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iamwarint/wongnai-restaurant-review","creator_name":"Warintorn Jampasee","creator_url":"https://huggingface.co/iamwarint","description":"\n\t\n\t\t\n\t\tDataset Card for wongnai-restaurant-review\n\t\n\nThis is a large-scale Wongnai Reviews dataset, collected in 2025 by Warintorn J.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains reviews collected from the Wongnai platform, a popular online restaurant review site in Thailand. It includes customer reviews and their associated ratings (stars) for various restaurants. This dataset is useful for natural language processing tasks such as sentiment analysis, review classification, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iamwarint/wongnai-restaurant-review.","first_N":5,"first_N_keywords":["text-classification","Thai","lgpl-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xm100","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM100\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"thai-w2p-ipa","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/B-K/thai-w2p-ipa","creator_name":"BoatKunGG","creator_url":"https://huggingface.co/B-K","description":"\n\t\n\t\t\n\t\tThai W2P with IPA\n\t\n\nThai W2P data from: https://huggingface.co/datasets/wannaphong/thai-w2p\nTranscribed pronunciation to phonemic IPA using https://gist.github.com/Boatkungg/cdb00ed7e61209e9caa0852a2e673d2e\n","first_N":5,"first_N_keywords":["Thai","apache-2.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Wiki-th-20250601","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Blaze7451/Wiki-th-20250601","creator_name":"Lung-Chuan Chen","creator_url":"https://huggingface.co/Blaze7451","description":"\n\t\n\t\t\n\t\tDataset Card for Wiki-th-20250601\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is derived from the Thailand‚ÄëWikipedia dump dated 2025‚Äë06‚Äë01, downloaded from Wikimedia.Articles were extracted from the original .xml.bz2 archive with Gensim and converted to Markdown format via regular‚Äëexpression post‚Äëprocessing.\n","first_N":5,"first_N_keywords":["text-generation","monolingual","wikipedia","Thai","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"llm-metric-mgsm","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rubricreward/llm-metric-mgsm","creator_name":"rubricreward","creator_url":"https://huggingface.co/rubricreward","description":"rubricreward/llm-metric-mgsm dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["found","found","expert-generated","multilingual","extended|gsm8k"],"keywords_longer_than_N":true},
	{"name":"quran_multilingual_parallel","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/quran_multilingual_parallel","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüìò Qur‚Äôan Multilingual Parallel Dataset (quran_multilingual_parallel)\n\t\n\nThis dataset presents a clean, structurally-aligned multilingual parallel corpus of the Qur‚Äôanic text. It is intended for linguistic, computational, and cross-lingual AI applications ‚Äî not only for religious interpretation.\nIt contains over 6,200 verse-level alignments in 54 human languages, formatted in a machine-friendly .csv structure with language-specific translation fields.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüß† Dataset Highlights‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/quran_multilingual_parallel.","first_N":5,"first_N_keywords":["translation","Arabic","Albanian","Amharic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"wikipedia-citation-index","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia-citation-index","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Dataset with citation indexes as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions. Research: ArXiv\n","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"math_onet","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TaengooTV/math_onet","creator_name":"Phichet Phuangrot","creator_url":"https://huggingface.co/TaengooTV","description":"TaengooTV/math_onet dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Thai","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"thai-w2p","keyword":"thai","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wannaphong/thai-w2p","creator_name":"Wannaphong Phatthiyaphaibun","creator_url":"https://huggingface.co/wannaphong","description":"\n\t\n\t\t\n\t\tThai W2P\n\t\n\nThai Word-to-Phoneme (W2P) converter.\nGitHub: https://github.com/wannaphong/thai_w2p\n","first_N":5,"first_N_keywords":["Thai","cc0-1.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Medical-Multimodal-EN-TH","keyword":"thai","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZombitX64/Medical-Multimodal-EN-TH","creator_name":"ZomBitX64","creator_url":"https://huggingface.co/ZombitX64","description":"\n\t\n\t\t\n\t\tHealthGPTVL-Translation Medical-Multimodal-EN-TH\n\t\n\nThis dataset is a bilingual (English-Thai) medical multimodal evaluation dataset containing medical images with corresponding question-answer pairs for visual question answering and translation tasks.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 17,047 medical image-text pairs designed for multimodal medical AI evaluation. It includes medical images from various imaging modalities (MRI, CT, X-Ray‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZombitX64/Medical-Multimodal-EN-TH.","first_N":5,"first_N_keywords":["image-classification","image-to-text","translation","visual-question-answering","English"],"keywords_longer_than_N":true},
	{"name":"moscar-corpus-thai-cleaned","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZombitX64/moscar-corpus-thai-cleaned","creator_name":"ZomBitX64","creator_url":"https://huggingface.co/ZombitX64","description":"\n\t\n\t\t\n\t\tDataset mOSCAR Thai Cleaned\n\t\n\n‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ (NLP) ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤ ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏• ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤ ‡∏Ø‡∏•‡∏Ø\n\n\n\t\n\t\t\n\t\t‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n\t\n\n\n‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: 1,643,471 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (train)\n‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: 5,132,779,656 ‡πÑ‡∏ö‡∏ï‡πå\n‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå:  \ntitle (string): ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á  \ntext (string): ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß\n\n\n‡∏†‡∏≤‡∏©‡∏≤: ‡πÑ‡∏ó‡∏¢ (th)\n‡∏•‡∏¥‡∏Ç‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå: Apache-2.0\n‡∏Ç‡∏ô‡∏≤‡∏î: 1M < n < 10M‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZombitX64/moscar-corpus-thai-cleaned.","first_N":5,"first_N_keywords":["text-generation","Thai","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"Sentiment-Analysis-TH","keyword":"thai","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BioneX/Sentiment-Analysis-TH","creator_name":"Charuwat","creator_url":"https://huggingface.co/BioneX","description":"BioneX/Sentiment-Analysis-TH dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Thai","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Thai-corpus-word","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZombitX64/Thai-corpus-word","creator_name":"ZomBitX64","creator_url":"https://huggingface.co/ZombitX64","description":"\n\t\n\t\t\n\t\tThai Combined Corpus\n\t\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å tokenizer/LLM\n","first_N":5,"first_N_keywords":["Thai","apache-2.0","10M - 100M","text","Text"],"keywords_longer_than_N":true},
	{"name":"Thai-corpus-word","keyword":"thai","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZombitX64/Thai-corpus-word","creator_name":"ZomBitX64","creator_url":"https://huggingface.co/ZombitX64","description":"\n\t\n\t\t\n\t\tThai Combined Corpus\n\t\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å tokenizer/LLM\n","first_N":5,"first_N_keywords":["Thai","apache-2.0","10M - 100M","text","Text"],"keywords_longer_than_N":true},
	{"name":"Wisesight-Sentiment-Thai","keyword":"thai","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZombitX64/Wisesight-Sentiment-Thai","creator_name":"ZomBitX64","creator_url":"https://huggingface.co/ZombitX64","description":"\n\t\n\t\t\n\t\tDataset Card for Zombitx64 Sentiment Corpus Thai\n\t\n\nThis dataset card describes the \"Zombitx64 Sentiment Corpus Thai,\" a large-scale, manually curated corpus for Thai sentiment analysis and token classification.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Zombitx64 Sentiment Corpus Thai is a collection of Thai-language social media comments and posts, annotated for sentiment at the sentence or token level. The dataset covers a wide range of topics and emotional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZombitX64/Wisesight-Sentiment-Thai.","first_N":5,"first_N_keywords":["token-classification","Thai","cc-by-sa-4.0","100K - 1M","json"],"keywords_longer_than_N":true}
]
;
