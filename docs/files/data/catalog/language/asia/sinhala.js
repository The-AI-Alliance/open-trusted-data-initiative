const data_for_language_asia_sinhala = 
[
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following boolean‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Quixi AI","creator_url":"https://huggingface.co/QuixiAI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"sinhala","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture","keyword":"sinhala","description":"\n\n\n\t\n\t\t\n\t\tTulu 3 SFT Mixture\n\t\n\nNote that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe Tulu 3 SFT mixture was used to train the Tulu 3 series of models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"c4","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tC4\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA colossal, cleaned version of Common Crawl's web crawl corpus. Based on Common Crawl dataset: \"https://commoncrawl.org\".\nThis is the processed version of Google's C4 dataset\nWe prepared five variants of the data: en, en.noclean, en.noblocklist, realnewslike, and multilingual (mC4).\nFor reference, these are the sizes of the variants:\n\nen: 305GB\nen.noclean: 2.3TB\nen.noblocklist: 380GB\nrealnewslike: 15GB\nmultilingual (mC4): 9.7TB (108 subsets, one per‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/c4.","url":"https://huggingface.co/datasets/allenai/c4","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"Sinhala-Neuspellcorrector","keyword":"sinhala","description":"This repository contains the dataset for paper \"A Neural Spell Corrector and a baseline for Sinhala SpellCorrection\"\n","url":"https://huggingface.co/datasets/NLPC-UOM/Sinhala-Neuspellcorrector","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["Sinhala","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"udhr-lid","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","Metlat√≥noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"CC-Cat","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tCC_Cat\n\t\n\n\nExtract from CC-WARC snapshots.\nMainly includes texts with 149 languages.\nPDF/IMAGE/AUDIO/VIDEO raw downloading link.\n\n\n\t\n\t\t\n\t\tNotice\n\t\n\n\nSince my computing resources are limited, this dataset will update by one-day of CC snapshots timestampts.\nAfter a snapshot is updated, the deduplicated version will be uploaded.\nIf you are interested in providing computing resources or have cooperation needs, please contact me.\n  carreyallthetime@gmail.com  \n      \n  \n\n","url":"https://huggingface.co/datasets/chengshidehaimianti/CC-Cat","creator_name":"zyq","creator_url":"https://huggingface.co/chengshidehaimianti","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","English","German","Russian"],"keywords_longer_than_N":true},
	{"name":"Tamil-Sinhala-short-sentence-similarity-deep-learning","keyword":"sinhala","description":"This research focuses on finding the best possible deep learning-based techniques to measure the short sentence similarity for low-resourced languages, focusing on Tamil and Sinhala sort sentences by utilizing existing unsupervised techniques for English. Original repo available on https://github.com/nlpcuom/Tamil-Sinhala-short-sentence-similarity-deep-learning\nIf you use this dataset, cite Nilaxan, S., & Ranathunga, S. (2021, July). Monolingual sentence similarity measurement using siamese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Tamil-Sinhala-short-sentence-similarity-deep-learning.","url":"https://huggingface.co/datasets/NLPC-UOM/Tamil-Sinhala-short-sentence-similarity-deep-learning","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["Tamil","Sinhala","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Writing-style-classification","keyword":"sinhala","description":"This file contains news texts (sentences) belonging to different writing styles. The original dataset created by {Upeksha, D., Wijayarathna, C., Siriwardena, M.,\nLasandun, L., Wimalasuriya, C., de Silva, N., and Dias, G. (2015). Implementing a corpus for Sinhala language. 01}is processed and cleaned.\nIf you use this dataset, please cite {Dhananjaya et al. BERTifying Sinhala - A Comprehensive Analysis of Pre-trained Language Models for Sinhala Text Classification, 2022} and the above mentioned‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Writing-style-classification.","url":"https://huggingface.co/datasets/NLPC-UOM/Writing-style-classification","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","monolingual","Sinhala","mit"],"keywords_longer_than_N":true},
	{"name":"multi_para_crawl","keyword":"sinhala","description":"Parallel corpora from Web Crawls collected in the ParaCrawl project and further processed for making it a multi-parallel corpus by pivoting via English. Here we only provide the additional language pairs that came out of pivoting. The bitexts for English are available from the ParaCrawl release.\n40 languages, 669 bitexts\ntotal number of files: 40\ntotal number of tokens: 10.14G\ntotal number of sentence fragments: 505.48M\n\nPlease, acknowledge the ParaCrawl project at http://paracrawl.eu. This version is derived from the original release at their website adjusted for redistribution via the OPUS corpus collection. Please, acknowledge OPUS as well for this service.","url":"https://huggingface.co/datasets/Helsinki-NLP/multi_para_crawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"finepdfs","keyword":"sinhala","description":"\n\nLiberating 3T of the finest tokens from PDFs\n\n\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nAs we run out of web pages to process, the natural question has always been: what to do next? Only a few knew about a data source that everyone avoided for ages, due to its incredible extraction cost and complexity: PDFs.\nüìÑ FinePDFs is exactly that. It is the largest publicly available corpus sourced exclusively from PDFs, containing about 3 trillion tokens across 475 million documents in 1733 languages.\nCompared to HTML‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/finepdfs.","url":"https://huggingface.co/datasets/HuggingFaceFW/finepdfs","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"teacher","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tCreate a README.md file with a description of the dataset\n\t\n\nreadme_content = \"\"\"\n\n\t\n\t\t\n\t\tSinhala Language Dataset for Educational Questions\n\t\n\nThis dataset contains Sinhala-language educational questions and their answers, specifically designed for the Sri Lankan educational curriculum. It includes instructions, optional inputs, and corresponding outputs.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nLanguage: Sinhala\nPurpose: For use in machine learning models for educational purposes, such as QA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/enzer1992/teacher.","url":"https://huggingface.co/datasets/enzer1992/teacher","creator_name":"Sunil Jayamanna","creator_url":"https://huggingface.co/enzer1992","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Sinhala","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"sinhala","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"SystemChat_Sinhala","keyword":"sinhala","description":"This is a SystemChat dataset for Sinhala\n","url":"https://huggingface.co/datasets/cognitivecomputations/SystemChat_Sinhala","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Sinhala","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"x-fact","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Card for \"x-fact\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while the language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact.","url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","Bengali","Spanish","Persian"],"keywords_longer_than_N":true},
	{"name":"SinhalaNewsClassification","keyword":"sinhala","description":"\n  SinhalaNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis file contains news texts (sentences) belonging to 5 different news categories (political, business, technology, sports and Entertainment). The original dataset was released by Nisansa de Silva (Sinhala Text Classification: Observations from the Perspective of a Resource Poor Language, 2015).\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SinhalaNewsClassification.","url":"https://huggingface.co/datasets/mteb/SinhalaNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","NLPC-UOM/Sinhala-News-Category-classification"],"keywords_longer_than_N":true},
	{"name":"sinhala-articles","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tSinhala Articles Dataset\n\t\n\nA large-scale, high-quality Sinhala text corpus curated from diverse sources including news articles, Wikipedia entries, and general web content. This dataset is designed to support a wide range of Sinhala Natural Language Processing (NLP) tasks.\n\n\n\t\n\t\t\n\t\tüìä Dataset Overview\n\t\n\n\nName: Navanjana/sinhala-articles\nTotal Samples:  2,148,688\nLanguages: Sinhala (si)\nFeatures:\ntext: A single column containing Sinhala text passages.\n\n\nSize: Approximately 1M < n <‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Navanjana/sinhala-articles.","url":"https://huggingface.co/datasets/Navanjana/sinhala-articles","creator_name":"Navanjana","creator_url":"https://huggingface.co/Navanjana","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Sinhala","apache-2.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"sinhala-articles","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tSinhala Articles Dataset\n\t\n\nA large-scale, high-quality Sinhala text corpus curated from diverse sources including news articles, Wikipedia entries, and general web content. This dataset is designed to support a wide range of Sinhala Natural Language Processing (NLP) tasks.\n\n\n\t\n\t\t\n\t\tüìä Dataset Overview\n\t\n\n\nName: Navanjana/sinhala-articles\nTotal Samples:  2,148,688\nLanguages: Sinhala (si)\nFeatures:\ntext: A single column containing Sinhala text passages.\n\n\nSize: Approximately 1M < n <‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Navanjana/sinhala-articles.","url":"https://huggingface.co/datasets/Navanjana/sinhala-articles","creator_name":"Navanjana","creator_url":"https://huggingface.co/Navanjana","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Sinhala","apache-2.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"montok","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tTraining Details\n\t\n\n\n\t\n\t\t\n\t\tTraining Data\n\t\n\nAll tokenizers are trained on samples of the data used to the train the Goldfish language models. \nThe tokenizers were either trained on scaled or unscaled data. This refers to whether the models are trained on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/montok.","url":"https://huggingface.co/datasets/catherinearnett/montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"si-wiki-OCR-synth-deduped","keyword":"sinhala","description":"Suchinthana/si-wiki-OCR-synth-deduped dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Suchinthana/si-wiki-OCR-synth-deduped","creator_name":"Wijesundara","creator_url":"https://huggingface.co/Suchinthana","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Sinhala","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"fiNERweb","keyword":"sinhala","description":"fiNERweb is a multilingual named entity recognition dataset containing annotated text in multiple languages.\nEach example contains the original text, tokenized text, BIO tags, and character/token spans for entities.","url":"https://huggingface.co/datasets/whoisjones/fiNERweb","creator_name":"Jonas Golde","creator_url":"https://huggingface.co/whoisjones","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","Vietnamese","Tamil","Oriya"],"keywords_longer_than_N":true},
	{"name":"sinhala-political-science-gce-alevel-2021-questions","keyword":"sinhala","description":"ov1n/sinhala-political-science-gce-alevel-2021-questions dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ov1n/sinhala-political-science-gce-alevel-2021-questions","creator_name":"Thenuka Weerasinghe","creator_url":"https://huggingface.co/ov1n","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Sinhala","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"sinhala","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Tatoeba-Translations","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the latest version of Tatoeba translations as of December 2024.\nThe sentences are downloaded from the Tatoeba collection website.\nThe dataset is processed through mapping sentences.tar.bz2 using sentences_base.tar.bz2 to find source (sentence_src) and target (sentence_tgt) sentences.\nWhile lang_src and lang_tgt columns follow the mapping provided by Tatoeba, the lang_pair column merely lists the two languages in the translation pair.\n\n\t\n\t\t\n\t\n\t\n\t\tStatistics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-Translations.","url":"https://huggingface.co/datasets/ymoslem/Tatoeba-Translations","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","multilingual","Abkhaz","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"Sinhala-News-Source-classification","keyword":"sinhala","description":"This dataset contains Sinhala news headlines extracted from 9 news sources (websites) (Sri Lanka Army, Dinamina, GossipLanka, Hiru, ITN, Lankapuwath, NewsLK,\nNewsfirst, World Socialist Web Site-Sinhala). This is a processed version of the corpus created by Sachintha, D., Piyarathna, L., Rajitha, C., and Ranathunga, S. (2021). Exploiting parallel corpora to improve multilingual embedding based document and sentence alignment. Single word sentences, invalid characters have been removed from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Source-classification.","url":"https://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Source-classification","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","monolingual","Sinhala","mit"],"keywords_longer_than_N":true},
	{"name":"Sinhala-Tamil-Aligned-Parallel-Corpus","keyword":"sinhala","description":"NLPC-UOM/Sinhala-Tamil-Aligned-Parallel-Corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/NLPC-UOM/Sinhala-Tamil-Aligned-Parallel-Corpus","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Sinhala","mit","1K - 10K","text","Text"],"keywords_longer_than_N":true},
	{"name":"bernice-pretrain-data","keyword":"sinhala","description":"Tweet IDs for the 2.5 billion multilingual tweets used to train Bernice, a Twitter encoder.\nThe tweets are from the public 1% Twitter API stream from January 2016 to December 2021. \nTwitter-provided language metadata is provided with the tweet ID. The data contains 66 unique languages, \nas identified by ISO 639 language codes, including `und` for undefined languages.\nTweets need to be re-gathered via the Twitter API.","url":"https://huggingface.co/datasets/jhu-clsp/bernice-pretrain-data","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","no-annotation","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"sinhala","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"SinhalaCorpusLarge","keyword":"sinhala","description":"LexiconShiftInnovations/SinhalaCorpusLarge dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/LexiconShiftInnovations/SinhalaCorpusLarge","creator_name":"LexiconShift Innovations","creator_url":"https://huggingface.co/LexiconShiftInnovations","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Sinhala","apache-2.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"MWP_Dataset","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tMWP-Dataset\n\t\n\nEnglish-Sinhala-Tamil Math Word Problem Dataset\n\n\t\n\t\t\n\t\tFile Structure\n\t\n\n\nSimple-English.txt -> Simple English Math Word Problems\nSimple-Sinhala.txt -> Simple Sinhala Math Word Problems\nSimple-Tamil.txt -> Simple Tamil Math Word Problems\nAlgebraic-English.txt -> Algebraic English Math Word Problems\nAlgebraic-Sinhala.txt -> Algebraic Sinhala Math Word Problems\nAlgebraic-Tamil.txt -> Algebraic Tamil Math Word Problems\n\nCitation: Niyarepola, K., Athapaththu, D., Ekanayake‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/MWP_Dataset.","url":"https://huggingface.co/datasets/NLPC-UOM/MWP_Dataset","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Sinhala","Tamil","English","mit"],"keywords_longer_than_N":true},
	{"name":"nllb-200-10M-sample","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Card for \"nllb-200-10M-sample\"\n\t\n\nThis is a sample of nearly 10M sentence pairs from the NLLB-200 \nmined dataset allenai/nllb, \nscored with the model facebook/blaser-2.0-qe \ndescribed in the SeamlessM4T paper.\nThe sample is not random; instead, we just took the top n sentence pairs from each translation direction.\nThe number n was computed with the goal of upsamping the directions that contain underrepresented languages.\nNevertheless, the 187 languoids (language and script‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slone/nllb-200-10M-sample.","url":"https://huggingface.co/datasets/slone/nllb-200-10M-sample","creator_name":"SLONE","creator_url":"https://huggingface.co/slone","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Akan","Amharic","Arabic","Awadhi"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Viet-Mistral/CulturaY.","url":"https://huggingface.co/datasets/Viet-Mistral/CulturaY","creator_name":"Vietnamese Mistral","creator_url":"https://huggingface.co/Viet-Mistral","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"Sinhala-QA-Translate","keyword":"sinhala","description":"Suchinthana/Sinhala-QA-Translate dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Suchinthana/Sinhala-QA-Translate","creator_name":"Wijesundara","creator_url":"https://huggingface.co/Suchinthana","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","Sinhala","English","mit"],"keywords_longer_than_N":true},
	{"name":"Sentiment-tagger","keyword":"sinhala","description":"Sentiment Analysis of Sinhala News Comments\nDataset used in this project is collected by crawling Sinhala online news sites, mainly www.lankadeepa.lk.\ncontact\nPlease contact us if you need more information.\nSurangika Ranathunga-surangika@cse.mrt.ac.lk\nIsuru Liyanage-theisuru@gmail.com\nhttps://github.com/theisuru/sentiment-tagger\ncite\nIf you use this data please cite this work\nRanathunga, S., & Liyanage, I. U. (2021). Sentiment Analysis of Sinhala News Comments. Transactions on Asian and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Sentiment-tagger.","url":"https://huggingface.co/datasets/NLPC-UOM/Sentiment-tagger","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Sinhala","mit","10K - 100K","text","Text"],"keywords_longer_than_N":true},
	{"name":"Sinhala-English-Code-Mixed-Code-Switched-Dataset","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tSinhala-English-Code-Mixed-Code-Switched-Dataset\n\t\n\nThis dataset contains 10,000 comments that have been annotated at the sentence level for sentiment analysis, humor detection, hate speech detection, aspect identification, and language identification.\nThe following is the tag scheme.\n\nSentiment -  Positive, Negative, Neutral,  Conflict\nHumor - Humorous, Non humorous\nHate Speech - Hate-Inducing, Abusive, Not offensive\nAspect - Network, Billing or Price, Package, Customer Service, Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Sinhala-English-Code-Mixed-Code-Switched-Dataset.","url":"https://huggingface.co/datasets/NLPC-UOM/Sinhala-English-Code-Mixed-Code-Switched-Dataset","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","hate-speech-detection","language-identification","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"sinhala","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"sinhala","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"CleanSinhalaTextCorpus","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tüìö Cleaned Sinhala Text Corpus\n\t\n\nThe Cleaned Sinhala Text Corpus is a large-scale, high-quality Sinhala text dataset prepared and released by Remeinium.\n\n\t\n\t\t\n\t\tüìÑ Sample Data (randomly copied from 4 different files)\n\t\n\n‡∑Ä‡∑í‡∑Ä‡∑ò‡∂≠ ‡∂¥‡∑î‡∂©‡∑î ‡∂Ö‡∑Ä‡∑É‡∑ä‡∂Æ‡∑è‡∑Ä‡∑ö ‡∑Ä‡∑í‡∑Ä‡∑ò‡∂≠ ‡∂¥‡∑î‡∂©‡∑î ‡∂Ω‡∑è‡∂∑‡∂∫ ‡∂ö‡∑è‡∂ª‡∂ö‡∑è‡∂≠‡∑ä‡∂∏‡∂ö ‡∑Ä‡∂ª‡∑ä‡∂∞‡∂ö‡∂∫‡∂ö ‡∂â‡∂≠‡∑è ‡∑Ä‡∑í‡∑Å‡∑è‡∂Ω‡∂∫ ‡∂ë‡∂∫ ‡∂¥‡∂ª‡∑è‡∑É‡∂∫‡∑ö ‡∑Ä‡∑ö ‡∂ë‡∂±‡∑í‡∑É‡∑è ‡∂ö‡∑î‡∂©‡∑è ‡∂¥‡∑ä‡∂ª‡∂Ø‡∑è‡∂± ‡∑Ä‡∑ù‡∂Ω‡∑ä‡∂ß‡∑ì‡∂∫‡∂≠‡∑è‡∑Ä‡∂ö‡∂ß ‡∑Ä‡∑î‡∑Ä‡∂Ø ‡∑Ä‡∑í‡∑Å‡∑è‡∂Ω ‡∂¥‡∑ä‡∂ª‡∂≠‡∑í‡∂Ø‡∑è‡∂± ‡∑Ä‡∑ù‡∂Ω‡∑ä‡∂ß‡∑ì‡∂∫‡∂≠‡∑è‡∑Ä‡∂ö‡∑ä ‡∂Ω‡∂∂‡∑è ‡∂Ø‡∑ì‡∂∏‡∑ö ‡∑Ñ‡∑ê‡∂ö‡∑í‡∂∫‡∑è‡∑Ä ‡∂á‡∂≠ ‡∂ë‡∂±‡∂∏‡∑ä ‡∂¥‡∑ä‡∂ª‡∂Ø‡∑è‡∂± ‡∑Ä‡∑ù‡∂Ω‡∑ä‡∂ß‡∑ì‡∂∫‡∂≠‡∑è ‡∂ö‡∑î‡∂©‡∑è ‡∂¥‡∂ª‡∑è‡∑É‡∂∫‡∂ö‡∑ä ‡∂≠‡∑î‡∑Ö ‡∑Ä‡∑ê‡∂©‡∑í ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∑ö‡∂Ø‡∑ì ‡∂¥‡∑ä‡∂ª‡∂≠‡∑í‡∂Ø‡∑è‡∂± ‡∑Ä‡∑ù‡∂Ω‡∑í‡∂ß‡∑ì‡∂∫‡∂≠‡∑è‡∑Ä ‡∑Ä‡∑í‡∑Å‡∑è‡∂Ω ‡∂¥‡∂ª‡∑è‡∑É‡∂∫‡∂ö‡∑ä ‡∂≠‡∑î‡∑Ö ‡∑Ä‡∑ê‡∂©‡∑í ‡∑Ä‡∑ö\n‡∂∏‡∑ô‡∑É‡∑ö‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Remeinium/CleanSinhalaTextCorpus.","url":"https://huggingface.co/datasets/Remeinium/CleanSinhalaTextCorpus","creator_name":"Remeinium AI","creator_url":"https://huggingface.co/Remeinium","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","token-classification","Sinhala","cc-by-4.0","10M<n<100M"],"keywords_longer_than_N":true},
	{"name":"CleanSinhalaTextCorpus","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tüìö Cleaned Sinhala Text Corpus\n\t\n\nThe Cleaned Sinhala Text Corpus is a large-scale, high-quality Sinhala text dataset prepared and released by Remeinium.\n\n\t\n\t\t\n\t\tüìÑ Sample Data (randomly copied from 4 different files)\n\t\n\n‡∑Ä‡∑í‡∑Ä‡∑ò‡∂≠ ‡∂¥‡∑î‡∂©‡∑î ‡∂Ö‡∑Ä‡∑É‡∑ä‡∂Æ‡∑è‡∑Ä‡∑ö ‡∑Ä‡∑í‡∑Ä‡∑ò‡∂≠ ‡∂¥‡∑î‡∂©‡∑î ‡∂Ω‡∑è‡∂∑‡∂∫ ‡∂ö‡∑è‡∂ª‡∂ö‡∑è‡∂≠‡∑ä‡∂∏‡∂ö ‡∑Ä‡∂ª‡∑ä‡∂∞‡∂ö‡∂∫‡∂ö ‡∂â‡∂≠‡∑è ‡∑Ä‡∑í‡∑Å‡∑è‡∂Ω‡∂∫ ‡∂ë‡∂∫ ‡∂¥‡∂ª‡∑è‡∑É‡∂∫‡∑ö ‡∑Ä‡∑ö ‡∂ë‡∂±‡∑í‡∑É‡∑è ‡∂ö‡∑î‡∂©‡∑è ‡∂¥‡∑ä‡∂ª‡∂Ø‡∑è‡∂± ‡∑Ä‡∑ù‡∂Ω‡∑ä‡∂ß‡∑ì‡∂∫‡∂≠‡∑è‡∑Ä‡∂ö‡∂ß ‡∑Ä‡∑î‡∑Ä‡∂Ø ‡∑Ä‡∑í‡∑Å‡∑è‡∂Ω ‡∂¥‡∑ä‡∂ª‡∂≠‡∑í‡∂Ø‡∑è‡∂± ‡∑Ä‡∑ù‡∂Ω‡∑ä‡∂ß‡∑ì‡∂∫‡∂≠‡∑è‡∑Ä‡∂ö‡∑ä ‡∂Ω‡∂∂‡∑è ‡∂Ø‡∑ì‡∂∏‡∑ö ‡∑Ñ‡∑ê‡∂ö‡∑í‡∂∫‡∑è‡∑Ä ‡∂á‡∂≠ ‡∂ë‡∂±‡∂∏‡∑ä ‡∂¥‡∑ä‡∂ª‡∂Ø‡∑è‡∂± ‡∑Ä‡∑ù‡∂Ω‡∑ä‡∂ß‡∑ì‡∂∫‡∂≠‡∑è ‡∂ö‡∑î‡∂©‡∑è ‡∂¥‡∂ª‡∑è‡∑É‡∂∫‡∂ö‡∑ä ‡∂≠‡∑î‡∑Ö ‡∑Ä‡∑ê‡∂©‡∑í ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∑ö‡∂Ø‡∑ì ‡∂¥‡∑ä‡∂ª‡∂≠‡∑í‡∂Ø‡∑è‡∂± ‡∑Ä‡∑ù‡∂Ω‡∑í‡∂ß‡∑ì‡∂∫‡∂≠‡∑è‡∑Ä ‡∑Ä‡∑í‡∑Å‡∑è‡∂Ω ‡∂¥‡∂ª‡∑è‡∑É‡∂∫‡∂ö‡∑ä ‡∂≠‡∑î‡∑Ö ‡∑Ä‡∑ê‡∂©‡∑í ‡∑Ä‡∑ö\n‡∂∏‡∑ô‡∑É‡∑ö‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Remeinium/CleanSinhalaTextCorpus.","url":"https://huggingface.co/datasets/Remeinium/CleanSinhalaTextCorpus","creator_name":"Remeinium AI","creator_url":"https://huggingface.co/Remeinium","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","token-classification","Sinhala","cc-by-4.0","10M<n<100M"],"keywords_longer_than_N":true},
	{"name":"sri_Lankan_classified_ads_dataset_for_ad_matching_and_retrieval","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset was developed to support research in ad matching, semantic retrieval, and intent alignment across offering and wanted ads in Sri Lankan classified marketplaces. It consists of 54,489 ad pairs.\nIt includes both human-verified real samples and LLM-generated synthetic samples.\n\n\t\n\t\t\n\t\tUse Case Highlights\n\t\n\n\nDesigned for training and evaluating ML models requiring generalization across low-resource subcategories\nEspecially valuable where wanted ads are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Damika-7/sri_Lankan_classified_ads_dataset_for_ad_matching_and_retrieval.","url":"https://huggingface.co/datasets/Damika-7/sri_Lankan_classified_ads_dataset_for_ad_matching_and_retrieval","creator_name":"Damika Alwis","creator_url":"https://huggingface.co/Damika-7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Sinhala","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"sinhala","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages ‚Üí dolly-machine-translated.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture-with-language","keyword":"sinhala","description":"\n\nJust a version of the good tulu-3-sft-mixture dataset with a column indicating language.\nLanguage detection has been performed with fastText.\n‚ö†Ô∏è It may contain errors.\n","url":"https://huggingface.co/datasets/anakin87/tulu-3-sft-mixture-with-language","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"sinhala-bank-speech","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThis dataset contains 100 audio files, one male voice in the format .wav. \nThe domain of this dataset is Banking.Only Language is Sinhalese(Sinhala,si)\nTotal Duration: 700.283 seconds.\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IshanSuga/sinhala-bank-speech.","url":"https://huggingface.co/datasets/IshanSuga/sinhala-bank-speech","creator_name":"Ishan Sugathadasa","creator_url":"https://huggingface.co/IshanSuga","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Sinhala","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"sinhala","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"sri_lankan_classifieds_data_set_ad_classification","keyword":"sinhala","description":"The Sri Lanka Classified Ads Dataset is a collection of classified advertisement listings sourced from various online marketplaces operating in Sri Lanka. It contains over 90,000 ads categorized under major sectors such as Property, Vehicles, and Electronics, and includes detailed titles and descriptions for each ad. This dataset is ideal for research and development in natural language processing (NLP) tasks like text classification, information extraction, and recommendation systems specific‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Damika-7/sri_lankan_classifieds_data_set_ad_classification.","url":"https://huggingface.co/datasets/Damika-7/sri_lankan_classifieds_data_set_ad_classification","creator_name":"Damika Alwis","creator_url":"https://huggingface.co/Damika-7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Sinhala","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"sinhala","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"sinhala-agriculture-gce-alevel-2021","keyword":"sinhala","description":"ov1n/sinhala-agriculture-gce-alevel-2021 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ov1n/sinhala-agriculture-gce-alevel-2021","creator_name":"Thenuka Weerasinghe","creator_url":"https://huggingface.co/ov1n","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Sinhala","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"sinhala-finetune-qa-eli5","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Card for sinhala-finetune-qa-eli5\n\t\n\nSinhala question answering (QA) dataset contains a subset of the translated eli5 (explain like I'm 5) English dataset. eli5 is a crowdsourced dataset based mainly on the content from the subreddit r/explainlikeimfive.\nThis is a forum where users post complex questions and other users provide simplified explanations. \nA subset of eli5 dataset (10k samples) has been machine translated to Sinhala language using the Google Cloud Translation API.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihalage/sinhala-finetune-qa-eli5.","url":"https://huggingface.co/datasets/ihalage/sinhala-finetune-qa-eli5","creator_name":"Achintha Ihalage","creator_url":"https://huggingface.co/ihalage","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","translation","text2text-generation","Sinhala"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"sinhala","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"oscar-mini","keyword":"sinhala","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-mini","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Fran√ßais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"tatoeba","keyword":"sinhala","description":"This is a collection of translated sentences from Tatoeba\n359 languages, 3,403 bitexts\ntotal number of files: 750\ntotal number of tokens: 65.54M\ntotal number of sentence fragments: 8.96M","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ms_terms","keyword":"sinhala","description":"The Microsoft Terminology Collection can be used to develop localized versions of applications that integrate with Microsoft products.\nIt can also be used to integrate Microsoft terminology into other terminology collections or serve as a base IT glossary\nfor language development in the nearly 100 languages available. Terminology is provided in .tbx format, an industry standard for terminology exchange.","url":"https://huggingface.co/datasets/microsoft/ms_terms","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","license_name":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":null,"first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","multilingual","translation"],"keywords_longer_than_N":true},
	{"name":"Sinhala_OCR_Dataset_Synthetic","keyword":"sinhala","description":"This is a synthetically generated dataset you can generate your own with the help of below codes in this github repo: https://github.com/suchinthana00/Synthetic_OCR_Dataset_Generator\n","url":"https://huggingface.co/datasets/Suchinthana/Sinhala_OCR_Dataset_Synthetic","creator_name":"Wijesundara","creator_url":"https://huggingface.co/Suchinthana","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Sinhala","mit","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-olmo-2-mixture","keyword":"sinhala","description":"Note that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe OLMo v2 SFT mixture was used to train the OLMo models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et al., 2023)\nNo Robots (CC-BY-NC-4.0), 9,500‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"SystemChat_Sinhala","keyword":"sinhala","description":"This is a SystemChat dataset for Sinhala\n","url":"https://huggingface.co/datasets/QuixiAI/SystemChat_Sinhala","creator_name":"Quixi AI","creator_url":"https://huggingface.co/QuixiAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Sinhala","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"nllb-top25k-ensi-cleaned","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nThe dataset is released under the terms of ODC-BY. By using this, you are also bound to the respective Terms of Use and License of the original source.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@inproceedings{ranathunga-etal-2024-quality,\n    title = \"Quality Does Matter: A Detailed Look at the Quality and Utility of Web-Mined Parallel Corpora\",\n    author = \"Ranathunga, Surangika  and\n      De Silva, Nisansa  and\n      Menan, Velayuthan  and\n      Fernando, Aloka  and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/nllb-top25k-ensi-cleaned.","url":"https://huggingface.co/datasets/NLPC-UOM/nllb-top25k-ensi-cleaned","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["translation","English","Sinhala","odc-by","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Sinhala-short-sentences","keyword":"sinhala","description":"This is the dataset used in the paper Kadupitiya, J.C.S., Ranathunga, S. and Dias, G., 2016, December. Sinhala Short Sentence Similarity Measures using Corpus-Based Simi-larity for Short Answer Grading. In 6th Workshop on South and Southeast Asian Natural Language Processing (pp. 44-53). The data set contains Sinhala short sentences generated from a flicker image data set (refer to papr for more detais). participants were asked to produce captions for 500 images. Then the similarity between‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Sinhala-short-sentences.","url":"https://huggingface.co/datasets/NLPC-UOM/Sinhala-short-sentences","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["Sinhala","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"SinhalaWikipediaArticles","keyword":"sinhala","description":"LexiconShiftInnovations/SinhalaWikipediaArticles dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/LexiconShiftInnovations/SinhalaWikipediaArticles","creator_name":"LexiconShift Innovations","creator_url":"https://huggingface.co/LexiconShiftInnovations","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Sinhala","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"sinhala","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"SSOCR-V.1","keyword":"sinhala","description":"Ransaka/SSOCR-V.1 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Ransaka/SSOCR-V.1","creator_name":"Ransaka Ravihara","creator_url":"https://huggingface.co/Ransaka","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Sinhala","mit","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"eng_montok","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\n","url":"https://huggingface.co/datasets/catherinearnett/eng_montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"sinhala-poems-v1","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tSinhala Poems (Filtered)\n\t\n\nCurated Sinhala poem blocks extracted from web blogs using a verse-shaped heuristic (v3.4) with weak attributes (theme/mood/style) and stats.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\ntext: full original block (cleaned)\nsnippet: first stanza or 8 lines\nurl: source URL\nsubtype: poem | song_like | promo_like | unknown\nkeep: boolean accepted by filter\ntheme, mood, style, length_class: weak labels\nps_*: structure stats (floats)\n\n\n\t\n\t\t\n\t\n\t\n\t\tFiltering summary\n\t\n\n\nBoilerplate/HTML‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dixydox888/sinhala-poems-v1.","url":"https://huggingface.co/datasets/dixydox888/sinhala-poems-v1","creator_name":"Manthila Mallawa","creator_url":"https://huggingface.co/dixydox888","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Sinhala","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"sinhala-poems-v1","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tSinhala Poems (Filtered)\n\t\n\nCurated Sinhala poem blocks extracted from web blogs using a verse-shaped heuristic (v3.4) with weak attributes (theme/mood/style) and stats.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\ntext: full original block (cleaned)\nsnippet: first stanza or 8 lines\nurl: source URL\nsubtype: poem | song_like | promo_like | unknown\nkeep: boolean accepted by filter\ntheme, mood, style, length_class: weak labels\nps_*: structure stats (floats)\n\n\n\t\n\t\t\n\t\n\t\n\t\tFiltering summary\n\t\n\n\nBoilerplate/HTML‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dixydox888/sinhala-poems-v1.","url":"https://huggingface.co/datasets/dixydox888/sinhala-poems-v1","creator_name":"Manthila Mallawa","creator_url":"https://huggingface.co/dixydox888","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Sinhala","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"sinhala","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"sinhala","description":"\n\n\n\t\n\t\t\n\t\tüî∑ Accepted in NAACL Proceedings (2025) üî∑\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval üìö [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"sinhala_sa","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tSentiment Analysis Data for the Sinhala Language\n\t\n\nDataset Description:\nThis dataset contains a sentiment analysis data from Ranathunga et al (2021).\nData Structure:\nThe data was used for the project on injecting external commonsense knowledge into multilingual Large Language Models.\nCitation:\n@article{ranathunga2021sentiment,\n  title={Sentiment analysis of sinhala news comments},\n  author={Ranathunga, Surangika and Liyanage, Isuru Udara},\n  journal={Transactions on Asian and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DGurgurov/sinhala_sa.","url":"https://huggingface.co/datasets/DGurgurov/sinhala_sa","creator_name":"Daniil Gurgurov","creator_url":"https://huggingface.co/DGurgurov","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Sinhala","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Nadi_Indic466k_Instruct","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tNadi_Indic466K_Instruct Dataset\n\t\n\nThe Nadi_Indic466K_Instruct dataset is the world's first coding dataset with 18 Indian language support, 466k rows and 142 Million total tokens. This dataset can be used by developers to build Indian coding language models (LLMs) for various programming languages.\nQ-LoRA based SFT/PPO/DPO fine-tuning can be done on the dataset in LLAMA-2 or Mistral or any opens-soure LLM for text generation.\nThe dataset was carefully curated such that the coding part‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct.","url":"https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct","creator_name":"Convai Innovations","creator_url":"https://huggingface.co/convaiinnovations","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Hindi","Panjabi","Bengali","Tamil"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"sinhala","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"K-BotDataset-forK-bot","keyword":"sinhala","description":"K3theking/K-BotDataset-forK-bot dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/K3theking/K-BotDataset-forK-bot","creator_name":"No","creator_url":"https://huggingface.co/K3theking","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","table-question-answering","text-to-speech","token-classification","automatic-speech-recognition"],"keywords_longer_than_N":true},
	{"name":"SiTSE","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tSinhala-Text-Simplification-Dataset-and-Evaluation\n\t\n\nThis repository contains the data for the paper \"SiTSE: Sinhala Text Simplification Dataset and Evaluation.\" It presents a human-curated, sentence-level text simplification dataset for the Sinhala language. The dataset contains 1,000 complex sentences and 3,000 corresponding simplified sentences, produced by three different human annotators.\nThe sme dataset is in Github as well:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/SiTSE.","url":"https://huggingface.co/datasets/NLPC-UOM/SiTSE","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Sinhala","mit","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"BuddhismEval","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Card for BuddhismEval\n\t\n\nBuddhismEval is the first bilingual evaluation benchmark designed to assess large language models (LLMs) on Buddhist ethical reasoning and philosophical understanding across Sinhala and English. It includes high-quality, culturally grounded multiple-choice question (MCQ) datasets derived primarily from the Dhammapada, a core TheravƒÅda Buddhist scripture, and other canonical sources and exam materials from Sri Lanka.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nethmi14/BuddhismEval.","url":"https://huggingface.co/datasets/Nethmi14/BuddhismEval","creator_name":"Nethmi Muthugala","creator_url":"https://huggingface.co/Nethmi14","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","English","Sinhala","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"sinhala-instruction-finetune-large","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Card for sinhala-instruction-finetune-large\n\t\n\nSinhala instruction finetune (SIF) dataset contains high quality question-answer pairs in Sinhala language. It is an aggregate of several Sinhala datasets in the\nHugging Face Datasets hub. SIF dataset has been compiled by transforming the datasets specified below into a common format. \n\nsinhala_eli5\nsinhala-llm-dataset-llama-prompt-format\nalpaca-sinhala\nCNN-Daily-Mail-Sinhala\ndatabricks-dolly-15k-sinhala\nSinhalaDentalQnA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ihalage/sinhala-instruction-finetune-large.","url":"https://huggingface.co/datasets/ihalage/sinhala-instruction-finetune-large","creator_name":"Achintha Ihalage","creator_url":"https://huggingface.co/ihalage","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","summarization","Sinhala","English"],"keywords_longer_than_N":true},
	{"name":"Sinhala-Stopword-list","keyword":"sinhala","description":"NLPC-UOM/Sinhala-Stopword-list dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/NLPC-UOM/Sinhala-Stopword-list","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["Sinhala","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"flores","keyword":"sinhala","description":"Evaluation datasets for low-resource machine translation: Nepali-English and Sinhala-English.","url":"https://huggingface.co/datasets/facebook-llama/flores","creator_name":"AstroKid","creator_url":"https://huggingface.co/facebook-llama","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","translation","extended|wikipedia"],"keywords_longer_than_N":true},
	{"name":"SinhalaWikipediaArticles","keyword":"sinhala","description":"KanishkaRandunu/SinhalaWikipediaArticles dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KanishkaRandunu/SinhalaWikipediaArticles","creator_name":"Kanishka Randunu ","creator_url":"https://huggingface.co/KanishkaRandunu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Sinhala","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"SinhalaWikipediaArticles","keyword":"sinhala","description":"KanishkaRandunu/SinhalaWikipediaArticles dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KanishkaRandunu/SinhalaWikipediaArticles","creator_name":"Kanishka Randunu ","creator_url":"https://huggingface.co/KanishkaRandunu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Sinhala","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"SinhalaDentalQnA","keyword":"sinhala","description":"LexiconShiftInnovations/SinhalaDentalQnA dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/LexiconShiftInnovations/SinhalaDentalQnA","creator_name":"LexiconShift Innovations","creator_url":"https://huggingface.co/LexiconShiftInnovations","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Sinhala","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Sinhala-News-Category-classification","keyword":"sinhala","description":"This file contains news texts (sentences) belonging to 5 different news categories (political, business, technology, sports and Entertainment). The original dataset was released by Nisansa de Silva (Sinhala Text Classification: Observations from the Perspective of a Resource Poor Language, 2015). The original dataset is processed and cleaned of single word texts, English only sentences etc. \nIf you use this dataset, please cite {Nisansa de Silva, Sinhala Text Classification: Observations from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Category-classification.","url":"https://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Category-classification","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","monolingual","Sinhala","mit"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"sinhala","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof Wr√≥bel","creator_url":"https://huggingface.co/djstrong","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"sinhala","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"alpaca-sinhala","keyword":"sinhala","description":"The Alpaca dataset translated into Sinhala using Google Translator. Manual verification and correction of translations are recommended for optimal performance.\n","url":"https://huggingface.co/datasets/sahanruwantha/alpaca-sinhala","creator_name":"sahan ruwantha","creator_url":"https://huggingface.co/sahanruwantha","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","Sinhala","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"alpaca-sinhala","keyword":"sinhala","description":"The Alpaca dataset translated into Sinhala using Google Translator. Manual verification and correction of translations are recommended for optimal performance.\n","url":"https://huggingface.co/datasets/sahanruwantha/alpaca-sinhala","creator_name":"sahan ruwantha","creator_url":"https://huggingface.co/sahanruwantha","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","Sinhala","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Sinhala-news-clustering","keyword":"sinhala","description":"This repo contains data and source code for the paper Nanayakkara, P., & Ranathunga, S. (2018, May). Clustering Sinhala News Articles Using Corpus-Based Similarity Measures. In 2018 Moratuwa Engineering Research Conference (MERCon) (pp. 437-442). IEEE.\nSource code - logic to cluster news articles, and measure performance. NOTE: this has a dependency to crawler4j, which is not included here.\n","url":"https://huggingface.co/datasets/NLPC-UOM/Sinhala-news-clustering","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["Sinhala","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"sinhala-sentiment-lexicon-generation","keyword":"sinhala","description":"NLPC-UOM/sinhala-sentiment-lexicon-generation dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/NLPC-UOM/sinhala-sentiment-lexicon-generation","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["Sinhala","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"mc4-sampling","keyword":"sinhala","description":"A sampling-enabled version of mC4, the colossal, cleaned version of Common Crawl's web crawl corpus.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is a version of the processed version of Google's mC4 dataset by AllenAI, in which sampling methods are implemented to perform on the fly.","url":"https://huggingface.co/datasets/bertin-project/mc4-sampling","creator_name":"BERTIN Project","creator_url":"https://huggingface.co/bertin-project","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"sinhala","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"opus_paracrawl","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Card for OpusParaCrawl\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nParallel corpora from Web Crawls collected in the ParaCrawl project.\nTha dataset contains:\n\n42 languages, 43 bitexts\ntotal number of files: 59,996\ntotal number of tokens: 56.11G\ntotal number of sentence fragments: 3.13G\n\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs,\ne.g.\ndataset = load_dataset(\"opus_paracrawl\", lang1=\"en\", lang2=\"so\")\n\nYou can find the valid‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl.","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arb√´resh√´ Albanian"],"keywords_longer_than_N":true},
	{"name":"science-sinhala-gce-olevel-2023-mcq","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset contains 40 Science MCQ questions and answers in Sinhala language of the GCE Ordinary Level Science paper 2023.\n","url":"https://huggingface.co/datasets/ov1n/science-sinhala-gce-olevel-2023-mcq","creator_name":"Thenuka Weerasinghe","creator_url":"https://huggingface.co/ov1n","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Sinhala","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"fineweb-2","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tü•Ç FineWeb2\n\t\n\n\n    \n\n\n\nA sparkling update with 1000s of languages\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis is the second iteration of the popular üç∑ FineWeb dataset, bringing high quality pretraining data to over 1000 üó£Ô∏è languages.\nThe ü•Ç FineWeb2 dataset is fully reproducible, available under the permissive ODC-By 1.0 license and extensively validated through hundreds of ablation experiments.\nIn particular, on the set of 9 diverse languages we used to guide our processing decisions, ü•Ç FineWeb2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/fineweb-2.","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb-2","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"wildchat-filtered","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tWildChat Filtered Dataset\n\t\n\nThis is a filtered version of the WildChat-4.8M dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3,199,860 conversations between human users and ChatGPT, filtered to keep only the essential conversation structure.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach conversation contains only:\n\nconversations: A list of message objects with:\nrole: Either \"user\" or \"assistant\"\ncontent: The text content of the message\n\n\n\nAll other metadata (timestamps, moderation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rayonlabs/wildchat-filtered.","url":"https://huggingface.co/datasets/rayonlabs/wildchat-filtered","creator_name":"Rayon Labs","creator_url":"https://huggingface.co/rayonlabs","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"Questions_Answers_In_Sinhala_Language","keyword":"sinhala","description":"@misc{AyeshaKalpani_2024,\n      title={Questions_Answers_In_Sinhala_Language}, \n      author={Ayesha Kalpani},\n      year={2024},\n      url={}, \n}\n\n\n\t\n\t\t\n\t\tQuestions_Answers_In_Sinhala_Language\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA dataset containing questions and answers in the Sinhala language. This dataset is intended for training and evaluating question-answering models in Sinhala.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under the MIT License.\n\n\t\n\t\t\n\t\tTask‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AyeshaKalpani98/Questions_Answers_In_Sinhala_Language.","url":"https://huggingface.co/datasets/AyeshaKalpani98/Questions_Answers_In_Sinhala_Language","creator_name":"Ayesha Kalpani","creator_url":"https://huggingface.co/AyeshaKalpani98","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text2text-generation","text-generation","Sinhala","mit"],"keywords_longer_than_N":true},
	{"name":"Questions_Answers_In_Sinhala_Language","keyword":"sinhala","description":"@misc{AyeshaKalpani_2024,\n      title={Questions_Answers_In_Sinhala_Language}, \n      author={Ayesha Kalpani},\n      year={2024},\n      url={}, \n}\n\n\n\t\n\t\t\n\t\tQuestions_Answers_In_Sinhala_Language\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA dataset containing questions and answers in the Sinhala language. This dataset is intended for training and evaluating question-answering models in Sinhala.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under the MIT License.\n\n\t\n\t\t\n\t\tTask‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AyeshaKalpani98/Questions_Answers_In_Sinhala_Language.","url":"https://huggingface.co/datasets/AyeshaKalpani98/Questions_Answers_In_Sinhala_Language","creator_name":"Ayesha Kalpani","creator_url":"https://huggingface.co/AyeshaKalpani98","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text2text-generation","text-generation","Sinhala","mit"],"keywords_longer_than_N":true},
	{"name":"tulu3-100samples","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nThis dataset contains 100 samples from the Tulu 3 SFT Mixture.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example in the dataset contains the standard instruction-tuning data points as follow:\n\nid (str): a unique identifier\nmessages (list): message format used for supervised fine-tuning (this contains user prompt and assistant responses)\nsource (str): the source dataset for the given sample\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under ODC-BY-1.0. It is intended for research and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anayak/tulu3-100samples.","url":"https://huggingface.co/datasets/anayak/tulu3-100samples","creator_name":"Akash Nayak","creator_url":"https://huggingface.co/anayak","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"MultiMWP","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tMultiMWP: A Multi-Way Parallel Dataset for Math Word Problem Generation\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nMultiMWP is a multi-way parallel dataset designed for math word problem (MWP) generation across 9 languages.\nThe dataset consists of structured math word problems in plain text format.\nIt is intended for problem generation rather than problem-solving. The same dataset is in Github: https://github.com/OmegaGamage/multiMWP/tree/master/dataset\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nMultiMWP includes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/MultiMWP.","url":"https://huggingface.co/datasets/NLPC-UOM/MultiMWP","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Albanian","Assamese","English","Chinese","Hindi"],"keywords_longer_than_N":true},
	{"name":"English-Sinhala-Idioms-Parallel-Translations","keyword":"sinhala","description":"Venuraa/English-Sinhala-Idioms-Parallel-Translations dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Venuraa/English-Sinhala-Idioms-Parallel-Translations","creator_name":"Rajapaksha","creator_url":"https://huggingface.co/Venuraa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Sinhala","apache-2.0","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"Augmented_SinhalatoRomanizedSinhala_Dataset","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tSinhala Romanized Dataset\n\t\n\nThis dataset contains Sinhala text with romanized (transliterated) versions, created using publicly available Sinhala data sources.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Augmented Sinhala to Romanized Sinhala Dataset provides paired examples of Sinhala text and their corresponding romanized transliterations. This dataset aims to facilitate research in Sinhala language processing, particularly for applications that require romanized representations of Sinhala‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deshanksuman/Augmented_SinhalatoRomanizedSinhala_Dataset.","url":"https://huggingface.co/datasets/deshanksuman/Augmented_SinhalatoRomanizedSinhala_Dataset","creator_name":"Deshan Sumanathilaka","creator_url":"https://huggingface.co/deshanksuman","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Sinhala","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"SinhalaNewsSourceClassification","keyword":"sinhala","description":"\n  SinhalaNewsSourceClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset contains Sinhala news headlines extracted from 9 news sources (websites) (Sri Lanka Army, Dinamina, GossipLanka, Hiru, ITN, Lankapuwath, NewsLK, Newsfirst, World Socialist Web Site-Sinhala).\n\n\t\n\t\t\n\n\n\n\n\t\tTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Source-classification\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SinhalaNewsSourceClassification.","url":"https://huggingface.co/datasets/mteb/SinhalaNewsSourceClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","NLPC-UOM/Sinhala-News-Source-classification"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"sinhala","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU üåç is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) üóΩ or Culturally Agnostic (CA) ‚öñÔ∏è. These annotations were collected as part of an open‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU.","url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"SinhalaNewsHeadlines","keyword":"sinhala","description":"Remeinium/SinhalaNewsHeadlines dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Remeinium/SinhalaNewsHeadlines","creator_name":"Remeinium AI","creator_url":"https://huggingface.co/Remeinium","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","sentence-similarity","Sinhala","mit"],"keywords_longer_than_N":true},
	{"name":"SinhalaNewsHeadlines","keyword":"sinhala","description":"Remeinium/SinhalaNewsHeadlines dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Remeinium/SinhalaNewsHeadlines","creator_name":"Remeinium AI","creator_url":"https://huggingface.co/Remeinium","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","sentence-similarity","Sinhala","mit"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following boolean‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"quran_multilingual_parallel","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tüìò Qur‚Äôan Multilingual Parallel Dataset (quran_multilingual_parallel)\n\t\n\nThis dataset presents a clean, structurally-aligned multilingual parallel corpus of the Qur‚Äôanic text. It is intended for linguistic, computational, and cross-lingual AI applications ‚Äî not only for religious interpretation.\nIt contains over 6,200 verse-level alignments in 54 human languages, formatted in a machine-friendly .csv structure with language-specific translation fields.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüß† Dataset Highlights‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/quran_multilingual_parallel.","url":"https://huggingface.co/datasets/freococo/quran_multilingual_parallel","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Albanian","Amharic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Sinhala-QnA-Generate","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AyeshaKalpani98/Sinhala-QnA-Generate.","url":"https://huggingface.co/datasets/AyeshaKalpani98/Sinhala-QnA-Generate","creator_name":"Ayesha Kalpani","creator_url":"https://huggingface.co/AyeshaKalpani98","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","Sinhala","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Sinhala-QnA-Generate","keyword":"sinhala","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AyeshaKalpani98/Sinhala-QnA-Generate.","url":"https://huggingface.co/datasets/AyeshaKalpani98/Sinhala-QnA-Generate","creator_name":"Ayesha Kalpani","creator_url":"https://huggingface.co/AyeshaKalpani98","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","Sinhala","mit","1K - 10K"],"keywords_longer_than_N":true}
]
;
