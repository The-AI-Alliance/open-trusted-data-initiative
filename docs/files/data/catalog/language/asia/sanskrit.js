const data_for_language_asia_sanskrit = 
[
	{"name":"IGB_XorQA","keyword":"sanskrit","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IGB_XorQA","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"VarunGumma/IGB_XorQA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"Devi_Bhagavatam","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/snskrt/Devi_Bhagavatam","creator_name":"Sanskrit Datasets","creator_url":"https://huggingface.co/snskrt","description":"\n\t\n\t\t\n\t\tDataset Card for srimad_devi_bhagavata_mahapurana\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a complete, structured representation of the ≈örƒ´mad Devƒ´-bhƒÅgavatam mahƒÅpurƒÅ·πáe in CSV format, broken down into Skandas, AdhyƒÅyas, and individual ≈õlokas. It is designed for NLP applications‚Äîincluding feature extraction, classification, translation, summarization, question-answering, and generation‚Äîon classical Sanskrit scripture.\n\nCurated by: Aluminium‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/snskrt/Devi_Bhagavatam.","first_N":5,"first_N_keywords":["feature-extraction","text-classification","token-classification","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"Shrimad_Bhagvat_Puran","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/snskrt/Shrimad_Bhagvat_Puran","creator_name":"Sanskrit Datasets","creator_url":"https://huggingface.co/snskrt","description":"","first_N":5,"first_N_keywords":["text-classification","token-classification","question-answering","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"multiblimp","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jumelet/multiblimp","creator_name":"Jaap Jumelet","creator_url":"https://huggingface.co/jumelet","description":"\n\t\n\t\t\n\t\tMultiBLiMP\n\t\n\nMultiBLiMP is a massively Multilingual Benchmark for Linguistic Minimal Pairs. The dataset is composed of synthetic pairs generated using Universal Dependencies and UniMorph.\nThe paper can be found here.\nWe split the data set by language: each language consists of a single .tsv file. The rows contain many attributes for a particular pair, most important are the sen and wrong_sen fields, which we use for evaluating the language models.\n\n\t\n\t\t\n\t\n\t\n\t\tUsing MultiBLiMP\n\t\n\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jumelet/multiblimp.","first_N":5,"first_N_keywords":["multilingual","Buriat","Spanish","Sanskrit","Romanian"],"keywords_longer_than_N":true},
	{"name":"samhitika-0.0.1","keyword":"sanskrit","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/khoomeik/samhitika-0.0.1","creator_name":"Rohan Pandey","creator_url":"https://huggingface.co/khoomeik","description":"\n\t\n\t\t\n\t\tDataset Card for samhitika-0.0.1\n\t\n\n\n\nTranslation of ~40M sentences from BookCorpus to Sanskrit with Gemma3-27b, yielding ~1.5B (gemma3-)tokens of low quality Sanskrit.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\n\nBookCorpus was translated one sentence at a time by Gemma3-27b in bf16 with the following prompt:\nTranslate the following English text to Sanskrit. Return only one Devanagari Sanskrit translation wrapped in triple backticks. Do NOT return any English.\n\nEnglish:\n\\```‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/khoomeik/samhitika-0.0.1.","first_N":5,"first_N_keywords":["text-generation","Sanskrit","mit","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"Sanskrit","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davanstrien/Sanskrit","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","description":"\n\t\n\t\t\n\t\tSanskrit Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a conversion of the Pracalit for Sanskrit and Newar MSS 16th to 19th C., Ground Truth dataset, originally published on Zenodo. The dataset contains pairs of images and corresponding plain text extracted from XML files. This dataset specifically includes the ground truth data from the original repository.\n\n\t\n\t\t\n\t\n\t\n\t\tPotential Use for VLM-based OCR Training\n\t\n\nThe existing ground truth OCR data can be particularly useful for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davanstrien/Sanskrit.","first_N":5,"first_N_keywords":["image-to-text","Sanskrit","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"morphscore","keyword":"sanskrit","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/catherinearnett/morphscore","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","description":"\n\t\n\t\t\n\t\tMorphScore\n\t\n\nMorphScore is a tokenizer evaluation framework, which evaluates the extent to which a tokenizer segments words along morpheme boundaries. This repository contains the datasets used to calculate MorphScore.\nIn total, we have datasetes for 86 languages, but only 70 languages have at least 100 items after filtering. \nAll datasets are derived from existing Universal Dependencies treebanks. In the table below, we link the source dataset for each language. \nSee the new preprint‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/morphscore.","first_N":5,"first_N_keywords":["Arabic","English","German","Russian","Turkish"],"keywords_longer_than_N":true},
	{"name":"IndicQuest","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/l3cube-pune/IndicQuest","creator_name":"L3Cube Labs","creator_url":"https://huggingface.co/l3cube-pune","description":"\n\t\n\t\t\n\t\tL3Cube-IndicQuest: A Benchmark Question Answering Dataset for Evaluating Knowledge of LLMs in Indic Context (LLM Factual Accuracy Benchmark)\n\t\n\nL3Cube-IndicQuest is a dataset comprising 4,000 question-answer pairs across 20 languages, including English, Assamese, Bengali, Dogri, Gujarati, Hindi, Kannada, Konkani, Maithili, Malayalam, Marathi, Meitei (Manipuri), Nepali, Odia, Punjabi, Sanskrit, Sindhi, Tamil, Telugu, and Urdu. This dataset is designed to assess the knowledge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/l3cube-pune/IndicQuest.","first_N":5,"first_N_keywords":["question-answering","English","Assamese","Bengali","Gujarati"],"keywords_longer_than_N":true},
	{"name":"IndicLangClassification","keyword":"sanskrit","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicLangClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicLangClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Non-fiction, Written\nReference\nhttps://arxiv.org/abs/2305.15814\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicLangClassification\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicLangClassification.","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-annotated","monolingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"sanskrit-metrical-poetry","keyword":"sanskrit","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dukeofmtnview/sanskrit-metrical-poetry","creator_name":"A G","creator_url":"https://huggingface.co/dukeofmtnview","description":"\n\t\n\t\t\n\t\tSanskrit Metrical Poetry Dataset\n\t\n\nThis dataset contains examples and tasks for Sanskrit metrical poetry composition, designed to train models to generate metrically correct Sanskrit poetry.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Sanskrit Metrical Poetry dataset is designed for training models to compose Sanskrit poetry that adheres to specific metrical patterns (chandas). It contains examples of Sanskrit poems with their metrical analysis and tasks for poetry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dukeofmtnview/sanskrit-metrical-poetry.","first_N":5,"first_N_keywords":["Sanskrit","cc-by-sa-4.0","üá∫üá∏ Region: US","sanskrit","poetry"],"keywords_longer_than_N":true},
	{"name":"sanskrit-metrical-poetry","keyword":"sanskrit","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dukeofmtnview/sanskrit-metrical-poetry","creator_name":"A G","creator_url":"https://huggingface.co/dukeofmtnview","description":"\n\t\n\t\t\n\t\tSanskrit Metrical Poetry Dataset\n\t\n\nThis dataset contains examples and tasks for Sanskrit metrical poetry composition, designed to train models to generate metrically correct Sanskrit poetry.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Sanskrit Metrical Poetry dataset is designed for training models to compose Sanskrit poetry that adheres to specific metrical patterns (chandas). It contains examples of Sanskrit poems with their metrical analysis and tasks for poetry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dukeofmtnview/sanskrit-metrical-poetry.","first_N":5,"first_N_keywords":["Sanskrit","cc-by-sa-4.0","üá∫üá∏ Region: US","sanskrit","poetry"],"keywords_longer_than_N":true},
	{"name":"gretil-chunks","keyword":"sanskrit","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/arakesha123/gretil-chunks","creator_name":"a","creator_url":"https://huggingface.co/arakesha123","description":"\n\n\n\nDataset creation, cleaning and anonimisation scripts (not very readable) available in Kaggle here. \n","first_N":5,"first_N_keywords":["Sanskrit","mit","100K - 1M","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"sanskrit_morph_prakriya","keyword":"sanskrit","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/preetammukherjee/sanskrit_morph_prakriya","creator_name":"preetam mukherjee","creator_url":"https://huggingface.co/preetammukherjee","description":"\n\t\n\t\t\n\t\tVidyut-Prakriya Tinanta Dataset for Morphological Rendering\n\t\n\nThis dataset contains pairs of Sanskrit morphological metadata and their corresponding surface forms,\ngenerated and verified using the vidyut-prakriya library.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is provided in JSON Lines (.jsonl) format. Each line is a JSON object with the following fields:\n\nllm_input (string): A textual representation of the morphological metadata. This serves as the input for a sequence-to-sequence‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/preetammukherjee/sanskrit_morph_prakriya.","first_N":5,"first_N_keywords":["Sanskrit","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"sanskrit_morph_prakriya","keyword":"sanskrit","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/preetammukherjee/sanskrit_morph_prakriya","creator_name":"preetam mukherjee","creator_url":"https://huggingface.co/preetammukherjee","description":"\n\t\n\t\t\n\t\tVidyut-Prakriya Tinanta Dataset for Morphological Rendering\n\t\n\nThis dataset contains pairs of Sanskrit morphological metadata and their corresponding surface forms,\ngenerated and verified using the vidyut-prakriya library.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is provided in JSON Lines (.jsonl) format. Each line is a JSON object with the following fields:\n\nllm_input (string): A textual representation of the morphological metadata. This serves as the input for a sequence-to-sequence‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/preetammukherjee/sanskrit_morph_prakriya.","first_N":5,"first_N_keywords":["Sanskrit","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"sib200_14classes","keyword":"sanskrit","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200_14classes","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for SIB-200\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\nThe train/validation/test sets are available for all the 205 languages.\nThis is another version with 14 classes, more idea for few-shot evaluation, it has 5 examples for few-shot, and larger test set (1225)\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopic classification: categorize wikipedia sentences‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200_14classes.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"wikipedia-monthly","keyword":"sanskrit","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/omarkamali/wikipedia-monthly","creator_name":"Omar Kamali","creator_url":"https://huggingface.co/omarkamali","description":"\n\t\n\t\t\n\t\tüöÄ Wikipedia Monthly\n\t\n\nLast updated: July 16, 2025, 22:53 UTC\nThis repository provides monthly, multilingual dumps of Wikipedia, processed and prepared for easy use in NLP projects.\nNOTE: The first run is still in progress and languages are still being processed and uploaded.\n\n\n\t\n\t\t\n\t\tüìä Live Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nüåç Languages Available\n341\n\n\nüìÑ Total Articles\n64.5M\n\n\nüíæ Total Size\n205.54 GB\n\n\n\t\n\n\n\n\t\n\t\t\n\t\tWhy Use This Dataset?\n\t\n\n\nFreshness: We run our pipeline monthly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/omarkamali/wikipedia-monthly.","first_N":5,"first_N_keywords":["Abkhaz","Achinese","Adyghe","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"sanskrit","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"sanskrit","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for Opus Ubuntu\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\nE.g.\ndataset = load_dataset(\"opus_ubuntu\", lang1=\"it\", lang2=\"pl\")\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"itihasa","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rahular/itihasa","creator_name":"Rahul Aralikatte","creator_url":"https://huggingface.co/rahular","description":"A Sanskrit-English machine translation dataset.","first_N":5,"first_N_keywords":["expert-generated","expert-generated","translation","original","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"sanskrit","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"sanskrit","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof Wr√≥bel","creator_url":"https://huggingface.co/djstrong","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"Bhasha-Abhijnaanam","keyword":"sanskrit","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tDataset Card for Aksharantar\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBhasha-Abhijnaanam is a language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\n\t\n\t\t\n\n\n\n\n\n\n\n\n\t\t\nAssamese (asm)\nHindi (hin)\nMaithili (mai)\nNepali (nep)\nSanskrit (san)\nTamil (tam)\n\n\nBengali (ben)\nKannada (kan)\nMalayalam (mal)\nOriya (ori)\nSantali (sat)\nTelugu (tel)\n\n\nBodo(brx)\nKashmiri‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"sanskrit","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for SIB-200\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\nThe train/validation/test sets are available for all the 205 languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 205 languages available :\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"sanskrit","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\n\t\n\t\t\n\t\tDataset Card for WikiAnc\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \nThe code for generating the dataset can be found here.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nwikificiation: The dataset can be used to train a model for Wikification.\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in all 320‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Fran√ßais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"sanskrit","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","Metlat√≥noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"tokenizer-wiki-bench","keyword":"sanskrit","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","description":"\n\t\n\t\t\n\t\tMultilingual Tokenizer Benchmark\n\t\n\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \nfrom transformers import AutoTokenizer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench.","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"sanskrit","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"shrimad-bhagavad-gita-dataset-alpaca","keyword":"sanskrit","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SatyaSanatan/shrimad-bhagavad-gita-dataset-alpaca","creator_name":"Sanatan Dharma","creator_url":"https://huggingface.co/SatyaSanatan","description":"SatyaSanatan/shrimad-bhagavad-gita-dataset-alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","Hindi","Sanskrit","mit"],"keywords_longer_than_N":true},
	{"name":"shrutilipi","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amithm3/shrutilipi","creator_name":"Amith M","creator_url":"https://huggingface.co/amithm3","description":"amithm3/shrutilipi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","Sanskrit","Bengali","Panjabi"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"sanskrit","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arb√´resh√´ Albanian"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Sentiments","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hemanth-Sai/Sentiments","creator_name":"Hemanth Sai Pavan Immidisetty","creator_url":"https://huggingface.co/Hemanth-Sai","description":"Hemanth-Sai/Sentiments dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Sanskrit","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"sangraha","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/sangraha","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tSangraha\n\t\n\n\n  \n\n\nSangraha is the largest high-quality, cleaned Indic language pretraining data containing 251B tokens summed up over 22 languages, extracted from curated sources, existing multilingual corpora and large scale translations.\nMore information:\n\nFor detailed information on the curation and cleaning process of Sangraha, please checkout our paper on Arxiv;\nCheck out the scraping and cleaning pipelines used to curate Sangraha on GitHub;\n\n\n\t\n\t\n\t\n\t\tGetting Started\n\t\n\nFor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/sangraha.","first_N":5,"first_N_keywords":["text-generation","Assamese","Bengali","Gujarati","English"],"keywords_longer_than_N":true},
	{"name":"indic-align","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/indic-align","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tIndicAlign\n\t\n\nA diverse collection of Instruction and Toxic alignment datasets for 14 Indic Languages. The collection comprises of:\n\nIndicAlign - Instruct\nIndic-ShareLlama\nDolly-T\nOpenAssistant-T\nWikiHow\nIndoWordNet\nAnudesh\nWiki-Conv\nWiki-Chat\n\n\nIndicAlign - Toxic\nHHRLHF-T\nToxic-Matrix\n\n\n\nWe use IndicTrans2 (Gala et al., 2023) for the translation of the datasets. \nWe recommend the readers to check out our paper on Arxiv for detailed information on the curation process of these‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/indic-align.","first_N":5,"first_N_keywords":["text-generation","Assamese","Bengali","Gujarati","English"],"keywords_longer_than_N":true},
	{"name":"Nadi_Indic466k_Instruct","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct","creator_name":"Convai Innovations","creator_url":"https://huggingface.co/convaiinnovations","description":"\n\t\n\t\t\n\t\tNadi_Indic466K_Instruct Dataset\n\t\n\nThe Nadi_Indic466K_Instruct dataset is the world's first coding dataset with 18 Indian language support, 466k rows and 142 Million total tokens. This dataset can be used by developers to build Indian coding language models (LLMs) for various programming languages.\nQ-LoRA based SFT/PPO/DPO fine-tuning can be done on the dataset in LLAMA-2 or Mistral or any opens-soure LLM for text generation.\nThe dataset was carefully curated such that the coding part‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct.","first_N":5,"first_N_keywords":["text-generation","Hindi","Panjabi","Bengali","Tamil"],"keywords_longer_than_N":true},
	{"name":"verse-anvaya-rigveda","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sampathlonka/verse-anvaya-rigveda","creator_name":"sampathlonka","creator_url":"https://huggingface.co/sampathlonka","description":"sampathlonka/verse-anvaya-rigveda dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Sanskrit","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"sanskrit","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"sanskrit","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"bhagavath-gita-telugu","keyword":"sanskrit","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/ajaysadhu02/bhagavath-gita-telugu","creator_name":"Ajay S","creator_url":"https://huggingface.co/ajaysadhu02","description":"ajaysadhu02/bhagavath-gita-telugu dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Telugu","Sanskrit","unlicense","< 1K"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"indic-swim-ir-cross-lingual","keyword":"sanskrit","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/indic-swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\n\t\n\t\t\n\t\tDataset Card for Indic SWIM-IR (Cross-lingual)\n\t\n\n\n\n\nThis is the cross-lingual Indic subset of the SWIM-IR dataset, where the query generated is in the Indo-European language and the passage is in English.\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\n\n\t\n\t\n\t\n\t\tWhat is SWIM-IR?\n\t\n\nSWIM-IR dataset is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/indic-swim-ir-cross-lingual.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","machine-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"sanskrit","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"sanskrit","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"flores","keyword":"sanskrit","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/flores","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FloresBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nFLORES is a benchmark dataset for machine translation between English and low-resource languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNon-fiction, Encyclopaedic, Written\n\nReference\nhttps://huggingface.co/datasets/facebook/flores\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FloresBitextMining\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/flores.","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Achinese","Mesopotamian Arabic"],"keywords_longer_than_N":true},
	{"name":"IN22-Conv","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IN22-Conv","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IN22ConvBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Conv is a n-way parallel conversation domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nSocial, Spoken, Fiction, Spoken\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Conv\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Conv.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"IN22-Gen","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IN22-Gen","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IN22GenBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Gen is a n-way parallel general-purpose multi-domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Legal, Government, News, Religious, Non-fiction, Written\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Gen\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Gen.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"sanskrit","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"gita_translations_and_commentaries","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jhaabhi/gita_translations_and_commentaries","creator_name":"Abhishek Jha","creator_url":"https://huggingface.co/jhaabhi","description":"jhaabhi/gita_translations_and_commentaries dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","Hindi","Sanskrit","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEDataset","keyword":"sanskrit","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tüåà Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEBench","keyword":"sanskrit","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tüåà Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"DCS_Sanskrit_Morphology_v1","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sampathlonka/DCS_Sanskrit_Morphology_v1","creator_name":"sampathlonka","creator_url":"https://huggingface.co/sampathlonka","description":"This dataset contains a dcs_output.csv file at the root.\n","first_N":5,"first_N_keywords":["Sanskrit","apache-2.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"sanskrit","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSIB-Fleurs\n\t\n\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \nThe topics are:\n\nScience/Technology\nTravel\nPolitics\nSports\nHealth\nEntertainment\nGeography\n\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset creation\n\t\n\nThis dataset processes and merges‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Achinese","Adyghe"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Achinese","Adyghe"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_sa","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_sa","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_sa","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_sa","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_sa","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_sa","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_sa","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"TAFSIL","keyword":"sanskrit","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/prachuryyaIITG/TAFSIL","creator_name":"Prachuryya Kaushik","creator_url":"https://huggingface.co/prachuryyaIITG","description":"\n\t\n\t\t\n\t\tTAFSIL: Taxonomy Adaptable Fine-grained Entity Recognition through Distant Supervision for Indian Languages\n\t\n\nTAFSIL is a taxonomy-adaptable Fine-grained Entity Recognition (FgER) framework designed to create FgER datasets in six Indian languages: Hindi (hi), Marathi (mr), Sanskrit (sa), Tamil (ta), Telugu (te), and Urdu (ur). These languages belong to two major language families‚ÄîIndo-European and Dravidian‚Äîand are spoken by over a billion people worldwide.\nTAFSIL leverages the high‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prachuryyaIITG/TAFSIL.","first_N":5,"first_N_keywords":["token-classification","Hindi","Marathi","Sanskrit","Tamil"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","description":"\n\n\n\t\n\t\t\n\t\tüî∑ Accepted in NAACL Proceedings (2025) üî∑\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval üìö [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"IGB_Flores_enxx","keyword":"sanskrit","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IGB_Flores_enxx","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"VarunGumma/IGB_Flores_enxx dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"IGB_Flores_xxen","keyword":"sanskrit","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IGB_Flores_xxen","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"VarunGumma/IGB_Flores_xxen dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"Saka-Alpaca-v1","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Saka-Alpaca-v1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"https://chatgpt.com\n","first_N":5,"first_N_keywords":["text-generation","Swedish","Norwegian","Finnish","German"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"panlex-definitions","keyword":"sanskrit","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-definitions","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-definitions\n\t\n\nThis is a dataset of word definitions in several hudnred languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20250201 database dump) and rearranged on the per-language basis (by the language of the definition).\nEach language subset consists of definitions (short phrases).\nEach definition is associated with some meanings (if there is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-definitions.","first_N":5,"first_N_keywords":["translation","Abkhazian","Hijazi Arabic","Afrikaans","Ainu (Japan)"],"keywords_longer_than_N":true},
	{"name":"ramayana-embeddings","keyword":"sanskrit","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Mercity/ramayana-embeddings","creator_name":"Mercity","creator_url":"https://huggingface.co/Mercity","description":"Ramayana Embedding DatasetThis repository contains a specialized embedding dataset of the ancient Indian epic, Ramayana, suitable for various NLP tasks, semantic search, and text retrieval purposes.\nDataset relesased by Mercity AI!\nDataset SourceThe original textual data has been sourced from the repository: Sanskrit Sahitya Data Repository  \n\nWe extend our sincere gratitude to the maintainers of this repository for compiling and sharing valuable Sanskrit literature datasets openly.\nEmbedding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mercity/ramayana-embeddings.","first_N":5,"first_N_keywords":["question-answering","Sanskrit","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"mahabharat-embeddings","keyword":"sanskrit","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Mercity/mahabharat-embeddings","creator_name":"Mercity","creator_url":"https://huggingface.co/Mercity","description":"Mahabharat Embedding DatasetThis repository contains a specialized embedding dataset of the ancient Indian epic, Mahabharat, suitable for various NLP tasks, semantic search, and text retrieval purposes.\nDataset relesased by Mercity AI!\nDataset SourceThe original textual data has been sourced from the repository: Sanskrit Sahitya Data Repository  \n\nWe extend our sincere gratitude to the maintainers of this repository for compiling and sharing valuable Sanskrit literature datasets openly.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mercity/mahabharat-embeddings.","first_N":5,"first_N_keywords":["question-answering","Sanskrit","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"bhagavad_gita-embeddings","keyword":"sanskrit","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Mercity/bhagavad_gita-embeddings","creator_name":"Mercity","creator_url":"https://huggingface.co/Mercity","description":"Bhagavad Gita Embedding DatasetThis repository contains a specialized embedding dataset of the ancient Indian epic, Bhagavad Gita, suitable for various NLP tasks, semantic search, and text retrieval purposes.\nDataset relesased by Mercity AI!\nDataset SourceThe original textual data has been sourced from the repository: VedaBase.io - Bhagavad Gita Library by ISKCON\nWe extend our sincere gratitude to ISKCON and the maintainers of VedaBase.io for compiling and openly sharing valuable Sanskrit‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mercity/bhagavad_gita-embeddings.","first_N":5,"first_N_keywords":["question-answering","Sanskrit","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"sanskrit","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"wiktionary-data","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QubitPi/wiktionary-data","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","description":"\n\t\n\t\t\n\t\tWiktionary Data on Hugging Face Datasets\n\t\n\n\n\n\n\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\nsupports the following languages:\n\nDeutsch - German\nLatinum - Latin\n·ºôŒªŒªŒ∑ŒΩŒπŒ∫ŒÆ - Ancient Greek\nÌïúÍµ≠Ïñ¥ - Korean\nêé†êéºêéπ - Old PersianíÄùíÖóíÅ∫íåë(íåù) - Akkadian\nElamite\n‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§Æ‡•ç - Sanskrit, or Classical Sanskrit\n\nThe Wiktionary language data is available on ü§ó Hugging Face Datasets. To access the data\nload API library first:\nfrom datasets import load_dataset\n\nThere‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wiktionary-data.","first_N":5,"first_N_keywords":["English","German","Latin","Ancient Greek (to 1453)","Korean"],"keywords_longer_than_N":true},
	{"name":"wiktionary-data","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QubitPi/wiktionary-data","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","description":"\n\t\n\t\t\n\t\tWiktionary Data on Hugging Face Datasets\n\t\n\n\n\n\n\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\nsupports the following languages:\n\nDeutsch - German\nLatinum - Latin\n·ºôŒªŒªŒ∑ŒΩŒπŒ∫ŒÆ - Ancient Greek\nÌïúÍµ≠Ïñ¥ - Korean\nêé†êéºêéπ - Old PersianíÄùíÖóíÅ∫íåë(íåù) - Akkadian\nElamite\n‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§Æ‡•ç - Sanskrit, or Classical Sanskrit\n\nThe Wiktionary language data is available on ü§ó Hugging Face Datasets. To access the data\nload API library first:\nfrom datasets import load_dataset\n\nThere‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wiktionary-data.","first_N":5,"first_N_keywords":["English","German","Latin","Ancient Greek (to 1453)","Korean"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_sa","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_sa","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_sa","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"IN22-Conv-Doc-Level","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IN22-Conv-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"This dataset was constructed by merging individual conversations from the IN22-Conv dataset to create a long-context, document-level parallel benchmark. For further information on domains and statistics, please refer to the original paper and dataset.\n","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"Flores-Indic-Doc-Level","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/Flores-Indic-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"This dataset was constructed by merging individual sentences from the Flores dataset based on matching domain, topic, and URL attributes. The result is a long-context, document-level parallel benchmark. For more details on the domains and dataset statistics, please refer to the original paper and the dataset.\n","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSynthdog Multilingual\n\t\n\n\n\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tSMOL\n\t\n\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\ntranslations into 221 Low-Resource Languages, for the purpose of training\ntranslation models, and otherwise increasing the representations of said\nlanguages in NLP and technology.\nPlease read the SMOL Paper and the\nGATITOS Paper for a much more\nthorough description!\nThere are four resources in this directory:\n\nSmolDoc: document-level translations into 100 languages\nSmolSent: sentence-level translations into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"wiktionary-data","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/paion-data/wiktionary-data","creator_name":"Paion Data","creator_url":"https://huggingface.co/paion-data","description":"\n\t\n\t\t\n\t\tWiktionary Data on Hugging Face Datasets\n\t\n\n\n\n\n\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\nsupports the following languages:\n\nDeutsch - German\nLatinum - Latin\n·ºôŒªŒªŒ∑ŒΩŒπŒ∫ŒÆ - Ancient Greek\nÌïúÍµ≠Ïñ¥ - Korean\nêé†êéºêéπ- Old Persian\níÄùíÖóíÅ∫íåë(íåù) - Akkadian\nElamite\n‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§Æ‡•ç - Sanskrit, or Classical Sanskrit\n\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/paion-data/wiktionary-data.","first_N":5,"first_N_keywords":["English","German","Latin","Ancient Greek (to 1453)","Korean"],"keywords_longer_than_N":true},
	{"name":"wiktionary-data","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/paion-data/wiktionary-data","creator_name":"Paion Data","creator_url":"https://huggingface.co/paion-data","description":"\n\t\n\t\t\n\t\tWiktionary Data on Hugging Face Datasets\n\t\n\n\n\n\n\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\nsupports the following languages:\n\nDeutsch - German\nLatinum - Latin\n·ºôŒªŒªŒ∑ŒΩŒπŒ∫ŒÆ - Ancient Greek\nÌïúÍµ≠Ïñ¥ - Korean\nêé†êéºêéπ- Old Persian\níÄùíÖóíÅ∫íåë(íåù) - Akkadian\nElamite\n‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§Æ‡•ç - Sanskrit, or Classical Sanskrit\n\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/paion-data/wiktionary-data.","first_N":5,"first_N_keywords":["English","German","Latin","Ancient Greek (to 1453)","Korean"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_sa","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_sa","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_sa","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Sanskrit version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_sa.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"RoundTripOCR-sanskrit","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cfilt/RoundTripOCR-sanskrit","creator_name":"Computation for Indian Language Technology","creator_url":"https://huggingface.co/cfilt","description":"Post-OCR error correction dataset (train, test and validation set) for Sanskrit language generated using RoundTripOCR technique.\nCode: https://github.com/harshvivek14/RoundTripOCR\n","first_N":5,"first_N_keywords":["Sanskrit","apache-2.0","1M - 10M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"verb-translation-dataset","keyword":"sanskrit","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Process-Venue/verb-translation-dataset","creator_name":"ProcessVenue","creator_url":"https://huggingface.co/Process-Venue","description":"\n\t\n\t\t\n\t\tProcess-Venue/verb-translation-dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset offers a comprehensive collection of verb translations from English into Hindi, Marathi, and Sanskrit, three major Indian languages. Each entry provides the English verb alongside its corresponding translations, enabling multilingual analysis and cross-lingual studies. The dataset is meticulously curated to support a wide range of natural language processing (NLP) and language technology applications‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Process-Venue/verb-translation-dataset.","first_N":5,"first_N_keywords":["translation","English","Hindi","Marathi","Sanskrit"],"keywords_longer_than_N":true},
	{"name":"ODEN-Indictext","keyword":"sanskrit","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BBSRguy/ODEN-Indictext","creator_name":"Rashmi Ranjan Dash","creator_url":"https://huggingface.co/BBSRguy","description":"\n\t\n\t\t\n\t\tODEN-Indictext üìö\n\t\n\nA tri-lingual (English en, Odia or, Sanskrit sa) question‚Äìanswer\ncorpus derived from the ODEN initiative.\n\nTotal rows: 717\nSplits: train / validation / test = 645 / 35 / 37\nLicense: cc-by-4.0\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\n{\n  \"id\": \"uuid\",\n  \"lang\": \"en|od|sa\",\n  \"question\": \"‚Ä¶\",\n  \"answer\": \"‚Ä¶\"\n}\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"BBSRguy/ODEN-Indictext\", split=\"train\")\nprint(ds[0])\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{oden-indictext-2025‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BBSRguy/ODEN-Indictext.","first_N":5,"first_N_keywords":["English","od","Sanskrit","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bhagwat-Corpus-Data","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PyPranav/Bhagwat-Corpus-Data","creator_name":"Pranav Sunil","creator_url":"https://huggingface.co/PyPranav","description":"\n\t\n\t\t\n\t\tBhagwat Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Bhagwat Corpus is a synthetic dataset of approximately 90,000 examples designed for instruction-tuning large language models (LLMs) to generate Vedic philosophical responses grounded in scriptural tradition. Each example consists of:\n\nA synthetic user question\nA relevant Sanskrit shloka (verse) from the Mahabharata or Ramayana\nAn English translation of the shloka\nA generated explanation and status for the response\n\nThe dataset is based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PyPranav/Bhagwat-Corpus-Data.","first_N":5,"first_N_keywords":["English","Sanskrit","apache-2.0","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Bhagwat-Corpus-Data","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PyPranav/Bhagwat-Corpus-Data","creator_name":"Pranav Sunil","creator_url":"https://huggingface.co/PyPranav","description":"\n\t\n\t\t\n\t\tBhagwat Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Bhagwat Corpus is a synthetic dataset of approximately 90,000 examples designed for instruction-tuning large language models (LLMs) to generate Vedic philosophical responses grounded in scriptural tradition. Each example consists of:\n\nA synthetic user question\nA relevant Sanskrit shloka (verse) from the Mahabharata or Ramayana\nAn English translation of the shloka\nA generated explanation and status for the response\n\nThe dataset is based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PyPranav/Bhagwat-Corpus-Data.","first_N":5,"first_N_keywords":["English","Sanskrit","apache-2.0","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Shiv_puran_OCR","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/snskrt/Shiv_puran_OCR","creator_name":"Sanskrit Datasets","creator_url":"https://huggingface.co/snskrt","description":"\n\t\n\t\t\n\t\tDataset Card for Shlok vs Non Shlok in Shiv puran\n\t\n\nThis dataset will enable a object detection model to differentiate between shlok vs Non-Shlok in this types of books, after that shloks can be cropped and a parallel corpus of image-text can be created.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\nPDF from internet archive was used, will link it here later\n\n\t\n\t\t\n\t\tUses\n\t\n\nTo further develop Sanskrit OCR\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\nWrite a python script to crop the shlok boxes and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/snskrt/Shiv_puran_OCR.","first_N":5,"first_N_keywords":["image-to-image","text-classification","feature-extraction","Sanskrit","Hindi"],"keywords_longer_than_N":true},
	{"name":"Shiv_Mahapuran","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/snskrt/Shiv_Mahapuran","creator_name":"Sanskrit Datasets","creator_url":"https://huggingface.co/snskrt","description":"\n\t\n\t\t\n\t\tDataset Card for Shiv_Mahapuran\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a complete, structured representation of the ≈öiva MahƒÅpurƒÅ·πáa (often called ≈öivapurƒÅ·πáa) in CSV format. It is broken down into Sa·πÉhitƒÅs (seven surviving Sa·πÉhitƒÅs), Kha·πá·∏ças, AdhyƒÅyas, and individual ≈õlokas, enabling fine-grained NLP work on classical Sanskrit scripture.\n\nCurated by: Aluminium  \nOrganization: Snskrt  \nShared by: Snskrt  \nLanguage(s): Sanskrit (ISO code: sa)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/snskrt/Shiv_Mahapuran.","first_N":5,"first_N_keywords":["feature-extraction","text-classification","token-classification","translation","text-generation"],"keywords_longer_than_N":true},
	{"name":"Shrimad_Bhagavad_Gita","keyword":"sanskrit","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/snskrt/Shrimad_Bhagavad_Gita","creator_name":"Sanskrit Datasets","creator_url":"https://huggingface.co/snskrt","description":"snskrt/Shrimad_Bhagavad_Gita dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","token-classification","translation","summarization","text-generation"],"keywords_longer_than_N":true},
	{"name":"SanskritShlokasClassification","keyword":"sanskrit","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/SanskritShlokasClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SanskritShlokasClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis data set contains ~500 Shlokas  \n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReligious, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-sanskrit\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"SanskritShlokasClassification\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SanskritShlokasClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","bpHigh/iNLTK_Sanskrit_Shlokas_Dataset"],"keywords_longer_than_N":true},
	{"name":"sango-sentiments-corpus","keyword":"sanskrit","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/michsethowusu/sango-sentiments-corpus","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","description":"\n\t\n\t\t\n\t\tSango Sentiment Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains sentiment-labeled text data in Sango for binary sentiment classification (Positive/Negative). Sentiments are extracted and processed from the English meanings of the sentences using DistilBERT for sentiment classification. The dataset is part of a larger collection of African language sentiment analysis resources.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal samples: 119,538\nPositive sentiment: 73005 (61.1%)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/sango-sentiments-corpus.","first_N":5,"first_N_keywords":["text-classification","Sanskrit","mit","100K - 1M","parquet"],"keywords_longer_than_N":true}
]
;
