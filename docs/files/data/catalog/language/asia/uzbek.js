const data_for_language_asia_uzbek = 
[
	{"name":"MultiQ","keyword":"uzbek","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiQ\\n\\t\\n\\nThis is the dataset corresponding to the paper \\\"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\\\". \\nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \\ntranslated into 137 typologically diverse languages. \\n\\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"uzbek","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"uzbek","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"uzbek","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"DPO-uz-9k","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MLDataScientist/DPO-uz-9k","creator_name":"Saeed","creator_url":"https://huggingface.co/MLDataScientist","description":"This is DPO Uzbek translated dataset with 9k chat pairs.\\nOriginal English dataset comes from DPO-En-Zh-20k (commit 9ad5f7428419d3cf78493cf3f4be832cf5346ba8. File:  dpo_en.json).\\nI translated 10k pairs of chat examples into Uzbek using NLLB 3.3B model.\\nAfter translation was completed, I used local lilac instance to remove records with coding examples since NLLB is not good at translating text with coding examples. \\nNote that each prompt has two answers. The first answer should be the 'selected'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MLDataScientist/DPO-uz-9k.","first_N":5,"first_N_keywords":["text-generation","Uzbek","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"SFT-UZ-9k","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MLDataScientist/SFT-UZ-9k","creator_name":"Saeed","creator_url":"https://huggingface.co/MLDataScientist","description":"This is SFT version of MLDataScientist/DPO-uz-9k (Uzbek translated dataset with two answers for each prompt for DPO fine-tuning).\\nI selected ['answer'][0] from each example and saved them in this dataset for easy fine-tuning of LLMs.\\n","first_N":5,"first_N_keywords":["text-generation","Uzbek","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"uzbek-sentiment-analysis","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/risqaliyevds/uzbek-sentiment-analysis","creator_name":"Riskaliev Muradjon","creator_url":"https://huggingface.co/risqaliyevds","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUzum Market Sentiment Analysis Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout the Dataset\\n\\t\\n\\nThis dataset is created for performing sentiment analysis on comments from Uzum Market. The dataset allows for evaluating the sentiments in the comments and categorizing them into various ratings.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure\\n\\t\\n\\nThe data is provided in JSON format with the following structure:\\n{\\n    \\\"features\\\": [\\\"normalized_review_text\\\", \\\"rating\\\"],\\n    \\\"num_rows\\\": 352151\\n}\\n\\nRatings are defined as follows:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/risqaliyevds/uzbek-sentiment-analysis.","first_N":5,"first_N_keywords":["text-classification","token-classification","Uzbek","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"uzbek_sa","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DGurgurov/uzbek_sa","creator_name":"Daniil Gurgurov","creator_url":"https://huggingface.co/DGurgurov","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentiment Analysis Data for the Uzbek Language\\n\\t\\n\\nDataset Description:\\nThis dataset contains a sentiment analysis dataset from Kuriyozov et al. (2019).\\nData Structure:\\nThe data was used for the project on improving word embeddings with graph knowledge for Low Resource Languages.\\nCitation:\\n@inproceedings{DBLP:conf/ltconf/KuriyozovMAG19,\\n  author    = {Elmurod Kuriyozov and\\n               Sanatbek Matlatipov and\\n               Miguel A. Alonso and\\n               Carlos‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DGurgurov/uzbek_sa.","first_N":5,"first_N_keywords":["text-classification","Uzbek","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"SlimOrca-Dedup-English-Uzbek","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MLDataScientist/SlimOrca-Dedup-English-Uzbek","creator_name":"Saeed","creator_url":"https://huggingface.co/MLDataScientist","description":"This is an Uzbek translated version of https://huggingface.co/datasets/Open-Orca/SlimOrca-Dedup.\\nIt is a single parquet file.\\nCheck here for cleaned Uzbek only slim Orca dataset: https://huggingface.co/datasets/MLDataScientist/SlimOrca-Dedup-Uzbek-cleaned\\n","first_N":5,"first_N_keywords":["text-classification","text2text-generation","text-generation","question-answering","Uzbek"],"keywords_longer_than_N":true},
	{"name":"SlimOrca-Dedup-Uzbek-cleaned","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MLDataScientist/SlimOrca-Dedup-Uzbek-cleaned","creator_name":"Saeed","creator_url":"https://huggingface.co/MLDataScientist","description":"This is an Uzbek translated and cleaned version of https://huggingface.co/datasets/Open-Orca/SlimOrca-Dedup. \\nSpecifically, these replaced/removed records that had 'Uzbek translation|Uzbekcha tarjima|Uzbek tarjima|impossible to translate|not possible to translate|cannot fulfill your request|text is in|tilida yozilgan|Uzbek|o'zbek|ozbek|I am sorry'.\\nYou can use this dataset for chat fine-tuning of LLMs.\\nThis dataset has around 100M tokens (500M*0.8/4 = 100M assuming 4 chars are one token).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MLDataScientist/SlimOrca-Dedup-Uzbek-cleaned.","first_N":5,"first_N_keywords":["text-generation","text-classification","question-answering","Uzbek","mit"],"keywords_longer_than_N":true},
	{"name":"fleurs_En_Uz","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MLDataScientist/fleurs_En_Uz","creator_name":"Saeed","creator_url":"https://huggingface.co/MLDataScientist","description":"This is a clean copy of google/fleurs dataset that has translation of text data in 100s of languages with speech.\\nThe primary goal of this dataset is to use it in fine-tuning phase of an LLM so that it could better translate English to Uzbek.\\nYou should add one more column called 'system instruction' and add some command like below:\\n\\\"Ushbu matnni ingliz tilidan o'zbek tiliga tarjima qiling.\\\"\\nPrompt: English text\\nResponse: Uzbek text\\n","first_N":5,"first_N_keywords":["translation","question-answering","text2text-generation","Uzbek","English"],"keywords_longer_than_N":true},
	{"name":"Wikipedia-uzbek-2024-05-01","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MLDataScientist/Wikipedia-uzbek-2024-05-01","creator_name":"Saeed","creator_url":"https://huggingface.co/MLDataScientist","description":"This dataset contains wikipedia dump in the Uzbek language for the date May 2024. \\n","first_N":5,"first_N_keywords":["text-generation","text-classification","Uzbek","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"uzbek-zero-shot-classification","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/risqaliyevds/uzbek-zero-shot-classification","creator_name":"Riskaliev Muradjon","creator_url":"https://huggingface.co/risqaliyevds","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUzbek Zero-Shot Classification Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout the Dataset\\n\\t\\n\\nThis dataset is created for categorizing texts in Uzbek into various categories. The dataset is prepared based on news websites and includes the following categories: Politics, Economy, Technology, Sports, Culture, Health, Family and Society, Education, Ecology, Foreign News.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure\\n\\t\\n\\nThe data is provided in JSON format with the following structure:\\n{\\n    \\\"classes\\\": \\n        Siyosat - If‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/risqaliyevds/uzbek-zero-shot-classification.","first_N":5,"first_N_keywords":["zero-shot-classification","Uzbek","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"uzbekpos","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/latofat/uzbekpos","creator_name":"Latofat Bobojonova","creator_url":"https://huggingface.co/latofat","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"uzbekpos\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nUzbek POS: First UPOS tagged dataset for Part-of-Speech tagging task\\nThis dataset is an annotated dataset for POS tagging. It contains 250 sample sentences collected from news outlets and fictional books respectively.\\nThe dataset is presented in both Uzbek scripts i.e., Latin and Cyrillic. The annotation was done manually according to UPOS tagset.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nNorthern Uzbek (a.k.a Uzbek)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/latofat/uzbekpos.","first_N":5,"first_N_keywords":["token-classification","Uzbek","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"uzbek","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"uz-data","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/uz-data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/uz-data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"UZ_voice","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/UZ_voice","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/UZ_voice dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"STT_uz","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/STT_uz","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"The dataset is organized into the following directories and files:\\naudio/\\nother/: Contains .tar archives like uz_other_0.taruz_other_1.tar\\ntrain/: Contains .tar archives like uz_train_0.tar.\\nvalidated/: Contains .tar archives like uz_validated_0.tar, uz_validated_1.tar, and uz_validated_2.tar.\\ntest/: Contains individual .wav files.\\ntranscription/: Contains .tsv files including:\\nother.tsv\\ntrain.tsv\\nvalidated.tsv\\ntest.tsv\\nThe .tsv files have two columns: file_name and transcription. Each entry‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Beehzod/STT_uz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","10K - 100K","webdataset"],"keywords_longer_than_N":true},
	{"name":"uzbek_stt_data","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/uzbek_stt_data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/uzbek_stt_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","100K - 1M","webdataset"],"keywords_longer_than_N":true},
	{"name":"new_data","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/new_data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/new_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"dilmash","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tahrirchi/dilmash","creator_name":"Tahrirchi","creator_url":"https://huggingface.co/tahrirchi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDilmash: Karakalpak Parallel Corpus\\n\\t\\n\\nThis repository contains a parallel corpus for the Karakalpak language, developed as part of the research paper \\\"Open Language Data Initiative: Advancing Low-Resource Machine Translation for Karakalpak\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Karakalpak Parallel Corpus is a collection of 300,000 sentence pairs, designed to support machine translation tasks involving the Karakalpak language. It includes:\\n\\nUzbek-Karakalpak (100,000 pairs)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tahrirchi/dilmash.","first_N":5,"first_N_keywords":["translation","English","Russian","Uzbek","Kara-Kalpak"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"uz-wiki","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yakhyo/uz-wiki","creator_name":"Yakhyo Valikhujaev","creator_url":"https://huggingface.co/yakhyo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUzbek Wikipedia Dataset\\n\\t\\n\\nThis dataset comprises a collection of Uzbek Wikipedia articles as of 2024.09.20. It is designed for use in text generation tasks and other NLP applications.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Uzbek Wikipedia Dataset provides a diverse collection of high-quality text extracted from Wikipedia. The dataset is specifically tailored for the Uzbek language and can be used for a variety of Natural Language Processing (NLP) tasks, such as text generation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yakhyo/uz-wiki.","first_N":5,"first_N_keywords":["text-generation","Uzbek","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"uz-news","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yakhyo/uz-news","creator_name":"Yakhyo Valikhujaev","creator_url":"https://huggingface.co/yakhyo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUzbek News Dataset\\n\\t\\n\\nThis dataset was originally for text classification and you can access to it here.\\nMany thanks to the authors of the dataset,  @murodbek et al.\\n@proceedings{kuriyozov_elmurod_2023_7677431,\\n  title        = {{Text classification dataset and analysis for Uzbek \\n                   language}},\\n  year         = 2023,\\n  publisher    = {Zenodo},\\n  month        = feb,\\n  doi          = {10.5281/zenodo.7677431},\\n  url          = {https://doi.org/10.5281/zenodo.7677431}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yakhyo/uz-news.","first_N":5,"first_N_keywords":["text-classification","text-generation","Uzbek","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"kompy","keyword":"uzbek","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/kompy","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Kompy.info\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 584,648 pages of educational content in Uzbek language extracted from kompy.info website. The content includes academic and educational materials, with a focus on technical and scientific topics.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Uzbek (uz).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes the following fields:\\n\\nurl: URL of the webpage (string)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/kompy.","first_N":5,"first_N_keywords":["text-classification","text-generation","topic-classification","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"alpaca-cleaned_uz","keyword":"uzbek","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bizb0630/alpaca-cleaned_uz","creator_name":"Behruz Izbaev","creator_url":"https://huggingface.co/bizb0630","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a translation of the alpaca-cleaned dataset into Uzbek (Latin), using the GPT-4o mini API.\\n","first_N":5,"first_N_keywords":["text-generation","Uzbek","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"zero-shot-classification-news-uzbek","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ShakhzoDavronov/zero-shot-classification-news-uzbek","creator_name":"Shakhzod Davronov","creator_url":"https://huggingface.co/ShakhzoDavronov","description":"ShakhzoDavronov/zero-shot-classification-news-uzbek dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["zero-shot-classification","found","Uzbek","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"uzlib","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tahrirchi/uzlib","creator_name":"Tahrirchi","creator_url":"https://huggingface.co/tahrirchi","description":"\\n\\t\\n\\t\\t\\n\\t\\tUzbek Linguistic Benchmark (UzLiB)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Uzbek Linguistic Benchmark (UzLiB) is a benchmark with multiple-choice questions for evaluating linguistic abilities of Large Language Models (LLMs) in Uzbek language. \\nTo load and use dataset, run this script:\\nfrom datasets import load_dataset\\n\\nuzlib = load_dataset(\\\"murodbek/uzlib\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nAn example of correct_word looks as follows.\\n{'id': 'CW1242',\\n 'question': 'Berilgan variantlar‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tahrirchi/uzlib.","first_N":5,"first_N_keywords":["question-answering","Uzbek","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"uzlib","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tahrirchi/uzlib","creator_name":"Tahrirchi","creator_url":"https://huggingface.co/tahrirchi","description":"\\n\\t\\n\\t\\t\\n\\t\\tUzbek Linguistic Benchmark (UzLiB)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Uzbek Linguistic Benchmark (UzLiB) is a benchmark with multiple-choice questions for evaluating linguistic abilities of Large Language Models (LLMs) in Uzbek language. \\nTo load and use dataset, run this script:\\nfrom datasets import load_dataset\\n\\nuzlib = load_dataset(\\\"murodbek/uzlib\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nAn example of correct_word looks as follows.\\n{'id': 'CW1242',\\n 'question': 'Berilgan variantlar‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tahrirchi/uzlib.","first_N":5,"first_N_keywords":["question-answering","Uzbek","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\\nsource: the source sentence.\\nchosen: the preferred translation.\\nreject: the dis-preferred translation.\\ndirections: the translation direction.\\n@misc{xu2024xalmaplugplay,\\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \\n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\\n      year={2024},\\n      eprint={2410.03115}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"product-database","keyword":"uzbek","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Food Facts Database\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is üçä Open Food Facts?\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tA food products database\\n\\t\\n\\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\\n\\n\\t\\n\\t\\t\\n\\t\\tMade by everyone\\n\\t\\n\\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"uzbek","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"translated_dataset","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Xondamir/translated_dataset","creator_name":"Xondamir Xamroyev","creator_url":"https://huggingface.co/Xondamir","description":"Xondamir/translated_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["summarization","Uzbek","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"bot_stt","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/bot_stt","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/bot_stt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Global-MMLU-Lite-uz","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/murodbek/Global-MMLU-Lite-uz","creator_name":"Abror Shopulatov","creator_url":"https://huggingface.co/murodbek","description":"Uzbek version of Global-MMLU-Lite dataset. Current version is automatically translated using 2 step process in Tilmoch platform. Subsequent releases will hopefully include human annotation process too.\\nFor more information, please refer to Global MMLU paper. \\n","first_N":5,"first_N_keywords":["Uzbek","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU-uz","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/murodbek/Global-MMLU-uz","creator_name":"Abror Shopulatov","creator_url":"https://huggingface.co/murodbek","description":"Uzbek version of Global-MMLU dataset. Current version is automatically translated using 2 step process in Tilmoch platform. Subsequent releases will hopefully include human annotation process too.\\nFor more information, please refer to Global MMLU paper.\\n","first_N":5,"first_N_keywords":["question-answering","Uzbek","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"uzbek","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\\n\\n   \\n       Overview |\\n       Details  |\\n       Structure  |\\n       Examples |\\n       Considerations |\\n       License |\\n       Citation |\\n       Contact |\\n       Acknowledgement\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"belebele","keyword":"uzbek","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\\n\\t\\n\\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele.","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","text-classification","multiple-choice","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"uz-books","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tahrirchi/uz-books","creator_name":"Tahrirchi","creator_url":"https://huggingface.co/tahrirchi","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for BookCorpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on low-resource languages, we release UzBooks dataset, a cleaned book corpus consisting of nearly 40000 books in Uzbek Language divided into two branches: \\\"original\\\" and \\\"lat,\\\" representing the OCRed (Latin and Cyrillic) and fully Latin versions of the texts, respectively. \\nPlease refer to our blogpost and paper (Coming soon!) for further details.\\nTo load and use dataset, run this script:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tahrirchi/uz-books.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"uzbek","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\\n","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"uzbekvoice-filtered","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DavronSherbaev/uzbekvoice-filtered","creator_name":"Dovron Sherbaev","creator_url":"https://huggingface.co/DavronSherbaev","description":"This is heavy filtered version of the dataset with additional information.\\nThis dataset does not contain original Mozilla Common Voice audios or texts\\nWe filtered the dataset using number approaches:\\n\\nVAD + Noise detection. Audios which lacked voice activity and produced no sound after denoiser were removed\\nReading Speed. Audios with outlier speeds (approximately 5-10%), as they didnt match natural speed or were too noisy\\nAutomatic STT validation. We trained the model using subset of valid‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DavronSherbaev/uzbekvoice-filtered.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection.","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\\n\\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\\nmachine-translations of handpicked examples into 101 languages ‚Üí‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"uzbek","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \\nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \\nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection_language_split","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection_language_split.","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"oasst2_uzbek","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MLDataScientist/oasst2_uzbek","creator_name":"Saeed","creator_url":"https://huggingface.co/MLDataScientist","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen Assistant Conversations Dataset Release 2 (OASST2) in Uzbek language\\n\\t\\n\\nThis dataset is an Uzbek translated version of OASST2 dataset.\\nLlama3 chat template + thread formatted dataset based on this translation is also available for model fine-tuning here. \\nThe Uzbek translation was completed in 45 hours using a single T4 GPU and nllb-200-3.3B model.\\nBased on nllb metrics, you might want to only filter out records that were not originally in English or Russian since‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MLDataScientist/oasst2_uzbek.","first_N":5,"first_N_keywords":["question-answering","translation","Uzbek","apache-2.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"uzbek_ner","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/risqaliyevds/uzbek_ner","creator_name":"Riskaliev Muradjon","creator_url":"https://huggingface.co/risqaliyevds","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUzbek NER Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout the Dataset\\n\\t\\n\\nThis dataset is created for Named Entity Recognition (NER) in Uzbek texts. The dataset includes named entities from various categories such as persons, places, organizations, dates, and more.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure\\n\\t\\n\\nThe data is provided in JSON format with the following structure:\\n{\\n    \\\"LOC\\\": [\\\"Location names\\\"],\\n    \\\"ORG\\\": [\\\"Organization names\\\"],\\n    \\\"PERSON\\\": [\\\"Person names\\\"],\\n    \\\"DATE\\\": [\\\"Date expressions\\\"]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/risqaliyevds/uzbek_ner.","first_N":5,"first_N_keywords":["token-classification","Uzbek","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"uzbek","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"Uzbek_news_dataset","keyword":"uzbek","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MLDataScientist/Uzbek_news_dataset","creator_name":"Saeed","creator_url":"https://huggingface.co/MLDataScientist","description":"This is an Uzbek News Dataset with 512,750 articles (120 million words and in the Latin script) scraped from the web in 2023. \\nI combined and uploaded the dataset in this HF repo so that the community can fine-tune LLMs based on the Uzbek language.\\n\\n@proceedings{kuriyozov_elmurod_2023_7677431,\\n  title        = {{Text classification dataset and analysis for Uzbek \\n                   language}},\\n  year         = 2023,\\n  publisher    = {Zenodo},\\n  month        = feb,\\n  doi          =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MLDataScientist/Uzbek_news_dataset.","first_N":5,"first_N_keywords":["text-generation","Uzbek","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"uzbek_speech_data","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/uzbek_speech_data","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/uzbek_speech_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"uzbek-instruct-llm","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UAzimov/uzbek-instruct-llm","creator_name":"Utkirbek","creator_url":"https://huggingface.co/UAzimov","description":"uzbek-instruct-llm  is a corpus of more than 15,000 records. It's made for instruct fine-tuning large language models for Uzbek language. It's mostly translated from other instruct datasets with some extra data added\\n","first_N":5,"first_N_keywords":["text-generation","Uzbek","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"uzbek-sentiment-analysis","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/behbudiy/uzbek-sentiment-analysis","creator_name":"Behbudiy Labs","creator_url":"https://huggingface.co/behbudiy","description":"Original Dataset: https://huggingface.co/datasets/risqaliyevds/uzbek-sentiment-analysis\\nBinary sentiment analysis dataset for benchmarking purposes. It was annotated using GPT-4o API.\\nLabel 1 is for Positive, 0 for Negative.\\n","first_N":5,"first_N_keywords":["text-classification","Uzbek","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"uzbek","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"uzbek","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBelebele-Fleurs\\n\\t\\n\\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\\n\\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/include-base-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-base (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-base-44.","first_N":5,"first_N_keywords":["text2text-generation","multiple-choice","Albanian","Arabic","Armenian"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/include-lite-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-lite (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-lite-44.","first_N":5,"first_N_keywords":["text2text-generation","multiple-choice","Albanian","Arabic","Armenian"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReranker training data\\n\\t\\n\\nThis data was generated using 4 steps:\\n\\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \\\"1\\\", \\\"2\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"uzbek-speech-corpus","keyword":"uzbek","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/murodbek/uzbek-speech-corpus","creator_name":"Abror Shopulatov","creator_url":"https://huggingface.co/murodbek","description":"\\n\\t\\n\\t\\t\\n\\t\\tUzbek Speech Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Uzbek speech corpus (USC) has been developed in collaboration between ISSAI and the Image and Speech Processing Laboratory in the Department of Computer Systems of the Tashkent University of Information Technologies. The USC comprises 958 different speakers with a total of 105 hours of transcribed audio recordings. To ensure high quality, the USC has been manually checked by native speakers. The USC is primarily designed for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/murodbek/uzbek-speech-corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"xquad_uz","keyword":"uzbek","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IzzatilloAI/xquad_uz","creator_name":"Izzatillo Yuldashev","creator_url":"https://huggingface.co/IzzatilloAI","description":"XQuAD.uz: A Multilingual Benchmark for Question Answering in Uzbek\\nDataset Summary:\\nXQuAD.uz is the Uzbek translation of the XQuAD (Cross-lingual Question Answering Dataset), designed to evaluate the performance of multilingual language models on the Uzbek language. It includes question-answer pairs that test a model‚Äôs ability to understand and respond accurately in Uzbek.\\nLanguages:\\nUzbek (Latin script)\\nUse Cases:\\nBenchmarking the performance of multilingual and Uzbek-specific language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IzzatilloAI/xquad_uz.","first_N":5,"first_N_keywords":["question-answering","Uzbek","cc-by-sa-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthdog Multilingual\\n\\t\\n\\n\\n\\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy It‚Äôs Important\\n\\t\\n\\n\\nEnhances Trust: For readers and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"uzbek","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"uzbek","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"uzbek","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"pwesuite-eval","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zouharvi/pwesuite-eval","creator_name":"Vil√©m Zouhar","creator_url":"https://huggingface.co/zouharvi","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tPWESuite-Eval\\n\\t\\n\\nDataset composed of multiple smaller datasets used for the evaluation of phonetic word embeddings.\\nSee code for evaluation here.\\nIf you use this dataset/evaluation, please cite the paper at LREC-COLING 2024:\\n@inproceedings{zouhar-etal-2024-pwesuite,\\n    title = \\\"{PWES}uite: Phonetic Word Embeddings and Tasks They Facilitate\\\",\\n    author = \\\"Zouhar, Vil{\\\\'e}m  and\\n      Chang, Kalvin  and\\n      Cui, Chenxuan  and\\n      Carlson, Nate B.  and\\n      Robinson, Nathaniel‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/pwesuite-eval.","first_N":5,"first_N_keywords":["multilingual","English","Amharic","Bengali","Swahili"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"uzbek","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"uzbek","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EntityCS\\n\\t\\n\\n\\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \\nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \\nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \\nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"seamless-align","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to use the data\\n\\t\\n\\nThere are two ways to access the data:\\n\\nVia the Hugging Face Python datasets library\\n\\nScripts coming soon‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align.","first_N":5,"first_N_keywords":["translation","audio-to-audio","Maltese","English","Welsh"],"keywords_longer_than_N":true},
	{"name":"uz-crawl","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tahrirchi/uz-crawl","creator_name":"Tahrirchi","creator_url":"https://huggingface.co/tahrirchi","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for UzCrawl\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on low-resource languages, we release UzCrawl dataset, a web and telegram crawl corpus consisting of materials from nearly 1.2 million unique sources in the Uzbek Language. \\nPlease refer to our blogpost for further details.\\nP.S. We updated the dataset with 2nd version that extends the scope to new topics as well as being up to date to March 2024.\\nTo load and use dataset, run this script:\\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tahrirchi/uz-crawl.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"lr-sum","keyword":"uzbek","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LR-Sum\\n\\t\\n\\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \\nThe data is based on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum.","first_N":5,"first_N_keywords":["summarization","text-generation","found","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"Pontoon-Translations","keyword":"uzbek","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","text2text-generation","crowdsourced","Abkhaz","Achinese"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"uzbek","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"Fran√ßais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog convention‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"Deltacorpus_1.1","keyword":"uzbek","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, Portoro≈æ, Slovenia).\\nChanges in version 1.1: \\n\\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \\n\\nSVM classifier trained on Universal Dependencies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1.","first_N":5,"first_N_keywords":["token-classification","multilingual","Afrikaans","Albanian","Amharic"],"keywords_longer_than_N":true},
	{"name":"saeedai-mini","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/otajonogli/saeedai-mini","creator_name":"Ro'zmat Otajon o'g'li","creator_url":"https://huggingface.co/otajonogli","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Saeed AI Mini\\n\\t\\n\\n","first_N":5,"first_N_keywords":["English","Uzbek","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"dataset_for_STT_TTSmodels","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Beehzod/dataset_for_STT_TTSmodels","creator_name":"Hoshimov","creator_url":"https://huggingface.co/Beehzod","description":"Beehzod/dataset_for_STT_TTSmodels dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Uzbek","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Uzbek_Speech_Corpus","keyword":"uzbek","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/issai/Uzbek_Speech_Corpus","creator_name":"Institute of Smart Systems and Artificial Intelligence, Nazarbayev University","creator_url":"https://huggingface.co/issai","description":"\\n\\t\\n\\t\\t\\n\\t\\tUzbek Speech Corpus (USC)\\n\\t\\n\\nPaper: USC: An Open-Source Uzbek Speech Corpus and Initial Speech Recognition Experiments\\nSummary: This repository contains dataset for reproducing the results presented in the paper \\\"USC: An Open-Source Uzbek Speech Corpus\\\". USC is a freely available, manually checked speech corpus comprising 958 speakers and 105 hours of transcribed audio recordings. \\nDataset Summary:\\n\\n\\t\\n\\t\\t\\nFeature\\nDescription\\n\\n\\n\\t\\t\\nLanguage\\nUzbek\\n\\n\\nSize\\n105 hours of audio\\n\\n\\nNumber of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/issai/Uzbek_Speech_Corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Uzbek","mit","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"uzbek","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true}
]
;
