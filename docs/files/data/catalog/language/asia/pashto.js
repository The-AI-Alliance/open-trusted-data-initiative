const data_for_language_asia_pashto = 
[
	{"name":"panlex","keyword":"southern pashto","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Loïck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it… See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex."},
	{"name":"ChatML-aya_dataset","keyword":"pushto","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = [\\n        {\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": columns[\\\"inputs\\\"].strip(),\\n        },\\n        {… See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset."},
	{"name":"MultiQ","keyword":"pashto","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiQ\\n\\t\\n\\nThis is the dataset corresponding to the paper \\\"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\\\". \\nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \\ntranslated into 137 typologically diverse languages. \\n\\nCurated by: Carolin Holtermann, Paul Röttger, Timm Dill, Anne Lauscher\\nLanguage(s) (NLP): 137 diverse… See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ."},
	{"name":"bhojpuri","keyword":"pushto","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri."},
	{"name":"panlex-meanings","keyword":"southern pashto","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are in… See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings."},
	{"name":"NTREX","keyword":"pashto","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian… See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX."},
	{"name":"indic-swim-ir-cross-lingual","keyword":"pashto","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/indic-swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Indic SWIM-IR (Cross-lingual)\\n\\t\\n\\n\\n\\n\\nThis is the cross-lingual Indic subset of the SWIM-IR dataset, where the query generated is in the Indo-European language and the passage is in English.\\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is… See the full description on the dataset page: https://huggingface.co/datasets/nthakur/indic-swim-ir-cross-lingual."},
	{"name":"xsimplusplus","keyword":"southern pashto","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n"},
	{"name":"sib200","keyword":"southern pashto","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :… See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200."},
	{"name":"NTREX","keyword":"pashto","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian… See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX."},
	{"name":"ParaNames","keyword":"pashto","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames."},
	{"name":"CaLMQA","keyword":"pashto","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shanearora/CaLMQA","creator_name":"Shane Arora","creator_url":"https://huggingface.co/shanearora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\n\\nCaLMQA is a long-form question answering (LFQA) dataset spanning 23 high- to low-resource languages. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCaLMQA is an LFQA dataset with 2K questions from 23 languages, 11 high- to mid-resource and 12 low-resource.\\nQuestions are either culturally specific – uniquely or more likely to be asked by people of a specific\\nculture – or culturally agnostic (not culturally specific). These questions were… See the full description on the dataset page: https://huggingface.co/datasets/shanearora/CaLMQA."},
	{"name":"bitext_sib200_miners","keyword":"southern pashto","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"fleurs_clean","keyword":"pushto","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean."},
	{"name":"xP3x-Kongo","keyword":"southern pashto","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys Fé-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI 🧡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save… See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo."},
	{"name":"pashto-wikipedia-corpus","keyword":"pashto","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto-wikipedia-corpus","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pashto Wikipedia Clean Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a cleaned version of the Pashto Wikipedia dump. It has been processed to remove HTML tags, URLs, special characters, and numbers. The text has been normalized and filtered to remove very short entries.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is in Pashto (ps).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nEach instance in the dataset contains the following fields:… See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto-wikipedia-corpus."},
	{"name":"muri-it-language-split","keyword":"pushto","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic… See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split."},
	{"name":"MegaWika","keyword":"pashto","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/conceptofmind/MegaWika","creator_name":"Enrico Shippole","creator_url":"https://huggingface.co/conceptofmind","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. Furthermore, nearly 130 million English… See the full description on the dataset page: https://huggingface.co/datasets/conceptofmind/MegaWika."},
	{"name":"test_4","keyword":"pushto","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4."},
	{"name":"pashto_speech_2k","keyword":"pashto","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_2k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\\n\\t\\n\\t\\t\\n\\t\\tPashto Synthetic Speech Dataset (2k)\\n\\t\\n\\nThis dataset contains 4000 synthetic speech recordings in the Pashto language,\\nwith 2000 male voice recordings and 2000 female voice recordings.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nDataset Size: 2000 sentences\\nTotal Recordings: 4000 audio files (2000 male + 2000 female)\\nAudio Format: WAV, 44.1kHz, 16-bit PCM\\nSampling Rate: 44.1kHz (44100 Hz)\\nVoices: \\nMale: ps-AF-GulNawazNeural\\nFemale: ps-AF-LatifaNeural\\n\\n\\nTotal Audio Duration: \\nMale: 0.00 seconds… See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_2k."},
	{"name":"pashto_speech_2k","keyword":"pashto","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ihanif/pashto_speech_2k","creator_name":"Hanif Rahman","creator_url":"https://huggingface.co/ihanif","description":"\\n\\t\\n\\t\\t\\n\\t\\tPashto Synthetic Speech Dataset (2k)\\n\\t\\n\\nThis dataset contains 4000 synthetic speech recordings in the Pashto language,\\nwith 2000 male voice recordings and 2000 female voice recordings.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nDataset Size: 2000 sentences\\nTotal Recordings: 4000 audio files (2000 male + 2000 female)\\nAudio Format: WAV, 44.1kHz, 16-bit PCM\\nSampling Rate: 44.1kHz (44100 Hz)\\nVoices: \\nMale: ps-AF-GulNawazNeural\\nFemale: ps-AF-LatifaNeural\\n\\n\\nTotal Audio Duration: \\nMale: 0.00 seconds… See the full description on the dataset page: https://huggingface.co/datasets/ihanif/pashto_speech_2k."},
	{"name":"wmt-da-human-evaluation","keyword":"pashto","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation","creator_name":"Ricardo Costa Dias Rei","creator_url":"https://huggingface.co/RicardoRei","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains all DA human annotations from previous WMT News Translation shared tasks.\\nThe data is organised into 8 columns:\\n\\nlp: language pair\\nsrc: input text\\nmt: translation\\nref: reference translation\\nscore: z score\\nraw: direct assessment\\nannotators: number of annotators\\ndomain: domain of the input text (e.g. news)\\nyear: collection year\\n\\nYou can also find the original data for each year in the results section… See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation."},
	{"name":"belebele","keyword":"pashto","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\\n\\t\\n\\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that… See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele."},
	{"name":"aya_dataset","keyword":"pushto","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_dataset","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\n\\nCurated by: Contributors of Aya Open Science Intiative.\\n\\nLanguage(s): 65 languages (71 including dialects &… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_dataset."},
	{"name":"aya_collection","keyword":"pushto","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection."},
	{"name":"aya_evaluation_suite","keyword":"pushto","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\\n\\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) → aya-human-annotated.\\nmachine-translations of handpicked examples into 101 languages →… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite."},
	{"name":"CulturaY","keyword":"pashto","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \\nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \\nThis data was used in part to train our SOTA… See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY."},
	{"name":"sib200","keyword":"southern pashto","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :… See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200."},
	{"name":"aya_collection_language_split","keyword":"pushto","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection_language_split","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection_language_split."},
	{"name":"GlotCC-V1","keyword":"pushto","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --… See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
	{"name":"GlotCC-V1","keyword":"southern pashto","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --… See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
	{"name":"muri-it","keyword":"pushto","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic… See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it."},
	{"name":"HPLT2.0_cleaned","keyword":"southern pashto","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files… See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned."},
	{"name":"belebele-fleurs","keyword":"pashto","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBelebele-Fleurs\\n\\t\\n\\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\\n\\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs."},
	{"name":"2M-Belebele","keyword":"pashto","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2M-Belebele\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\\n\\t\\n\\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \\nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs… See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele."},
	{"name":"reranker_continuous_filt_max7_train","keyword":"pashto","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReranker training data\\n\\t\\n\\nThis data was generated using 4 steps:\\n\\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \\\"1\\\", \\\"2\\\"… See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train."},
	{"name":"sib-fleurs","keyword":"southern pashto","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes and… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs."},
	{"name":"wmt-da-human-evaluation-long-context","keyword":"pashto","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLong-context / document-level dataset for Quality Estimation of Machine Translation.\\nIt is an augmented variant of the sentence-level WMT DA Human Evaluation dataset.\\nIn addition to individual sentences, it contains augmentations of 2, 4, 8, 16, and 32 sentences, among each language pair lp and domain.\\nThe raw column represents a weighted average of scores of augmented sentences using character lengths of src and mt as weights.\\nThe code used to apply the augmentation… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context."},
	{"name":"multilingual_translation_sft","keyword":"pashto","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"opus_ubuntu","keyword":"pashto","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and… See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu."},
	{"name":"flores_101","keyword":"pashto","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
	{"name":"HashtagPrediction","keyword":"pashto","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\\n\\t\\n\\n  \\nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \\n[arXiv]\\n[HuggingFace Models]\\n[Github repo]\\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDownload\\n\\t\\n\\nUse the… See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction."},
	{"name":"flores_101","keyword":"pashto","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
	{"name":"xP3x-sample","keyword":"southern pashto","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities."},
	{"name":"wikianc","keyword":"pashto","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is… See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc."},
	{"name":"entity_cs","keyword":"pashto","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EntityCS\\n\\t\\n\\n\\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \\nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \\nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \\nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to… See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs."},
	{"name":"lr-sum","keyword":"pashto","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LR-Sum\\n\\t\\n\\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \\nThe data is based on… See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum."},
	{"name":"megawika-report-generation","keyword":"pashto","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika for Report Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. \\nThis dataset… See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation."},
	{"name":"Pontoon-Translations","keyword":"pashto","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)… See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations."},
	{"name":"language_tags","keyword":"southern pashto","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Loïck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"Français\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog convention… See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags."},
	{"name":"language_tags","keyword":"pushto","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Loïck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"Français\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog convention… See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags."},
	{"name":"V1Q","keyword":"pashto","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate… See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q."},
	{"name":"multilingual_translation_gen_binarized","keyword":"pashto","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"HPLT2.0_cleaned","keyword":"southern pashto","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files… See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned."}
]
;
