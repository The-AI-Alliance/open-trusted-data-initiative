const data_for_language_asia_nepali = 
[
	{"name":"xP3megds","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset Card for xP3\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.\n\n\nCreation: The dataset can be recreated using instructions available here. We provide this version to save processing time and ease reproducibility.\nLanguages: 46 (Can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bigscience/xP3megds.","url":"https://huggingface.co/datasets/bigscience/xP3megds","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"eng2nep","keyword":"nepali","description":"momo22/eng2nep dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/momo22/eng2nep","creator_name":"Sajjan","creator_url":"https://huggingface.co/momo22","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","English","Nepali","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"c4","keyword":"nepali","description":"\n\t\n\t\t\n\t\tC4\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA colossal, cleaned version of Common Crawl's web crawl corpus. Based on Common Crawl dataset: \"https://commoncrawl.org\".\nThis is the processed version of Google's C4 dataset\nWe prepared five variants of the data: en, en.noclean, en.noblocklist, realnewslike, and multilingual (mC4).\nFor reference, these are the sizes of the variants:\n\nen: 305GB\nen.noclean: 2.3TB\nen.noblocklist: 380GB\nrealnewslike: 15GB\nmultilingual (mC4): 9.7TB (108 subsets, one per‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/c4.","url":"https://huggingface.co/datasets/allenai/c4","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"CC-Cat","keyword":"nepali","description":"\n\t\n\t\t\n\t\tCC_Cat\n\t\n\n\nExtract from CC-WARC snapshots.\nMainly includes texts with 149 languages.\nPDF/IMAGE/AUDIO/VIDEO raw downloading link.\n\n\n\t\n\t\t\n\t\tNotice\n\t\n\n\nSince my computing resources are limited, this dataset will update by one-day of CC snapshots timestampts.\nAfter a snapshot is updated, the deduplicated version will be uploaded.\nIf you are interested in providing computing resources or have cooperation needs, please contact me.\n  carreyallthetime@gmail.com  \n      \n  \n\n","url":"https://huggingface.co/datasets/chengshidehaimianti/CC-Cat","creator_name":"zyq","creator_url":"https://huggingface.co/chengshidehaimianti","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","English","German","Russian"],"keywords_longer_than_N":true},
	{"name":"multi_para_crawl","keyword":"nepali","description":"Parallel corpora from Web Crawls collected in the ParaCrawl project and further processed for making it a multi-parallel corpus by pivoting via English. Here we only provide the additional language pairs that came out of pivoting. The bitexts for English are available from the ParaCrawl release.\n40 languages, 669 bitexts\ntotal number of files: 40\ntotal number of tokens: 10.14G\ntotal number of sentence fragments: 505.48M\n\nPlease, acknowledge the ParaCrawl project at http://paracrawl.eu. This version is derived from the original release at their website adjusted for redistribution via the OPUS corpus collection. Please, acknowledge OPUS as well for this service.","url":"https://huggingface.co/datasets/Helsinki-NLP/multi_para_crawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"lehengas-in-schools-question-bank","keyword":"nepali","description":"\n\t\n\t\t\n\t\tCultural Knowledge Question Bank\n\t\n\nThis dataset contains questions designed to evaluate cultural knowledge within the context of India.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is provided as a CSV file with the following fields:\n\n\t\n\t\t\nField\nDescription\n\n\n\t\t\nID\nUnique identifier\n\n\nDifficulty\nQuestion difficulty level (e.g., Easy, Medium, Hard)\n\n\nQuestion\nQuestion text\n\n\nAnswer\nCorrect answer text\n\n\nType\nQuestion type (e.g., MCQ, One-word, etc.)\n\n\nLanguage\nLanguage of the question‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kirtibg/lehengas-in-schools-question-bank.","url":"https://huggingface.co/datasets/Kirtibg/lehengas-in-schools-question-bank","creator_name":"Kirti Bhagat","creator_url":"https://huggingface.co/Kirtibg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Tamil","Oriya","Telugu"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"nepali","description":"\n\t\n\t\t\n\t\tSMOL\n\t\n\nSMOL (Set for Maximal Overall Leverage) is a collection professional\ntranslations into 221 Low-Resource Languages, for the purpose of training\ntranslation models, and otherwise increasing the representations of said\nlanguages in NLP and technology.\nPlease read the SMOL Paper and the\nGATITOS Paper for a much more\nthorough description!\nThere are four resources in this directory:\n\nSmolDoc: document-level translations into 104 language pairs (103 unique languages)\nSmolSent:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"nepali_to_english_pipeline_evaluation","keyword":"nepali","description":"\n\t\n\t\t\n\t\tNepali-English Speech-to-Text Translation Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for evaluating Nepali‚ÜíEnglish speech-to-text translation pipelines.\nIt contains audio recordings of 300 Nepali sentences, spoken by three speakers, covering a range of sentence types (statements, questions, commands, complex sentences, and named entities/numbers).\nEach sentence is paired with:\n\nSource text (Nepali) transcription\nReference English translation\nAudio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iamTangsang/nepali_to_english_pipeline_evaluation.","url":"https://huggingface.co/datasets/iamTangsang/nepali_to_english_pipeline_evaluation","creator_name":"Tangsang Chongbang","creator_url":"https://huggingface.co/iamTangsang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Nepali","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"phonetic-piper-recording-studio-prompts","keyword":"nepali","description":"\n\t\n\t\t\n\t\tPhonetic Piper Studio Recordings Prompts\n\t\n\nThis dataset is a processed version of an utterance dataset made available for various languages as prompts for the Piper recording studio. Along with the original prompts, we include:\n\ncolumns ipa_espeak and ipa_epitran containing phonemized versions of the original sentences according to espeak-ng and Epitran phonemizers, respectively\ncolumns lang, espeak_lang_code, epitran_lang_code containing the language codes as reported by piper‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts.","url":"https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts","creator_name":"Fl√°vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ne","keyword":"nepali","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Nepali"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"nepali","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Roleplay-Nepali","keyword":"nepali","description":"\n\t\n\t\t\n\t\tRolePlay-Nepali\n\t\n\nRoleplay-Nepali Dataset is a dataset for roleplaying in the Nepali language for the Large Language Model.\nThe base dataset is the GPTeacher role play dataset by teknium 1, which can be found under this link, released under MIT License. The dataset is then translated into respective languages. The translation process is powered by Google Translate, using cloud translation API. \nFor more information and other language datasets for roleplay, see this github repo.\nFor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Nepali.","url":"https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Nepali","creator_name":"Min Si Thu","creator_url":"https://huggingface.co/jojo-ai-mst","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Nepali","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"nepali_news_text","keyword":"nepali","description":"iamsubingyawali/nepali_news_text dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/iamsubingyawali/nepali_news_text","creator_name":"Subin Gyawali","creator_url":"https://huggingface.co/iamsubingyawali","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Nepali","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"textbook-qa-nepali-reasoning","keyword":"nepali","description":"\n\t\n\t\t\n\t\tTextbook Question-Answering Dataset (Nepali)\n\t\n\nThis repository contains ShareGPT-style conversations generated by the Textbook QA agentic pipeline.\n\n\t\n\t\t\n\t\tSplits\n\t\n\n\ntrain: validated conversations with non-empty question, answer, and rephrased_text.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"dineshkarki/textbook-qa-nepali-reasoning\")\ntrain = ds[\"train\"]\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\ntrain: each row contains:\nid: unique string\nconversations: list of N messages (N ‚â•‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dineshkarki/textbook-qa-nepali-reasoning.","url":"https://huggingface.co/datasets/dineshkarki/textbook-qa-nepali-reasoning","creator_name":"Dinesh Karki","creator_url":"https://huggingface.co/dineshkarki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Nepali","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"textbook-qa-nepali-reasoning","keyword":"nepali","description":"\n\t\n\t\t\n\t\tTextbook Question-Answering Dataset (Nepali)\n\t\n\nThis repository contains ShareGPT-style conversations generated by the Textbook QA agentic pipeline.\n\n\t\n\t\t\n\t\tSplits\n\t\n\n\ntrain: validated conversations with non-empty question, answer, and rephrased_text.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"dineshkarki/textbook-qa-nepali-reasoning\")\ntrain = ds[\"train\"]\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\ntrain: each row contains:\nid: unique string\nconversations: list of N messages (N ‚â•‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dineshkarki/textbook-qa-nepali-reasoning.","url":"https://huggingface.co/datasets/dineshkarki/textbook-qa-nepali-reasoning","creator_name":"Dinesh Karki","creator_url":"https://huggingface.co/dineshkarki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Nepali","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"nepali","description":"\n\t\n\t\t\n\t\tINCLUDE-lite (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-lite-44.","url":"https://huggingface.co/datasets/CohereLabs/include-lite-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"textbook-qa-nepali-multiturn","keyword":"nepali","description":"\n\t\n\t\t\n\t\tTextbook Question-Answering Dataset (Nepali)\n\t\n\nThis repository contains ShareGPT-style conversations generated by the Textbook QA agentic pipeline.\n\n\t\n\t\t\n\t\tSplits\n\t\n\n\ntrain: validated conversations with non-empty question, answer, and rephrased_text.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"dineshkarki/textbook-qa-nepali-multiturn\")\ntrain = ds[\"train\"]\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\ntrain: each row contains:\nid: unique string\nconversations: list of N messages (N ‚â•‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dineshkarki/textbook-qa-nepali-multiturn.","url":"https://huggingface.co/datasets/dineshkarki/textbook-qa-nepali-multiturn","creator_name":"Dinesh Karki","creator_url":"https://huggingface.co/dineshkarki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Nepali","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"textbook-qa-nepali-multiturn","keyword":"nepali","description":"\n\t\n\t\t\n\t\tTextbook Question-Answering Dataset (Nepali)\n\t\n\nThis repository contains ShareGPT-style conversations generated by the Textbook QA agentic pipeline.\n\n\t\n\t\t\n\t\tSplits\n\t\n\n\ntrain: validated conversations with non-empty question, answer, and rephrased_text.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"dineshkarki/textbook-qa-nepali-multiturn\")\ntrain = ds[\"train\"]\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\ntrain: each row contains:\nid: unique string\nconversations: list of N messages (N ‚â•‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dineshkarki/textbook-qa-nepali-multiturn.","url":"https://huggingface.co/datasets/dineshkarki/textbook-qa-nepali-multiturn","creator_name":"Dinesh Karki","creator_url":"https://huggingface.co/dineshkarki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Nepali","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"nepali","description":"These are the GSM8K and ARC dataset translated by Google Translate. \nBibTex\n@misc{lu2024languagecountslearnunlearn,\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \n      author={Taiming Lu and Philipp Koehn},\n      year={2024},\n      eprint={2406.13748},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2406.13748}, \n}\n\n","url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"IndicMSMARCO","keyword":"nepali","description":"\n\t\n\t\t\n\t\tüîç IndicMSMARCO: Multilingual Information Retrieval Benchmark\n\t\n\nA comprehensive multilingual variant of MS MARCO specifically tailored for Indian languages, featuring carefully selected queries and corresponding passages with high-quality translations.\n\n\t\n\t\t\n\t\tüöÄ Quick Start - Load Individual Languages\n\t\n\nfrom datasets import load_dataset\n\n# Load ONLY Hindi data (fast and efficient!)\nhindi_data = load_dataset(\"ai4bharat/IndicMSMARCO\", \"hi\")\nprint(f\"Hindi queries:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/IndicMSMARCO.","url":"https://huggingface.co/datasets/ai4bharat/IndicMSMARCO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multilingual","ms_marco","Assamese"],"keywords_longer_than_N":true},
	{"name":"nepali-triplets","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset Card for Nepali/English Triplets\n\t\n\nThis dataset contains sentence and a positive and a negative triplets suitable for training semantic similarity models.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nDataset created using the triplets generator\nThis dataset was automatically generated using llm-data-gen library\n\nCurated by: ['Sanjaya Subedi jangedoo@gmail.com']\n\n\n\t\n\t\t\n\t\tDataset Card Authors [optional]\n\t\n\n['Sanjaya Subedi jangedoo@gmail.com']\n\n\t\n\t\t\n\t\tDataset Card‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jangedoo/nepali-triplets.","url":"https://huggingface.co/datasets/jangedoo/nepali-triplets","creator_name":"Sanjaya Subedi","creator_url":"https://huggingface.co/jangedoo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["machine-generated","jangedoo/nepalinews","English","Nepali","mit"],"keywords_longer_than_N":true},
	{"name":"fiNERweb","keyword":"nepali","description":"fiNERweb is a multilingual named entity recognition dataset containing annotated text in multiple languages.\nEach example contains the original text, tokenized text, BIO tags, and character/token spans for entities.","url":"https://huggingface.co/datasets/whoisjones/fiNERweb","creator_name":"Jonas Golde","creator_url":"https://huggingface.co/whoisjones","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","Vietnamese","Tamil","Oriya"],"keywords_longer_than_N":true},
	{"name":"okapi-ranking","keyword":"nepali","description":"Saugatkafley/okapi-ranking dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Saugatkafley/okapi-ranking","creator_name":"Saugat Kafley","creator_url":"https://huggingface.co/Saugatkafley","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Nepali","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Nepali-Health-QA","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Chhabi/Nepali-Health-QA.","url":"https://huggingface.co/datasets/Chhabi/Nepali-Health-QA","creator_name":"Acharya","creator_url":"https://huggingface.co/Chhabi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Nepali","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Nepali-Health-QA","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Chhabi/Nepali-Health-QA.","url":"https://huggingface.co/datasets/Chhabi/Nepali-Health-QA","creator_name":"Acharya","creator_url":"https://huggingface.co/Chhabi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Nepali","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"nepali_law_datasets","keyword":"nepali","description":"\n\t\n\t\t\n\t\tüìú Nepali Law Commission Dataset\n\t\n\nA structured dataset of Nepali legal questions and answers, focusing on the rights of people with disabilities.\n\n\t\n\t\t\n\t\tüìå Overview\n\t\n\nThis dataset contains questions and answers based on Nepal's legal framework, particularly regarding the rights of persons with disabilities. The dataset is designed for AI/ML applications such as:‚úÖ Legal chatbots‚úÖ Question-answering models‚úÖ Legal document analysis‚úÖ NLP research on Nepali language  \nThe dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ashalupreti/nepali_law_datasets.","url":"https://huggingface.co/datasets/Ashalupreti/nepali_law_datasets","creator_name":"Ashal Upreti","creator_url":"https://huggingface.co/Ashalupreti","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Nepali","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"bordirlines","keyword":"nepali","description":"\n\t\n\t\t\n\t\tBordIRLines Dataset\n\t\n\nThis is the dataset associated with the paper \"BordIRlines: A Dataset for Evaluating Cross-lingual Retrieval-Augmented Generation\" (link).\nCode: https://github.com/manestay/bordIRlines\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BordIRLines Dataset is an information retrieval (IR) dataset constructed from various language corpora. It contains queries and corresponding ranked docs along with their relevance scores. The dataset includes multiple languages, including English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/borderlines/bordirlines.","url":"https://huggingface.co/datasets/borderlines/bordirlines","creator_name":"cross-lingual LLMs and RAG","creator_url":"https://huggingface.co/borderlines","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","human","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ne","keyword":"nepali","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Nepali"],"keywords_longer_than_N":true},
	{"name":"Customer-Care-Services-Dataset-in-Nepali","keyword":"nepali","description":"kshitizgajurel/Customer-Care-Services-Dataset-in-Nepali dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kshitizgajurel/Customer-Care-Services-Dataset-in-Nepali","creator_name":"Kshitiz Gajurel","creator_url":"https://huggingface.co/kshitizgajurel","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","fill-mask","open-domain-abstractive-qa","document-question-answering"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ne","keyword":"nepali","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Nepali"],"keywords_longer_than_N":true},
	{"name":"nep-spell-synthetic-27k","keyword":"nepali","description":"Contains 27k sentence pairs for Nepali Spell Checking.\nhttps://www.kaggle.com/code/amardura/thegroup-nep-spell-synthetic-datapoints\n","url":"https://huggingface.co/datasets/duraad/nep-spell-synthetic-27k","creator_name":"Dura Amar","creator_url":"https://huggingface.co/duraad","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Nepali","mit","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"nep-spell-synthetic-27k","keyword":"nepali","description":"Contains 27k sentence pairs for Nepali Spell Checking.\nhttps://www.kaggle.com/code/amardura/thegroup-nep-spell-synthetic-datapoints\n","url":"https://huggingface.co/datasets/duraad/nep-spell-synthetic-27k","creator_name":"Dura Amar","creator_url":"https://huggingface.co/duraad","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Nepali","mit","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"nepali","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"bernice-pretrain-data","keyword":"nepali","description":"Tweet IDs for the 2.5 billion multilingual tweets used to train Bernice, a Twitter encoder.\nThe tweets are from the public 1% Twitter API stream from January 2016 to December 2021. \nTwitter-provided language metadata is provided with the tweet ID. The data contains 66 unique languages, \nas identified by ISO 639 language codes, including `und` for undefined languages.\nTweets need to be re-gathered via the Twitter API.","url":"https://huggingface.co/datasets/jhu-clsp/bernice-pretrain-data","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","no-annotation","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"misclassified-department","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset: mr-kush/misclassified-department\n\t\n\nProcessed and versioned dataset for department classification.\n\n\n\t\n\t\t\n\t\tVersion Information\n\t\n\n\nVersion Tag: v20251017_083441\nCreated At: 2025-10-17T08:34:45.700557\nLabel Column: department\nTotal Samples: 2426\n\n\n\t\n\t\t\n\t\tLabel Mapping\n\t\n\n\n\t\n\t\t\nLabel\nID\n\n\n\t\t\nMunicipal Governance & Community Services\n0\n\n\nEducation, Health & Social Welfare\n1\n\n\nInfrastructure, Utilities & Natural Resources\n2\n\n\nSecurity & Law Enforcement\n3\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mr-kush/misclassified-department.","url":"https://huggingface.co/datasets/mr-kush/misclassified-department","creator_name":"Kushal Regmi","creator_url":"https://huggingface.co/mr-kush","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","English","Nepali","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"nllb-200-10M-sample","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset Card for \"nllb-200-10M-sample\"\n\t\n\nThis is a sample of nearly 10M sentence pairs from the NLLB-200 \nmined dataset allenai/nllb, \nscored with the model facebook/blaser-2.0-qe \ndescribed in the SeamlessM4T paper.\nThe sample is not random; instead, we just took the top n sentence pairs from each translation direction.\nThe number n was computed with the goal of upsamping the directions that contain underrepresented languages.\nNevertheless, the 187 languoids (language and script‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slone/nllb-200-10M-sample.","url":"https://huggingface.co/datasets/slone/nllb-200-10M-sample","creator_name":"SLONE","creator_url":"https://huggingface.co/slone","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Akan","Amharic","Arabic","Awadhi"],"keywords_longer_than_N":true},
	{"name":"bible_para","keyword":"nepali","description":"This is a multilingual parallel corpus created from translations of the Bible compiled by Christos Christodoulopoulos and Mark Steedman.\n\n102 languages, 5,148 bitexts\ntotal number of files: 107\ntotal number of tokens: 56.43M\ntotal number of sentence fragments: 2.84M","url":"https://huggingface.co/datasets/Helsinki-NLP/bible_para","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"nepali","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Viet-Mistral/CulturaY.","url":"https://huggingface.co/datasets/Viet-Mistral/CulturaY","creator_name":"Vietnamese Mistral","creator_url":"https://huggingface.co/Viet-Mistral","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"IndicCOPA","keyword":"nepali","description":"\\","url":"https://huggingface.co/datasets/ai4bharat/IndicCOPA","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3mt","keyword":"nepali","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"dataset-for-peft-cv-nepds","keyword":"nepali","description":"kiranpantha/dataset-for-peft-cv-nepds dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kiranpantha/dataset-for-peft-cv-nepds","creator_name":"Kiran Pantha","creator_url":"https://huggingface.co/kiranpantha","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Nepali","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"nepali_speech_to_text","keyword":"nepali","description":"\n\t\n\t\t\n\t\tNepali Speech-to-Text Dataset\n\t\n\nThis repository contains a dataset for Automatic Speech Recognition (ASR) in the Nepali language. The dataset is designed for supervised learning tasks and includes audio files along with their corresponding transcriptions. The audio samples have been collected from various open-source platforms and other publicly available sources on the internet.  \nEach audio file has an average length of 15 seconds and has been converted into a consistent WAV format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pujanpaudel/nepali_speech_to_text.","url":"https://huggingface.co/datasets/pujanpaudel/nepali_speech_to_text","creator_name":"Pujan Paudel","creator_url":"https://huggingface.co/pujanpaudel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Nepali","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ne","keyword":"nepali","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Nepali"],"keywords_longer_than_N":true},
	{"name":"Cultural_heritage_Narrator_SFT_dataset","keyword":"nepali","description":"name: nepal_heritage_stories\ntags:\n\ncultural-heritage\nstory\nQ&A\ngossip\nNepal\nmultilingual\nconversational\nnarrative\ndataset\nlanguage:\nen\nlicense: cc-by-4.0\ntask_categories:\ntext-generation\nquestion-answering\ndialogue\ndataset_summary: >\n  A text-based dataset of Nepalese cultural heritage stories, gossip, and Q&A style interactions. \n  Designed to train language models to narrate, answer, and generate dramatic or conversational \n  content related to Nepalese communities, folklore, festivals‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nabin2004/Cultural_heritage_Narrator_SFT_dataset.","url":"https://huggingface.co/datasets/nabin2004/Cultural_heritage_Narrator_SFT_dataset","creator_name":"Nabin Oli","creator_url":"https://huggingface.co/nabin2004","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Nepali","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Bharat_NanoTouche2020_ne","keyword":"nepali","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Nepali"],"keywords_longer_than_N":true},
	{"name":"Indic-Rag-Suite","keyword":"nepali","description":"\n\t\n\t\t\n\t\tüåè Multilingual Indic RAG Suite\n\t\n\nA comprehensive multilingual question-answering dataset covering 18 Indian languages with 12,802,615 total samples, designed for RAG (Retrieval-Augmented Generation) applications and multilingual NLP research.\n\n\t\n\t\t\n\t\tüöÄ Quick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load specific language (recommended)\ndataset = load_dataset(\"AshwinSankar/Indic-Rag-Suite\", \"as\")\ntrain_data = dataset['train']\n\nprint(f\"Loaded {len(train_data)} samples\")\n\n# Access‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AshwinSankar/Indic-Rag-Suite.","url":"https://huggingface.co/datasets/AshwinSankar/Indic-Rag-Suite","creator_name":"Ashwin Sankar","creator_url":"https://huggingface.co/AshwinSankar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","multilingual","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"webui-dom-snapshots","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset Card for WebUI DOM snapshots\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Gary Benson\nLanguages: Mostly English (87%);\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\nLicense: CC0 1.0 Universal\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots.","url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","reinforcement-learning","text-classification","multilingual","biglab/webui-7k"],"keywords_longer_than_N":true},
	{"name":"Lemonade","keyword":"nepali","description":"LEMONADE is a large, expert-annotated dataset for event extraction from news articles in 20 languages: English, Spanish, Arabic, French, Italian, Russian, German, Turkish, Burmese, Indonesian, Ukrainian, Korean, Portuguese, Dutch, Somali, Nepali, Chinese, Persian, Hebrew, and Japanese.\nSee https://github.com/stanford-oval/Lemonade for details.\n","url":"https://huggingface.co/datasets/stanford-oval/Lemonade","creator_name":"Stanford Open Virtual Assistant Lab (OVAL)","creator_url":"https://huggingface.co/stanford-oval","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"Devanagari-Ecommerce-Dataset","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n‡§Ø‡•ã ‡§¶‡•á‡§µ‡§®‡§æ‡§ó‡§∞‡•Ä ‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§≠‡§æ‡§∑‡§æ‡§ï‡•ã ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§µ‡§ø‡§∂‡•á‡§∑‡§ó‡§∞‡•Ä ‡§ö‡•ç‡§Ø‡§æ‡§ü‡§¨‡•ã‡§ü ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä‡§π‡§∞‡•Ç ‡§¨‡§®‡§æ‡§â‡§®‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§°‡§ø‡§ú‡§æ‡§á‡§® ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§π‡•ã‡•§ ‡§Ø‡§∏‡§Æ‡§æ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§∂‡•ç‡§∞‡•á‡§£‡•Ä‡§π‡§∞‡•Ç‡§ï‡•ã ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü‡§π‡§∞‡•Ç ‡§∏‡§Æ‡§æ‡§µ‡•á‡§∂ ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§õ, ‡§ú‡§∏‡§≤‡§æ‡§à JSON ‡§Æ‡§æ ‡§¢‡§æ‡§Å‡§ö‡§æ ‡§¨‡§®‡§æ‡§à‡§è‡§ï‡•ã ‡§õ, ‡§ú‡§∏‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§µ‡§æ‡§∞‡•ç‡§§‡§æ‡§≤‡§æ‡§™ ‡§è‡§Ü‡§à ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§π‡§∞‡•Ç‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•ã‡§°‡•á‡§≤‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§§‡§æ‡§≤‡§ø‡§Æ ‡§∞ ‡§´‡§æ‡§á‡§®-‡§ü‡•ç‡§Ø‡•Ç‡§® ‡§ó‡§∞‡•ç‡§®‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§∏‡•ç‡§∞‡•ã‡§§ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ó‡§∞‡•ç‡§¶‡§õ‡•§\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Prepared by:\n\t\n\n\nAakash‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kshitizgajurel/Devanagari-Ecommerce-Dataset.","url":"https://huggingface.co/datasets/kshitizgajurel/Devanagari-Ecommerce-Dataset","creator_name":"Kshitiz Gajurel","creator_url":"https://huggingface.co/kshitizgajurel","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Nepali","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"nepali-alpaca-reasoning","keyword":"nepali","description":"\n\t\n\t\t\n\t\tShareGPT Conversations\n\t\n\nThis repository contains multi-turn human ‚Üî gpt conversations.\n\n\t\n\t\t\n\t\tSplits\n\t\n\n\ndineshkarki/nepali-alpaca-reasoning provides a split named train by default.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"dineshkarki/nepali-alpaca-reasoning\")\ntrain = ds[\"train\"]\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\nEach row contains:\n\nid: unique string\nconversations: list of N messages (N ‚â• 2), alternating human and gpt roles\n\nNotes:\n\nConversations are lightly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dineshkarki/nepali-alpaca-reasoning.","url":"https://huggingface.co/datasets/dineshkarki/nepali-alpaca-reasoning","creator_name":"Dinesh Karki","creator_url":"https://huggingface.co/dineshkarki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Nepali","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Devanagari-Ecommerce-fomatted-for-llama2-chat-Dataset","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n‡§Ø‡•ã ‡§¶‡•á‡§µ‡§®‡§æ‡§ó‡§∞‡•Ä ‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§≠‡§æ‡§∑‡§æ‡§ï‡•ã ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§µ‡§ø‡§∂‡•á‡§∑‡§ó‡§∞‡•Ä ‡§ö‡•ç‡§Ø‡§æ‡§ü‡§¨‡•ã‡§ü ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä‡§π‡§∞‡•Ç ‡§¨‡§®‡§æ‡§â‡§®‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§°‡§ø‡§ú‡§æ‡§á‡§® ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§π‡•ã‡•§ ‡§Ø‡§∏‡§Æ‡§æ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§∂‡•ç‡§∞‡•á‡§£‡•Ä‡§π‡§∞‡•Ç‡§ï‡•ã ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü‡§π‡§∞‡•Ç ‡§∏‡§Æ‡§æ‡§µ‡•á‡§∂ ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§õ, ‡§ú‡§∏‡§≤‡§æ‡§à JSON ‡§Æ‡§æ ‡§¢‡§æ‡§Å‡§ö‡§æ ‡§¨‡§®‡§æ‡§à‡§è‡§ï‡•ã ‡§õ, ‡§ú‡§∏‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§µ‡§æ‡§∞‡•ç‡§§‡§æ‡§≤‡§æ‡§™ ‡§è‡§Ü‡§à ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§π‡§∞‡•Ç‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•ã‡§°‡•á‡§≤‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§§‡§æ‡§≤‡§ø‡§Æ ‡§∞ ‡§´‡§æ‡§á‡§®-‡§ü‡•ç‡§Ø‡•Ç‡§® ‡§ó‡§∞‡•ç‡§®‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§∏‡•ç‡§∞‡•ã‡§§ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ó‡§∞‡•ç‡§¶‡§õ‡•§\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kshitizgajurel/Devanagari-Ecommerce-fomatted-for-llama2-chat-Dataset.","url":"https://huggingface.co/datasets/kshitizgajurel/Devanagari-Ecommerce-fomatted-for-llama2-chat-Dataset","creator_name":"Kshitiz Gajurel","creator_url":"https://huggingface.co/kshitizgajurel","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Nepali","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"nep_qa_test","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset Card for Nepali Q&A Dataset\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nNepali Q&A Dataset\nThis dataset was automatically generated using this library\n\nCurated by: ['Sanjaya Subedi jangedoo@gmail.com']\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): ['ne']\nLicense: mit\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jangedoo/nep_qa_test.","url":"https://huggingface.co/datasets/jangedoo/nep_qa_test","creator_name":"Sanjaya Subedi","creator_url":"https://huggingface.co/jangedoo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","document-question-answering","machine-generated","NepaliAI/Nepali-Health-Fact","mridul3301/nepali-text-corpus-64"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ne","keyword":"nepali","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ne","keyword":"nepali","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ne","keyword":"nepali","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Nepali"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ne","keyword":"nepali","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Nepali"],"keywords_longer_than_N":true},
	{"name":"nepalitext-language-model-dataset","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset Card for \"nepalitext-language-model-dataset\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\"NepaliText\" language modeling dataset is a collection of over 13 million Nepali text sequences (phrases/sentences/paragraphs) extracted by combining the datasets: OSCAR , cc100 and a set of scraped Nepali articles on Wikipedia. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is intended to pre-train language models and word representations on Nepali Language.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe data is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sakonii/nepalitext-language-model-dataset.","url":"https://huggingface.co/datasets/Sakonii/nepalitext-language-model-dataset","creator_name":"Utsav Maskey","creator_url":"https://huggingface.co/Sakonii","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","other"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ne","keyword":"nepali","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Nepali"],"keywords_longer_than_N":true},
	{"name":"IN22-Conv-Doc-Level","keyword":"nepali","description":"This dataset was constructed by merging individual conversations from the IN22-Conv dataset to create a long-context, document-level parallel benchmark. For further information on domains and statistics, please refer to the original paper and dataset.\n","url":"https://huggingface.co/datasets/VarunGumma/IN22-Conv-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"nepalimetaphorcorpus","keyword":"nepali","description":"\n\t\n\t\t\n\t\tNepali Metaphor Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tHere metaphor includes all kind of figurative speech that can be interpreted diferrently while reading literal and mean differently in meaning. The AarthaAlankaars like Simile,oxymoron, paradox, juxtaposition, personification, proverbs and idioms/phrases are included\nas a metaphor and thus annotated as metaphor. The classification of these subtypes is not done in dataset.\n\t\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bnabin/nepalimetaphorcorpus.","url":"https://huggingface.co/datasets/bnabin/nepalimetaphorcorpus","creator_name":"Nabin Bhusal","creator_url":"https://huggingface.co/bnabin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Nepali","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"nepalimetaphorcorpus","keyword":"nepali","description":"\n\t\n\t\t\n\t\tNepali Metaphor Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tHere metaphor includes all kind of figurative speech that can be interpreted diferrently while reading literal and mean differently in meaning. The AarthaAlankaars like Simile,oxymoron, paradox, juxtaposition, personification, proverbs and idioms/phrases are included\nas a metaphor and thus annotated as metaphor. The classification of these subtypes is not done in dataset.\n\t\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bnabin/nepalimetaphorcorpus.","url":"https://huggingface.co/datasets/bnabin/nepalimetaphorcorpus","creator_name":"Nabin Bhusal","creator_url":"https://huggingface.co/bnabin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Nepali","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"indicCorpv2","keyword":"nepali","description":"    IndicCORPV2 is the largest collection of texts for Indic langauges consisting of 20.9 Billion tokens of which 14.4B tokens correspond to 23 Indic languages and 6.B tokens of Indian English content curated from Indian websites.","url":"https://huggingface.co/datasets/satpalsr/indicCorpv2","creator_name":"Satpal Singh Rathore","creator_url":"https://huggingface.co/satpalsr","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","Assamese","Bodo (India)","Bengali","Dogri (macrolanguage)"],"keywords_longer_than_N":true},
	{"name":"Nepali","keyword":"nepali","description":"SunilC/Nepali dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/SunilC/Nepali","creator_name":"Sunil Chaudhary","creator_url":"https://huggingface.co/SunilC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Nepali","mit","Audio","üá∫üá∏ Region: US","code"],"keywords_longer_than_N":false},
	{"name":"oscar-mini","keyword":"nepali","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-mini","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"thegroup-datafile-31k","keyword":"nepali","description":"","url":"https://huggingface.co/datasets/duraad/thegroup-datafile-31k","creator_name":"Dura Amar","creator_url":"https://huggingface.co/duraad","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Nepali","mit","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"all-scam-spam","keyword":"nepali","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\n1040 rows of balanced data, consisting of casual conversations and scam emails in ‚âà10 languages, were manually collected and annotated by me, with some help from ChatGPT.\n\n\n\n\t\n\t\t\n\t\tSome preprcoessing algorithms\n\t\n\n\nspam_assassin.js, followed by spam_assassin.py\nenron_spam.py\n\n\n\n\n\t\n\t\t\n\t\tData composition\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTo make the text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam.","url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Norwegian","Spanish","Somali"],"keywords_longer_than_N":true},
	{"name":"misclassified-urgency","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset: mr-kush/misclassified-urgency\n\t\n\nProcessed and versioned dataset for urgency classification.\n\n\n\t\n\t\t\n\t\tVersion Information\n\t\n\n\nVersion Tag: v20251017_083447\nCreated At: 2025-10-17T08:34:51.211645\nLabel Column: urgency\nTotal Samples: 2426\n\n\n\t\n\t\t\n\t\tLabel Mapping\n\t\n\n\n\t\n\t\t\nLabel\nID\n\n\n\t\t\nNORMAL\n0\n\n\nURGENT\n1\n\n\nHIGHLY URGENT\n2\n\n\n\t\n\n\n\t\n\t\t\n\t\tDataset Splits\n\t\n\n\nTrain: 1940 samples\nEval: 243 samples\nTest: 243 samples\n\n\n\t\n\t\t\n\t\tTask Description\n\t\n\nThis dataset contains preprocessed citizen‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mr-kush/misclassified-urgency.","url":"https://huggingface.co/datasets/mr-kush/misclassified-urgency","creator_name":"Kushal Regmi","creator_url":"https://huggingface.co/mr-kush","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","English","Nepali","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ms_terms","keyword":"nepali","description":"The Microsoft Terminology Collection can be used to develop localized versions of applications that integrate with Microsoft products.\nIt can also be used to integrate Microsoft terminology into other terminology collections or serve as a base IT glossary\nfor language development in the nearly 100 languages available. Terminology is provided in .tbx format, an industry standard for terminology exchange.","url":"https://huggingface.co/datasets/microsoft/ms_terms","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","license_name":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":null,"first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","multilingual","translation"],"keywords_longer_than_N":true},
	{"name":"xP3","keyword":"nepali","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","url":"https://huggingface.co/datasets/bigscience/xP3","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"nepali-recipes-qwen-processed","keyword":"nepali","description":"\n\t\n\t\t\n\t\tNepali Recipes for Qwen Fine-tuning\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 1227 Nepali recipes formatted for fine-tuning Qwen models using ChatML format.\n\nTrain Split: 900 recipes\nTest Split: 327 recipes\nLanguage: Nepali (ne)\nFormat: Qwen ChatML\nBase Model: Qwen/Qwen2-1.5B\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ntext: Full ChatML formatted prompt with answer (for training)\ntest_text: ChatML prompt without answer (for inference)\nname: Recipe name in Nepali‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sijanpaudel/nepali-recipes-qwen-processed.","url":"https://huggingface.co/datasets/sijanpaudel/nepali-recipes-qwen-processed","creator_name":"Sijan Paudel","creator_url":"https://huggingface.co/sijanpaudel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Nepali","English","mit"],"keywords_longer_than_N":true},
	{"name":"nepali-recipes-qwen-processed","keyword":"nepali","description":"\n\t\n\t\t\n\t\tNepali Recipes for Qwen Fine-tuning\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 1227 Nepali recipes formatted for fine-tuning Qwen models using ChatML format.\n\nTrain Split: 900 recipes\nTest Split: 327 recipes\nLanguage: Nepali (ne)\nFormat: Qwen ChatML\nBase Model: Qwen/Qwen2-1.5B\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ntext: Full ChatML formatted prompt with answer (for training)\ntest_text: ChatML prompt without answer (for inference)\nname: Recipe name in Nepali‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sijanpaudel/nepali-recipes-qwen-processed.","url":"https://huggingface.co/datasets/sijanpaudel/nepali-recipes-qwen-processed","creator_name":"Sijan Paudel","creator_url":"https://huggingface.co/sijanpaudel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Nepali","English","mit"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"no-filter-raw-NepaliParliamentDSv2","keyword":"nepali","description":"kiranpantha/no-filter-raw-NepaliParliamentDSv2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kiranpantha/no-filter-raw-NepaliParliamentDSv2","creator_name":"Kiran Pantha","creator_url":"https://huggingface.co/kiranpantha","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","cc-by-4.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"nepali","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"nepali_news_text_summary_sharegpt_with_system_ne","keyword":"nepali","description":"iamsubingyawali/nepali_news_text_summary_sharegpt_with_system_ne dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/iamsubingyawali/nepali_news_text_summary_sharegpt_with_system_ne","creator_name":"Subin Gyawali","creator_url":"https://huggingface.co/iamsubingyawali","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Nepali","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Flores-Indic-Doc-Level","keyword":"nepali","description":"This dataset was constructed by merging individual sentences from the Flores dataset based on matching domain, topic, and URL attributes. The result is a long-context, document-level parallel benchmark. For more details on the domains and dataset statistics, please refer to the original paper and the dataset.\n","url":"https://huggingface.co/datasets/VarunGumma/Flores-Indic-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"nepali_news_text_summary_sharegpt","keyword":"nepali","description":"iamsubingyawali/nepali_news_text_summary_sharegpt dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/iamsubingyawali/nepali_news_text_summary_sharegpt","creator_name":"Subin Gyawali","creator_url":"https://huggingface.co/iamsubingyawali","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Nepali","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"nepali","description":"This is the translation preference dataset used by X-ALMA.\nsource: the source sentence.\nchosen: the preferred translation.\nreject: the dis-preferred translation.\ndirections: the translation direction.\n@misc{xu2024xalmaplugplay,\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\n      year={2024},\n      eprint={2410.03115}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"nepali_news_text_summary_sharegpt_with_system_en","keyword":"nepali","description":"iamsubingyawali/nepali_news_text_summary_sharegpt_with_system_en dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/iamsubingyawali/nepali_news_text_summary_sharegpt_with_system_en","creator_name":"Subin Gyawali","creator_url":"https://huggingface.co/iamsubingyawali","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Nepali","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ne","keyword":"nepali","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Nepali"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"nepali","description":"\n\n\n\t\n\t\t\n\t\tüî∑ Accepted in NAACL Proceedings (2025) üî∑\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval üìö [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"devanagari_and_roman_digits","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThe OCR Digits Dataset consists of 20,000 high-quality images of digit combinations captured under various conditions. This dataset is designed to support research in optical character recognition, particularly for multi-digit recognition tasks.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nBibTeX:\n@dataset{SumitYadav2025OCRDigits,\n  author       = {[Sumit Yadav]},\n  title        = {OCR Digits Dataset: A Collection of 20,000 Multi-Digit(Roman and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rockerritesh/devanagari_and_roman_digits.","url":"https://huggingface.co/datasets/rockerritesh/devanagari_and_roman_digits","creator_name":"Sumit Yadav","creator_url":"https://huggingface.co/rockerritesh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["object-detection","Nepali","Hindi","English","mit"],"keywords_longer_than_N":true},
	{"name":"Nadi_Indic466k_Instruct","keyword":"nepali","description":"\n\t\n\t\t\n\t\tNadi_Indic466K_Instruct Dataset\n\t\n\nThe Nadi_Indic466K_Instruct dataset is the world's first coding dataset with 18 Indian language support, 466k rows and 142 Million total tokens. This dataset can be used by developers to build Indian coding language models (LLMs) for various programming languages.\nQ-LoRA based SFT/PPO/DPO fine-tuning can be done on the dataset in LLAMA-2 or Mistral or any opens-soure LLM for text generation.\nThe dataset was carefully curated such that the coding part‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct.","url":"https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct","creator_name":"Convai Innovations","creator_url":"https://huggingface.co/convaiinnovations","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Hindi","Panjabi","Bengali","Tamil"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"nepali","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\n\n\t\n\t\t\n\nToxic\nNeutral\nTotal\n\n\n\t\t\nmultilingual-train-deduplicated.csv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Spanish","Panjabi"],"keywords_longer_than_N":true},
	{"name":"squad_v1.1_np","keyword":"nepali","description":"\n\t\n\t\t\n\t\tSQuAD-NP: Nepali Translation of SQuAD\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSQuAD-NP is a Nepali translation of the SQuAD dataset, the standard dataset for question answering task. The dataset consists of Nepali translations of the original English passages, questions, and answers from the SQuAD dataset. \nThis resource is useful for training machine learning models on extractive question-answering tasks in Nepali.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Nepali (ne)\nSource: Translated from SQuAD-English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suban244/squad_v1.1_np.","url":"https://huggingface.co/datasets/suban244/squad_v1.1_np","creator_name":"Suban Shrestha","creator_url":"https://huggingface.co/suban244","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Nepali","Hindi","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ne","keyword":"nepali","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Nepali"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"nepali","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"nepali_news_text_summary","keyword":"nepali","description":"iamsubingyawali/nepali_news_text_summary dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/iamsubingyawali/nepali_news_text_summary","creator_name":"Subin Gyawali","creator_url":"https://huggingface.co/iamsubingyawali","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Nepali","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"sangraha","keyword":"nepali","description":"\n\t\n\t\t\n\t\tSangraha\n\t\n\n\n  \n\n\nSangraha is the largest high-quality, cleaned Indic language pretraining data containing 251B tokens summed up over 22 languages, extracted from curated sources, existing multilingual corpora and large scale translations.\nMore information:\n\nFor detailed information on the curation and cleaning process of Sangraha, please checkout our paper on Arxiv;\nCheck out the scraping and cleaning pipelines used to curate Sangraha on GitHub;\n\n\n\t\n\t\n\t\n\t\tGetting Started\n\t\n\nFor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/sangraha.","url":"https://huggingface.co/datasets/ai4bharat/sangraha","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Assamese","Bengali","Gujarati","English"],"keywords_longer_than_N":true},
	{"name":"Nepali-Text-Corpus","keyword":"nepali","description":"\n\t\n\t\t\n\t\tNepali Text Corpus\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nNepali-Text-Corpus is a comprehensive collection of approximately 6.4 million articles in the \nNepali language. This dataset is the largest text dataset on Nepali Language. It  encompasses a \ndiverse range of text types, including news articles, blogs, and more, making it an invaluable \nresource for researchers, developers, and enthusiasts in the fields of Natural Language Processing (NLP)\nand computational linguistics.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IRIIS-RESEARCH/Nepali-Text-Corpus.","url":"https://huggingface.co/datasets/IRIIS-RESEARCH/Nepali-Text-Corpus","creator_name":"Institute for Research and Innovation in Intelligent Systems (IRIIS)","creator_url":"https://huggingface.co/IRIIS-RESEARCH","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","Nepali","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Devnagari-Romanized-Pair","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThe dataset devanagari romanized pair contains, 959 rows, where each row has one English sentence and its corresponding Nepali translations both in the devanagari script and in romanized format, the size of the data set is less than 1,000 elements and it's designed for use in Translation, text generation and text to text generation tasks.\n","url":"https://huggingface.co/datasets/nirajandhakal/Devnagari-Romanized-Pair","creator_name":"Nirajan Dhakal","creator_url":"https://huggingface.co/nirajandhakal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","text2text-generation","English","Nepali"],"keywords_longer_than_N":true},
	{"name":"Devnagari-Romanized-Pair","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThe dataset devanagari romanized pair contains, 959 rows, where each row has one English sentence and its corresponding Nepali translations both in the devanagari script and in romanized format, the size of the data set is less than 1,000 elements and it's designed for use in Translation, text generation and text to text generation tasks.\n","url":"https://huggingface.co/datasets/nirajandhakal/Devnagari-Romanized-Pair","creator_name":"Nirajan Dhakal","creator_url":"https://huggingface.co/nirajandhakal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","text2text-generation","English","Nepali"],"keywords_longer_than_N":true},
	{"name":"IndicQuest","keyword":"nepali","description":"\n\t\n\t\t\n\t\tL3Cube-IndicQuest: A Benchmark Question Answering Dataset for Evaluating Knowledge of LLMs in Indic Context (LLM Factual Accuracy Benchmark)\n\t\n\nL3Cube-IndicQuest is a dataset comprising 4,000 question-answer pairs across 20 languages, including English, Assamese, Bengali, Dogri, Gujarati, Hindi, Kannada, Konkani, Maithili, Malayalam, Marathi, Meitei (Manipuri), Nepali, Odia, Punjabi, Sanskrit, Sindhi, Tamil, Telugu, and Urdu. This dataset is designed to assess the knowledge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/l3cube-pune/IndicQuest.","url":"https://huggingface.co/datasets/l3cube-pune/IndicQuest","creator_name":"L3Cube Labs","creator_url":"https://huggingface.co/l3cube-pune","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Assamese","Bengali","Gujarati"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"nepali","description":"\n\t\n\t\t\n\t\tINCLUDE-base (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-base-44.","url":"https://huggingface.co/datasets/CohereLabs/include-base-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Pornhub","keyword":"nepali","description":"\n\t\n\t\t\n\t\tPornhub Dataset\n\t\n\nThe Pornhub Dataset provides a comprehensive collection of data sourced from pornhub.com, encompassing various details from MANYYY videos available on the platform.\nThe file consists of 742.133 lines of videos.\n\n\t\n\t\t\n\t\tData Description\n\t\n\n\nDelimiter: ‚ÄΩ\nFile Format: CSV\nContent:\nURL: The URL of the video.\nCategory: The genre or category of the video.\nUser: The username of the uploader.\nVideo_title: The title of the video.\nViews: The number of views the video has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nikity/Pornhub.","url":"https://huggingface.co/datasets/Nikity/Pornhub","creator_name":"Nikita","creator_url":"https://huggingface.co/Nikity","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Albanian","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"flores","keyword":"nepali","description":"Evaluation datasets for low-resource machine translation: Nepali-English and Sinhala-English.","url":"https://huggingface.co/datasets/facebook-llama/flores","creator_name":"AstroKid","creator_url":"https://huggingface.co/facebook-llama","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","translation","extended|wikipedia"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"nepali","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof Wr√≥bel","creator_url":"https://huggingface.co/djstrong","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"nepali","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"nepali","description":"Attribution: Wikipedia.org\n","url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"mc4-sampling","keyword":"nepali","description":"A sampling-enabled version of mC4, the colossal, cleaned version of Common Crawl's web crawl corpus.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is a version of the processed version of Google's mC4 dataset by AllenAI, in which sampling methods are implemented to perform on the fly.","url":"https://huggingface.co/datasets/bertin-project/mc4-sampling","creator_name":"BERTIN Project","creator_url":"https://huggingface.co/bertin-project","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"opus_paracrawl","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset Card for OpusParaCrawl\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nParallel corpora from Web Crawls collected in the ParaCrawl project.\nTha dataset contains:\n\n42 languages, 43 bitexts\ntotal number of files: 59,996\ntotal number of tokens: 56.11G\ntotal number of sentence fragments: 3.13G\n\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs,\ne.g.\ndataset = load_dataset(\"opus_paracrawl\", lang1=\"en\", lang2=\"so\")\n\nYou can find the valid‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl.","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"Nepali-Roman-Transliteration","keyword":"nepali","description":"Saugatkafley/Nepali-Roman-Transliteration dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Saugatkafley/Nepali-Roman-Transliteration","creator_name":"Saugat Kafley","creator_url":"https://huggingface.co/Saugatkafley","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Nepali","English","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"xP3all","keyword":"nepali","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"XLSum-nepali-summerization-dataset","keyword":"nepali","description":"sanjeev-bhandari01/XLSum-nepali-summerization-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sanjeev-bhandari01/XLSum-nepali-summerization-dataset","creator_name":"Sanjeev Bhandari","creator_url":"https://huggingface.co/sanjeev-bhandari01","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Nepali","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"XLSum-nepali-summerization-dataset","keyword":"nepali","description":"sanjeev-bhandari01/XLSum-nepali-summerization-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sanjeev-bhandari01/XLSum-nepali-summerization-dataset","creator_name":"Sanjeev Bhandari","creator_url":"https://huggingface.co/sanjeev-bhandari01","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Nepali","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Nepali-HealthChat","keyword":"nepali","description":"NepaliAI/Nepali-HealthChat dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/NepaliAI/Nepali-HealthChat","creator_name":"NepaliAI","creator_url":"https://huggingface.co/NepaliAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Nepali","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Kaleidoscope","keyword":"nepali","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Anonym-sub/Kaleidoscope.","url":"https://huggingface.co/datasets/Anonym-sub/Kaleidoscope","creator_name":"Anonymous submission","creator_url":"https://huggingface.co/Anonym-sub","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"Indic-Rag-Suite","keyword":"nepali","description":"\n\t\n\t\t\n\t\tüåè Multilingual Indic RAG Suite\n\t\n\nA comprehensive multilingual question-answering dataset covering 18 Indian languages with 21,439,886 total samples, designed for RAG (Retrieval-Augmented Generation) applications and multilingual NLP research.\n\n\t\n\t\t\n\t\tüöÄ Quick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load specific language (recommended)\ndataset = load_dataset(\"ai4bharat/Indic-Rag-Suite\", \"as\")\ntrain_data = dataset['train']\n\nprint(f\"Loaded {len(train_data)} samples\")\n\n# Access‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Indic-Rag-Suite.","url":"https://huggingface.co/datasets/ai4bharat/Indic-Rag-Suite","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","multilingual","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"CodeMixBench","keyword":"nepali","description":"\n\t\n\t\t\n\t\t‚ÑπÔ∏èDataset Card for CodeMixBench\n\t\n\n\n\t\n\t\t\n\t\t[EMNLP'25] CodeMixBench: Evaluating Code-Mixing Capabilities of LLMs Across 18 Languages\n\t\n\n   \n      \n   \n        \n  \n      \n   \n  \n      \n   \n\n\n\n\n\nCode-mixing is a linguistic phenomenon where multilingual speakers switch or mix two or more languages within a single utterance or conversation. \nTo evaluate LLMs‚Äô comprehension of multilingual code-mixed texts, we introduce CodeMixBench, a benchmark comprising eight tasks across 18 languages.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CodeMixBench/CodeMixBench.","url":"https://huggingface.co/datasets/CodeMixBench/CodeMixBench","creator_name":"CodeMixBench","creator_url":"https://huggingface.co/CodeMixBench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Chinese","English","Spanish","Hindi","German"],"keywords_longer_than_N":true},
	{"name":"Nepali-Small","keyword":"nepali","description":"NKRSubedi/Nepali-Small dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/NKRSubedi/Nepali-Small","creator_name":"NKRS","creator_url":"https://huggingface.co/NKRSubedi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Nepali","apache-2.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ne","keyword":"nepali","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Nepali version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ne.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Nepali"],"keywords_longer_than_N":true},
	{"name":"roman2nepali-transliteration","keyword":"nepali","description":"\n\t\n\t\t\n\t\tUse this dataset\n\t\n\nfrom datasets import load_dataset\n\ndata = load_dataset(\"syubraj/roman2nepali-transliteration\")\n\n\n\t\n\t\t\n\t\tSource Dataset:\n\t\n\nSaugatkafley/Nepali-Roman-Transliteration\n","url":"https://huggingface.co/datasets/syubraj/roman2nepali-transliteration","creator_name":"Yubraj Sigdel","creator_url":"https://huggingface.co/syubraj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Nepali","English","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"roman2nepali-transliteration","keyword":"nepali","description":"\n\t\n\t\t\n\t\tUse this dataset\n\t\n\nfrom datasets import load_dataset\n\ndata = load_dataset(\"syubraj/roman2nepali-transliteration\")\n\n\n\t\n\t\t\n\t\tSource Dataset:\n\t\n\nSaugatkafley/Nepali-Roman-Transliteration\n","url":"https://huggingface.co/datasets/syubraj/roman2nepali-transliteration","creator_name":"Yubraj Sigdel","creator_url":"https://huggingface.co/syubraj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Nepali","English","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"nepali_sa","keyword":"nepali","description":"\n\t\n\t\t\n\t\tSentiment Analysis Data for the Nepali Language\n\t\n\nDataset Description:\nThis dataset contains a sentiment analysis dataset from Singh et al. (2020).\nData Structure:\nThe data was used for the project on injecting external commonsense knowledge into multilingual Large Language Models.\nCitation:\n@INPROCEEDINGS{9381292,\n  author={Singh, Oyesh Mann and Timilsina, Sandesh and Bal, Bal Krishna and Joshi, Anupam},\n  booktitle={2020 IEEE/ACM International Conference on Advances in Social‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DGurgurov/nepali_sa.","url":"https://huggingface.co/datasets/DGurgurov/nepali_sa","creator_name":"Daniil Gurgurov","creator_url":"https://huggingface.co/DGurgurov","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Nepali","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"constitution","keyword":"nepali","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nayan135/constitution.","url":"https://huggingface.co/datasets/nayan135/constitution","creator_name":"NAYAN ACHARYA","creator_url":"https://huggingface.co/nayan135","license_name":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","translation","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"wildchat-filtered","keyword":"nepali","description":"\n\t\n\t\t\n\t\tWildChat Filtered Dataset\n\t\n\nThis is a filtered version of the WildChat-4.8M dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3,199,860 conversations between human users and ChatGPT, filtered to keep only the essential conversation structure.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach conversation contains only:\n\nconversations: A list of message objects with:\nrole: Either \"user\" or \"assistant\"\ncontent: The text content of the message\n\n\n\nAll other metadata (timestamps, moderation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rayonlabs/wildchat-filtered.","url":"https://huggingface.co/datasets/rayonlabs/wildchat-filtered","creator_name":"Rayon Labs","creator_url":"https://huggingface.co/rayonlabs","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"kaleidoscope","keyword":"nepali","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/kaleidoscope.","url":"https://huggingface.co/datasets/CohereLabs/kaleidoscope","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"nepali","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"ÿßŸÖÿßŸÖ ÿ¨ŸÖÿπŸá ÿßÿµŸÅŸáÿßŸÜ ⁄ØŸÅÿ™: ŸÖ€åÿ≤ÿßŸÜ ŸÜ€åÿßÿ≤ ÿ¢ÿ® ÿ¥ÿ±ÿ® ÿßÿµŸÅŸáÿßŸÜ €±€±.€µ ŸÖÿ™ÿ± ŸÖ⁄©ÿπÿ® ÿßÿ≥ÿ™ ⁄©Ÿá ÿ™ŸÖÿßŸÖ ÿßÿ≥ÿ™ÿßŸÜ ÿßÿµŸÅŸáÿßŸÜ ÿ±ÿß ŸæŸàÿ¥ÿ¥ ŸÖ€åÿØŸáÿØ Ÿà ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸÇÿ®ŸÑ ÿßÿ≤ ÿßŸÜŸÇŸÑÿßÿ® €å⁄©€å ÿßÿ≤ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿáÿß ÿØÿ± ÿ≠Ÿàÿ≤Ÿá ÿ¢ÿ® ÿ®ŸàÿØŸá ÿßÿ≥ÿ™.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"textbooks-qa-nepali","keyword":"nepali","description":"\n\t\n\t\t\n\t\tTextbook Question-Answering Dataset (Nepali)\n\t\n\nThis repository contains ShareGPT-style conversations generated by the Textbook QA agentic pipeline.\n\n\t\n\t\t\n\t\tSplits\n\t\n\n\ntrain: validated conversations with non-empty question, answer, and rephrased_text.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"dineshkarki/textbooks-qa-nepali\")\ntrain = ds[\"train\"]\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\ntrain: each row contains:\nid: unique string\nconversations: list of 2 messages: human and gpt‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dineshkarki/textbooks-qa-nepali.","url":"https://huggingface.co/datasets/dineshkarki/textbooks-qa-nepali","creator_name":"Dinesh Karki","creator_url":"https://huggingface.co/dineshkarki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Nepali","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"textbooks-qa-nepali","keyword":"nepali","description":"\n\t\n\t\t\n\t\tTextbook Question-Answering Dataset (Nepali)\n\t\n\nThis repository contains ShareGPT-style conversations generated by the Textbook QA agentic pipeline.\n\n\t\n\t\t\n\t\tSplits\n\t\n\n\ntrain: validated conversations with non-empty question, answer, and rephrased_text.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"dineshkarki/textbooks-qa-nepali\")\ntrain = ds[\"train\"]\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\ntrain: each row contains:\nid: unique string\nconversations: list of 2 messages: human and gpt‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dineshkarki/textbooks-qa-nepali.","url":"https://huggingface.co/datasets/dineshkarki/textbooks-qa-nepali","creator_name":"Dinesh Karki","creator_url":"https://huggingface.co/dineshkarki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Nepali","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"nepali_alpaca_multiturn","keyword":"nepali","description":"\n\t\n\t\t\n\t\tShareGPT Conversations\n\t\n\nThis repository contains multi-turn human ‚Üî gpt conversations.\n\n\t\n\t\t\n\t\tSplits\n\t\n\n\ndineshkarki/nepali_alpaca_multiturn provides a split named train by default.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"dineshkarki/nepali_alpaca_multiturn\")\ntrain = ds[\"train\"]\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\nEach row contains:\n\nid: unique string\nconversations: list of N messages (N ‚â• 2), alternating human and gpt roles\n\nNotes:\n\nConversations are lightly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dineshkarki/nepali_alpaca_multiturn.","url":"https://huggingface.co/datasets/dineshkarki/nepali_alpaca_multiturn","creator_name":"Dinesh Karki","creator_url":"https://huggingface.co/dineshkarki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Nepali","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"nepali-textbooks-corpus","keyword":"nepali","description":"\n\t\n\t\t\n\t\tNepali Textbooks Corpus for Grades 1-12\n\t\n\nThis dataset contains OCR-extracted, chapter-first, chunked text from Nepali school textbooks.\n\n\t\n\t\t\n\t\tSummary\n\t\n\n\nSamples: 5634\nGrades: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\nSubjects: ['Civic_Education', 'Civic_Science', 'Economics', 'Education', 'Enterprenuership_and_Technology', 'Health_Physcial_and_Creative_Arts', 'Health_Physical_and_Creative_Arts', 'Health_and_Physical_Education', 'Math', 'My_Math', 'My_Nepali'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dineshkarki/nepali-textbooks-corpus.","url":"https://huggingface.co/datasets/dineshkarki/nepali-textbooks-corpus","creator_name":"Dinesh Karki","creator_url":"https://huggingface.co/dineshkarki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","expert-generated","Nepali","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"indic-align","keyword":"nepali","description":"\n\t\n\t\t\n\t\tIndicAlign\n\t\n\nA diverse collection of Instruction and Toxic alignment datasets for 14 Indic Languages. The collection comprises of:\n\nIndicAlign - Instruct\nIndic-ShareLlama\nDolly-T\nOpenAssistant-T\nWikiHow\nIndoWordNet\nAnudesh\nWiki-Conv\nWiki-Chat\n\n\nIndicAlign - Toxic\nHHRLHF-T\nToxic-Matrix\n\n\n\nWe use IndicTrans2 (Gala et al., 2023) for the translation of the datasets. \nWe recommend the readers to check out our paper on Arxiv for detailed information on the curation process of these‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/indic-align.","url":"https://huggingface.co/datasets/ai4bharat/indic-align","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Assamese","Bengali","Gujarati","English"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"nepali","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU üåç is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) üóΩ or Culturally Agnostic (CA) ‚öñÔ∏è. These annotations were collected as part of an open‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU.","url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true}
]
;
