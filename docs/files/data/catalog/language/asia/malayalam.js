const data_for_language_asia_malayalam = 
[
	{"name":"IGB_XQuAD","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IGB_XQuAD","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"VarunGumma/IGB_XQuAD dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"MUSTARD","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/badrivishalk/MUSTARD","creator_name":"Badri Vishal Kasuba","creator_url":"https://huggingface.co/badrivishalk","description":"\n\t\n\t\t\n\t\tDataset Card for MUSTARD\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMUSTARD (Multilingual Scanned and Scene Table Structure Recognition Dataset) is a diverse dataset curated for table structure recognition across multiple languages. The dataset consists of tables extracted from magazines, including printed, scanned, and scene-text tables, labeled with Optimized Table Structure Language (OTSL) sequences. It is designed to facilitate research in multilingual tableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/badrivishalk/MUSTARD.","first_N":5,"first_N_keywords":["image-to-text","English","Hindi","Telugu","Tamil"],"keywords_longer_than_N":true},
	{"name":"MalayalamNewsClassification","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MalayalamNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MalayalamNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Malayalam dataset for 3-class classification of Malayalam news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/goru001/nlp-for-malyalam\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MalayalamNewsClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MalayalamNewsClassification.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Malayalam"],"keywords_longer_than_N":true},
	{"name":"indictts-malayalam","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kavyamanohar/indictts-malayalam","creator_name":"Kavya Manohar","creator_url":"https://huggingface.co/kavyamanohar","description":"The Malayalam Split of IndicTTS dataset. This is part of AI4Bharat Vistaar dataset.\n","first_N":5,"first_N_keywords":["Malayalam","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"TEXTRON_INDIC_DATASETS","keyword":"malayalam","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/badrivishalk/TEXTRON_INDIC_DATASETS","creator_name":"Badri Vishal Kasuba","creator_url":"https://huggingface.co/badrivishalk","description":"This dataset is intended for testing purposes only. It contains a set of test data to evaluate the performance of models. It does not include training or validation data.\n\n\t\n\t\t\n\t\tTEXTRON Paper Release Dataset (WACV 2024)\n\t\n\nWelcome to the TEXTRON Paper Release Dataset for the WACV 2024 conference! This dataset contains handwritten and printed text detection datasets in three different languages. This README provides essential information on the dataset structure, contents, and how to use theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/badrivishalk/TEXTRON_INDIC_DATASETS.","first_N":5,"first_N_keywords":["object-detection","Tamil","Gujarati","Malayalam","Telugu"],"keywords_longer_than_N":true},
	{"name":"IGB_Flores_enxx","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IGB_Flores_enxx","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"VarunGumma/IGB_Flores_enxx dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"IGB_Flores_xxen","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IGB_Flores_xxen","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"VarunGumma/IGB_Flores_xxen dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"indic-squad","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/l3cube-pune/indic-squad","creator_name":"L3Cube Labs","creator_url":"https://huggingface.co/l3cube-pune","description":"\n\t\n\t\t\n\t\tIndicSQuAD Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nIndicSQuAD is a comprehensive multilingual extractive Question Answering (QA) dataset covering nine major Indic languages: Hindi, Bengali, Tamil, Telugu, Marathi, Gujarati, Urdu, Kannada, Oriya, and Malayalam. It's systematically derived from the popular English SQuAD (Stanford Question Answering Dataset).\nThe rapid progress in QA systems has predominantly benefited high-resource languages, leaving Indic languages significantlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/l3cube-pune/indic-squad.","first_N":5,"first_N_keywords":["question-answering","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"sib200_14classes","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200_14classes","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for SIB-200\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\nThe train/validation/test sets are available for all the 205 languages.\nThis is another version with 14 classes, more idea for few-shot evaluation, it has 5 examples for few-shot, and larger test set (1225)\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopic classification: categorize wikipedia sentencesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200_14classes.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"IndicLangClassification","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicLangClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicLangClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Non-fiction, Written\nReference\nhttps://arxiv.org/abs/2305.15814\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicLangClassification\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicLangClassification.","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-annotated","monolingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"milu-cleaned","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/murthyrudra/milu-cleaned","creator_name":"Rudra Murthy","creator_url":"https://huggingface.co/murthyrudra","description":"\n\t\n\t\t\n\t\tMILU: A Multi-task Indic Language Understanding Benchmark\n\t\n\n\n  \n  \n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nMILU (Multi-task Indic Language Understanding Benchmark) is a comprehensive evaluation dataset designed to assess the performance of Large Language Models (LLMs) across 11 Indic languages. It spans 8 domains and 41 subjects, reflecting both general and culturally specific knowledge from India.\n\n\t\n\t\n\t\n\t\tKey Features\n\t\n\n\n11 Indian Languages: Bengali, Gujarati, Hindi, Kannada, Malayalamâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/murthyrudra/milu-cleaned.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"IGB_XorQA","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IGB_XorQA","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"VarunGumma/IGB_XorQA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"PMIndiaSum","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PMIndiaData/PMIndiaSum","creator_name":"PMIndiaData","creator_url":"https://huggingface.co/PMIndiaData","description":"\n\t\n\t\t\n\t\tDataset Card for \"PMIndiaSum\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nPMIndiaSum is a new multilingual and massively parallel headline summarization corpus focused on languages in India. Our corpus covers four language families, 14 languages, and the largest to date, 196 language pairs. It provides a testing ground for all cross-lingual pairs.\n\n\t\n\t\t\n\t\tSupported tasks\n\t\n\nMonolingual, multilingual and cross-lingual summarization for languages in India.\n\n\t\n\t\t\n\t\tLanguagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PMIndiaData/PMIndiaSum.","first_N":5,"first_N_keywords":["summarization","Assamese","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\n","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for SIB-200\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\nThe train/validation/test sets are available for all the 205 languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 205 languages available :\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","MetlatÃ³noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"BB-Ultrachat-IndicLingual6-12k","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rohansolo/BB-Ultrachat-IndicLingual6-12k","creator_name":"Rohan","creator_url":"https://huggingface.co/rohansolo","description":"\n\t\n\t\t\n\t\tBB-Ultrachat-IndicLingual6-12k\n\t\n\nThis dataset is created by bhaiyabot ai to enrich language model training data, especially in the context of Indic languages. code for creation is also open source at https://github.com/ro-hansolo/IndicTrans2HuggingFaceDatasets\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nBB-Ultrachat-IndicLingual6-12k is a curated dataset comprising 12,000 multi-turn conversations, which are a subset of the larger HuggingFaceH4/ultrachat_200k dataset. These conversations have been evenlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rohansolo/BB-Ultrachat-IndicLingual6-12k.","first_N":5,"first_N_keywords":["question-answering","text-generation","Hindi","Malayalam","Tamil"],"keywords_longer_than_N":true},
	{"name":"openslr63","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vrclc/openslr63","creator_name":"Virtual Resource Centre for Language Computing (Digital University Kerala)","creator_url":"https://huggingface.co/vrclc","description":"\n\t\n\t\t\n\t\tSLR63: Crowdsourced high-quality Malayalam multi-speaker speech data set\n\t\n\nThis data set contains transcribed high-quality audio of Malayalam sentences recorded by volunteers. The data set consists of wave files, and a TSV file (line_index.tsv). The file line_index.tsv contains a anonymized FileID and the transcription of audio in the file.\nThe data set has been manually quality checked, but there might still be errors.\nPlease report any issues in the following issue tracker onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vrclc/openslr63.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Malayalam","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"FranÃ§ais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) â†’ aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages â†’ dolly-machine-translated.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"belebele","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\n\t\n\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that discriminateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele.","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","text-classification","multiple-choice","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\n\t\n\t\t\n\t\tDataset Card for WikiAnc\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \nThe code for generating the dataset can be found here.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nwikificiation: The dataset can be used to train a model for Wikification.\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in all 320â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"megawika-report-generation","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\n\t\n\t\t\n\t\tDataset Card for MegaWika for Report Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\nnon-English language, an automated English translation is provided. \nThis dataset provides theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation.","first_N":5,"first_N_keywords":["summarization","text-retrieval","text-generation","text2text-generation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"imasc_slr","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vrclc/imasc_slr","creator_name":"Virtual Resource Centre for Language Computing (Digital University Kerala)","creator_url":"https://huggingface.co/vrclc","description":"Clone of : thennal/IMaSC\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Malayalam","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MSC","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/smcproject/MSC","creator_name":"Swathanthra Malayalam Computing","creator_url":"https://huggingface.co/smcproject","description":"\n\t\n\t\t\n\t\tDataset Card for [msc]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n1541 speech samples\n75 speech contributors\n1:38:16 hours of speech\n482 unique sentences\n1400 unique words\n553 unique syllables\n48 unique phonemes\n\nFor more detailed analysis see the python notebook provided here\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nAutomatic Speech Recognition system development, gender and age identification of speakers\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nMalayalam\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\nfile_nameâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/smcproject/MSC.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Malayalam","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ml-phonetic-lexicon","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/smcproject/ml-phonetic-lexicon","creator_name":"Swathanthra Malayalam Computing","creator_url":"https://huggingface.co/smcproject","description":"\n\t\n\t\t\n\t\tMalayalam Phonetic Lexicon\n\t\n\nThis dataset contains words in Malayalam script and their pronunciation in International Phonetic Alphabet (IPA)\nThe words in the lexicon are sourced from \n\nThe most frequest 100 thousand words from Indic NLP corpus\nCurated collection of word categories from Mlmorph project\n\nThis pronunciations are created using Mlphon python Library.\n\n\t\n\t\t\n\t\n\t\n\t\tApplications\n\t\n\n\nReady to use pronunciation lexicons for ASR and TTS\nTo train datadriven grapheme to phonemeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/smcproject/ml-phonetic-lexicon.","first_N":5,"first_N_keywords":["text2text-generation","Malayalam","cc-by-4.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"Pontoon-Translations","keyword":"malayalam","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\n\t\n\t\t\n\t\tDataset Card for Pontoon Translations\n\t\n\n\n\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\nSource strings are in English.\nTo avoid rows with values like \"None\" and \"N/A\" being interpreted as missing values, pass the keep_default_na parameter like this:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ayymen/Pontoon-Translations\", keep_default_na=False)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","text2text-generation","crowdsourced","Abkhaz","Achinese"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\n\t\n\t\t\n\t\tDataset Card for WIT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\nFrom the official blog post:\n\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\nThe WIT dataset offers extremely valuable data about theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NTREXBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNTREX is a News Test References dataset for Machine Translation Evaluation, covering translation from English into 128 languages. We select language pairs according to the M2M-100 language grouping strategy, resulting in 1916 directions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/davidstap/NTREX\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","translated","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","description":"\n\n\n\t\n\t\t\n\t\tðŸ”· Accepted in NAACL Proceedings (2025) ðŸ”·\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval ðŸ“š [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","first_N":5,"first_N_keywords":["text2text-generation","Afar","Abkhaz","Avestan","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"Indic-Rag-Suite","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/Indic-Rag-Suite","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tðŸŒ Multilingual Indic RAG Suite\n\t\n\n\n\t\n\t\t\n\t\tðŸš€ Quick Start - Load Individual Languages (RECOMMENDED)\n\t\n\nfrom datasets import load_dataset\n\n# Load ONLY Hindi data (fast and efficient!)\nhindi_data = load_dataset(\"ai4bharat/Indic-Rag-Suite\", name=\"hi\")\nprint(f\"Hindi samples: {len(hindi_data['train'])}\")\n\n# Load ONLY Bengali data\nbengali_data = load_dataset(\"ai4bharat/Indic-Rag-Suite\", name=\"bn\") \nprint(f\"Bengali samples: {len(bengali_data['train'])}\")\n\n# Access the data directly\nforâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Indic-Rag-Suite.","first_N":5,"first_N_keywords":["question-answering","text-generation","multilingual","original","Assamese"],"keywords_longer_than_N":true},
	{"name":"offenseval_dravidian","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/offenseval_dravidian","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for Offenseval Dravidian\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOffensive language identification is classification task in natural language processing (NLP) where the aim is to moderate and minimise offensive content in social media. It has been an active area of research in both academia and industry for the past two decades. There is an increasing demand for offensive language identification on social media texts which are largely code-mixed. Code-mixing is a prevalentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/offenseval_dravidian.","first_N":5,"first_N_keywords":["text-classification","expert-generated","crowdsourced","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"malayalam","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for Opus Ubuntu\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\nE.g.\ndataset = load_dataset(\"opus_ubuntu\", lang1=\"it\", lang2=\"pl\")\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboardsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tDataset Card for \"xtreme\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"indicxnli","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Divyanshu/indicxnli","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","description":"IndicXNLI is a translated version of XNLI to 11 Indic Languages. As with XNLI, the goal is\nto predict textual entailment (does sentence A imply/contradict/neither sentence\nB) and is a classification task (given two sentences, predict one of three\nlabels).","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","machine-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_scenario","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_scenario","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveScenarioClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveScenarioClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_scenario.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_intent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveIntentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_intent.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"xP3all","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"xP3mt","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"IE_SemParse","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Divyanshu/IE_SemParse","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","description":"    IE-SemParse is an Inter-bilingual Seq2seq Semantic parsing dataset for 11 distinct Indian languages","first_N":5,"first_N_keywords":["text2text-generation","parsing","machine-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"IMaSC","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/IMaSC","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tIMaSC: ICFOSS Malayalam Speech Corpus\n\t\n\nIMaSC is a Malayalam text and speech corpus made available by ICFOSS for the purpose of developing speech technology for Malayalam, particularly text-to-speech. The corpus contains 34,473 text-audio pairs of Malayalam sentences spoken by 8 speakers, totalling in approximately 50 hours of audio.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of 34,473 instances with fields text, speaker, and audio. The audio is mono, sampled at 16kH. Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/thennal/IMaSC.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"msc","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/msc","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tSMC Malayalam Speech Corpus\n\t\n\nMalayalam Speech Corpus (MSC) is a repository of curated speech samples collected using MSC web application, released by Swathanthra Malayalam Computing. \nThe official blog post and source data can be found at https://blog.smc.org.in/malayalam-speech-corpus/.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe first version of Malayalam Speech Corpus contains 1541 speech samples from 75 contributors amounting to 1:38:16 hours of speech. It has 482 unique sentences, 1400â€¦ See the full description on the dataset page: https://huggingface.co/datasets/thennal/msc.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","monolingual","Malayalam"],"keywords_longer_than_N":true},
	{"name":"ulca_ml","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/ulca_ml","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tULCA ASR Dataset Malayalam Speech Corpus\n\t\n\nThe labelled Malayalam speech subcorpus from the larger ULCA ASR Corpus.\nThe speech is taken from news broadcasts, and is largely composed of short soundbites with some longer outliers.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","found","monolingual","Malayalam"],"keywords_longer_than_N":true},
	{"name":"naamapadam","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/naamapadam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\\","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","machine-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof WrÃ³bel","creator_url":"https://huggingface.co/djstrong","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"Alpaca-CoT","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QingyiSi/Alpaca-CoT","creator_name":"Qingyi Si","creator_url":"https://huggingface.co/QingyiSi","description":"\n\t\n\t\t\n\t\n\t\n\t\tInstruction-Finetuning Dataset Collection (Alpaca-CoT)\n\t\n\nThis repository will continuously collect various instruction tuning datasets. And we standardize different datasets into the same format, which can be directly loaded by the code of Alpaca model.\nWe also have conducted empirical study on various instruction-tuning datasets based on the Alpaca model, as shown in https://github.com/PhoebusSi/alpaca-CoT.  \nIf you think this dataset collection is helpful to you, please likeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QingyiSi/Alpaca-CoT.","first_N":5,"first_N_keywords":["English","Chinese","Malayalam","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"malayalam-morphology-analyser","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/santhosh/malayalam-morphology-analyser","creator_name":"Santhosh Thottingal","creator_url":"https://huggingface.co/santhosh","description":"\n\t\n\t\t\n\t\tMalayalam Morphology Analyser dataset\n\t\n\nThis is a dataset of 801585 Malayalam words and their morphology analysis using Mlmorph Malayalam morphology analyser. \n\n\t\n\t\t\n\t\tLicense\n\t\n\nCreative Commons Attribution Share Alike 4.0\n\n\t\n\t\t\n\t\tContact\n\t\n\nContact santhosh.thottingal @ gmail.com\n","first_N":5,"first_N_keywords":["Malayalam","cc-by-sa-4.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"malayalam-morphology-analyser","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/santhosh/malayalam-morphology-analyser","creator_name":"Santhosh Thottingal","creator_url":"https://huggingface.co/santhosh","description":"\n\t\n\t\t\n\t\tMalayalam Morphology Analyser dataset\n\t\n\nThis is a dataset of 801585 Malayalam words and their morphology analysis using Mlmorph Malayalam morphology analyser. \n\n\t\n\t\t\n\t\tLicense\n\t\n\nCreative Commons Attribution Share Alike 4.0\n\n\t\n\t\t\n\t\tContact\n\t\n\nContact santhosh.thottingal @ gmail.com\n","first_N":5,"first_N_keywords":["Malayalam","cc-by-sa-4.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"english-malayalam-names","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/santhosh/english-malayalam-names","creator_name":"Santhosh Thottingal","creator_url":"https://huggingface.co/santhosh","description":"\n\t\n\t\t\n\t\tEnglish Malayalam names\n\t\n\nThis dataset has 27814162 person names both in English and Malayalam. \nThe source for this dataset is various election roles published by Government.\nPotential usages:\n\nEnglish <-> Malayalam name transliteration tasks\nNamed entity recognition\nPerson name recognition\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nCreative commons Attribution Share Alike 4.0\n\n\t\n\t\t\n\t\tContact\n\t\n\nSanthosh Thottingal santhosh.thottingal @ gmail.com\n","first_N":5,"first_N_keywords":["text2text-generation","English","Malayalam","cc-by-sa-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"english-malayalam-names","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/santhosh/english-malayalam-names","creator_name":"Santhosh Thottingal","creator_url":"https://huggingface.co/santhosh","description":"\n\t\n\t\t\n\t\tEnglish Malayalam names\n\t\n\nThis dataset has 27814162 person names both in English and Malayalam. \nThe source for this dataset is various election roles published by Government.\nPotential usages:\n\nEnglish <-> Malayalam name transliteration tasks\nNamed entity recognition\nPerson name recognition\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nCreative commons Attribution Share Alike 4.0\n\n\t\n\t\t\n\t\tContact\n\t\n\nSanthosh Thottingal santhosh.thottingal @ gmail.com\n","first_N":5,"first_N_keywords":["text2text-generation","English","Malayalam","cc-by-sa-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"GMaSC","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/GMaSC","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\n\t\n\t\t\n\t\tGMaSC: GEC Barton Hill Malayalam Speech Corpus\n\t\n\nGMaSC is a Malayalam text and speech corpus created by the Government Engineering College Barton Hill with an emphasis on Malayalam-accented English. The corpus contains 2,000 text-audio pairs of Malayalam sentences spoken by 2 speakers, totalling in approximately 139 minutes of audio. Each sentences has at least one English word common in Malayalam speech.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of 2,000 instances with fieldsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/thennal/GMaSC.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Bhasha-Abhijnaanam","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tDataset Card for Aksharantar\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBhasha-Abhijnaanam is a language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\n\t\n\t\t\n\n\n\n\n\n\n\n\n\t\t\nAssamese (asm)\nHindi (hin)\nMaithili (mai)\nNepali (nep)\nSanskrit (san)\nTamil (tam)\n\n\nBengali (ben)\nKannada (kan)\nMalayalam (mal)\nOriya (ori)\nSantali (sat)\nTelugu (tel)\n\n\nBodo(brx)\nKashmiriâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\n\n\t\n\t\t\n\nToxic\nNeutral\nTotal\n\n\n\t\t\nmultilingual-train-deduplicated.csvâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Spanish","Panjabi"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"laion-14k-GPT4V-LIVIS-Captions_Malayalam","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VishnuPJ/laion-14k-GPT4V-LIVIS-Captions_Malayalam","creator_name":"Vishnu Prasad J","creator_url":"https://huggingface.co/VishnuPJ","description":"\nMalayalam translated version of laion-14k-GPT4V-LIVIS-Captions\nTranslated using indictrans2\nTranslation Code : code\n\n","first_N":5,"first_N_keywords":["Malayalam","mit","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ml","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoDBPedia dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ml","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ml","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ml","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoMSMARCO dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ml","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ml","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoSCIDOCS dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ml","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoSciFact dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Malayalam"],"keywords_longer_than_N":true},
	{"name":"dhpileIN","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aloobun/dhpileIN","creator_name":"aloobun","creator_url":"https://huggingface.co/aloobun","description":"@misc{aralikatte2023varta,\n      title={V\\=arta: A Large-Scale Headline-Generation Dataset for Indic Languages}, \n      author={Rahul Aralikatte and Ziling Cheng and Sumanth Doddapaneni and Jackie Chi Kit Cheung},\n      year={2023},\n      eprint={2305.05858},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n","first_N":5,"first_N_keywords":["Bengali","Gujarati","Hindi","Kannada","Tamil"],"keywords_longer_than_N":true},
	{"name":"IndoNLP-Transliteration-ml","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vrclc/IndoNLP-Transliteration-ml","creator_name":"Virtual Resource Centre for Language Computing (Digital University Kerala)","creator_url":"https://huggingface.co/vrclc","description":"\n\t\n\t\t\n\t\tRomanized to Native Malayalam Script Transliteration\n\t\n\nShared-Task code submitted to IndoNLP Workshop colocated with COLING 2025, in Abu Dhabi, UAE.\nThe training notebook shows the code.\n\n\t\n\t\t\n\t\tTraining\n\t\n\nData derived from:\n\nDakshina\nRomanized - 186 thousand  word transliteration pairs\nLexicons - 58.4 thousand lexicon entries\n\n\nAksharantar - 4.3 million word transliteration pairs\n\n\n\t\n\t\t\n\t\n\t\n\t\tRESULT\n\t\n\nWe present the evaluation scores averaged over the two test datsets shared by theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vrclc/IndoNLP-Transliteration-ml.","first_N":5,"first_N_keywords":["text2text-generation","Malayalam","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Pralekha","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/Pralekha","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tPralekha: Cross-Lingual Document Alignment for Indic Languages\n\t\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\nPralekha is a large-scale parallel document dataset spanning across 11 Indic languages and English. It comprises over 3 milliondocument pairs, with 1.5 million being English-centric. This dataset serves both as a benchmark for evaluating Cross-Lingual Document Alignment (CLDA) techniques and as a domain-specific parallel corpus for training document-level Machine Translationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Pralekha.","first_N":5,"first_N_keywords":["translation","Bengali","English","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"2M-Belebele","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\t2M-Belebele\n\t\n\n\n\t\n\t\t\n\t\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\n\t\n\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs datasets asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.","first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Bulgarian","Panjabi","English"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"Deltacorpus_1.1","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\n[!NOTE]\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, PortoroÅ¾, Slovenia).\nChanges in version 1.1: \n\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \n\nSVM classifier trained on Universalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1.","first_N":5,"first_N_keywords":["token-classification","multilingual","Afrikaans","Albanian","Amharic"],"keywords_longer_than_N":true},
	{"name":"IndicReviewsClusteringP2P","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicReviewsClusteringP2P","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicReviewsClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of reviews from IndicSentiment dataset. Clustering of 14 sets on the generic categories label.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicReviewsClusteringP2P\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicReviewsClusteringP2P.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"IndicCrosslingualSTS","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicCrosslingualSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicCrosslingualSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a Semantic Textual Similarity testset between English and 12 high-resource Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Non-fiction, Web, Spoken, Government, Written, Spoken\nReference\nhttps://huggingface.co/datasets/jaygala24/indic_sts\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicCrosslingualSTS.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","expert-annotated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSIB-Fleurs\n\t\n\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \nThe topics are:\n\nScience/Technology\nTravel\nPolitics\nSports\nHealth\nEntertainment\nGeography\n\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset creation\n\t\n\nThis dataset processes and mergesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"Aksharantar-ml","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vrclc/Aksharantar-ml","creator_name":"Virtual Resource Centre for Language Computing (Digital University Kerala)","creator_url":"https://huggingface.co/vrclc","description":"\n\t\n\t\t\n\t\tAksharanatar Malayalam\n\t\n\nSource: https://huggingface.co/datasets/ai4bharat/Aksharantar\n@misc{madhani2022aksharantar,\n      title={Aksharantar: Towards Building Open Transliteration Tools for the Next Billion Users}, \n      author={Yash Madhani and Sushane Parthan and Priyanka Bedekar and Ruchi Khapra and Anoop Kunchukuttan and Pratyush Kumar and Mitesh Shantadevi Khapra},\n      year={2022},\n      eprint={},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n","first_N":5,"first_N_keywords":["text2text-generation","Malayalam","cc-by-sa-4.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ml","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Malayalam"],"keywords_longer_than_N":true},
	{"name":"IN22-Conv-Doc-Level","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/IN22-Conv-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"This dataset was constructed by merging individual conversations from the IN22-Conv dataset to create a long-context, document-level parallel benchmark. For further information on domains and statistics, please refer to the original paper and dataset.\n","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"Flores-Indic-Doc-Level","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VarunGumma/Flores-Indic-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","description":"This dataset was constructed by merging individual sentences from the Flores dataset based on matching domain, topic, and URL attributes. The result is a long-context, document-level parallel benchmark. For more details on the domains and dataset statistics, please refer to the original paper and the dataset.\n","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"indic_sentiment_analyzer","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dhruv0808/indic_sentiment_analyzer","creator_name":"Dhruv Bhatnagar","creator_url":"https://huggingface.co/dhruv0808","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n\t\n\t\t\n\t\tMultilingual Sentiment Analysis Dataset for Indian Languages\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository contains a comprehensive sentiment analysis dataset covering 11 Indian languages and English. The dataset is designed to support sentiment analysis tasks across multiple domains and languages, making it valuable for developing multilingual sentiment analysis models and applications.\n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\n\nEnglish (en) - Original\nHindi (hi)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/dhruv0808/indic_sentiment_analyzer.","first_N":5,"first_N_keywords":["English","Hindi","Telugu","Tamil","Kannada"],"keywords_longer_than_N":true},
	{"name":"hindi-malayalam-dataset","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YADHU1234/hindi-malayalam-dataset","creator_name":"YADHU","creator_url":"https://huggingface.co/YADHU1234","description":"\n\t\n\t\t\n\t\tHindi-Malayalam Dataset\n\t\n\nThis dataset contains parallel translations between Hindi and Malayalam, extracted from the bible_para dataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguages: Hindi (hin_Deva) and Malayalam (mal_Mlym)\nSource: nllb\nLicense: CC BY 4.0\nUse Cases: Machine translation, linguistic research.\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n\n\t\n\t\t\nHindi\nMalayalam\n\n\n\t\t\nà¤¨à¤®à¤¸à¥à¤¤à¥‡\nà´¹à´²àµ‹\n\n\n\t\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThe dataset is licensed under the CC BY 4.0 License.\n","first_N":5,"first_N_keywords":["cc-by-4.0","1M - 10M","parquet","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ml","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ml","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ml","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ml","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ml","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Malayalam version of the NanoArguAna dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ml.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Malayalam"],"keywords_longer_than_N":true},
	{"name":"Telugu-NLP-AI-Dialect-Comedy-video-Dataset","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Automation-Tribe/Telugu-NLP-AI-Dialect-Comedy-video-Dataset","creator_name":"AUTTRIBE-AI-AUTOMATION","creator_url":"https://huggingface.co/Automation-Tribe","description":"Telugu is one of the sweetest and oldest languages of India. A deep Dive into Telugu its spoken in 2 states and majorly 16 regional dailects.\nThis Dataset help you perform operations in NLP and Speech Recognition Models towards telugu Dialects.\n","first_N":5,"first_N_keywords":["text-classification","feature-extraction","Telugu","Kannada","English"],"keywords_longer_than_N":true},
	{"name":"sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tasmay-Tib/sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600","creator_name":"Tasmay Pankaj Tibrewal","creator_url":"https://huggingface.co/Tasmay-Tib","description":"Dataset for sarvam's entity normalisation task. More detailed information can be found here, in the main model repo: Hugging Face\nDetailed Report (Writeup): Google Drive\nIt also has a gguf variant, with certain additional gguf based innstructions: Hugging Face\nModel inference script can be found here: Colab\nModel predictions can be found in this dataset and both the repo files. named as: \n\neval_data_001_predictions.csv and eval_data_001_predictions_excel.csv.\ntrain_data_001_predictions.csvandâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tasmay-Tib/sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600.","first_N":5,"first_N_keywords":["Hindi","Tamil","Telugu","Marathi","Bengali"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"flores","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/flores","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FloresBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nFLORES is a benchmark dataset for machine translation between English and low-resource languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNon-fiction, Encyclopaedic, Written\n\nReference\nhttps://huggingface.co/datasets/facebook/flores\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FloresBitextMining\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/flores.","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Achinese","Mesopotamian Arabic"],"keywords_longer_than_N":true},
	{"name":"IN22-Conv","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IN22-Conv","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IN22ConvBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Conv is a n-way parallel conversation domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nSocial, Spoken, Fiction, Spoken\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Conv\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Conv.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"IN22-Gen","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IN22-Gen","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IN22GenBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Gen is a n-way parallel general-purpose multi-domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Legal, Government, News, Religious, Non-fiction, Written\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Gen\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Gen.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"shrutilipi","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amithm3/shrutilipi","creator_name":"Amith M","creator_url":"https://huggingface.co/amithm3","description":"amithm3/shrutilipi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","Sanskrit","Bengali","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Pronunciation-dictionary-malayalam","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kavyamanohar/Pronunciation-dictionary-malayalam","creator_name":"Kavya Manohar","creator_url":"https://huggingface.co/kavyamanohar","description":"\n\t\n\t\t\n\t\tMalayalam Pronunciation Dictionary\n\t\n\nThis Dataset has an alternate name of Malayalam Phonetic Lexicon. It is curated from the original source here \nIt gives Phonemic transcription of Malayalam words in IPA format.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a collection of Malayalam words and their pronunciation described in IPA format. The pronunciations has been automatically generated using [Mlphon]\n(https://pypi.org/project/mlphon/) Python library.\n\nCuratedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kavyamanohar/Pronunciation-dictionary-malayalam.","first_N":5,"first_N_keywords":["text2text-generation","Malayalam","cc-by-sa-4.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"day_in_history","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/santhosh/day_in_history","creator_name":"Santhosh Thottingal","creator_url":"https://huggingface.co/santhosh","description":"\n\t\n\t\t\n\t\tDay in History\n\t\n\nThis is a dataset prepared out of wikipedia pages https://en.wikipedia.org/wiki/Category:Days_of_the_year.\nHistoric events are mapped against each date with reference if available.\nHere is a demo app using this dataset: https://huggingface.co/spaces/santhosh/day_in_history\nScript used for parsing wiki pages: https://github.com/santhoshtr/day-in-history. Please use that repository for tracking issues regarding adding more languages, data cleanup etc.\n","first_N":5,"first_N_keywords":["English","Malayalam","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Ultimate-Malayalam-Dataset","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Arjun-G-Ravi/Ultimate-Malayalam-Dataset","creator_name":"Arjun G Ravi","creator_url":"https://huggingface.co/Arjun-G-Ravi","description":"\n\t\n\t\t\n\t\n\t\n\t\tAbout\n\t\n\nThis is a large dataset that contains a lot of (more than 6 million) lines of malayalam text. The dataset is created by combining many other malayalam datasets, and cleaning them.\nThe dataset is ideal to train or fine tune a Large Language Model on Malayalam language.\n\n\t\n\t\t\n\t\n\t\n\t\tCredits\n\t\n\n\nhttps://www.kaggle.com/datasets/disisbig/malyalam-news-dataset\nhttps://www.kaggle.com/datasets/parvmodi/english-to-malayalam-machine-translation-dataset?select=train.mlâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Arjun-G-Ravi/Ultimate-Malayalam-Dataset.","first_N":5,"first_N_keywords":["text-generation","summarization","Malayalam","mit","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Indic_south_langs","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Logii33/Indic_south_langs","creator_name":"Logesh","creator_url":"https://huggingface.co/Logii33","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Logii33/Indic_south_langs.","first_N":5,"first_N_keywords":["translation","Hindi","Tamil","Malayalam","Telugu"],"keywords_longer_than_N":true},
	{"name":"Saka-Alpaca-v1","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Saka-Alpaca-v1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"https://chatgpt.com\n","first_N":5,"first_N_keywords":["text-generation","Swedish","Norwegian","Finnish","German"],"keywords_longer_than_N":true},
	{"name":"linkedin-industry-list","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fantastic-jobs/linkedin-industry-list","creator_name":"Fantastic.jobs","creator_url":"https://huggingface.co/fantastic-jobs","description":"fantastic-jobs/linkedin-industry-list dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","translation","English","Korean","Spanish"],"keywords_longer_than_N":true},
	{"name":"english-to-malayalam-mt","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hemanth-thunder/english-to-malayalam-mt","creator_name":"Hemanth-thunder","creator_url":"https://huggingface.co/Hemanth-thunder","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nEnglish to Malayalam Parallel dataset for Machine translation task\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nRepository: https://www.kaggle.com/datasets/parvmodi/english-to-malayalam-machine-translation-dataset/data\n\n","first_N":5,"first_N_keywords":["translation","Malayalam","English","cc0-1.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Malayalam-VQA","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VishnuPJ/Malayalam-VQA","creator_name":"Vishnu Prasad J","creator_url":"https://huggingface.co/VishnuPJ","description":"\nMalayalam translated version of merve/vqav2-small\nTranslated using indictrans2\nTranslation Code : code\n\n","first_N":5,"first_N_keywords":["Malayalam","mit","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"shiksha","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SPRINGLab/shiksha","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","description":"\n\t\n\t\t\n\t\tShiksha Dataset\n\t\n\nThis is a Technical Domain focused Translation Dataset for 8 Indian Languages. It consists of more than 2.5 million rows of translation pairs between all 8 languages and English.\nThis data has been derived from raw NPTEL documents. More information on this can be found in our paper: https://arxiv.org/abs/2412.09025\nIf you use this data in your work, please cite us:\n@misc{joglekar2024shikshatechnicaldomainfocused,\n      title={Shiksha: A Technical Domain focusedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/shiksha.","first_N":5,"first_N_keywords":["translation","Hindi","Bengali","Tamil","Telugu"],"keywords_longer_than_N":true},
	{"name":"NLG-Machine-Translation","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisingapore/NLG-Machine-Translation","creator_name":"AI Singapore","creator_url":"https://huggingface.co/aisingapore","description":"\n\t\n\t\t\n\t\tSEA Machine Translation\n\t\n\nSEA Machine Translation evaluates a model's ability to translate a document from a source language into a target language coherently and fluently. It is sampled from FLORES 200 for Burmese, Chinese, English, Indonesian, Khmer, Malay, Tamil, Thai, and Vietnamese, and NusaX for Indonesian, Javanese, and Sundanese.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nSEA Machine Translation is designed for evaluating chat or instruction-tuned large language modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aisingapore/NLG-Machine-Translation.","first_N":5,"first_N_keywords":["text-generation","English","Indonesian","Javanese","Khmer"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"indic-parallel-sentences-talks","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aloobun/indic-parallel-sentences-talks","creator_name":"aloobun","creator_url":"https://huggingface.co/aloobun","description":"\n\t\n\t\t\n\t\tDataset Card for Parallel Sentences - Indic Talks\n\t\n\nThis dataset contains parallel sentences (i.e. English sentence + the same sentences in another language) for numerous other languages.\n","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"IndicQARetrieval","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIndicQA is a manually curated cloze-style reading comprehension dataset that can be used for evaluating question-answering models in 11 Indic languages. It is repurposed retrieving relevant context for each question.\n\n\t\n\t\t\n\n\n\n\n\t\tTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicQARetrieval.","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","translated","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"corpus-eng-mal","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MagicHand/corpus-eng-mal","creator_name":"Joseph Rony Correya","creator_url":"https://huggingface.co/MagicHand","description":"MagicHand/corpus-eng-mal dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","Malayalam","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MegaWika","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/conceptofmind/MegaWika","creator_name":"Enrico Shippole","creator_url":"https://huggingface.co/conceptofmind","description":"\n\t\n\t\t\n\t\tDataset Card for MegaWika\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\nnon-English language, an automated English translation is provided. Furthermore, nearly 130 million Englishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/conceptofmind/MegaWika.","first_N":5,"first_N_keywords":["summarization","question-answering","text-generation","text2text-generation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tBelebele-Fleurs\n\t\n\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\n\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30â€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/include-base-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tINCLUDE-base (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-base-44.","first_N":5,"first_N_keywords":["text2text-generation","multiple-choice","Albanian","Arabic","Armenian"],"keywords_longer_than_N":true},
	{"name":"ASR-REF-PRED","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vrclc/ASR-REF-PRED","creator_name":"Virtual Resource Centre for Language Computing (Digital University Kerala)","creator_url":"https://huggingface.co/vrclc","description":"\n\n\n","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Malayalam","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/include-lite-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tINCLUDE-lite (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-lite-44.","first_N":5,"first_N_keywords":["text2text-generation","multiple-choice","Albanian","Arabic","Armenian"],"keywords_longer_than_N":true},
	{"name":"dakshina-lexicons-ml","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vrclc/dakshina-lexicons-ml","creator_name":"Virtual Resource Centre for Language Computing (Digital University Kerala)","creator_url":"https://huggingface.co/vrclc","description":"\n\t\n\t\t\n\t\tDakshina Malayalam Transliteration Lexicon\n\t\n\nFor original source: https://github.com/google-research-datasets/dakshina\n@inproceedings{roark-etal-2020-processing,\n    title = \"Processing {South} {Asian} Languages Written in the {Latin} Script:\n    the {Dakshina} Dataset\",\n    author = \"Roark, Brian and\n      Wolf-Sonkin, Lawrence and\n      Kirov, Christo and\n      Mielke, Sabrina J. and\n      Johny, Cibu and\n      Demir{\\c{s}}ahin, I{\\c{s}}in and\n      Hall, Keith\",\n    booktitle =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/vrclc/dakshina-lexicons-ml.","first_N":5,"first_N_keywords":["text2text-generation","Malayalam","cc-by-sa-4.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"mmlu-indic","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sarvamai/mmlu-indic","creator_name":"Sarvam AI","creator_url":"https://huggingface.co/sarvamai","description":"\n\t\n\t\t\n\t\tIndic MMLU Dataset\n\t\n\nA multilingual version of the Massive Multitask Language Understanding (MMLU) benchmark, translated from English into 10 Indian languages.\nThis version contains the translations of the development and test sets only. \n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\nThe dataset includes translations in the following languages:\n\nBengali (bn)\nGujarati (gu)\nHindi (hi)\nKannada (kn)\nMarathi (mr)\nMalayalam (ml)\nOriya (or)\nPunjabi (pa)\nTamil (ta)\nTelugu (te)\n\n\n\t\n\t\t\n\t\tTask Format\n\t\n\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sarvamai/mmlu-indic.","first_N":5,"first_N_keywords":["question-answering","Bengali","English","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"reranking-datasets-light","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","description":"\n\t\n\t\t\n\t\tðŸ”¥ Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation ðŸ”¥\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\n\t\n\n\n    \n    \n    \n    \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n    \n\n\n\nA curated collection of ready-to-use datasets for retrieval and rerankingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light.","first_N":5,"first_N_keywords":["question-answering","English","Arabic","German","French"],"keywords_longer_than_N":true},
	{"name":"Indic-subtitler-audio_evals","keyword":"malayalam","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kurianbenoy/Indic-subtitler-audio_evals","creator_name":"Kurian Benoy","creator_url":"https://huggingface.co/kurianbenoy","description":"\n\t\n\t\t\n\t\tIndic_audio_evals\n\t\n\nAs part of this project. We are evaluating our performance of various ASR models as well\nin a benchmarking dataset, we have created in various languages. This benchmarking dataset\nis more alligned to real-world use-cases rather than having any academic datasets.\n\n\t\n\t\t\n\t\tAbout Dataset\n\t\n\n\nDataset Link in HuggingFace: kurianbenoy/Indic-subtitler-audio_evals\n\nThis dataset contains audio file in .wav format and video file in .mp4. The respective groundtruth will beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kurianbenoy/Indic-subtitler-audio_evals.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Malayalam","Hindi","English","Bengali"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\nand converted into different parts (see process.py):\n\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\n\nRaw data files are in raw.tar.gz, which contains:\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\n[...] 9.8M Feb 24â€¦ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul RÃ¶ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"sangraha","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/sangraha","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tSangraha\n\t\n\n\n  \n\n\nSangraha is the largest high-quality, cleaned Indic language pretraining data containing 251B tokens summed up over 22 languages, extracted from curated sources, existing multilingual corpora and large scale translations.\nMore information:\n\nFor detailed information on the curation and cleaning process of Sangraha, please checkout our paper on Arxiv;\nCheck out the scraping and cleaning pipelines used to curate Sangraha on GitHub;\n\n\n\t\n\t\n\t\n\t\tGetting Started\n\t\n\nForâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/sangraha.","first_N":5,"first_N_keywords":["text-generation","Assamese","Bengali","Gujarati","English"],"keywords_longer_than_N":true},
	{"name":"indic-align","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/indic-align","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tIndicAlign\n\t\n\nA diverse collection of Instruction and Toxic alignment datasets for 14 Indic Languages. The collection comprises of:\n\nIndicAlign - Instruct\nIndic-ShareLlama\nDolly-T\nOpenAssistant-T\nWikiHow\nIndoWordNet\nAnudesh\nWiki-Conv\nWiki-Chat\n\n\nIndicAlign - Toxic\nHHRLHF-T\nToxic-Matrix\n\n\n\nWe use IndicTrans2 (Gala et al., 2023) for the translation of the datasets. \nWe recommend the readers to check out our paper on Arxiv for detailed information on the curation process of theseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/indic-align.","first_N":5,"first_N_keywords":["text-generation","Assamese","Bengali","Gujarati","English"],"keywords_longer_than_N":true},
	{"name":"Nadi_Indic466k_Instruct","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct","creator_name":"Convai Innovations","creator_url":"https://huggingface.co/convaiinnovations","description":"\n\t\n\t\t\n\t\tNadi_Indic466K_Instruct Dataset\n\t\n\nThe Nadi_Indic466K_Instruct dataset is the world's first coding dataset with 18 Indian language support, 466k rows and 142 Million total tokens. This dataset can be used by developers to build Indian coding language models (LLMs) for various programming languages.\nQ-LoRA based SFT/PPO/DPO fine-tuning can be done on the dataset in LLAMA-2 or Mistral or any opens-soure LLM for text generation.\nThe dataset was carefully curated such that the coding partâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct.","first_N":5,"first_N_keywords":["text-generation","Hindi","Panjabi","Bengali","Tamil"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"indic_sts","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/indic_sts","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"\n\t\n\t\t\n\t\tDataset Card for Indic STS\n\t\n\nThis dataset is STS benchmark between English and 12 high-resource Indic languages. This was released as a part of Samanantar paper. Please refer to the paper for more details.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAvailable languages are: en-as, en-bn, en-gu, en-hi, en-kn, en-ml, en-mr, en-or, en-pa, en-ta, en-te, en-ur\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataset Fields\n\t\n\n\nlang_code: 2-digit ISO language code\nsource: The source from which the candidate sentence isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jaygala24/indic_sts.","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"indic-swim-ir-cross-lingual","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/indic-swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\n\t\n\t\t\n\t\tDataset Card for Indic SWIM-IR (Cross-lingual)\n\t\n\n\n\n\nThis is the cross-lingual Indic subset of the SWIM-IR dataset, where the query generated is in the Indo-European language and the passage is in English.\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\n\n\t\n\t\n\t\n\t\tWhat is SWIM-IR?\n\t\n\nSWIM-IR dataset is aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/indic-swim-ir-cross-lingual.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","machine-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"webui-dom-snapshots","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\n\t\n\t\t\n\t\tDataset Card for WebUI DOM snapshots\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Gary Benson\nLanguages: Mostly English (87%);\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\nLicense: CC0 1.0 Universal\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots.","first_N":5,"first_N_keywords":["image-feature-extraction","reinforcement-learning","text-classification","multilingual","biglab/webui-7k"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"Alpaca_Instruct_Malayalam","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VishnuPJ/Alpaca_Instruct_Malayalam","creator_name":"Vishnu Prasad J","creator_url":"https://huggingface.co/VishnuPJ","description":"VishnuPJ/Alpaca_Instruct_Malayalam dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Malayalam","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"indic_sts","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/indic_sts","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n\t\n\t\t\n\t\tDataset Card for Indic STS\n\t\n\nThis dataset is STS benchmark between English and 12 high-resource Indic languages. This was released as a part of Samanantar paper. Please refer to the paper for more details.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAvailable languages are: en-as, en-bn, en-gu, en-hi, en-kn, en-ml, en-mr, en-or, en-pa, en-ta, en-te, en-ur\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataset Fields\n\t\n\n\nlang_code: 2-digit ISO language code\nsource: The source from which the candidate sentence isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/indic_sts.","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"IndicSentiment","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/IndicSentiment","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  IndicSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA new, multilingual, and n-way parallel dataset for sentiment analysis in 13 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReferencehttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicSentimentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicSentiment.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SIB200ClusteringS2S\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nSIB-200 is the largest publicly available topic classification\n        dataset based on Flores-200 covering 205 languages and dialects annotated. The dataset is\n        annotated in English for the topics,  science/technology, travel, politics, sports,\n        health, entertainment, and geography. The labels are then transferred to the other languages\n        in Flores-200 which are human-translated.\n\t\n\t\t\n\n\n\n\n\t\t\nTaskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","expert-generated","translated","Achinese"],"keywords_longer_than_N":true},
	{"name":"flores_eng_mal","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Govardhan-06/flores_eng_mal","creator_name":"Govardhan A R","creator_url":"https://huggingface.co/Govardhan-06","description":"\n\t\n\t\t\n\t\tDataset Card for flores_eng_mal\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a custom subset of the FLORES-101 dataset tailored for English to Malayalam translation tasks. It contains parallel sentences in both English and Malayalam.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThe primary task supported by this dataset is:\n\nMachine Translation: Translating text from English to Malayalam.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset includes parallel corpora for the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Govardhan-06/flores_eng_mal.","first_N":5,"first_N_keywords":["translation","English","Malayalam","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ml-sentences","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kavyamanohar/ml-sentences","creator_name":"Kavya Manohar","creator_url":"https://huggingface.co/kavyamanohar","description":"kavyamanohar/ml-sentences dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Malayalam","cc-by-sa-4.0","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"Mal_ASR_Predict_Ref_Samples","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asr-malayalam/Mal_ASR_Predict_Ref_Samples","creator_name":"Malayalam ASR","creator_url":"https://huggingface.co/asr-malayalam","description":"\n\t\n\t\t\n\t\tMalayalam ASR Reference Prediction dataset\n\t\n\nThis repository contains evaluation results from the Malayalam ASR model \"vrclc/Whisper_small_malayalam\" using the \"google/fleurs\" dataset.\n\nASR Model Name: vrclc/Whisper_small_malayalam\nDataset: google/fleurs\n\n\nCurated by: VRCLC\nvrclc/Whisper_small_malayalam was trained with 50 hours of Malayalam speech data.\nThe test set of google/fleurs dataset which consists of Malayalam speech data was used to evaluate the model\nThe evaluation of 500â€¦ See the full description on the dataset page: https://huggingface.co/datasets/asr-malayalam/Mal_ASR_Predict_Ref_Samples.","first_N":5,"first_N_keywords":["sentence-similarity","Malayalam","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"ml_vqa","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bipin/ml_vqa","creator_name":"Bipin Krishnan P","creator_url":"https://huggingface.co/bipin","description":"This is the Malayalam translated version of the VQA-X dataset.\n","first_N":5,"first_N_keywords":["visual-question-answering","Malayalam","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"Benchmark-Testing","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shounakpaul95/Benchmark-Testing","creator_name":"Shounak Paul","creator_url":"https://huggingface.co/shounakpaul95","description":"shounakpaul95/Benchmark-Testing dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","summarization","translation","token-classification","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"aimeghamuse","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/siyadsiya/aimeghamuse","creator_name":"K","creator_url":"https://huggingface.co/siyadsiya","description":"siyadsiya/aimeghamuse dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["image-classification","text-to-image","Malayalam","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"aimeghamuse","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/siyadsiya/aimeghamuse","creator_name":"K","creator_url":"https://huggingface.co/siyadsiya","description":"siyadsiya/aimeghamuse dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["image-classification","text-to-image","Malayalam","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"INDICSTR12_REAL_IMAGES","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ananya12k/INDICSTR12_REAL_IMAGES","creator_name":"Ananya Kulkarni","creator_url":"https://huggingface.co/ananya12k","description":"ananya12k/INDICSTR12_REAL_IMAGES dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Marathi","Bengali","Kannada","Oriya","Panjabi"],"keywords_longer_than_N":true},
	{"name":"quran_multilingual_parallel","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/quran_multilingual_parallel","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tðŸ“˜ Qurâ€™an Multilingual Parallel Dataset (quran_multilingual_parallel)\n\t\n\nThis dataset presents a clean, structurally-aligned multilingual parallel corpus of the Qurâ€™anic text. It is intended for linguistic, computational, and cross-lingual AI applications â€” not only for religious interpretation.\nIt contains over 6,200 verse-level alignments in 54 human languages, formatted in a machine-friendly .csv structure with language-specific translation fields.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ§  Dataset Highlightsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/freococo/quran_multilingual_parallel.","first_N":5,"first_N_keywords":["translation","Arabic","Albanian","Amharic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2Jyq/common_voice_21_0","creator_name":"2Jyq","creator_url":"https://huggingface.co/2Jyq","description":"Due to storage limits some files had to be split into multiple parts. They can be merged like this: cat file.* > file.\n","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","multilingual","extended|common_voice","Abkhaz"],"keywords_longer_than_N":true},
	{"name":"IndicQuest","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/l3cube-pune/IndicQuest","creator_name":"L3Cube Labs","creator_url":"https://huggingface.co/l3cube-pune","description":"\n\t\n\t\t\n\t\tL3Cube-IndicQuest: A Benchmark Question Answering Dataset for Evaluating Knowledge of LLMs in Indic Context (LLM Factual Accuracy Benchmark)\n\t\n\nL3Cube-IndicQuest is a dataset comprising 4,000 question-answer pairs across 20 languages, including English, Assamese, Bengali, Dogri, Gujarati, Hindi, Kannada, Konkani, Maithili, Malayalam, Marathi, Meitei (Manipuri), Nepali, Odia, Punjabi, Sanskrit, Sindhi, Tamil, Telugu, and Urdu. This dataset is designed to assess the knowledgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/l3cube-pune/IndicQuest.","first_N":5,"first_N_keywords":["question-answering","English","Assamese","Bengali","Gujarati"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"Ø§Ù…Ø§Ù… Ø¬Ù…Ø¹Ù‡ Ø§ØµÙÙ‡Ø§Ù† Ú¯ÙØª: Ù…ÛŒØ²Ø§Ù† Ù†ÛŒØ§Ø² Ø¢Ø¨ Ø´Ø±Ø¨ Ø§ØµÙÙ‡Ø§Ù† Û±Û±.Ûµ Ù…ØªØ± Ù…Ú©Ø¹Ø¨ Ø§Ø³Øª Ú©Ù‡ ØªÙ…Ø§Ù… Ø§Ø³ØªØ§Ù† Ø§ØµÙÙ‡Ø§Ù† Ø±Ø§ Ù¾ÙˆØ´Ø´ Ù…ÛŒØ¯Ù‡Ø¯ Ùˆ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ù†Ù‚Ù„Ø§Ø¨ ÛŒÚ©ÛŒ Ø§Ø² Ù¾ÛŒØ´Ø±ÙØªÙ‡Ø§ Ø¯Ø± Ø­ÙˆØ²Ù‡ Ø¢Ø¨ Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"malayalam","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tWMT24++\n\t\n\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\nthe publication\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\nIf you are interested in the images of the source URLs for each document, please see here.\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach language pair is stored in its own jsonl file.\nEach row isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"IndicMSMARCO","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/IndicMSMARCO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\n\t\n\t\t\n\t\tðŸ” IndicMSMARCO: Multilingual Information Retrieval Benchmark\n\t\n\nA comprehensive multilingual variant of MS MARCO specifically tailored for Indian languages, featuring carefully selected queries and corresponding passages with high-quality translations.\n\n\t\n\t\t\n\t\tðŸš€ Quick Start - Load Individual Languages\n\t\n\nfrom datasets import load_dataset\n\n# Load ONLY Hindi data (fast and efficient!)\nhindi_data = load_dataset(\"ai4bharat/IndicMSMARCO\", \"hi\")\nprint(f\"Hindi queries:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/IndicMSMARCO.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multilingual","ms_marco","Assamese"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"cnn_mal","keyword":"malayalam","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/atsphd2023/cnn_mal","creator_name":"Athira T S","creator_url":"https://huggingface.co/atsphd2023","description":"atsphd2023/cnn_mal dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["summarization","Malayalam","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Language_Identification_v1","keyword":"malayalam","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Process-Venue/Language_Identification_v1","creator_name":"ProcessVenue","creator_url":"https://huggingface.co/Process-Venue","description":"\n\t\n\t\t\n\t\tDataset Card for Language Identification Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA comprehensive dataset for Indian language identification and text classification. The dataset contains text samples across 10 major Indian languages, making it suitable for developing language identification systems and multilingual NLP applications.\n\n\t\n\t\t\n\t\tLanguages and Distribution\n\t\n\nLanguage Distribution:\nUrdu         1000\nHindi        1000\nOdia         1000\nTamil        1000\nKannada      1000\nBengaliâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Process-Venue/Language_Identification_v1.","first_N":5,"first_N_keywords":["text-classification","text2text-generation","text-generation","Hindi","Urdu"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"panlex-definitions","keyword":"malayalam","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-definitions","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-definitions\n\t\n\nThis is a dataset of word definitions in several hudnred languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20250201 database dump) and rearranged on the per-language basis (by the language of the definition).\nEach language subset consists of definitions (short phrases).\nEach definition is associated with some meanings (if there isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-definitions.","first_N":5,"first_N_keywords":["translation","Abkhazian","Hijazi Arabic","Afrikaans","Ainu (Japan)"],"keywords_longer_than_N":true},
	{"name":"TinyDS-20k","keyword":"malayalam","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","description":"\n\t\n\t\t\n\t\tTinyDS\n\t\n\nTinyDS (short for Tiny DeepSeek) is a dataset generated synthetically using SyntheticAlpaca and Qwen3-8B.  \n  \n\n\nThis dataset is a simple Alpaca-format dataset using the viral TTC concept (structured reasoning, mainly).The LLM was prompted to generate questions and answers in 32 different languages, and the most spoken languages were picked. Since the Qwen org stated that this model supports over 100 languages, this is something reasonable to do without compromising onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k.","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","text2text-generation","English"],"keywords_longer_than_N":true}
]
;
