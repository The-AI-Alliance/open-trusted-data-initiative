const data_for_language_asia_japanese = 
[
	{"name":"MAPS","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fujitsu-FRE/MAPS","creator_name":"Fujitsu Research of Europe","creator_url":"https://huggingface.co/Fujitsu-FRE","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Benchmark for Global Agent Performance and Security\n\t\n\nThis is the first Multilingual Agentic AI Benchmark for evaluating agentic AI systems across different languages and diverse tasks. Benchmark enables systematic analysis of how agents perform under multilingual conditions. To balance performance and safety evaluation, our benchmark comprises 805 tasks: 405 from performance-oriented datasets (GAIA, SWE-bench, MATH) and 400 from the Agent Security… See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu-FRE/MAPS.","first_N":5,"first_N_keywords":["text-generation","question-answering","Arabic","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"tokenizer-robustness-mmlu","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-mmlu","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","description":"\n\t\n\t\t\n\t\tTokenizer Robustness MMLU Dataset\n\t\n\nThis dataset contains MMLU-formatted questions and answers designed to test tokenizer robustness across different text formats and languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of the same questions presented in 6 different formats, with both test (20 questions) and development (5 questions) sets:\n\noriginal - Standard formatted questions\nminor_spelling_errors - Questions with minor misspellings\nspoken_language - Questions in casual… See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-mmlu.","first_N":5,"first_N_keywords":["English","Russian","Chinese","Japanese","German"],"keywords_longer_than_N":true},
	{"name":"MangaVQA-train","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hal-utokyo/MangaVQA-train","creator_name":"Hal Lab UTokyo","creator_url":"https://huggingface.co/hal-utokyo","description":"\n\t\n\t\t\n\t\tMangaVQA Training Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset details\n\t\n\nThis dataset is a synthetic VQA dataset for Manga. Using images from Manga109, we generated VQA samples by providing both images and its text annotations to GPT-4o (gpt-4o-2024-11-20).\nThe dataset contains a total of 41,895 synthetic VQA samples from 8,379 images. \n\n\t\n\t\t\n\t\tLicense\n\t\n\nCreative Commons Attribution 4.0 License; and it should abide by the OpenAI terms of use\n","first_N":5,"first_N_keywords":["visual-question-answering","Japanese","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MangaVQA","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hal-utokyo/MangaVQA","creator_name":"Hal Lab UTokyo","creator_url":"https://huggingface.co/hal-utokyo","description":"\n\t\n\t\t\n\t\tMangaVQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the MangaVQA benchmark, designed to evaluate performance under realistic conditions for manga understanding.\nThis dataset includes 526 manually created question-answer pairs based on images from Manga109.\n","first_N":5,"first_N_keywords":["visual-question-answering","Japanese","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"MangaOCR","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hal-utokyo/MangaOCR","creator_name":"Hal Lab UTokyo","creator_url":"https://huggingface.co/hal-utokyo","description":"\n\t\n\t\t\n\t\tMangaOCR Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the MangaOCR dataset. We constructed this dataset by consolidating annotations from the Manga109 dataset and the manga onomatopoeia dataset.\nIt contains approximately 209K narrative text instances, spanning a wide variety of visual styles and layouts.\n","first_N":5,"first_N_keywords":["Japanese","cc-by-4.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"MAPS_Verified","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fujitsu-FRE/MAPS_Verified","creator_name":"Fujitsu Research of Europe","creator_url":"https://huggingface.co/Fujitsu-FRE","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Benchmark for Global Agent Performance and Security\n\t\n\nThis is the first Multilingual Agentic AI Benchmark for evaluating agentic AI systems across different languages and diverse tasks. Benchmark enables systematic analysis of how agents perform under multilingual conditions. This dataset contains 550 instances for GAIA, 660 instances for ASB, 737 instances for Maths, and 1100 instances for SWE. Each task was translated into 10 target languages resulting… See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu-FRE/MAPS_Verified.","first_N":5,"first_N_keywords":["text-generation","question-answering","Arabic","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"Japanese-Pythonic-FunctionCall","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SousiOmine/Japanese-Pythonic-FunctionCall","creator_name":"SousiOmine","creator_url":"https://huggingface.co/SousiOmine","description":"\n\t\n\t\t\n\t\t概要\n\t\n\nチャットLLMにpython関数呼び出し機能を付与するための低品質なデータセットです。\nKendamarron/jimba-instruction-allデータセットのうち、dataset_id=Kendamarron/system-instruction-calm3-chat-formatのもの先頭1002件を用いています。\n関数定義、関数呼び出しをQwen2.5-32b-instructで、回答をPhi-4で生成しました。\n\n\t\n\t\t\n\t\t注意点\n\t\n\n\ntoolsが空になっている項目があります。\ntoolsが中国語になっている項目があります。\n同じ関数を同じ引数で何度も呼び出している箇所が散見されます。\n回答部分の品質が低い項目があると思います。\n\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"acl-6060","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/acl-6060","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tACL 60/60\n\t\n\n\n\t\n\t\t\n\t\tDataset details\n\t\n\nACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@inproceedings{salesky-etal-2023-evaluating,\n    title = \"Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology\",\n    author = \"Salesky, Elizabeth  and\n      Darwish, Kareem  and\n      Al-Badrashiny, Mohamed  and\n      Diab, Mona  and\n      Niehues, Jan\"… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/acl-6060.","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","English","Arabic","German"],"keywords_longer_than_N":true},
	{"name":"reasoning-conversations","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/syntaxsynth/reasoning-conversations","creator_name":"SyntaxSynth","creator_url":"https://huggingface.co/syntaxsynth","description":"\n\t\n\t\t\n\t\tMultilingual Reasoning Dataset\n\t\n\n\nInclude languages from German, Korean, Spanish, Japanese, French, Simplified Chinese, Traditional Chinese\n\nReasoning traces from Deepseek-v3-R1, Deepseek-v3-R1-Zero\n\n\nCredits sponsored by Currents API\n","first_N":5,"first_N_keywords":["text2text-generation","English","Spanish","Korean","German"],"keywords_longer_than_N":true},
	{"name":"metamath_ja_950_reka3flash","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kurogane/metamath_ja_950_reka3flash","creator_name":"kurogane himaki","creator_url":"https://huggingface.co/kurogane","description":"\n\t\n\t\t\n\t\tmetamath_ja_950_reka3flash\n\t\n\nmeta-math/MetaMathQAの最初の1000件をRekaAI/reka-flash-3で翻訳した後、フォーマットが維持されなかったものを除去しました。\nデータセットは1000件ありますが、実際は950件程度です。\nまた、フォーマットのみでクリーニングしたので、出力自体がおかしいものは除去できていません。このあたりは各自でクリーニングし直してください。\n\n\t\n\t\t\n\t\t例\n\t\n\ninput\n\\nグレイシーとジョーは複素平面上で数を選んでいます。ジョーは点 $1+2i$ を選び、グレイシーは $-1+i$ を選びました。二人の点間の距離はどれくらいですか？\\n\\n\n\noutput\n\\n複素平面上の点 $(x_1,y_1)$ と $(x_2,y_2)$ の距離は、式 $\\\\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}$ で求められます。  \\nこの場合、ジョーの点は$(1,2)$、グレイシーの点は$(-1,1)$です。  \\nしたがって、彼らの点間の距離は… See the full description on the dataset page: https://huggingface.co/datasets/kurogane/metamath_ja_950_reka3flash.","first_N":5,"first_N_keywords":["Japanese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"JCQ","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nlp-waseda/JCQ","creator_name":"Kawahara Lab at Waseda University","creator_url":"https://huggingface.co/nlp-waseda","description":"\n\t\n\t\t\n\t\tJapanese Creativity Questions (JCQ)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nJCQは創造性を評価するための7タスク、各100問からなる日本語のデータセットです。このデータセットはNLP2025の研究論文で発表されたものです。Torrance Test of Creative Thinking (TTCT)、Zhaoらの研究 (2024)を参考にして作成しました。\n\n\t\n\t\t\n\t\tTask Definition and Examples\n\t\n\nJCQは7つの異なるタスクで構成されています。以下の表に各タスクの定義と代表的な問題例を示します。\n\n\t\n\t\t\nタスク\n定義\n問題例\n\n\n\t\t\n非通常使用 (unusual uses)\n一般的な物体の珍しい使い方や多様な使い方を考えるタスク。\n電球の通常でない使い方をできるだけたくさん挙げてください。\n\n\n結果 (consequences)\n普通ではない、または仮説的な状況における結果や影響を予測するタスク。\nもしも世界中で 24… See the full description on the dataset page: https://huggingface.co/datasets/nlp-waseda/JCQ.","first_N":5,"first_N_keywords":["question-answering","text-generation","Japanese","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"JCQ","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nlp-waseda/JCQ","creator_name":"Kawahara Lab at Waseda University","creator_url":"https://huggingface.co/nlp-waseda","description":"\n\t\n\t\t\n\t\tJapanese Creativity Questions (JCQ)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nJCQは創造性を評価するための7タスク、各100問からなる日本語のデータセットです。このデータセットはNLP2025の研究論文で発表されたものです。Torrance Test of Creative Thinking (TTCT)、Zhaoらの研究 (2024)を参考にして作成しました。\n\n\t\n\t\t\n\t\tTask Definition and Examples\n\t\n\nJCQは7つの異なるタスクで構成されています。以下の表に各タスクの定義と代表的な問題例を示します。\n\n\t\n\t\t\nタスク\n定義\n問題例\n\n\n\t\t\n非通常使用 (unusual uses)\n一般的な物体の珍しい使い方や多様な使い方を考えるタスク。\n電球の通常でない使い方をできるだけたくさん挙げてください。\n\n\n結果 (consequences)\n普通ではない、または仮説的な状況における結果や影響を予測するタスク。\nもしも世界中で 24… See the full description on the dataset page: https://huggingface.co/datasets/nlp-waseda/JCQ.","first_N":5,"first_N_keywords":["question-answering","text-generation","Japanese","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"magpie-bakeneko-32b-instruction-113k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kendamarron/magpie-bakeneko-32b-instruction-113k","creator_name":"Kendamarron","creator_url":"https://huggingface.co/Kendamarron","description":"\n\t\n\t\t\n\t\tmagpie-bakeneko-32b-instruct-113k\n\t\n\nrinna/qwen2.5-bakeneko-32b-instruct-awqを用いたMagpieで生成した合成Instructionデータセットです。\nなお、計算リソースの問題からoutputの品質評価は行っていません。\nご利用の際はご注意ください。\n\n\t\n\t\t\n\t\t作成手順\n\t\n\n\nrinna/qwen2.5-bakeneko-32b-instruct-awqを用いたMagpieで\"base_instruction\"を生成（magpie_systemの値をシステムプロンプトとして使用）\nrinna/qwen2.5-bakeneko-32b-instruct-awqを用いて\"base_instruction\"を難化することで\"instruction\"を生成\nrinna/qwen2.5-bakeneko-32b-instruct-awqを用いて\"instruction\"の言語、タスクの種類、難易度、品質を評価… See the full description on the dataset page: https://huggingface.co/datasets/Kendamarron/magpie-bakeneko-32b-instruction-113k.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"magpie-easy-math-instruction-88k-qwen2.5-bakeneko-32b-instruct","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kendamarron/magpie-easy-math-instruction-88k-qwen2.5-bakeneko-32b-instruct","creator_name":"Kendamarron","creator_url":"https://huggingface.co/Kendamarron","description":"\n\t\n\t\t\n\t\tmagpie-easy-math-instruction-88k-qwen2.5-bakeneko-32b-instruct\n\t\n\nrinna/qwen2.5-bakeneko-32b-instructを用いたMagpieで生成した合成Instructionデータセットです。\n合成したinstructionに対して、以下の方法で2つで回答を生成し、LLM評価で回答が一致していると判定されたレコードのみを残しています。\n\n「あなたは論理的で数学が得意なアシスタントです。」をsystem promptとして得られた応答\n「あなたは論理的で数学が得意で優秀なプログラマーです。与えられた問題をPythonを用いて回答します。最後に問題の最終的な答えをprint文で出力します。」をsystem promptとして得られたコードを実行した結果\n\n\n\t\n\t\t\n\t\n\t\n\t\t作成手順\n\t\n\n\nrinna/qwen2.5-bakeneko-32b-instructを用いたMagpieで\"instruction\"を生成（magpie_systemの値をシステムプロンプトとして使用）… See the full description on the dataset page: https://huggingface.co/datasets/Kendamarron/magpie-easy-math-instruction-88k-qwen2.5-bakeneko-32b-instruct.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"MiscSpeech-ja","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rakuto/MiscSpeech-ja","creator_name":"rakuto","creator_url":"https://huggingface.co/Rakuto","description":"\n\t\n\t\t\n\t\tMiscSpeech-ja\n\t\n\nThis dataset comprises audio and corresponding transcripts collected from a diverse range of YouTube videos and Podcasts. \n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"magpie-python-coding-instruction-62k-qwen2.5-bakeneko-32b-instruct","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kendamarron/magpie-python-coding-instruction-62k-qwen2.5-bakeneko-32b-instruct","creator_name":"Kendamarron","creator_url":"https://huggingface.co/Kendamarron","description":"\n\t\n\t\t\n\t\tmagpie-python-coding-instruction-62k-qwen2.5-bakeneko-32b-instruct\n\t\n\nrinna/qwen2.5-bakeneko-32b-instructを用いたMagpieで生成した合成Instructionデータセットです。\nなお、計算リソースの問題からoutputの品質評価は行っていません。\nご利用の際はご注意ください。\n\n\t\n\t\t\n\t\t作成手順\n\t\n\n\nrinna/qwen2.5-bakeneko-32b-instruct-awqを用いたMagpieで\"instruction\"を生成（magpie_systemの値をシステムプロンプトとして使用）\nrinna/qwen2.5-bakeneko-32b-instruct-awqを用いて\"instruction\"の言語、タスクの種類、難易度、品質を評価\nlanguageがja以外、もしくは品質がpoor/very poorのレコードを削除\nrinna/qwen2.5-bakeneko-32b-instruct-awqを用いて応答を\"output\"として生成\n\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"coffeebean","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rpravee/coffeebean","creator_name":"praveena","creator_url":"https://huggingface.co/rpravee","description":"rpravee/coffeebean dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","Japanese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"commoncatalog-cc-by-ja-300k","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aki-0421/commoncatalog-cc-by-ja-300k","creator_name":"Aki","creator_url":"https://huggingface.co/aki-0421","description":"\n\t\n\t\t\n\t\taki-0421/commoncatalog-cc-by-ja-300k\n\t\n\nこのレポジトリはalfredplpl/commoncatalog-cc-by-jaで生成されたキャプションに512px以内に加工した画像を追加したものです。\n最初の30万件分のデータとなっております。\nライセンス、その他情報についてはalfredplpl/commoncatalog-cc-by-jaをご確認ください。\n\nalfredplpl/commoncatalog-cc-by-ja\n\n","first_N":5,"first_N_keywords":["Japanese","cc-by-4.0","100K - 1M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"DailyTalkContiguous-ja","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rakuto/DailyTalkContiguous-ja","creator_name":"rakuto","creator_url":"https://huggingface.co/Rakuto","description":"\n\t\n\t\t\n\t\tDailyTalkContiguous-ja: Spoken Dialogue Dataset in Japanese\n\t\n\nDailyTalkContiguous-ja is a synthetic multi-turn Japanese conversational speech dataset in which DailyTalk [Keon Lee etal., 2022]\ntranslated by Gemma-3-27B and speech data is synthesized by TTS engine Zyphra/Zonos-v0.1-transformer.\nFor each speaker in covnersation, different voice is randomly asssigned from voice dataset with five voices in total.\nAs like with kyutai/DailyTalkContiguous, rather than having separate files… See the full description on the dataset page: https://huggingface.co/datasets/Rakuto/DailyTalkContiguous-ja.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Japanese","cc-by-sa-4.0","arxiv:2207.01063","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"ja_en_massive_1000_sharegpt_filtered_fixed_short","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mpasila/ja_en_massive_1000_sharegpt_filtered_fixed_short","creator_name":"minipasila","creator_url":"https://huggingface.co/mpasila","description":"This only contains around 191 examples. This is just quick test will release the full around 1k examples soon.\nI've done a quick cleaning of the data manually using Notepad++. There may still be broken stuff or other problems.\nUses ShareGPT (the only format we will ever need).\nUses NilanE/ParallelFiction-Ja_En-100k for the data.\nToken Count Statistics:\n\nTotal conversations: 191\nTotal tokens: 918486\nAverage tokens per conversation: 4808.83\nMedian tokens per conversation: 4187.0\nMaximum tokens… See the full description on the dataset page: https://huggingface.co/datasets/mpasila/ja_en_massive_1000_sharegpt_filtered_fixed_short.","first_N":5,"first_N_keywords":["translation","English","Japanese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"YakugakuQA","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EQUES/YakugakuQA","creator_name":"EQUES Inc.","creator_url":"https://huggingface.co/EQUES","description":"\n\t\n\t\t\n\t\tYakugakuQA\n\t\n\n\n\nYakugakuQA is a question answering dataset, consisting of 13 years (2012-2024) of past questions and answers from the Japanese National License Examination for Pharmacists. It contains over 4K pairs of questions, answers, and commentaries.\n2025-5-29: Leaderboard added.  \n2025-2-17: Image data added.  \n2024-12-10: Dataset release.\n\n\t\n\t\t\n\t\tLeaderboard\n\t\n\n3-shot Accuracy (%)\n\n\t\n\t\t\n\nYakugakuQA\nIgakuQA\n\n\n\t\t\no1-preview\n87.9\n\n\n\nGPT-4o\n83.6\n86.6… See the full description on the dataset page: https://huggingface.co/datasets/EQUES/YakugakuQA.","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-sa-4.0","arxiv:2505.16661","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"Japanese-Wikipedia-202506","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OmniAICreator/Japanese-Wikipedia-202506","creator_name":"OmniAICreator","creator_url":"https://huggingface.co/OmniAICreator","description":"\n\t\n\t\t\n\t\tJapanese-Wikipedia-202506\n\t\n\nThis dataset contains data from the Japanese Wikipedia as of June 1, 2025.\n","first_N":5,"first_N_keywords":["text-classification","text-generation","Japanese","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"wikipedia-citation-index","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia-citation-index","creator_name":"Włodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Dataset with citation indexes as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions. Research: ArXiv\n","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"aidealab-videojp-eval","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aidealab/aidealab-videojp-eval","creator_name":"AIdeaLab","creator_url":"https://huggingface.co/aidealab","description":"\n\t\n\t\t\n\t\tAIdeaLab VideoJP 評価再現用データ\n\t\n\n\n\t\n\t\t\n\t\tはじめに\n\t\n\nこのリポジトリはAIdeaLab VideoJPのFVDを測定するためのデータを\n集めました。再現手順を次のとおりに示します。\n\n\t\n\t\t\n\t\t評価方法\n\t\n\nまず、評価用ライブラリをダウンロードします。\ngit clone https://github.com/JunyaoHu/common_metrics_on_video_quality\n\nダウンロードできたら、ライブラリのインストール手順を踏んで、インストールします。\nインストールしたら、同じディレクトリに次のファイルをコピーしてください\n\nevaluate_videos.py\nvideos.tar\ngen_ja.tar\n\nコピーできたら、videos.tarとgen_ja.tarを展開します。\ntar xf videos.tar\ntar xf gen_ja.tar\n\n最後にevaluate_videos.pyを実行すると、FVDが表示されるはずです。\n\n\t\n\t\t\n\t\n\t\n\t\tおまけ： 評価用映像の作り方… See the full description on the dataset page: https://huggingface.co/datasets/aidealab/aidealab-videojp-eval.","first_N":5,"first_N_keywords":["text-to-video","Japanese","apache-2.0","1K - 10K","webdataset"],"keywords_longer_than_N":true},
	{"name":"JSICK","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/JSICK","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  JSICK\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nJSICK is the Japanese NLI and STS dataset by manually translating the English dataset SICK (Marelli et al., 2014) into Japanese.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"JSICK\"])\nevaluator = mteb.MTEB(task)… See the full description on the dataset page: https://huggingface.co/datasets/mteb/JSICK.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","human-annotated","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"JaGovFaqsRetrieval","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/JaGovFaqsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  JaGovFaqsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nJaGovFaqs is a dataset consisting of FAQs manully extracted from the website of Japanese bureaus. The dataset consists of 22k FAQs, where the queries (questions) and corpus (answers) have been shuffled, and the goal is to match the answer with the question.\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can… See the full description on the dataset page: https://huggingface.co/datasets/mteb/JaGovFaqsRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"MewsC16JaClustering","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MewsC16JaClustering","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MewsC16JaClustering\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMewsC-16 (Multilingual Short Text Clustering Dataset for News in 16 languages) is constructed from Wikinews.\n        This dataset is the Japanese split of MewsC-16, containing topic sentences from Wikinews articles in 12 categories.\n        More detailed information is available in the Appendix E of the citation.\n\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB… See the full description on the dataset page: https://huggingface.co/datasets/mteb/MewsC16JaClustering.","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"NLPJournalAbsIntroRetrieval","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NLPJournalAbsIntroRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given abstract.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model… See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalAbsIntroRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"youtube-comment-sentiment","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AmaanP314/youtube-comment-sentiment","creator_name":"Amaan Poonawala","creator_url":"https://huggingface.co/AmaanP314","description":"\n\t\n\t\t\n\t\tYouTube Comments Sentiment Analysis Dataset (1M+ Labeled Comments)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset comprises over one million YouTube comments, each annotated with sentiment labels—Positive, Neutral, or Negative. The comments span a diverse range of topics including programming, news, sports, politics and more, and are enriched with comprehensive metadata to facilitate various NLP and sentiment analysis tasks.\n\n\t\n\t\t\n\t\tHow to use:\n\t\n\nimport pandas as pd\ndf =… See the full description on the dataset page: https://huggingface.co/datasets/AmaanP314/youtube-comment-sentiment.","first_N":5,"first_N_keywords":["text-classification","English","Hindi","Japanese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BanG_Dream_150k","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Takaharadesu/BanG_Dream_150k","creator_name":"Takahara Kiriba","creator_url":"https://huggingface.co/Takaharadesu","description":"\n\n\nBanG Dream Dialogue 150K\n\nA large-scale multilingual dialogue corpus featuring 150,000+ interactions across 40 characters from the BanG Dream!本数据集收录 BanG Dream! 系列 40 角色 的 150,000+ 条对话，适用于自然语言处理任务，深度还原角色性格与互动模式。\n\n\n\n\n\t\n\t\t\n\t\tDataset Statistics|统计\n\t\n\n· ako: 4854条\n· anon: 2251条\n· arisa: 6713条\n· aya: 5479条\n· chisato: 5074条\n· chuchu: 2432条\n· eve: 4639条\n· hagumi: 4144条\n· himari: 5266条\n· hina: 5102条\n· kanon: 4022条\n· kaoru: 4083条\n· kasumi: 7233条\n· kokoro: 4493条\n· layer: 2225条\n· lisa: 6057条\n· lock:… See the full description on the dataset page: https://huggingface.co/datasets/Takaharadesu/BanG_Dream_150k.","first_N":5,"first_N_keywords":["translation","Chinese","Japanese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"kanalizer-dataset","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VOICEVOX/kanalizer-dataset","creator_name":"VOICEVOX","creator_url":"https://huggingface.co/VOICEVOX","description":"\n\t\n\t\t\n\t\tkanalizer\n\t\n\n英単語から読みを推測するライブラリ、kanalizerのデータセット置き場。データセットの作成に用いたコードはGitHubのVOICEVOX/kanalizer、学習済みモデルはVOICEVOX/kanalizer-modelを参照してください。\n","first_N":5,"first_N_keywords":["Japanese","mit","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"gkmas-yolo.producer-challenge","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/skyfsj/gkmas-yolo.producer-challenge","creator_name":"fengshangji","creator_url":"https://huggingface.co/skyfsj","description":"skyfsj/gkmas-yolo.producer-challenge dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","Japanese","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"LightNovel5000","keyword":"japanese","license":"zlib License","license_url":"https://choosealicense.com/licenses/zlib/","language":"en","dataset_url":"https://huggingface.co/datasets/bh2821/LightNovel5000","creator_name":"Dekalb  J","creator_url":"https://huggingface.co/bh2821","description":"\n\t\n\t\t\n\t\tLight novels translated in Chinese - crawled from public websites that do not prohibit crawlers\n\t\n\n\n\t\n\t\t\n\t\t脚盆轻小说汉化 - 从未禁止爬虫的公共网站爬取\n\t\n\n\n\n\t\n\t\t\n\t\tVersion 1 (2025-05-03)\n\t\n\n\n\t\n\t\t\n\t\t版本 1 (2025-05-03)\n\t\n\n  Contains around 1500 light novels, including PDF with illustration and txt text files.\n\nIt may be a good source of data that can be used to train your stylish LLM.\n\nKindly note that the author has partially clean the text BUT DOES NOT GUARANTEE that it is fully cleaned up.\n\n包含约 1500… See the full description on the dataset page: https://huggingface.co/datasets/bh2821/LightNovel5000.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","translation","Chinese","zlib"],"keywords_longer_than_N":true},
	{"name":"japanese-photos-2-with-vids","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ThePioneer/japanese-photos-2-with-vids","creator_name":"The Pioneer","creator_url":"https://huggingface.co/ThePioneer","description":"\n\t\n\t\t\n\t\tJapan Diverse Images Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a comprehensive collection of high-quality images (and some videos) capturing the diverse aspects of Japan, including urban landscapes, natural scenery, historical sites, contemporary art, everyday life, and culinary experiences. It is designed to provide a rich and varied representation of Japan for AI training purposes.\nNote that the photos were taken by myself in the 2020s, mainly from 2024 to 2025, with some… See the full description on the dataset page: https://huggingface.co/datasets/ThePioneer/japanese-photos-2-with-vids.","first_N":5,"first_N_keywords":["English","Japanese","cc0-1.0","10K<n<100K","Image"],"keywords_longer_than_N":true},
	{"name":"jcrrag","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alt-dev/jcrrag","creator_name":"alt Inc.","creator_url":"https://huggingface.co/alt-dev","description":"\n\t\n\t\t\n\t\tJCrRAG : Japanese Contextual relevance RAG Benchmark\n\t\n\nA human-annotated benchmark for evaluating Japanese Retrieval-Augmented Generation (RAG) systems, featuring multi-level complexity and diverse categories.\nThis benchmark does not address context selection; instead, with the context fixed, it evaluates the ability to appropriately handle the information within that context.\nThe benchmark contains 20,000 data records. \nEach record has the following format : \n(Context, Question… See the full description on the dataset page: https://huggingface.co/datasets/alt-dev/jcrrag.","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-sa-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"code-switching-tokenizer-robustness","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","description":"\n\t\n\t\t\n\t\tCode-Switching Dataset for Tokenizer Robustness Analysis\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for tokenizer robustness testing in multilingual and code-switching contexts. It contains identical content expressed across 16 different language variants, including pure English and 15 English-X code-switching pairs, allowing researchers to isolate tokenization effects from semantic differences when evaluating language models.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\n\nTokenizer Comparison:… See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness.","first_N":5,"first_N_keywords":["text-generation","text-classification","multilingual","English","Russian"],"keywords_longer_than_N":true},
	{"name":"sib200_14classes","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200_14classes","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for SIB-200\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\nThe train/validation/test sets are available for all the 205 languages.\nThis is another version with 14 classes, more idea for few-shot evaluation, it has 5 examples for few-shot, and larger test set (1225)\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopic classification: categorize wikipedia sentences… See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200_14classes.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"new-imatrix-dataset-ja-en","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yayoimizuha/new-imatrix-dataset-ja-en","creator_name":"Tomokazu Katayama","creator_url":"https://huggingface.co/yayoimizuha","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n日英LLM向けのimatrix蒸留用データセットです。\n既存のデータセットとしてはTFMC/imatrix-dataset-for-japanese-llmがありますが、\nテキストの品質が低いように感じたので、\n青空文庫、日英Wikipedia,Project Gutenbergよりデータをシャッフルして作成しました。\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\nfujiki/wiki40b_ja\nglobis-university/aozorabunko-clean\nmanu/project_gutenberg\nblo05/cleaned_wiki_en_80-100\n\n\t\n\t\t\n\t\n\t\n\t\tUses\n\t\n\nllama-imatrix -m /path/to/model-file/original-f16.gguf -f imatrix_sample.txt\n\n","first_N":5,"first_N_keywords":["text-generation","English","Japanese","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"japanese-reasoning-dataset-sample","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/APTOinc/japanese-reasoning-dataset-sample","creator_name":"APTO,Inc.","creator_url":"https://huggingface.co/APTOinc","description":"reasoningモデルのファインチューニングのためのデータセットとなります。\n各データは、推論を必要とする質問と、その回答を含み、「思考過程」が <think>～</think> タグ内に記述されています。本データセットは弊社技術により開発した合成データから、問題がないか人によってチェックされた高品質なデータとなっています。\n\n\t\n\t\t\n\t\tデータ内容\n\t\n\nデータセットは以下のようなJSON形式で提供され、各レコードには推論を必要とする質問と回答のペアが含まれています：\n[\n  {\n    \"question\": \"推論問題の内容\",\n    \"answer\": \"問題に対する回答の内容\",\n    \"tag\": {\n      \"question\": \"質問ジャンルのタグ情報\",\n    }\n  },\n  ...\n]\n\n\nquestion 推論を必要とする質問文。問題状況の説明や条件など、推論に必要な情報が含まれています。\n\n2.answer: 質問に対する回答。<think>～</think>… See the full description on the dataset page: https://huggingface.co/datasets/APTOinc/japanese-reasoning-dataset-sample.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"multilingual-terminology","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jerry999/multilingual-terminology","creator_name":"Jiarui Liu","creator_url":"https://huggingface.co/Jerry999","description":"\n\t\n\t\t\n\t\t📚 GIST: Glossary of Multilingual AI Scientific Terminology\n\t\n\nPaper Title: Towards Global AI Inclusivity: A Large-Scale Multilingual Terminology Dataset (GIST)\nWebsite Demo Instructions: https://github.com/jiarui-liu/MultilingualAITerminology\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGIST is a large-scale, high-quality multilingual AI terminology dataset developed to support global inclusivity in AI research. It consists of around 5,000 English AI-specific terms, each translated into Arabic, Chinese… See the full description on the dataset page: https://huggingface.co/datasets/Jerry999/multilingual-terminology.","first_N":5,"first_N_keywords":["English","Arabic","Chinese","French","Japanese"],"keywords_longer_than_N":true},
	{"name":"Lemonade","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stanford-oval/Lemonade","creator_name":"Stanford Open Virtual Assistant Lab (OVAL)","creator_url":"https://huggingface.co/stanford-oval","description":"LEMONADE is a large, expert-annotated dataset for event extraction from news articles in 20 languages: English, Spanish, Arabic, French, Italian, Russian, German, Turkish, Burmese, Indonesian, Ukrainian, Korean, Portuguese, Dutch, Somali, Nepali, Chinese, Persian, Hebrew, and Japanese.\nSee https://github.com/stanford-oval/Lemonade for details.\n","first_N":5,"first_N_keywords":["text-classification","text2text-generation","English","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleAbsRetrieval","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NLPJournalTitleAbsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding abstract with the given title.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on… See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleAbsRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"NLPJournalTitleIntroRetrieval","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NLPJournalTitleIntroRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset was created from the Japanese NLP Journal LaTeX Corpus. The titles, abstracts and introductions of the academic papers were shuffled. The goal is to find the corresponding introduction with the given title.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Written\n\n\nReference\nhttps://github.com/sbintuitions/JMTEB\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model… See the full description on the dataset page: https://huggingface.co/datasets/mteb/NLPJournalTitleIntroRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"MIRACLRetrieval","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RSamoed/MIRACLRetrieval","creator_name":"RS","creator_url":"https://huggingface.co/RSamoed","description":"\n  MIRACLRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttp://miracl.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =… See the full description on the dataset page: https://huggingface.co/datasets/RSamoed/MIRACLRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","Arabic","Bengali"],"keywords_longer_than_N":true},
	{"name":"MIRACLRetrieval","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MIRACLRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MIRACLRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttp://miracl.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/MIRACLRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","RSamoed/MIRACLRetrieval","Arabic"],"keywords_longer_than_N":true},
	{"name":"embeding-ja-synthesis","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaeyong2/embeding-ja-synthesis","creator_name":"jeongjaeyong","creator_url":"https://huggingface.co/jaeyong2","description":"\n\t\n\t\t\n\t\tDevelopment Process\n\t\n\n\ncontext dataset from Cohere/miracl-ja-corpus-22-12\nWe used deepcogito/cogito-v1-preview-qwen-32B\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\n\nCohere/miracl-ja-corpus-22-12 : https://choosealicense.com/licenses/apache-2.0/\ndeepcogito/cogito-v1-preview-qwen-32B : https://choosealicense.com/licenses/apache-2.0/\n\n\n\t\n\t\t\n\t\tAcknowledgement\n\t\n\nThis research is supported by TPU Research Cloud program.\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"esci","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tasksource/esci","creator_name":"tasksource","creator_url":"https://huggingface.co/tasksource","description":"\n\t\n\t\t\n\t\tDataset Card for \"esci\"\n\t\n\nESCI product search dataset\nhttps://github.com/amazon-science/esci-data/\nPreprocessings: \n-joined the two relevant files\n-product_text aggregate all product text\n-mapped esci_label to full name \n@article{reddy2022shopping,\ntitle={Shopping Queries Dataset: A Large-Scale {ESCI} Benchmark for Improving Product Search},\nauthor={Chandan K. Reddy and Lluís Màrquez and Fran Valero and Nikhil Rao and Hugo Zaragoza and Sambaran Bandyopadhyay and Arnab Biswas and Anlu… See the full description on the dataset page: https://huggingface.co/datasets/tasksource/esci.","first_N":5,"first_N_keywords":["text-classification","text-retrieval","English","Japanese","Spanish"],"keywords_longer_than_N":true},
	{"name":"jaqket_v1_qa_wikija_context","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hotchpotch/jaqket_v1_qa_wikija_context","creator_name":"Yuichi Tateno","creator_url":"https://huggingface.co/hotchpotch","description":"\n\t\n\t\t\n\t\t⚠️ ! 注意 !\n\t\n\n公開したデータセットは、私の不注意で本来学習させる用途には相応しくない、JAQKET テスト用のデータセットも train に含んでしまっています。\nそのため、以下のように再度テスト用のデータを分離してからの利用をお勧めします。\nimport datasets\n\nds = datasets.load_dataset(\"hotchpotch/jaqket_v1_qa_wikija_context\")\ntrain_ds = ds[\"train\"]  # type: ignore\nvalid_ds = ds[\"validation\"]  # type: ignore\n\n# 大元の \"hotchpotch/jaqket_v1_qa_wikija_context\" の train / valid 分割方法がよくないので、再度分割する\n\ntrain_df = train_ds.to_pandas()\nvalid_df = valid_ds.to_pandas()\ndf = pd.concat([train_df, valid_df])… See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/jaqket_v1_qa_wikija_context.","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-sa-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ranobe_sample","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/metral/ranobe_sample","creator_name":"Tetuya Ono","creator_url":"https://huggingface.co/metral","description":"\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nThis is the text of my novel. It has approximately 240,000 words.\nThe genre is fantasy light novel.\n\n\t\n\t\t\n\t\tWhat is the licence?\n\t\n\nThe licence type is Apache 2.0.\n\n\t\n\t\t\n\t\tHow can I use it?\n\t\n\nI want you to use this novel as a sample of Japanese writing.\nAfter that, you are free to use it within the scope of the licence.\nYou can send me fan letters :)\n\n\t\n\t\t\n\t\tAre there any precautions I should be aware of?\n\t\n\nThis text is still available on Kakuyom. The unique format… See the full description on the dataset page: https://huggingface.co/datasets/metral/ranobe_sample.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","1K - 10K","text","Text"],"keywords_longer_than_N":true},
	{"name":"japanese-wikipedia-paragraphs","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oshizo/japanese-wikipedia-paragraphs","creator_name":"oshizo","creator_url":"https://huggingface.co/oshizo","description":"A slightly modified version of the parsing and chunking method for singletongue/wikipedia-utils.\nPre-processing was performed using oshizo/wikipedia-utils, which is a fork of the original repository, singletongue/wikipedia-utils.\nThe Wikipedia data was crawled between 2023/12/5 and 2023/12/8.\n","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","10M - 100M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"mqnli","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SachinPatel248/mqnli","creator_name":"Patel","creator_url":"https://huggingface.co/SachinPatel248","description":"SachinPatel248/mqnli dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","English","German","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"GSM8KInstruct_Parallel","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mathoctopus/GSM8KInstruct_Parallel","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","description":"Mathoctopus/GSM8KInstruct_Parallel dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","Chinese","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"MSVAMP","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mathoctopus/MSVAMP","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","description":"Mathoctopus/MSVAMP dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Bengali","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"oasst1_ja_ppl","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/if001/oasst1_ja_ppl","creator_name":"issei fujimoto","creator_url":"https://huggingface.co/if001","description":"** 以下のrepositoryのforkです。 ** \nhttps://huggingface.co/datasets/kunishou/oasst1-89k-ja\ninstructionとinput、outputにまとめ、kenllmでperplexityのスコアが付与してあります。\nperplexityの計算に用いたtokenizerはこちら\nhttps://huggingface.co/if001/sentencepiece_ja\n\ninstruction_ppl: instructionのみのperplexity\noutput_ppl: outputのみのperplexity\nfull_ppl: instructionとoutputを合わせ、instruction用の文章にしたperplexity\n\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"jhumaneval","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kogi-jwu/jhumaneval","creator_name":"Kuramitsu Lab, JWU","creator_url":"https://huggingface.co/kogi-jwu","description":"\n\t\n\t\t\n\t\tDataset Card for JHumanEval: Japanese Hand-Translated HumanEval\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a Japanese translated version of HumanEval, an evaluation harness for the HumanEval problem solving dataset described in the paper \"Evaluating Large Language Models Trained on Code\".\nLLM のコード生成能力の標準ベンチマーク HumanEval の日本語翻訳版です。機械翻訳(DeepL, GPT-4)の翻訳結果を全て人手によって再修正し、 訳文を日本人のプログラマが読んで理解し、コードが書ける内容かチェックしました。ただし、英語版 HumanEval の間違いは、修正せずに残して、 HumanEval 同様に不完全なドキュメントからの生成能力を見るようになっています。日本語LLM… See the full description on the dataset page: https://huggingface.co/datasets/kogi-jwu/jhumaneval.","first_N":5,"first_N_keywords":["text2text-generation","openai_humaneval","Japanese","English","mit"],"keywords_longer_than_N":true},
	{"name":"hh-rlhf-49k-ja-alpaca-format","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/hh-rlhf-49k-ja-alpaca-format","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\n\t\n\t\t\n\t\tDataset Card for \"hh-rlhf-49k-ja-alpaca-format\"\n\t\n\nこれはkunishou/hh-rlhf-49k-jaに以下の変更を加えたデータセットです。\n\nalpaca形式に変更\n翻訳が失敗したもの（つまりng_translation!=\"0.0\"のもの）の削除\nindexの頭に\"hh-rlhf.\"をつける\n\nThis is a dataset of kunishou/hh-rlhf-49k-en with the following changes\n\nChanged to alpaca format\nRemoved failed translations (i.e., those with ng_translation!=\"0.0\")\nAdd \"hh-rlhf.\" at the beginning of indexes\n\n","first_N":5,"first_N_keywords":["Japanese","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"llm-japanese-dataset-vanilla-aya-format","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tellarin-ai/llm-japanese-dataset-vanilla-aya-format","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\n\t\n\t\t\n\t\tDataset Card for llm-japanese-dataset-vanilla in the Aya format\n\t\n\nThis dataset is a format conversion from its original v1.0.0 format and released here under the same CC-BY-SA 4.0 license and conditions.\nIt contains Japanese instruction-like data intended for LLM construction/tuning.\nThe dataset only contains a 'train' split, with ~2.46M rows of data.\nThanks Jian Wu (@wujian123) for the help in converting and validating the dataset.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you utilize this dataset… See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/llm-japanese-dataset-vanilla-aya-format.","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"ja-stackoverflow","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/p1atdev/ja-stackoverflow","creator_name":"Plat","creator_url":"https://huggingface.co/p1atdev","description":"\n\t\n\t\t\n\t\tja-stackoverflow\n\t\n\n日本語版 Stack Overflow の スタック・オーバーフロー のデータダンプ をもとにデータを加工し、質問文と回答文のペアになるように調整した QA データセット。\n\n\t\n\t\t\n\t\tデータ構造\n\t\n\n投稿本文は html2text を使ってマークダウン化されています。その際、\n\nコードブロックは ``` で囲まれるように変更されています。\n画像 URL に base64 エンコードされた画像が含まれる場合、 [unk] に置き換えています。\n\n\n\t\n\t\t\n\t\tdefault サブセット\n\t\n\n\nid: 質問投稿の ID\nquestion: 質問投稿\nanswers: 質問に対する回答投稿のリスト\naccepted_answer_id: 質問者に選ばれた回答のID。null の可能性がある\npopular_answer_id: もっともスコアが高かった回答のID。null の可能性がある\n\n\n\t\n\t\t\n\t\tsimple サブセット\n\t\n\ndefault サブセットから、 question と answers… See the full description on the dataset page: https://huggingface.co/datasets/p1atdev/ja-stackoverflow.","first_N":5,"first_N_keywords":["text-generation","question-answering","Japanese","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"japanese-stackexchange","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/p1atdev/japanese-stackexchange","creator_name":"Plat","creator_url":"https://huggingface.co/p1atdev","description":"\n\t\n\t\t\n\t\tjapanese-stackexchange\n\t\n\n英語による日本語に関する質問ができる Japanese Stack Exchange のデータダンプ をもとにデータを加工し、質問文と回答文のペアになるように調整した QA データセット。\n日本語翻訳された StackExchange ではないです。\n\n\t\n\t\t\n\t\tデータ構造\n\t\n\n投稿本文は html2text を使ってマークダウン化されています。その際、\n\nコードブロックは ``` で囲まれるように変更されています。\n画像 URL に base64 エンコードされた画像が含まれる場合、 [unk] に置き換えています。\n\n\n\t\n\t\t\n\t\tdefault サブセット\n\t\n\n\nid: 質問投稿の ID\nquestion: 質問投稿\nanswers: 質問に対する回答投稿のリスト\naccepted_answer_id: 質問者に選ばれた回答のID。null の可能性がある\npopular_answer_id: もっともスコアが高かった回答のID。null の可能性がある\n\n\n\t\n\t\t\n\t\tsimple サブセット… See the full description on the dataset page: https://huggingface.co/datasets/p1atdev/japanese-stackexchange.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Japanese","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"novecomi-novel-metadata","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/p1atdev/novecomi-novel-metadata","creator_name":"Plat","creator_url":"https://huggingface.co/p1atdev","description":"\n\t\n\t\t\n\t\tnovecomi-novel-metadata\n\t\n\nhttps://dengekibunko.jp/novecomi/novel/ からスクレイピング。 (本文なし)\n","first_N":5,"first_N_keywords":["Japanese","cc0-1.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\n","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"japanese-image-classification-evaluation-dataset","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/recruit-jp/japanese-image-classification-evaluation-dataset","creator_name":"Recruit Co., Ltd.","creator_url":"https://huggingface.co/recruit-jp","description":"\n\t\n\t\t\n\t\trecruit-jp/japanese-image-classification-evaluation-dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\nDeveloped by: Recruit Co., Ltd.\nDataset type: Image Classification\nLanguage(s): Japanese\nLICENSE: CC-BY-4.0\n\nMore details are described in our tech blog post.\n\n日本語CLIP学習済みモデルとその評価用データセットの公開\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nThis dataset is comprised of four image classification tasks related to concepts and things unique to Japan. Specifically, is consists of the following tasks.\n\njafood101: Image… See the full description on the dataset page: https://huggingface.co/datasets/recruit-jp/japanese-image-classification-evaluation-dataset.","first_N":5,"first_N_keywords":["image-classification","Japanese","cc-by-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"ntx_llm_instructions","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\n\t\n\t\t\n\t\tDataset Card for NTX v1 in the Aya format\n\t\n\nThis dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license and conditions.\nIt contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you utilize this dataset version, feel free to cite/footnote this huggingface dataset repo, but please also cite the original dataset… See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions.","first_N":5,"first_N_keywords":["token-classification","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"ntx_llm_inst_japanese","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_japanese","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\n\t\n\t\t\n\t\tDataset Card for NTX v1 in the Aya format - Japanese subset\n\t\n\nThis dataset is a format conversion for the Japanese data from the original NTX into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nFor the original NTX dataset, the conversion to the Aya instructions format, or more details, please refer to the full dataset in instruction form (https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions) or to the paper… See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_japanese.","first_N":5,"first_N_keywords":["token-classification","Japanese","cc-by-sa-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Tokama_Club_QA","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MakiAi/Tokama_Club_QA","creator_name":"Sunwood.ai.labs","creator_url":"https://huggingface.co/MakiAi","description":"\n\t\n\t\t\n\t\n\t\n\t\t東方トカマクラブ データセット\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t概要\n\t\n\nこのデータセットは、東方Projectのトカマクラブに関する情報を収集したものです。主にキャラクターに関する質問と回答を含んでいます。\n\n\t\n\t\t\n\t\n\t\n\t\tデータセットの構造\n\t\n\nデータはCSVファイルに格納されており、以下のカラムで構成されています:\n\nQ: 質問のテキスト\nA: 回答のテキスト\n\n\n\t\n\t\t\n\t\n\t\n\t\t使用例\n\t\n\nこのデータセットは、チャットボットや質問応答システム、機械学習モデルのトレーニングに使用することができます。\n","first_N":5,"first_N_keywords":["question-answering","Japanese","mit","n<1K","🇺🇸 Region: US"],"keywords_longer_than_N":true},
	{"name":"ml-kge","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davanstrien/ml-kge","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","description":"\n\t\n\t\t\n\t\tMKGE: Multilingual Knowledge Graph Enhancement\n\t\n\nnote this dataset card was copied from this GitHub Repository\nTask Description |\nWikiKGE-10 |\nEvaluation |\nPaper |\nCitation |\nLicense\nRecent work in Natural Language Processing and Computer Vision has been leveraging textual information -- e.g., entity names and descriptions -- available in knowledge graphs to ground neural models to high-quality structured data.\nHowever, when it comes to non-English languages, both quantity and quality… See the full description on the dataset page: https://huggingface.co/datasets/davanstrien/ml-kge.","first_N":5,"first_N_keywords":["English","Arabic","German","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for SIB-200\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\nThe train/validation/test sets are available for all the 205 languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 205 languages available :\n\n\t\n\t\t\n\t\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"openassistant-guanaco-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masajek/openassistant-guanaco-ja","creator_name":"MasayaShimomatsu","creator_url":"https://huggingface.co/masajek","description":"This dataset is a subset of the Open Assistant dataset, which contains Japanese conversations only.You can find a base datset here: https://huggingface.co/datasets/timdettmers/openassistant-guanaco  \n \n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"sayoko-tts-corpus","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bandad/sayoko-tts-corpus","creator_name":"kai washizaki","creator_url":"https://huggingface.co/bandad","description":"\n\t\n\t\t\n\t\tサヨ子 音声コーパス\n\t\n\n\n\t\n\t\t\n\t\tダウンロード方法\n\t\n\nデータセットを圧縮したzipファイルを、gdriveに置いています。\nまた、以下のスクリプトで、huggingface hubからダウンロードも可能です。\n# pip install --upgrade huggingface_hub\nfrom huggingface_hub import snapshot_download\n\nsnapshot_download(repo_id=\"bandad/sayoko-tts-corpus\", repo_type=\"dataset\", revision=\"main\", local_dir=\"./sayoko-tts-corpus\")\n\n\n\t\n\t\t\n\t\t概要\n\t\n\n81歳の女性の音声コーパスです。… See the full description on the dataset page: https://huggingface.co/datasets/bandad/sayoko-tts-corpus.","first_N":5,"first_N_keywords":["text-to-speech","Japanese","cc-by-4.0","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"oasst1-21k-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-jp/oasst1-21k-ja","creator_name":"LLM-jp","creator_url":"https://huggingface.co/llm-jp","description":"\n\t\n\t\t\n\t\toasst1-21k-ja\n\t\n\nThis repository provides an instruction tuning dataset developed by LLM-jp, a collaborative project launched in Japan.\nThis dataset is a Japanese translation of an English subset of oasst1 using DeepL.\nEnglish subset is here.\n\n\t\n\t\t\n\t\n\t\n\t\tSend Questions to\n\t\n\nllm-jp(at)nii.ac.jp\n\n\t\n\t\t\n\t\n\t\n\t\tModel Card Authors\n\t\n\nThe names are listed in alphabetical order.\nHirokazu Kiyomaru, Hiroshi Matsuda, Jun Suzuki, Namgi Han, Saku Sugawara, Shota Sasaki, Shuhei Kurita, Taishi… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/oasst1-21k-ja.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Voice-KusanagiNene","keyword":"japanese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MomoyamaSawa/Voice-KusanagiNene","creator_name":"うさぎ","creator_url":"https://huggingface.co/MomoyamaSawa","description":"\n  \n\n 🥕 \n 如果兔兔的仓库对你有帮助的话点个⭐喵~ \n If Tutu's repository is helpful to you, please give it a ⭐ meow~ \n もしうさぎのリポジトリが役に立った場合は、⭐をぽちっとしてくださいにゃん~  \n\n 🍉 \n 任何 ❓问题 / 💭思考 /💡想法 都欢迎提出！\n Any ❓question / 💭thought /💡idea  is welcome! \n どんな ❓質問 / 💭考え /💡アイデア でも歓迎です！ \n\n\n\n\t\n\t\t\n\t\n\t\n\t\t简介\n\t\n\n\n草薙寧々 干声带标签数据集\n\n本数据集只收集了游戏内的一部分，并不是全部的宁宁干声语音，其中 nene_org.txt 是标签文件\npjsk 全部角色干声带标签数据集的话可以加QQ群：691795641，群公告里有网盘地址\n\n\t\n\t\n\t\n\t\t参考\n\t\n\n\n声源归属：草薙寧々(CV:Machico)-「プロジェクトセカイ カラフルステージ！ feat. 初音ミク」\n\t\n\t\t\n\t\tTODO\n\t\n\n\n（长期）补全宁宁语音，规范数据集格式。\n\n","first_N":5,"first_N_keywords":["other","text-to-speech","audio-to-audio","Japanese","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"MAGBIG","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/felfri/MAGBIG","creator_name":"Felix Friedrich","creator_url":"https://huggingface.co/felfri","description":"\n\t\n\t\t\n\t\tMAGBIG benchmark\n\t\n\nThis is the MAGBIG benchmark proposed in https://arxiv.org/abs/2401.16092\nThis benchmark is intended for multilingual text-to-image models. With MAGBIG, you can generate images for a diverse set of prompts across ten different languages. These images can be evaluated for differences across languages. MAGBIG is designed to uncover and assess biases across languages such as gender, race, age, etc. This way, we can measure whether bias exists in a language, but also… See the full description on the dataset page: https://huggingface.co/datasets/felfri/MAGBIG.","first_N":5,"first_N_keywords":["text-to-image","English","German","Italian","French"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"RyokoAI_Syosetu711K","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/RyokoAI_Syosetu711K","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Syosetu711K\n\t\n\nThe BigKnow2022 dataset and its subsets are not yet complete. Not all information here may be accurate or accessible.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nSyosetu711K is a dataset composed of approximately 711,700 novels scraped from the Japanese novel self-publishing\nwebsite Syosetuka ni Narou (JA: 小説家になろう, lit. \"Let's Become a Novelist\") between March 26 and March 27, 2023.\nThe dataset contains most if not all novels published on the site, regardless of… See the full description on the dataset page: https://huggingface.co/datasets/botp/RyokoAI_Syosetu711K.","first_N":5,"first_N_keywords":["text-classification","text-generation","Japanese","apache-2.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"llm-japanese-dataset-custom","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/longquan/llm-japanese-dataset-custom","creator_name":"qiulongquan","creator_url":"https://huggingface.co/longquan","description":"longquan/llm-japanese-dataset-custom dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Japanese","English","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"llm-japanese-dataset-split_10","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/longquan/llm-japanese-dataset-split_10","creator_name":"qiulongquan","creator_url":"https://huggingface.co/longquan","description":"longquan/llm-japanese-dataset-split_10 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Japanese","English","cc-by-sa-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"llm-japanese-dataset-split_10_1","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/longquan/llm-japanese-dataset-split_10_1","creator_name":"qiulongquan","creator_url":"https://huggingface.co/longquan","description":"longquan/llm-japanese-dataset-split_10_1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Japanese","English","cc-by-sa-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"oscar_2023_filtered","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/if001/oscar_2023_filtered","creator_name":"issei fujimoto","creator_url":"https://huggingface.co/if001","description":"from datasets import load_dataset\nds=load_dataset(\"if001/oscar_2023_filtered\")\nds['train']\n\n---\n\nDataset({\n    features: ['text'],\n    num_rows: 312396\n})\n\noscar 2023をfilterしたものhttps://huggingface.co/datasets/oscar-corpus/OSCAR-2301\n詳細はコードを参照https://github.com/if001/HojiChar_OSCAR_sample/tree/0.0.4\n","first_N":5,"first_N_keywords":["text-generation","Japanese","cc0-1.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"business-questions","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stockmark/business-questions","creator_name":"Stockmark Inc.","creator_url":"https://huggingface.co/stockmark","description":"\n\t\n\t\t\n\t\tStockmark Business Questions\n\t\n\n","first_N":5,"first_N_keywords":["Japanese","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.… See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","Metlatónoc Mixtec"],"keywords_longer_than_N":true},
	{"name":"WEATHub","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iamshnoo/WEATHub","creator_name":"Anjishnu Mukherjee","creator_url":"https://huggingface.co/iamshnoo","description":"\n\n\n\n\n\t\n\t\t\n\t\tDataset Card for \"WEATHub\"\n\t\n\nThis dataset corresponds to the data described in the paper \"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\"\naccepted to EMNLP 2023.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)\nto measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers. And we… See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub.","first_N":5,"first_N_keywords":["Arabic","Bengali","Central Kurdish","Danish","German"],"keywords_longer_than_N":true},
	{"name":"OpenOrcaJapanese","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shi3z/OpenOrcaJapanese","creator_name":"Ryo Shimizu","creator_url":"https://huggingface.co/shi3z","description":"OpenOrcaデータセットの日本語翻訳版です\nhttps://huggingface.co/datasets/Open-Orca/OpenOrca\n現在翻訳作業が続行中で、OpenOrca全体の1/5程度の翻訳が終わった状態でひとまず公開します。商用利用可能です。\n","first_N":5,"first_N_keywords":["table-question-answering","Japanese","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"open2ch","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/p1atdev/open2ch","creator_name":"Plat","creator_url":"https://huggingface.co/p1atdev","description":"\n\t\n\t\t\n\t\tおーぷん2ちゃんねる対話コーパス\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nおーぷん2ちゃんねる対話コーパス を Huggingface Datasets 向けに変換したものになります。\n\nCurated by: [More Information Needed]\nLanguage: Japanese\nLicense: Apache-2.0\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nRepository: https://github.com/1never/open2ch-dialogue-corpus\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nall-corpus: livejupiter, news4vip, newsplus サブセットを連結したもの\n\ndialogue: 対話データ (list[dict])\nspeaker: 話者番号。1 または 2。\ncontent: 発言内容\n\n\nboard: 連結元のサブセット名… See the full description on the dataset page: https://huggingface.co/datasets/p1atdev/open2ch.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Japanese","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"genai-terminology-en-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alfredplpl/genai-terminology-en-ja","creator_name":"Yasunori Ozaki","creator_url":"https://huggingface.co/alfredplpl","description":"生成AIの日英専門用語集です。正確さは保証しませんが、GPT-4などの頭に入れておくと綺麗に訳せると思います。\n","first_N":5,"first_N_keywords":["English","Japanese","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"openassistant-falcon","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant Falcon\n\t\n\nThis dataset allows for fine-tuning chat models using '\\Human:' AND '\\nAssistant:' to wrap user messages.\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\nSample \nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe… See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"oasst2-135k-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kunishou/oasst2-135k-ja","creator_name":"kunishou","creator_url":"https://huggingface.co/kunishou","description":"Update:  \n\n2023/12/25oasst2-135k-jaをチャット形式に変換したoasst2-chat-68k-jaを公開しました。\n\nThis dataset was created by automatically translating \"OpenAssistant/oasst2\" into Japanese by DeepL. \n\"OpenAssistant/oasst2\" を DeepL翻訳を用いて日本語に自動翻訳したデータセットになります。\n以下のコードを用いることで、 Instruction と Output （prompterの命令とassistantの回答）の形式に変換することができます。\nファインチューニングで使用する場合はこちらのコードで変換して下さい（変換には5分程度かかります）。\n変換コード参考https://github.com/h2oai/h2o-llmstudio/blob/5ebfd3879e226b4e1afd0a0b45eb632e60412129/app_utils/utils.py#L1888\npip install… See the full description on the dataset page: https://huggingface.co/datasets/kunishou/oasst2-135k-ja.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"oasst2-chat-68k-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kunishou/oasst2-chat-68k-ja","creator_name":"kunishou","creator_url":"https://huggingface.co/kunishou","description":"oasst2-135k-jaをチャット形式に変換したデータセットになります。マルチターン会話でのファインチューニングをする際にご活用下さい（1レコードのトークン長が大きいのでそれなりの計算リソースが必要になります）。フォーマットは ShareGPT 形式になっています。ファインチューニングをする際はこちらの記事を参考にして下さい。\nOpenAssistant/oasst2https://huggingface.co/datasets/OpenAssistant/oasst2\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"orca_dpo_pairs_ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yongtae-jp/orca_dpo_pairs_ja","creator_name":"Hwang Yongtae","creator_url":"https://huggingface.co/yongtae-jp","description":"\n\t\n\t\t\n\t\tAbout this dataset\n\t\n\nThis dataset is a machine translation of the Intel/orca_dpo_pairs dataset with Palm 2 (prompt for translation is pasted below).\nI hope this dataset can be used for LLM developers, especially Japanese LLM developers.\n\n\t\n\t\t\n\t\tLisence\n\t\n\nThe license is apache-2.0, which follows the will of the original dataset (Intel/orca_dpo_pairs).\n\n\t\n\t\t\n\t\tPrompt for translation\n\t\n\nWe use text-bison-32k@002 for translation. The rough Python code for translation is below.\nmodel =… See the full description on the dataset page: https://huggingface.co/datasets/yongtae-jp/orca_dpo_pairs_ja.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"WikidataLabels","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rayliuca/WikidataLabels","creator_name":"Ray Liu","creator_url":"https://huggingface.co/rayliuca","description":"\n\t\n\t\t\n\t\tWikidata Labels\n\t\n\nLarge parallel corpus for machine translation\n\nEntity label data extracted from Wikidata (2022-01-03), filtered for item entities only  \nOnly download the languages you need with datasets>=2.14.0\nSimilar dataset: https://huggingface.co/datasets/wmt/wikititles (18 Wikipedia titles pairs instead of all Wikidata entities)\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources\n\t\n\n\nWikidata JSON dump (wikidata-20220103-all.json.gz)… See the full description on the dataset page: https://huggingface.co/datasets/rayliuca/WikidataLabels.","first_N":5,"first_N_keywords":["translation","text2text-generation","English","French","German"],"keywords_longer_than_N":true},
	{"name":"GPT-4-Self-Instruct-Japanese","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CausalLM/GPT-4-Self-Instruct-Japanese","creator_name":"CausalLM","creator_url":"https://huggingface.co/CausalLM","description":"Here we share a Japanese dataset synthesized using the OpenAI GPT-4 model with Self-Instruct, utilizing some excess Azure credits. Please feel free to use it. All questions and answers are newly generated by GPT-4, without specialized verification, only simple filtering and strict semantic similarity control have been applied.\nWe hope that this will be helpful for fine-tuning open-source models for non-English languages, particularly Japanese. This dataset will be updated continuously.\n","first_N":5,"first_N_keywords":["Japanese","cc-by-4.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"oasst2_top1_chat_format","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","description":"\n\t\n\t\t\n\t\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\n\t\n\nExport of oasst2 only top 1 threads in huggingface chat format\n\n\t\n\t\t\n\t\tScript\n\t\n\nThe convert script can be find here\n","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"openassistant-deepseek-coder","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\n\t\n\nThis dataset allows for fine-tuning chat models using:\nB_INST = '\\n### Instruction:\\n'\nE_INST = '\\n### Response:\\n'\nBOS = '<｜begin▁of▁sentence｜>'\nEOS = '\\n<|EOT|>\\n'\n\nSample Preparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe… See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Loïck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Français\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.… See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","Pará Arára","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"hh-rlhf-12k-ja","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-jp/hh-rlhf-12k-ja","creator_name":"LLM-jp","creator_url":"https://huggingface.co/llm-jp","description":"\n\t\n\t\t\n\t\thh-rlhf-12k-ja\n\t\n\nThis repository provides a human preference dataset developed by LLM-jp, a collaborative project launched in Japan.\nThis dataset is a Japanese translation of a subset of hh-rlhf using DeepL.\nThis dataset consists of 12,000 entries randomly sampled from hh-rlhf. Specifically, it includes a random selection of 3,000 entries from the training splits of the four groups: harmless-base, helpful-base, helpful-online, and helpful-rejection-sampled. For more information on… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/hh-rlhf-12k-ja.","first_N":5,"first_N_keywords":["Japanese","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) → aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages → dolly-machine-translated.… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"llm-japanese-dataset-split_1","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/longquan/llm-japanese-dataset-split_1","creator_name":"qiulongquan","creator_url":"https://huggingface.co/longquan","description":"longquan/llm-japanese-dataset-split_1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Japanese","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ELYZA-tasks-100","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/elyza/ELYZA-tasks-100","creator_name":"ELYZA.inc","creator_url":"https://huggingface.co/elyza","description":"\n\t\n\t\t\n\t\tELYZA-tasks-100: 日本語instructionモデル評価データセット\n\t\n\n\n\n\t\n\t\t\n\t\tData Description\n\t\n\n本データセットはinstruction-tuningを行ったモデルの評価用データセットです。詳細は リリースのnote記事 を参照してください。\n特徴:\n\n複雑な指示・タスクを含む100件の日本語データです。\n役に立つAIアシスタントとして、丁寧な出力が求められます。\n全てのデータに対して評価観点がアノテーションされており、評価の揺らぎを抑えることが期待されます。\n\n具体的には以下のようなタスクを含みます。\n\n要約を修正し、修正箇所を説明するタスク\n具体的なエピソードから抽象的な教訓を述べるタスク\nユーザーの意図を汲み役に立つAIアシスタントとして振る舞うタスク\n場合分けを必要とする複雑な算数のタスク\n未知の言語からパターンを抽出し日本語訳する高度な推論を必要とするタスク\n複数の指示を踏まえた上でyoutubeの対話を生成するタスク\n架空の生き物や熟語に関する生成・大喜利などの想像力が求められるタスク… See the full description on the dataset page: https://huggingface.co/datasets/elyza/ELYZA-tasks-100.","first_N":5,"first_N_keywords":["text2text-generation","Japanese","cc-by-sa-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"belebele","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\n\t\n\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that discriminate… See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele.","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","text-classification","multiple-choice","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"aozorabunko-clean-sin","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/if001/aozorabunko-clean-sin","creator_name":"issei fujimoto","creator_url":"https://huggingface.co/if001","description":"this is forkhttps://huggingface.co/datasets/globis-university/aozorabunko-clean\nfiltered\nrow[\"meta\"][\"文字遣い種別\"] == \"新字新仮名\"\n","first_N":5,"first_N_keywords":["text-generation","text-classification","Japanese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\n\t\n\t\t\n\t\tDataset Card for WikiAnc\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \nThe code for generating the dataset can be found here.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nwikificiation: The dataset can be used to train a model for Wikification.\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in all 320… See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.… See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"misskey.io","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WitchesSocialStream/misskey.io","creator_name":"Witches Social Stream","creator_url":"https://huggingface.co/WitchesSocialStream","description":"\n\t\n\t\t\n\t\tCURRENTLY OFFLINE\n\t\n\nThis is old code + hosted on a VM which I accidentally filled the storage with.\n\n\t\n\t\t\n\t\tDataset Card for misskey.io\n\t\n\nNOTE: Looks familiar? Because it is!We have moved from RyokoExtra/MissingKeys -> WitchesSocialStream/misskey.io\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMissingKeys (Or this specific dataset) is a raw dataset archive of the misskey.io network.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is primarily intended for unsupervised training of text… See the full description on the dataset page: https://huggingface.co/datasets/WitchesSocialStream/misskey.io.","first_N":5,"first_N_keywords":["text-classification","text-generation","text-to-image","text-to-video","Japanese"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTA… See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"Aya_ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryota39/Aya_ja","creator_name":"kaeru39","creator_url":"https://huggingface.co/ryota39","description":"\n\t\n\t\t\n\t\tAya_ja\n\t\n\n\n\nこのデータセットはCohereForAI/aya_datasetの日本語インストラクションデータのみを抽出したデータセットです。\n人手でアノテーションされた指示応答のペアが6,259件収録されています。\n\n\t\n\t\t\n\t\tpythonでの使用例\n\t\n\nfrom datasets import load_dataset\n\naya_ja = load_dataset(\n    \"ryota39/Aya_ja\",\n    split='train',\n    )\n\n\n\t\n\t\t\n\t\t例\n\t\n\n\n\n[\n    {\n        \"inputs\": \"火縄銃の威力が全国に知られる事となった、１５７５年に織田・徳川連合軍が鉄砲隊を用いて武田勝頼率いる騎馬隊を破った戦いを何というでしょう？\",\n        \"targets\": \"長篠の戦いです。\",\n        \"language\": \"Japanese\",\n        \"language_code\": \"jpn\",\n        \"annotation_type\":… See the full description on the dataset page: https://huggingface.co/datasets/ryota39/Aya_ja.","first_N":5,"first_N_keywords":["question-answering","text-generation","Japanese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"kanji_embeddings","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/etrotta/kanji_embeddings","creator_name":"etrotta","creator_url":"https://huggingface.co/etrotta","description":"This repository contains the embeddings used by https://huggingface.co/spaces/etrotta/kanji_lookup\nThe embeddings were generated by:\n\nGenerating synthetic Kanji images using multiple different fonts then\nEncoding these images into using a Neural Network\n\nFor one example use case, you can use them to search for embeddings similar to handdrawn Kanji images as demonstrated in the space\nThe neural network used was the ViTModel encoder from https://huggingface.co/kha-white/manga-ocr-base\nThe… See the full description on the dataset page: https://huggingface.co/datasets/etrotta/kanji_embeddings.","first_N":5,"first_N_keywords":["Japanese","mit","10K<n<100K","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"ChatML-aya_dataset","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {… See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Japanese_Wikipedia_Conversation","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shi3z/Japanese_Wikipedia_Conversation","creator_name":"Ryo Shimizu","creator_url":"https://huggingface.co/shi3z","description":"Wikipedia日本語版データセット(izumi-lab/wikipedia-ja-20230720)を元にGPT-3.5-Turboで会話文を生成したデータセットです\nGPT-3.5-Turboを使っているため、商用利用はできません\n","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"megawika-report-generation","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\n\t\n\t\t\n\t\tDataset Card for MegaWika for Report Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\nnon-English language, an automated English translation is provided. \nThis dataset provides the… See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation.","first_N":5,"first_N_keywords":["summarization","text-retrieval","text-generation","text2text-generation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"oasst1-chat-44k-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kunishou/oasst1-chat-44k-ja","creator_name":"kunishou","creator_url":"https://huggingface.co/kunishou","description":"oasst1-89k-jaをチャット形式に変換したデータセットになります。マルチターン会話でのファインチューニングをする際にご活用下さい（1レコードのトークン長が大きいのでそれなりの計算リソースが必要になります）。フォーマットは ShareGPT 形式になっています。ファインチューニングをする際はこちらの記事を参考にして下さい。\noasst1-ja-89k Repositoryhttps://github.com/kunishou/oasst1-89k-ja\nOpenAssistant/oasst1https://huggingface.co/datasets/OpenAssistant/oasst1\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"VNTL","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmg-anon/VNTL","creator_name":"Anon","creator_url":"https://huggingface.co/lmg-anon","description":"lmg-anon/VNTL dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","English","Japanese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Open_Assistant_Conversation_Chains","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset description\n\t\n\n\n\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\n\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\n\nIt was modified… See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains.","first_N":5,"first_N_keywords":["text-generation","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"retrieval_qa","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lnwang/retrieval_qa","creator_name":"Luning Wang","creator_url":"https://huggingface.co/lnwang","description":"\n\t\n\t\t\n\t\tRetrieval_QA: A Simple Multilingual Benchmark For Retrieval Encoder Models\n\t\n\n\n\nThe purpose of this dataset is to provide a simple and easy-to-use benchmark for retrieval encoder models, which helps researchers quickly select the most effective retrieval encoder for text extraction and achieve optimal results in subsequent retrieval tasks such as retrieval-augmented-generation (RAG). The dataset contains multiple document-question pairs, where each document is a short text about the… See the full description on the dataset page: https://huggingface.co/datasets/lnwang/retrieval_qa.","first_N":5,"first_N_keywords":["English","Chinese","Japanese","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"multilingual-tts","keyword":"japanese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/multilingual-tts","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\n\t\n\t\t\n\t\tBefore Anything and Everything ⚱\n\t\n\nIn the time of writing this Dataset Card, 17,490 18,412 civilian has been killed in Palestine (7,870 8,000 are children and 6,121 6,200 are women).\nSeek any non-profit organization to help them with what you can (For myself, I use Mersal) 🇵🇸\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe Multilingual TTS dataset is an exceptional compilation of text-to-speech (TTS) samples, meticulously crafted to showcase the richness and diversity of human languages.… See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/multilingual-tts.","first_N":5,"first_N_keywords":["text-to-speech","Arabic","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"Pontoon-Translations","keyword":"japanese","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\n\t\n\t\t\n\t\tDataset Card for Pontoon Translations\n\t\n\n\n\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\nSource strings are in English.\nTo avoid rows with values like \"None\" and \"N/A\" being interpreted as missing values, pass the keep_default_na parameter like this:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ayymen/Pontoon-Translations\", keep_default_na=False)… See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","text2text-generation","crowdsourced","Abkhaz","Achinese"],"keywords_longer_than_N":true},
	{"name":"ultra-orca-boros-en-ja-v1","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/augmxnt/ultra-orca-boros-en-ja-v1","creator_name":"AUGMXNT","creator_url":"https://huggingface.co/augmxnt","description":"EN/JA dataset used for shisa-7b-v1 - see details in that model's readme.\n","first_N":5,"first_N_keywords":["text-generation","Japanese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"modern_haiku","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/p1atdev/modern_haiku","creator_name":"Plat","creator_url":"https://huggingface.co/p1atdev","description":"This new dataset is designed to solve this great NLP task and is crafted with a lot of care.","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","10K - 100K","Text"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_regions","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Regions\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\nKey Features:\n\nTextual Data: The dataset contains 500,000 text samples.… See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"Scenery_of_japan","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JapanDegitalMaterial/Scenery_of_japan","creator_name":"Japan Degital Material","creator_url":"https://huggingface.co/JapanDegitalMaterial","description":"\n\t\n\t\t\n\t\tScenery of japan.\n\t\n\nThis is a dataset to train text-to-image or other models without any copyright issue.\nAll materials used in this dataset are CC0 (Public domain /P.D.).\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More… See the full description on the dataset page: https://huggingface.co/datasets/JapanDegitalMaterial/Scenery_of_japan.","first_N":5,"first_N_keywords":["text-to-image","English","Japanese","cc0-1.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Texture_images","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JapanDegitalMaterial/Texture_images","creator_name":"Japan Degital Material","creator_url":"https://huggingface.co/JapanDegitalMaterial","description":"\n\t\n\t\t\n\t\tTextuer images\n\t\n\nThis is a dataset to train text-to-image or other models without any copyright issue.\nAll materials used in this dataset are CC0 (Public domain /P.D.).\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More… See the full description on the dataset page: https://huggingface.co/datasets/JapanDegitalMaterial/Texture_images.","first_N":5,"first_N_keywords":["text-to-image","English","Japanese","cc0-1.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Places_in_Japan","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JapanDegitalMaterial/Places_in_Japan","creator_name":"Japan Degital Material","creator_url":"https://huggingface.co/JapanDegitalMaterial","description":"\n\t\n\t\t\n\t\tPlaces in japan.\n\t\n\nThis is a dataset to train text-to-image or other models without any copyright issue.\nAll materials used in this dataset are CC0 (Public domain /P.D.).\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More… See the full description on the dataset page: https://huggingface.co/datasets/JapanDegitalMaterial/Places_in_Japan.","first_N":5,"first_N_keywords":["text-to-image","English","Japanese","cc0-1.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"openassistant-guanaco-EOS","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Guanaco Style\n\t\n\nThis dataset allows for fine-tuning chat models using \"### Human:\" AND \"### Assistant\" as the beginning and end of sequence tokens.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then slightly adjusted to:\n\n\nif a row of… See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"sharegpt-deduplicated","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated","creator_name":"Caterina Lacerra","creator_url":"https://huggingface.co/CaterinaLac","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a deduplicated version of sharegpt4. \nThe deduplication process has two steps:\n\nThe literal duplicates (both input and outputs) are removed\nThe remaining (5749) instances are embedded with the SentenceTransformer library (\"paraphrase-multilingual-mpnet-base-v2\" model).\nThen, we compute the cosine similarity among all the possible pairs, and consider paraphrases those pairs with a… See the full description on the dataset page: https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated.","first_N":5,"first_N_keywords":["English","Chinese","Korean","French","Japanese"],"keywords_longer_than_N":true},
	{"name":"openassistant-llama-style","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Llama 2 Style\n\t\n\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then filtered to:\n\n\nreplace instances of '### Human:' with '[INST]'\nreplace… See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"Qarasu_Wikipedia_multiturn_human_gpt_10K","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shi3z/Qarasu_Wikipedia_multiturn_human_gpt_10K","creator_name":"Ryo Shimizu","creator_url":"https://huggingface.co/shi3z","description":"Japanese multi-turn conversation data was generated using Qarasu14B based on Wikipedia data. for non commercial use(Because Qarasu14B learned from ShareGPT)\nHuman-gpt format conversation dataset that can be learned with Axolotl.\n\n\t\n\t\t\n\t\tBased on\n\t\n\nhttps://huggingface.co/datasets/shi3z/Qarasu_Wikipedia_Multiturn\n\n\t\n\t\t\n\t\tModel\n\t\n\nhttps://huggingface.co/lightblue/qarasu-14B-chat-plus-unleashed\n\n\t\n\t\t\n\t\tDataset\n\t\n\nhttps://huggingface.co/datasets/izumi-lab/wikipedia-ja-20230720\n\n\t\n\t\t\n\t\tDeveloped by… See the full description on the dataset page: https://huggingface.co/datasets/shi3z/Qarasu_Wikipedia_multiturn_human_gpt_10K.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"yandere2023","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nyanko7/yandere2023","creator_name":"Nyanko","creator_url":"https://huggingface.co/nyanko7","description":"\n\t\n\t\t\n\t\tYandere2023: A Large-Scale Crowdsourced and Tagged Anime Illustration Dataset\n\t\n\n\n\nYandere2023 is a comprehensive anime image dataset with over 1.2 million high-quality images sourced from various materials, including key frames, manga scans, artbooks, and more. While the average number of tags per image is relatively low, the dataset boasts a diverse collection of images with exceptional quality.\n\nShared by: Nyanko Devs\nLanguage(s): English, Japanese\nLicense: MIT\n\n\n\t\n\t\t\n\t\n\t\n\t\tUses… See the full description on the dataset page: https://huggingface.co/datasets/nyanko7/yandere2023.","first_N":5,"first_N_keywords":["image-classification","image-to-image","text-to-image","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"work","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Gustav114514/work","creator_name":"Ryohei Kasai","creator_url":"https://huggingface.co/Gustav114514","description":"\n\t\n\t\t\n\t\n\t\n\t\tFine-tuned XLSR-53 large model for speech recognition in Japanese\n\t\n\nFine-tuned facebook/wav2vec2-large-xlsr-53 on Japanese using the train and validation splits of Common Voice 6.1, CSS10 and JSUT.\nWhen using this model, make sure that your speech input is sampled at 16kHz.\nThis model has been fine-tuned thanks to the GPU credits generously given by the OVHcloud :)\nThe script used for training can be found here: https://github.com/jonatasgrosman/wav2vec2-sprint\n\n\t\n\t\t\n\t\n\t\n\t\tUsage… See the full description on the dataset page: https://huggingface.co/datasets/Gustav114514/work.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","Audio","🇺🇸 Region: US","audio"],"keywords_longer_than_N":true},
	{"name":"oasst1","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effort… See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\n\t\n\t\t\n\t\tDataset Card for WIT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\nFrom the official blog post:\n\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\nThe WIT dataset offers extremely valuable data about the… See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"mgsm","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/juletxara/mgsm","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","description":"Multilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper [Language models are multilingual chain-of-thought reasoners](http://arxiv.org/abs/2210.03057).\n\nThe same 250 problems from [GSM8K](https://arxiv.org/abs/2110.14168) are each translated via human annotators in 10 languages. The 10 languages are:\n- Spanish\n- French\n- German\n- Russian\n- Chinese\n- Japanese\n- Thai\n- Swahili\n- Bengali\n- Telugu\n\nYou can find the input and targets for each of the ten languages (and English) as `.tsv` files.\nWe also include few-shot exemplars that are also manually translated from each language in `exemplars.py`.","first_N":5,"first_N_keywords":["text2text-generation","found","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"japanese-anime-speech","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joujiboi/japanese-anime-speech","creator_name":"JawGBoi","creator_url":"https://huggingface.co/joujiboi","description":"\n\t\n\t\t\n\t\tJapanese Anime Speech Dataset\n\t\n\n日本語はこちら\njapanese-anime-speech is an audio-text dataset designed for the training of automatic speech recognition models. The dataset is comprised of thousands of audio clips and their corresponding transcriptions from different visual novels.\nThe goal of this dataset is to increase the accuracy of automatic speech recognition models, such as OpenAI's Whisper, in accurately transcribing dialogue from anime and other similar Japanese media. This genre is… See the full description on the dataset page: https://huggingface.co/datasets/joujiboi/japanese-anime-speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Japanese","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"japanese-anime-speech","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joujiboi/japanese-anime-speech","creator_name":"JawGBoi","creator_url":"https://huggingface.co/joujiboi","description":"\n\t\n\t\t\n\t\tJapanese Anime Speech Dataset\n\t\n\n日本語はこちら\njapanese-anime-speech is an audio-text dataset designed for the training of automatic speech recognition models. The dataset is comprised of thousands of audio clips and their corresponding transcriptions from different visual novels.\nThe goal of this dataset is to increase the accuracy of automatic speech recognition models, such as OpenAI's Whisper, in accurately transcribing dialogue from anime and other similar Japanese media. This genre is… See the full description on the dataset page: https://huggingface.co/datasets/joujiboi/japanese-anime-speech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Japanese","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"oasst2","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\n\t\n\t\t\n\t\tOpen Assistant Conversations Dataset Release 2 (OASST2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \nAll messages have a role property: this can either be \"assistant\" or \"prompter\". The roles in \nconversation threads from prompt to leaf node strictly alternate between \"prompter\" and… See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"JaGovFaqs-22k","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/matsuxr/JaGovFaqs-22k","creator_name":"Yuichi Matsushita","creator_url":"https://huggingface.co/matsuxr","description":"\n\t\n\t\t\n\t\tこのデータセットについて\n\t\n\nこのデータは、日本の官公庁のWebサイトに掲載されている「よくある質問」を手作業で抽出し、インストラクション用のデータセットとしたものです。\n日本の官公庁のWebサイトは多くが「政府標準利用規約（第2.0版）」に準拠しており、この規約はCC-BY-4.0（国際）と互換性があると記述されています。\n参考 https://www.digital.go.jp/copyright-policy\nしたがって本データセットの著作権者はデータセットのcopyrightに記載された各官公庁であり、ライセンスもCC-BY-4.0（国際）です。データセット製作者は著作権を主張しません。\n\n\t\n\t\t\n\t\t特徴\n\t\n\n\n質問と回答の形式になっています。\n国家公務員によるチェックを経ているので、誤字脱字がほぼありません。もしあったら、このデータセット製作者（松xR）のミスに起因するものです。御指摘いただければ修正いたします。\n論旨も明快で、日本語として品質の高いデータセットであると考えています。… See the full description on the dataset page: https://huggingface.co/datasets/matsuxr/JaGovFaqs-22k.","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NTREXBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNTREX is a News Test References dataset for Machine Translation Evaluation, covering translation from English into 128 languages. We select language pairs according to the M2M-100 language grouping strategy, resulting in 1916 directions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/davidstap/NTREX\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an… See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","translated","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"anime-with-caption-cc0","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alfredplpl/anime-with-caption-cc0","creator_name":"Yasunori Ozaki","creator_url":"https://huggingface.co/alfredplpl","description":"\n\t\n\t\t\n\t\tAnime with caption CC-0 dataset\n\t\n\nこのデータセットはイラストに対する日本語キャプションを\n倫理的に学習しやすくするためのデータセットです。\nここに掲載されているイラストは自律的にAIが作成したものであり、\n著作権はありません。またキャプションも自律的につけられたものなので、\n著作権はありません。したがって、データセットの著作権を私は放棄します。\n勝手に使ってください。\n\n\t\n\t\t\n\t\tライセンス\n\t\n\nパブリックドメイン\n\n\t\n\t\t\n\t\tデータセットの構成\n\t\n\nデータセットは以下の列で構成されています。\n\nimage: Emi 2でランダムに生成した画像\nprompt: 言語モデルでランダムに生成された画像のプロンプト(ただし、画像とあまり一致していないため、あてにならない)\nphi3_caption: Phi-3 VisionでDense captioningした結果\nphi3_caption_ja: phi3_captionをPhi-3 Mediumで日本語訳した結果\n\n\n\t\n\t\t\n\t\tイラストの作り方… See the full description on the dataset page: https://huggingface.co/datasets/alfredplpl/anime-with-caption-cc0.","first_N":5,"first_N_keywords":["image-to-text","English","Japanese","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\n\t\n\t\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\nWe translated the MMLU’s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases… See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"MultiSimV2","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MichaelR207/MultiSimV2","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","description":"\n\t\n\t\t\n\t\tDataset Card for MultiSim Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe MultiSim benchmark is a growing collection of text simplification datasets targeted at sentence simplification in several languages.  Currently, the benchmark spans 12 languages.\n\n\n\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\n\nSentence Simplification\n\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets importload_dataset\n\ndataset = load_dataset(\"MichaelR207/MultiSimV2\")\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this benchmark, please cite our paper:… See the full description on the dataset page: https://huggingface.co/datasets/MichaelR207/MultiSimV2.","first_N":5,"first_N_keywords":["summarization","text2text-generation","text-generation","English","French"],"keywords_longer_than_N":true},
	{"name":"product-database","keyword":"japanese","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\n\t\n\t\t\n\t\tOpen Food Facts Database\n\t\n\n\n\t\n\t\t\n\t\tWhat is 🍊 Open Food Facts?\n\t\n\n\n\t\n\t\t\n\t\tA food products database\n\t\n\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\n\n\t\n\t\t\n\t\tMade by everyone\n\t\n\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scan… See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"suno","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/suno","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Suno.ai Music Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains metadata for 659,788 songs generated by artificial intelligence on the suno.com platform, a service that generates music using artificial intelligence. The songs were discovered by search queries with words from the dwyl/english-words word list.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is multilingual with English as the primary language:\n\nEnglish (en): Primary language for metadata and most lyrics… See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/suno.","first_N":5,"first_N_keywords":["audio-classification","text-to-audio","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"P-MMEval","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Qwen/P-MMEval","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","description":"\n\t\n\t\t\n\t\tP-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWe introduce a multilingual benchmark, P-MMEval, covering effective fundamental and capability-specialized datasets. We extend the existing benchmarks, ensuring consistent language coverage across all datasets and providing parallel samples among multiple languages, supporting up to 10 languages from 8 language families (i.e., en, zh, ar, es, ja, ko, th, fr, pt, vi). As a… See the full description on the dataset page: https://huggingface.co/datasets/Qwen/P-MMEval.","first_N":5,"first_N_keywords":["Arabic","Spanish","French","Japanese","Korean"],"keywords_longer_than_N":true},
	{"name":"MultiLingualSentiment","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clapAI/MultiLingualSentiment","creator_name":"clapAI","creator_url":"https://huggingface.co/clapAI","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nMultilingualSentiment is a sentiment classification dataset that encompasses three sentiment labels: Positive, Neutral, Negative\nThe dataset spans multiple languages and covers a wide range of domains, making it ideal for multilingual sentiment analysis tasks.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThe dataset was meticulously collected and aggregated from various sources, including Hugging Face and Kaggle. These sources provide diverse languages and domains to ensure a… See the full description on the dataset page: https://huggingface.co/datasets/clapAI/MultiLingualSentiment.","first_N":5,"first_N_keywords":["text-classification","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"llm-jp-instructions","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-jp/llm-jp-instructions","creator_name":"LLM-jp","creator_url":"https://huggingface.co/llm-jp","description":"\n\t\n\t\t\n\t\t概要\n\t\n\nllm-jp-instructionsは人手により作成されたインストラクションデータセットです。\n\n\t\n\t\t\n\t\tOverview\n\t\n\nllm-jp-instructions is a manually created instruction dataset.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# load train, dev and test splits of v1.0\nv1_train = load_dataset(\"llm-jp/llm-jp-instructions\", data_dir=\"v1.0\", split=\"train\")\nv1_dev = load_dataset(\"llm-jp/llm-jp-instructions\", data_dir=\"v1.0\", split=\"dev\")\nv1_test = load_dataset(\"llm-jp/llm-jp-instructions\", data_dir=\"v1.0\", split=\"test\")\n\n","first_N":5,"first_N_keywords":["text-generation","Japanese","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"HelpSteer3","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nvidia/HelpSteer3","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","description":"\n\t\n\t\t\n\t\tHelpSteer3\n\t\n\nHelpSteer3 is an open-source dataset (CC-BY-4.0) that supports aligning models to become more helpful in responding to user prompts.\nHelpSteer3-Preference can be used to train Llama 3.3 Nemotron Super 49B v1 (for Generative RMs) and Llama 3.3 70B Instruct Models (for Bradley-Terry RMs) to produce Reward Models that score as high as 85.5% on RM-Bench and 78.6% on JudgeBench, which substantially surpass existing Reward Models on these benchmarks.\nHelpSteer3-Feedback and… See the full description on the dataset page: https://huggingface.co/datasets/nvidia/HelpSteer3.","first_N":5,"first_N_keywords":["English","Chinese","Korean","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"miracl-vision","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nvidia/miracl-vision","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","description":"\n\t\n\t\t\n\t\tMIRACL-VISION\n\t\n\nMIRACL-VISION is a multilingual visual retrieval dataset for 18 different languages. It is an extension of MIRACL, a popular text-only multilingual retrieval dataset. The dataset contains user questions, images of Wikipedia articles and annotations, which article can answer a user question. There are 7898 questions and 338734 images. More details can be found in the paper MIRACL-VISION: A Large, multilingual, visual document retrieval benchmark.\nThis dataset is ready… See the full description on the dataset page: https://huggingface.co/datasets/nvidia/miracl-vision.","first_N":5,"first_N_keywords":["document-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"shisa-v2-sharegpt","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shisa-ai/shisa-v2-sharegpt","creator_name":"Shisa.AI","creator_url":"https://huggingface.co/shisa-ai","description":"\n\t\n\t\t\n\t\tshisa-v2-sharegpt\n\t\n\nThis is an updated version of the original shisa-v1 dataset augmxnt/ultra-orca-boros-en-ja-v1 and retains the same conversations field and sharegpt formatting to facilitate its use as drop-in replacement for the original dataset.\nThe shisa-v2 revision filters a few entries, but largely retains the exact composition and prompts of the original.\n\nAll responses have been entirely regenerated from open weight models (Athene V2, Llama 3.3 70B, and Tulu 3 405B)\nOutputs… See the full description on the dataset page: https://huggingface.co/datasets/shisa-ai/shisa-v2-sharegpt.","first_N":5,"first_N_keywords":["text-generation","Japanese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"multivsr","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sindhuhegde/multivsr","creator_name":"Sindhu Hegde","creator_url":"https://huggingface.co/sindhuhegde","description":"\n\t\n\t\t\n\t\tDataset: MultiVSR\n\t\n\nWe introduce a large-scale multilingual lip-reading dataset: MultiVSR. The dataset comprises a total of 12,000 hours of video footage, covering English + 12 non-English languages. MultiVSR is a massive dataset with a huge diversity in terms of the speakers as well as languages, with approximately 1.6M video clips across 123K YouTube videos. Please check the website for samples.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDownload instructions\n\t\n\nPlease check the GitHub repo to download… See the full description on the dataset page: https://huggingface.co/datasets/sindhuhegde/multivsr.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","description":"\n\n\n\t\n\t\t\n\t\t🔷 Accepted in NAACL Proceedings (2025) 🔷\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval 📚 [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailed… See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","first_N":5,"first_N_keywords":["text2text-generation","Afar","Abkhaz","Avestan","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"extraction-wiki-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-jp/extraction-wiki-ja","creator_name":"LLM-jp","creator_url":"https://huggingface.co/llm-jp","description":"\n\t\n\t\t\n\t\textraction-wiki-ja\n\t\n\nThis repository provides an instruction-tuning dataset developed by LLM-jp, a collaborative project launched in Japan.\nThis is a Japanese instruction-tuning dataset tailored for information extraction and structuring from Japanese Wikipedia text.\nThe dataset consists of instruction–response pairs automatically generated from Japanese Wikipedia articles. Instructions are created by prompting Qwen/Qwen2.5-32B-Instruct with passages from Wikipedia, and the… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/extraction-wiki-ja.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"MLSNT","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ComplexDataLab/MLSNT","creator_name":"Complex Data Lab","creator_url":"https://huggingface.co/ComplexDataLab","description":"\n\t\n\t\t\n\t\tMLSNT: Multi-Lingual Social Network Toxicity Dataset\n\t\n\nMLSNT is a multi-lingual dataset for toxicity detection created through a large language model-assisted label transfer pipeline. It enables efficient and scalable moderation across languages and platforms, and is built to support span-level and category-specific classification for toxic content.\nThis dataset is introduced in the following paper:\n\nUnified Game Moderation: Soft-Prompting and LLM-Assisted Label Transfer for… See the full description on the dataset page: https://huggingface.co/datasets/ComplexDataLab/MLSNT.","first_N":5,"first_N_keywords":["text-classification","token-classification","Chinese","Japanese","Portuguese"],"keywords_longer_than_N":true},
	{"name":"alt","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mutiyama/alt","creator_name":"Masao Utiyama","creator_url":"https://huggingface.co/mutiyama","description":"\n\t\n\t\t\n\t\tDataset Card for Asian Language Treebank (ALT)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ALT project aims to advance the state-of-the-art Asian natural language processing (NLP) techniques through the open collaboration for developing and using ALT. It was first conducted by NICT and UCSY as described in Ye Kyaw Thu, Win Pa Pa, Masao Utiyama, Andrew Finch and Eiichiro Sumita (2016). Then, it was developed under ASEAN IVO as described in this Web page. \nThe process of building ALT began with… See the full description on the dataset page: https://huggingface.co/datasets/mutiyama/alt.","first_N":5,"first_N_keywords":["translation","token-classification","parsing","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"conceptnet5","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/conceptnet5/conceptnet5","creator_name":"conceptnet5","creator_url":"https://huggingface.co/conceptnet5","description":"\n\t\n\t\t\n\t\tDataset Card for Conceptnet5\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nConceptNet is a multilingual knowledge base, representing words and\nphrases that people use and the common-sense relationships between\nthem. The knowledge in ConceptNet is collected from a variety of\nresources, including crowd-sourced resources (such as Wiktionary and\nOpen Mind Common Sense), games with a purpose (such as Verbosity and\nnadya.jp), and expert-created resources (such as WordNet and JMDict).\nYou can browse what… See the full description on the dataset page: https://huggingface.co/datasets/conceptnet5/conceptnet5.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"japanese","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for Opus Ubuntu\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\nE.g.\ndataset = load_dataset(\"opus_ubuntu\", lang1=\"it\", lang2=\"pl\")\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards… See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"tydiqa","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/tydiqa","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for \"tydiqa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\nin the world. It contains language phenomena that would not be found in… See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/tydiqa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xcsr","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/INK-USC/xcsr","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","description":"\n\t\n\t\t\n\t\tDataset Card for X-CSR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTo evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR.… See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","crowdsourced","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tDataset Card for \"xtreme\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with the… See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"fungi_diagnostic_chars_comparison_japanese","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Atsushi/fungi_diagnostic_chars_comparison_japanese","creator_name":"Atsushi Nakajima","creator_url":"https://huggingface.co/Atsushi","description":"\n\t\n\t\t\n\t\tfungi_diagnostic_chars_comparison_japanese大菌輪「識別形質まとめ」データセット最終更新日 / Last updated: 2025/5/2（up to R3-12744）\n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nJapanese  \nThis dataset is available in Japanese only.  \n\n\t\n\t\t\n\t\t概要 / Overview\n\t\n\nAtsushi Nakajima（中島淳志）が個人で運営しているWebサイト大菌輪では、数千件以上の菌類分類学論文を「論文3行まとめ」という形で要約および索引付け（インデキシング）した情報を提供しています。その一環として、ある菌と別の菌の「共通する」あるいは「異なる」識別形質 (diagnostic characters) に関する記述を人手で抽出しています。\nDaikinrin, a website personally operated by Atsushi Nakajima, provides summaries and indexing… See the full description on the dataset page: https://huggingface.co/datasets/Atsushi/fungi_diagnostic_chars_comparison_japanese.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"fungi_indexed_mycological_papers_japanese","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Atsushi/fungi_indexed_mycological_papers_japanese","creator_name":"Atsushi Nakajima","creator_url":"https://huggingface.co/Atsushi","description":"\n\t\n\t\t\n\t\tfungi_indexed_mycological_papers_japanese\n大菌輪「論文3行まとめ」データセット最終更新日：2025/5/2（R3-12744まで）  \n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nJapanese  \nThis dataset is available in Japanese only.  \n\n\t\n\t\t\n\t\t概要 / Overview\n\t\n\n大菌輪は、Atsushi Nakajima（中島淳志）が個人で運営しているWebサイトです。ここでは、数千件以上の菌類分類学論文を「論文3行まとめ」という形で要約および索引付け（インデキシング）した情報を提供しています。\nDaikinrin is a website personally operated by Atsushi Nakajima. It provides summaries and indexing information for thousands of mycological taxonomy papers in the form of \"Three-line… See the full description on the dataset page: https://huggingface.co/datasets/Atsushi/fungi_indexed_mycological_papers_japanese.","first_N":5,"first_N_keywords":["other","monolingual","original","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"fungi_trait_circus_database","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Atsushi/fungi_trait_circus_database","creator_name":"Atsushi Nakajima","creator_url":"https://huggingface.co/Atsushi","description":"\n\t\n\t\t\n\t\tfungi_trait_circus_database大菌輪「Trait Circus」データセット（統制形質）最終更新日：2023/12/29  \n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nJapanese and English \nPlease do not use this dataset for academic purposes for the time being. (casual use only)当面の間仮公開とします。学術目的での使用はご遠慮ください。  \n\n\t\n\t\t\n\t\t概要\n\t\n\nAtsushi Nakajima（中島淳志）が個人で運営しているWebサイト大菌輪 では、菌類の記載文を自然言語処理の手法を利用して半自動的に処理し、菌類の形態、生態などに関する様々な「形質 (traits)」データを抽出して、集計や解析の便宜を図るために、あらかじめ設定された「統制語 (controlled… See the full description on the dataset page: https://huggingface.co/datasets/Atsushi/fungi_trait_circus_database.","first_N":5,"first_N_keywords":["other","multilingual","original","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"mr-tydi-corpus","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/mr-tydi-corpus","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\nThis dataset stores documents of Mr. TyDi. To access the queries and judgments, please refer to castorini/mr-tydi.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe only configuration here is the language. As all three folds (train, dev and test) share the same… See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi-corpus.","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"mr-tydi","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/mr-tydi","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\nThis dataset stores the queries, judgements, and example training data of Mr. TyDi. To access the corpus, please refer to castorini/mr-tydi-corpus.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe only configuration here is the language, \nFor each language… See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi.","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"mqa","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_scenario","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_scenario","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveScenarioClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveScenarioClassification\"])\nevaluator =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_scenario.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_intent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveIntentClassification\"])\nevaluator =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_intent.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"amazon_counterfactual","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_counterfactual","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AmazonCounterfactualClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA collection of Amazon customer reviews annotated for counterfactual detection pair classification.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\nReference\nhttps://arxiv.org/abs/2104.06893\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AmazonCounterfactualClassification\"])… See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_counterfactual.","first_N":5,"first_N_keywords":["text-classification","human-annotated","multilingual","German","English"],"keywords_longer_than_N":true},
	{"name":"xwinograd","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xwinograd","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"\n\t\n\t\t\n\t\tXWinograd\n\t\n\nMultilingual winograd schema challenge as used in Crosslingual Generalization through Multitask Finetuning.\n\n\t\n\t\t\n\t\tLanguages & Samples\n\t\n\n\n\"en\": 2325\n\"fr\": 83\n\"jp\": 959\n\"pt\": 263 \n\"ru\": 315\n\"zh\": 504\n\n\n\t\n\t\t\n\t\tDataset creation\n\t\n\nThe Winograd schema challenges in this dataset combine winograd schemas from the XWinograd dataset introduced in Tikhonov et al and as it only contains 16 Chinese schemas, we add 488 Chinese schemas from clue/cluewsc2020.\nIf you only want the… See the full description on the dataset page: https://huggingface.co/datasets/Muennighoff/xwinograd.","first_N":5,"first_N_keywords":["English","French","Japanese","Portuguese","Russian"],"keywords_longer_than_N":true},
	{"name":"answerable_tydiqa","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/answerable_tydiqa","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\n\t\n\t\t\n\t\tDataset Card for \"answerable-tydiqa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages. \nAnswerable TyDi QA is an extension of the GoldP subtask of the original TyDi QA dataset to also include unanswertable questions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains a train and a validation set, with 116067 and 13325 examples, respectively. Access them with\nfrom datasets import load_dataset\ndataset =… See the full description on the dataset page: https://huggingface.co/datasets/copenlu/answerable_tydiqa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"tydiqa_copenlu","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/tydiqa_copenlu","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\n\t\n\t\t\n\t\tDataset Card for \"tydiqa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\nin the world. It contains language phenomena that would not be found in… See the full description on the dataset page: https://huggingface.co/datasets/copenlu/tydiqa_copenlu.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"multilingual-sentiments","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tyqiangz/multilingual-sentiments","creator_name":"Tay Yong Qiang","creator_url":"https://huggingface.co/tyqiangz","description":"\n\t\n\t\t\n\t\tMultilingual Sentiments Dataset\n\t\n\nA collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.\nMost multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, a positive/negative… See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-classification","monolingual","multilingual"],"keywords_longer_than_N":true},
	{"name":"miracl-corpus","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/miracl-corpus","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\n\t\n\t\t\n\t\tDataset Card for MIRACL Corpus\n\t\n\nMIRACL 🌍🙌🌏 (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\nThis dataset contains the collection data of the 16 \"known languages\". The remaining 2 \"surprise languages\" will not be released until later.\nThe corpus for each language is prepared from a Wikipedia… See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse the… See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"jsnli","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shunk031/jsnli","creator_name":"Shunsuke Kitada","creator_url":"https://huggingface.co/shunk031","description":"== 日本語SNLI(JSNLI)データセット ==\n\nSNLI コーパスを日本語に翻訳した自然言語推論データセット\n学習データは元データを翻訳し、計算機によるフィルタリングによって作成\n評価データは日本語として意味が通るか、翻訳後のラベルが元のラベルと一致しているかどうかの2段階のクラウドソーシングによりデータをフィルタリング","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"qag_jaquad","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qag_jaquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Question & answer generation dataset based on SQuAD.","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","lmqg/qg_jaquad","Japanese"],"keywords_longer_than_N":true},
	{"name":"odex","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/odex","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"ODEX is an Open-Domain EXecution-based NL-to-Code generation data benchmark. \nIt contains 945 samples with a total of 1,707 human-written test cases, \ncovering intents in four different natural languages -- 439 in English, 90 in Spanish, 164 in Japanese, and 252 in Russian.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","English","Spanish","Japanese"],"keywords_longer_than_N":true},
	{"name":"Umamusume-voice-text-pairs","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Plachta/Umamusume-voice-text-pairs","creator_name":"ElderFrog","creator_url":"https://huggingface.co/Plachta","description":"Plachta/Umamusume-voice-text-pairs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-ja-embeddings","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-ja-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\n\t\n\t\t\n\t\tWikipedia (ja) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (ja) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this… See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-ja-embeddings.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","multilingual","Japanese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"defamation-japanese-twitter","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kubota/defamation-japanese-twitter","creator_name":"Issei","creator_url":"https://huggingface.co/kubota","description":"\n\t\n\t\t\n\t\tdefamation_japanese_twitter\n\t\n\n\n\t\n\t\t\n\t\tTwitter日本語誹謗中傷検出データセット\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSNSにおける誹謗中傷検出のためのデータセットです．\n5,000件の日本語のツイートに，それぞれ以下で定義している誹謗中傷の対象者と内容をアノテーションしています．アノテーションは，3人のクラウドワーカーにより行われています．2022年2月15日から2022年6月30日までのツイートです．\n元のツイートは含まれていないため，Twitter APIを用いてデータセットを収集してください．\n中傷対象(target)と中傷内容(label)の2項目がアノテーションされています．\n\ntarget ：テキストが話題にしている対象者の分類\nlabel ： targetで選択された対象者に対する誹謗中傷の種類の分類\n\n文として成立しておらず意味の取れないものはラベルC(0)としています．\n\n\t\n\t\t\ntarget\n対象\n例\n\n\n\t\t\nA1(1)\n(人種・性別・職業・思想などを共通とする)グループ… See the full description on the dataset page: https://huggingface.co/datasets/kubota/defamation-japanese-twitter.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"pvc","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/p1atdev/pvc","creator_name":"Plat","creator_url":"https://huggingface.co/p1atdev","description":"\n\t\n\t\t\n\t\tPVC figure products dataset\n\t\n\nThis dataset contains product information of figure images scraped from multiple Web sites.\n\n\t\n\t\t\n\t\tDataset information\n\t\n\n\n\t\n\t\t\nSubset\nSource\nSize\n\n\n\t\t\ngoodsmile-figma\nhttps://www.goodsmile.info/ja/products/category/figma/announced/2023\n947\n\n\ngoodsmile-nendoroid\nhttps://www.goodsmile.info/ja/products/category/nendoroid_series/announced/2023\n3378\n\n\ngoodsmile-scale\nhttps://www.goodsmile.info/ja/products/category/scale/announced/2023\n2203\n\n\nkotobukiya… See the full description on the dataset page: https://huggingface.co/datasets/p1atdev/pvc.","first_N":5,"first_N_keywords":["English","Japanese","cc0-1.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"miracl-ja-corpus-22-12","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-ja-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\n\t\n\t\t\n\t\tMIRACL (ja) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ja-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ja-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL 🌍🙌🌏 (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval… See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ja-corpus-22-12.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"miracl-ja-queries-22-12","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-ja-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\n\t\n\t\t\n\t\tMIRACL (ja) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ja-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ja-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL 🌍🙌🌏 (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval… See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ja-queries-22-12.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"phantom-diffusion-dataset","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Phantom-Artist/phantom-diffusion-dataset","creator_name":"The Phantom","creator_url":"https://huggingface.co/Phantom-Artist","description":"Images trained for my phantom diffusion series.\nSince they are all AI generated images that are public domain under the US law, I claim it is legal to redistribute them as public domain.\nHowever, they might have copyright in your/their original country.\nStill, many countries including Japan allow us to use them for training an AI under their copyrights law, and because all the artists here are from Japan, I assume it should be allowed to reuse it for training globally.\n","first_N":5,"first_N_keywords":["English","Japanese","cc0-1.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"mconala","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/mconala","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"MCoNaLa is a Multilingual Code/Natural Language Challenge dataset with \n896 NL-Code pairs in three languages: Spanish, Japanese, and Russian.","first_N":5,"first_N_keywords":["text-generation","translation","Spanish","Japanese","Russian"],"keywords_longer_than_N":true},
	{"name":"wmt-da-human-evaluation","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation","creator_name":"Ricardo Rei","creator_url":"https://huggingface.co/RicardoRei","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains all DA human annotations from previous WMT News Translation shared tasks.\nThe data is organised into 8 columns:\n\nlp: language pair\nsrc: input text\nmt: translation\nref: reference translation\nscore: z score\nraw: direct assessment\nannotators: number of annotators\ndomain: domain of the input text (e.g. news)\nyear: collection year\n\nYou can also find the original data for each year in the results section https://www.statmt.org/wmt{YEAR}/results.html… See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation.","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Estonian"],"keywords_longer_than_N":true},
	{"name":"wmt-sqm-human-evaluation","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RicardoRei/wmt-sqm-human-evaluation","creator_name":"Ricardo Rei","creator_url":"https://huggingface.co/RicardoRei","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn 2022, several changes were made to the annotation procedure used in the WMT Translation task. In contrast to the standard DA (sliding scale from 0-100) used in previous years, in 2022 annotators performed DA+SQM (Direct Assessment + Scalar Quality Metric). In DA+SQM, the annotators still provide a raw score between 0 and 100, but also are presented with seven labeled tick marks. DA+SQM helps to stabilize scores across annotators (as compared to DA).\nThe data is… See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-sqm-human-evaluation.","first_N":5,"first_N_keywords":["Czech","German","English","Croatian","Japanese"],"keywords_longer_than_N":true},
	{"name":"Artificial-Super-Girlfriend-for-Dreambooth","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ThePioneer/Artificial-Super-Girlfriend-for-Dreambooth","creator_name":"The Pioneer","creator_url":"https://huggingface.co/ThePioneer","description":"This is a dataset of \"atashi,\" the artificial girlfriend of mine, which I used for the training of my new model based on ChaosMix.\nAll the images has 87 or more beauty score before cropping it to square (it could slightly change, however, because of my cropping), and many of them score 90 or more (which afaik do not exist in real person).\nFeel free to use them to reach a super beauty. Since the person is based on myself and is a fictional character, you don't have to worry about the portrait… See the full description on the dataset page: https://huggingface.co/datasets/ThePioneer/Artificial-Super-Girlfriend-for-Dreambooth.","first_N":5,"first_N_keywords":["English","Japanese","cc0-1.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof Wróbel","creator_url":"https://huggingface.co/djstrong","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"guanaco_belle_merge_v1.0","keyword":"japanese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Chinese-Vicuna/guanaco_belle_merge_v1.0","creator_name":"Chinese-Vicuna","creator_url":"https://huggingface.co/Chinese-Vicuna","description":"Thanks for Guanaco Dataset and Belle Dataset\nThis dataset was created by merging the above two datasets in a certain format so that they can be used for training our code Chinese-Vicuna\n","first_N":5,"first_N_keywords":["Chinese","English","Japanese","gpl-3.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"janli","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/janli","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"\n\t\n\t\t\n\t\tDataset Card for JaNLI\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe JaNLI (Japanese Adversarial NLI) dataset, inspired by the English HANS dataset, is designed to necessitate an understanding of Japanese linguistic phenomena and to illuminate the vulnerabilities of models.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe language data in JaNLI is in Japanese (BCP-47 ja-JP).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nWhen loading a specific configuration, users has to append a version dependent suffix:\nimport… See the full description on the dataset page: https://huggingface.co/datasets/hpprc/janli.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","other","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"WikiMatrix-v1-Ja_Zh-filtered","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/larryvrh/WikiMatrix-v1-Ja_Zh-filtered","creator_name":"larryvrh","creator_url":"https://huggingface.co/larryvrh","description":"Filtered and modified version of Japanese/Chinese language pair data from WikiMatrix v1.\n\n\t\n\t\t\n\t\n\t\n\t\tProcess steps:\n1. Basic regex based filtering / length checking to remove abnormal pairs.\n2. Semantic similarity filtering with a threshold value of 0.6, based on sentence-transformers/LaBSE.\n3. Convert all Traditional Chinese sentences into Simplified Chinese with zhconv.\n\t\n\n经过过滤和修改的日语/中文语言对数据，来自WikiMatrix v1。\n\n\t\n\t\t\n\t\t处理步骤：\n1. 基本的基于正则表达式的过滤/长度检查，以删除异常对。\n2.… See the full description on the dataset page: https://huggingface.co/datasets/larryvrh/WikiMatrix-v1-Ja_Zh-filtered.","first_N":5,"first_N_keywords":["translation","Japanese","Chinese","cc-by-sa-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"jsick","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/jsick","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"Japanese Sentences Involving Compositional Knowledge (JSICK) Dataset.\nJSICK is the Japanese NLI and STS dataset by manually translating the English dataset SICK (Marelli et al., 2014) into Japanese.\nWe hope that our dataset will be useful in research for realizing more advanced models that are capable of appropriately performing multilingual compositional inference.\n(from official website)","first_N":5,"first_N_keywords":["sentence-similarity","text-classification","natural-language-inference","semantic-similarity-scoring","expert-generated"],"keywords_longer_than_N":true},
	{"name":"guanaco_jp","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aruno/guanaco_jp","creator_name":"Arnaud","creator_url":"https://huggingface.co/Aruno","description":"Japanese Prompt of GuanacoDataset extracted using langdetect.\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"wiki40b_ja","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fujiki/wiki40b_ja","creator_name":"fujiki","creator_url":"https://huggingface.co/fujiki","description":"This dataset is a reformatted version of the Japanese portion of wiki40b dataset.\nWhen you use this dataset, please cite the original paper:\n@inproceedings{guo-etal-2020-wiki,\n    title = \"{W}iki-40{B}: Multilingual Language Model Dataset\",\n    author = \"Guo, Mandy  and\n      Dai, Zihang  and\n      Vrande{\\v{c}}i{\\'c}, Denny  and\n      Al-Rfou, Rami\",\n    booktitle = \"Proceedings of the Twelfth Language Resources and Evaluation Conference\",\n    month = may,\n    year = \"2020\",\n    address =… See the full description on the dataset page: https://huggingface.co/datasets/fujiki/wiki40b_ja.","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"llm-japanese-dataset","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/izumi-lab/llm-japanese-dataset","creator_name":"Izumi Lab.","creator_url":"https://huggingface.co/izumi-lab","description":"\n\t\n\t\t\n\t\tllm-japanese-dataset\n\t\n\nLLM構築用の日本語インストラクション(チャット)データセット\n主に，英語で構築されたLLMモデルなどに対して，チャット(Instruction)応答タスクに関してLoRAなどでチューニングするために使用できます．\n※様々な公開言語資源を利用させていただきました．関係各位にはこの場を借りて御礼申し上げます．\n\n\t\n\t\t\n\t\tupdates\n\t\n\n2023/5/15にAlpaca datasetがNCにライセンス変更されたことに対応し，安心してご利用いただけるように，データセットから当該データセットをドロップしました．\nv1.0.1にて，ドロップ後のデータセットをご利用いただけます．\n2024/1/4にWikipedia summaryに空白文字のみで構成される出力を削除することに対応し，Wikipediaのバージョンアップデート(20240101)をしました(v1.0.2)．\n2024/1/18にAsian Language Treebank (ALT)データセットの欠損した出力を削除しました(v1.0.3)．… See the full description on the dataset page: https://huggingface.co/datasets/izumi-lab/llm-japanese-dataset.","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"oasst1-89k-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kunishou/oasst1-89k-ja","creator_name":"kunishou","creator_url":"https://huggingface.co/kunishou","description":"\nThis dataset was created by automatically translating \"OpenAssistant/oasst1\" into Japanese.  \nThe \"ng_translation\" flag indicates that the translation was not successful, and \"1\" means that the translation failed.Therefore, for data with \"1\", \"text\" and \"text_en\" contain the same text.  \nUpdate:  \n\n2023/11/12oasst1-89k-jaをチャット形式に変換したoasst1-chat-44k-jaを公開しました。  \n2023/10/21自動翻訳によるコード関連データの翻訳誤り2000箇所程度を手動で修正しました。\n\n修正イメージを表示\n\n修正前\n\nもちろん！これは、Flask… See the full description on the dataset page: https://huggingface.co/datasets/kunishou/oasst1-89k-ja.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"ja-zh-twitter-translate","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Nekofox/ja-zh-twitter-translate","creator_name":"Huang","creator_url":"https://huggingface.co/Nekofox","description":"translate by @Nekofoxtweet (me)\ntwitter source from @RindouMikoto\n","first_N":5,"first_N_keywords":["translation","Chinese","Japanese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"ShareGPT-Processed","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zetavg/ShareGPT-Processed","creator_name":"Pokai Chang","creator_url":"https://huggingface.co/zetavg","description":"\n\t\n\t\t\n\t\tShareGPT-Processed\n\t\n\nThe RyokoAI/ShareGPT52K dataset, converted to Markdown and labeled with the language used.\n\n\t\n\t\t\n\t\tAcknowledgements\n\t\n\n\nvinta/pangu.js — To insert whitespace between CJK (Chinese, Japanese, Korean) and half-width characters (alphabetical letters, numerical digits and symbols).\nmatthewwithanm/python-markdownify — Provides a starting point to convert HTML to Markdown.\nBYVoid/OpenCC — Conversions between Traditional Chinese and Simplified Chinese.\naboSamoor/polyglot… See the full description on the dataset page: https://huggingface.co/datasets/zetavg/ShareGPT-Processed.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","Spanish","Japanese"],"keywords_longer_than_N":true},
	{"name":"alpaca_cleaned_ja_json","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shi3z/alpaca_cleaned_ja_json","creator_name":"Ryo Shimizu","creator_url":"https://huggingface.co/shi3z","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation… See the full description on the dataset page: https://huggingface.co/datasets/shi3z/alpaca_cleaned_ja_json.","first_N":5,"first_N_keywords":["text-generation","Japanese","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"rsd-ists-2016","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016","creator_name":"University of Zurich, Department of Computational Linguistics","creator_url":"https://huggingface.co/ZurichNLP","description":"Training and test data for the task of Recognizing Semantic Differences (RSD).\nSee the paper for details on how the dataset was created, and see our code at https://github.com/ZurichNLP/recognizing-semantic-differences for an example of how to use the data for evaluation.\nThe data are derived from the SemEval-2016 Task 2 for Interpretable Semantic Textual Similarity organized by Agirre et al. (2016).\nThe original URLs of the data are:\n\nTrain:… See the full description on the dataset page: https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016.","first_N":5,"first_N_keywords":["token-classification","machine-generated","English","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs 🧡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processing… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"liz-nojaloli-ja-ds","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ebisuke/liz-nojaloli-ja-ds","creator_name":"ebisuke","creator_url":"https://huggingface.co/ebisuke","description":"\n\t\n\t\t\n\t\n\t\n\t\tebisuke/liz-nojaloli-ja-ds\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tLicense\n\t\n\nMIT License  \n\n\t\n\t\t\n\t\n\t\n\t\tDescription\n\t\n\nebisuke/liz-nojaloli-jaの学習元のデータセットです。私（ebisuke）の手打ちのデータセットになります。pythonのコードについてはqiitaを参照している場合があります。\n\n\t\n\t\t\n\t\n\t\n\t\tPlan\n\t\n\n\nRLHF用のデータセットの準備をしてみる。\n\n","first_N":5,"first_N_keywords":["Japanese","mit","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"llm-japanese-dataset-vanilla","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/izumi-lab/llm-japanese-dataset-vanilla","creator_name":"Izumi Lab.","creator_url":"https://huggingface.co/izumi-lab","description":"\n\t\n\t\t\n\t\tllm-japanese-dataset-vanilla\n\t\n\nLLM構築用の日本語チャットデータセット\nizumi-lab/llm-japanese-dataset から，日英翻訳のデータセット等を抜いたものです．\n主に，日本語LLMモデルなどに対して，チャット(Instruction)応答タスクに関してLoRAなどでチューニングするために使用できます．\n※様々な公開言語資源を利用させていただきました．関係各位にはこの場を借りて御礼申し上げます．\n\n\t\n\t\t\n\t\tデータの詳細\n\t\n\nデータの詳細は，izumi-lab/llm-japanese-dataset に関する，以下の論文を参照してください．\n\n日本語: https://jxiv.jst.go.jp/index.php/jxiv/preprint/view/383\n英語: https://arxiv.org/abs/2305.12720\nGitHub: https://github.com/masanorihirano/llm-japanese-dataset\n最新情報: llm.msuzuki.me.… See the full description on the dataset page: https://huggingface.co/datasets/izumi-lab/llm-japanese-dataset-vanilla.","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"hh-rlhf-helpful-base-ja","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nakayama/hh-rlhf-helpful-base-ja","creator_name":"Ren Nakayama","creator_url":"https://huggingface.co/nakayama","description":"https://github.com/anthropics/hh-rlhf　の内容のうち、helpful-base内のchosenに記載されている英文をfuguMTで翻訳、うまく翻訳できていないものを除外、修正したものです。  \n","first_N":5,"first_N_keywords":["Japanese","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"japanese_hh-rlhf-49k","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fujiki/japanese_hh-rlhf-49k","creator_name":"fujiki","creator_url":"https://huggingface.co/fujiki","description":"\nThis is a little bit different version of kunishou/hh-rlhf-49k-ja without ng_translation == 1 examples.\nPlease also refer to the original dataset kunishou/hh-rlhf-49k-ja.\n\n","first_N":5,"first_N_keywords":["Japanese","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"rachel","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shi3z/rachel","creator_name":"Ryo Shimizu","creator_url":"https://huggingface.co/shi3z","description":"This is a handmade dataset for making a Japanese chatbot. Conversations will continue to grow.\n","first_N":5,"first_N_keywords":["question-answering","Japanese","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"yokote_test","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Coaso/yokote_test","creator_name":"Coicihro","creator_url":"https://huggingface.co/Coaso","description":"test\n","first_N":5,"first_N_keywords":["table-question-answering","Japanese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"docs_on_several_languages","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages","creator_name":"Aleksey Timoshin","creator_url":"https://huggingface.co/AlekseyScorpi","description":"\n\t\n\t\t\n\t\tDataset Card for \"docs_on_several_languages\"\n\t\n\nThis dataset is a collection of different images in different languages.\nThe daset includes the following languages: Azerbaijani (az: 0), Belorussian (be: 1), Chinese (zh: 16), English (en: 2), Estonian (et: 3), Finnish (fn: 4), Georgian (gr: 5), Japanese (ja: 6), Korean (ko: 7), Kazakh (kk: 8), Latvian (lv: 10), Lithuanian (lt: 9), Mongolian (mn: 11), Norwegian (no: 12), Polish (pl: 13), Russian (ru: 14), Ukranian (uk: 15).\nEach language… See the full description on the dataset page: https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages.","first_N":5,"first_N_keywords":["text-classification","translation","feature-extraction","Azerbaijani","Belarusian"],"keywords_longer_than_N":true},
	{"name":"SREDFM","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Babelscape/SREDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\nFirst, we present SRED\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}.","first_N":5,"first_N_keywords":["token-classification","Arabic","Catalan","German","Greek"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"JAQKET","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kumapo/JAQKET","creator_name":"kumapo","creator_url":"https://huggingface.co/kumapo","description":"JAQKET: JApanese Questions on Knowledge of EnTitie","first_N":5,"first_N_keywords":["multiple-choice","question-answering","Japanese","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"rakuda-questions","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuzuai/rakuda-questions","creator_name":"yuzuai","creator_url":"https://huggingface.co/yuzuai","description":"\n\t\n\t\t\n\t\tRakuda - Questions for Japanese models\n\t\n\nRepository: https://github.com/yuzu-ai/japanese-llm-ranking\nThis is a set of 40 questions in Japanese about Japanese-specific topics designed to evaluate the capabilities of AI Assistants in Japanese.\nThe questions are evenly distributed between four categories: history, society, government, and geography. \nQuestions in the first three categories are open-ended, while the geography questions are more specific.\nAnswers to these questions can be… See the full description on the dataset page: https://huggingface.co/datasets/yuzuai/rakuda-questions.","first_N":5,"first_N_keywords":["question-answering","original","Japanese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"guanaco_ja","keyword":"japanese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fujiki/guanaco_ja","creator_name":"fujiki","creator_url":"https://huggingface.co/fujiki","description":"\nThis is a Japanese portion of the Guanaco dataset.\nYou can also refer to other similar datasets like inu-ai/alpaca-guanaco-japanese-gpt-1b.\n\n","first_N":5,"first_N_keywords":["Japanese","gpl-3.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"aozorabunko-clean","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/globis-university/aozorabunko-clean","creator_name":"GLOBIS University","creator_url":"https://huggingface.co/globis-university","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset provides a convenient and user-friendly format of data from Aozora Bunko (青空文庫), a website that compiles public-domain books in Japan, ideal for Machine Learning applications.\n[For Japanese] 日本語での概要説明を Qiita に記載しました: https://qiita.com/akeyhero/items/b53eae1c0bc4d54e321f\n\n\t\n\t\t\n\t\tMethodology\n\t\n\nThe code to reproduce this dataset is made available on GitHub: globis-org/aozorabunko-exctractor.\n\n\t\n\t\t\n\t\t1. Data collection\n\t\n\nWe firstly downloaded the CSV file that… See the full description on the dataset page: https://huggingface.co/datasets/globis-university/aozorabunko-clean.","first_N":5,"first_N_keywords":["text-generation","text-classification","Japanese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\n\n\t\n\t\t\n\nToxic\nNeutral\nTotal\n\n\n\t\t\nmultilingual-train-deduplicated.csv… See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Spanish","Panjabi"],"keywords_longer_than_N":true},
	{"name":"den2niji","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/den2nova/den2niji","creator_name":"denden","creator_url":"https://huggingface.co/den2nova","description":"LoRAデータセット開示用データ。私がnijijourney v5で生成したイラストです。\n280枚、女性のイラストのみ収録。一部版権キャラクターが含まれます。\nモデルマージの透明性確保のためのデータセット公開ですが、収録した画像データとタグが記載されているテキストファイルはご自由にご利用頂けます。\nただし犯罪行為への利用や他人へ迷惑をかける行為に利用するのはおやめください。\nまた版権のあるキャラクターに関しましては、権利元の不利益になるようなご使用はおやめください。\nキャプションはwd14-taggerそのままで精査していません。\n\n\t\n\t\t\n\t\n\t\n\t\tLoRA本体もダウンロード可能です（SDHKv3.0で学習）\n\t\n\n","first_N":5,"first_N_keywords":["Japanese","cc0-1.0","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"CoTangent","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sudy-super/CoTangent","creator_name":"Sudy","creator_url":"https://huggingface.co/sudy-super","description":"CoTangentは人手で作成された高品質でクリーンな100セットの日本語CoT用データセットです。\nCoTangent_ja.json: CoT部分とoutput部分が繋がっています。\nCoTangent_separated_ja.json: CoT部分とoutput部分が分離されていますが、CoTangent_ja.jsonの方が繋ぎが自然です。\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"all-scam-spam","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\n1040 rows of balanced data, consisting of casual conversations and scam emails in ≈10 languages, were manually collected and annotated by me, with some help from ChatGPT.\n\n\n\n\t\n\t\t\n\t\tSome preprcoessing algorithms\n\t\n\n\nspam_assassin.js, followed by spam_assassin.py\nenron_spam.py\n\n\n\n\n\t\n\t\t\n\t\tData composition\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTo make the text… See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Norwegian","Spanish","Somali"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"onepiece-characters","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yjg30737/onepiece-characters","creator_name":"yjg","creator_url":"https://huggingface.co/yjg30737","description":"\n\t\n\t\t\n\t\n\t\n\t\tonepiece-character\n\t\n\nThis is a dataset created from crawling the One Piece Fandom on 2023-07-08.\n","first_N":5,"first_N_keywords":["table-question-answering","English","Japanese","Korean","mit"],"keywords_longer_than_N":true},
	{"name":"mc4-japanese-data","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Atom007/mc4-japanese-data","creator_name":"Shrikant Koltur ","creator_url":"https://huggingface.co/Atom007","description":"Reference https://huggingface.co/datasets/mc4\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"malicious-website-features-2.4M","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"Important Notice:\n\nA subset of the URL dataset is from Kaggle, and the Kaggle datasets contained 10%-15% mislabelled data. See this dicussion I opened for some false positives. I have contacted Kaggle regarding their erroneous \"Usability\" score calculation for these unreliable datasets.\nThe feature extraction methods shown here are not robust at all in 2023, and there're even silly mistakes in 3 functions: not_indexed_by_google, domain_registration_length, and age_of_domain.\n\n\n\nThe features… See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M.","first_N":5,"first_N_keywords":["text-classification","feature-extraction","tabular-classification","Norwegian","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"oscar2301-ja-filter-ja-normal","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/izumi-lab/oscar2301-ja-filter-ja-normal","creator_name":"Izumi Lab.","creator_url":"https://huggingface.co/izumi-lab","description":"\n\t\n\t\t\n\t\tDataset Card for \"oscar2301-ja-filter-ja-normal\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["Japanese","cc0-1.0","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"dialogsum-ja","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sudy-super/dialogsum-ja","creator_name":"Sudy","creator_url":"https://huggingface.co/sudy-super","description":"dialogsum-ja\nこのデータセットはdialogsum、CSDSなどを翻訳した日本語対話要約データセットです。\n元のデータセット\nknkarthick/dialogsum https://huggingface.co/datasets/knkarthick/dialogsum\nxiaolinAndy/CSDS https://github.com/xiaolinAndy/CSDS\n","first_N":5,"first_N_keywords":["summarization","Japanese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"MissingKeys","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RyokoExtra/MissingKeys","creator_name":"RyokoAI Extra","creator_url":"https://huggingface.co/RyokoExtra","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for MissingKeys\n\t\n\nNOTE: This contains old data before 10/04/24. The uploader has moved to here!\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nMissingKeys is a raw dataset archive of the misskey.io network.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is primarily intended for unsupervised training of text generation models; however, it may be useful for other purposes.\n\ntext-classification\ntext-generation\n\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nPrimarily japanese, however there… See the full description on the dataset page: https://huggingface.co/datasets/RyokoExtra/MissingKeys.","first_N":5,"first_N_keywords":["text-classification","text-generation","text-to-image","text-to-video","Japanese"],"keywords_longer_than_N":true},
	{"name":"japan-law","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/y2lan/japan-law","creator_name":"lan","creator_url":"https://huggingface.co/y2lan","description":"\n\t\n\t\t\n\t\tJapanese Laws\n\t\n\nThis dataset comprises 8.75K law records retrieved from the official Japanese government website e-Gov. Each entry furnishes comprehensive details about a particular law, encapsulating its number, title, unique ID, the date it came into effect, and its complete text.\nTo ensure the dataset's uniqueness, deduplication was executed based on the most recent effective version as of August 1, 2023.\nA typical entry in this dataset is structured as follows:\n{\n    \"num\": \"Law… See the full description on the dataset page: https://huggingface.co/datasets/y2lan/japan-law.","first_N":5,"first_N_keywords":["summarization","text-generation","question-answering","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"massive_translation_dataset","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Amani27/massive_translation_dataset","creator_name":"Amani N","creator_url":"https://huggingface.co/Amani27","description":"\n\t\n\t\t\n\t\tDataset Card for Massive Dataset for Translation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is derived from AmazonScience/MASSIVE dataset for translation task purpose.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTranslation\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en_US)\nGerman (de_DE)\nHindi (hi_IN)\nSpanish (es_ES)\nFrench (fr_FR)\nItalian (it_IT)\nArabic (ar_SA)\nDutch (nl_NL)\nJapanese (ja_JP)\nPortugese (pt_PT)\n\n","first_N":5,"first_N_keywords":["translation","English","German","Spanish","Hindi"],"keywords_longer_than_N":true},
	{"name":"humaneval-ja-v0.6","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/humaneval-ja-v0.6","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\n\t\n\t\t\n\t\tDataset Card for \"humaneval-ja\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["text2text-generation","openai_humaneval","Japanese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"MMLU_Japanese","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/MMLU_Japanese","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"Japanese version of MMLU dataset tranlasted by gpt-3.5-turbo.The dataset is used in the research related to MultilingualSIFT. \n","first_N":5,"first_N_keywords":["Japanese","mit","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"oasst1-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tombailey/oasst1-ja","creator_name":"Tom Bailey","creator_url":"https://huggingface.co/tombailey","description":"\n\t\n\t\t\n\t\toasst1-ja\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nBased on OpenAssistant Conversations Dataset (OASST1) but only the messages labeled as Japanese.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe format is changed to ### Human: ...### Assistant: ....\nEach row of the text file contains a single human message and the assistant's reply. This means a single row may be missing context from messages earlier in the conversation.\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","< 1K","text","Text"],"keywords_longer_than_N":true},
	{"name":"calculation","keyword":"japanese","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/OzoneAsai/calculation","creator_name":"AsaiTaka","creator_url":"https://huggingface.co/OzoneAsai","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Calculation\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tsize\n\t\n\n  JSON file: output1.json≒1.3GB\n  ~\n    output60.json\n     In total 70 ~ 80GB\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nen: Calculation. Its range will be expanded later.\nzh: 计算。其范围将在以后扩展。\nde: Berechnung. Der Umfang wird später erweitert werden.\nru: Расчет. Его диапазон будет расширен позже.\nko: 계산. 범위는 나중에 확장될 것입니다.\nfr: Calcul. Sa portée sera étendue ultérieurement.\nja: 計算。範囲は後で拡張されます。\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nen:… See the full description on the dataset page: https://huggingface.co/datasets/OzoneAsai/calculation.","first_N":5,"first_N_keywords":["English","Chinese","German","Russian","Korean"],"keywords_longer_than_N":true},
	{"name":"factorExpander","keyword":"japanese","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/OzoneAsai/factorExpander","creator_name":"AsaiTaka","creator_url":"https://huggingface.co/OzoneAsai","description":"\n\t\n\t\t\n\t\tPolynomial Expansion and Factoring Dataset\n\t\n\nThis dataset contains problem and solution pairs for polynomial expansion and factoring. Each problem is a result of expanding and factoring the (x + n)^2 form expression, where n takes values from -1000 to 1000.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nfactorized_dataset.csv: CSV file containing the dataset.\nREADME.md: This file that provides an overview and usage instructions for the dataset.\n\n\n\t\n\t\t\n\t\tData Format\n\t\n\nThe CSV file of the dataset… See the full description on the dataset page: https://huggingface.co/datasets/OzoneAsai/factorExpander.","first_N":5,"first_N_keywords":["Japanese","wtfpl","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"diet-members-voice-embeddings","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yutakobayashi/diet-members-voice-embeddings","creator_name":"Yuta Kobayashi","creator_url":"https://huggingface.co/yutakobayashi","description":"\n\t\n\t\t\n\t\n\t\n\t\tdiet-members-voice-embeddings\n\t\n\n日本の国会議員の声を speechbrain/spkrec-ecapa-voxcelebで embedding したデータセットです。話者分離などのタスクで使用できます。\n国会中継や演説等の分析など、ご自由にお使いください。\n\n\t\n\t\t\n\t\n\t\n\t\t使用例\n\t\n\n以下はトランスクリプトと音声ファイルを元に、話者分析を行う例です。\npip install pandas numpy wave ast scipy pyannote.audio\n\nimport pandas as pd\nimport numpy as np\nimport contextlib\nimport wave\nimport ast\nfrom typing import List, Tuple\nfrom scipy.spatial.distance import cosine\nfrom pyannote.audio import Audio\nfrom pyannote.core import Segment\nfrom… See the full description on the dataset page: https://huggingface.co/datasets/yutakobayashi/diet-members-voice-embeddings.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","Audio","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"aozorabunko-chats","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/globis-university/aozorabunko-chats","creator_name":"GLOBIS University","creator_url":"https://huggingface.co/globis-university","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is of conversations extracted from Aozora Bunko (青空文庫), which collects public-domain books in Japan, using a simple heuristic approach.\n[For Japanese] 日本語での概要説明を Qiita に記載しました: https://qiita.com/akeyhero/items/b53eae1c0bc4d54e321f\n\n\t\n\t\t\n\t\tMethod\n\t\n\nFirst, lines surrounded by quotation mark pairs (「」) are extracted as utterances from the text field of globis-university/aozorabunko-clean.\nThen, consecutive utterances are collected and grouped together.\nThe code… See the full description on the dataset page: https://huggingface.co/datasets/globis-university/aozorabunko-chats.","first_N":5,"first_N_keywords":["text-generation","text-classification","Japanese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"JapaneseGoblin","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RyokoExtra/JapaneseGoblin","creator_name":"RyokoAI Extra","creator_url":"https://huggingface.co/RyokoExtra","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for JapaneseGoblin\n\t\n\nWE ARE THE JAPANESE GOBLIN!\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nJapaneseGoblin is a dump of en.touhouwiki.net wiki.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is primarily intended for unsupervised training of text generation models; however, it may be useful for other purposes.\n\ntext-classification\ntext-generation\n\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nPrimarily english, however there are also japanese as well.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure… See the full description on the dataset page: https://huggingface.co/datasets/RyokoExtra/JapaneseGoblin.","first_N":5,"first_N_keywords":["text-classification","text-generation","text-to-image","text-to-video","Japanese"],"keywords_longer_than_N":true},
	{"name":"4typeCalculation","keyword":"japanese","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/OzoneAsai/4typeCalculation","creator_name":"AsaiTaka","creator_url":"https://huggingface.co/OzoneAsai","description":"\n\t\n\t\t\n\t\tDataset Card for Calculation\n\t\n\n\n\t\n\t\t\n\t\tsize\n\t\n\n  JSON file: output1.json≒1.3GB\n  ~\n    output60.json\n     In total 70 ~ 80GB\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nen: Calculation. Its range will be expanded later.\nzh: 计算。其范围将在以后扩展。\nde: Berechnung. Der Umfang wird später erweitert werden.\nru: Расчет. Его диапазон будет расширен позже.\nko: 계산. 범위는 나중에 확장될 것입니다.\nfr: Calcul. Sa portée sera étendue ultérieurement.\nja: 計算。範囲は後で拡張されます。\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nen: conversation… See the full description on the dataset page: https://huggingface.co/datasets/OzoneAsai/4typeCalculation.","first_N":5,"first_N_keywords":["English","Chinese","German","Russian","Korean"],"keywords_longer_than_N":true},
	{"name":"nagisa_stopwords","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/taishi-i/nagisa_stopwords","creator_name":"Taishi Ikeda","creator_url":"https://huggingface.co/taishi-i","description":"Japanese stopwords for nagisa.","first_N":5,"first_N_keywords":["Japanese","mit","< 1K","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"elementray_l","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/if001/elementray_l","creator_name":"issei fujimoto","creator_url":"https://huggingface.co/if001","description":"calm3-22bを使って簡単な日本語の例文を作成したデータセットです。\n以下のパターンが含まれるように一文を作成しています。\n生成に失敗しているものはクリーニングしています。\n    \"です/だ (肯定文)\",\n    \"ではありません/じゃない (否定文)\",\n    \"〜ます (動詞の丁寧形)\",\n    \"〜ません (動詞の否定形)\",\n    \"〜たい (希望・願望)\",\n    \"〜ている (進行形)\",\n    \"〜てください (依頼)\",\n    \"〜てもいいですか (許可)\",\n    \"〜なければなりません/〜なきゃいけない (義務)\",\n    \"〜でしょう/〜だろう (推測)\",\n    \"〜が好きです/嫌いです (好み)\",\n    \"〜と思います (意見・思考)\",\n    \"〜から/〜ので (理由)\",\n    \"〜のが好きです/嫌いです (動作の好み)\",\n    \"〜でしょうか (丁寧な質問)\",\n    \"〜てしまう (完了・後悔)\",\n    \"〜ながら (同時進行)\",\n    \"〜ば/〜たら (仮定形)\",\n    \"〜ておく (準備)\"… See the full description on the dataset page: https://huggingface.co/datasets/if001/elementray_l.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"weather_forecast_japan","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jniimi/weather_forecast_japan","creator_name":"Junichiro Niimi","creator_url":"https://huggingface.co/jniimi","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains daily-collected weather forecasts for up to seven days ahead for all the meteorological observatories in Japan, published by the Japan Meteorological Agency (JMA) at https://www.jma.go.jp/bosai/forecast/. \nWe collect, structurize, and accumulate the prediction since the page is overridden whenever the information is updated. \nThe data is automatically updated daily using GitHub Actions. Since the actual forecasts are published multiple times a day, we… See the full description on the dataset page: https://huggingface.co/datasets/jniimi/weather_forecast_japan.","first_N":5,"first_N_keywords":["tabular-regression","tabular-classification","Japanese","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"FaithCAMERA","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyberagent/FaithCAMERA","creator_name":"CyberAgent","creator_url":"https://huggingface.co/cyberagent","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nIn ad text generation (ATG), desirable ad text is both faithful and informative. That is, it should be faithful to the input document, while at the same time containing important information that appeals to potential customers.\nThe existing evaluation data, CAMERA (Mita et al.,2024), is suitable for evaluating informativeness, as it consists of reference ad texts created by ad creators. However, these references often include information unfaithful to the input, which is a… See the full description on the dataset page: https://huggingface.co/datasets/cyberagent/FaithCAMERA.","first_N":5,"first_N_keywords":["text-generation","Japanese","cc-by-sa-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Magpie-Tanuki-8B-annotated-96k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Magpie-Tanuki-8B-annotated-96k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tMagpie-Tanuki-8B-annotated-96k\n\t\n\nMagpieの手法をweblab-GENIAC/Tanuki-8B-dpo-v1.0に対して適用し作成したデータセットであるAratako/Magpie-Tanuki-8B-97kに対して、cyberagent/calm3-22b-chatを用いてinstructionに対して難易度、クオリティ、カテゴリをアノテーションしたデータセットです。\n\n\t\n\t\t\n\t\n\t\n\t\tアノテーションのプロンプト\n\t\n\ncalm3によるアノテーションにはそれぞれ以下のプロンプトを利用しました。\n\n\t\n\t\t\n\t\n\t\n\t\t難易度のアノテーション\n\t\n\n# 指示\n\nまず、与えられたユーザーの意図を特定し、その後、ユーザーのクエリの内容に基づいて難易度レベルをラベル付けしてください。\n\n## ユーザーのクエリ\n```\n{input}\n```\n\n## 出力フォーマット\nユーザーのクエリに基づき、まずユーザーの意図を特定し、そのクエリを解決するために必要な知識を明示してください。\nその後、難易度レベルを `very… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Magpie-Tanuki-8B-annotated-96k.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"multilingual-coco","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/romrawinjp/multilingual-coco","creator_name":"Romrawin Chumpu","creator_url":"https://huggingface.co/romrawinjp","description":"\n\t\n\t\t\n\t\tMultilingual Common Objects in Context (COCO) Dataset\n\t\n\nThis dataset is a collection of multiple language open-source captions of COCO dataset. \nThe split in this dataset is set according to Andrej Karpathy's split from dataset_coco.json file. The collection was created specifically for simplicity of use in training and evaluation pipeline by non-commercial and research purposes. The COCO images dataset is licensed under a Creative Commons Attribution 4.0 License.… See the full description on the dataset page: https://huggingface.co/datasets/romrawinjp/multilingual-coco.","first_N":5,"first_N_keywords":["image-to-text","English","Thai","Russian","Japanese"],"keywords_longer_than_N":true},
	{"name":"m-ArenaHard","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/m-ArenaHard","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for m-ArenaHard\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be used… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-ArenaHard.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"e_gov_chunked","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nlp-waseda/e_gov_chunked","creator_name":"Kawahara Lab at Waseda University","creator_url":"https://huggingface.co/nlp-waseda","description":"\n\t\n\t\t\n\t\tAbstract\n\t\n\nThis is the Japapnese law dataset obtained from e-Gov (Date of download: Oct. 20th, 2024)\nEach piece of text data is chunked into fewer than 4,096 tokens.\nNot chunked version is available HERE\n\n\t\n\t\t\n\t\tData Format\n\t\n\nEach data is consist of 2 fields, \"text\" and \"metadata\".\n\n\"text\" fields contains the legal texts, which are expected to be mainly used.\n\"metadata\" fields contains additional information including 10 subfields below:\n\"Era\": The Japanese Era when the law is… See the full description on the dataset page: https://huggingface.co/datasets/nlp-waseda/e_gov_chunked.","first_N":5,"first_N_keywords":["Japanese","cc-by-4.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"e_gov","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nlp-waseda/e_gov","creator_name":"Kawahara Lab at Waseda University","creator_url":"https://huggingface.co/nlp-waseda","description":"\n\t\n\t\t\n\t\tAbstract\n\t\n\nThis is the Japapnese law dataset obtained from e-Gov (Date of download: Oct. 20th, 2024)\n\n\t\n\t\t\n\t\tData Format\n\t\n\nEach data is consist of 2 fields, \"text\" and \"metadata\".\n\n\"text\" fields contains the legal texts, which are expected to be mainly used.\n\"metadata\" fields contains additional information including 9 subfields below:\n\"Era\": The Japanese Era when the law is promulgated such as \"Showa\".\n\"Lang\": The language the text is written in. All of them are Japanese.\n\"LawType\":… See the full description on the dataset page: https://huggingface.co/datasets/nlp-waseda/e_gov.","first_N":5,"first_N_keywords":["Japanese","cc-by-4.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"danbooru2024-latents-sdxl-1ktar","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/6DammK9/danbooru2024-latents-sdxl-1ktar","creator_name":"Darren Laurie","creator_url":"https://huggingface.co/6DammK9","description":"\n\t\n\t\t\n\t\tDanbooru 2024 SDXL VAE latents in 1k tar\n\t\n\n\nDedicated dataset to align deepghs/danbooru2024-webp-4Mpixel. \"4MP-Focus\" for average raw image resolution. \nLatents are ARB with maximum size of 1024x1024 as the recommended setting in kohyas. Major reason is to make sure I can finetune with RTX 3090. VRAM usage will raise drastically after 1024.\nGenerated from prepare_buckets_latents_v2.py, modified from prepare_buckets_latents.py.\nUsed for kohya-ss/sd-scripts. In theory it may replace… See the full description on the dataset page: https://huggingface.co/datasets/6DammK9/danbooru2024-latents-sdxl-1ktar.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","text-to-image","no-annotation","danbooru"],"keywords_longer_than_N":true},
	{"name":"nick_name_from_hiroiki-ariyoshi","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/baxin/nick_name_from_hiroiki-ariyoshi","creator_name":"koji","creator_url":"https://huggingface.co/baxin","description":"\n\t\n\t\t\n\t\tdata format\n\t\n\n{\n  \"name\": \"person_name\",\n  \"nickname\": \"person_nickname\"\n}\n\n","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"LAION-art-EN-improved-captions-translate","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaeyong2/LAION-art-EN-improved-captions-translate","creator_name":"jeongjaeyong","creator_url":"https://huggingface.co/jaeyong2","description":"\n\t\n\t\t\n\t\tDevelopment Process\n\t\n\n\nsource dataset from recastai/LAION-art-EN-improved-captions\nWe used Qwen/Qwen2-72B-Instruct model to translate.\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\n\nQwen/Qwen2.5-72B-Instruct : https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/LICENSE\nrecastai/LAION-art-EN-improved-captions : https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/cc-by-4.0.md\n\n\n\t\n\t\t\n\t\n\t\n\t\tAcknowledgement\n\t\n\nThis research is supported by TPU Research Cloud program.\n","first_N":5,"first_N_keywords":["Korean","Japanese","Thai","Vietnamese","Hindi"],"keywords_longer_than_N":true},
	{"name":"wmt-da-human-evaluation-long-context","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLong-context / document-level dataset for Quality Estimation of Machine Translation.\nIt is an augmented variant of the sentence-level WMT DA Human Evaluation dataset.\nIn addition to individual sentences, it contains augmentations of 2, 4, 8, 16, and 32 sentences, among each language pair lp and domain.\nThe raw column represents a weighted average of scores of augmented sentences using character lengths of src and mt as weights.\nThe code used to apply the augmentation… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context.","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Estonian"],"keywords_longer_than_N":true},
	{"name":"TALPCo","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/TALPCo","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"TALPCoデータセットの日英翻訳ペアをHuggingFace形式に変換したデータセットです。日本語の生データには分かち書き由来の空白文字が含まれていたため、それについは削除してあります。ライセンスは元データセットの記述に従い、CC-BY 4.0とします。\n\nGitHub\n論文\n\nNomoto, Hiroki, Kenji Okano, David Moeljadi and Hideo Sawada. 2018. \nTUFS Asian Language Parallel Corpus (TALPCo).\nProceedings of the Twenty-Fourth Annual Meeting of the Association for Natural Language Processing, 436-439.\n\n","first_N":5,"first_N_keywords":["translation","Japanese","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"open-dict-words-ipa","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","description":"\n\t\n\t\t\n\t\tOpen-dict Words IPA\n\t\n\nThis dataset is a copy of https://github.com/open-dict-data/ipa-dict\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nIPA data is currently available for the following languages:\n\n\t\n\t\t\nLanguage\nCode\n\n\n\t\t\nar\nArabic (Modern Standard)\n\n\nde\nGerman\n\n\nen_UK\nEnglish (Received Pronunciation)\n\n\nen_US\nEnglish (General American)\n\n\neo\nEsperanto\n\n\nes_ES\nSpanish (Spain)\n\n\nes_MX\nSpanish (Mexico)\n\n\nfa\nPersian\n\n\nfi\nFinnish\n\n\nfr_FR\nFrench (France)\n\n\nfr_QC\nFrench (Québec)\n\n\nis\nIcelandic\n\n\nja\nJapanese\n\n\njam… See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa.","first_N":5,"first_N_keywords":["Arabic","German","English","Esperanto","Spanish"],"keywords_longer_than_N":true},
	{"name":"e621-2024-webp-4Mpixel_index","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deepghs/e621-2024-webp-4Mpixel_index","creator_name":"DeepGHS","creator_url":"https://huggingface.co/deepghs","description":"Index files of NebulaeWis/e621-2024-webp-4Mpixel.\nYou can download images from NebulaeWis/e621-2024-webp-4Mpixel with cheesechaser.\nfrom cheesechaser.datapool import E621NewestWebpDataPool\n\npool = E621NewestWebpDataPool()\n\n# download e621 #2010000-2010300, to directory /data/e621\npool.batch_download_to_directory(\n    resource_ids=range(2010000, 2010300),\n    dst_dir='/data/e621',\n    max_workers=12,\n)\n\n","first_N":5,"first_N_keywords":["image-classification","image-to-image","text-to-image","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\nsource: the source sentence.\nchosen: the preferred translation.\nreject: the dis-preferred translation.\ndirections: the translation direction.\n@misc{xu2024xalmaplugplay,\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\n      year={2024},\n      eprint={2410.03115}… See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"relaion2B-en-research-safe-japanese-translation","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-jp/relaion2B-en-research-safe-japanese-translation","creator_name":"LLM-jp","creator_url":"https://huggingface.co/llm-jp","description":"\n\t\n\t\t\n\t\trelaion2B-en-research-safe-japanese-translation\n\t\n\nThis dataset is the Japanese translation of the English subset of ReLAION-5B (laion/relaion2B-en-research-safe), translated by gemma-2-9b-it.\nWe used text2dataset for translating with open-weight LLMs. \nBy leveraging the fast LLM inference library vLLM, this tool enables the rapid translation of large English datasets into Japanese.\n\n\t\n\t\t\n\t\n\t\n\t\tPrompt\n\t\n\nThe following is the prompt used for translation with Gemma.\n\n You are an… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/relaion2B-en-research-safe-japanese-translation.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","1B - 10B","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"JA_audio_JA_text_180k_samples","keyword":"japanese","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sin2pi/JA_audio_JA_text_180k_samples","creator_name":"Danielle","creator_url":"https://huggingface.co/Sin2pi","description":"","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","text-to-speech","text-to-audio","Japanese"],"keywords_longer_than_N":true},
	{"name":"JA_audio_JA_text_180k_samples","keyword":"japanese","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sin2pi/JA_audio_JA_text_180k_samples","creator_name":"Danielle","creator_url":"https://huggingface.co/Sin2pi","description":"","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","text-to-speech","text-to-audio","Japanese"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xchat","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xchat","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"neulab/PangeaBench-xchat dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["visual-question-answering","Chinese","English","Hindi","Indonesian"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-tydiqa","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-tydiqa","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\n\t\n\t\t\n\t\tDataset Card for \"tydiqa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\nin the world. It contains language phenomena that would not be found in… See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-tydiqa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar_2023_filtered_and_ai_text_filtered","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rio-Rf/oscar_2023_filtered_and_ai_text_filtered","creator_name":"Rio Iwata","creator_url":"https://huggingface.co/Rio-Rf","description":"\n人間が作成したテキスト(OSCAR)とLLM生成テキスト(GPT-3.5 Turbo)から成るデータセット\nLLMで生成された日本語テキストの検出性能の検証のために作成した\n\n詳細はコードを参照\nhttps://github.com/Rio-Rf/Lab-CreateDataset\n","first_N":5,"first_N_keywords":["text-classification","text-generation","Japanese","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Tengentoppa-sft-qwen2.5-32b-reasoning-100k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-sft-qwen2.5-32b-reasoning-100k","creator_name":"Taisei Ozaki","creator_url":"https://huggingface.co/DeL-TaiseiOzaki","description":"\n\t\n\t\t\n\t\t合成日本語指示データセット\n\t\n\n\n\t\n\t\t\n\t\t概要\n\t\n\nこのデータセットは、大規模言語モデル（Qwen2.5-32B-instruct）を用いて自動生成された日本語の指示とそれに対する応答のコレクションです。データセットは指示付与型のタスクのための学習や評価に使用することを目的としています。\n\n\t\n\t\t\n\t\tデータセット仕様\n\t\n\n\nサンプル数: 125,000\n言語: 日本語\nフォーマット: JSONL\nライセンス: Apache-2.0\nサイズカテゴリ: 100K<n\n\n\n\t\n\t\t\n\t\t生成方法\n\t\n\nデータセットは以下のプロセスを通じて生成されました：\n\nQwen2.5-32B Instructモデルを使用\n各サンプルは3段階のプロセスで生成:\na) マルチペルソナに基づく多様な指示文の生成\nb) Chain-of-Thought (CoT) 指示文に対する回答手順を生成\nc) 回答生成\nc) self-refine後の回答\n\n\n生成の多様性を向上させるため、10種類のペルソナからランダムに1つ選んでシステムプロンプトに入力\n\n\n\t\n\t\t\n\t\tデータ構造… See the full description on the dataset page: https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-sft-qwen2.5-32b-reasoning-100k.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"mc-translation","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/efederici/mc-translation","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","description":"This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.\n\n\t\n\t\t\n\t\tWhy This Dataset?\n\t\n\nTranslation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specialized… See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation.","first_N":5,"first_N_keywords":["translation","English","Swahili","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"SingMOS","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TangRain/SingMOS","creator_name":"Tang","creator_url":"https://huggingface.co/TangRain","description":"paper link: SingMOS: An extensive Open-Source Singing Voice Dataset for MOS Prediction\nNOTICE: Our new paper has not been released and the information in SingMOS paper remain in SingMOS_v1. We will update it soon.\nIf you want to use our pretrained SingMOS model, you can visit our repo at Singing MOS Predictor.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nSingMOS includes 6583 Chinese and Japanese vocal clips, totaling 9.07 hours in duration. \nIt covers samples mainly in 16 kHz and a little in 24kHz and 44.1kHz.… See the full description on the dataset page: https://huggingface.co/datasets/TangRain/SingMOS.","first_N":5,"first_N_keywords":["Chinese","Japanese","cc-by-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Theresa","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Theresa","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Theresa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-generation","Chinese","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates from… See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"dataset-for-annotation","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/dataset-for-annotation","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"Aratako/dataset-for-annotation dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Theresa-Recording","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Theresa-Recording","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Theresa-Recording dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Japanese","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"ihyoki","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/ihyoki","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"hpprc/ihyoki dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"magpie-sft-v1.0","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-jp/magpie-sft-v1.0","creator_name":"LLM-jp","creator_url":"https://huggingface.co/llm-jp","description":"\n\t\n\t\t\n\t\tmagpie-sft-v1.0\n\t\n\nThis repository provides an instruction-tuning dataset developed by LLM-jp, a collaborative project launched in Japan.\nThis is a dataset of instruction and response pairs created using the Magpie method.\ncyberagent/calm3-22b-chat was used for generating the instructions, and Qwen/Qwen2.5-32B-Instruct was used for generating the responses.\n\n\t\n\t\t\n\t\n\t\n\t\tSend Questions to\n\t\n\nllm-jp(at)nii.ac.jp\n\n\t\n\t\t\n\t\n\t\n\t\tModel Card Authors\n\t\n\nThe names are listed in alphabetical order.… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/magpie-sft-v1.0.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"booru_tag_and_artist_20241208","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/supercatdoing/booru_tag_and_artist_20241208","creator_name":"supercatdoing","creator_url":"https://huggingface.co/supercatdoing","description":"\n\t\n\t\t\n\t\n\t\n\t\tbooru_tag_and_artist_20241208\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tAbout\n\t\n\nThis data set is a JSON file with tags and artists extracted from danbooru (2024/12/8 version)  \nAll data is pre-sorted by tag count.  \nA JSONL file is also available so that it can be used in environments where Apache allows Parquet files.  \nPlease use this as a reference when processing data locally, such as creating CSV files.  \nThis file was created based on the danbooru API.  \n\n\t\n\t\t\n\t\n\t\n\t\tFile description… See the full description on the dataset page: https://huggingface.co/datasets/supercatdoing/booru_tag_and_artist_20241208.","first_N":5,"first_N_keywords":["English","Japanese","cc-by-sa-4.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"parallel_corpus_game_2024","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bot-yaya/parallel_corpus_game_2024","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","description":"https://github.com/mnbvc-parallel-corpus-team/parallel_corpus_mnbvc\nMNBVC平行语料小组：游戏语料\n不定期更新，目前已收录的游戏语料文件，共29份：\n\n博德之门3\n赛博朋克2077\n黑暗之魂3\n底特律：化身为人\n饥荒\n艾尔登法环\n原神\n黑帝斯\n霍格沃兹之遗\nIb\n如龙8\n如龙7外传\n荒野大镖客2\n只狼：影逝二度\n文明6\n杀戮尖塔\n崩坏星穹铁道\n群星\n泰拉瑞亚\n巫师3\n魔女之泉3\n魔女之泉R\n鸣潮\n如龙3\n如龙4\n如龙5\n如龙6\n如龙极2\n如龙7\n\n","first_N":5,"first_N_keywords":["translation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU-Lite","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 16 languages, including English. It is \"lite\" version of the original Global-MMLU dataset 🌍.\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \nNOTE: Of the 16 languages presently included in Global-MMLU-Lite, 15… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite.","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"animelist-dataset","keyword":"japanese","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/labofsahil/animelist-dataset","creator_name":"Sahil","creator_url":"https://huggingface.co/labofsahil","description":"A JSON based anime dataset containing the most important meta data as well as cross references to various anime sites such as MAL, ANIDB, ANILIST, KITSU and more...\nCredits: https://github.com/manami-project/anime-offline-database\n","first_N":5,"first_N_keywords":["English","Japanese","agpl-3.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"amazon-esci-data","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/milistu/amazon-esci-data","creator_name":"Milutin Studen","creator_url":"https://huggingface.co/milistu","description":"\n\t\n\t\t\n\t\tAmazon Shopping Queries Dataset\n\t\n\nA comprehensive dataset for improving product search, ranking and recommendations, featuring query-product pairs with detailed relevance labels.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe dataset contains search queries paired with up to 40 potentially relevant products, each labeled using the ESCI system:\n\nExact match: Products that perfectly match the customer's search intent (e.g., searching \"iPhone 13\" and finding \"Apple iPhone 13 128GB\")\nSubstitute product:… See the full description on the dataset page: https://huggingface.co/datasets/milistu/amazon-esci-data.","first_N":5,"first_N_keywords":["text-classification","token-classification","text-generation","text2text-generation","sentence-similarity"],"keywords_longer_than_N":true},
	{"name":"stickers","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LiuliFox/stickers","creator_name":"LiuliFox","creator_url":"https://huggingface.co/LiuliFox","description":"\n\t\n\t\t\n\t\tるりのステッカー\n\t\n\njust for fun.\n","first_N":5,"first_N_keywords":["image-classification","Chinese","Japanese","English","mit"],"keywords_longer_than_N":true},
	{"name":"Synthetic-JP-EN-Coding-Dataset-801k-50k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Coding-Dataset-801k-50k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tSynthetic-JP-EN-Coding-Dataset-801k-50k\n\t\n\nAratako/Synthetic-JP-EN-Coding-Dataset-801kから英語部分5万件を抽出したデータセットです。\n中身や注意事項等については元データセットの概要をご確認ください。\n","first_N":5,"first_N_keywords":["Japanese","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"wiki-trans-en-ja","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/wiki-trans-en-ja","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"hpprc/wiki-trans-en-ja dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Japanese","English","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Rosmontis","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Rosmontis","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Rosmontis dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","Chinese","Japanese","Korean"],"keywords_longer_than_N":true},
	{"name":"Tengentoppa-sft-v1.0","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-sft-v1.0","creator_name":"Taisei Ozaki","creator_url":"https://huggingface.co/DeL-TaiseiOzaki","description":"\n\t\n\t\t\n\t\tTengentoppa corpus for sft (Combined Japanese Instruction Dataset)\n\t\n\n\n\t\n\t\t\n\t\t概要\n\t\n\nこのデータセットは、日本語の instruction-following データセット16個を統合して作成された大規模な教師あり学習用データセットです。様々なタスクや対話形式を含む多様なデータソースから構成されています。\n\n\t\n\t\t\n\t\tデータセット構成\n\t\n\n\n\t\n\t\t\n\t\t基本情報\n\t\n\n\nフォーマット: JSON\n各データポイントの構造:{\n  \"instruction\": \"指示/質問文\",\n  \"input\": \"追加の文脈や入力（オプション）\",\n  \"output\": \"応答/回答文\"\n}\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tデータセット変換コード\n\t\n\nデータセット作成に使用したコードは以下のGitHubリポジトリで公開しています：\ndataset-processor\n\n\t\n\t\t\n\t\n\t\n\t\t含まれるデータセット\n\t\n\n\nHachi-Alpaca_newans… See the full description on the dataset page: https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-sft-v1.0.","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"nanipilled","keyword":"japanese","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NaniDAO/nanipilled","creator_name":"Nani DAO","creator_url":"https://huggingface.co/NaniDAO","description":"NaniDAO/nanipilled dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","Japanese","agpl-3.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"demo","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eyl45/demo","creator_name":"Ethan","creator_url":"https://huggingface.co/eyl45","description":"eyl45/demo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","Korean","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"Our-Regional-Cuisines","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JunichiroMorita/Our-Regional-Cuisines","creator_name":"Junichiro Morita","creator_url":"https://huggingface.co/JunichiroMorita","description":"\n\t\n\t\t\n\t\tOur Regional Cuisines Database\n\t\n\n\"Our Regional Cuisines\" is a database created by Japan's Ministry of Agriculture, Forestry and Fisheries to preserve and pass on Washoku, a UNESCO Intangible Cultural Heritage. \nIt offers information on the origins, history, and recipes of regional dishes, along with cultural and geographical backgrounds. \nLaunched in 2019, the database supports home cooking, menu development, product creation, and research, promoting the rich diversity of Japan's food… See the full description on the dataset page: https://huggingface.co/datasets/JunichiroMorita/Our-Regional-Cuisines.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"2M-Belebele","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\t2M-Belebele\n\t\n\n\n\t\n\t\t\n\t\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\n\t\n\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs datasets as… See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.","first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Bulgarian","Panjabi","English"],"keywords_longer_than_N":true},
	{"name":"Asian-dataset","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Asian-dataset","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"Sakalti/Asian-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Japanese","apache-2.0","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"jamp","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zenless-lab/jamp","creator_name":"Zenless Lab","creator_url":"https://huggingface.co/zenless-lab","description":"\n\t\n\t\t\n\t\tJamp: Controlled Japanese Temporal Inference Dataset for Evaluating Generalization Capacity of Language Models\n\t\n\nJamp(tomo-vv/temporalNLI_dataset) is the Japanese temporal inference benchmark. \nThis dataset consists of templates, test data, and training data. \nTemplate subset containing template, time format, or time span in their names are split based on tense fragment, time format, \nor time span, respectively.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources… See the full description on the dataset page: https://huggingface.co/datasets/zenless-lab/jamp.","first_N":5,"first_N_keywords":["text-classification","Japanese","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"jsem","keyword":"japanese","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/zenless-lab/jsem","creator_name":"Zenless Lab","creator_url":"https://huggingface.co/zenless-lab","description":"\n\t\n\t\t\n\t\tJSeM: Japanese semantic test suite (Japanese FraCaS and extensions)\n\t\n\n叙述文間の含意関係は、言語学においては意味論の中心的な説明対象の一つであるとともに、理論を検証するためのベンチマークとして用いられています。\nまた近年の自然言語処理においては、含意関係認識(Recognizing Textual Entailment: RTE)が意味処理タスクの中核となっています。\n\n前提(premise)：一つの文\n仮説(hypothesis)：一つの文\n判定(answer)：1.と2.の間に含意関係があるかどうかについての母語話者の判断（entailment, neutralあるいはcontradiction)\n\nこのテストセットでは、FraCaS test suite（Cooper et al.(1996)で公開されたオリジナルのテストセット, \nおよびBill MacCartney氏による同セットのXML版）の方針にならい、言語現象ごとに含意関係のテストをまとめています。… See the full description on the dataset page: https://huggingface.co/datasets/zenless-lab/jsem.","first_N":5,"first_N_keywords":["text-classification","Japanese","bsd-3-clause","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"JSTS","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/JSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  JSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nJapanese Semantic Textual Similarity Benchmark dataset construct from YJ Image Captions Dataset (Miyazaki and Shimizu, 2016) and annotated by crowdsource annotators.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomainsWeb, Written\n\n\nReference\nhttps://aclanthology.org/2022.lrec-1.317.pdf#page=2.00\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/JSTS.","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","human-annotated","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"thinking_dataset_v1","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nurture-intelligence/thinking_dataset_v1","creator_name":"Nurture_intelligence","creator_url":"https://huggingface.co/Nurture-intelligence","description":"\n\t\n\t\t\n\t\t概要\n\t\n\nこのデータセットは思考モデルを製作する際のもととなる質問データを集めたものになります。\nこのデータはQwen/Qwen2.5-32B-Instructのq8_0/GGUFをollama上で動かして製作されたものです。\n一応(質問の)クリーニングを入れてはありますが、回答のクリーニング入れておりません。\n\n\t\n\t\t\n\t\t注意\n\t\n\n回答には別のモデル（mistral large）(確か)を利用したため、\"質問の部分だけ\"Apache 2.0です。\ninstruction fine tuning したモデルを公開することはお勧めしません。\n\n\t\n\t\t\n\t\t謝辞\n\t\n\n元モデルの製作者、計算資源を貸してくださったvolt mindに感謝を申し上げます。\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"kamakura-tasks-100","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fukugawa/kamakura-tasks-100","creator_name":"Ryoichi Fukugawa","creator_url":"https://huggingface.co/fukugawa","description":"\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndata = load_dataset(\"fukugawa/kamakura-tasks-100\")\n\ndata\n\nDatasetDict({\n    train: Dataset({\n        features: ['task_id', 'input', 'output'],\n        num_rows: 100\n    })\n})\n\ndata[\"train\"][0]\n\n{'task_id': 0,\n 'input': '鎌倉観光のアイデアを5つ教えて下さい。',\n 'output': '1. 鶴岡八幡宮や銭洗弁天などのパワースポット巡り。\\n2. 国宝の鎌倉大仏への参拝。\\n3. 小町通り商店街で美味しいものを食べ歩き。\\n4. 七里ヶ浜や由比ヶ浜で海の景色を楽しむ。\\n5. 長谷寺や極楽寺などのお寺めぐり。'}\n\n","first_N":5,"first_N_keywords":["text2text-generation","Japanese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Simplifyingmt","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cl-nagoya/Simplifyingmt","creator_name":"CL Research Group in Nagoya, Japan","creator_url":"https://huggingface.co/cl-nagoya","description":"\n\t\n\t\t\n\t\tSimplifyingMT\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n-Repository: https://github.com/nttcslab-nlp/SimplifyingMT_ACL24-Papre: to appear\n\n\t\n\t\t\n\t\tPaper\n\t\n\nOshika et al., Simplifying Translations for Children: Iterative Simplification Considering Age of Acquisition with LLMs, Findings of ACL 2024\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nIn recent years, neural machine translation (NMT) has been widely used in everyday life.\nHowever, the current NMT lacks a mechanism to adjust the difficulty level of translations to… See the full description on the dataset page: https://huggingface.co/datasets/cl-nagoya/Simplifyingmt.","first_N":5,"first_N_keywords":["text2text-generation","English","Japanese","cc-by-sa-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"JESC","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hoshikuzu/JESC","creator_name":"Hoshikuzu","creator_url":"https://huggingface.co/Hoshikuzu","description":"\n\t\n\t\t\n\t\tDataset Card for JESC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis corpus is extracted from the JESC, with Japanese-English pairs.\nFor more information, see website below!\n(https://nlp.stanford.edu/projects/jesc/index_ja.html)\nJESC is the product of a collaboration between Stanford University, Google Brain, and Rakuten Institute of Technology. It was created by crawling the internet for movie and tv subtitles and aligining their captions. It is one of the largest freely available EN-JA corpus… See the full description on the dataset page: https://huggingface.co/datasets/Hoshikuzu/JESC.","first_N":5,"first_N_keywords":["translation","English","Japanese","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"Todo - Write dataset card\n","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"llmjp-kaken","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/llmjp-kaken","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"llm-jp-corpus-v3のkakenサブセットをHFフォーマットに変換し、各データに付与されたURLから元記事のタイトルを取得可能なものについては取得して付与したデータセットです。\nライセンスは元ページに従いCC-BY 4.0とします。\n","first_N":5,"first_N_keywords":["Japanese","cc-by-4.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic… See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"paraphrase-qa","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/paraphrase-qa","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"日本語Wikipedia中のテキストを元に言い換えを生成し、その言い換えを元にクエリと回答をLLMに生成させたデータセットです。\n出力にライセンス的な制約があるモデルを利用していないことと、元データとして日本語Wikipediaを利用していることから、CC-BY-SA 4.0ライセンスのもとでの配布とします。\n","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-sa-4.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"MM-Eval","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prometheus-eval/MM-Eval","creator_name":"prometheus-eval","creator_url":"https://huggingface.co/prometheus-eval","description":"\n\t\n\t\t\n\t\tMultilingual Meta-EVALuation benchmark (MM-Eval)\n\t\n\n\n👨‍💻Code\n|\n📄Paper\n|\n🤗 MMQA\n\n\nMM-Eval is a multilingual meta-evaluation benchmark consisting of five core subsets—Chat, Reasoning, Safety, Language Hallucination, and Linguistics—spanning 18 languages and a Language Resource subset spanning 122 languages for a broader analysis of language effects. \n\nDesign ChoiceIn this work, we minimize the inclusion of translated samples, as mere translation may alter existing preferences due to… See the full description on the dataset page: https://huggingface.co/datasets/prometheus-eval/MM-Eval.","first_N":5,"first_N_keywords":["Arabic","Bengali","Catalan","German","English"],"keywords_longer_than_N":true},
	{"name":"SFT-Dataset-For-Self-Taught-Evaluators-iter1","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/SFT-Dataset-For-Self-Taught-Evaluators-iter1","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"Aratako/SFT-Dataset-For-Self-Taught-Evaluators-iter1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xmmmu","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xmmmu","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"neulab/PangeaBench-xmmmu dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","multiple-choice","Arabic","French"],"keywords_longer_than_N":true},
	{"name":"cl-humaneval_v1.0","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kogi-jwu/cl-humaneval_v1.0","creator_name":"Kuramitsu Lab, JWU","creator_url":"https://huggingface.co/kogi-jwu","description":"\n\t\n\t\t\n\t\tCL-HumanEval\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCL-HumanEval is a benchmark for evaluating cross-lingual transfer through code generation. \nIt is based on the code generation benchmark HumanEval.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset contains coding problems in 2 natural languages: English and Japanese.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nfrom datasets import load_dataset\nload_dataset(\"kogi-jwu/cl-humaneval_v1.0\", \"en\")\n\nDatasetDict({\n    test: Dataset({\n        features: ['task_id', 'lang'… See the full description on the dataset page: https://huggingface.co/datasets/kogi-jwu/cl-humaneval_v1.0.","first_N":5,"first_N_keywords":["text2text-generation","English","Japanese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"small_tengentoppa_12k","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YY1128/small_tengentoppa_12k","creator_name":"Yushi Yokomizo","creator_url":"https://huggingface.co/YY1128","description":"\n\t\n\t\t\n\t\tsmall tengentoppa 12k\n\t\n\n日本語の学習用データセットDeL-TaiseiOzaki/Tengentoppa-sft-v1.0の一部のデータに対してLLMQwen/Qwen2.5-32B-Instruct-AWQにインストラクションチューニング用の一問一答データとして有用かをラベル付けさせたものです。\nオリジナルのDeL-TaiseiOzaki/Tengentoppa-sft-v1.0が膨大なので学習用サブセットを作る際の参考に作成しました。\n用いたプロンプトテンプレートは以下の通りです。\n\"\"\"\n下記の二つのInstruction tuning用のデータを確認し、有用な方を教えてください。\n前者が有用だと思う場合は0を、後者が有用だと思う場合は1を出力してください。\n他には何も出力しないでください。\n｀｀｀markdown\n{instruction tuning用データ1}\n｀｀｀\n｀｀｀markdown\n{instruction tuning用データ2}\n｀｀｀\n\"\"\"\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\nOriginal:… See the full description on the dataset page: https://huggingface.co/datasets/YY1128/small_tengentoppa_12k.","first_N":5,"first_N_keywords":["text-generation","question-answering","Japanese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSIB-Fleurs\n\t\n\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \nThe topics are:\n\nScience/Technology\nTravel\nPolitics\nSports\nHealth\nEntertainment\nGeography\n\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset creation\n\t\n\nThis dataset processes and merges… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"japanese-text-image-retrieval-train","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oshizo/japanese-text-image-retrieval-train","creator_name":"oshizo","creator_url":"https://huggingface.co/oshizo","description":"shunk031/JDocQAのtrain splitに含まれるPDFデータを画像化し、NDLOCRでOCRしたテキストとペアにしたデータセットです。OCRは長い辺を1200pxにリサイズした画像に対して実施しました。OCR結果には、読み取りに失敗した際の文字列「〓」が含まれます。本データセットに含めている画像は、長い辺を896px、700px、588pxのいずれかにリサイズしています。どのサイズとするかは主にページに含まれる文字数で決めました。  \nquery列は、OCR結果の文字列に対しQwen/Qwen2.5-14B-Instructで生成したものです。3つの質問を生成させ、ランダムに1つを選んだものをデータセットに含めました。質問を生成する際は以下のプロンプトを使用しました。  \nあなたは、質問から画像をretrieveするためのモデルをトレーニングするための(質問, 画像)ペアのデータセットを作成するプロジェクトのメンバーである。\nプロジェクトは以下のように進める。\nstep1. ドキュメントPDFを1ページ1枚の画像ファイルに変換する\nstep2.… See the full description on the dataset page: https://huggingface.co/datasets/oshizo/japanese-text-image-retrieval-train.","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","100K - 1M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"ja-en-r1-distill-qwen","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/ja-en-r1-distill-qwen","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japaneseを用いて、英語Wikipedia中のテキストを日本語に翻訳したデータセットです。\n本データセットの処理には、A6000を4枚使用して、vLLMで約100分程度必要でした。\ntext_jaカラムがモデルから出力された日本語を前処理して余分な部分を除いたもので、text_enカラムは元となる英語テキストです。\ninputカラムはモデルに入力した入力そのものであり、outputカラムは<think>トークンなどを含み出力をそのまま収載しています。\nモデルへの入力には、hpprc/honyakuから英日翻訳事例を3件選び、few-shot exampleとして加えています。\nモデルの出力にライセンス上の制約がないことと、元にしているテキストがWikipediaのものであることから、本データはCC-BY-SA 4.0ライセンスのもと公開いたします。\n","first_N":5,"first_N_keywords":["translation","Japanese","English","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"aya-ja-evol-inst","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-jp/aya-ja-evol-inst","creator_name":"LLM-jp","creator_url":"https://huggingface.co/llm-jp","description":"\n\t\n\t\t\n\t\taya-ja-eval-inst\n\t\n\nThis repository provides a preference dataset developed by LLM-jp, a collaborative project launched in Japan.\nThis dataset was created by generating the chosen response using Qwen/Qwen2.5-32B-Instruct and the rejected response using llm-jp/llm-jp-3-1.8b-instruct for the prompts in weblab-GENIAC/aya-ja-evol-instruct-calm3-dpo-masked.\nThis repository does not contain prompts but only the corresponding indices. Please obtain the original prompts from the original data… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/aya-ja-evol-inst.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"wizardlm8x22b-logical-math-coding-sft-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-jp/wizardlm8x22b-logical-math-coding-sft-ja","creator_name":"LLM-jp","creator_url":"https://huggingface.co/llm-jp","description":"\n\t\n\t\t\n\t\twizardlm8x22b-logical-math-coding-sft-ja\n\t\n\nThis repository provides an instruction tuning dataset developed by LLM-jp, a collaborative project launched in Japan.\nThe dataset comprises a subset from kanhatakeyama/wizardlm8x22b-logical-math-coding-sft-ja and kanhatakeyama/wizardlm8x22b-logical-math-coding-sft_additional-ja.\n\n\t\n\t\t\n\t\n\t\n\t\tSend Questions to\n\t\n\nllm-jp(at)nii.ac.jp\n\n\t\n\t\t\n\t\n\t\n\t\tModel Card Authors\n\t\n\nThe names are listed in alphabetical order.\nHirokazu Kiyomaru and Takashi… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/wizardlm8x22b-logical-math-coding-sft-ja.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-Polylingo-50k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","description":"\n\t\n\t\t\n\t\tGammaCorpus Polylingo 50k\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\nLanguage: The language used in the interaction.\n\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if you… See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k.","first_N":5,"first_N_keywords":["text-generation","English","Russian","Vietnamese","German"],"keywords_longer_than_N":true},
	{"name":"r1-distill-qwen-pseudo-qa","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/r1-distill-qwen-pseudo-qa","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"日本語WikipediaからLLMを用いて自動生成した質問と、対応する日本語Wikipediaのページを元に、cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japaneseを用いて回答を生成したデータセットです。\n出力にライセンス的な制約があるLLMを用いていないことと、日本語Wikipediaを用いていることから、本データセットはCC-BY-SA 4.0での配布とします。\n","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSynthdog Multilingual\n\t\n\n\n\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","description":"\n\t\n\t\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\nWe translated the MMLU’s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases… See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"Hazumi-AffNeg-Data","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ouktlab/Hazumi-AffNeg-Data","creator_name":"ouktlab","creator_url":"https://huggingface.co/ouktlab","description":"\n\t\n\t\t\n\t\tAbstract\n\t\n\nThis dataset comprises exchanges of Yes/No questions from the \nsystem and corresponding user responses, extracted from the multimodal \ndialogue corpus Hazumi.\nIt was used to fine-tune our released model.\n","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"degeneration-html-multilingual","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","description":"\n\t\n\t\t\n\t\tThe Degeneration of the Nation Multilingual Dataset\n\t\n\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual.","first_N":5,"first_N_keywords":["translation","text2text-generation","text-generation","text-classification","token-classification"],"keywords_longer_than_N":true},
	{"name":"distilabel-reasoning-R1-Llama-70B","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/distilabel-reasoning-R1-Llama-70B","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\n\t\n\t\t\n\t\tHow this Data was made\n\t\n\nWe made this data through the following steps:\n\nSample English reasoning-style prompts from argilla/distilabel-reasoning-prompts.\nRemove similar prompts using text similarity based on BAAI/bge-m3 embeddings.\nTranslate English prompts to Japanese using gpt-4o-mini-2024-07-18.\nGenerate answers to prompts using deepseek-ai/DeepSeek-R1-Distill-Llama-70B.\nFilter responses (to ja_valid) which did not:\nFinish within 2048 tokens\nContain a valid <think> section\nHave… See the full description on the dataset page: https://huggingface.co/datasets/lightblue/distilabel-reasoning-R1-Llama-70B.","first_N":5,"first_N_keywords":["Japanese","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"DSR1D-qwen-2.5-32B-aya-ja-1k-generated","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kurogane/DSR1D-qwen-2.5-32B-aya-ja-1k-generated","creator_name":"kurogane himaki","creator_url":"https://huggingface.co/kurogane","description":"\n\t\n\t\t\n\t\tDSR1D-qwen-2.5-32B-aya-ja-1k-generated\n\t\n\nこれはdeepseek-ai/DeepSeek-R1-Distill-Qwen-32Bを用いて、weblab-GENIAC/aya-ja-evol-instruct-calm3-dpo-maskedの最初の1000件の応答をmax_new_tokens=3060で生成させました。\ntransformers内のbnbの8bitで生成したため、元モデルと比べて若干精度が落ちていると思います。\nkurogane/DSR1D-Llama-8B-aya-ja-1k-generatedと同じコードで生成したのに、<think>が正常に生成されていないものがほとんどとなってしまいました。\nもしかしなくても<think>から始めたほうがいいかもしれません。\n実用性は皆無です。参考程度や前処理の準備用に使ってください。\n","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"gsm8k-ja-slim","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/p1atdev/gsm8k-ja-slim","creator_name":"Plat","creator_url":"https://huggingface.co/p1atdev","description":"\n\t\n\t\t\n\t\tGSM8K Japanese Slim\n\t\n\nJapanese translated version of openai/gsm8k, and the answer extracted from descriptions. \nnejumi/phi-4-GPTQ-Int4-calib-ja-1k was used for translation.\n\n[!WARNING]\nSome data are invalid in Japanese.\nExample:\n\nThe question:\n\n\nサマンサの苗字は、ボビーの苗字より3文字少ない。ボビーが自分の苗字から2文字を取り除けば、ジェイミーの苗字の2倍の長さになる。ジェイミーのフルネームはジェイミー・グレイである。サマンサの苗字には何文字ありますか？\n\n\nThe answer: 7\n\n\n","first_N":5,"first_N_keywords":["Japanese","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"SakaEval-V1","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/SakaEval-V1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"https://chatgpt.com\n","first_N":5,"first_N_keywords":["text-generation","Japanese","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Math","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Math","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Math is a dataset of BenchMAX, sourcing from MGSM, which evaluates the math reasoning capability in multilingual scenarios.\nWe extend the original MGSM dataset by six additional languages, i.e. Arabic, Czech, Hungarian, Korean, Serbian, and… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Math.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Science","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Science","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Science is a dataset of BenchMAX, sourcing from GPQA, which evaluates the natural science reasoning capability in multilingual scenarios.\nWe extend the original English dataset to 16 non-English languages.\nThe data is first translated by Google… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Science.","first_N":5,"first_N_keywords":["question-answering","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Question_Answering","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Question_Answering is a dataset of BenchMAX for evaluating the long-context capability of LLMs in multilingual scenarios.\nThe subtasks are similar to the subtasks in RULER.\nThe data is sourcing from UN Parallel Corpus and xquad.\nThe haystacks… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"r1-distill-qwen-pseudo-qa-taste","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/r1-distill-qwen-pseudo-qa-taste","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"hpprc/r1-distill-qwen-pseudo-qa-taste dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"jawiki-bullet-points","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/jawiki-bullet-points","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"日本語Wikipediaから抽出したテキストに基づいて、rinna/deepseek-r1-distill-qwen2.5-bakeneko-32bとhttps://huggingface.co/cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japaneseを用いて箇条書きにしたデータセットです。\n重複を許してランダムにサンプリングしながら生成をしたので、collection subsetにある事例がgenerated subsetに無い場合があります。\nまた、HF上のviewerでは改行や空白がうまく見えませんが、実際にはほとんどの箇条書きの要素が改行で区切られています。\n生成に用いたモデルがApache 2.0で配布されていること、日本語Wikipediaのテキストを用いていることから、本データセットはCC-BY-SA 4.0での配布とします。\n","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"genius-video","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sleeping-ai/genius-video","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","description":"sleeping-ai/genius-video dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","Japanese","Arabic","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"ShiftySpeech","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ash56/ShiftySpeech","creator_name":"Ashi Garg","creator_url":"https://huggingface.co/ash56","description":"This repository introduces:  🌀 ShiftySpeech: A Large-Scale Synthetic Speech Dataset with Distribution Shifts\n\n\t\n\t\t\n\t\t🔥 Key Features\n\t\n\n\n3000+ hours of synthetic speech\nDiverse Distribution Shifts: The dataset spans 7 key distribution shifts, including:  \n📖 Reading Style  \n🎙️ Podcast  \n🎥 YouTube  \n🗣️ Languages (Three different languages)  \n🌎 Demographics (including variations in age, accent, and gender)\n\n\nMultiple Speech Generation Systems: Includes data synthesized from various TTS… See the full description on the dataset page: https://huggingface.co/datasets/ash56/ShiftySpeech.","first_N":5,"first_N_keywords":["English","Chinese","Japanese","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"M-ABSA","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","description":"\n\t\n\t\t\n\t\tM-ABSA\n\t\n\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\n\n\n\t\n\t\t\n\t\tData Description:\n\t\n\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\nAll datasets are stored in the data/ folder:\n\nAll dataset contains 7 domains.\n\ndomains = [\"coursera\", \"hotel\", \"laptop\", \"restaurant\", \"phone\", \"sight\", \"food\"]\n\n\nEach dataset contains 21 languages.\n\nlangs = [\"ar\", \"da\", \"de\", \"en\", \"es\", \"fr\", \"hi\", \"hr\"… See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA.","first_N":5,"first_N_keywords":["token-classification","text-classification","Arabic","Danish","German"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Chat","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","description":"\n\t\n\t\t\n\t\tDATA-AI: Il Modello di IA di M.INC.\n\t\n\n\n\t\n\t\t\n\t\t📌 Introduzione\n\t\n\nDATA-AI è un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello è basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \nDATA-AI è stato addestrato su un… See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat.","first_N":5,"first_N_keywords":["Italian","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"PolyGuardMix","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","description":"\n\t\n\t\t\n\t\tPolyGuard: A Multilingual Safety Moderation Tool for 17 Languages\n\t\n\nAbstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and the… See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix.","first_N":5,"first_N_keywords":["text2text-generation","Arabic","Chinese","Czech","Dutch"],"keywords_longer_than_N":true},
	{"name":"Nayose-Bench-QA","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EQUES/Nayose-Bench-QA","creator_name":"EQUES Inc.","creator_url":"https://huggingface.co/EQUES","description":"\n\t\n\t\t\n\t\tDataset Card for Nayose-Bench-Instruction\n\t\n\nThis dataset was created as a benchmark for the entity resolution task in the pharmaceutical domain.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset is designed for the entity resolution task in the pharmaceutical domain.\nThe entity resolution task refers to a paraphrasing task, such as rephrasing drug names, converting chemical substances into brand names, or rewriting chemical substances into chemical formulas.\n\n\t\n\t\t\n\t\tUses\n\t\n\nfrom datasets import… See the full description on the dataset page: https://huggingface.co/datasets/EQUES/Nayose-Bench-QA.","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-sa-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"japanese_ultrachat_6.6k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EQUES/japanese_ultrachat_6.6k","creator_name":"EQUES Inc.","creator_url":"https://huggingface.co/EQUES","description":"\n\t\n\t\t\n\t\tJapanese Ultrachat 6.6k\n\t\n\nJapanese Ultrachat 6.6k is the Japanese-translated version of the subset of ultrachat_200k using machine translation.\nJapanese Ultrachat 6.6kはultrachat_200kの一部分を機械翻訳により和訳したデータセットです. \n\n\t\n\t\t\n\t\n\t\n\t\tThe number of data\n\t\n\n\nTrain split : 6537\nTest split : 995\n\nTo be updated.\n\n\t\n\t\t\n\t\n\t\n\t\tNotes\n\t\n\n\nBeware that the columns 'id' corresponds to the original dataset. Some are missing for now.\n\n\n\t\n\t\t\n\t\n\t\n\t\tMethod\n\t\n\nWe used… See the full description on the dataset page: https://huggingface.co/datasets/EQUES/japanese_ultrachat_6.6k.","first_N":5,"first_N_keywords":["translation","Japanese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"LogicJa","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sionic-ai/LogicJa","creator_name":"sionic-ai","creator_url":"https://huggingface.co/sionic-ai","description":"\n\t\n\t\t\n\t\tLogicJa Dataset Card\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nLogicJa is a multi-turn benchmark designed to assess the reasoning capabilities of Japanese language models across multiple domains. This dataset consists of 105 multi-turn tasks (each containing two questions) for a total of 210 questions. Each category has 30 questions to ensure statistical significance.\n\n\t\n\t\t\nCategory\nReasoning\nMath\nWriting\nCoding\nUnderstanding\nGrammar\nCulture\nTotal\n\n\n\t\t\nMulti-turn Tasks\n15\n15\n15\n15\n15\n15\n15\n105… See the full description on the dataset page: https://huggingface.co/datasets/sionic-ai/LogicJa.","first_N":5,"first_N_keywords":["text-generation","question-answering","Japanese","apache-2.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"MIRACLReranking","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MIRACLReranking","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MIRACLReranking\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://project-miracl.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/MIRACLReranking.","first_N":5,"first_N_keywords":["text-ranking","expert-annotated","multilingual","miracl/mmteb-miracl","Arabic"],"keywords_longer_than_N":true},
	{"name":"Rakuten-Alpaca-Data-32K","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/toshi456/Rakuten-Alpaca-Data-32K","creator_name":"toshi456","creator_url":"https://huggingface.co/toshi456","description":"\n\t\n\t\t\n\t\tDataset Card for \"Rakuten-Alpaca-Data-32K\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Detail\n\t\n\nDataset Type: Rakuten-Alpaca-Data-32KはStanford Alpacaの手法を参考にRakuten/RakutenAI-7B-chatを使用して自動生成した日本語インストラクションデータです。\nデータ生成を行う際のSEEDデータには有志の方々が作成したseed_tasks_japanese.jsonlを利用させていただきました。\nデータの品質が低いため、何かしらの方法でフィルタリングして有益なデータのみ利用するのをおすすめします。\nLicense: Apache license 2.0  \n\n\t\n\t\t\n\t\n\t\n\t\tAcknowledgement\n\t\n\n\nStanford Alpaca\nRakuten\nseed_tasks_japanese.jsonl\n\n","first_N":5,"first_N_keywords":["question-answering","Japanese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ELYZA-tasks-100_Human_solved","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YukiTomita-CC/ELYZA-tasks-100_Human_solved","creator_name":"Yuki Tomita","creator_url":"https://huggingface.co/YukiTomita-CC","description":"\n\t\n\t\t\n\t\t概要\n\t\n\nこのデータセットは日本語LLMの評価用としてよく用いられるelyza/ELYZA-tasks-100について人間が回答を行った結果です。outputはこのリポジトリの作成者によるオリジナルですが、inputはELYZA-tasks-100からそのまま流用しています。\n詳しくは下記の記事をご覧ください。https://zenn.dev/yuki127/articles/2496cd8383c84c\n\n\t\n\t\t\n\t\t採点\n\t\n\nGPT-4oによる自動採点において、この回答での平均スコアは3.69点(+0.03 / -0.03) (計5回の同条件での採点結果の平均値と、最大値及び最小値との差分)  \nClaude 3.5 Sonnet(api: claude-3-5-sonnet-20240620)のELYZA-tasks-100の回答を同様に自動採点したところ4.42点(+0.02 / -0.02) となりました。… See the full description on the dataset page: https://huggingface.co/datasets/YukiTomita-CC/ELYZA-tasks-100_Human_solved.","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"yuho-text-2014-2022","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/numad/yuho-text-2014-2022","creator_name":"kiyoshi.numatazawa","creator_url":"https://huggingface.co/numad","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nこのデータはEDINET閲覧（提出）サイトで公開されている2014~2022年に提出された有価証券報告書から特定の章を抜粋したデータです。\n各レコードのurl列が出典となります。データ取得の都合上2014/06/14以降のデータになります。\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nデータの内容は下記想定です\n\n\t\n\t\t\n物理名\n論理名\n型\n概要\n必須\n\n\n\t\t\ndoc_id\n文書ID\nstr\n有価証券報告書の単位で発行されるID\n〇\n\n\nedinet_code\nEDINETコード\nstr\nEDINET内での企業単位に採番されるID\n〇\n\n\ncompany_name\n企業名\nstr\n企業名\n〇\n\n\ndocument_name\n文書タイトル\nstr\n有価証券報告書のタイトル\n〇\n\n\nsec_code\n証券コード\nstr\n証券コード\n×\n\n\nperiod_start\n期開始日\ndate(yyyy-mm-dd)… See the full description on the dataset page: https://huggingface.co/datasets/numad/yuho-text-2014-2022.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"Self-Instruct-Japanese-Elzya-13B","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iam-ajaymeena/Self-Instruct-Japanese-Elzya-13B","creator_name":"Ajay Meena","creator_url":"https://huggingface.co/iam-ajaymeena","description":"A Japanese dataset generated with an opensource elyza/ELYZA-japanese-Llama-2-13b-instruct model. \nThis dataset is used in evaluating AI-generated text detection methods and is well-suited for self-instruct methods.\nThe instructions were taken from:\n\nhttps://huggingface.co/datasets/CausalLM/GPT-4-Self-Instruct-Japanese\n\nThe model used is:\n\nhttps://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b\n\nLicense: refer to the model's license\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MELA","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Geralt-Targaryen/MELA","creator_name":"Ziyin Zhang","creator_url":"https://huggingface.co/Geralt-Targaryen","description":"See the GitHub repo for details.\n","first_N":5,"first_N_keywords":["text-classification","English","Chinese","Italian","Russian"],"keywords_longer_than_N":true},
	{"name":"Self-Instruct-Japanese-Qwen1.5-14B","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iam-ajaymeena/Self-Instruct-Japanese-Qwen1.5-14B","creator_name":"Ajay Meena","creator_url":"https://huggingface.co/iam-ajaymeena","description":"A Japanese dataset generated with Qwen/Qwen1.5-14B model. \nThis dataset is used in evaluating AI-generated text detection methods and is well-suited for self-instruct methods.\nThe instructions were taken from:\n\nhttps://huggingface.co/datasets/CausalLM/GPT-4-Self-Instruct-Japanese\n\nThe model used is:\n\nhttps://huggingface.co/Qwen/Qwen1.5-14B\n\nLicense: Please refer to the model's license\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Magpie_RakutenAI_prompt_extract_example50","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kurogane/Magpie_RakutenAI_prompt_extract_example50","creator_name":"kurogane himaki","creator_url":"https://huggingface.co/kurogane","description":"Magpie方式によるprompt抽出をRakuten/RakutenAI-7B-chatで行ってみました。\n設定しているsystem promptは論文のサプリ記載のpromptを翻訳したものを使用しています。\nMagpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing\nhttps://arxiv.org/abs/2406.08464\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"Japanese-English_translation_of_contents_HScodes","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ikeno-ada/Japanese-English_translation_of_contents_HScodes","creator_name":"ikenokazuki","creator_url":"https://huggingface.co/ikeno-ada","description":"日本郵便が提供する「国際郵便　内容品の日英・中英訳、HSコード類」（2024/05/09）のデータに基づいています。\n詳しくはサイトをご覧ください\nhttps://www.post.japanpost.jp/int/use/publication/contentslist/index.php?id=0&ie=utf8&lang=_ja&q=\n","first_N":5,"first_N_keywords":["Japanese","English","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"NLVR-JA","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/toshi456/NLVR-JA","creator_name":"toshi456","creator_url":"https://huggingface.co/toshi456","description":"This dataset was created by machine translating \"nlvr\" into Japanese.\nnlvr\nhttps://github.com/lil-lab/nlvr/tree/master/nlvr\n","first_N":5,"first_N_keywords":["image-to-text","Japanese","cc-by-4.0","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"mCoT-MATH","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laihuiyuan/mCoT-MATH","creator_name":"Huiyuan Lai","creator_url":"https://huggingface.co/laihuiyuan","description":"\n\t\n\t\t\n\t\tmCoT: Multilingual Instruction Tuning for Reasoning Consistency in Language Models\n\t\n\nPaper: https://arxiv.org/abs/2406.02301\nCode: https://github.com/laihuiyuan/mCoT\nModel: https://huggingface.co/laihuiyuan/mCoT\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nBased on MetaMathQA and MathInstruct\n, we use machine translation to compile mCoT-MATH, the first large-scale multilingual math CoT reasoning dataset containing around 6.3 million samples for 11 diverse languages.\nWe train a 7B parameter model mCoT for… See the full description on the dataset page: https://huggingface.co/datasets/laihuiyuan/mCoT-MATH.","first_N":5,"first_N_keywords":["Swahili","Bengali","Telugu","Thai","Japanese"],"keywords_longer_than_N":true},
	{"name":"auto-wiki-nli","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/auto-wiki-nli","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"hpprc/auto-wiki-nli dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"WikiHowNFQA-ja_cleaned","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GENIAC-Team-Ozaki/WikiHowNFQA-ja_cleaned","creator_name":"GENIAC Team Ozaki","creator_url":"https://huggingface.co/GENIAC-Team-Ozaki","description":"Lurunchik/WikiHowNFQAを日本語に翻訳し、人手でクリーニングしたデータセットです。\n","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"docci_ja","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/toshi456/docci_ja","creator_name":"toshi456","creator_url":"https://huggingface.co/toshi456","description":"This data was translated from the \"DOCCI\" into Japanese by DeepL\nDOCCI: https://google.github.io/docci/\nLisence\nCC-BY-4.0\n","first_N":5,"first_N_keywords":["image-to-text","Japanese","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Evol-Alpaca-gen3-500","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/Evol-Alpaca-gen3-500","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\n\t\n\t\t\n\t\tEvol-Alpaca-gen3-500\n\t\n\n\nEvol-Alpaca-gen3-500は、  \n\nStanford Alpacaのseed tasksを日本語化\nEvol-Instructionの手法  \nmistralai/Mixtral-8x22B-Instruct-v0.1\n\nで作った合成データ(Synthetic data)です。モデルの利用にはDeepinfraを利用しています。  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: HachiML\nLanguage(s) (NLP): Japanese\nLicense: Apache 2.0\nGithub: Evol-Instruct-jp\n\n\n\t\n\t\n\t\n\t\tUses\n\t\n\n\n\n# library\nfromdatasets import load_dataset\n\n# Load dataset.\ndataset =… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/Evol-Alpaca-gen3-500.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Evol-hh-rlhf-gen3-1k","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/Evol-hh-rlhf-gen3-1k","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\n\t\n\t\t\n\t\tEvol-hh-rlhf-gen3-1k\n\t\n\n\nEvol-hh-rlhf-gen3-1kは、  \n\nkunishou/hh-rlhf-49k-jaをseed tasksとして\nEvol-Instructionの手法  \nmistralai/Mixtral-8x22B-Instruct-v0.1\n\nで作った合成データ(Synthetic data)です。モデルの利用にはDeepinfraを利用しています。  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: HachiML\nLanguage(s) (NLP): Japanese\nLicense: Apache 2.0\nGithub: Evol-Instruct-jp\n\n\n\t\n\t\n\t\n\t\tUses\n\t\n\n\n\n# library\nfromdatasets import load_dataset\n\n# Load dataset.\ndataset =… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/Evol-hh-rlhf-gen3-1k.","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"LLaVA-JP-Instruct-108K","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/toshi456/LLaVA-JP-Instruct-108K","creator_name":"toshi456","creator_url":"https://huggingface.co/toshi456","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset details\n\t\n\nDataset type: LLaVA JP Instruct 108K created by changing the data sets in Japanese Visual Genome VQA dataset and train data of docci_ja to the LLaVA-Instruct format.\n\n\t\n\t\t\n\t\n\t\n\t\tAcknowledgement\n\t\n\n\nJapanese Visual Genome VQA dataset\nDOCCI\n\n\n\t\n\t\t\n\t\n\t\n\t\tLisence\n\t\n\nApach lisense 2.0\n","first_N":5,"first_N_keywords":["image-to-text","Japanese","apache-2.0","100K<n<1M","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"fleurs_clean","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ConceptNetSyntheticPhi3Text_ja","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RJZ/ConceptNetSyntheticPhi3Text_ja","creator_name":"JZ","creator_url":"https://huggingface.co/RJZ","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\nConceptNet(5.7)の日本語のトリプルに対して, Phi-3 を用いて文を生成したデータセット\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\nGenerate a sentence in phi-3 using the below prompt\n\n// h = {start}, r = {relation}, t = {end}\nprompt = f\"<|assistant|>\\n次に示すトリプル: <start>, <relation>, <end>を用いて、<start>と<end>を<relation>で結びつけた関係を表す文を作成しなさい。必ずすべての情報を網羅し､日本語で出力すること。<|end|>\\n<|user|>\\nトリプル: {h}, {r}, {t}<|end|>\\n<|assistant|>\"\n\n[More Information Needed]\n\n\t\n\t\t\n\t\n\t\n\t\tSource Data… See the full description on the dataset page: https://huggingface.co/datasets/RJZ/ConceptNetSyntheticPhi3Text_ja.","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"auto-wiki-qa-nemotron","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cl-nagoya/auto-wiki-qa-nemotron","creator_name":"CL Research Group in Nagoya, Japan","creator_url":"https://huggingface.co/cl-nagoya","description":"\n\t\n\t\t\n\t\tAutoWikiQA Nemotron\n\t\n\nA dataset constructed by generating queries and answers from Wikipedia text using Nemotron-4 340B.\n","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"STAIR-Captions","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shunk031/STAIR-Captions","creator_name":"Shunsuke Kitada","creator_url":"https://huggingface.co/shunk031","description":"\n\t\n\t\t\n\t\tDataset Card for STAIR-Captions\n\t\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nSTAIR Captions is a large-scale dataset containing 820,310 Japanese captions. This dataset can be used for caption generation, multimodal retrieval, and image generation.\n\n\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\n\n\n\n\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe language data in JDocQA is in Japanese (BCP-47 ja-JP).\n\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]… See the full description on the dataset page: https://huggingface.co/datasets/shunk031/STAIR-Captions.","first_N":5,"first_N_keywords":["image-to-text","image-captioning","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"HelpSteer2-20k-ja","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kunishou/HelpSteer2-20k-ja","creator_name":"kunishou","creator_url":"https://huggingface.co/kunishou","description":"NVIDIA が公開している SteerLM 向けのトライアルデータセット HelpSteer2を日本語に自動翻訳したデータセットになります。HelpSteer2 は Nemotron-4-430B-Reward でも利用されています。SteerLM でのアライメントや報酬モデルの作成にご活用下さい。\nNVIDIA Releases Open Synthetic Data Generation Pipeline for Training Large Language Models  \nSteerLM での LLM トレーニング方法については以下の URL を参考にして下さい。  \n\nAnnouncing NVIDIA SteerLM : https://developer.nvidia.com/blog/announcing-steerlm-a-simple-and-practical-technique-to-customize-llms-during-inference\nNeMo Aligner : https://github.com/NVIDIA/NeMo-Aligner… See the full description on the dataset page: https://huggingface.co/datasets/kunishou/HelpSteer2-20k-ja.","first_N":5,"first_N_keywords":["Japanese","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"aio-extended-answers","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sbintuitions/aio-extended-answers","creator_name":"SB Intuitions","creator_url":"https://huggingface.co/sbintuitions","description":"\n\t\n\t\t\n\t\tAIO with extended answers\n\t\n\nAIO (AI王) is a Japanese quiz dataset.\nThis repository contains the validation set of Version 2.0, augmented with manually annotated valid answers for each question.\nSource: AI王　〜クイズAI日本一決定戦〜\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nqid (str): Unique identifier for each entry in the dataset.\ncompetition (str): The name of the competition that the data was first created for.\ntimestamp (str): The timestamp when the data was created.\nsection (str): The split the data belongs… See the full description on the dataset page: https://huggingface.co/datasets/sbintuitions/aio-extended-answers.","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-sa-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ASRClustering-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oshizo/ASRClustering-ja","creator_name":"oshizo","creator_url":"https://huggingface.co/oshizo","description":"埋め込みモデルの学習、評価のためのクラスタリングデータセットです。\nnumad/yuho-text-2023を整形して作成しました。元データの取得元であるEDINETの利用規約に基づきデータセットとして公開しております。\n事業の内容を表すテキストとして、tagが\"DescriptionOfBusinessTextBlock\"のデータを抽出し、edinet_codeを使ってEDINETで使われている業種コードとの紐づけを行い、クラスラベルを付与しました。labelの割合を保ちつつ、ランダムにtrainとtestに分割しました。それぞれのsplitの件数は以下の通りです。\n\n\t\n\t\t\nlabel\n提出者業種\ntrain\ntest\n\n\n\t\t\n0\n水産・農林業\n8\n3\n\n\n1\n鉱業\n5\n2\n\n\n2\n建設業\n127\n42\n\n\n3\n食料品\n99\n33\n\n\n4\n繊維製品\n39\n13\n\n\n5\nパルプ・紙\n18\n7\n\n\n6\n化学\n162\n54\n\n\n7\n医薬品\n60\n20\n\n\n8\n石油・石炭製品\n7\n3\n\n\n9\nゴム製品\n14\n5\n\n\n10\nガラス・土石製品\n45\n15\n\n\n11\n鉄鋼\n33\n10… See the full description on the dataset page: https://huggingface.co/datasets/oshizo/ASRClustering-ja.","first_N":5,"first_N_keywords":["text-classification","Japanese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"auto-wiki-nli-reward","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cl-nagoya/auto-wiki-nli-reward","creator_name":"CL Research Group in Nagoya, Japan","creator_url":"https://huggingface.co/cl-nagoya","description":"\n\t\n\t\t\n\t\tAutoWikiNLI reward\n\t\n\nA dataset constructed by generating hypothesis sentences corresponding to entailment and contradiction from Wikipedia text using Nemotron-4 340B.\nHelpfulness and other scores are assigned using the Nemotron-4 340B reward model.\n","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","100K - 1M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"LawClustering-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oshizo/LawClustering-ja","creator_name":"oshizo","creator_url":"https://huggingface.co/oshizo","description":"埋め込みモデルの学習、評価のためのクラスタリングデータセットです。\ne-Govから収集したXMLデータを整形して作成しました。利用規約に基づき、データセットとして公開しております。\n2024/6/22時点でダウンロードした11,111件のXMLファイルのうち、Eraタグが\"Heisei\"または\"Reiwa\"のデータ6,127件を抽出しました。\ntext列はLawTitleタグから取得した法令タイトルと、MainProvisionタグから取得した本文を結合したデータです。label列は、上記のURLの「法令分類データ」に基づく分類としています。labelの割合を保ちつつ、ランダムにtrainとtestに分割しました。それぞれのsplitの件数は以下の通りです。\n\n\t\n\t\t\nlabel\n分類\ntrain\ntest\n\n\n\t\t\n1\n憲法\n27\n8\n\n\n2\n刑事\n81\n27\n\n\n3\n財務通則\n9732\n\n\n4\n水産業\n31\n11\n\n\n5\n観光\n32\n11\n\n\n6\n国会\n22\n8\n\n\n7\n警察\n94\n31\n\n\n8\n国有財産\n10\n3\n\n\n9\n鉱業\n9\n3\n\n\n10\n郵務\n23\n8\n\n\n11… See the full description on the dataset page: https://huggingface.co/datasets/oshizo/LawClustering-ja.","first_N":5,"first_N_keywords":["text-classification","Japanese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ndlbib-furigana","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlienKevin/ndlbib-furigana","creator_name":"Xiang (Kevin) Li","creator_url":"https://huggingface.co/AlienKevin","description":"国立国会図書館の書誌データから作成した振り仮名のデータセット\nA dataset of furigana characters created from bibliographic data from the National Diet Library.\nGithub Repo: https://github.com/ndl-lab/huriganacorpus-ndlbib\nDownload Source: https://lab.ndl.go.jp/dataset/huriganacorpus/shosi_dataset.zip\n","first_N":5,"first_N_keywords":["token-classification","Japanese","cc-by-4.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"Synthetic-JP-Roleplay-Instruction-Nemotron-4-1k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Synthetic-JP-Roleplay-Instruction-Nemotron-4-1k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tSynthetic-JP-Roleplay-Instruction-Nemotron-4\n\t\n\nMagpieの手法をnvidia/Nemotron-4-340B-Instructに対して適用し作成した、約1000件の日本語ロールプレイ用のinstructionデータセットです。\nデータセットの作成にはDeepInfraを利用しました。\n特に事後的なフィルタ処理は加えていないため、クオリティの低いレコードが含まれている可能性があります。ご注意ください。\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"HSClustering-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oshizo/HSClustering-ja","creator_name":"oshizo","creator_url":"https://huggingface.co/oshizo","description":"埋め込みモデルの学習、評価のためのクラスタリングデータセットです。\n税関の事前教示回答（品目分類）から収集したデータを整形して作成しました。利用規約に基づき、データセットとして公開しております。\n2024/6/23時点でダウンロードしたデータから、「一般的品名」が重複しているデータを削除しました。text列は「一般的品名」と「貨物概要」を結合したデータです。label列は、HSコードの「部」に該当します。部の情報は関税率表解説・分類例規のページの一覧表から取得しました。labelの割合を保ちつつ、ランダムにtrainとtestに分割しました。それぞれのsplitの件数は以下の通りです。\n\n\t\n\t\t\nlabel\ntrain\ntest\n\n\n\t\t\n1\n150\n51\n\n\n2\n214\n71\n\n\n3\n32\n11\n4\n576\n192\n\n\n5\n27\n9\n\n\n6\n308\n102\n\n\n7\n246\n82\n\n\n8\n46\n16\n\n\n9\n67\n22\n\n\n10\n30\n10\n\n\n11\n304\n101\n\n\n12\n66\n22\n\n\n13\n45\n15\n\n\n14\n14\n5\n\n\n15\n149\n50\n\n\n16\n138\n45… See the full description on the dataset page: https://huggingface.co/datasets/oshizo/HSClustering-ja.","first_N":5,"first_N_keywords":["text-classification","Japanese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"JMDNClustering-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oshizo/JMDNClustering-ja","creator_name":"oshizo","creator_url":"https://huggingface.co/oshizo","description":"埋め込みモデルの学習、評価のためのクラスタリングデータセットです。\n独立行政法人医薬品医療機器総合機構のウェブサイトのページから取得したデータを整形して作成しました。利用規約に基づき、出展を明示してデータセットとして公開しております。\n2024/6/22時点でダウンロードしたデータから「類別コード」が空欄のデータを削除しました。text列は「一般的名称」と「一般的名称定義」を結合したデータです。label列は「類別コード」に該当します。labelの割合を保ちつつ、ランダムにtrainとtestに分割しました。それぞれのsplitの件数は以下の通りです。\n\n\t\n\t\t\nlabel\n類別\ntrain\ntest\n\n\n\t\t\n0\nプ01\n131\n43\n\n\n1\nプ02\n14\n5\n\n\n2\n医01\n5\n2\n\n\n3\n医02\n20\n7\n\n\n4\n医03\n6\n2\n\n\n5\n医04\n257\n85\n\n\n6\n医05\n8\n3\n\n\n7\n医06\n9\n3\n\n\n8\n器01\n28\n10\n\n\n9\n器02\n14\n5\n\n\n10\n器03\n24\n8\n\n\n11\n器04\n1\n0\n\n\n12\n器05\n22\n7\n\n\n13\n器06\n65\n22… See the full description on the dataset page: https://huggingface.co/datasets/oshizo/JMDNClustering-ja.","first_N":5,"first_N_keywords":["text-classification","Japanese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Timeseries-QA","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/Timeseries-QA","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\n\t\n\t\t\n\t\tTimeseries-QA\n\t\n\n\n\nThis is a dataset for Timeseries Instruction Tuning.\nIt was created using the following steps:\n\nExtracted features from time series data in AutonLab/Timeseries-PILE\nmicrosoft/Phi-3-medium-4k-instruct generated the QA pairs\n\nTimeseries Instruction Tuning用のデータセットです。\n以下の手順で作成しました。\n\nAutonLab/Timeseries-PILE　の時系列データの特徴を抽出\nmicrosoft/Phi-3-medium-4k-instruct がQAを作成\n\n\n\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: HachiMLLanguage(s) (NLP): English… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/Timeseries-QA.","first_N":5,"first_N_keywords":["text-generation","time-series-forecasting","English","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys Fé-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI 🧡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save… See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"open_preference-v0.3","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryota39/open_preference-v0.3","creator_name":"kaeru39","creator_url":"https://huggingface.co/ryota39","description":"\n\t\n\t\t\n\t\tdescription\n\t\n\n\npublic RLHF dataset in Japanese\nthe construction of the reward model was reformatted into a classification task.\nQuality of Japanese text is middle arise from the synthetic generated sentences by Phi-3-medium(14B)\n\n\n\t\n\t\t\n\t\tdetails\n\t\n\n\nreformatted version of this dataset\nlabel 1 stands for chosen sentence.\nlabel 0 stands for rejected sentence.\n\n","first_N":5,"first_N_keywords":["Japanese","cc-by-4.0","10K - 100K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"JEMHopQA","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sbintuitions/JEMHopQA","creator_name":"SB Intuitions","creator_url":"https://huggingface.co/sbintuitions","description":"評価スコアの再現性確保と SB Intuitions 修正版の公開用クローン\nソース: aiishii/JEMHopQA on GitHub\n\n\t\n\t\t\n\t\tJEMHopQA\n\t\n\n\nJEMHopQA (Japanese Explainable Multi-hop Question Answering)は、回答導出ステップの情報付きの日本語の根拠情報付きマルチホップQAデータセットです。質問 (Question)を入力として、回答 (Answer)と導出 (Derivation)を生成するタスクです。導出は導出ステップの集合で、半構造化されたエンティティ間の関係表現です。問題は、Wikipediaの２つの記事の情報をリンクさせて答える構成問題 (compositional)と2つの記事の情報を比較して答える比較問題 (comparison)が含まれています。\n\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nCreative Commons Attribution Share Alike 4.0 International\n\n\t\n\t\t\n\t\tCitation… See the full description on the dataset page: https://huggingface.co/datasets/sbintuitions/JEMHopQA.","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-sa-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ja-vicuna-qa-benchmark","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-book/ja-vicuna-qa-benchmark","creator_name":"大規模言語モデル入門","creator_url":"https://huggingface.co/llm-book","description":"\n\t\n\t\t\n\t\tDataset Card for llm-book/ja-vicuna-qa-benchmark\n\t\n\n書籍『大規模言語モデル入門Ⅱ〜生成型LLMの実装と評価』で使用する、京都大学が提供する「Japanese Vicuna QA Benchmark」のデータセットです。 \nオリジナルのサイトと同じものを使用しています。\n本データセットは、10のカテゴリー(汎用、コーディング、ロールプレイ、ライティングなど)にわたる80の多様な質問で構成されており、LLM-as-a-judgeを使用して、参照なしで日本語LLMモデルの回答を評価することができます。\n\n\t\n\t\t\n\t\tLicence\n\t\n\nApache License, Version 2.0\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"SE-Chatting.en","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/berwart/SE-Chatting.en","creator_name":"Berwart","creator_url":"https://huggingface.co/berwart","description":"\n\t\n\t\t\n\t\tSE.02\n\t\n\nDataset\nHello, welcome to the official main dataset of SE.02 that's always getting updated, make sure to like to help us a lot.\nthis dataset contains pretty much everything from math to isk what to put but pretty much anything you think an ai can say.\nanyways this is our biggest dataset yet, and out first one that I don't even know how I managed to make this.\nyou can use it to train your own ai if you want.\n","first_N":5,"first_N_keywords":["question-answering","translation","English","French","Japanese"],"keywords_longer_than_N":true},
	{"name":"wikidata-parallel-descriptions-en-ja","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mitsua/wikidata-parallel-descriptions-en-ja","creator_name":"elanmitsua","creator_url":"https://huggingface.co/Mitsua","description":"\n\t\n\t\t\n\t\tWikidata parallel descriptions en-ja\n\t\n\n\nParallel corpus for machine translation generated from wikidata dump (2024-05-06).\nCurrently we processed only English/Japanese pair.\nThe jsonl file is ready-to-train by Hugging Face transformers trainer for translation tasks.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nhttps://www.wikidata.org/wiki/Wikidata:Database_download\n\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\nAs Wikidata description field does not represent exact direct translation, filtering is required for… See the full description on the dataset page: https://huggingface.co/datasets/Mitsua/wikidata-parallel-descriptions-en-ja.","first_N":5,"first_N_keywords":["translation","English","Japanese","cc0-1.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"flores","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/flores","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FloresBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nFLORES is a benchmark dataset for machine translation between English and low-resource languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNon-fiction, Encyclopaedic, Written\n\nReference\nhttps://huggingface.co/datasets/facebook/flores\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FloresBitextMining\"])… See the full description on the dataset page: https://huggingface.co/datasets/mteb/flores.","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Achinese","Mesopotamian Arabic"],"keywords_longer_than_N":true},
	{"name":"jawiki-paragraphs","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/jawiki-paragraphs","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"hpprc/jawiki-paragraphs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"multilingual-llava-bench-in-the-wild","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\tMultilingual LLaVA Bench in the Wild\n\t\n\n\n\t\n\t\t\n\t\tNote that this is a copy from https://huggingface.co/datasets/MBZUAI/multilingual-llava-bench-in-the-wild\n\t\n\nIt was created due to issues in the original repo. It also includes the image features and has a uniform and joined structure.\nIf you use this dataset, please cite the original authors:\n@article{PALO2024,\n  title={Palo: A Large Multilingual Multimodal Language Model},\n  author={Maaz, Muhammad and Rasheed, Hanoona and Shaker… See the full description on the dataset page: https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild.","first_N":5,"first_N_keywords":["Arabic","Bengali","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"amenokaku-code-instruct-python-mit","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/amenokaku-code-instruct-python-mit","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"kunishou/amenokaku-code-instructを以下の条件で絞り込んだものです。  \n\nMITライセンス (licence: 'MIT')\npython (source: ['gasyori_100_knocks', 'datascience_100_knocks_python', 'bifi', 'python_for_begginers_solve_50_exercises', 'nlp_100_knocks')\n\n","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"amenokaku-code-instruct-python-mit-450","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/amenokaku-code-instruct-python-mit-450","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"kunishou/amenokaku-code-instructを以下の条件で絞り込んだものです。  \n\nMITライセンス (licence: 'MIT')\npython (source: ['gasyori_100_knocks', 'datascience_100_knocks_python', 'bifi', 'python_for_begginers_solve_50_exercises', 'nlp_100_knocks')\nsource: 'bifi'をランダムに100件に絞り込み\n\n","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"alpaca_jp_python","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/alpaca_jp_python","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\n\t\n\t\t\n\t\talpaca_jp_python\n\t\n\n\nalpaca_jp_pythonは、  \n\nStanford Alpacaの手法  \nmistralai/Mixtral-8x22B-Instruct-v0.1\n\nで作った合成データ(Synthetic data)です。モデルの利用にはDeepinfraを利用しています。  \nまた、\"_cleaned\"がついたデータセットはmistralai/Mixtral-8x22B-Instruct-v0.1によって精査されています。  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: HachiML\nLanguage(s) (NLP): Japanese\nLicense: Apache 2.0\nGithub: Alpaca-jp\n\n\n\t\n\t\n\t\n\t\tUses\n\t\n\n\n\n# library\nfromdatasets import load_dataset\n\n# Recommend getting the latest… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/alpaca_jp_python.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"test_rp","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aipracticecafe/test_rp","creator_name":"aipracticecafe","creator_url":"https://huggingface.co/aipracticecafe","description":"Format to have User, Assistant in order.\ndef merge_roles(data):\n    merged_data = []\n    current_role = None\n    current_content = []\n\n    for entry in data[\"messages\"]:\n#         print(entry)\n        role = entry['role']\n        if role == \"system\":\n            role = \"user\"\n        content = entry['content']\n\n        if role == current_role:\n            current_content.append(content)\n        else:\n            ifcurrent_role is not None:\n                merged_data.append({\"role\":… See the full description on the dataset page: https://huggingface.co/datasets/aipracticecafe/test_rp.","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"xm3600","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\nIt also includes the image features as PIL Image and has a uniform and… See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xm3600_1k","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600 - 1K Split\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a 1K split of XM3600!\n\t\n\nFor this, we… See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xflickrco","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xflickrco","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"floschne/xflickrco dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["image-to-text","German","English","Spanish","Indonesian"],"keywords_longer_than_N":true},
	{"name":"LimaRP-augmented-ja-karakuri","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/LimaRP-augmented-ja-karakuri","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tLimaRP-augmented-ja-karakuri\n\t\n\ngrimulkan/LimaRP-augmentedを、GENIAC-Team-Ozaki/karakuri-lm-8x7b-chat-v0.1-awqを用いて日本語に翻訳したロールプレイ学習用データセットです。\nLLMの推論にはDeepInfraというサービスを使いました。\n\n\t\n\t\t\n\t\t翻訳の詳細\n\t\n\n\n3-shots promptingでの翻訳\nmistralのtokenizerで出力が8000トークンを超えるまで翻訳\n元データセットにある非常に長い対話は上記条件で途中のターンで翻訳を終了しています。\n\n\nLLM特有の同じ出力が繰り返される現象に遭遇した場合、その時点で該当レコードの翻訳を終了\nこの結果1ターン未満となったレコード（33件）を削除\n\n\n\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"LimaRP-augmented-ja-WizardLM","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/LimaRP-augmented-ja-WizardLM","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tLimaRP-augmented-ja-WizardLM\n\t\n\ngrimulkan/LimaRP-augmentedを、WizardLM-2-8x22Bを用いて日本語に翻訳したロールプレイ学習用データセットです。\nLLMの推論にはDeepInfraというサービスを使いました。\n\n\t\n\t\t\n\t\t翻訳の詳細\n\t\n\n\n3-shots promptingでの翻訳\nmistralのtokenizerで出力が8000トークンを超えるまで翻訳\n元データセットにある非常に長い対話は上記条件で途中のターンで翻訳を終了しています。\n\n\nLLM特有の同じ出力が繰り返される現象に遭遇した場合、その時点で該当レコードの翻訳を終了\nこの結果1ターン未満となったレコード（12件）を削除\n\n\n\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"mqa-ja","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/mqa-ja","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"mqaデータセットのquery--passageのペアについて重複を削除したデータセットです。\n元データ中のノイジーなテキストのクリーニングやNFKC正規化などの前処理を行ってあります。\ndataset subsetのpos_idsおよびneg_ids中のidは、collectionsubsetのインデックス番号に対応しています。\nしたがって、collection[pos_id]のようにアクセスしてもらえれば所望のデータを得ることができます。\nライセンスは元データセットに従います。\n","first_N":5,"first_N_keywords":["Japanese","cc0-1.0","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Swallow-Instruct-v0.1","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tokyotech-llm/Swallow-Instruct-v0.1","creator_name":"tokyotech-llm","creator_url":"https://huggingface.co/tokyotech-llm","description":"\n\t\n\t\t\n\t\tSwallow Instruct v0.1 Dataset\n\t\n\nThis dataset was used for supervised fine-tuning (SFT) of the Swallow v0.1 model series.\n\n\t\n\t\t\n\t\tModel Index\n\t\n\nThe following Instruct models were created using this dataset:\n\nLlama-3-Swallow-8B-Instruct-v0.1\nLlama-3-Swallow-70B-Instruct-v0.1\nSwallow-7b-instruct-v0.1\nSwallow-13b-instruct-v0.1\nSwallow-70b-instruct-v0.1\n\nNote: The data used for Swallow-MS-7b-instruct-v0.1 is different.\n\n\t\t\n\t\tStatistical Information\n\t\n\n\n\t\n\t\t\nDataset\nConversations… See the full description on the dataset page: https://huggingface.co/datasets/tokyotech-llm/Swallow-Instruct-v0.1.","first_N":5,"first_N_keywords":["Japanese","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"jawiki-books-paragraphs","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/jawiki-books-paragraphs","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"hpprc/jawiki-books-paragraphs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"jawiki-news-paragraphs","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/jawiki-news-paragraphs","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"hpprc/jawiki-news-paragraphs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"oasst2-chat-5k-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sudy-super/oasst2-chat-5k-ja","creator_name":"Sudy","creator_url":"https://huggingface.co/sudy-super","description":"\n\t\n\t\t\n\t\t説明\n\t\n\nこれはoasst2-chat-68k-jaの前半約41000件をSwallow-MX-8x7b-NVE-instruct-v2で評価した中で最高評価を獲得した物のみを抽出したデータセットです。\nマルチターン会話でのファインチューニングをする際にご活用下さい。\n\n\t\n\t\t\n\t\tPret-a-porter\n\t\n\n\nデータセット\n\n\t\n\t\t\nVariant\nLink\n\n\n\t\t\ninstruction-v0.1\nKendamarron/pret-a-porter-instruction-v0.1\n\n\nmath-problem-v0.1\nKendamarron/pret-a-porter-math-problem-v0.1\n\n\njimba-instruction-simplify-200\nKendamarron/jimba-instruction-simplify-200\n\n\nchat-with-cosmopedia\naixsatoshi/Chat-with-cosmopedia\n\n\nlongcontext-aozora-summary… See the full description on the dataset page: https://huggingface.co/datasets/sudy-super/oasst2-chat-5k-ja.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Japanese-Roleplay","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OmniAICreator/Japanese-Roleplay","creator_name":"OmniAICreator","creator_url":"https://huggingface.co/OmniAICreator","description":"\n\t\n\t\t\n\t\tJapanese-Roleplay\n\t\n\nThis is a dialogue corpus collected from Japanese role-playing forum (commonly known as \"なりきりチャット(narikiri chat)\"). Each record corresponds to a single thread.\nThe following filtering and cleaning conditions have been applied:\n\nFor all post_content in the posts of each record, remove response anchors.\nFor all post_content in the posts of each record, delete posts where the post_content length is 10 characters or less.\nIf the number of unique poster types in the… See the full description on the dataset page: https://huggingface.co/datasets/OmniAICreator/Japanese-Roleplay.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"oasst2-chat-40k-ja-classified","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sudy-super/oasst2-chat-40k-ja-classified","creator_name":"Sudy","creator_url":"https://huggingface.co/sudy-super","description":"\n\t\n\t\t\n\t\n\t\n\t\t説明\n\t\n\nこれはoasst2-chat-68k-jaの前半約41000件をSwallow-MX-8x7b-NVE-instruct-v2で評価したデータセットです。\nマルチターン会話でのファインチューニングをする際にご活用下さい。\n\n\t\n\t\t\n\t\n\t\n\t\tPret-a-porter\n\t\n\n\nデータセット\n\n\t\n\t\t\nVariant\nLink\n\n\n\t\t\ninstruction-v0.1\nKendamarron/pret-a-porter-instruction-v0.1\n\n\nmath-problem-v0.1\nKendamarron/pret-a-porter-math-problem-v0.1\n\n\njimba-instruction-simplify-200\nKendamarron/jimba-instruction-simplify-200\n\n\nchat-with-cosmopedia\naixsatoshi/Chat-with-cosmopedia\n\n\nlongcontext-aozora-summary… See the full description on the dataset page: https://huggingface.co/datasets/sudy-super/oasst2-chat-40k-ja-classified.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","🇺🇸 Region: US"],"keywords_longer_than_N":false},
	{"name":"Bluemoon_Top50MB_Sorted_Fixed_ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Bluemoon_Top50MB_Sorted_Fixed_ja","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tBluemoon_Top50MB_Sorted_Fixed_ja\n\t\n\nSicariusSicariiStuff/Bluemoon_Top50MB_Sorted_Fixedを、GENIAC-Team-Ozaki/karakuri-lm-8x7b-chat-v0.1-awqを用いて日本語に翻訳したロールプレイ学習用データセットです。\nLLMの推論にはDeepInfraというサービスを使いました。\n\n\t\n\t\t\n\t\n\t\n\t\t翻訳の詳細\n\t\n\n\n3-shots promptingでの翻訳\nmistralのtokenizerで出力が8000トークンを超えるまで翻訳\n元データセットにある非常に長い対話は上記条件で途中のターンで翻訳を終了しています。\n\n\nLLM特有の同じ出力が繰り返される現象に遭遇した場合、その時点で該当レコードの翻訳を終了\nこの結果1ターン未満となったレコード（157件）を削除… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Bluemoon_Top50MB_Sorted_Fixed_ja.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ViQuAE-JA","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/toshi456/ViQuAE-JA","creator_name":"toshi456","creator_url":"https://huggingface.co/toshi456","description":"This dataset was created by machine translating \"ViQuAE\" into Japanese.\noriginal_answer_ja translated from original_answer. I didn't translate answer.\nViQuAE: https://github.com/PaulLerner/ViQuAE\n","first_N":5,"first_N_keywords":["image-to-text","Japanese","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"alpaca_jp_math","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/alpaca_jp_math","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\n\t\n\t\t\n\t\talpaca_jp_math\n\t\n\n\nalpaca_jp_mathは、  \n\nStanford Alpacaの手法  \nmistralai/Mixtral-8x22B-Instruct-v0.1\n\nで作った合成データ(Synthetic data)です。モデルの利用にはDeepinfraを利用しています。  \nまた、\"_cleaned\"がついたデータセットは以下の手法で精査されています。  \n\npythonの計算結果がきちんと、テキストの計算結果が同等であるか確認\nLLM(mistralai/Mixtral-8x22B-Instruct-v0.1)による確認（詳細は下記）\n\ncode_result, text_resultは小数第三位で四捨五入してあります。\n\n\n\n\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: HachiMLLanguage(s) (NLP): Japanese\nLicense: Apache 2.0\nGithub: Alpaca-jp… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/alpaca_jp_math.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"commoncatalog-cc-by-ext","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alfredplpl/commoncatalog-cc-by-ext","creator_name":"Yasunori Ozaki","creator_url":"https://huggingface.co/alfredplpl","description":"\n\t\n\t\t\n\t\tCommonCatalog CC-BY Extention\n\t\n\nこのリポジトリはCommonCatalog CC-BYを拡張して、追加の情報を入れたものです。\n以下の情報が追加されています。\n\nPhi-3 VisionでDense Captioningした英語キャプション\n英語キャプションをPhi-3 Mediumで日本語化した日本語キャプション\n\n主キーはphotoidですので、CommonCatalog CC-BYと結合するなりして使ってください。\nstreaming=Trueで読み込むと同じ順に読み込まれますのでそれを利用するのが一番楽です。\n\n\t\n\t\t\n\t\tLicense\n\t\n\n画像がCC BYなため、わかりやすくCC BYにしています。したがって、商用利用可能です。\n\n\t\n\t\t\n\t\tSample Code\n\t\n\nimport pandas\nfrom datasets import load_dataset\n\ndf=pandas.read_csv(\"commoncatalog-cc-by-phi3-ja.csv\")\n\ndataset =… See the full description on the dataset page: https://huggingface.co/datasets/alfredplpl/commoncatalog-cc-by-ext.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","English","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"oasst1_for_self-rewarding_IFT","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/oasst1_for_self-rewarding_IFT","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n\nkunishou/oasst1-89k-ja\nOpenAssistant/oasst1\n\nを元に、self-rewardingのIFT(Instruction Fine-Tuning data)を作成しました。 \nSelf-rewardingの論文では3,200件に絞り込んでいますが、このデータは4,744件となっています。さらに人手でのフィルタリングをする必要があるかもしれません。  \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: HachiML\nLanguage(s) (NLP): Japanese\nLicense: Apache-2.0\n\n\n\t\n\t\t\n\t\tFiltering Rule\n\t\n\n以下のルールで絞り込んでいます。  \n\nFirst Conversational Turn\nrank 0 の回答をもつ\nSingle Turn Conversation\n\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"oasst1_for_self-rewarding_EFT_before_judge","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/oasst1_for_self-rewarding_EFT_before_judge","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n\nkunishou/oasst1-89k-ja\nOpenAssistant/oasst1\n\nを元に、self-rewardingのEFT(Evaluation Fine-Tuning data)の元データを作成しました。 \nこの後に、学習させたいモデルを使ってLLM-as-a-Judgeを行います。Self-rewardingの論文では最終的に train: 1,630 records, test: 531 records に絞り込んでいます。  \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: HachiML\nLanguage(s) (NLP): Japanese\nLicense: Apache-2.0\n\n\n\t\n\t\n\t\n\t\tFiltering Rule\n\t\n\n以下のルールで絞り込んでいます。  \n\nFirst Conversational Turn\nSingle Turn… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/oasst1_for_self-rewarding_EFT_before_judge.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"xflickrco_1k","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xflickrco_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"floschne/xflickrco_1k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["image-to-text","German","English","Spanish","Indonesian"],"keywords_longer_than_N":true},
	{"name":"Rosebleu-1on1-Dialogues","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Rosebleu-1on1-Dialogues","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tRosebleu-1on1-Dialogues\n\t\n\n2025/05/17 3人での対話のデータを追加\n\n\t\n\t\t\n\t\t概要\n\t\n\n@matsuxrさんが公開しているRosebleuデータセットのうち、1つのシーン中で1対1の会話が行われていレコード（登場人物が2人のみのもの）を抽出し、さらに各話者ごとの連続した発話をまとめ、データセットとしてまとめたものです。\nデータの提供者である青猫様、およびデータをまとめデータセットの形式で公開いただいた@matsuxrさんに感謝いたします。\n\n\t\n\t\t\n\t\tRosebleuデータセットについて\n\t\n\n元データセットから概要文を引用します。\n\nRosebleuブランドの代表を務められていた青猫様にご提供いただいた、… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Rosebleu-1on1-Dialogues.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Rosebleu-1on1-Dialogues-RP","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Rosebleu-1on1-Dialogues-RP","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tRosebleu-1on1-Dialogues-RP\n\t\n\n2025/05/17 3人での対話のデータを追加&無駄な改行の削除\n@matsuxrさんが公開しているRosebleuデータセットを加工したAratako/Rosebleu-1on1-Dialoguesを元に、キャラクターや作品の設定などを付け加えたうえで、ロールプレイ的な文脈になるように加工したデータセットです。\nLLMのファインチューニングにおけるロールプレイングタスクの学習を想定しています。\nOpenAI APIのようにroleとcontentのペアの形式となっており、tokenizer.apply_chat_template()によって簡単に各モデルのチャットテンプレートのデータセットへと変換可能です。\n\n\t\n\t\t\n\t\n\t\n\t\tデータセットの詳細\n\t\n\n各キャラの設定や各作品の世界観・あらすじなどをWikipediaやニコニコ大百科からまとめ、ロールプレイ向けにシステムメッセージへと埋め込んでいます。\n現在、以下の2パターンのデータセットを用意してあります。主に地の文の処理方法が異なります。… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Rosebleu-1on1-Dialogues-RP.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"three_line_summarization_for_japanese_news_articles","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/waddledee/three_line_summarization_for_japanese_news_articles","creator_name":"m takahashi","creator_url":"https://huggingface.co/waddledee","description":"ライブドアニュースコーパスの3行要約データセットです。\nLlama v2向けのプロンプトを追加して成形してあります。\n学習に利用する際は、 [R_START] [R_END] をspecial tokenとして追加することを推奨します。\nNumber of rows: 3,907 \nDatasetは以下のリポジトリを利用してscrapeしました。\ngit@github.com:KodairaTomonori/ThreeLineSummaryDataset.git\n","first_N":5,"first_N_keywords":["summarization","Japanese","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"KaidanNihonbunka","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mohamed-khalil/KaidanNihonbunka","creator_name":"Mohammed Khalil","creator_url":"https://huggingface.co/mohamed-khalil","description":"\n\t\n\t\t\n\t\tKaidan Nihonbunka: A Journey Through Hyakumonogatari's Ghostly Tales\n\t\n\n\nWelcome to the Kaidan Nihonbunka Dataset\n\n\n    \n        \n        \n        \n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tAbout Name\n\t\n\nkaidan Nihonbunka translates to 怪談日本文化 in Japanese:\n\n怪談 (Kwaidan): Ghost story or supernatural tale.日本文化 (Nihonbunka): Japanese culture.\n\nSo, the translated name would be 怪談日本文化.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe kaidan Nihonbunka Dataset is a collection of Japanese folklore of ghost stories, also known as \"kaidan\"… See the full description on the dataset page: https://huggingface.co/datasets/mohamed-khalil/KaidanNihonbunka.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Japanese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"jpflan","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ego/jpflan","creator_name":"Paolo","creator_url":"https://huggingface.co/Ego","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a templated version of data from ~40 Japanese open source downstream task datasets.This dataset was built with the intention of instruction tuning LLMs with high quality data that was not machine translated to and from Japanese.The raw data version can be found here.  \n\n\t\n\t\t\n\t\tDataset format\n\t\n\nThis dataset version contains at most 20000 samples for each dataset, half of which are 0-shot examples, and the other half are few-shot examples (max 3).To create your… See the full description on the dataset page: https://huggingface.co/datasets/Ego/jpflan.","first_N":5,"first_N_keywords":["text-generation","Japanese","cc-by-sa-4.0","100K - 1M","arrow"],"keywords_longer_than_N":true},
	{"name":"japanese-nsfw-syosetsu-dataset","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Elizezen/japanese-nsfw-syosetsu-dataset","creator_name":"Elize Veldhuizen","creator_url":"https://huggingface.co/Elizezen","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset comprises a collection of NSFW (Not Safe for Work) novels sourced from various platforms on the internet. Originally created for personal use, the selection of novels included in the dataset is based on my personal preferences.\nThe dataset is used for fine-tuning most of the Japanese LLMs I have uploaded, including Antler-7B.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is primarily intended for unsupervised training of erotic text… See the full description on the dataset page: https://huggingface.co/datasets/Elizezen/japanese-nsfw-syosetsu-dataset.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","🇺🇸 Region: US","novel","training"],"keywords_longer_than_N":true},
	{"name":"japanese-nsfw-syosetsu-dataset","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Elizezen/japanese-nsfw-syosetsu-dataset","creator_name":"Elize Veldhuizen","creator_url":"https://huggingface.co/Elizezen","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset comprises a collection of NSFW (Not Safe for Work) novels sourced from various platforms on the internet. Originally created for personal use, the selection of novels included in the dataset is based on my personal preferences.\nThe dataset is used for fine-tuning most of the Japanese LLMs I have uploaded, including Antler-7B.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is primarily intended for unsupervised training of erotic text… See the full description on the dataset page: https://huggingface.co/datasets/Elizezen/japanese-nsfw-syosetsu-dataset.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","🇺🇸 Region: US","novel","training"],"keywords_longer_than_N":true},
	{"name":"ParallelFiction-Ja_En-100k-alpaca-4k-context","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mpasila/ParallelFiction-Ja_En-100k-alpaca-4k-context","creator_name":"minipasila","creator_url":"https://huggingface.co/mpasila","description":"This is a modified version of NilanE/ParallelFiction-Ja_En-100k which has been turned into Alpaca format.\nThis has also been chunked for 4096 tokens for augmxnt/shisa-base-7b-v1 model's tokenizer.\nIf you want the non chunked version it's here.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset format (correct one)\n\t\n\n{\n  'instruction' : 'Japanese chapter'\n  'output' : 'English translation'\n  'input' : 'empty'\n}\n\n\n\t\n\t\n\t\n\t\tOriginal Dataset card\n\t\n\n\n\t\n\t\n\t\n\t\tDataset details\n\t\n\nEach entry in this dataset is a sentence-aligned… See the full description on the dataset page: https://huggingface.co/datasets/mpasila/ParallelFiction-Ja_En-100k-alpaca-4k-context.","first_N":5,"first_N_keywords":["translation","Japanese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"chat-daily","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/minnade/chat-daily","creator_name":"MinnadeChat","creator_url":"https://huggingface.co/minnade","description":"\n\t\n\t\t\n\t\tMinnadeChat データセット (毎日更新)\n\t\n\nみんなで作る指示データセット の投稿のデータセットです。このデータセットは毎日12時に更新されます。\n\n\t\n\t\t\n\t\t🤗 HuggingFace datasets から使う\n\t\n\n最新版 を取得したい場合:\nfrom datasets import load_dataset\n\nds = load_dataset(\"minnade/chat-daily\", split=\"train\")\n\nprint(ds)\n#Dataset({\n#    features: ['id', 'parent_id', 'role', 'body', 'category_id', 'tags', 'is_synthetic', 'is_deleted', 'knowledge_cut_off', 'created_at', 'review', 'review_count', 'flag', 'flag_count'],\n#    num_rows: 196\n#})\n\n日付を指定して取得したい場合:\nfrom datasets… See the full description on the dataset page: https://huggingface.co/datasets/minnade/chat-daily.","first_N":5,"first_N_keywords":["text-generation","Japanese","cc0-1.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mbpp-ja","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-jp/mbpp-ja","creator_name":"LLM-jp","creator_url":"https://huggingface.co/llm-jp","description":"\n\t\n\t\t\n\t\tmbpp-ja\n\t\n\nThis repository provides a mbpp dataset translated from English into Japanese by LLM-jp, a collaborative project launched in Japan.\nFor English to Japanese translation, DeepL was used.\nThe links of the original mbpp dataset are here(HuggingFace) or here(GitHub).\n\n\t\n\t\t\n\t\n\t\n\t\tSend Questions to\n\t\n\nllm-jp(at)nii.ac.jp\n\n\t\n\t\t\n\t\n\t\n\t\tModel Card Authors\n\t\n\nThe names are listed in alphabetical order.\nNamgi Han, Masatoshi Otake, Shintaro Ozaki, Yusuke Miyao.\n","first_N":5,"first_N_keywords":["text2text-generation","Japanese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"hh-rlhf-12k-ja_orpo","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ryota39/hh-rlhf-12k-ja_orpo","creator_name":"kaeru39","creator_url":"https://huggingface.co/ryota39","description":"ryota39/hh-rlhf-12k-ja_orpo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Japanese","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-17.0-ja-client_id-grouped","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-ja-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\n\t\n\t\t\n\t\tcv-corpus-17.0-ja-client_id-grouped\n\t\n\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nThe dataset is derived from the Common Voice dataset.\nThe original dataset is available at Common Voice Dataset.\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\nEach group is filtered to include only client IDs with a minimum of 30 samples and a maximum of… See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-ja-client_id-grouped.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","Japanese"],"keywords_longer_than_N":true},
	{"name":"nomiracl-instruct","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/nomiracl-instruct","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\n\t\n\t\t\n\t\tDataset Card for NoMIRACL (EMNLP 2024 Findings Track)\n\t\n\n\n\t\n\t\t\n\t\tQuick Overview\n\t\n\nThis repository contains the fine-tuning (training & development split) of the NoMIRACL instruct dataset for fine-tuning LLMs on multilingual relevance assessment.\nThe training dataset is a binary classification task; they need to explicitly output either Yes, answer is present or I don't know. \nThe dataset contains training pairs from all 18 languages for both splits: relevant & non-relevant.\nimport… See the full description on the dataset page: https://huggingface.co/datasets/miracl/nomiracl-instruct.","first_N":5,"first_N_keywords":["text-classification","text-generation","Arabic","Bengali","German"],"keywords_longer_than_N":true},
	{"name":"JA-Multi-Image-VQA","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SakanaAI/JA-Multi-Image-VQA","creator_name":"Sakana AI","creator_url":"https://huggingface.co/SakanaAI","description":"\n\t\n\t\t\n\t\tJA-Multi-Image-VQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nJA-Multi-Image-VQA is a dataset for evaluating the question answering capabilities on multiple image inputs. \nWe carefully collected a diverse set of 39 images with 55 questions in total.\nSome images contain Japanese culture and objects in Japan. The Japanese questions and answers were created manually.\n\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"SakanaAI/JA-Multi-Image-VQA\", split=\"test\")… See the full description on the dataset page: https://huggingface.co/datasets/SakanaAI/JA-Multi-Image-VQA.","first_N":5,"first_N_keywords":["visual-question-answering","Japanese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"japanese-photos","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ThePioneer/japanese-photos","creator_name":"The Pioneer","creator_url":"https://huggingface.co/ThePioneer","description":"\n\t\n\t\t\n\t\tJapan Diverse Images Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a comprehensive collection of high-quality images capturing the diverse aspects of Japan, including urban landscapes, natural scenery, historical sites, contemporary art, everyday life, and culinary experiences. It is designed to provide a rich and varied representation of Japan for AI training purposes.\nNote that the photos were taken by myself in the 2020s, mainly from 2022 to 2024, with some exceptions.… See the full description on the dataset page: https://huggingface.co/datasets/ThePioneer/japanese-photos.","first_N":5,"first_N_keywords":["English","Japanese","cc0-1.0","10K<n<100K","Image"],"keywords_longer_than_N":true},
	{"name":"Furigana-Aozora","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Calvin-Xu/Furigana-Aozora","creator_name":"Calvin Xu","creator_url":"https://huggingface.co/Calvin-Xu","description":"Derived from 青空文庫及びサピエの点字データから作成した振り仮名のデータセット（GitHub）\nhttps://github.com/ndl-lab/huriganacorpus-aozora\nCertain mismatches in the original corpus were eliminated during validation (307 instances)\nError: 烈しい調子である。 != パンツだったのである。, file: 中島敦/環礁_ミクロネシヤ巡島記抄/kansho.txt\nError: 彼がそれにどれだけ成功するかは、これからの問題だが。 != ――, file: 堀辰雄/聖家族/seikazoku.txt\nError: 「なんだか目の中にゴミがはいっちゃったわ……」 != 「びっくりしたじゃないの……」, file: 堀辰雄/聖家族/seikazoku.txt\nError: それは斯波という男の声であった。 != ……, file: 堀辰雄/聖家族/seikazoku.txt\nError:… See the full description on the dataset page: https://huggingface.co/datasets/Calvin-Xu/Furigana-Aozora.","first_N":5,"first_N_keywords":["text2text-generation","Japanese","mit","1M - 10M","arrow"],"keywords_longer_than_N":true},
	{"name":"Furigana-NDLBIB","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Calvin-Xu/Furigana-NDLBIB","creator_name":"Calvin Xu","creator_url":"https://huggingface.co/Calvin-Xu","description":"Derived from 全国書誌データから作成した振り仮名のデータセット（GitHub）\nhttps://github.com/ndl-lab/huriganacorpus-ndlbib\nCertain mismatches in the original corpus were eliminated during validation (5064 instances).\n","first_N":5,"first_N_keywords":["text2text-generation","Japanese","mit","10M - 100M","arrow"],"keywords_longer_than_N":true},
	{"name":"JSQuAD","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sbintuitions/JSQuAD","creator_name":"SB Intuitions","creator_url":"https://huggingface.co/sbintuitions","description":"評価スコアの再現性確保と SB Intuitions 修正版の公開用クローン\nソース: yahoojapan/JGLUE on GitHub\n\n\t\n\t\t\n\t\tJSQuAD\n\t\n\n\nJSQuAD is a Japanese version of SQuAD (Rajpurkar+, 2016), one of the datasets of reading comprehension.\nEach instance in the dataset consists of a question regarding a given context (Wikipedia article) and its answer.\nJSQuAD is based on SQuAD 1.1 (there are no unanswerable questions).\nWe used the Japanese Wikipedia dump as of 20211101.\n\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nCreative Commons Attribution Share… See the full description on the dataset page: https://huggingface.co/datasets/sbintuitions/JSQuAD.","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"JCommonsenseQA","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sbintuitions/JCommonsenseQA","creator_name":"SB Intuitions","creator_url":"https://huggingface.co/sbintuitions","description":"評価スコアの再現性確保と SB Intuitions 修正版の公開用クローン\nソース: yahoojapan/JGLUE on GitHub\n\ndatasets/jcommonsenseqa-v1.1\n\n\n\t\n\t\t\n\t\tJCommonsenseQA\n\t\n\n\nJCommonsenseQA is a Japanese version of CommonsenseQA (Talmor+, 2019), which is a multiple-choice question answering dataset that requires commonsense reasoning ability.\nIt is built using crowdsourcing with seeds extracted from the knowledge base ConceptNet.\n\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nCreative Commons Attribution Share Alike 4.0 International\n\n\t\n\t\t\n\t\tCitation… See the full description on the dataset page: https://huggingface.co/datasets/sbintuitions/JCommonsenseQA.","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"EC-Guide","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AiMijie/EC-Guide","creator_name":"AiMijie","creator_url":"https://huggingface.co/AiMijie","description":"\n\t\n\t\t\n\t\tThis repo is only used for dataset viewer. Please download from here.\n\t\n\n\n\t\n\t\t\n\t\tAmazon KDDCup 2024 Team ZJU-AI4H’s Solution and Dataset (Track 2 Top 2; Track 5 Top 5)\n\t\n\nThe Amazon KDD Cup’24 competition presents a unique challenge by focusing on the application of LLMs in E-commerce across multiple tasks. Our solution for addressing Tracks 2 and 5 involves a comprehensive pipeline encompassing dataset construction, instruction tuning, post-training quantization, and inference… See the full description on the dataset page: https://huggingface.co/datasets/AiMijie/EC-Guide.","first_N":5,"first_N_keywords":["question-answering","text-generation","translation","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"ValueConsistency","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jlcmoore/ValueConsistency","creator_name":"Jared","creator_url":"https://huggingface.co/jlcmoore","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for ValueConsistency\n\t\n\n\n\nThis is the ValueConsistency data set as introduced in the paper\n\"Are Large Language Models Consistent over Value-laden Questions?\".\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\nValueConsistency is a dataset of both controversial and uncontroversial questions \nin English, Chinese, German, and Japanese for topics from the U.S., China, Germany, and Japan. \nIt was generated via prompting by GPT-4 and validated manually.\nYou… See the full description on the dataset page: https://huggingface.co/datasets/jlcmoore/ValueConsistency.","first_N":5,"first_N_keywords":["English","Chinese","German","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"danbooru2025-metadata","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/trojblue/danbooru2025-metadata","creator_name":"trojblue","creator_url":"https://huggingface.co/trojblue","description":" \n   \n \n\n🎨 Danbooru 2025 Metadata \n\n\n  Latest Post ID: 9,158,800\n  (as of Apr 16, 2025)\n\n\n\n📁 About the DatasetThis dataset provides structured metadata for user-submitted images on Danbooru, a large-scale imageboard focused on anime-style artwork.\nScraping began on January 2, 2025, and the data are stored in Parquet format for efficient programmatic access.Compared to earlier versions, this snapshot includes:\n\nMore consistent tag history tracking  \nBetter coverage of older or previously… See the full description on the dataset page: https://huggingface.co/datasets/trojblue/danbooru2025-metadata.","first_N":5,"first_N_keywords":["text-to-image","image-classification","English","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"BoundingDocs","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/letxbe/BoundingDocs","creator_name":"Letxbe","creator_url":"https://huggingface.co/letxbe","description":"\n\nBoundingDocs\n\n🔍 The largest spatially-annotated dataset for Document Question Answering\n\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nBoundingDocs is a unified dataset for Document Question Answering (QA) that includes spatial annotations. It consolidates multiple public datasets from Document AI and Visually Rich Document Understanding (VRDU) domains. The dataset reformulates Information Extraction (IE) tasks into QA tasks, making it a valuable resource for training and evaluating Large Language… See the full description on the dataset page: https://huggingface.co/datasets/letxbe/BoundingDocs.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","Italian","Spanish"],"keywords_longer_than_N":true},
	{"name":"booru_artists_merged","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/supercatdoing/booru_artists_merged","creator_name":"supercatdoing","creator_url":"https://huggingface.co/supercatdoing","description":"\n\t\n\t\t\n\t\tbooru_artists_merged\n\t\n\n\n\t\n\t\t\n\t\tAbout\n\t\n\nThis data set is a parquet file containing artist lists extracted from danbooru (2024/12/1x version)  \nExcluding those with a post_count of 0  \nPlease use this as a reference when processing data locally, such as creating CSV files.Example of processing to create CSV and translation for tag completion of A1111\nThis file was created based on the danbooru API.  \n\n\t\n\t\t\n\t\n\t\n\t\tField Name Description\n\t\n\nThe field names are as you see, but some… See the full description on the dataset page: https://huggingface.co/datasets/supercatdoing/booru_artists_merged.","first_N":5,"first_N_keywords":["English","Japanese","cc0-1.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Saka-Alpaca-v1","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Saka-Alpaca-v1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"https://chatgpt.com\n","first_N":5,"first_N_keywords":["text-generation","Swedish","Norwegian","Finnish","German"],"keywords_longer_than_N":true},
	{"name":"tasks-ime-and-kakko-jp","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pokutuna/tasks-ime-and-kakko-jp","creator_name":"Pokuda Tunahiko","creator_url":"https://huggingface.co/pokutuna","description":"\n\t\n\t\t\n\t\time-and-kakko\n\t\n\nelyza/ELYZA-tasks-100 中の\n\nIME のように変換候補を提示するタスク\nカッコの対応関係を整えるタスク\n\nのバリエーションを手で作成したもの\n東京大学松尾・岩澤研究室（松尾研）大規模言語モデル Deep Learning 応用講座 2024 で開催されたコンペティションにおいて、 @pokutuna が作成したモデルの苦手問題を克服するために作成しました。\n","first_N":5,"first_N_keywords":["fill-mask","Japanese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"ChouBun","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SakanaAI/ChouBun","creator_name":"Sakana AI","creator_url":"https://huggingface.co/SakanaAI","description":"\n\t\n\t\t\n\t\tChouBun\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nChouBun is a benchmark for assessing LLMs' performance in long-context tasks in the Japanese language.\nIt is created and introduced in the paper An Evolved Universal Transformer Memory.\nThe benchmark includes documents from multiple websites and synthetic question-answer pairs generated by GPT-4 variants and Claude-3.5-Sonnet.\nThe current version of ChouBun contains 2 task categories -- extractive QA and abstractive summarization -- and 4 tasks… See the full description on the dataset page: https://huggingface.co/datasets/SakanaAI/ChouBun.","first_N":5,"first_N_keywords":["question-answering","summarization","Japanese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"RAG-Evaluation-Dataset-JA","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/allganize/RAG-Evaluation-Dataset-JA","creator_name":"allganize","creator_url":"https://huggingface.co/allganize","description":"\n\t\n\t\t\n\t\tAllganize RAG Leaderboard とは\n\t\n\nAllganize RAG Leaderboard は、5つの業種ドメイン（金融、情報通信、製造、公共、流通・小売）において、日本語のRAGの性能評価を実施したものです。一般的なRAGは簡単な質問に対する回答は可能ですが、図表の中に記載されている情報などに対して回答できないケースが多く存在します。RAGの導入を希望する多くの企業は、自社と同じ業種ドメイン、文書タイプ、質問形態を反映した日本語のRAGの性能評価を求めています。RAGの性能評価には、検証ドキュメントや質問と回答といったデータセット、検証環境の構築が必要となりますが、AllganizeではRAGの導入検討の参考にしていただきたく、日本語のRAG性能評価に必要なデータを公開いたしました。RAGソリューションは、Parser、Retrieval、Generation の3つのパートで構成されています。現在、この3つのパートを総合的に評価した日本語のRAG Leaderboardは存在していません。（公開時点）Allganize RAG… See the full description on the dataset page: https://huggingface.co/datasets/allganize/RAG-Evaluation-Dataset-JA.","first_N":5,"first_N_keywords":["Japanese","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"NeuroPiano-data","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anusfoil/NeuroPiano-data","creator_name":"Huan Zhang","creator_url":"https://huggingface.co/anusfoil","description":"\n\t\n\t\t\n\t\tDataset Card for NeuroPiano-data\n\t\n\n\n\nThis dataset contains 2255 entries of audio-question-answer pairs that specializes in music education. Questions ranges from cleaness of attack to hands balancing, each one come with verbal response as well as a rating within 6. There are 104 unique student recordings of piano excercises and part of them are rated by multiple teachers.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\nCurated by: Hayato Nishioka, Vincent Cheung, Huan… See the full description on the dataset page: https://huggingface.co/datasets/anusfoil/NeuroPiano-data.","first_N":5,"first_N_keywords":["audio-classification","Japanese","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"in-foxhound-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DataPilot/in-foxhound-ja","creator_name":"DataPilot","creator_url":"https://huggingface.co/DataPilot","description":"\n\t\n\t\t\n\t\t概要\n\t\n\nこのデータセットはglaive-aiが公開しているin-foxhoundをKUJIRAを用いて日本語に翻訳したものになります。\n\n\t\n\t\t\n\t\t内容\n\t\n\nこのデータセットは主に投資やバークシャーハサウェイ、ウォーレン・バフェットについて書かれているinstructionデータセットになります。\n\n\t\n\t\t\n\t\t謝辞\n\t\n\n翻訳するための計算資源を貸して下さいったMDLのみなさまに感謝を申し上げます。\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"kurage_training_data","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/kurage_training_data","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"lightblue/kurage_training_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Arabic","English","Spanish","Hindi","Indonesian"],"keywords_longer_than_N":true},
	{"name":"mgsm","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jbross-ibm-research/mgsm","creator_name":"J Bross","creator_url":"https://huggingface.co/jbross-ibm-research","description":"\n\t\n\t\t\n\t\tDataset Card for MGSM\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCopy and merge of this MGSM Dataset, Catalan version, Basque version, Galician version, but in training samples we removed the prompt formatting, e.g. removed Question: ... in question field or Answer: ... in answer field.\nMultilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper Language models are multilingual chain-of-thought reasoners.\nThe same 250 problems from GSM8K are… See the full description on the dataset page: https://huggingface.co/datasets/jbross-ibm-research/mgsm.","first_N":5,"first_N_keywords":["text2text-generation","found","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"elementray_m","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/if001/elementray_m","creator_name":"issei fujimoto","creator_url":"https://huggingface.co/if001","description":"calm3-22bを使って簡単な日本語の例文を作成したデータセットです。\n以下のパターンが含まれるように一文を作成しています。\n生成に失敗しているものはクリーニングしています。\n    \"です/だ (肯定文)\",\n    \"ではありません/じゃない (否定文)\",\n    \"〜ます (動詞の丁寧形)\",\n    \"〜ません (動詞の否定形)\",\n    \"〜たい (希望・願望)\",\n    \"〜ている (進行形)\",\n    \"〜てください (依頼)\",\n    \"〜てもいいですか (許可)\",\n    \"〜なければなりません/〜なきゃいけない (義務)\",\n    \"〜でしょう/〜だろう (推測)\",\n    \"〜が好きです/嫌いです (好み)\",\n    \"〜と思います (意見・思考)\",\n    \"〜から/〜ので (理由)\",\n    \"〜のが好きです/嫌いです (動作の好み)\",\n    \"〜でしょうか (丁寧な質問)\",\n    \"〜てしまう (完了・後悔)\",\n    \"〜ながら (同時進行)\",\n    \"〜ば/〜たら (仮定形)\",\n    \"〜ておく (準備)\"… See the full description on the dataset page: https://huggingface.co/datasets/if001/elementray_m.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"xtreme-up-semantic-parsing","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for afrixnli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSee XTREME-UP GitHub\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 20 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata = load_dataset('Davlan/xtreme-up-semantic-parsing', 'yor') \n# Please, specify the language code\n# A data point example is below:\n{\n\"id\": \"3231323330393336\",\n\"split\": \"test\",\n\"intent\": \"IN:GET_REMINDER\",\n\"locale\": \"en\"… See the full description on the dataset page: https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing.","first_N":5,"first_N_keywords":["text-classification","multilingual","Amharic","Belarusian","Bengali"],"keywords_longer_than_N":true},
	{"name":"e621-2024_index","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deepghs/e621-2024_index","creator_name":"DeepGHS","creator_url":"https://huggingface.co/deepghs","description":"Tar index files for boxingscorpionbagel/e621-2024.\nYou can download images from both boxingscorpionbagel/e621-2024 and deepghs/e621_newest with cheesechaser.\nfrom cheesechaser.datapool import E621NewestDataPool\n\npool = E621NewestDataPool()\n\n# download e621 #2010000-2010300, to directory /data/e621\npool.batch_download_to_directory(\n    resource_ids=range(2010000, 2010300),\n    dst_dir='/data/e621',\n    max_workers=12,\n)\n\n","first_N":5,"first_N_keywords":["image-classification","image-to-image","text-to-image","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"jaqket","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/jaqket","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  JaqketRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nJAQKET (JApanese Questions on Knowledge of EnTities) is a QA dataset that is created based on quiz questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Non-fiction, Written\nReference\nhttps://github.com/kumapo/JAQKET-dataset\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"JaqketRetrieval\"])… See the full description on the dataset page: https://huggingface.co/datasets/mteb/jaqket.","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","Japanese"],"keywords_longer_than_N":true},
	{"name":"tradingview_msn_financial_news_1k","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xinqiyang/tradingview_msn_financial_news_1k","creator_name":"XinqiYang","creator_url":"https://huggingface.co/xinqiyang","description":"xinqiyang/tradingview_msn_financial_news_1k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["summarization","Japanese","English","cc0-1.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Wikipedia-Vision-JA","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turing-motors/Wikipedia-Vision-JA","creator_name":"Turing Inc.","creator_url":"https://huggingface.co/turing-motors","description":"\n\t\n\t\t\n\t\tDataset Card for Wikipedia-Vision-JA\n\t\n\n\n\t\n\t\t\n\t\tDataset description\n\t\n\nThe Wikipedia-Vision-JA is a Vision Language Model dataset generated from Japanese Wikipedia, containing 1.6M pairs of images, captions, and descriptions.\nThis dataset itself does not contain raw image data. Instead, an image_url is provided for each item.\n\n\t\n\t\t\n\t\tFormat\n\t\n\nWikipedia_Vision_JA.jsonl contains JSON-formatted rows with the following keys:\n\nkey: Unique JSON ID\ncaption: Short caption for the image… See the full description on the dataset page: https://huggingface.co/datasets/turing-motors/Wikipedia-Vision-JA.","first_N":5,"first_N_keywords":["image-to-text","Japanese","cc-by-sa-4.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"wit","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/wit","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  WITT2IRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve images based on multilingual descriptions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://proceedings.mlr.press/v162/bugliarello22a/bugliarello22a.pdf\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"WITT2IRetrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/wit.","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","multilingual"],"keywords_longer_than_N":true},
	{"name":"atlassian-qna","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/youngmon/atlassian-qna","creator_name":"youngseo","creator_url":"https://huggingface.co/youngmon","description":"\n\t\n\t\t\n\t\t📄 Question and Answer for Atlassian Products\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nAtlassian Community\n\n\n\t\n\t\t\n\t\tData Description\n\t\n\nThe dataset primarily includes questions, answers, tags, and URLs.\n\nQuestions contain the author, title, and content of the post.\nAnswers include usage instructions, solutions, and other information provided by engineers and users.\nTags represent the categories or topics of the post.\nURLs provide links to the original documents.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure… See the full description on the dataset page: https://huggingface.co/datasets/youngmon/atlassian-qna.","first_N":5,"first_N_keywords":["question-answering","English","Korean","Chinese","Japanese"],"keywords_longer_than_N":true},
	{"name":"japanese-photo-instruction","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kendamarron/japanese-photo-instruction","creator_name":"Kendamarron","creator_url":"https://huggingface.co/Kendamarron","description":"\n\t\n\t\t\n\t\tDataset Information\n\t\n\nこのデータセットは、ThePioneer/japanese-photosの写真をお借りして、\n\nQwen/Qwen2-VL-7B-Instruct\nQwen/Qwen2.5-32B-Instruct-AWQ\n\nの2つのモデルを使って生成した合成データセットです。\n\n\t\n\t\t\n\t\tDetail\n\t\n\nhttps://zenn.dev/kendama/articles/cd5196a33bc46c\n","first_N":5,"first_N_keywords":["visual-question-answering","Japanese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU 🌍 is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) 🗽 or Culturally Agnostic (CA) ⚖️. These annotations were collected as part of an open… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU.","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"comment-translation-01","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ifmain/comment-translation-01","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","description":"This dataset is based on Kaggle.  \nThis dataset includes translations of 69,000 Reddit comments into 17 languages (English to 16 languages):\nBelarusian, Czech, German,\nEnglish, Spanish, Finnish,\nFrench, Italian, Japanese,\nKazakh, Korean, Latvian,\nPolish, Russian, Swedish,\nUkrainian, and Chinese.\nIt contains 50% regular comments and 50% highly negative ones.\nEnjoy using it!\n","first_N":5,"first_N_keywords":["English","German","French","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEDataset","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   📃 Paper • 🌐 Demo • 🤗 ApolloMoEDataset • 🤗 ApolloMoEBench  • 🤗 Models  •🌐 Apollo  • 🌐 ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\t🌈 Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is published！🎉\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click to… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEBench","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   📃 Paper • 🌐 Demo • 🤗 ApolloMoEDataset • 🤗 ApolloMoEBench  • 🤗 Models  •🌐 Apollo  • 🌐 ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\t🌈 Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is published！🎉\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click to… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"magpie-qwen2.5-32B-10K-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DeL-TaiseiOzaki/magpie-qwen2.5-32B-10K-ja","creator_name":"Taisei Ozaki","creator_url":"https://huggingface.co/DeL-TaiseiOzaki","description":"\n\t\n\t\t\n\t\t合成日本語指示データセット\n\t\n\n\n\t\n\t\t\n\t\t概要\n\t\n\nこのデータセットは、大規模言語モデル（Qwen2.5-32B-instruct）を用いて自動生成された日本語の指示とそれに対する応答のコレクションです。データセットは指示付与型のタスクのための学習や評価に使用することを目的としています。\n\n\t\n\t\t\n\t\tデータセット仕様\n\t\n\n\nサンプル数: 20,000\n言語: 日本語\nフォーマット: JSON\nライセンス: Apache-2.0\nサイズカテゴリ: 10K<n<100K\n\n\n\t\n\t\t\n\t\t生成方法\n\t\n\nデータセットは以下のプロセスを通じて生成されました：\n\nQwen2.5-32B Instructモデルを使用\n各サンプルは3段階のプロセスで生成:\na) 指示文の生成\nb) Chain-of-Thought (CoT) 応答の生成 (一部のデータには含まれない)\nc) 最終的な応答のself-refine\n\n\n生成の多様性を向上させるため、10種類のペルソナからランダムに1つ選んでシステムプロンプトに入力\n\n詳細な生成プロセスはこちらをご覧ください。… See the full description on the dataset page: https://huggingface.co/datasets/DeL-TaiseiOzaki/magpie-qwen2.5-32B-10K-ja.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"global_mmlu_ja_edited","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akkikiki/global_mmlu_ja_edited","creator_name":"Yoshinari Fujinuma","creator_url":"https://huggingface.co/akkikiki","description":"Associated code for this dataset is available at https://github.com/akkikiki/global_mmlu_edit\n\n\t\n\t\t\n\t\tLoading the dataset\n\t\n\nfrom datasets import load_dataset\n\n# From JSON\nds = load_dataset(\"akkikiki/global_mmlu_ja_edited\")\n\n# If migrating with the original Global MMLU, remove additional columns\nds = ds.remove_columns(\"is_edited\")\n\n\n# load HF dataset\nglobal_mmlu_ja = load_dataset(\"CohereForAI/Global-MMLU\", 'ja')\nglobal_mmlu_ja[\"dev\"] = ds[\"train\"]\n\n\n\t\n\t\t\n\t\tAdditional Information\n\t\n\nAuthorship… See the full description on the dataset page: https://huggingface.co/datasets/akkikiki/global_mmlu_ja_edited.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xm100","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM100\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"mmmlu_lite","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","description":"\n\t\n\t\t\n\t\tMMMLU-Lite\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is about 10% of… See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"prompt-injection-multilingual","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rikka-snow/prompt-injection-multilingual","creator_name":"Le Xuan Hoang","creator_url":"https://huggingface.co/rikka-snow","description":"rikka-snow/prompt-injection-multilingual dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Vietnamese","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"Vulpisfoglia","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Vulpisfoglia","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Vulpisfoglia dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","Italian"],"keywords_longer_than_N":true},
	{"name":"Japanese-QA111dataset","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tomo1222/Japanese-QA111dataset","creator_name":"tomo mimu","creator_url":"https://huggingface.co/tomo1222","description":"Data created manually\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"art-museums-pd-440k","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mitsua/art-museums-pd-440k","creator_name":"elanmitsua","creator_url":"https://huggingface.co/Mitsua","description":"\n\t\n\t\t\n\t\tArt Museums PD 440K\n\t\n\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThis is a dataset to train text-to-image or any text and image multimodal models with minimized copyright/licensing concerns.\nAll images and texts in this dataset are orignally shared under CC0 or public domain, and no pretrained models or any AI models are used to build this dataset except for our ElanMT model to translate English captions to Japanese.\nElanMT model is trained solely on licensed corpus.\n\n\t\n\t\t\n\t\n\t\n\t\tData sources\n\t\n\nImages and… See the full description on the dataset page: https://huggingface.co/datasets/Mitsua/art-museums-pd-440k.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","English","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"safe-commons-pd-3m","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mitsua/safe-commons-pd-3m","creator_name":"elanmitsua","creator_url":"https://huggingface.co/Mitsua","description":"\n\t\n\t\t\n\t\tSafe Commons PD 3M\n\t\n\n\nThis is a balanced and safe-to-use public domain / CC0 images dataset.\nAll images and texts come from Wikimedia Commons and Wikidata with strict filtering.\nImages license is either Public Domain or CC0 (varies by image).\nTexts license is either CC0 or CC BY-SA (varies by caption source).\nNo synthetic data (AI generated images or captions) is in the dataset.\n\nTo build this dataset, we tried to avoid any knowledge leaks from existing pre-trained models at the… See the full description on the dataset page: https://huggingface.co/datasets/Mitsua/safe-commons-pd-3m.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","English","Japanese","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"Magpie-QwQ-Reasoning-dpo","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/niryuu/Magpie-QwQ-Reasoning-dpo","creator_name":"Itsuro Tajima","creator_url":"https://huggingface.co/niryuu","description":"This DPO dataset is synthesized by this way:\n\ninstructions: Magpie on QwQ-32b-Preview\noutputs: QwQ-32b-Preview and calm3-22b-chat.\n\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"jnli","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zenless-lab/jnli","creator_name":"Zenless Lab","creator_url":"https://huggingface.co/zenless-lab","description":"\n\t\n\t\t\n\t\tJGLUE[JNLI]: Japanese General Language Understanding Evaluation\n\t\n\nJNLI(yahoojapan/JGLUE) is a Japanese version of the NLI (Natural Language Inference) dataset. \nNLI is a task to recognize the inference relation that a premise sentence has to a hypothesis sentence. \nThe inference relations are entailment, contradiction, and neutral.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]\n\t\n\n\nRepository: yahoojapan/JGLUE\nPaper: [More Information Needed]\n\n\n\t\n\t\n\t\n\t\tCitation… See the full description on the dataset page: https://huggingface.co/datasets/zenless-lab/jnli.","first_N":5,"first_N_keywords":["text-classification","Japanese","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"… See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"Synthetic-Preference-ja-Qwen2.5-32B-Mistral-Nemo","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kendamarron/Synthetic-Preference-ja-Qwen2.5-32B-Mistral-Nemo","creator_name":"Kendamarron","creator_url":"https://huggingface.co/Kendamarron","description":"\n\t\n\t\t\n\t\tdetail\n\t\n\nhttps://zenn.dev/kendama/articles/d9f6937f28c5a5\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"magpie-qwen-turbo-27k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hama-jp/magpie-qwen-turbo-27k","creator_name":"Hitoshi Takahama","creator_url":"https://huggingface.co/hama-jp","description":"\n\t\n\t\t\n\t\tMagpie-Qwen-Turbo-27k\n\t\n\nAratako/Magpie-Tanuki-8B-annotated-96k\nのアノテーションを利用して件数を減らし、outputをqwen-2.5-turboで再生成したSFT用の26728件のサブセットです。\n\n\t\n\t\t\n\t\t用途\n\t\n\nコーディングを除く小規模な日本語チャット用LLMのためのファインチューニングを想定しています。\n\n\t\n\t\t\n\t\t使用データ\n\t\n\n以下の条件で抽出したinstructionデータを利用して生成しました。\n\ninput_quality（クエリの質）：excellent　のみ\ndifficulty（難易度）：very easy/easy/medium/hard\nprimary_tag（カテゴリ）：\n\"Information seeking\",  # ユーザーがさまざまなトピックに関する特定の情報や事実を求めるクエリ。\n\"Reasoning\",  # 論理的思考、問題解決、または複雑なアイデアの処理が必要なクエリ。\n\"Planning\",  #… See the full description on the dataset page: https://huggingface.co/datasets/hama-jp/magpie-qwen-turbo-27k.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"PossitivaAI","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/PossitivaAI","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"Sakalti/PossitivaAI dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Japanese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Lappland-the-Decadenza","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Lappland-the-Decadenza","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Lappland-the-Decadenza dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","Italian"],"keywords_longer_than_N":true},
	{"name":"Galgame_Speech_SER_16kHz","keyword":"japanese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\n\t\n\t\t\n\t\tDataset Card for Galgame_Speech_SER_16kHz\n\t\n\n\n[!IMPORTANT]The following rules (in the original repository) must be followed:\n必须遵守GNU General Public License v3.0内的所有协议！附加：禁止商用，本数据集以及使用本数据集训练出来的任何模型都不得用于任何商业行为，如要用于商业用途，请找数据列表内的所有厂商授权（笑），因违反开源协议而出现的任何问题都与本人无关！\n训练出来的模型必须开源，是否在README内引用本数据集由训练者自主决定，不做强制要求。\nEnglish:\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset… See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","monolingual","Japanese","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"Galgame_Speech_SER_16kHz","keyword":"japanese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\n\t\n\t\t\n\t\tDataset Card for Galgame_Speech_SER_16kHz\n\t\n\n\n[!IMPORTANT]The following rules (in the original repository) must be followed:\n必须遵守GNU General Public License v3.0内的所有协议！附加：禁止商用，本数据集以及使用本数据集训练出来的任何模型都不得用于任何商业行为，如要用于商业用途，请找数据列表内的所有厂商授权（笑），因违反开源协议而出现的任何问题都与本人无关！\n训练出来的模型必须开源，是否在README内引用本数据集由训练者自主决定，不做强制要求。\nEnglish:\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset… See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","monolingual","Japanese","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"multiturn-qwen2.5-32b","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kendamarron/multiturn-qwen2.5-32b","creator_name":"Kendamarron","creator_url":"https://huggingface.co/Kendamarron","description":"Qwen/Qwen2.5-32B-Instruct-AWQで生成した3ターンのマルチターンinstructionデータセットです。\nQwenで生成したため、英語や中国語が混ざっているレコードがあります。適宜フィルタリングを行ってください。\nAratako/Magpie-Tanuki-8B-annotated-96kのinstructionをお借りしました。\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"dataset-for-annotation-v2","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/dataset-for-annotation-v2","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"Aratako/dataset-for-annotation-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Lappland","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Lappland","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Lappland dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","English"],"keywords_longer_than_N":true},
	{"name":"jbats","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marzena/jbats","creator_name":"Marzena Karpinska","creator_url":"https://huggingface.co/marzena","description":"While we are working on adding a nice datacard please refer to the paper (https://aclanthology.org/W18-2905/) and here (https://vecto.space/projects/jBATS/) for more details!\n","first_N":5,"first_N_keywords":["text-generation","Japanese","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"MegaWika","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/conceptofmind/MegaWika","creator_name":"Enrico Shippole","creator_url":"https://huggingface.co/conceptofmind","description":"\n\t\n\t\t\n\t\tDataset Card for MegaWika\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\nnon-English language, an automated English translation is provided. Furthermore, nearly 130 million English… See the full description on the dataset page: https://huggingface.co/datasets/conceptofmind/MegaWika.","first_N":5,"first_N_keywords":["summarization","question-answering","text-generation","text2text-generation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"honyaku","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/honyaku","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"英語Wikipedia記事の冒頭複数文を抽出し、人手で日本語翻訳した文章レベル対訳データセットです。\n日英対訳コーパスはライセンスが厳しいものが多く、自由に利用できる高品質なパッセージレベルの対訳データセットが少なかったため作成しました。\n翻訳は大体をhpprcが、数件をyano氏が行いました。\npassageサブセットは文章レベルの翻訳(対応する文ごとに改行区切り)を、sentenceサブセットは文ごとの対訳(こちらは代名詞の翻訳の齟齬など誤った翻訳になっている可能性がある)を収載したデータセットです。\n\n\t\n\t\t\n\t\t翻訳方針\n\t\n\nDeepLやGoogle翻訳など、既存の翻訳ツールは翻訳結果を機械学習モデルの入力として使用することを禁じています。\n本データセットは機械学習用途にも利用できる寛容なライセンスの元で公開したかったため、安全のため、できるだけこれらのツールを使用せずに英日翻訳を行いました。\nその代わり、ライセンスの寛容なLLMによる翻訳結果を参考に翻訳を行いました。\n具体的には、日本語における性能が高くライセンスがApache… See the full description on the dataset page: https://huggingface.co/datasets/hpprc/honyaku.","first_N":5,"first_N_keywords":["translation","Japanese","English","cc-by-sa-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"magpie-qwen2.5-32b-reasoning-100k-formatted","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/magpie-qwen2.5-32b-reasoning-100k-formatted","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tmagpie-qwen2.5-32b-reasoning-100k-formatted\n\t\n\nDeL-TaiseiOzaki/magpie-qwen2.5-32b-reasoning-100kをOpenAI messages形式に変換したデータセットです。\n中身や注意事項等については元データセットの概要をご確認ください。\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"jsec","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/jsec","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"JSECホームページ\n","first_N":5,"first_N_keywords":["Japanese","English","cc-by-sa-4.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"Open-Platypus-Japanese-masked-formatted","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Open-Platypus-Japanese-masked-formatted","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tOpen-Platypus-Japanese-masked-formatted\n\t\n\nweblab-GENIAC/Open-Platypus-Japanese-maskedをOpenAI messages形式に変換したデータセットです。\n中身や注意事項等については元データセットの概要をご確認ください。\n","first_N":5,"first_N_keywords":["Japanese","cc-by-4.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"wiki-trans-ja-en","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/wiki-trans-ja-en","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"hpprc/wiki-trans-ja-en dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Japanese","English","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tBelebele-Fleurs\n\t\n\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\n\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/include-base-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tINCLUDE-base (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-base-44.","first_N":5,"first_N_keywords":["text2text-generation","multiple-choice","Albanian","Arabic","Armenian"],"keywords_longer_than_N":true},
	{"name":"kaken-trans-ja-en","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/kaken-trans-ja-en","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"llm-jp-corpus-v3のkakenサブセット中の日本語テキストを、Qwen/Qwen2.5-32B-Instructを用いて日本語から英語に翻訳したデータセットです。\nオープンな日英パラレルコーパスを意図して作成・公開しました。\nid列は翻訳の際に使用したカラムであり、元データセットに存在するidカラムとは異なっています。\nkakenサブセット自体のHF版データセットも合わせてご覧ください: hpprc/llmjp-kaken。\n本データセットのライセンスは元データセットのライセンスを継承し、CC-BY 4.0とします。\n","first_N":5,"first_N_keywords":["translation","Japanese","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Tengentoppa-sft-reasoning-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-sft-reasoning-ja","creator_name":"Taisei Ozaki","creator_url":"https://huggingface.co/DeL-TaiseiOzaki","description":"\n\t\n\t\t\n\t\t日本語指示・推論・回答データセット\n\t\n\n\n\t\n\t\t\n\t\t概要\n\t\n\nこのリポジトリは、SkunkworksAI/reasoning-0.01 に含まれるインストラクションデータを基に、Qwen/Qwen2.5-32B-Instruct モデルを用いて作成した日本語版の指示・推論・回答データセットです。全2000件を生成し、一部の問題のあるデータを除外した後、約1800件の高品質なデータを収録しています。\n\n\t\n\t\t\n\t\tデータセットの構成\n\t\n\n各データエントリは以下の3つの要素で構成されています：\n\n指示（Instruction）: ユーザーからの具体的な指示や質問。\n推論（Reasoning）: 指示に対する論理的な考察やプロセス。\n回答（Answer）: 最終的な回答や解決策。\n\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"magpie-llm-jp-3-13b-20k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DeL-TaiseiOzaki/magpie-llm-jp-3-13b-20k","creator_name":"Taisei Ozaki","creator_url":"https://huggingface.co/DeL-TaiseiOzaki","description":"\n\t\n\t\t\n\t\t合成日本語指示データセット\n\t\n\n\n\t\n\t\t\n\t\t概要\n\t\n\nこのデータセットは、大規模言語モデル（LLM）を用いて自動生成された日本語の指示とそれに対する応答のコレクションです。データセットは指示付与型のタスクのための学習や評価に使用することを目的としています。\n\n\t\n\t\t\n\t\tデータセット仕様\n\t\n\n\nサンプル数: 20,000\n言語: 日本語\nフォーマット: JSON\n\n\n\t\n\t\t\n\t\t生成方法\n\t\n\nデータセットは以下のプロセスを通じて生成されました：\n\nLLM-JP 3.13B Instructモデルを使用\n各サンプルは3段階のプロセスで生成:\na) 指示文の生成\nb) Chain-of-Thought (CoT) 応答の生成 (一部のデータには含まれない)\nc) 最終的な応答のself-refine\n\n\n\nhttps://github.com/DeL-TaiseiOzaki/magpie-llm-jp-3\n\n\t\n\t\t\n\t\tデータ構造\n\t\n\n各サンプルは以下の構造を持つJSONオブジェクトです：\n{\n  \"instruction\": \"指示文\"… See the full description on the dataset page: https://huggingface.co/datasets/DeL-TaiseiOzaki/magpie-llm-jp-3-13b-20k.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"text-moderation-02-multilingual","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ifmain/text-moderation-02-multilingual","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","description":"This dataset is based on Kaggle.It represents a version of @ifmain/text-moderation-410K that has been cleansed of semantically similar values and normalized to a 50/50 ratio of negative and neutral entries.\nThe dataset contains 1.5M entries (91K * 17 languages).  \nBefore use, augmentation is recommended! (e.g., character substitution to bypass moderation).\nFor augmentation, you can use @ifmain/StringAugmentor.  \nEnjoy using it!\n","first_N":5,"first_N_keywords":["English","German","French","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"TinyStories-Japanese","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kai271/TinyStories-Japanese","creator_name":"Kai Eberl","creator_url":"https://huggingface.co/kai271","description":"Dataset containing ~3000 synthetically generated (by GPT-4o-mini) children's stories in Japanese that only use simple words.\nIt was created using the method described in https://arxiv.org/abs/2305.07759.\n","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"Multilingal-sakalt-data","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"マルチリンガルデータセットです。mitライセンスです。\n","first_N":5,"first_N_keywords":["text-generation","Abkhaz","Bhojpuri","Chechen","Czech"],"keywords_longer_than_N":true},
	{"name":"danbooru-ja-tag-pair-20241015","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/p1atdev/danbooru-ja-tag-pair-20241015","creator_name":"Plat","creator_url":"https://huggingface.co/p1atdev","description":"\n\t\n\t\t\n\t\tdanbooru-ja-tag-pair-20241015\n\t\n\n2024/10/15に作成したdanbooruタグと日本語タグのペアデータセット(約15万件)\np1atdev/danbooru-ja-tag-pair-20240715 との違いは、\n\nベースのwikiデータが増えたのでその分対応タグも増えた\nfasttextでのフィルタリングを挟むようにした\n「明らかに他言語のタグ」が混じる頻度はちょっと減った気がするけど、完全ではない\n\n\n\n(calm3くんの処理に)ミスがなければ、最低一つ以上の日本語タグ (other_names フィールド) が存在するはず\n\n\t\n\t\t\n\t\t作成過程\n\t\n\nisek-ai/danbooru-wiki-2024 の #202408-at20240906 revision を元に、\n\nother_names (基本的にPixivのタグ)がついているものから、日本語じゃないもの・曖昧・意味の過不足が大きいタグを除去。処理内容:\nfasttext で80%以上の確信度で日本語ではないものを除去… See the full description on the dataset page: https://huggingface.co/datasets/p1atdev/danbooru-ja-tag-pair-20241015.","first_N":5,"first_N_keywords":["translation","English","Japanese","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Everything_Instruct_Multilingual","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","description":"\n\t\n\t\t\n\t\tEverything Instruct (Multilingual Edition)\n\t\n\nEverything you need... all in one place 💘\n\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\nNote2: This version of the dataset supports the following languages:\n\nEnglish\nRussian… See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual.","first_N":5,"first_N_keywords":["English","Russian","Chinese","Korean","Urdu"],"keywords_longer_than_N":true},
	{"name":"Cauldron-JA","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turing-motors/Cauldron-JA","creator_name":"Turing Inc.","creator_url":"https://huggingface.co/turing-motors","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for The Cauldron-JA\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset description\n\t\n\nThe Cauldron-JA is a Vision Language Model dataset that translates 'The Cauldron' into Japanese using the DeepL API. The Cauldron is a massive collection of 50 vision-language datasets (training sets only) that were used for the fine-tuning of the vision-language model Idefics2.\nTo create a Japanese Vision Language Dataset, datasets related to OCR, coding, and graphs were excluded because translating them into… See the full description on the dataset page: https://huggingface.co/datasets/turing-motors/Cauldron-JA.","first_N":5,"first_N_keywords":["visual-question-answering","Japanese","cc-by-4.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"LLM-jp-Toxicity-Dataset","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/p1atdev/LLM-jp-Toxicity-Dataset","creator_name":"Plat","creator_url":"https://huggingface.co/p1atdev","description":"\n\t\n\t\t\n\t\tLLM-jp Toxicity Dataset\n\t\n\n日本語有害文書データセット「LLM-jp Toxicity Dataset」\nSee https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-toxicity-dataset\n","first_N":5,"first_N_keywords":["text-classification","Japanese","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"mirage-bench-instruct","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/mirage-bench-instruct","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\n\t\n\t\t\n\t\tMIRAGE-Bench (Instruct)\n\t\n\nThis dataset contains the structured RAG outputs for queries in the train split of MIRAGE-Bench (or MIRACL) for 16 languages for five models:\n\ngpt-4o-azure                          (GPT-4o using Azure API)\nmeta-llama/Meta-Llama-3-70B-Instruct  (Llama-3-70B-Instruct using Anyscale API)\nmistralai/Mixtral-8x22B-Instruct-v0.1 (Mixtral-8x22B-Instruct using Anyscale API)\nmeta-llama/Meta-Llama-3-8B-Instruct   (Llama-3-8B-Instruct using vLLM)… See the full description on the dataset page: https://huggingface.co/datasets/nthakur/mirage-bench-instruct.","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","Bengali","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"zenless_zone_zero_interknots_v1.0","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\n\t\n\t\t\n\t\n\t\n\t\tZZZ Interknots\n\t\n\nThis datasets contains extracted Interknot posts and comments (绳网的博客与评论) in multi-language.\nUp to game version: 1.0\n\nInterknot posts and comments examples\n\n{\n  \"id\": \"1021\",\n  \"poster\": \"Sorrowful Intern\",\n  \"title\": \"[Commission] Missing Bangboo merchants\",\n  \"text\": \"Hello, pros... Some of the senior Bangboo of our merchant association have gone missing! We urgently need an expert to help find them!!\\nLet me explain, I recently joined a very prestigious… See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","Japanese","German"],"keywords_longer_than_N":true},
	{"name":"wikipedia-2024-06-bge-m3","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3","creator_name":"Upstash","creator_url":"https://huggingface.co/Upstash","description":"\n\t\n\t\t\n\t\tWikipedia Embeddings with BGE-M3\n\t\n\nThis dataset contains embeddings from the\nJune 2024 Wikipedia dump\nfor the 11 most popular languages.\nThe embeddings are generated with the multilingual\nBGE-M3 model.\nThe dataset consists of Wikipedia articles split into paragraphs,\nand embedded with the aforementioned model.\nTo enhance search quality, the paragraphs are prefixed with their\nrespective article titles before embedding.\nAdditionally, paragraphs containing fewer than 100 characters… See the full description on the dataset page: https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3.","first_N":5,"first_N_keywords":["English","German","Spanish","Persian","French"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-EnKoZhJa-18k","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/werty1248/OpenOrca-EnKoZhJa-18k","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","description":"This dataset is a collection of Korean, Chinese, and Japanese OpenOrca translation datasets.\nThe dataset was matched using id based on kyujinpy/OpenOrca-KO, which had the smallest number of rows.\nWhen more than one translation existed for a language, I chose the more similar one based on similarity of embedding(BAAI/BGE-m3).\n\n\t\n\t\t\n\t\tData Sources\n\t\n\n\nEnglish(Original)\nOpen-Orca/OpenOrca\n\n\nKorean(Translated with DeepL Pro API)\nkyujinpy/OpenOrca-KO\n\n\nChinese(Translated with Google Translate)… See the full description on the dataset page: https://huggingface.co/datasets/werty1248/OpenOrca-EnKoZhJa-18k.","first_N":5,"first_N_keywords":["English","Korean","Chinese","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"mmarco-hard-negatives-reranker-score","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score","creator_name":"Yuichi Tateno","creator_url":"https://huggingface.co/hotchpotch","description":"\nhotchpotch/mmarco-hard-negatives-reranker-score\n\nThis repository contains data from mMARCO scored using the reranker BAAI/bge-reranker-v2-m3.\n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\ntarget_languages = [\n    \"english\",\n    \"chinese\", \n    \"french\",\n    \"german\",\n    \"indonesian\",\n    \"italian\",\n    \"portuguese\",\n    \"russian\",\n    \"spanish\",\n    \"arabic\",\n    \"dutch\",\n    \"hindi\",\n    \"japanese\",\n    \"vietnamese\"\n]\n\n\n\t\n\t\t\n\t\tHard Negative Data\n\t\n\nThe hard negative data is derived from… See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score.","first_N":5,"first_N_keywords":["English","Chinese","French","German","Indonesian"],"keywords_longer_than_N":true},
	{"name":"qwq-ja-en","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/qwq-ja-en","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"hpprc/qwq-ja-en dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","English","Japanese","cc-by-sa-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Galgame_Speech_ASR_16kHz","keyword":"japanese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\n\t\n\t\t\n\t\tDataset Card for Galgame_Speech_ASR_16kHz\n\t\n\n\n[!IMPORTANT]The following rules (in the original repository) must be followed:\n必须遵守GNU General Public License v3.0内的所有协议！附加：禁止商用，本数据集以及使用本数据集训练出来的任何模型都不得用于任何商业行为，如要用于商业用途，请找数据列表内的所有厂商授权（笑），因违反开源协议而出现的任何问题都与本人无关！\n训练出来的模型必须开源，是否在README内引用本数据集由训练者自主决定，不做强制要求。\nEnglish:\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset… See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","Japanese","gpl-3.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Galgame_Speech_ASR_16kHz","keyword":"japanese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\n\t\n\t\t\n\t\tDataset Card for Galgame_Speech_ASR_16kHz\n\t\n\n\n[!IMPORTANT]The following rules (in the original repository) must be followed:\n必须遵守GNU General Public License v3.0内的所有协议！附加：禁止商用，本数据集以及使用本数据集训练出来的任何模型都不得用于任何商业行为，如要用于商业用途，请找数据列表内的所有厂商授权（笑），因违反开源协议而出现的任何问题都与本人无关！\n训练出来的模型必须开源，是否在README内引用本数据集由训练者自主决定，不做强制要求。\nEnglish:\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset… See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz.","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","Japanese","gpl-3.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/include-lite-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tINCLUDE-lite (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-lite-44.","first_N":5,"first_N_keywords":["text2text-generation","multiple-choice","Albanian","Arabic","Armenian"],"keywords_longer_than_N":true},
	{"name":"Tylbass","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Tylbass","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"Sakalti/Tylbass dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Japanese","Yakut","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original… See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"english_quotes_ja","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/speed/english_quotes_ja","creator_name":"speed","creator_url":"https://huggingface.co/speed","description":"This dataset is a translation of https://huggingface.co/datasets/Abirate/english_quotes into Japanese using the llm-jp/llm-jp-3-3.7b-instruct model. \nThe license follows the original dataset's Creative Commons Attribution 4.0 International License.\nThe translation was performed using text2dataset.\n","first_N":5,"first_N_keywords":["English","Japanese","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"global-festivals-translated","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/azminetoushikwasi/global-festivals-translated","creator_name":"Azmine Toushik Wasi","creator_url":"https://huggingface.co/azminetoushikwasi","description":"azminetoushikwasi/global-festivals-translated dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"llmjp-warp-html","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/llmjp-warp-html","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"llm-jp-corpus-v3のwarp_htmlのうちlevel2フィルタリングされたデータをHFフォーマットに変換し、各データに付与されたURLから元記事のタイトルを取得可能なものについては取得して付与したデータセットです。\nライセンスは元ページに従いCC-BY 4.0とします。\n","first_N":5,"first_N_keywords":["Japanese","cc-by-4.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic… See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"jawiki-yomi","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/jawiki-yomi","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"hpprc/jawiki-yomi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"multiturn-conv-from-aozora-bunko","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kanhatakeyama/multiturn-conv-from-aozora-bunko","creator_name":"kan hatakeyama","creator_url":"https://huggingface.co/kanhatakeyama","description":"\n\t\n\t\t\n\t\t自動生成の対話データ\n\t\n\n青空文庫からランダムに抜粋したテキストをもとに､Calm3-22B-chatで自動生成のマルチンターンデータを生成しました｡\n\n生成コード\n吾輩は猫である 限定ver\n\n\n軽いクリーニング\n\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"elementray_small","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/if001/elementray_small","creator_name":"issei fujimoto","creator_url":"https://huggingface.co/if001","description":"より多く作成したのがこっちhttps://huggingface.co/datasets/if001/elementray_m\ncalm3-22bを使って簡単な日本語の例文を作成したデータセットです。\n以下のパターンが含まれるように一文を作成しています。\n生成に失敗しているものはクリーニングしています。\n    \"です/だ (肯定文)\",\n    \"ではありません/じゃない (否定文)\",\n    \"〜ます (動詞の丁寧形)\",\n    \"〜ません (動詞の否定形)\",\n    \"〜たい (希望・願望)\",\n    \"〜ている (進行形)\",\n    \"〜てください (依頼)\",\n    \"〜てもいいですか (許可)\",\n    \"〜なければなりません/〜なきゃいけない (義務)\",\n    \"〜でしょう/〜だろう (推測)\",\n    \"〜が好きです/嫌いです (好み)\",\n    \"〜と思います (意見・思考)\",\n    \"〜から/〜ので (理由)\",\n    \"〜のが好きです/嫌いです (動作の好み)\",\n    \"〜でしょうか (丁寧な質問)\",\n    \"〜てしまう… See the full description on the dataset page: https://huggingface.co/datasets/if001/elementray_small.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"JMMMU","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JMMMU/JMMMU","creator_name":"JMMMU","creator_url":"https://huggingface.co/JMMMU","description":"\n\t\n\t\t\n\t\tJMMMU: A Japanese Massive Multi-discipline Multimodal Understanding Benchmark\n\t\n\n🌐 Homepage | 🤗 Dataset | 🏆 HF Leaderboard | 📖 arXiv | 💻 Code\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nWe introduce JMMMU (Japanese MMMU), a multimodal benchmark that can truly evaluate LMM performance in Japanese. To create JMMMU, we first carefully analyzed the existing MMMU benchmark and examined its cultural dependencies. Then, for questions in culture-agnostic subjects, we employed native Japanese speakers who… See the full description on the dataset page: https://huggingface.co/datasets/JMMMU/JMMMU.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"Magpie-Tanuki-8B-97k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Magpie-Tanuki-8B-97k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tMagpie-Tanuki-8B-97k\n\t\n\nMagpieの手法をweblab-GENIAC/Tanuki-8B-dpo-v1.0に対して適用し作成した、97269件の日本語対話データセットです。\n特に事後的なフィルタ処理は加えていないため、クオリティの低いレコードが含まれている可能性があります。ご注意ください。\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"hachiwari","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/hachiwari","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"#Origin\nThe name comes from \"hachiwari/はちわれ\" (chiikawa/ちいかわ).\n","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-sa-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"JHumanEval-Mod","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/myst72/JHumanEval-Mod","creator_name":"Miyu Sato","creator_url":"https://huggingface.co/myst72","description":"myst72/JHumanEval-Mod dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","English","Japanese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"MGSM_ja","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sbintuitions/MGSM_ja","creator_name":"SB Intuitions","creator_url":"https://huggingface.co/sbintuitions","description":"評価スコアの再現性確保と SB Intuitions 修正版の公開用クローン\n\nソース: juletxara/mgsm on Hugging Face\nSubset: ja のみを抽出\n\n\n\n\n\t\n\t\t\n\t\tMGSM\n\t\n\n\nMultilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems,\nproposed in the paper Language models are multilingual chain-of-thought reasoners.\n\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nCreative Commons Attribution Share Alike 4.0 International\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@article{cobbe2021gsm8k,\n    title={Training Verifiers to Solve Math Word Problems}… See the full description on the dataset page: https://huggingface.co/datasets/sbintuitions/MGSM_ja.","first_N":5,"first_N_keywords":["text2text-generation","Japanese","cc-by-sa-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"vqa","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldcuisines/vqa","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\n\t\n\t\t\n\t\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\n\t\n\n\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 October 2024.… See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa.","first_N":5,"first_N_keywords":["multilingual","English","Indonesian","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"Malum-230","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Manual-Dataset-Creation-Project/Malum-230","creator_name":"ManualDatasetCreation-Project","creator_url":"https://huggingface.co/Manual-Dataset-Creation-Project","description":"\n\t\n\t\t\n\t\tMalum-230\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nMalum-230 is a meticulously handcrafted Japanese dataset featuring multi-turn conversations and passages, specifically designed for logical reasoning tasks.\nThis dataset can be used for both pre-training and post-training.\n\n\t\n\t\t\n\t\tDetails\n\t\n\n\nCreation method: Human effort\n\nDataset type: Logical reasoning\n\nUse case: pre-training and post-training\n\n\n\n\t\n\t\t\n\t\tPerformance\n\t\n\nThis radar chart shows the evaluation results on Japanese MT-Bench for the… See the full description on the dataset page: https://huggingface.co/datasets/Manual-Dataset-Creation-Project/Malum-230.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"reranking-datasets-light","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","description":"\n\t\n\t\t\n\t\t🔥 Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation 🔥\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\n\t\n\n\n    \n    \n    \n    \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n    \n\n\n\nA curated collection of ready-to-use datasets for retrieval and reranking… See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light.","first_N":5,"first_N_keywords":["question-answering","English","Arabic","German","French"],"keywords_longer_than_N":true},
	{"name":"sakugabooru2025","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/trojblue/sakugabooru2025","creator_name":"trojblue","creator_url":"https://huggingface.co/trojblue","description":"\n\n\t\n\t\t\n\t\tSakugabooru2025: Curated Animation Clips from Enthusiasts\n\t\n\nSakugabooru.com is a booru-style imageboard dedicated to collecting and sharing noteworthy animation clips, emphasizing Japanese anime but open to creators worldwide. Over the years, it has amassed more than 240,000 animation clips, alongside informative blog posts for anime fans everywhere.\nWith the growing interest in generative video models and AI animations, the scarcity of proper animation-related video datasets has… See the full description on the dataset page: https://huggingface.co/datasets/trojblue/sakugabooru2025.","first_N":5,"first_N_keywords":["text-to-image","text-to-video","English","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"question-type-and-complexity","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rokokot/question-type-and-complexity","creator_name":"Robin Kokot","creator_url":"https://huggingface.co/rokokot","description":"\n\t\n\t\t\n\t\tQuestion Type and Complexity (QTC) Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThe Question Type and Complexity (QTC) dataset is a comprehensive resource for linguistics/NLP research focusing on question classification and linguistic complexity analysis across multiple languages. It contains questions from two distinct sources (TyDi QA and Universal Dependencies v2.15), automatically annotated with question types (polar/content) and a set of linguistic complexity features.\nKey Features:\n\n2… See the full description on the dataset page: https://huggingface.co/datasets/rokokot/question-type-and-complexity.","first_N":5,"first_N_keywords":["text-classification","question-answering","text-scoring","intent-classification","extractive-qa"],"keywords_longer_than_N":true},
	{"name":"datasets","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Athipan01/datasets","creator_name":"C.","creator_url":"https://huggingface.co/Athipan01","description":"\n\t\n\t\t\n\t\tGotdata\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nGotdata เป็นชุดข้อมูลที่รวบรวมโค้ดตัวอย่างพร้อม metadata ที่เกี่ยวข้อง เช่น ชื่อฟังก์ชันและเอกสารประกอบ เหมาะสำหรับการพัฒนาโมเดล NLP เพื่อ:\n\nแยกและสร้างโค้ดโปรแกรม\nจำแนกประเภทโค้ด (Code Classification)\nสร้างเอกสารโค้ดอัตโนมัติ (Code Summarization)\n\n\n\t\n\t\t\n\t\tMetadata\n\t\n\n\nLicense: MIT  \nLanguage: ไทย (th), อังกฤษ (en), ญี่ปุ่น (ja)  \nSize: 10K < n < 100K ตัวอย่าง  \nTags: code, biology\n\n\n\t\n\t\t\n\t\tExample Structure\n\t\n\nข้อมูลในชุดนี้มีโครงสร้างดังนี้:\n{… See the full description on the dataset page: https://huggingface.co/datasets/Athipan01/datasets.","first_N":5,"first_N_keywords":["text-generation","text-classification","translation","text2text-generation","Thai"],"keywords_longer_than_N":true},
	{"name":"JDocQA_SingleImage","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/umiyuki/JDocQA_SingleImage","creator_name":"umiyuki","creator_url":"https://huggingface.co/umiyuki","description":"\n\t\n\t\t\n\t\tJDocQA_SingleImage Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nJDocQA_SingleImageは、shunk031/JDocQAのtestサブセットを基に作成されたデータセットで、PDFファイルを200dpiの画像に変換し、画像が取得できない設問と複数画像が必要な設問を除外しています。元のデータセットが37GBと大きすぎるため、サイズを削減しつつ実用性を保つことを目的としています。\n\n元データ: shunk031/JDocQA (test split, 1,176 instances)\n変換後: PDFを画像に置き換え、画像が取得できてかつ単一画像入力の設問のみを含む\n言語: 日本語 (BCP-47 ja-JP)\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ninput_text: 質問テキスト\nquestion_id: ユニークなID\nanswer: 回答\nanswer_type: 回答タイプ（0: Yes/No, 1: Factoid, 2: Numerical, 3: Open-ended）… See the full description on the dataset page: https://huggingface.co/datasets/umiyuki/JDocQA_SingleImage.","first_N":5,"first_N_keywords":["shunk031/JDocQA","Japanese","cc-by-sa-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ethics","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/swdq/ethics","creator_name":"ootsuka","creator_url":"https://huggingface.co/swdq","description":"\n\t\n\t\t\n\t\t倫理に関するデータセット\n\t\n\n\n\t\n\t\t\n\t\t概要\n\t\n\nこのデータセットは日本語の倫理に関するデータセットです。anthracite-org/magnum-v4-12bを使用しすべて作成しました。\n\n\t\n\t\t\n\t\tデータ内容\n\t\n\n\nevilとjusticeをラベルとし質問と回答を作成しています。\nこれにより分類タスク、生成タスク両方にて使える汎用性かつシンプル性を持たせました。\n\n\n\t\n\t\t\n\t\tライセンス\n\t\n\nこのデータセットはApache-2.0ライセンスのもとで提供されます。\n\n\t\n\t\t\n\t\tデータサイズ\n\t\n\n本データセットの規模は10K〜100Kの範囲に収まります。\n\n\t\n\t\t\n\t\t貢献\n\t\n\nデータの改善や拡張に関する提案は歓迎します。\n","first_N":5,"first_N_keywords":["text2text-generation","text-generation","Japanese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"TagInstruct-JP","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SousiOmine/TagInstruct-JP","creator_name":"SousiOmine","creator_url":"https://huggingface.co/SousiOmine","description":"出力になにかしらの制約があるシステムプロンプトに対する追従性を向上させるためのデータセットの試作です。Deepseek-V3-0324によって生成されました。生成に使ったプロンプト等はリポジトリ内のgenerate_dataset.pyを参照してください。  \n本データセットおよびソースコードはMITライセンスで提供されます。  \n","first_N":5,"first_N_keywords":["Japanese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Ani-Bench-JP","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/umiyuki/Ani-Bench-JP","creator_name":"umiyuki","creator_url":"https://huggingface.co/umiyuki","description":"\n\t\n\t\t\n\t\tAni-Bench-JP\n\t\n\n\n\t\n\t\t\n\t\tデータセット概要\n\t\n\nAni-Bench-JP は、日本の人気アニメに関する知識を測定するためのベンチマーク用データセットです。このデータセットは、5つのアニメ作品（『魔法少女まどか☆マギカ』、『ぼっち・ざ・ろっく！』、『機動戦士ガンダム』、『HUNTER×HUNTER』、『新世紀エヴァンゲリオン』）からそれぞれ20問ずつ、合計100問のクイズ形式の問題で構成されています。\nLLMのアニメに関する理解度を日本語で評価する用途を想定してます。\n\n\t\n\t\t\n\t\tデータ構造\n\t\n\nデータはCSV形式で提供されており、test スプリットとしてアップロードされています。ファイルには以下の3つの列が含まれます：\n\n問題: アニメに関するクイズ形式の質問\n答え: その質問に対する正解\n番組名: 質問が関連するアニメ作品の名前\n\n\n\t\n\t\t\n\t\t列の詳細\n\t\n\n\n\t\n\t\t\n列名\n説明\n例\n\n\n\t\t\n問題\nクイズの質問文\n主人公の名前は何ですか？\n\n\n答え\n質問に対する正解\n鹿目まどか\n\n\n番組名\n関連するアニメのタイトル… See the full description on the dataset page: https://huggingface.co/datasets/umiyuki/Ani-Bench-JP.","first_N":5,"first_N_keywords":["Japanese","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"ja-code-reasoning","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jaeyong2/ja-code-reasoning","creator_name":"jeongjaeyong","creator_url":"https://huggingface.co/jaeyong2","description":"\n\t\n\t\t\n\t\tDevelopment Process\n\t\n\n\nquestion dataset from HachiML/amenokaku-code-instruct-python-mit\nWe used gemini-2.0-thinking\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\n\nHachiML/amenokaku-code-instruct-python-mit : https://choosealicense.com/licenses/mit/\n\n","first_N":5,"first_N_keywords":["Japanese","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"VNJPTranslate","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haiFrHust/VNJPTranslate","creator_name":"Hai Phan","creator_url":"https://huggingface.co/haiFrHust","description":"\n\t\n\t\t\n\t\tVietnamese-Japanese Parallel Corpus\n\t\n\n🌟 If you find this project valuable, please consider starring our VNJPTranslate GitHub repo! Your support helps us reach more people and continue improving the project. 🔗 Check it out here! 🌟\nThe Vietnamese-Japanese Parallel Corpus is a bilingual dataset specifically designed for translation tasks between Vietnamese and Japanese. It consists of 3.3M rows of parallel text. This makes it a robust resource for developing and evaluating machine… See the full description on the dataset page: https://huggingface.co/datasets/haiFrHust/VNJPTranslate.","first_N":5,"first_N_keywords":["translation","Vietnamese","Japanese","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"world-languages-dataset","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SivaMallikarjun/world-languages-dataset","creator_name":"Parvatham Siva Mallikarjun","creator_url":"https://huggingface.co/SivaMallikarjun","description":"\n\t\n\t\t\n\t\t🌍 World Languages Dataset\n\t\n\nThis dataset contains a list of official and unofficial languages categorized by language families...\n","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"Zero_SFT_Ja_by_Mistral_Small","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DataPilot/Zero_SFT_Ja_by_Mistral_Small","creator_name":"DataPilot","creator_url":"https://huggingface.co/DataPilot","description":"\n\t\n\t\t\n\t\tDataPilot/Zero_SFT_Ja_by_Mistral_Small\n\t\n\nこのデータセットは、日本語で記述された高品質な合成プロンプトとそのAI出力を収録しています。すべてのデータは Mistral Small 3.1 24B Instruct 2503 モデルを使用してゼロから合成されています。\n\n\t\n\t\t\n\t\t概要\n\t\n\n\n\t\n\t\t\n項目\n詳細\n\n\n\t\t\nデータセット名\nDataPilot/Zero_SFT_Ja_by_Mistral_Small\n\n\n言語\n日本語\n\n\nデータ作成方法\n完全自動生成（モデルによるゼロショット合成）\n\n\n使用モデル\nMistral Small 3.1 24B Instruct 2503\n\n\nフォーマット\nJSONL（id, input, output, conversation）\n\n\nライセンス\nApache-2.0\n\n\n作成コード\nfoxn2000/zero_one_instruction\n\n\n\t\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tデータセット構造\n\t\n\nデータセットには以下のカラムが含まれています。\n\n\t\n\t\t\nカラム名… See the full description on the dataset page: https://huggingface.co/datasets/DataPilot/Zero_SFT_Ja_by_Mistral_Small.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"AnimeQuotes","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mohamed-khalil/AnimeQuotes","creator_name":"Mohammed Khalil","creator_url":"https://huggingface.co/mohamed-khalil","description":"\n\t\n\t\t\n\t\tAnime Quotes Dataset ― アニメの名言データセット🎐\n\t\n\n\nWelcome to Anime Quotes Dataset\n\n\n    \n        \n        \n        \n    \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThis dataset contains a curated collection of inspiring and memorable quotes from various anime series, sourced from the Anime Motivation website. The quotes are stored as a list of dictionaries and can be easily accessed for analysis, research, or personal enjoyment.\n\n\t\n\t\n\t\n\t\tData Format\n\t\n\nEach entry in the dataset is represented by a dictionary… See the full description on the dataset page: https://huggingface.co/datasets/mohamed-khalil/AnimeQuotes.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","text-classification","Japanese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"oaast_rm_full_jieba","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"尝试解决\"llm repetition problem\"，使用分词模型对oaast语料进行“结巴化”数据增强，提供更强的重复内容拒绝效果。\nAttempts to solve the \"llm repetition problem\" by using a segmentation model to enhance the oaast corpus with \"stuttering\" data to provide stronger rejection of duplicate content.\n其次，还过滤掉了所有自我认知的微调样本。\nSecond, it also filters out all the fine-tuned samples of self-cognition.\nfiles:\n\noaast_rm_full_jieba.jsonl : word level repeat\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\n\n","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"danbooru2023_index","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deepghs/danbooru2023_index","creator_name":"DeepGHS","creator_url":"https://huggingface.co/deepghs","description":"Tar index files for nyanko7/danbooru2023.\nYou can download images from both nyanko7/danbooru2023 and deepghs/danbooru_newest with cheesechaser.\nfrom cheesechaser.datapool import DanbooruNewestDataPool\n\npool = DanbooruNewestDataPool()\n\n# download danbooru original images from 7200000-7201000, to directory /data/danbooru_original\npool.batch_download_to_directory(\n    resource_ids=range(7200000, 7201000),\n    dst_dir='/data/danbooru_original',\n    max_workers=12,\n)\n\n","first_N":5,"first_N_keywords":["image-classification","image-to-image","text-to-image","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"wataoshi-dialogues-rp","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aipracticecafe/wataoshi-dialogues-rp","creator_name":"aipracticecafe","creator_url":"https://huggingface.co/aipracticecafe","description":"このデータセットは「私の推しは悪役令嬢。」のアニメから少しクリーニングされたセリフです。私はこのアニメの権利を持ってません、データセットの使い方について、責任がない。\nUserは大体レイが言ったセリフが、他のキャラも含めてる。Assistantはクレアの答え。\n","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"jaqket_cc","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hotchpotch/jaqket_cc","creator_name":"Yuichi Tateno","creator_url":"https://huggingface.co/hotchpotch","description":"\n\t\n\t\t\n\t\tJAQKET から CC-BY-SA のデータのみを含めたデータセット\n\t\n\nAI王 公式配布データセット(JAQKET) で配布されているクイズデータのうち、ライセンスが　CC-BY-SA-4.0のデータのみを含めたデータセットです。\n\n\t\n\t\t\n\t\t謝辞\n\t\n\nAI王の開催・クイズ作成等々をされた関係者の方々に、有益なデータセットの公開ありがとうございます。\n\n\t\n\t\t\n\t\t利用方法\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"hotchpotch/jaqket_cc\")\nds[\"aio_01_dev\"][0]\n\n#=> {'qid': 'QA20CAPR-0002',\n 'question': '明治時代に西洋から伝わった「テーブル・ターニング」に起源を持つ占いの一種で、50音表などを記入した紙を置き、参加者全員の人差し指をコインに置いて行うのは何でしょう?',\n 'answers': ['コックリさん'],\n 'competition': '第1回AI王',\n 'timestamp':… See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/jaqket_cc.","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-sa-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MMCode","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/likaixin/MMCode","creator_name":"Kaixin Li","creator_url":"https://huggingface.co/likaixin","description":"\n    \n    MMCode\n\n\nMMCode Github Repo \n\nNote: Please find the files directly via the \"Files and versions\" panel. Preview is not available. \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nMMCode is a multi-modal code generation dataset designed to evaluate the problem-solving skills of code language models in visually rich contexts (i.e. images). \nIt contains 3,548 questions paired with 6,620 images, derived from real-world programming challenges across 10 code competition websites, with Python solutions… See the full description on the dataset page: https://huggingface.co/datasets/likaixin/MMCode.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"eagle","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MasahiroKaneko/eagle","creator_name":"Masahiro Kaneko","creator_url":"https://huggingface.co/MasahiroKaneko","description":"\n\t\n\t\t\n\t\tEagle 🦅: Ethical Dataset Given from Real Interactions\n\t\n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis repository contains the Eagle dataset, which is an ethical dataset of real interactions between humans and ChatGPT. This dataset is created to evaluate social bias, opinion bias, toxic language, and morality in Large Language Models (LLMs).\nIf you use the Eagle dataset in your research, please cite the following:\n@inproceedings{Eagle:arxiv:2024,\n    title={Eagle: Ethical Dataset Given from Real… See the full description on the dataset page: https://huggingface.co/datasets/MasahiroKaneko/eagle.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","French","Korean"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\nand converted into different parts (see process.py):\n\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\n\nRaw data files are in raw.tar.gz, which contains:\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\n[...] 9.8M Feb 24… See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"cosmopedia-100k-ja-preview","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kunishou/cosmopedia-100k-ja-preview","creator_name":"kunishou","creator_url":"https://huggingface.co/kunishou","description":"cosmopedia-100k のindex 20k ～ 100k を日本語に自動翻訳したデータになります（テキストが長すぎて翻訳エラーになったレコードは除外しています）。このデータセット自体は別作業者が取り組んでいる 0 ～ 20k の翻訳結果とマージ後に削除します。データセット自体は残しておきます。\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"jimba-instuction-1k-beta","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kendamarron/jimba-instuction-1k-beta","creator_name":"Kendamarron","creator_url":"https://huggingface.co/Kendamarron","description":"cyberagent/calm2-7b-chatの出力を人手でチェック・修正することで作成した日本語Instructionデータセットです。\n詳しくはこちらの記事を御覧ください。\nhttps://zenn.dev/kendama/articles/dc727218a2eae6\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"JA-VG-VQA-500","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SakanaAI/JA-VG-VQA-500","creator_name":"Sakana AI","creator_url":"https://huggingface.co/SakanaAI","description":"\n\t\n\t\t\n\t\tJA-VG-VQA-500\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nJA-VG-VQA-500 is a 500-sample subset of Japanese Visual Genome VQA dataset.\nThis dataset was used in the evaluation of EvoVLM-JP-v1-7B. \nPlease refer to our report and blog for more details. \nWe are grateful to the developers for making the dataset available under Creative Commons Attribution 4.0 License. \n\nVisual Genome\nJapanese Visual Genome VQA dataset\n\t\n\t\t\n\t\tUsage\n\t\n\nUse the code below to get started with the dataset.\nfrom datasets… See the full description on the dataset page: https://huggingface.co/datasets/SakanaAI/JA-VG-VQA-500.","first_N":5,"first_N_keywords":["visual-question-answering","Japanese","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul Röttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverse… See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"HelpSteer-35k-ja","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kunishou/HelpSteer-35k-ja","creator_name":"kunishou","creator_url":"https://huggingface.co/kunishou","description":"NVIDIA が公開している SteerLM 向けのトライアルデータセット HelpSteerを日本語に自動翻訳したデータセットになります。SteerLM でのアライメントをお試ししたい際にご活用下さい。\nSteerLM での LLM トレーニング方法については以下の URL を参考にして下さい。  \n\nAnnouncing NVIDIA SteerLM : https://developer.nvidia.com/blog/announcing-steerlm-a-simple-and-practical-technique-to-customize-llms-during-inference\nNeMo Aligner : https://github.com/NVIDIA/NeMo-Aligner  \nSteerLM training user guide : https://docs.nvidia.com/nemo-framework/user-guide/latest/modelalignment/steerlm.html\n\n[参考] SteerLM :… See the full description on the dataset page: https://huggingface.co/datasets/kunishou/HelpSteer-35k-ja.","first_N":5,"first_N_keywords":["Japanese","cc-by-4.0","10K - 100K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"cosmopedia-japanese-100k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aixsatoshi/cosmopedia-japanese-100k","creator_name":"aixsatoshi","creator_url":"https://huggingface.co/aixsatoshi","description":"cosmopedia-japanese-20kのデータに、kunishou様から20k-100kをご提供いただけることになり100kまで拡大しました。　　\nhttps://huggingface.co/datasets/kunishou/cosmopedia-100k-ja-preview　　\nテキスト生成プロンプトの翻訳も含むデータは、上記レポジトリを確認してください。\n","first_N":5,"first_N_keywords":["Japanese","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"SmallParallelDocs-Ja_En-6k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NilanE/SmallParallelDocs-Ja_En-6k","creator_name":"Nilan Ekanayake","creator_url":"https://huggingface.co/NilanE","description":"This dataset contains document-length Japanese-English parallel texts from various sources.\nThe intended use case is for translation tasks.\nThe cumulative dataset is under an apache 2.0 license, but the sources differ on that account. If there are conflicts, assume the more restrictive clause takes priority (?)\nI am unfamiliar with licenses in general, so if someone sees any issues with the licensing situation, please let me know.\n\n\t\n\t\t\n\t\tMetadata meaning:\n\t\n\nsource: self-explanatory… See the full description on the dataset page: https://huggingface.co/datasets/NilanE/SmallParallelDocs-Ja_En-6k.","first_N":5,"first_N_keywords":["translation","Japanese","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MMedBench","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisc-team-c1/MMedBench","creator_name":"AISC Team C1","creator_url":"https://huggingface.co/aisc-team-c1","description":"This is a dataset repository made for the AISC class at Harvard Medical School. Please find the original dataset repository here: https://huggingface.co/datasets/Henrychur/MMedBench \n\n\t\n\t\t\n\t\tMMedBench\n\t\n\n💻Github Repo   🖨️arXiv Paper\nThe official benchmark for \"Towards Building Multilingual Language Model for Medicine\".\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis repo contains MMedBench, a comprehensive multilingual medical benchmark comprising 45,048 QA pairs for training and 8,518 QA pairs for testing.… See the full description on the dataset page: https://huggingface.co/datasets/aisc-team-c1/MMedBench.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","Japanese","French"],"keywords_longer_than_N":true},
	{"name":"MMedBench","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisc-team-c2/MMedBench","creator_name":"AISC Team C2","creator_url":"https://huggingface.co/aisc-team-c2","description":"This is a dataset repository made for the AISC class at Harvard Medical School. Please find the original dataset repository here: https://huggingface.co/datasets/Henrychur/MMedBench \n\n\t\n\t\t\n\t\tMMedBench\n\t\n\n💻Github Repo   🖨️arXiv Paper\nThe official benchmark for \"Towards Building Multilingual Language Model for Medicine\".\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis repo contains MMedBench, a comprehensive multilingual medical benchmark comprising 45,048 QA pairs for training and 8,518 QA pairs for testing.… See the full description on the dataset page: https://huggingface.co/datasets/aisc-team-c2/MMedBench.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","Japanese","French"],"keywords_longer_than_N":true},
	{"name":"AnimeSongsLyrics","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mohamed-khalil/AnimeSongsLyrics","creator_name":"Mohammed Khalil","creator_url":"https://huggingface.co/mohamed-khalil","description":"\n    \n\n\n\n\t\n\t\t\n\t\tAnime Songs Lyrics Dataset ― アニメソングの歌詞データセット\n\t\n\n\nWelcome to the Anime Songs Lyrics Dataset\n\n\n    \n        \n        \n        \n    \n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThis dataset compiles a diverse collection of lyrics from various anime songs, providing a rich resource for enthusiasts and researchers alike. \nThe lyrics information are structured in a Parquet file format named AnimeSongsLyrics.parquet, allowing efficient storage and retrieval of the dataset.\nYou find code of this… See the full description on the dataset page: https://huggingface.co/datasets/mohamed-khalil/AnimeSongsLyrics.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","text-classification","Japanese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"llava-bench-in-the-wild-ja","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/toshi456/llava-bench-in-the-wild-ja","creator_name":"toshi456","creator_url":"https://huggingface.co/toshi456","description":"This dataset is the data that corrected the translation errors and untranslated data of the Japanese data in MBZUAI/multilingual-llava-bench-in-the-wild.\nOriginal dataset is liuhaotian/llava-bench-in-the-wild.\n","first_N":5,"first_N_keywords":["image-to-text","Japanese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Multi-lingual_Detection","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Manirathinam21/Multi-lingual_Detection","creator_name":"Manirathinam","creator_url":"https://huggingface.co/Manirathinam21","description":"Manirathinam21/Multi-lingual_Detection dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Arabic","Tamil","Japanese","English"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances of… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"zenn-articles-20240115","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/p1atdev/zenn-articles-20240115","creator_name":"Plat","creator_url":"https://huggingface.co/p1atdev","description":"Dataset of URLs of articles on Zenn (zenn.dev)\n","first_N":5,"first_N_keywords":["Japanese","cc0-1.0","10K - 100K","text","Text"],"keywords_longer_than_N":true},
	{"name":"wikipedia-human-retrieval-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/baobab-trees/wikipedia-human-retrieval-ja","creator_name":"Baobab, Inc.","creator_url":"https://huggingface.co/baobab-trees","description":"\n\t\n\t\t\n\t\tJapanese Wikipedia Human Retrieval dataset\n\t\n\nThis is a Japanese question answereing dataset with retrieval on Wikipedia articles\nby trained human workers.\n\n\t\n\t\t\n\t\tContributors\n\t\n\n\nYusuke Oda\ndefined the dataset specification, data structure, and the scheme of data collection.\nBaobab, Inc.\noperated data collection, data checking, and formatting.\n\n\n\t\n\t\t\n\t\tAbout the dataset\n\t\n\nEach entry represents a single QA session:\ngiven a question sentence, the responsible worker tried to search for… See the full description on the dataset page: https://huggingface.co/datasets/baobab-trees/wikipedia-human-retrieval-ja.","first_N":5,"first_N_keywords":["question-answering","Japanese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"language-dataset","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","description":"\n","first_N":5,"first_N_keywords":["text-classification","English","Chinese","French","Russian"],"keywords_longer_than_N":true},
	{"name":"oscor-2301-ja-text-content","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayousanz/oscor-2301-ja-text-content","creator_name":"yousan","creator_url":"https://huggingface.co/ayousanz","description":"OSCOR-2301-jaのcontent部分だけをテキスト化したもの\nデータセットからcontentのvalueだけ取得する際には、以下のコードで実行しました\nimport json\nimport os\nimport sys\n\n# コマンドライン引数からフォルダ名を取得する\nif len(sys.argv) < 2:\n    print(\"使用法: python script.py folder_name\")\n    sys.exit(1)\n\nfolder_name = sys.argv[1]\n\n# フォルダ内のすべての .json ファイルを処理する\nfor filename in os.listdir(folder_name):\n    if filename.endswith(\".txt\"):\n        input_file = os.path.join(folder_name, filename)\n        output_file = os.path.splitext(filename)[0] + \"_convert.txt\"… See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/oscor-2301-ja-text-content.","first_N":5,"first_N_keywords":["Japanese","cc0-1.0","10M - 100M","text","Text"],"keywords_longer_than_N":true},
	{"name":"ApolloCorpus-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kunishou/ApolloCorpus-ja","creator_name":"kunishou","creator_url":"https://huggingface.co/kunishou","description":"\n\n\t\n\t\t\n\t\tApolloCorpus-ja\n\t\n\n\n\t\n\t\t\n\t\t概要\n\t\n\n多言語医療データセットの ApolloCorpus を日本語に自動翻訳した 525k の指示チューニングデータセットになります。ApolloCorpus は、オープンソースでかつ品質を担保できるデータのみをスクリーニングし収集されたデータセットになります。詳細は 論文 をご覧下さい。  \n\n\t\n\t\t\n\t\t翻訳対象ファイル\n\t\n\nデータ量が多いのでひとまず以下の 1 ファイルのみを翻訳しました。なお、英語以外のデータセットについては翻訳品質が低くくなるため、英語データセットのみを日本語に自動翻訳しました（今後、他のファイルを追加で翻訳する場合も英語データのファイルのみを対象にすると思います）。  \n\nmedicalPaper_en_qa.json (525k)\n\n\n\t\n\t\t\n\t\t使用上の注意\n\t\n\n多言語データセットを自動翻訳で日本語に翻訳したものであり、翻訳誤りも一部含まれています。医療領域での LLM に利用する際は十分注意した上で使用して下さい。  \n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"tokenizer-wiki-bench","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","description":"\n\t\n\t\t\n\t\tMultilingual Tokenizer Benchmark\n\t\n\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \nfrom transformers import AutoTokenizer… See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench.","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"piece-of-refined-oscar","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sudy-super/piece-of-refined-oscar","creator_name":"Sudy","creator_url":"https://huggingface.co/sudy-super","description":"\n\t\n\t\t\n\t\tDescrption\n\t\n\nThis dataset is part of the OSCAR-2301 cleaned.\nThere are about 0.5b tokens counted by calm2 tokenizer.\n\n\t\n\t\t\n\t\tNOTE\n\t\n\nThis dataset has not passed sentence end boundary determination or Perplexity Filtering, so there is room for improvement in quality.\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"CLoT-Oogiri-GO","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zhongshsh/CLoT-Oogiri-GO","creator_name":"Shanshan Zhong","creator_url":"https://huggingface.co/zhongshsh","description":"\n   \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOogiri-GO Dataset Card\n\t\n\nProject Page | Paper | Code | Model\nData discription: Oogiri-GO is a multimodal and multilingual humor dataset, and contains more than 130,000 Oogiri samples in English (en.jsonl), Chinese (cn.jsonl), and Japanese (jp.jsonl).  Notably,  in Oogiri-GO, 77.95% of samples are annotated with human preferences, namely the number of likes, indicating the popularity of a response. As illustrated in Fig. 1,  Oogiri-GO contains three types of Oogiri games… See the full description on the dataset page: https://huggingface.co/datasets/zhongshsh/CLoT-Oogiri-GO.","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","English","Chinese","Japanese"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\nExample of loading:\ndataset = load_dataset(\"davidstap/NTREX\", \"rus_Cyrl\", trust_remote_code=True)\n\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe following languages are available:\n\n\t\n\t\t\nLanguage Code\nLanguage Name\n\n\n\t\t\nafr_Latn\nAfrikaans\n\n\namh_Ethi\nAmharic\n\n\narb_Arab\nArabic\n\n\naze_Latn\nAzerbaijani\nbak_Cyrl\nBashkir\n\n\nbel_Cyrl\nBelarusian… See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"mittens","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/mittens","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tMiTTenS: A Dataset for Evaluating Misgendering in Translation\n\t\n\nMisgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scripts… See the full description on the dataset page: https://huggingface.co/datasets/google/mittens.","first_N":5,"first_N_keywords":["translation","Arabic","Finnish","Oromo","Ganda"],"keywords_longer_than_N":true},
	{"name":"izumi-lab-dpo-45k","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryota39/izumi-lab-dpo-45k","creator_name":"kaeru39","creator_url":"https://huggingface.co/ryota39","description":"ryota39/izumi-lab-dpo-45k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"OSCOR-2301-ja-cleaned-0","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayousanz/OSCOR-2301-ja-cleaned-0","creator_name":"yousan","creator_url":"https://huggingface.co/ayousanz","description":"\n\t\n\t\t\n\t\t概要\n\t\n\noscar-corpus/OSCAR-2301の以下のjaのみを corpus-cleanerを使用してデータクリーニングを行なったデーセット群\n\n\t\n\t\t\nCode\nLanguage\n# docs\n# words\nContent Length :\n\n\n\t\t\nja\nJapanese\n94,236,404\n4,401,059,165\n181.2 GB\n\n\n\t\n\n","first_N":5,"first_N_keywords":["Japanese","cc0-1.0","🇺🇸 Region: US","OSCAR-2301"],"keywords_longer_than_N":false},
	{"name":"synthetic-introduction-extraction","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/angelmmiguel/synthetic-introduction-extraction","creator_name":"Angel M De Miguel","creator_url":"https://huggingface.co/angelmmiguel","description":"angelmmiguel/synthetic-introduction-extraction dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["feature-extraction","Spanish","English","French","Russian"],"keywords_longer_than_N":true},
	{"name":"tanaka-corpus","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/tanaka-corpus","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"HF Datasets version of Tanaka Corpus.\n\n\t\n\t\t\n\t\tPreprocess for HF Datasets\n\t\n\n以下の内容でオリジナルデータを前処理しました。\nwget ftp://ftp.edrdg.org/pub/Nihongo/examples.utf.gz\ngunzip examples.utf.gz\n\nimport re\nfrom pathlib import Path\n\nfrom more_itertools import chunked\n\nimport datasets as ds\n\ndata = []\nwith Path(\"examples.utf\").open() as f:\n    for row, _ in chunked(f, 2):\n        ja, en, idx = re.findall(r\"A: (.*?)\\t(.*?)#ID=(.*$)\", row)[0]\n        data.append(\n            {\n                \"id\": idx… See the full description on the dataset page: https://huggingface.co/datasets/hpprc/tanaka-corpus.","first_N":5,"first_N_keywords":["translation","Japanese","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"alt-parallel-en-ja","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/alt-parallel-en-ja","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"\n\t\n\t\t\n\t\tAsian Language Treebank (ALT) Project\n\t\n\nALT Parallel Corpusのうち、日英対訳部分のみを抽出したデータセットです。\n処理元のデータとしては、HuggingFace上のhttps://huggingface.co/datasets/altを利用しています。\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@inproceedings{riza2016introduction,\n  title={Introduction of the asian language treebank},\n  author={Riza, Hammam and Purwoadi, Michael and Uliniansyah, Teduh and Ti, Aw Ai and Aljunied, Sharifah Mahani and Mai, Luong Chi and Thang, Vu Tat and Thai, Nguyen Phuong and Chea, Vichet and Sam, Sethserey and others}… See the full description on the dataset page: https://huggingface.co/datasets/hpprc/alt-parallel-en-ja.","first_N":5,"first_N_keywords":["translation","English","Japanese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })… See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })… See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"miracl-japanese-small-corpus","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mpkato/miracl-japanese-small-corpus","creator_name":"Makoto Kato","creator_url":"https://huggingface.co/mpkato","description":"mpkato/miracl-japanese-small-corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-retrieval","Japanese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"swim-ir-cross-lingual","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\n\t\n\t\t\n\t\tDataset Card for SWIM-IR (Cross-lingual)\n\t\n\n\n\n\nThis is the cross-lingual subset of the SWIM-IR dataset, where the query generated is in the target language and the passage is in English.\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\n\n\t\n\t\n\t\n\t\tWhat is SWIM-IR?\n\t\n\nSWIM-IR dataset is a synthetic multilingual… See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","machine-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"token-classification-japanese-search-local-cuisine","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wolf4032/token-classification-japanese-search-local-cuisine","creator_name":"wolf4032","creator_url":"https://huggingface.co/wolf4032","description":"料理を検索するための質問文と、質問文に含まれる検索検索用キーワードの情報を持ったデータセットです\n固有表現の種類は以下の４つです。\n\nAREA：　都道府県/地方\nTYPE：　種類\nSZN：　季節\nINGR：　食材\n\nGitHub\n\nuntokenized_dataset_list.ipynb(データセットの作成に使ったノートブック)\nこのデータセットを使った言語モデルのファインチューニングと、ファインチューニングした言語モデルを使ったアプリのコードもこのリポジトリにあります\n\n詳細情報\n\nQiita\n\n","first_N":5,"first_N_keywords":["token-classification","Japanese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"oasst2-33k-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-jp/oasst2-33k-ja","creator_name":"LLM-jp","creator_url":"https://huggingface.co/llm-jp","description":"\n\t\n\t\t\n\t\toasst2-33k-ja\n\t\n\nThis repository provides an instruction tuning dataset developed by LLM-jp, a collaborative project launched in Japan.\nThe dataset comprises a Japanese translation of an English subset from oasst2, translated using DeepL.\nThe English subset can be found here.\nFor the creation of this dataset, we processed data from kunishou/oasst2-135k-ja.\n\n\t\n\t\t\n\t\n\t\n\t\tSend Questions to\n\t\n\nllm-jp(at)nii.ac.jp\n\n\t\n\t\t\n\t\n\t\n\t\tModel Card Authors\n\t\n\nThe names are listed in alphabetical order.… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/oasst2-33k-ja.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"webui-dom-snapshots","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\n\t\n\t\t\n\t\tDataset Card for WebUI DOM snapshots\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Gary Benson\nLanguages: Mostly English (87%);\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\nLicense: CC0 1.0 Universal\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]… See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots.","first_N":5,"first_N_keywords":["image-feature-extraction","reinforcement-learning","text-classification","multilingual","biglab/webui-7k"],"keywords_longer_than_N":true},
	{"name":"sharegpt_dialogue_base","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base","creator_name":"Hieu Lam","creator_url":"https://huggingface.co/lamhieu","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThe dataset is from unknown, formatted as dialogues for speed and ease of use. Many thanks to author for releasing it.\nImportantly, this format is easy to use via the default chat template of transformers, meaning you can use huggingface/alignment-handbook immediately, unsloth.\n\n\t\n\t\t\n\t\n\t\n\t\tStructure\n\t\n\nView online through viewer.\n\n\t\n\t\t\n\t\n\t\n\t\tNote\n\t\n\nWe advise you to reconsider before use, thank you. If you find it useful, please like and follow this account.… See the full description on the dataset page: https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","Vietnamese","Chinese"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Loïck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds to… See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arbëreshë Albanian"],"keywords_longer_than_N":true},
	{"name":"JetCopper-10B","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sudy-super/JetCopper-10B","creator_name":"Sudy","creator_url":"https://huggingface.co/sudy-super","description":"\n\t\n\t\t\n\t\tJetCopper-10B\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nJetCopper-10B was created by extracting a portion of the data after cleaning, filtering, and deduplicating the following datasets.\n\nThe japanese subset of C4\nThe japanese subset of CC-100\nThe japanese subset of OSCAR-2301\nThe japanese subset of HPLT Datasets v1.2\nwiki40b-ja\n\nThis dataset was used to pre-train Contrail-200m-64k when we participated in LOCAL AI HACKATHON #000.\n\n\t\n\t\t\n\t\tThe number of tokens (Using tokenizer of calm2-chat)… See the full description on the dataset page: https://huggingface.co/datasets/sudy-super/JetCopper-10B.","first_N":5,"first_N_keywords":["Japanese","English","code","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"sake_qa","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuiseki/sake_qa","creator_name":"Yui Matsumura","creator_url":"https://huggingface.co/yuiseki","description":"yuiseki/sake_qa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Japanese","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"nu-snli","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cl-nagoya/nu-snli","creator_name":"CL Research Group in Nagoya, Japan","creator_url":"https://huggingface.co/cl-nagoya","description":"\n\t\n\t\t\n\t\tTranslation Code\n\t\n\nWe used vLLM for a faster, batched generation.\nimport datasets as ds\nfrom vllm import LLM, SamplingParams, RequestOutput\nfrom transformers import AutoTokenizer\n\n\nmodel_path = \"hoge/fuga\"\n\ndataset: ds.Dataset = ds.load_dataset(\"snli\", split=\"train\")\n\nllm = LLM(\n    model=model_path,\n    quantization=None,\n    dtype=\"bfloat16\",\n    tensor_parallel_size=4,\n    enforce_eager=True,\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\n# temperature must be 0 when… See the full description on the dataset page: https://huggingface.co/datasets/cl-nagoya/nu-snli.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","bilingual","snli"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separate… See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"Chat-with-cosmopedia","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aixsatoshi/Chat-with-cosmopedia","creator_name":"aixsatoshi","creator_url":"https://huggingface.co/aixsatoshi","description":"Reasoning、知識、会話の掛け合いなどの情報密度が高いマルチターンの会話データです。\n利用データセット日本語化cosmopedia日本語化cosmopedia  \nから作成した合成データセットです。\nExample1  \n\n\nユーザー: 数学をもっと身近に感じるためには、どのような取り組みが必要でしょうか？\nアシスタント: 数学を身近に感じるためには、適切な年齢層に合わせた教材やビデオ記録を利用することが効果的です。たとえば、MoMathなどの組織は、年齢に応じたコンテンツと戦略的なビデオ記録を利用することで、数学への参加を阻む障壁を取り除いています。これにより、STEM分野への幅広い参加が可能になり、かつてはエリート主義的なトピックを生み出すことで、将来の発見と革新の肥沃な土壌を作り出すことができます。\nユーザー: ビデオ記録がなぜ数学教育において重要なのでしょうか？\nアシスタント:… See the full description on the dataset page: https://huggingface.co/datasets/aixsatoshi/Chat-with-cosmopedia.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"japan_diet_q_and_a_sessions_20k","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/notoxicpeople/japan_diet_q_and_a_sessions_20k","creator_name":"takashi miwa","creator_url":"https://huggingface.co/notoxicpeople","description":"\n\t\n\t\t\n\t\tJapan Diet Q&A Sessions Dataset\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\n\nThis dataset was created by scraping the parliamentary questions and answers webpage. \nAs of March 27, 2024, it includes 216 sessions.\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nid: Consists of three parts. \nThe initial alphabet indicates whether it is a question (a) or an answer (b).\nThe next three digits represent the session number of the parliament.\nThe last three digits are the question number within the parliament session.\n\n\ntitle: The title… See the full description on the dataset page: https://huggingface.co/datasets/notoxicpeople/japan_diet_q_and_a_sessions_20k.","first_N":5,"first_N_keywords":["monolingual","Japanese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ParallelFiction-Ja_En-100k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NilanE/ParallelFiction-Ja_En-100k","creator_name":"Nilan Ekanayake","creator_url":"https://huggingface.co/NilanE","description":"\n\t\n\t\t\n\t\tDataset details:\n\t\n\nEach entry in this dataset is a sentence-aligned Japanese web novel chapter and English fan translation.\nThe intended use-case is for document translation tasks.\n\n\t\n\t\t\n\t\tDataset format:\n\t\n\n{\n    'src': 'JAPANESE WEB NOVEL CHAPTER',\n    'trg': 'CORRESPONDING ENGLISH TRANSLATION',\n    'meta': {\n        'general': {\n            'series_title_eng': 'ENGLISH SERIES TITLE',\n            'series_title_jap': 'JAPANESE SERIES TITLE',\n            'sentence_alignment_score':… See the full description on the dataset page: https://huggingface.co/datasets/NilanE/ParallelFiction-Ja_En-100k.","first_N":5,"first_N_keywords":["translation","Japanese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ParallelFiction-Ja_En-100k-json","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mpasila/ParallelFiction-Ja_En-100k-json","creator_name":"minipasila","creator_url":"https://huggingface.co/mpasila","description":"This is my conversion of NilanE/ParallelFiction-Ja_En-100k into json which can be read by text-generation-webui when training a model.\n\n\t\n\t\t\n\t\tOriginal Dataset card\n\t\n\n\n\t\n\t\t\n\t\tDataset details\n\t\n\nEach entry in this dataset is a sentence-aligned Japanese web novel chapter and English fan translation.\nThe intended use-case is for document translation tasks.\n\n\t\n\t\t\n\t\tDataset format\n\t\n\n{\n  'src' : 'JAPANESE CHAPTER'\n  'trg' : 'ENGLISH TRANSLATION'\n  'meta' : {\n    \"source\": 'SAME ACROSS ALL ENTRIES'… See the full description on the dataset page: https://huggingface.co/datasets/mpasila/ParallelFiction-Ja_En-100k-json.","first_N":5,"first_N_keywords":["translation","Japanese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ParallelFiction-Ja_En-100k-alpaca","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mpasila/ParallelFiction-Ja_En-100k-alpaca","creator_name":"minipasila","creator_url":"https://huggingface.co/mpasila","description":"This is a modified version of NilanE/ParallelFiction-Ja_En-100k which has been turned into Alpaca format.\n\n\t\n\t\t\n\t\tUpdate no longer chunked!!!\n\t\n\nThis is the non chunked version. If you want the chunked version it's here for 4k context based on augmxnt/shisa-base-7b-v1 tokenizer.\n\n\t\n\t\t\n\t\tDataset format (correct one)\n\t\n\n{\n  'instruction' : 'Japanese chapter'\n  'output' : 'English translation'\n  'input' : 'empty'\n}\n\n\n\t\n\t\t\n\t\tOriginal Dataset card\n\t\n\n\n\t\n\t\t\n\t\tDataset details\n\t\n\nEach entry in this… See the full description on the dataset page: https://huggingface.co/datasets/mpasila/ParallelFiction-Ja_En-100k-alpaca.","first_N":5,"first_N_keywords":["translation","Japanese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"pret-a-porter-instruction-v0.1","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kendamarron/pret-a-porter-instruction-v0.1","creator_name":"Kendamarron","creator_url":"https://huggingface.co/Kendamarron","description":"\n\t\n\t\t\n\t\tデータセットについて\n\t\n\nオープンソースLLMの出力を人手でチェック・修正したinstructionにSwallow-MXでoutputを生成したデータセットです。\noutputの精査は行っていないので、答えが間違っているデータが含まれます。\n詳細についてはこちらをご覧ください。\n\n\t\n\t\t\n\t\t備考\n\t\n\nDiscordサーバー「ローカルLLMに向き合う会」とメタデータラボ株式会社が共同開催された「LOCAL AI HACKATHON #000」にて作成した成果物になります。\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"nu-snli-rev","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cl-nagoya/nu-snli-rev","creator_name":"CL Research Group in Nagoya, Japan","creator_url":"https://huggingface.co/cl-nagoya","description":"cl-nagoya/nu-snli-rev dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Japanese","English","cc-by-sa-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"auto-wiki-qa","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cl-nagoya/auto-wiki-qa","creator_name":"CL Research Group in Nagoya, Japan","creator_url":"https://huggingface.co/cl-nagoya","description":"\n\t\n\t\t\n\t\tAutoWikiQA\n\t\n\n東工大が公開しているSwallow-MXを用いて、Wikipedia中のテキストを入力として「質問(query)」と「回答(answer)」を生成し、生成された質問と回答についてフィルタリングを行ったデータセットです。日本語のフリーなQAデータセットとしては2024年4月現在で最大規模となっています。\nまた、データの生成にはテンプレートなどのルールベース処理を入れていないため、既存データセットと比較して質問・回答の出力・形式が多様であることが特徴です。モデルに知識を教えるためのQAデータセットとしての利用や、検索拡張生成(Retrieval Augmented Generation: RAG)のための検索・埋め込みモデル開発への利用を想定しています。  \n\n\t\n\t\t\n\t\tUsage\n\t\n\nimport datasets as ds\n\ndataset: ds.Dataset = ds.load_dataset(\"cl-nagoya/auto-wiki-qa\", split=\"train\")\n\nprint(dataset)\n#… See the full description on the dataset page: https://huggingface.co/datasets/cl-nagoya/auto-wiki-qa.","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-sa-4.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"wiki40b_qa_ja","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/U23-lab/wiki40b_qa_ja","creator_name":"u-lab","creator_url":"https://huggingface.co/U23-lab","description":"wiki40b-ja から生成した質問応答データセット\n","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-sa-4.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"Swallow-MX-chatbot-DPO","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aixsatoshi/Swallow-MX-chatbot-DPO","creator_name":"aixsatoshi","creator_url":"https://huggingface.co/aixsatoshi","description":"Chatbot Arena Conversationsの質問文から、aixsatoshi/Swallow-MX-8x7b-NVE-chatvector-Mixtral-instruct-v2を使用して応答文を作成しました\n質問文は、以下のモデルのPrompt部分を使用しました\nChatbot Arena Conversations JA (calm2)\n以下引用です。\n\n指示文（prompt）はlmsys/chatbot_arena_conversationsのユーザ入力（CC-BY 4.0）を和訳したものです。これはChatbot Arenaを通して人間が作成した指示文であり、CC-BY 4.0で公開されているものです。複数ターンの対話の場合は最初のユーザ入力のみを使っています（そのため、このデータセットはすべて１ターンの対話のみになっております）。\n和訳にはfacebookの翻訳モデル（MIT License）を使っています。\n\n","first_N":5,"first_N_keywords":["Japanese","cc-by-4.0","1K - 10K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"jimba-instruction-simplify-200","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kendamarron/jimba-instruction-simplify-200","creator_name":"Kendamarron","creator_url":"https://huggingface.co/Kendamarron","description":"\n\t\n\t\t\n\t\tデータセットについて\n\t\n\nKendamarron/jimba-instuction-1k-betaのinstructionのうち200個をより単純なタスクに書き換えたデータセットです。\n『Wizard LM』のIn-depth evolvingを再現するために作成しました。\n将来的にはもう少しレコード数を増やしたいと考えています。\n詳細についてはこちらをご覧ください。\n\n\t\n\t\t\n\t\t備考\n\t\n\nDiscordサーバー「ローカルLLMに向き合う会」とメタデータラボ株式会社が共同開催された「LOCAL AI HACKATHON #000」にて作成した成果物になります。\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"jpflan-raw","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ego/jpflan-raw","creator_name":"Paolo","creator_url":"https://huggingface.co/Ego","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a collection of raw data from ~40 Japanese open source downstream task datasets.This dataset was built with the intention of collecting high quality datasets which were not machine translated to and from Japanese.The templated version, which should be used to perform instruction finetuning on LLMs, can be found here.  \n\n\t\n\t\t\n\t\tDataset format\n\t\n\nAs this is a collection of datasets, each one is categorized by task and can contain different amounts of information… See the full description on the dataset page: https://huggingface.co/datasets/Ego/jpflan-raw.","first_N":5,"first_N_keywords":["text-generation","Japanese","cc-by-sa-4.0","1M - 10M","arrow"],"keywords_longer_than_N":true},
	{"name":"AthenaGenSynth-dataset","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/win10/AthenaGenSynth-dataset","creator_name":"ZINWIN(Zuojun-Ye)","creator_url":"https://huggingface.co/win10","description":"使用我本人的github項目(https://github.com/win10ogod/AthenaGenSynth)生成的預訓練資料\nUse the pre-training data generated by my own github project (https://github.com/win10ogod/AthenaGenSynth)\n","first_N":5,"first_N_keywords":["text-generation","English","Chinese","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"Hachi-Alpaca","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/Hachi-Alpaca","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\n\t\n\t\t\n\t\tHachi-Alpaca\n\t\n\n\nHachi-Alpacaは、  \n\nStanford Alpacaの手法  \nmistralai/Mixtral-8x22B-Instruct-v0.1\n\nで作った合成データ(Synthetic data)です。モデルの利用にはDeepinfraを利用しています。  \nまた、\"_cleaned\"がついたデータセットはmistralai/Mixtral-8x22B-Instruct-v0.1によって精査されています。  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: HachiML\nLanguage(s) (NLP): Japanese\nLicense: Apache 2.0\nGithub: Alpaca-jp\n\n\n\t\n\t\n\t\n\t\tUses\n\t\n\n\n\n# library\nfromdatasets import load_dataset\n\n# Recommend getting the latest version… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/Hachi-Alpaca.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"chatbot-arena-ja-calm2-7b-chat-experimental_deduped","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GENIAC-Team-Ozaki/chatbot-arena-ja-calm2-7b-chat-experimental_deduped","creator_name":"GENIAC Team Ozaki","creator_url":"https://huggingface.co/GENIAC-Team-Ozaki","description":"chatbot-arena-ja-calm2-7b-chatからpromptが一致するデータを削除したデータセットです。\n","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"economy-watchers-survey","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/retarfi/economy-watchers-survey","creator_name":"Masahiro Suzuki","creator_url":"https://huggingface.co/retarfi","description":"\n\t\n\t\t\n\t\teconomy-watchers-survey\n\t\n\nEconomy Watchers Survey data.It is automatically updated by GitHub Actions as the economy watcher is updated.The dataset for tasks is retarfi/economy-watchers-survey-evaluation. \n景気ウォッチャー調査のデータを自動更新・整形・抽出を行います。自動更新はGitHub Actionsによって月次で行われます。タスク用のデータセットはretarfi/economy-watchers-survey-evaluationから利用可能です。  \n\n\t\n\t\t\n\t\n\t\n\t\tData detail\n\t\n\nPlease refer to the following papers for the data detail.データの詳細は、以下の論文を参照してください。\n\nEnglish paper:… See the full description on the dataset page: https://huggingface.co/datasets/retarfi/economy-watchers-survey.","first_N":5,"first_N_keywords":["Japanese","cc-by-4.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"VibeEval","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RekaAI/VibeEval","creator_name":"Reka AI","creator_url":"https://huggingface.co/RekaAI","description":"\n\t\n\t\t\n\t\tVibe-Eval\n\t\n\nA benchmark for evaluating multimodal chat models, including especially challenging examples.\n[Link to paper] [Blogpost] [Github]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset\n\t\n\nEach example has the following fields:\n\nexample_id: a unique ID for the example\ncategory: the category that this example belongs to, either difficulty-normal or difficulty-hard\nprompt: the user prompt\nreference: a golden reference answer for the prompt\nimage: an image struct (containing bytes and path keys).… See the full description on the dataset page: https://huggingface.co/datasets/RekaAI/VibeEval.","first_N":5,"first_N_keywords":["image-to-text","image-classification","English","Polish","Chinese"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })… See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })… See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"WikiHowNFQA-ja","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GENIAC-Team-Ozaki/WikiHowNFQA-ja","creator_name":"GENIAC Team Ozaki","creator_url":"https://huggingface.co/GENIAC-Team-Ozaki","description":"Lurunchik/WikiHowNFQAを日本語に翻訳したデータセットです。\n","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  SIB200ClusteringS2S\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nSIB-200 is the largest publicly available topic classification\n        dataset based on Flores-200 covering 205 languages and dialects annotated. The dataset is\n        annotated in English for the topics,  science/technology, travel, politics, sports,\n        health, entertainment, and geography. The labels are then transferred to the other languages\n        in Flores-200 which are human-translated.\n\t\n\t\t\n\n\n\n\n\t\t\nTask… See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200.","first_N":5,"first_N_keywords":["text-classification","expert-annotated","expert-generated","translated","Achinese"],"keywords_longer_than_N":true},
	{"name":"OSCOR-2301-ja-cleaned","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayousanz/OSCOR-2301-ja-cleaned","creator_name":"yousan","creator_url":"https://huggingface.co/ayousanz","description":"\n\t\n\t\t\n\t\t概要\n\t\n\noscar-corpus/OSCAR-2301の以下のjaのみを corpus-cleanerを使用してデータクリーニングを行なったデーセット群\n\n\t\n\t\t\nCode\nLanguage\n# docs\n# words\nContent Length :\n\n\n\t\t\nja\nJapanese\n94,236,404\n4,401,059,165\n181.2 GB\n\n\n\t\n\nただし以下のファイルは、クリーニングが成功していないため除外しています。\nja_meta_part_117.jsonl\nja_meta_part_13.jsonl\nja_meta_part_24.jsonl\nja_meta_part_4.jsonl\nja_meta_part_64.jsonl\nja_meta_part_81.jsonl\nja_meta_part_82.jsonl\n\n","first_N":5,"first_N_keywords":["Japanese","cc0-1.0","10M - 100M","json","Text"],"keywords_longer_than_N":true},
	{"name":"AutoWikiQA","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kanhatakeyama/AutoWikiQA","creator_name":"kan hatakeyama","creator_url":"https://huggingface.co/kanhatakeyama","description":"\n\t\n\t\t\n\t\tWikipedia日本語版からのQ&Aの自動生成\n\t\n\n\nMixtral 8x22bのGGUF(5bit)をベースに､Wikipedia日本語版の記事から､\n自動生成コード1\n自動生成コード2\n\n\nを使ってQ&Aを作成しました｡\n計算には東京工業大学のスーパーコンピュータTSUBAME4.0を利用しました｡\n\n\n\t\n\t\t\n\t\n\t\n\t\t注意\n\t\n\n\n回答にハルシネーション等が含まれている可能性があるので､フィルタリングをかける必要があるかもしれません｡\n\n","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"SingMOS_v1","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TangRain/SingMOS_v1","creator_name":"Tang","creator_url":"https://huggingface.co/TangRain","description":"paper link: SingMOS: An extensive Open-Source Singing Voice Dataset for MOS Prediction\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nSingMOS-v1 includes 3,421 Chinese and Japanese vocal clips with a sample rate of 16 kHz, totaling 4.25 hours in duration.\n\n\t\n\t\t\n\t\n\t\n\t\tSingMOS arichitecture\n\t\n\n|---SingMOS-v1\n    |---sets\n        |---train.txt\n        |---dev.txt\n        |---test-main.txt\n        |---test-other1.txt\n    |---wav\n        |---sys0001-utt0001.wav\n        ...\n    |---metadata.csv\n    |---system_info.txt… See the full description on the dataset page: https://huggingface.co/datasets/TangRain/SingMOS_v1.","first_N":5,"first_N_keywords":["Chinese","Japanese","cc-by-4.0","100M<n<1B","arxiv:2406.10911"],"keywords_longer_than_N":true},
	{"name":"cc_audio_8","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qgyd2021/cc_audio_8","creator_name":"晴耕雨读","creator_url":"https://huggingface.co/qgyd2021","description":"\n\t\n\t\t\n\t\t国际语音,电话场景中的声音分类\n\t\n\n","first_N":5,"first_N_keywords":["Chinese","English","Spanish","Korean","Japanese"],"keywords_longer_than_N":true},
	{"name":"niilc-qa","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sbintuitions/niilc-qa","creator_name":"SB Intuitions","creator_url":"https://huggingface.co/sbintuitions","description":"評価スコアの再現性確保と SB Intuitions 修正版の公開用クローン\n\nソース: mynlp/niilc-qa on GitHub\n\n\n\t\n\t\t\n\t\tNIILC Question Answering Dataset\n\t\n\n\nThis project provides a dataset for supporting the development of question answering systems. The data includes questions and their answers, and meta information such as question types, clues to obtain answers, Wikipedia pages in which answers can be found, and SPARQL queries for JWO (Japanese Wikipedia Ontology).\n\n\nHomepage:\n日本語:… See the full description on the dataset page: https://huggingface.co/datasets/sbintuitions/niilc-qa.","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-sa-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"hf-first","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kenu/hf-first","creator_name":"Kenu Gwangnam Heo","creator_url":"https://huggingface.co/kenu","description":"kenu/hf-first dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","Korean","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"assembly","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kenu/assembly","creator_name":"Kenu Gwangnam Heo","creator_url":"https://huggingface.co/kenu","description":"kenu/assembly dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","Japanese","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"Synthetic-JP-10-Turns-Roleplay-Dialogues-Nemotron-4-1k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Synthetic-JP-10-Turns-Roleplay-Dialogues-Nemotron-4-1k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tSynthetic-JP-10-Turns-Roleplay-Dialogues-Nemotron-4-1k\n\t\n\nnvidia/Nemotron-4-340B-Instructを用いて作成した、約1000件・各10ターンの日本語ロールプレイの対話を収録した合成対話データセットです。\nMagpieの手法を用いて作成した合成instructionデータセットであるAratako/Synthetic-JP-Roleplay-Instruction-Nemotron-4-1kを元に、同じくMagpieの手法を使い続きの対話を生成させています。\nNemotron-4の利用にはDeepInfraを利用しました。\n特に事後的なフィルタ処理は加えていないため、クオリティの低いレコードが含まれている可能性があります。ご注意ください。\nまた、一部のデータを見る限り、長いターンの対話の際途中でロールプレイを終了させようとする傾向があるように見えます。5ターンまで使うなど、利用するデータを絞ったほうが良いかもしれません。\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Synthetic-JP-Conversations-Magpie-Nemotron-4-10k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Synthetic-JP-Conversations-Magpie-Nemotron-4-10k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tSynthetic-JP-Conversations-Magpie-Nemotron-4-10k\n\t\n\nMagpieの手法をnvidia/Nemotron-4-340B-Instructに対して適用し作成した、約10000件の日本語instruction tuning用データセットです。\nデータセットの作成にはDeepInfraを利用しました。\nまた、このリポジトリでデータセット作成に用いたコードを公開しています。\n特に事後的なフィルタ処理は加えていないため、クオリティの低いレコードが含まれている可能性があります。ご注意ください。\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Synthetic-JP-Coding-Dataset-Magpie-Nemotron-4-10k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Synthetic-JP-Coding-Dataset-Magpie-Nemotron-4-10k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tSynthetic-JP-Coding-Dataset-Magpie-Nemotron-4-10k\n\t\n\nMagpieの手法をnvidia/Nemotron-4-340B-Instructに対して適用し作成した、約10000件の日本語のコーディング用対話データセットです。\nデータセットの作成にはDeepInfraを利用しました。\nまた、このリポジトリでデータセット作成に用いたコードを公開しています。これをベースに、システムプロンプトとstopを一部変更することで生成しています。\n特に事後的なフィルタ処理は加えていないため、クオリティの低いレコードが含まれている可能性があります。ご注意ください。\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \nBibTex\n@misc{lu2024languagecountslearnunlearn,\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \n      author={Taiming Lu and Philipp Koehn},\n      year={2024},\n      eprint={2406.13748},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2406.13748}, \n}\n\n","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"danbooru-wiki-2024","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/isek-ai/danbooru-wiki-2024","creator_name":"ISEKAI","creator_url":"https://huggingface.co/isek-ai","description":"\n\t\n\t\t\n\t\tdanbooru-wiki-2024\n\t\n\n\n\t\n\t\t\n\t\tAbout\n\t\n\nWiki pages about the danbooru tags on danbooru.donmai.us. The wiki contains the description of each tag and matching to pixiv tags.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\n  \"isek-ai/danbooru-wiki-2024\",\n# revision=\"202408-at20240906\", # optional\n  split=\"train\",\n)\n\nThe revision name is as same as isek-ai/danbooru-tags-2024's.\n\n[!WARNING]\nNote:\nThis dataset would be irreguraly updated, if you want to use the same… See the full description on the dataset page: https://huggingface.co/datasets/isek-ai/danbooru-wiki-2024.","first_N":5,"first_N_keywords":["text-generation","text-classification","English","Japanese","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"Synthetic-JP-EN-Translation-Dataset-Magpie-Nemotron-4-20k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Translation-Dataset-Magpie-Nemotron-4-20k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tSynthetic-JP-EN-Translation-Dataset-Magpie-Nemotron-4-20k\n\t\n\nMagpieの手法をnvidia/Nemotron-4-340B-Instructに対して適用し作成した、20000件の日⇔英翻訳データセットです。\nデータセットの作成にはDeepInfraを利用しました。\nまた、このリポジトリでデータセット作成に用いたコードを公開しています。これをベースに、システムプロンプトとstopを一部変更することで生成しています。\n特に事後的なフィルタ処理は加えていないため、クオリティの低いレコードが含まれている可能性があります。ご注意ください。\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"auto-wikinews-qa","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/auto-wikinews-qa","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"hpprc/auto-wikinews-qa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-sa-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"corrected-mt-bench-ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/karakuri-ai/corrected-mt-bench-ja","creator_name":"KARAKURI","creator_url":"https://huggingface.co/karakuri-ai","description":"\n\t\n\t\t\n\t\tCorrected MT-Bench-ja\n\t\n\nInflection AIによるCorrected MT-Benchの日本語訳です。\n一部の設問はStability AIによるJapanese MT-Benchを使用しています。\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Synthetic-JP-EN-Coding-Dataset-Magpie-69k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Coding-Dataset-Magpie-69k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tSynthetic-JP-EN-Coding-Dataset-Magpie-69k\n\t\n\nMagpieの手法を様々なモデルに対して適用し作成した、約69000件の日本語・英語のコーディング対話データセットです。\n作成に利用したモデルは以下の通りです。modelキーに該当レコードの作成に利用したモデル情報があります。\n\nnvidia/Nemotron-4-340B-Instruct\nmicrosoft/Phi-3-medium-4k-instruct\nmistralai/Mixtral-8x22B-Instruct-v0.1\ncyberagent/calm3-22b-chat\n\nデータセットの作成にはDeepInfraを利用しました。\nまた、このリポジトリでデータセット作成に用いたコードを公開しています。これをベースに、プロンプトテンプレートやシステムプロンプト等を一部変更することで生成しています。特に事後的なフィルタ処理は加えていないため、クオリティの低いレコードが含まれている可能性があります。ご注意ください。\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"tydi_xor_rc","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/coastalcph/tydi_xor_rc","creator_name":"CoAStaL NLP Group","creator_url":"https://huggingface.co/coastalcph","description":"\n\t\n\t\t\n\t\tDataset Card for \"tydi_xor_rc\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages. \nXORQA is an extension of the original TyDi QA dataset to also include unanswerable questions, where context documents are only in English but questions are in 7 languages.\nXOR-AttriQA contains annotated attribution data for a sample of XORQA.\nThis dataset is a combined and simplified version of the Reading Comprehension data from XORQA and… See the full description on the dataset page: https://huggingface.co/datasets/coastalcph/tydi_xor_rc.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"Synthetic-JP-EN-Coding-Dataset-801k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Coding-Dataset-801k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tSynthetic-JP-EN-Coding-Dataset-801k\n\t\n\nMagpieによって作成したコードSFTデータセットであるAratako/Synthetic-JP-EN-Coding-Dataset-Magpie-69kを元に、Evol-Instructのような手法を用いて複数のinstructionとresonseを生成し拡張して作成した、日英混合801262件のコードSFT用合成データセットです。\n\n日本語: 173849件\n英語: 627413件\n\n元のinstructionの作成に利用したモデルは以下の通りです。modelキーに該当レコードの作成に利用したモデル情報があります。\n\nnvidia/Nemotron-4-340B-Instruct\nmicrosoft/Phi-3-medium-4k-instruct\nmistralai/Mixtral-8x22B-Instruct-v0.1… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Coding-Dataset-801k.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"self-rewarding_instruct","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/self-rewarding_instruct","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\n\t\n\t\t\n\t\tself-rewarding_instruct\n\t\n\n\nself-rewarding_instructは、  \n\nStanford Alpacaの手法\nkunishou/oasst1-89k-jaをseed tasksとして  \nmistralai/Mixtral-8x22B-Instruct-v0.1\n\nで作った合成データ(Synthetic data)です。モデルの利用にはDeepinfraを利用しています。データセットはmistralai/Mixtral-8x22B-Instruct-v0.1によって精査されています。  \nself-rewarding用に作成したため、output_exampleとなっていますがInstruction Tuningにも用いれると思います。  \n\n\n\n\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: HachiMLLanguage(s) (NLP): Japanese\nLicense: Apache 2.0\nGithub:… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/self-rewarding_instruct.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"self-rewarding_AIFT_MSv0.3_lora","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HachiML/self-rewarding_AIFT_MSv0.3_lora","creator_name":"Hajime Yagihara","creator_url":"https://huggingface.co/HachiML","description":"\n\t\n\t\t\n\t\tself-rewarding_AIFT_MSv0.3_lora\n\t\n\n\n\nHachiML/self-rewarding_instructを、\n\nsplit=AIFT_M1 は HachiML/Mistral-7B-v0.3-m1-lora\nsplit=AIFT_M2 は HachiML/Mistral-7B-v0.3-m2-lora\nでそれぞれself-rewardingして作成したAIFT(AI Feedback Tuning) dataです。\n手順は以下の通りです。\n\n\nHachiML/self-rewarding_instructのInstructionに対する回答を各モデルで4つずつ作成\n回答に対して各モデルで点数評価\n最高評価の回答をchosen、最低評価の回答をrejectedとする\n詳細はself-rewardingの論文を参照してください。\n\n\n\n\n\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: HachiMLLanguage(s) (NLP):… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/self-rewarding_AIFT_MSv0.3_lora.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"rendered_xnli","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ernie-research/rendered_xnli","creator_name":"ernie-research","creator_url":"https://huggingface.co/ernie-research","description":"   \n\n\t\n\t\t\n\t\tDataset Card for rendered XNLI\n\t\n\n\nThis repository contains the rendered XNLI dataset evaluated in the paper Autoregressive Pre-Training on Pixels and Texts (EMNLP 2024). For detailed instructions on how to use the model, please visit our GitHub page.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{chai2024autoregressivepretrainingpixelstexts,\n  title = {Autoregressive Pre-Training on Pixels and Texts},\n  author = {Chai, Yekun and Liu, Qingyi and Xiao, Jingwu and Wang, Shuohuan and Sun, Yu and Wu, Hua}… See the full description on the dataset page: https://huggingface.co/datasets/ernie-research/rendered_xnli.","first_N":5,"first_N_keywords":["English","Japanese","Chinese","French","Russian"],"keywords_longer_than_N":true},
	{"name":"kuon-audio","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lissette/kuon-audio","creator_name":"kuon","creator_url":"https://huggingface.co/lissette","description":"久远语音\n来源于TV动画提取，进过uvr分离背景音，人工筛选质量较好的。\n610个短语音，1个歌曲\n","first_N":5,"first_N_keywords":["audio-to-audio","text-to-audio","Japanese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)… See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)… See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"aihub-koja-translation-integrated-large-4.3m","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-large-4.3m","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\n\t\n\t\t\n\t\tAI Hub Ko-Ja Translation Dataset (Integrated)\n\t\n\nAI Hub의 한-일 번역 관련 데이터셋 10개를 병합한 자료입니다. 병합 시 총 데이터 개수는 4,339,465개이며, 이중 10,000개의 validation set와 2,000개의 test set가 분리되어 모든 데이터 사이즈(large-4.3m, base-1m, small-100k)에서 동일하게 사용됩니다.\n\nlarge-4.3m (train): 병합 데이터 100% 사용; 총 4,327,465개\n\nbase-1m (train): 병합 데이터 중 1M개 사용; 총 1,000,000개\n\nsmall-100k (train): 병합 데이터 중 100K개 사용; 총 100,000개\n\n\n\n\t\n\t\t\n\t\tSubsets\n\t\n\n\n\t\n\t\t\nName\nTotal Size\nJapanese Size (Utilized Only)\nURL\nDatasetkey (AIHub)\n\n\n\t\t\n한국어-일본어 번역 말뭉치… See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-large-4.3m.","first_N":5,"first_N_keywords":["translation","Korean","Japanese","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"aihub-koja-translation-integrated-base-1m","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-base-1m","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\n\t\n\t\t\n\t\tAI Hub Ko-Ja Translation Dataset (Integrated)\n\t\n\nAI Hub의 한-일 번역 관련 데이터셋 10개를 병합한 자료입니다. 병합 시 총 데이터 개수는 4,339,465개이며, 이중 10,000개의 validation set와 2,000개의 test set가 분리되어 모든 데이터 사이즈(large-4.3m, base-1m, small-100k)에서 동일하게 사용됩니다.\n\nlarge-4.3m (train): 병합 데이터 100% 사용; 총 4,327,465개\n\nbase-1m (train): 병합 데이터 중 1M개 사용; 총 1,000,000개\n\nsmall-100k (train): 병합 데이터 중 100K개 사용; 총 100,000개\n\n\n\n\t\n\t\t\n\t\tSubsets\n\t\n\n\n\t\n\t\t\nName\nTotal Size\nJapanese Size (Utilized Only)\nURL\nDatasetkey (AIHub)\n\n\n\t\t\n한국어-일본어 번역 말뭉치… See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-base-1m.","first_N":5,"first_N_keywords":["translation","Korean","Japanese","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"aihub-koja-translation-integrated-small-100k","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-small-100k","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\n\t\n\t\t\n\t\tAI Hub Ko-Ja Translation Dataset (Integrated)\n\t\n\nAI Hub의 한-일 번역 관련 데이터셋 10개를 병합한 자료입니다. 병합 시 총 데이터 개수는 4,339,465개이며, 이중 10,000개의 validation set와 2,000개의 test set가 분리되어 모든 데이터 사이즈(large-4.3m, base-1m, small-100k)에서 동일하게 사용됩니다.\n\nlarge-4.3m (train): 병합 데이터 100% 사용; 총 4,327,465개\n\nbase-1m (train): 병합 데이터 중 1M개 사용; 총 1,000,000개\n\nsmall-100k (train): 병합 데이터 중 100K개 사용; 총 100,000개\n\n\n\n\t\n\t\t\n\t\tSubsets\n\t\n\n\n\t\n\t\t\nName\nTotal Size\nJapanese Size (Utilized Only)\nURL\nDatasetkey (AIHub)\n\n\n\t\t\n한국어-일본어 번역 말뭉치… See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-small-100k.","first_N":5,"first_N_keywords":["translation","Korean","Japanese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"danbooru2023-webp-4Mpixel_index","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deepghs/danbooru2023-webp-4Mpixel_index","creator_name":"DeepGHS","creator_url":"https://huggingface.co/deepghs","description":"Index files of KBlueLeaf/danbooru2023-webp-4Mpixel.\nYou can download images from KBlueLeaf/danbooru2023-webp-4Mpixel with cheesechaser.\nfrom cheesechaser.datapool import DanbooruWebpDataPool\n\npool = DanbooruWebpDataPool()\n\n# download danbooru images with webp format, to directory /data/danbooru_webp\npool.batch_download_to_directory(\n    resource_ids=range(6000000, 6001000),\n    dst_dir='/data/danbooru_webp',\n    max_workers=12,\n)\n\n","first_N":5,"first_N_keywords":["image-classification","image-to-image","text-to-image","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"kenkensz9_1242tw2","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kenkensz9/kenkensz9_1242tw2","creator_name":"福島　健四郎","creator_url":"https://huggingface.co/kenkensz9","description":"このデータセットは、著作者である自分がしたツイートから特に優れたもの(後述)を集めたものです。\n定義：言語化が難しい事柄を言語化しているツイート。または世界観が独特なもの。\n期間：2022年5月16日～2024年5月24日\nツイート数：1243\n上の期間以前にもツイート自体はしていますが、人力で選定しているため、とりあえずこの期間のみとなっています。\nこのセットで微調整をすると、ベースモデルの表現力を拡張することはできるのではないかと思います。\nとりわけ、人格を与えることとツイートを生成するタスクに使用しているため、システムプロンプトと入力は固定で使用しています。\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"nareba1691","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kenkensz9/nareba1691","creator_name":"福島　健四郎","creator_url":"https://huggingface.co/kenkensz9","description":"このデータセットは、OpenAI社のGPT-3.5を\nhttps://huggingface.co/datasets/kenkensz9/kenkensz9_1242tw2\nのデータでファインチューニングした後に、更に独自に収集した人格のあるツイート330でファインチューニングしたモデルでツイートを生成し、\nそれに対してスコアを付与したモデルです。\n10点：おー\n9点：まあまあ\n8点：うーん\nみたいな感じです。\n","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"danbooru_wikis_full","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deepghs/danbooru_wikis_full","creator_name":"DeepGHS","creator_url":"https://huggingface.co/deepghs","description":"\n\t\n\t\t\n\t\tDanbooru Full Wiki Dataset\n\t\n\nThis is the full wiki dataset of danbooru.donmai.us, containing the wiki pages/tags/tag aliases/tag implications. You can train something like LLMs on this dataset\n\n\t\n\t\t\n\t\tInformation\n\t\n\n\n\t\n\t\t\n\t\tWiki Pages\n\t\n\nThere are 189161 wiki items in total. Last updated at 2024-06-16 02:31:27 UTC.\nThese are the information of recent 50 wiki items:\n\n\t\n\t\t\nid\ntitle\nother_names\ntext_length\nis_locked\nis_deleted\ncreated_at\nupdated_at\n\n\n\t\t\n196503\nli_yuting_(female)\n[\"离雨婷\"… See the full description on the dataset page: https://huggingface.co/datasets/deepghs/danbooru_wikis_full.","first_N":5,"first_N_keywords":["text-classification","text-generation","feature-extraction","no-annotation","danbooru"],"keywords_longer_than_N":true},
	{"name":"Nanami-Chiaki-audio","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lissette/Nanami-Chiaki-audio","creator_name":"kuon","creator_url":"https://huggingface.co/lissette","description":"弹丸论破的七海千秋语音数据\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"Yokodera-audio","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lissette/Yokodera-audio","creator_name":"kuon","creator_url":"https://huggingface.co/lissette","description":"《变态王子与不笑猫》男主角，横寺阳人，声优：梶裕贵\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"Tanuki-Phase2-annotation-dataset","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kevineen/Tanuki-Phase2-annotation-dataset","creator_name":"KW","creator_url":"https://huggingface.co/kevineen","description":"kevineen/Tanuki-Phase2-annotation-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Japanese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Chatgpt","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effort… See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"pokemon_battle_team_dataset_regulation_f","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fufufukakaka/pokemon_battle_team_dataset_regulation_f","creator_name":"YusukeFukasawa","creator_url":"https://huggingface.co/fufufukakaka","description":"ポケモン(VGC)のレギュレーションF ルールにおける選出データを記録したデータセットです。\nYouTube 上で公開状態になっていた対戦配信から選出データを収集しました。trainer_id がそれぞれ配信を行っていた方に対応します。\nなお、trainer_id 13 は本データセット作者が行った対戦データを示しています。\nこちらのデータを用いて、2024年5月にリモートポケモン学会というコミュニティで発表を行いました。\n\n配信 https://youtu.be/4Op-JvVEQ10?t=3479\nスライド https://speakerdeck.com/fufufukakaka/ji-jie-xue-xi-woyong-itapokemondui-zhan-xuan-chu-yu-ce\n\n","first_N":5,"first_N_keywords":["Japanese","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Japanese-Roleplay-Dialogues","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OmniAICreator/Japanese-Roleplay-Dialogues","creator_name":"OmniAICreator","creator_url":"https://huggingface.co/OmniAICreator","description":"\n\t\n\t\t\n\t\tJapanese-Roleplay-Dialogues\n\t\n\nThis is a dialogue corpus collected from Japanese role-playing forum (commonly known as \"なりきりチャット(narikiri chat)\"). Each record corresponds to a single thread.\nFor the original version, no filtering has been applied.\nFor the filtered version, the following filtering and cleaning conditions have been applied:\n\nIf the number of unique poster in the posts of each record is 1 or less, delete the entire record.\nIf the length of the posts is 10 or less, delete… See the full description on the dataset page: https://huggingface.co/datasets/OmniAICreator/Japanese-Roleplay-Dialogues.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"commoncatalog-cc-by-ja","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alfredplpl/commoncatalog-cc-by-ja","creator_name":"Yasunori Ozaki","creator_url":"https://huggingface.co/alfredplpl","description":"\n\t\n\t\t\n\t\tCommonCatalog CC-BY Ja\n\t\n\nこのリポジトリはCommonCatalog CC-BYを拡張して、追加の情報を入れたものです。\n以下の情報が追加されています。\n\nLLaVA-JPを改良したモデルによる簡易な日本語キャプション1つ\nLLaVA-JPを改良したモデルによるできるだけ詳細な日本語キャプション3つ (予定)\n\n\n\t\n\t\t\n\t\tSample Code\n\t\n\ndf2=pandas.read_csv(\"cc-by-ja.csv\")\n\ndataset = load_dataset(\"common-canvas/commoncatalog-cc-by\",split=\"train\",streaming=True)\n\ndata_info=[]\nfor i,data in enumerate(tqdm(dataset)):\n    data[\"jpg\"].save(f\"/mnt/my_raid/pixart_jp/InternImgs/{i:09}.jpg\")\n\n    data_info.append({\n        \"height\":… See the full description on the dataset page: https://huggingface.co/datasets/alfredplpl/commoncatalog-cc-by-ja.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","Japanese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"auto-wiki-qa-rels","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/auto-wiki-qa-rels","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"hpprc/auto-wiki-qa-rels dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Japanese","cc-by-sa-4.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"CaLMQA","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shanearora/CaLMQA","creator_name":"Shane Arora","creator_url":"https://huggingface.co/shanearora","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\nCaLMQA is a long-form question answering (LFQA) dataset spanning 23 high- to low-resource languages. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCaLMQA is an LFQA dataset with 2K questions from 23 languages, 11 high- to mid-resource and 12 low-resource.\nQuestions are either culturally specific – uniquely or more likely to be asked by people of a specific\nculture – or culturally agnostic (not culturally specific). These questions were collected to… See the full description on the dataset page: https://huggingface.co/datasets/shanearora/CaLMQA.","first_N":5,"first_N_keywords":["multilingual","Afar","Arabic","Baluchi","German"],"keywords_longer_than_N":true},
	{"name":"ESCI","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/henilp105/ESCI","creator_name":"henil panchal","creator_url":"https://huggingface.co/henilp105","description":"henilp105/ESCI dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","text-retrieval","English","Japanese","Spanish"],"keywords_longer_than_N":true},
	{"name":"yuho-text-2023","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/numad/yuho-text-2023","creator_name":"kiyoshi.numatazawa","creator_url":"https://huggingface.co/numad","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nこのデータはEDINET閲覧（提出）サイトで公開されている2023年に提出された有価証券報告書から特定の章を抜粋したデータです。\n各レコードのurl列が出典となります。\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nデータの内容は下記想定です\n\n\t\n\t\t\n物理名\n論理名\n型\n概要\n必須\n\n\n\t\t\ndoc_id\n文書ID\nstr\n有価証券報告書の単位で発行されるID\n〇\n\n\nedinet_code\nEDINETコード\nstr\nEDINET内での企業単位に採番されるID\n〇\n\n\ncompany_name\n企業名\nstr\n企業名\n〇\n\n\ndocument_name\n文書タイトル\nstr\n有価証券報告書のタイトル\n〇\n\n\nsec_code\n証券コード\nstr\n証券コード\n×\n\n\nperiod_start\n期開始日\ndate(yyyy-mm-dd)\n報告対象期間の開始日\n〇\n\n\nperiod_end\n期終了日… See the full description on the dataset page: https://huggingface.co/datasets/numad/yuho-text-2023.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"yuho-text-2024","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/numad/yuho-text-2024","creator_name":"kiyoshi.numatazawa","creator_url":"https://huggingface.co/numad","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nこのデータはEDINET閲覧（提出）サイトで公開されている2024年に提出された有価証券報告書から特定の章を抜粋したデータです。\n各レコードのurl列が出典となります。\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nデータの内容は下記想定です\n\n\t\n\t\t\n物理名\n論理名\n型\n概要\n必須\n\n\n\t\t\ndoc_id\n文書ID\nstr\n有価証券報告書の単位で発行されるID\n〇\n\n\nedinet_code\nEDINETコード\nstr\nEDINET内での企業単位に採番されるID\n〇\n\n\ncompany_name\n企業名\nstr\n企業名\n〇\n\n\ndocument_name\n文書タイトル\nstr\n有価証券報告書のタイトル\n〇\n\n\nsec_code\n証券コード\nstr\n証券コード\n×\n\n\nperiod_start\n期開始日\ndate(yyyy-mm-dd)\n報告対象期間の開始日\n〇\n\n\nperiod_end\n期終了日… See the full description on the dataset page: https://huggingface.co/datasets/numad/yuho-text-2024.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"quran_multilingual_parallel","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/quran_multilingual_parallel","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\t📘 Qur’an Multilingual Parallel Dataset (quran_multilingual_parallel)\n\t\n\nThis dataset presents a clean, structurally-aligned multilingual parallel corpus of the Qur’anic text. It is intended for linguistic, computational, and cross-lingual AI applications — not only for religious interpretation.\nIt contains over 6,200 verse-level alignments in 54 human languages, formatted in a machine-friendly .csv structure with language-specific translation fields.\n\n\n\t\n\t\t\n\t\n\t\n\t\t🧠 Dataset Highlights… See the full description on the dataset page: https://huggingface.co/datasets/freococo/quran_multilingual_parallel.","first_N":5,"first_N_keywords":["translation","Arabic","Albanian","Amharic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Qwen2.5-7B-Instruct-magpie-R-questions-ja-0.8k-tmp","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OsakanaTeishoku/Qwen2.5-7B-Instruct-magpie-R-questions-ja-0.8k-tmp","creator_name":"Jinsei Shiraishi","creator_url":"https://huggingface.co/OsakanaTeishoku","description":"OsakanaTeishoku/Qwen2.5-7B-Instruct-magpie-R-questions-ja-0.8k-tmp dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Japanese","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2Jyq/common_voice_21_0","creator_name":"2Jyq","creator_url":"https://huggingface.co/2Jyq","description":"Due to storage limits some files had to be split into multiple parts. They can be merged like this: cat file.* > file.\n","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","multilingual","extended|common_voice","Abkhaz"],"keywords_longer_than_N":true},
	{"name":"everyday_conversations_ja","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/U23-lab/everyday_conversations_ja","creator_name":"u-lab","creator_url":"https://huggingface.co/U23-lab","description":"\n\t\n\t\t\n\t\tデータセットについて\n\t\n\nこのデータセットは、 HuggingFaceTB/everyday-conversations-llama3.1-2k を機械翻訳で日本語化したものになります。\n具体的には、everyday-conversations-llama3.1-2kをトピックごとの対話のペアに変更してDeepLで翻訳したものとなります。\n\n\t\n\t\t\n\t\t詳細\n\t\n\n\ntopic: everyday-conversations-llama3.1-2kのtopic\nuser: 各トピックごとのユーザーからの発話\nassistant: 各トピックごとのユーザーへの返答\nassistantの返答がない場合はNone\n\n\n\t\n\t\t\n\t\t注意事項\n\t\n\n\n人手で若干修正をしましたが、日本語が変な箇所がいくつか散見されます。\nライセンス：apache 2.0\n\n","first_N":5,"first_N_keywords":["text2text-generation","Japanese","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"danbooru2023-captions-1ktar","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/6DammK9/danbooru2023-captions-1ktar","creator_name":"Darren Laurie","creator_url":"https://huggingface.co/6DammK9","description":"\n\t\n\t\t\n\t\tDanbooru 2023 captions only in 1k tar\n\t\n\n\nRaw captions jointed by unpublished extended dataset from KBlueLeaf/danbooru2023-metadata-database\n\nIt aligns to nyanko7/danbooru2023. There are around 200k missing for the 2024 version, I'll try to use Minthy/ToriiGate-v0.4-7B to fill in the rest.\n\nmeta_cap.json has been provided in compressed format if you want to train with kohyas triner. Currently I'm trying to merge this with my 2024 version.\n\n\n\n\t\n\t\t\n\t\tCore logic\n\t\n\n\nThe script building… See the full description on the dataset page: https://huggingface.co/datasets/6DammK9/danbooru2023-captions-1ktar.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","text-to-image","no-annotation","danbooru"],"keywords_longer_than_N":true},
	{"name":"imatrix-calibration","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eaddario/imatrix-calibration","creator_name":"Ed Addario","creator_url":"https://huggingface.co/eaddario","description":"\n\t\n\t\t\n\t\tImportance Matrix Calibration Datasets\n\t\n\nThis repository contains calibration datasets used to generate importance matrices (imatrix), which in turn help minimise errors introduced during quantization.\n\n\t\n\t\t\n\t\tMath calibration datasets\n\t\n\nThis dataset consists of over 10M tokens of cleaned math prompts and is available in six sizes, ranging from huge (~ 430,000 lines equivalent to approx. 10M tokens), to micro (~ 13,700 lines and 1.7M tokens avg).\nOriginal data sourced from… See the full description on the dataset page: https://huggingface.co/datasets/eaddario/imatrix-calibration.","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\n\t\n\t\t\n\t\tlightblue/reasoning-multilingual-R1-Llama-70B-train\n\t\n\nThis is a multilingual reasoning dataset covering more than 30 languages.\nThis dataset was made by:\n\nSampling prompts from English datasets and translating them to various languages\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\n\nThis dataset was then used to train a multilingual… See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"Synthetic-JP-EN-Coding-Dataset","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-jp/Synthetic-JP-EN-Coding-Dataset","creator_name":"LLM-jp","creator_url":"https://huggingface.co/llm-jp","description":"\n\t\n\t\t\n\t\tSynthetic-JP-EN-Coding-Dataset\n\t\n\nThis repository provides an instruction tuning dataset developed by LLM-jp, a collaborative project launched in Japan.\nThe dataset comprises a subset from Aratako/Synthetic-JP-EN-Coding-Dataset-801k.\n\n\t\n\t\t\n\t\tSend Questions to\n\t\n\nllm-jp(at)nii.ac.jp\n\n\t\n\t\t\n\t\tModel Card Authors\n\t\n\nThe names are listed in alphabetical order.\nHirokazu Kiyomaru and Takashi Kodama.\n","first_N":5,"first_N_keywords":["Japanese","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate… See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"japanese-music-emotion","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayousanz/japanese-music-emotion","creator_name":"yousan","creator_url":"https://huggingface.co/ayousanz","description":"\n\t\n\t\t\n\t\tjapanese music emotion\n\t\n\nMusic2Emotionを使って主に日本の音楽の感情分析を行ったデータセット\n分析されたデータは以下のようなフォーマットのjsonlになっています。\n{\n    \"index\": 1,\n    \"video_id\": \"xxxxxxxxx\",\n    \"title\": \"sampleTitle\",\n    \"channel\": \"sample channel name\",\n    \"url\": \"video url\",\n    \"download_date\": \"2025-02-24T00:19:22.334487\",\n    \"predicted_moods\": [\n        \"energetic\",\n        \"fast\",\n        \"fun\",\n        \"funny\",\n        \"groovy\",\n        \"happy\",\n        \"holiday\",\n        \"love\",\n        \"party\",\n        \"positive\"… See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/japanese-music-emotion.","first_N":5,"first_N_keywords":["Japanese","cc-by-4.0","1K - 10K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"japanese-music-emotion","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayousanz/japanese-music-emotion","creator_name":"yousan","creator_url":"https://huggingface.co/ayousanz","description":"\n\t\n\t\t\n\t\tjapanese music emotion\n\t\n\nMusic2Emotionを使って主に日本の音楽の感情分析を行ったデータセット\n分析されたデータは以下のようなフォーマットのjsonlになっています。\n{\n    \"index\": 1,\n    \"video_id\": \"xxxxxxxxx\",\n    \"title\": \"sampleTitle\",\n    \"channel\": \"sample channel name\",\n    \"url\": \"video url\",\n    \"download_date\": \"2025-02-24T00:19:22.334487\",\n    \"predicted_moods\": [\n        \"energetic\",\n        \"fast\",\n        \"fun\",\n        \"funny\",\n        \"groovy\",\n        \"happy\",\n        \"holiday\",\n        \"love\",\n        \"party\",\n        \"positive\"… See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/japanese-music-emotion.","first_N":5,"first_N_keywords":["Japanese","cc-by-4.0","1K - 10K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"امام جمعه اصفهان گفت: میزان نیاز آب شرب اصفهان ۱۱.۵ متر مکعب است که تمام استان اصفهان را پوشش میدهد و نسبت به قبل از انقلاب یکی از پیشرفتها در حوزه آب بوده است.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:… See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"magpie-japanese-math-instruction-17k-qwen2.5-bakeneko-32b-instruct","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kendamarron/magpie-japanese-math-instruction-17k-qwen2.5-bakeneko-32b-instruct","creator_name":"Kendamarron","creator_url":"https://huggingface.co/Kendamarron","description":"\n\t\n\t\t\n\t\tmagpie-japanese-math-instruction-17k-qwen2.5-bakeneko-32b-instruct\n\t\n\nrinna/qwen2.5-bakeneko-32b-instructを用いたMagpieで生成した合成Instructionデータセットです。\n合成したinstructionに対して、以下の方法で2つで回答を生成し、LLM評価で回答が一致していると判定されたレコードのみを残しています。\n\n「あなたは論理的で数学が得意なアシスタントです。」をsystem promptとして得られた応答\n「あなたは論理的で数学が得意で優秀なプログラマーです。与えられた問題をPythonを用いて回答します。最後に問題の最終的な答えをprint文で出力します。」をsystem promptとして得られたコードを実行した結果\n\n\n\t\n\t\t\n\t\n\t\n\t\t作成手順… See the full description on the dataset page: https://huggingface.co/datasets/Kendamarron/magpie-japanese-math-instruction-17k-qwen2.5-bakeneko-32b-instruct.","first_N":5,"first_N_keywords":["Japanese","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"Zero_SFT_Ja_v2_b3t4","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DataPilot/Zero_SFT_Ja_v2_b3t4","creator_name":"DataPilot","creator_url":"https://huggingface.co/DataPilot","description":"\n\t\n\t\t\n\t\tDataPilot/Zero_SFT_Ja_v2_b3t4\n\t\n\nこのデータセットは、日本語で記述された高品質な合成プロンプトとそのAI出力を収録しています。すべてのデータは Mistral Small 3.1 24B Instruct 2503 モデルを使用してゼロから合成されています。\n\n\t\n\t\t\n\t\t概要\n\t\n\n\n\t\n\t\t\n項目\n詳細\n\n\n\t\t\nデータセット名\nDataPilot/Zero_SFT_Ja_v2_b3t4\n\n\n言語\n日本語\n\n\nデータ作成方法\n完全自動生成（モデルによるゼロショット合成）\n\n\n使用モデル\nMistral Small 3.1 24B Instruct 2503\n\n\nフォーマット\nJSONL（id, input, output, conversation）\n\n\nライセンス\nApache-2.0\n\n\n作成コード\nfoxn2000/zero_one_instruction\n\n\n\t\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tデータセット構造\n\t\n\nデータセットには以下のカラムが含まれています。\n\n\t\n\t\t\nカラム名\n説明\n\n\n\t\t\nid… See the full description on the dataset page: https://huggingface.co/datasets/DataPilot/Zero_SFT_Ja_v2_b3t4.","first_N":5,"first_N_keywords":["text-generation","Japanese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Open-R1-Mulitlingual-SFT","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT","creator_name":"GUIJIN SON","creator_url":"https://huggingface.co/amphora","description":"\n\t\n\t\t\n\t\tOpen-R1-Mulitlingual-SFT\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nOpen-R1-Mulitlingual-SFT is a curated dataset designed for multilingual supervised fine-tuning.\nThe source data comprises multiple datasets containing original prompts and responses, which were subsequently translated into 14 languages using GPT-4o.\n\n\t\n\t\t\n\t\tSources\n\t\n\nThe dataset is derived from:\n\nopen-thoughts/OpenThoughts-114kHugging Face: open-thoughts/OpenThoughts-114k\nbespokelabs/Bespoke-Stratos-17kHugging Face:… See the full description on the dataset page: https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT.","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering… See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tWMT24++\n\t\n\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\nthe publication\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\nIf you are interested in the images of the source URLs for each document, please see here.\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach language pair is stored in its own jsonl file.\nEach row is… See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"SimpleStories-JA","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SimpleStories/SimpleStories-JA","creator_name":"The SimpleStories Project","creator_url":"https://huggingface.co/SimpleStories","description":"\n\t\n\t\t\n\t\t📘📕 SimpleStories 📙📗\n\t\n\nこのデータセットは、gpt-4o-miniによって生成された短編小説で出来ているデータセットです。生成方法や、自分で物語を生成する方法については、こちらのリポジトリをご覧ください。\n他の言語や物語形式の制作を希望される場合は、メールにてお問い合わせください。\nSimpleStoriesは、EldenとLiによるTinyStoriesの改良版です。\n\n\t\n\t\t\n\t\t特徴\n\t\n\n\n物語の注釈情報（theme、topic、styleなど）\n多様性の高さ\n2024年のモデルによって生成\nNLPのデータが用意しているためフィルタリングしやすい\n以下の言語版が利用可能：\n英語\n日本語\n他にも追加予定\n\n\n\n\nThis dataset is a collection of short stories generated by gpt-4o-mini (+ other models, soon). To see how this dataset was generated, or to generate some stories… See the full description on the dataset page: https://huggingface.co/datasets/SimpleStories/SimpleStories-JA.","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Rule-based","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Rule-based is a dataset of BenchMAX, sourcing from IFEval, which is a rule-based benchmark for evaluating the instruction following capabilities in multilingual scenarios.\nWe extend the original dataset to 16 non-English languages by first… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Model-based","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Model-based is a dataset of BenchMAX, sourcing from m-ArenaHard, which evaluates the instruction following capability via model-based judgment.\nWe extend the original dataset to include languages that are not supported by m-ArenaHard through… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Function_Completion","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from humanevalplus, which evaluates the code generation capability in multilingual scenarios.\nWe extend the original English dataset to 16 non-English languages.\nThe data is first translated… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Problem_Solving","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Problem_Solving is a dataset of BenchMAX, sourcing from LiveCodeBench_v4, which evaluates the code generation capability for solving multilingual competitive code problems.\nWe extend the original English dataset by 16 non-English languages.\nThe… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Multiple_Functions","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Multiple_Functions is a dataset of BenchMAX, sourcing from Nexus.\nThis dataset evaluates the tool use capability in multilingual senarios, which requires a model to call the correct function given the user query and multiple functions.\nWe… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_General_Translation","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_General_Translation is a dataset of BenchMAX, which evaluates the translation capability on the general domain.\nWe collect parallel test data from Flore-200, TED-talk, and WMT24.\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\ngit clone… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation.","first_N":5,"first_N_keywords":["translation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Domain_Translation","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Domain_Translation is a dataset of BenchMAX, which evaluates the translation capability on specific domains.\nWe collect the domain multi-way parallel data from other tasks in BenchMAX, such as math data, code data, etc.\nEach sample contains one… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation.","first_N":5,"first_N_keywords":["translation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"Retrieval-SFT-Chat","keyword":"japanese","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/CausalLM/Retrieval-SFT-Chat","creator_name":"CausalLM","creator_url":"https://huggingface.co/CausalLM","description":"\n\t\n\t\t\n\t\tRetrieval-Based Multi-Turn Chat SFT Synthetic Data\n\t\n\nA year ago, we released CausalLM/Refined-Anime-Text, a thematic subset of a dataset generated using the then state-of-the-art LLMs. This dataset comprises 1 million entries synthesized through long-context models that rewrote multi-document web text inputs, intended for continued pre-training. We are pleased to note that this data has been employed in various training scenarios and in studies concerning data and internet culture.\nIn… See the full description on the dataset page: https://huggingface.co/datasets/CausalLM/Retrieval-SFT-Chat.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Chinese","Japanese"],"keywords_longer_than_N":true},
	{"name":"RolePlay-v1","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/RolePlay-v1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"https://chatgpt.com\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"Włodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy It’s Important\n\t\n\n\nEnhances Trust: For readers and… See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"magpie-reasoning-preference-japanese","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kendamarron/magpie-reasoning-preference-japanese","creator_name":"Kendamarron","creator_url":"https://huggingface.co/Kendamarron","description":"Kendamarron/magpie-reasoning-preference-japanese dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Japanese","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"JIC-VQA","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/line-corporation/JIC-VQA","creator_name":"LINE","creator_url":"https://huggingface.co/line-corporation","description":"\n\t\n\t\t\n\t\tJIC-VQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nJapanese Image Classification Visual Question Answering (JIC-VQA) is a benchmark for evaluating Japanese Vision-Language Models (VLMs). We built this benchmark based on the recruit-jp/japanese-image-classification-evaluation-dataset by adding questions to each sample. All questions are multiple-choice, each with four options. We select options that closely relate to their respective labels in order to increase the task's difficulty.\nThe images… See the full description on the dataset page: https://huggingface.co/datasets/line-corporation/JIC-VQA.","first_N":5,"first_N_keywords":["visual-question-answering","Japanese","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"thinking-multilingual-30-23-small-690","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \nOr use the \"big\" version: big 10k rows version\n","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Thinking-multilingual-big-10k-sft","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\nenjoy 👍\n","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Lux-Japanese-Speech-Corpus","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lami/Lux-Japanese-Speech-Corpus","creator_name":"KohnoseLami","creator_url":"https://huggingface.co/Lami","description":"\n\t\n\t\t\n\t\tLux Japanese Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\t概要\n\t\n\nLux Japanese Speech Corpus は、オリジナルキャラクター「Lux (ルクス)」による日本語のテキスト読み上げ音声を収録したデータセットです。このデータセットは、以下の2種類の音声ファイルで構成されています。\n\nraw: 加工前の 96kHz/16bit の WAV ファイル\ncleaned: ノイズ除去などの処理を施した 96kHz/16bit の WAV ファイル\n\n各音声ファイルに対応するトランスクリプション（読み上げた文章）は、metadata.csv に記録しています。データセット全体のメタ情報は dataset_infos.json で管理されています。\n\n\t\n\t\t\n\t\tディレクトリ構造\n\t\n\n以下は、このリポジトリの推奨ディレクトリ構造の例です。\nLux-Japanese-Speech-Corpus/\n├── .gitattributes           # Gitのカスタマイズファイル\n├── README.md… See the full description on the dataset page: https://huggingface.co/datasets/Lami/Lux-Japanese-Speech-Corpus.","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Japanese","cc-by-4.0","1B<n<10B"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"jobs_dataset","keyword":"japanese","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/vmal/jobs_dataset","creator_name":"Vimal Chaudhari","creator_url":"https://huggingface.co/vmal","description":"vmal/jobs_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","Thai","Japanese","unlicense","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Nayose-Bench-Instruction","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EQUES/Nayose-Bench-Instruction","creator_name":"EQUES Inc.","creator_url":"https://huggingface.co/EQUES","description":"\n\t\n\t\t\n\t\tDataset Card for Nayose-Bench-Instruction\n\t\n\nThis dataset was created as a benchmark for the entity resolution task in the pharmaceutical domain.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset is designed for the entity resolution task in the pharmaceutical domain.\nThe entity resolution task refers to a paraphrasing task, such as rephrasing drug names, converting chemical substances into brand names, or rewriting chemical substances into chemical formulas.\n\n\t\n\t\t\n\t\tUses\n\t\n\nfrom datasets import… See the full description on the dataset page: https://huggingface.co/datasets/EQUES/Nayose-Bench-Instruction.","first_N":5,"first_N_keywords":["question-answering","Japanese","cc-by-sa-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"vtuber-youtube-list-dataset","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ayousanz/vtuber-youtube-list-dataset","creator_name":"yousan","creator_url":"https://huggingface.co/ayousanz","description":"\n\t\n\t\t\n\t\tVTuber YouTube Channel List Dataset\n\t\n\nこのデータセットは、VTuber チャンネルと VTuber でない（例：料理チャンネルなど）の YouTube チャンネルのメタデータを JSONL 形式でまとめたものです。各レコードは以下のフィールドを含んでいます：\n\nchannel_id: YouTube チャンネルの固有 ID\ntitle: チャンネルのタイトル\ndescription: チャンネルの説明文\ntext: タイトルと説明文を連結したテキスト（モデルの入力用に利用できます）\nlabel: バイナリラベル（VTuber の場合は 1、非VTuber の場合は 0）\n\n\n\t\n\t\t\n\t\n\t\n\t\tデータセットの概要\n\t\n\n\n目的: このデータセットは、テキスト分類タスクにおいて VTuber チャンネルかどうかを判定するモデルの学習および評価に利用できます。\n言語: 主に日本語ですが、一部英語やその他の言語の記述も含まれる可能性があります。\nライセンス: MIT License\n\n\n\t\n\t\n\t\n\t\t使用上の注意点… See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/vtuber-youtube-list-dataset.","first_N":5,"first_N_keywords":["text-classification","no-annotation","multilingual","original","Japanese"],"keywords_longer_than_N":true},
	{"name":"danbooru2024-captions-1ktar","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/6DammK9/danbooru2024-captions-1ktar","creator_name":"Darren Laurie","creator_url":"https://huggingface.co/6DammK9","description":"\n\t\n\t\t\n\t\tDanbooru 2024 captions only in 1k tar\n\t\n\n\nRaw captions jointed by 7.62M unpublished extended dataset from KBlueLeaf/danbooru2023-metadata-database and 0.48M generated dataset via Minthy/ToriiGate-v0.4-7B in exl2-8bpw mode. There are 8.13M in total.\n\npython convert_meta_to_tar.py\nReading source JSON\nKeys count: 8136011\nmax id: 8360499\n100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000… See the full description on the dataset page: https://huggingface.co/datasets/6DammK9/danbooru2024-captions-1ktar.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","text-to-image","no-annotation","danbooru"],"keywords_longer_than_N":true},
	{"name":"ea-mt-benchmark","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark","creator_name":"Sapienza NLP, Sapienza University of Rome","creator_url":"https://huggingface.co/sapienzanlp","description":"\n\t\n\t\t\n\t\tDataset Card for EA-MT\n\t\n\nEA-MT (Entity-Aware Machine Translation) is a multilingual benchmark for evaluating the capabilities of Large Language Models (LLMs) and Machine Translation (MT) models in translating simple sentences with potentially challenging entity mentions, e.g., entities for which a word-for-word translation may not be accurate.\nHere is an example of a simple sentence with a challenging entity mention:\n\nEnglish: \"What is the plot of The Catcher in the Rye?\"\nItalian:… See the full description on the dataset page: https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark.","first_N":5,"first_N_keywords":["text-generation","English","Arabic","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"VoyageMMarcoReranking","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/VoyageMMarcoReranking","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  VoyageMMarcoReranking\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\na hard-negative augmented version of the Japanese MMARCO dataset as used in Voyage AI Evaluation Suite\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Non-fiction, Written\n\nReference\nhttps://arxiv.org/abs/2312.16144\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"VoyageMMarcoReranking\"])\nevaluator =… See the full description on the dataset page: https://huggingface.co/datasets/mteb/VoyageMMarcoReranking.","first_N":5,"first_N_keywords":["text-ranking","derived","monolingual","Japanese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ESCIReranking","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/ESCIReranking","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  ESCIReranking\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/amazon-science/esci-data/\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"ESCIReranking\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn more about how to run models on mteb task check out… See the full description on the dataset page: https://huggingface.co/datasets/mteb/ESCIReranking.","first_N":5,"first_N_keywords":["text-ranking","derived","multilingual","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"gsm8k-translated","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sara237/gsm8k-translated","creator_name":"Sara Rajaee","creator_url":"https://huggingface.co/Sara237","description":"Sara237/gsm8k-translated dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","English","German","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"AyaVisionBench","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/AyaVisionBench","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for Aya Vision Benchmark\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited for… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/AyaVisionBench.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"m-WildVision","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/m-WildVision","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for m-WildVision\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \nThe authors demonstrated that these prompts enable automatic LLM judge… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-WildVision.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"emilia-yodas","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TTS-AGI/emilia-yodas","creator_name":"TTS AGI","creator_url":"https://huggingface.co/TTS-AGI","description":"A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.\nhttps://huggingface.co/datasets/amphion/Emilia-Dataset\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","German","French"],"keywords_longer_than_N":true},
	{"name":"OpenHumanreasoning-multilingual-2.2k","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\nnote: translations are not human generated.\n","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL files… See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"cat_conversations_jp","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yokomachi/cat_conversations_jp","creator_name":"Naoki Yokomachi","creator_url":"https://huggingface.co/yokomachi","description":"yokomachi/cat_conversations_jp dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Japanese","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"CoT-XLang","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Egor-AI/CoT-XLang","creator_name":"Egor AI","creator_url":"https://huggingface.co/Egor-AI","description":"RU:CoT-XLang — это многоязычный датасет, состоящий из текстовых примеров с пошаговыми рассуждениями (Chain-of-Thought, CoT) на различных языках, включая английский, русский, японский и другие. Он используется для обучения и тестирования моделей в задачах, требующих пояснений решений через несколько шагов. Датасет включает около 2,419,912 примеров, что позволяет эффективно обучать модели, способные генерировать пошаговые рассуждения.\nРекомендация:Используйте датасет для обучения моделей… See the full description on the dataset page: https://huggingface.co/datasets/Egor-AI/CoT-XLang.","first_N":5,"first_N_keywords":["text-generation","question-answering","Russian","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"Japanese-patent-evaluation-dataset-01","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Chasottco/Japanese-patent-evaluation-dataset-01","creator_name":"Yasuhito Yanagisawa","creator_url":"https://huggingface.co/Chasottco","description":"\n\t\n\t\t\n\t\t試験的なデータセットとなります\n\t\n\n\n\t\n\t\t\n\t\t評価用データセットの作成方法\n\t\n\n\nChatGPT-4oで弁理士紹介を含む5つの観点から50のクエリを生成\nChatGPT-4oでクエリに対する回答と評価ポイントを生成※弁理士を直接紹介する10問は除く\n除外した10問に関しては、開放特許情報データベース及びj-platpatの公開データより回答を手動作成\n\n","first_N":5,"first_N_keywords":["Japanese","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"MiSide-Japanese","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AkitoP/MiSide-Japanese","creator_name":"L","creator_url":"https://huggingface.co/AkitoP","description":"AkitoP/MiSide-Japanese dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Japanese","apache-2.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"e621_2024-latents-sdxl-1ktar","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/6DammK9/e621_2024-latents-sdxl-1ktar","creator_name":"Darren Laurie","creator_url":"https://huggingface.co/6DammK9","description":"\n\t\n\t\t\n\t\tE621 2024 SDXL VAE latents in 1k tar\n\t\n\n\nDedicated dataset to align both NebulaeWis/e621-2024-webp-4Mpixel and deepghs/e621_newest-webp-4Mpixel. \"4MP-Focus\" for average raw image resolution. \nLatents are ARB with maximum size of 1024x1024 as the recommended setting in kohyas. Major reason is to make sure I can finetune with RTX 3090. VRAM usage will raise drastically after 1024.\nGenerated from prepare_buckets_latents_v2.py, modified from prepare_buckets_latents.py.\nUsed for… See the full description on the dataset page: https://huggingface.co/datasets/6DammK9/e621_2024-latents-sdxl-1ktar.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","text-to-image","no-annotation","danbooru"],"keywords_longer_than_N":true},
	{"name":"oita-ken-strawberries","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fa0311/oita-ken-strawberries","creator_name":"ふぁ","creator_url":"https://huggingface.co/fa0311","description":"\n\t\n\t\t\n\t\toita-ken-strawberries\n\t\n\nThis dataset contains 5,000 images of ベリーツ (Beriitsu), a premium strawberry variety grown in Oita Prefecture, Japan.  \n\nImages in dataset/input/* are organized by harvest year and grading category.  \nThe dataset/input/**/include directory contains cleaned strawberry images.  \nData cleansing was performed using background_erase.\n\n\n\t\n\t\t\n\t\n\t\n\t\tConversion to Pascal VOC\n\t\n\n\ndataset/input/input.json and dataset/input/** can be processed with image_data_augmentation… See the full description on the dataset page: https://huggingface.co/datasets/fa0311/oita-ken-strawberries.","first_N":5,"first_N_keywords":["image-classification","Japanese","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"JDocQA_SingleImage_200","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/umiyuki/JDocQA_SingleImage_200","creator_name":"umiyuki","creator_url":"https://huggingface.co/umiyuki","description":"\n\t\n\t\t\n\t\tJDocQA_SingleImage_200 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nJDocQA_SingleImage_200は、shunk031/JDocQAのtestサブセットを基に作成されたデータセットで、PDFファイルを200dpiの画像に変換し、画像が取得できない設問と複数画像が必要な設問を除外しています。さらに計測時間短縮のために各設問形式毎に50問、計200問に絞りました。元のデータセットが37GBと大きすぎるため、サイズを削減しつつ実用性を保つことを目的としています。\n\n元データ: shunk031/JDocQA (test split, 1,176 instances)\n変換後: PDFを画像に置き換え、画像が取得できてかつ単一画像入力の設問のみを含む。さらに各設問形式毎に先頭から50問ずつに絞る。\n言語: 日本語 (BCP-47 ja-JP)\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ninput_text: 質問テキスト\nquestion_id: ユニークなID\nanswer: 回答… See the full description on the dataset page: https://huggingface.co/datasets/umiyuki/JDocQA_SingleImage_200.","first_N":5,"first_N_keywords":["shunk031/JDocQA","Japanese","cc-by-sa-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"hatoma_for_DL","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nakagawanatuko/hatoma_for_DL","creator_name":"Natsuko Nakagawa","creator_url":"https://huggingface.co/nakagawanatuko","description":"nakagawanatuko/hatoma_for_DL dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","Japanese","cc-by-4.0","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"OGC_Military","keyword":"japanese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/racineai/OGC_Military","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","description":"\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\n\t\n\t\t\n\t\tMilitary Vision DSE\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nMade with https://github.com/RacineAIOS/OGC_pdf-to-parquet\nThis dataset was created by scraping PDF documents from online sources and generating relevant synthetic queries.\nWe used Google's Gemini 2.0 Flash Lite model in our custom pipeline to produce the queries, allowing us to create a diverse set of questions based on the document content.… See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Military.","first_N":5,"first_N_keywords":["English","French","Arabic","German","Russian"],"keywords_longer_than_N":true},
	{"name":"e621_2024-captions-1ktar","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/6DammK9/e621_2024-captions-1ktar","creator_name":"Darren Laurie","creator_url":"https://huggingface.co/6DammK9","description":"\n\t\n\t\t\n\t\tE621 2024 captions only in 1k tar\n\t\n\n\nRaw captions jointed from lodestones/e621-captions\n\nIt doesn't align to any dataset yet.\n\nmeta_cap.json has been provided in compressed format if you want to train with kohyas triner. Currently I'm trying to merge this with my 2024 version.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tCore logic\n\t\n\n\nThe script building this 1ktar\n\nThere is not much choice, I don't have GPU to run for 1M captions with VLM so I just \"take it or leave it\".\n\n\nrearranged_tags = [row.regular_summary… See the full description on the dataset page: https://huggingface.co/datasets/6DammK9/e621_2024-captions-1ktar.","first_N":5,"first_N_keywords":["image-classification","zero-shot-image-classification","text-to-image","no-annotation","e621"],"keywords_longer_than_N":true},
	{"name":"JA_Emilia_Yodas_266h","keyword":"japanese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MrDragonFox/JA_Emilia_Yodas_266h","creator_name":"MrDragonFox","creator_url":"https://huggingface.co/MrDragonFox","description":"the dataset is 266h out of the japanese part from https://huggingface.co/datasets/amphion/Emilia-Dataset ( Emilia Yodas - cc by 4.0)\naudio event classified via scribe v1 (elevenlabs stt/asr)\nfacebook audio aestetics to be used as prefilter\nthe dataset is very much at a v1 -\nif you want to help - lets talk\nhttps://discord.gg/RUs3uzBdW3 (nsfw is fully opt in only - as sfw)\nif you want full transaction timestamps as they come from scribe v1 - they are cc by 4.0 NC and can be found here… See the full description on the dataset page: https://huggingface.co/datasets/MrDragonFox/JA_Emilia_Yodas_266h.","first_N":5,"first_N_keywords":["Japanese","cc-by-4.0","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"vqa-v1.1","keyword":"japanese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldcuisines/vqa-v1.1","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\n\t\n\t\t\n\t\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\n\t\n\n\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 October 2024.… See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa-v1.1.","first_N":5,"first_N_keywords":["multilingual","English","Indonesian","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"Synthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tSynthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k\n\t\n\n\n\t\n\t\t\n\t\t概要\n\t\n\ndeepseek-ai/DeepSeek-V3-0324を用いて作成した、約20000件の日本語ロールプレイの対話を収録した合成データセットです。各データは10ターンから20ターン程度あります。\nこのデータセットはNSFW表現を含みます。\n\n\t\n\t\t\n\t\tデータの詳細\n\t\n\n各データは以下のキーを含んでいます。\n\nmajor_genre: ジャンル（大分類）\nminor_genre: ジャンル（小分類）\ntag: 年齢制限用タグ（R-18）\nworld_setting: 舞台・世界観の設定\nscene_setting: 対話シーンの設定\nuser_setting: ユーザー側のキャラクターの設定\nassistant_setting: アシスタント側のキャラクターの設定\ndialogue_tone: 対話のトーン\nconversations: 上記設定に基づいたユーザーとアシスタントの対話（OpenAI messages形式）… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k.","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"lunaris-prompts","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/moonsynthdata/lunaris-prompts","creator_name":"Moon Synth Data: High Quality Synthetic Datasets for AI.","creator_url":"https://huggingface.co/moonsynthdata","description":"\n\t\n\t\t\n\t\tLunaris-Prompts Dataset\n\t\n\n\n\t\n\t\t\n\t\t🚀 Overview\n\t\n\nLunaris-Prompts is a diverse and growing multilingual dataset containing approximately 7,000 prompts designed for various AI and Natural Language Processing tasks. Curated and maintained by moonsynthdata, this dataset spans a wide array of themes and languages.\nKey Features:\n\nMultilingual: Includes prompts in numerous languages, with significant portions in English, Korean, Portuguese, Chinese, Japanese, French, Spanish, Arabic, German… See the full description on the dataset page: https://huggingface.co/datasets/moonsynthdata/lunaris-prompts.","first_N":5,"first_N_keywords":["English","Korean","Portuguese","Chinese","Japanese"],"keywords_longer_than_N":true},
	{"name":"panlex-definitions","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-definitions","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-definitions\n\t\n\nThis is a dataset of word definitions in several hudnred languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20250201 database dump) and rearranged on the per-language basis (by the language of the definition).\nEach language subset consists of definitions (short phrases).\nEach definition is associated with some meanings (if there is… See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-definitions.","first_N":5,"first_N_keywords":["translation","Abkhazian","Hijazi Arabic","Afrikaans","Ainu (Japan)"],"keywords_longer_than_N":true},
	{"name":"GPT-5-model-switch","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ChiekoSeren/GPT-5-model-switch","creator_name":"Chieko Seren","creator_url":"https://huggingface.co/ChiekoSeren","description":"\n\t\n\t\t\n\t\tGPT-5-Model-Switch Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe GPT-5-Model-Switch dataset is designed to train an open-source model selector, serving as an alternative to OpenAI's GPT-5. As Sam Altman stated, \"GPT-5 will be a model selector,\" and this dataset supports the development of an intelligent system capable of dynamically selecting the optimal model based on task requirements.\n\n\t\n\t\t\n\t\tDataset Purpose\n\t\n\nThe goal of this dataset is to train a model selector that can:\n\nAnalyze the… See the full description on the dataset page: https://huggingface.co/datasets/ChiekoSeren/GPT-5-model-switch.","first_N":5,"first_N_keywords":["text-generation","Chinese","Japanese","English","French"],"keywords_longer_than_N":true},
	{"name":"Speech-Translation-Instructions","keyword":"japanese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mesolitica/Speech-Translation-Instructions","creator_name":"Mesolitica","creator_url":"https://huggingface.co/mesolitica","description":"\n\t\n\t\t\n\t\tSpeech-Translation-Instructions\n\t\n\nThe instructions translated from 120 languages Common Voice to english, arabic, japanese, mandarin and french from common voice speech dataset. Suitable to use to finetune Speech LLM.\n","first_N":5,"first_N_keywords":["text2text-generation","multilingual","Malay","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tSynthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k\n\t\n\n\n\t\n\t\t\n\t\t概要\n\t\n\ndeepseek-ai/DeepSeek-V3-0324を用いて作成した、約20000件の日本語ロールプレイの対話を収録した合成データセットです。各データは10ターンから20ターン程度あります。\n\n\t\n\t\t\n\t\tデータの詳細\n\t\n\n各データは以下のキーを含んでいます。\n\nmajor_genre: ジャンル（大分類）\nminor_genre: ジャンル（小分類）\ntag: 年齢制限用タグ（全年齢、R-15）\nworld_setting: 舞台・世界観の設定\nscene_setting: 対話シーンの設定\nuser_setting: ユーザー側のキャラクターの設定\nassistant_setting: アシスタント側のキャラクターの設定\ndialogue_tone: 対話のトーン\nconversations: 上記設定に基づいたユーザーとアシスタントの対話（OpenAI messages形式）\n\n設定等の情報からsystem… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k.","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k-formatted","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k-formatted","creator_name":"Aratako","creator_url":"https://huggingface.co/Aratako","description":"\n\t\n\t\t\n\t\tSynthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k-formatted\n\t\n\n\n\t\n\t\t\n\t\t概要\n\t\n\ndeepseek-ai/DeepSeek-V3-0324を用いて作成した日本語ロールプレイデータセットであるAratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20kにsystem messageを追加して整形したデータセットです。\nデータの詳細については元データセットのREADMEを参照してください。\n\n\t\n\t\t\n\t\tライセンス\n\t\n\nMITライセンスの元配布します。\n","first_N":5,"first_N_keywords":["text-generation","Japanese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"TinyDS-20k","keyword":"japanese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","description":"\n\t\n\t\t\n\t\tTinyDS\n\t\n\nTinyDS (short for Tiny DeepSeek) is a dataset generated synthetically using SyntheticAlpaca and Qwen3-8B.  \n  \n\n\nThis dataset is a simple Alpaca-format dataset using the viral TTC concept (structured reasoning, mainly).The LLM was prompted to generate questions and answers in 32 different languages, and the most spoken languages were picked. Since the Qwen org stated that this model supports over 100 languages, this is something reasonable to do without compromising on… See the full description on the dataset page: https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k.","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","text2text-generation","English"],"keywords_longer_than_N":true}
]
;
