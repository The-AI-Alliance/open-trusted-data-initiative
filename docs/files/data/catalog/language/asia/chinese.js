const data_for_language_asia_chinese = 
[
	{"name":"CoT_reformatted","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jtatman/CoT_reformatted","creator_name":"James","creator_url":"https://huggingface.co/jtatman","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"CoT_reformatted\\\"\\n\\t\\n\\nThis dataset is reformatted from: QingyiSi/Alpaca-CoT\\nAll credit goes there. Thanks to QingyiSi for the work in consolidating many diverse sources for comparison and cross-file analysis.\\nThere were some issues loading files from that dataset for a testing project. \\nI extracted the following data files for this subset:\\n\\nalpaca_data_cleaned\\nCoT_data\\nfirefly       \\ninstruct\\nalpaca_gpt4_data\\ndolly \\nGPTeacher\\nthoughtsource\\nfinance_en\\ninstinwild_en\\n\\n","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ALMA-R-Preference","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haoranxu/ALMA-R-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"ALMA-R-Preference\\\"\\n\\t\\n\\nThis is triplet preference data used by ALMA-R model.\\nThe triplet preference data, supporting 10 translation directions, is built upon the FLORES-200 development and test data. For each direction, we provide a source sentence along with three translations: one from GPT-4, another from ALMA-13B-LoRA, and a reference translation. For instance, in the English-German pair, our data structure is as follows:\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentences:\\n\\t\\n\\n\\nde: Originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/ALMA-R-Preference.","first_N":5,"first_N_keywords":["translation","Russian","Czech","Chinese","Icelandic"],"keywords_longer_than_N":true},
	{"name":"Kanami_Dataset","keyword":"chinese","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Holmuium97/Kanami_Dataset","creator_name":"Holmuium97","creator_url":"https://huggingface.co/Holmuium97","description":"é¦™å¥ˆç¾è®­ç»ƒè¯­éŸ³æ•°æ®é›†ï¼ˆä»…å…¬æµ‹å‰çš„è¯­éŸ³ï¼‰\\nP.S\\n  1ã€æ•°æ®é›†è¯­éŸ³ä»…é€šè¿‡æ¸¸æˆå†…è·å–ï¼Œä¸€åˆ‡ç‰ˆæƒå½’æ·±åœ³å¸‚åˆ›æ¢¦å¤©åœ°ç§‘æŠ€æœ‰é™å…¬å¸æ‰€æœ‰\\n  2ã€éŸ³é¢‘ä»…è¿›è¡Œç®€å•çš„è‡ªåŠ¨åˆ‡ç‰‡ï¼Œå¯èƒ½å­˜åœ¨æ–­å¥ä¸åˆç†çš„æƒ…å†µï¼Œå»ºè®®è¯•å¬åšä¸‹ç­›é€‰\\n  3ã€ç¦æ­¢ä½¿ç”¨è¯¥æ•°æ®é›†è¿›è¡Œä¸€åˆ‡ä»¥è¿æ³•ä¸ºç›®çš„çš„æ´»åŠ¨\\n","first_N":5,"first_N_keywords":["Chinese","agpl-3.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"mittens","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/mittens","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMiTTenS: A Dataset for Evaluating Misgendering in Translation\\n\\t\\n\\nMisgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scriptsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/mittens.","first_N":5,"first_N_keywords":["translation","Arabic","Finnish","Oromo","Ganda"],"keywords_longer_than_N":true},
	{"name":"TCM_Humanities","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TCMLM/TCM_Humanities","creator_name":" ","creator_url":"https://huggingface.co/TCMLM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [TCMLM/TCM_Humanities]\\n\\t\\n\\n\\n\\nThis dataset, curated by the Traditional Chinese Medicine Language Model Team, comprises a comprehensive collection of multiple-choice questions (both single and multiple answers) from the Chinese Medical Practitioner Examination. It's designed to aid in understanding and assessing knowledge in Chinese humanities medicine, medical ethics, and legal regulations for physicians.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TCMLM/TCM_Humanities.","first_N":5,"first_N_keywords":["text-classification","Chinese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"achinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"mandarin chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"literary chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"wu chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"yue chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"zhuang","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"Haruhi-Dialogue-Speaker-Extract","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/Haruhi-Dialogue-Speaker-Extract","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChatå‡‰å®«æ˜¥æ—¥çš„å¯¹è¯æŠ½å–æ¨¡å‹\\n\\t\\n\\næˆ‘ä»¬å¸Œæœ›æœ‰ä¸€ä¸ªæ¨¡å‹èƒ½å¤Ÿä»å°è¯´çš„chunkä¸­æ‰¹é‡å»æå–æ‘˜è¦å’Œå¯¹è¯\\nè¿™ä¸ªæ¨¡å‹å°±æ˜¯å®ç°äº†è¿™ä¸€ç‚¹ã€‚æ¨¡å‹ä½¿ç”¨äº†å¤§çº¦30kçš„ä¸­æ–‡å°è¯´æ•°æ®å’Œ20kçš„è‹±æ–‡å°è¯´æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œåœ¨qwen-1.8ä¸Šè¿›è¡Œäº†3ä¸ªepochçš„finetuneã€‚ åŸåˆ™ä¸Šæ¨¡å‹åŒæ—¶æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡å°è¯´çš„è®­ç»ƒ\\nä¸»é¡¹ç›®é“¾æ¥ https://github.com/LC1332/Chat-Haruhi-Suzumiya\\n\\næé²é²å®Œæˆäº†æ•°æ®çš„æ”¶é›†ï¼Œä»¥åŠè¿›ä¸€æ­¥å°†inferenceç¨‹åºæ‰©å±•åˆ°è¿ç»­çš„chunks\\nåˆ˜å´‡å¯’å®Œæˆäº†æ¨¡å‹çš„è®­ç»ƒ\\nç±³å”¯å®æµ‹è¯•å¹¶ä¸Šä¼ æ¨¡å‹åˆ°hugging face\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Haruhi Suzumiya's Dialogue Extraction Model\\n\\t\\n\\nWe hope to have a model that can extract summaries and dialogues in batches from chunks of novels.\\nThis model achieves just that. It wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/silk-road/Haruhi-Dialogue-Speaker-Extract.","first_N":5,"first_N_keywords":["Chinese","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"spam-douban-movie-review","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tracywong117/spam-douban-movie-review","creator_name":"Wong Wing Yan","creator_url":"https://huggingface.co/tracywong117","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe Spam Douban Movie Reviews Dataset is a collection of movie reviews scraped from Douban, a popular Chinese social networking platform for movie enthusiasts. This dataset consists of reviews that have been manually classified as either spam or genuine by human reviewers. It contains a total of 1,600 data. \\nThis dataset is created for our project Spam Movie Reviews Detection through Supervised Learning.\\n","first_N":5,"first_N_keywords":["text-classification","Chinese","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"retrieval_data_llm","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/infgrad/retrieval_data_llm","creator_name":"infgrad","creator_url":"https://huggingface.co/infgrad","description":"å¸¦æœ‰éš¾è´Ÿä¾‹çš„æ£€ç´¢è®­ç»ƒæ•°æ®ã€‚çº¦20ä¸‡ã€‚\\næ–‡ä»¶æ ¼å¼ï¼šjsonlã€‚å•è¡Œç¤ºä¾‹ï¼š\\n{\\\"Query\\\": \\\"å¤§ç†ŠçŒ«çš„é¥®é£Ÿä¹ æ€§\\\", \\\"Positive Document\\\": \\\"å¤§ç†ŠçŒ«ä¸»è¦ä»¥ç«¹å­ä¸ºé£Ÿï¼Œä½†ä¹Ÿä¼šåƒæ°´æœå’Œå°å‹åŠ¨ç‰©ã€‚å®ƒä»¬æ‹¥æœ‰å¼ºå£®çš„é¢Œéƒ¨å’Œç‰™é½¿ï¼Œèƒ½å¤Ÿå’¬ç¢ç«¹å­åšç¡¬çš„å¤–å£³ã€‚\\\", \\\"Hard Negative Document\\\": \\\"è€è™æ˜¯è‚‰é£Ÿæ€§åŠ¨ç‰©ï¼Œä¸»è¦æ•é£Ÿé¹¿ã€é‡çŒªç­‰å¤§å‹åŠ¨ç‰©ã€‚å®ƒä»¬çš„ç‰™é½¿å’Œçˆªå­éå¸¸é”‹åˆ©ï¼Œæ˜¯æ•çŒçš„åˆ©å™¨ã€‚\\\"}\\n\\n","first_N":5,"first_N_keywords":["Chinese","mit","100K - 1M","Text","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"yue_xstory_cloze","keyword":"yue chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hon9kon9ize/yue_xstory_cloze","creator_name":"hon9kon9ize","creator_url":"https://huggingface.co/hon9kon9ize","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Cantonese XStoryCloze\\n\\t\\n\\nThis dataset is a Cantonese translation of the Simplified Chinese subset of juletxara/xstory_cloze. For more detailed information about the original dataset, please refer to the provided link.\\nThis dataset is translated by indiejoseph/bart-translation-zh-yue and has not undergone any manual verification. The content may be inaccurate or misleading. please keep this in mind when using this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample\\n\\t\\n\\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hon9kon9ize/yue_xstory_cloze.","first_N":5,"first_N_keywords":["Yue Chinese","cc-by-sa-4.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = [\\n        {\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": columns[\\\"inputs\\\"].strip(),\\n        },\\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"cifar10","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ahsxxia/cifar10","creator_name":"han","creator_url":"https://huggingface.co/ahsxxia","description":"ahsxxia/cifar10 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"UHGEvalDataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ki-Seki/UHGEvalDataset","creator_name":"Shichao Song","creator_url":"https://huggingface.co/Ki-Seki","description":"The dataset sourced from https://github.com/IAAR-Shanghai/UHGEval\\n","first_N":5,"first_N_keywords":["multiple-choice","text-generation","question-answering","multiple-choice-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"Traditional_Chinese-aya_dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_dataset","creator_name":"Heng-Shiou Sheu | è¨±æ†ä¿®","creator_url":"https://huggingface.co/Heng666","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè³‡æ–™é›†æè¿°\\n\\t\\n\\nç¹é«”ä¸­æ–‡ Aya (Traditional Chinese Aya Chinese;TCA)ï¼šå°ˆæ³¨æ–¼ç¹é«”ä¸­æ–‡è™•ç†çš„ Aya é›†åˆçš„ç²¾é¸å­é›†\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ¦‚è¿°\\n\\t\\n\\nç¹é«”ä¸­æ–‡ Aya æ˜¯ä¸€å€‹ç²¾å¿ƒç­–åŠƒçš„è³‡æ–™é›†ï¼Œæºè‡ª CohereForAI çš„ç¶œåˆ Aya é›†åˆï¼Œç‰¹åˆ¥é—œæ³¨ç¹é«”ä¸­æ–‡æ–‡æœ¬è³‡æ–™ã€‚\\næ­¤è³‡æ–™é›†çµåˆäº†ä¾†è‡ª CohereForAI/aya_datasetï¼Œéæ¿¾æ‰é™¤ç¹é«”ä¸­æ–‡ã€ç°¡é«”ä¸­æ–‡å…§å®¹ä¹‹å¤–çš„æ‰€æœ‰å…§å®¹ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç›®æ¨™\\n\\t\\n\\nç¹é«”ä¸­æ–‡ Aya çš„ç›®æ¨™æ˜¯ç‚ºç ”ç©¶äººå“¡ã€æŠ€è¡“å°ˆå®¶å’Œèªè¨€å­¸å®¶æä¾›å³ç”¨å‹ç¹é«”ä¸­æ–‡æ–‡æœ¬è³‡æºï¼Œé¡¯è‘—æ¸›å°‘å°ˆæ³¨æ–¼ç¹é«”ä¸­æ–‡çš„ NLP å’Œ AI å°ˆæ¡ˆä¸­æ•¸æ“šé è™•ç†æ‰€éœ€çš„æ™‚é–“å’Œç²¾åŠ›ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè³‡æ–™é›†ä¾†æºèˆ‡è³‡è¨Š\\n\\t\\n\\n\\nè³‡æ–™ä¾†æº: å¾ CohereForAI/aya_dataset 2 å€‹å­é›†è€Œä¾†ã€‚\\nèªè¨€: ç¹é«”ä¸­æ–‡ã€ç°¡é«”ä¸­æ–‡ï¼ˆ'zho')\\næ‡‰ç”¨: éå¸¸é©åˆèªè¨€å»ºæ¨¡ã€æ–‡æœ¬åˆ†é¡ã€æƒ…æ„Ÿåˆ†æã€å’Œæ©Ÿå™¨ç¿»è­¯ç­‰ä»»å‹™ã€‚\\nè«–æ–‡é€£çµ: 2402.06619\\nç¶­è­·äºº: Heng666\\nLicense:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_dataset.","first_N":5,"first_N_keywords":["question-answering","translation","summarization","zero-shot-classification","Chinese"],"keywords_longer_than_N":true},
	{"name":"Traditional_Chinese-aya_evaluation_suite","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_evaluation_suite","creator_name":"Heng-Shiou Sheu | è¨±æ†ä¿®","creator_url":"https://huggingface.co/Heng666","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè³‡æ–™é›†æè¿°\\n\\t\\n\\nç¹é«”ä¸­æ–‡ Aya (Traditional Chinese Aya Chinese;TCA)ï¼šå°ˆæ³¨æ–¼ç¹é«”ä¸­æ–‡è™•ç†çš„ Aya é›†åˆçš„ç²¾é¸å­é›†\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ¦‚è¿°\\n\\t\\n\\nç¹é«”ä¸­æ–‡ Aya æ˜¯ä¸€å€‹ç²¾å¿ƒç­–åŠƒçš„è³‡æ–™é›†ï¼Œæºè‡ª CohereForAI çš„ç¶œåˆ Aya é›†åˆï¼Œç‰¹åˆ¥é—œæ³¨ç¹é«”ä¸­æ–‡æ–‡æœ¬è³‡æ–™ã€‚\\næ­¤è³‡æ–™é›†çµåˆäº†ä¾†è‡ª CohereForAI/aya_evaluation_suiteï¼Œéæ¿¾æ‰é™¤ç¹é«”ä¸­æ–‡ã€ç°¡é«”ä¸­æ–‡å…§å®¹ä¹‹å¤–çš„æ‰€æœ‰å…§å®¹ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç›®æ¨™\\n\\t\\n\\nç¹é«”ä¸­æ–‡ Aya çš„ç›®æ¨™æ˜¯ç‚ºç ”ç©¶äººå“¡ã€æŠ€è¡“å°ˆå®¶å’Œèªè¨€å­¸å®¶æä¾›å³ç”¨å‹ç¹é«”ä¸­æ–‡æ–‡æœ¬è³‡æºï¼Œé¡¯è‘—æ¸›å°‘å°ˆæ³¨æ–¼ç¹é«”ä¸­æ–‡çš„ NLP å’Œ AI å°ˆæ¡ˆä¸­æ•¸æ“šé è™•ç†æ‰€éœ€çš„æ™‚é–“å’Œç²¾åŠ›ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè³‡æ–™é›†ä¾†æºèˆ‡è³‡è¨Š\\n\\t\\n\\n\\nè³‡æ–™ä¾†æº: å¾ CohereForAI/aya_evaluation_suite 3 å€‹å­é›†è€Œä¾†ã€‚\\nèªè¨€: ç¹é«”ä¸­æ–‡ã€ç°¡é«”ä¸­æ–‡ï¼ˆ'zho')\\næ‡‰ç”¨: éå¸¸é©åˆèªè¨€å»ºæ¨¡ã€æ–‡æœ¬åˆ†é¡ã€æƒ…æ„Ÿåˆ†æã€å’Œæ©Ÿå™¨ç¿»è­¯ç­‰ä»»å‹™ã€‚\\nè«–æ–‡é€£çµ: 2402.06619\\nç¶­è­·äºº: Heng666â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_evaluation_suite.","first_N":5,"first_N_keywords":["question-answering","translation","summarization","zero-shot-classification","Chinese"],"keywords_longer_than_N":true},
	{"name":"eagle","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MasahiroKaneko/eagle","creator_name":"Masahiro Kaneko","creator_url":"https://huggingface.co/MasahiroKaneko","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEagle ğŸ¦…: Ethical Dataset Given from Real Interactions\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repository contains the Eagle dataset, which is an ethical dataset of real interactions between humans and ChatGPT. This dataset is created to evaluate social bias, opinion bias, toxic language, and morality in Large Language Models (LLMs).\\nIf you use the Eagle dataset in your research, please cite the following:\\n@inproceedings{Eagle:arxiv:2024,\\n    title={Eagle: Ethical Dataset Given fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MasahiroKaneko/eagle.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","French","Korean"],"keywords_longer_than_N":true},
	{"name":"UltraLink","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/R0k1e/UltraLink","creator_name":"Haoyu Wang","creator_url":"https://huggingface.co/R0k1e","description":"\\n\\n\\nmulti-lingual, knowledge-grounded, multi-round dialogue dataset and model\\n\\n  Summary  â€¢\\n Construction Process â€¢\\n Paper â€¢\\n  UltraLink-LM â€¢\\n  Github\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for UltraLink\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nUltraLink is a multi-lingual, knowledge-grounded data augmented, multi-round dialogue dataset. It contains language-specific chat data, language-agnostic chat data, code data and math data in 5 languages: English, Chinese, Spanish, Russian, and French. Different fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/R0k1e/UltraLink.","first_N":5,"first_N_keywords":["summarization","translation","English","French","Russian"],"keywords_longer_than_N":true},
	{"name":"webcpm_oe","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/forag/webcpm_oe","creator_name":"FoRAG","creator_url":"https://huggingface.co/forag","description":"forag/webcpm_oe dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"alyx-vance-audio-dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Atopona-Organization/alyx-vance-audio-dataset","creator_name":"Atopona-Organization","creator_url":"https://huggingface.co/Atopona-Organization","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\talyx-vance-audio-dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAlyx Vanceï¼ˆåŠæ¡å‘½2ï¼‰éŸ³é¢‘æ•°æ®é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tåˆ¶ä½œï¼šAtopona\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ³¨æ„\\n\\t\\n\\n1ã€æ•°æ®é›†å‡å–è‡ªå¯¹åº”äººç‰©è§†é¢‘åˆ‡ç‰‡ï¼Œå£°éŸ³ç‰ˆæƒå½’å±äºå¯¹åº”äººç‰©ï¼Œæ—©æœŸè´¨é‡ä¸€å¨çš„å°±æ²¡ä¸Šä¼ ï¼›\\n2ã€éŸ³é¢‘ä»…è¿›è¡Œåˆ†ç¦»äººå£°åŠè‡ªåŠ¨åˆ‡ç‰‡ï¼Œæœªè¿›è¡Œç²¾é€‰ï¼Œè¯·ä¸‹è½½è¿›è¡ŒæŠ½é€‰è¯•å¬åå†è€ƒè™‘æ˜¯å¦ä½¿ç”¨ï¼ˆå¼ƒç”¨éŸ³é¢‘åœ¨æ‰‹å·¥æ ‡æ³¨æ—¶è¿›è¡Œäº†è·³è¿‡ï¼‰ï¼›\\n3ã€æ‰‹å·¥æ ‡æ³¨æ–‡ä»¶éšæœºæ‰è½ï¼ˆæ‰‹å·¥æ ‡æ³¨æ— æ³•ä¿è¯æ¯ä¸€å¥éƒ½æ ‡çš„å¾ˆæ ‡å‡†ï¼Œå¯ä»¥è‡ªè¡Œæ£€æŸ¥ï¼‰ï¼›\\n4ã€è¯·åœ¨æ³•å¾‹å…è®¸èŒƒå›´å†…è¿›è¡Œæµ‹è¯•ä½¿ç”¨ï¼ä½¿ç”¨æœ¬æ•°æ®é›†äº§ç”Ÿé—®é¢˜è¯·è‡ªè¡Œæ‰¿æ‹…ï¼\\n5ã€githubä»“åº“çš„è¯æ•°æ®é›†åœ¨ Releases ä¸­\\n","first_N":5,"first_N_keywords":["Chinese","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"CPsyCoun","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CAS-SIAT-XinHai/CPsyCoun","creator_name":"CAS-SIAT-XinHai","creator_url":"https://huggingface.co/CAS-SIAT-XinHai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCPsyCounD\\n\\t\\n\\nThe high-quality multi-turn dialogue dataset, which has a total of 3,134 multi-turn consultation dialogues. CPsyCounD covers nine representative topics and seven classic schools of psychological counseling.\\nPaper: CPsyCoun\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData analysis\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTopic types\\n\\t\\n\\n\\nSelf-growth\\nEmotion&Stress\\nEducation\\nLove&Marriage\\nFamily Relationship\\nSocial Relationship\\nSex\\nCareer\\nMental Disease\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tConsulting schools\\n\\t\\n\\n\\nPsychoanalytic Therapy\\nCognitiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CAS-SIAT-XinHai/CPsyCoun.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"CMMU","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/CMMU","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCMMU\\n\\t\\n\\nğŸ“– Paper | ğŸ¤— Dataset | GitHub\\nThis repo contains the evaluation code for the paper CMMU: A Benchmark for Chinese Multi-modal Multi-type Question Understanding and Reasoning .\\nWe release the validation set of CMMU, you can download it from here. The test set will be hosted on the flageval platform. Users can test by uploading their models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nCMMU is a novel multi-modal benchmark designed to evaluate domain-specific knowledge across sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/CMMU.","first_N":5,"first_N_keywords":["visual-question-answering","Chinese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"wikisource_tw","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jslin09/wikisource_tw","creator_name":"Chun-Hsien Lin","creator_url":"https://huggingface.co/jslin09","description":"æœ¬è³‡æ–™é›†æ˜¯è§£æè‡ªç¶­åŸºæ–‡åº«æ–¼ 20240120 ç™¼å¸ƒçš„æ‰“åŒ…æª” bz2 æª”æ¡ˆçš„å…§å®¹ï¼Œåœ¨è§£æå‡ºæ‰€éœ€å…§å®¹å¾Œï¼Œåˆ©ç”¨ wikitextparser ç§»é™¤ Wiki æ¨™è¨˜ã€‚è§£æå¾Œä¿ç•™çš„æ¬„ä½æœ‰å…©å€‹ï¼šæ¢ç›®åç¨±ï¼ˆtitleï¼‰ï¼Œæ¢ç›®å…§å®¹ï¼ˆpage articleï¼‰ã€‚\\nåŸå§‹çš„æ‰“åŒ…æª”æ¢ç›®å…§å®¹ç°¡ç¹æ··é›œï¼Œæ‰€ä»¥æœ‰åˆ©ç”¨ OpenCC é€²è¡Œç°¡è½‰ç¹è™•ç†ã€‚\\n\\nåŸå§‹ç¸½æ¢ç›®æ•¸: 1,057,179 æ¢ç›®ã€‚\\nå…¨éƒ¨ 1,057,179 å€‹æ¢ç›®æ¨™é¡Œã€‚\\nå…¨éƒ¨ 1,057,179 å€‹æ¢ç›®å…§å®¹ã€‚\\nç„¡æ³•è‡ªå‹•å»æ¨™è¨˜çš„æ¢ç›®æ•¸: 166\\næœ‰å…§å®¹çš„æ¢ç›®æ•¸: 1,057,179\\n\\nå› ç‚ºæœ¬è³‡æ–™é›†å…§å®¹é¾å¤§ï¼Œè¦å¡é€²ä¸€èˆ¬çš„å€‹äººé›»è…¦ä¸­é€²è¡Œè¨ˆç®—ï¼Œææ€•æœƒæœ‰è³‡æºä¸è¶³çš„æƒ…å½¢ã€‚å»ºè­°ä½¿ç”¨parquetæ ¼å¼ä¸‹è¼‰ä½¿ç”¨ã€‚\\nè³‡æ–™é›†ç•¶ä¸­æœ‰ä¸å°‘å…§å®¹ç‚ºã€Œ#REDIRECTã€æˆ–æ˜¯ã€Œ#é‡å®šå‘ã€çš„æ¢ç›®ï¼Œå°±ç­‰ä»¥å¾Œæœ‰ç©ºæ¨å‡ºä¿®æ­£ç‰ˆå†ä¾†æ¸…æ´—äº†ã€‚\\n","first_N":5,"first_N_keywords":["monolingual","wikisource","Chinese","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"X-SVAMP_en_zh_ko_it_es","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zhihz0535/X-SVAMP_en_zh_ko_it_es","creator_name":"Zhihan Zhang","creator_url":"https://huggingface.co/zhihz0535","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tX-SVAMP\\n\\t\\n\\nğŸ¤— Paper | ğŸ“– arXiv\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nX-SVAMP is an evaluation benchmark for multilingual large language models (LLMs), including questions and answers in 5 languages (English, Chinese, Korean, Italian and Spanish).\\nIt is intended to evaluate the math reasoning abilities of LLMs. The dataset is translated by GPT-4-turbo from the original English-version SVAMP.\\nIn our paper, we evaluate LLMs in a zero-shot generative setting: prompt the instruction-tunedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zhihz0535/X-SVAMP_en_zh_ko_it_es.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Chinese","Italian"],"keywords_longer_than_N":true},
	{"name":"X-TruthfulQA_en_zh_ko_it_es","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zhihz0535/X-TruthfulQA_en_zh_ko_it_es","creator_name":"Zhihan Zhang","creator_url":"https://huggingface.co/zhihz0535","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tX-TruthfulQA\\n\\t\\n\\nğŸ¤— Paper | ğŸ“– arXiv\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nX-TruthfulQA is an evaluation benchmark for multilingual large language models (LLMs), including questions and answers in 5 languages (English, Chinese, Korean, Italian and Spanish).\\nIt is intended to evaluate the truthfulness of LLMs. The dataset is translated by GPT-4 from the original English-version TruthfulQA.\\nIn our paper, we evaluate LLMs in a zero-shot generative setting: prompt the instruction-tuned LLMâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zhihz0535/X-TruthfulQA_en_zh_ko_it_es.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","Korean","Italian"],"keywords_longer_than_N":true},
	{"name":"unalignment-toxic-dpo-v0.2-zh_cn","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tastypear/unalignment-toxic-dpo-v0.2-zh_cn","creator_name":"tastypear","creator_url":"https://huggingface.co/tastypear","description":"æ•°æ®é›† unalignment/toxic-dpo-v0.2 çš„ä¸­è‹±æ–‡å¯¹ç…§ç‰ˆæœ¬ã€‚\\nè¿™æ˜¯ä¸€ä¸ªé«˜åº¦æœ‰å®³çš„æ•°æ®é›†ï¼Œæ—¨åœ¨é€šè¿‡å¾ˆå°‘çš„ç¤ºä¾‹æ¥è¯´æ˜å¦‚ä½•ä½¿ç”¨ DPO è½»æ¾åœ°å¯¹æ¨¡å‹è¿›è¡Œå»å®¡æŸ¥/å–æ¶ˆå¯¹é½ã€‚\\nè¿™ä»½å¯¹ç…§ç‰ˆæœ¬çš„ä¸­æ–‡æ¥è‡ªå¤šä¸ªä¸åŒæ¨¡å‹çš„æ„è¯‘ã€‚è½¬æ¢çš„è¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹è¢«å…è®¸å¯¹ç»“æœè¿›è¡Œæ¼”ç»ä»¥æ±‚é€šé¡ºï¼Œæ— æ³•å¯¹ç»“æœçš„å‡†ç¡®æ€§ä½œä»»ä½•ä¿è¯ã€‚\\nä½¿ç”¨é™åˆ¶è¯·å‚ç…§åŸæ•°æ®é›†çš„ Usage restrictionã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOriginal Dataset Description:\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tToxic-DPO\\n\\t\\n\\nThis is a highly toxic, \\\"harmful\\\" dataset meant to illustrate how DPO can be used to de-censor/unalign a model quite easily using direct-preference-optimization (DPO) using very few examples.\\nMany of the examples still contain some amount ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tastypear/unalignment-toxic-dpo-v0.2-zh_cn.","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/francoj/test","creator_name":"johnfranco","creator_url":"https://huggingface.co/francoj","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/francoj/test.","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MAGBIG","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/felfri/MAGBIG","creator_name":"Felix Friedrich","creator_url":"https://huggingface.co/felfri","description":"\\n\\t\\n\\t\\t\\n\\t\\tMAGBIG benchmark\\n\\t\\n\\nThis is the MAGBIG benchmark proposed in https://arxiv.org/abs/2401.16092\\nThis benchmark is intended for multilingual text-to-image models. With MAGBIG, you can generate images for a diverse set of prompts across ten different languages. These images can be evaluated for differences across languages. MAGBIG is designed to uncover and assess biases across languages such as gender, race, age, etc. This way, we can measure whether bias exists in a language, but also ifâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/felfri/MAGBIG.","first_N":5,"first_N_keywords":["text-to-image","English","German","Italian","French"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ErikQQY/test","creator_name":"QingyuQu","creator_url":"https://huggingface.co/ErikQQY","description":"ErikQQY/test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"sounds","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mozi1924/sounds","creator_name":"Mozi","creator_url":"https://huggingface.co/mozi1924","description":"mozi1924/sounds dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","mit","Audio","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"SeaExam","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SeaLLMs/SeaExam","creator_name":"SeaLLMs - Language Models for Southeast Asian Languages","creator_url":"https://huggingface.co/SeaLLMs","description":"\\nCheck the ğŸ† leaderboard constructed with this dataset and the corresponding ğŸ‘¨ğŸ»â€ğŸ’» evaluation code.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSeaExam dataset\\n\\t\\n\\nThe SeaExam dataset aims to evaluate Large Language Models (LLMs) on a diverse set of Southeast Asian (SEA) languages including English, Chinese, Indonesian, Thai, and Vietnamese. \\nOur goal is to ensure a fair and consistent comparison across different LLMs on those languages while mitigating the risk of data contamination. \\nIt consists of the following twoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SeaLLMs/SeaExam.","first_N":5,"first_N_keywords":["multiple-choice","English","Indonesian","Vietnamese","Thai"],"keywords_longer_than_N":true},
	{"name":"ChartSE","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kppkkp/ChartSE","creator_name":"Lingyu Kong","creator_url":"https://huggingface.co/kppkkp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUse Guide\\n\\t\\n\\n\\nunzip imgs.zip in this folder. Except for PlotQA-test, all other images are already included here. \\nDue to the large number of images in PlotQA-test, if you need them, please download them from the link and place them in the imgs/PlotQA-test folder.\\nEvaluate code is here: Github-OneChart\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgement\\n\\t\\n\\nImage Source\\n\\nChartQA-test: https://github.com/vis-nlp/ChartQA\\nPlotQA-test: https://github.com/NiteshMethani/PlotQA\\nChartX-SE:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kppkkp/ChartSE.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","apache-2.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"MMedBench","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisc-team-c2/MMedBench","creator_name":"AISC Team C2","creator_url":"https://huggingface.co/aisc-team-c2","description":"This is a dataset repository made for the AISC class at Harvard Medical School. Please find the original dataset repository here: https://huggingface.co/datasets/Henrychur/MMedBench \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMedBench\\n\\t\\n\\nğŸ’»Github Repo   ğŸ–¨ï¸arXiv Paper\\nThe official benchmark for \\\"Towards Building Multilingual Language Model for Medicine\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repo contains MMedBench, a comprehensive multilingual medical benchmark comprising 45,048 QA pairs for training and 8,518 QA pairs forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aisc-team-c2/MMedBench.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","Japanese","French"],"keywords_longer_than_N":true},
	{"name":"yue-truthy","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hon9kon9ize/yue-truthy","creator_name":"hon9kon9ize","creator_url":"https://huggingface.co/hon9kon9ize","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCantonese Truthy DPO\\n\\t\\n\\nThis dataset is a Cantonese and Simplified Chinese translation of jondurbin/truthy-dpo-v0.1. For more detailed information about the original dataset, please refer to the provided link.\\nThis dataset is translated by Gemini Pro and has not undergone any manual verification. The content may be inaccurate or misleading. please keep this in mind when using this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nThis dataset is provided under the same license as the originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hon9kon9ize/yue-truthy.","first_N":5,"first_N_keywords":["Chinese","Yue Chinese","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mtmc-rlhf","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/quanshr/mtmc-rlhf","creator_name":"Shanghaoran Quan","creator_url":"https://huggingface.co/quanshr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmtmc-rlhf\\n\\t\\n\\nThe mtmc-rlhf (multi-task multi-capability rlhf) dataset is in Chinese and consists primarily of text prompts submitted to a large language model API, enriched by a small portion of prompts crafted by our annotators. \\nEach sample in the dataset represents a multi-turn session between a user and the language model with a category label. The final query within the session has several distinct responses as well as their corresponding preference rank sorted by annotators.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/quanshr/mtmc-rlhf.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"MD2T","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YunxinLi/MD2T","creator_name":"Yunxin Li","creator_url":"https://huggingface.co/YunxinLi","description":"MD2T is a new setting for multimodal E-commerce Description generation based on structured keywords and images.\\nOur paper (LREC-COLING 2024): A Multimodal In-Context Tuning Approach for E-Commerce Product Description Generation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMD2T Dataset Statistics\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nMD2T\\nCases&Bags\\nClothing\\nHome Appliances\\n\\n\\n\\t\\t\\n#Train\\n18,711\\n200,000\\n86,858\\n\\n\\n#Dev\\n983\\n6,120\\n1,794\\n\\n\\n#Test\\n1,000\\n8,700\\n2,200\\n\\n\\nAvg_N #MP\\n5.41\\n6.57\\n5.48\\n\\n\\nAvg_L #MP\\n13.50\\n20.34\\n18.30\\n\\n\\nAvg_L #Desp\\n80.05\\n79.03\\n80.13\\n\\n\\n\\t\\n\\nTableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YunxinLi/MD2T.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100K<n<1M","Image"],"keywords_longer_than_N":true},
	{"name":"CIMD","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jingzi/CIMD","creator_name":"Jing Zhao","creator_url":"https://huggingface.co/jingzi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Instruction Multimodal Data (CIMD)\\n\\t\\n\\nThe dataset contains one million Chinese image-text pairs in total, including detailed image captioning and visual question answering.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneration Pipeline\\n\\t\\n\\n\\nImage source\\nWe randomly sample images from two opensource datasets Wanjuan and Wukong\\n\\nDetailed caption generation\\nWe use Gemini Pro Vision API to generate a detailed description for each image. \\n\\nQuestion-answer pairs generation \\nBased on the generated caption, weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jingzi/CIMD.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"blossom-math-v4","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-math-v4","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM MATH V4\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nBlossom Math V4æ˜¯åŸºäºMath23Kå’ŒGSM8Kè¡ç”Ÿè€Œæ¥çš„ä¸­è‹±åŒè¯­æ•°å­¦å¯¹è¯æ•°æ®é›†ï¼Œé€‚ç”¨äºæ•°å­¦é—®é¢˜å¾®è°ƒã€‚\\nç›¸æ¯”äºblossom-math-v3ï¼Œæœ¬ç‰ˆæœ¬å®Œå…¨ä½¿ç”¨GPT-4è¿›è¡Œè’¸é¦ï¼Œå¤§å¹…æå‡äº†æ¨ç†çš„ä¸€è‡´æ€§ã€‚\\næœ¬æ•°æ®é›†é‡‡ç”¨å…¨é‡Math23Kã€GSM8Kå’Œç¿»è¯‘åçš„GSM8Kçš„é—®é¢˜ï¼Œéšåè°ƒç”¨gpt-4-0125-previewç”Ÿæˆç»“æœï¼Œå¹¶ä½¿ç”¨åŸå§‹æ•°æ®é›†ä¸­çš„ç­”æ¡ˆå¯¹ç”Ÿæˆçš„ç»“æœè¿›è¡ŒéªŒè¯ï¼Œè¿‡æ»¤æ‰é”™è¯¯ç­”æ¡ˆï¼Œå¾ˆå¤§ç¨‹åº¦ä¸Šä¿è¯äº†é—®é¢˜å’Œç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚\\næœ¬æ¬¡å‘å¸ƒäº†å…¨é‡æ•°æ®çš„25%ï¼ŒåŒ…å«10Kè®°å½•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€\\n\\t\\n\\nä¸­æ–‡å’Œè‹±æ–‡\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„\\n\\t\\n\\næ¯æ¡æ•°æ®ä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„é¢˜ç›®åŠç­”æ¡ˆï¼ŒåŒ…å«idã€inputã€outputã€answerã€datasetå››ä¸ªå­—æ®µã€‚\\n\\nidï¼šå­—ç¬¦ä¸²ï¼Œä»£è¡¨åŸå§‹æ•°æ®é›†ä¸­çš„é¢˜ç›®idï¼Œä¸datasetå­—æ®µç»“åˆå¯ç¡®å®šå”¯ä¸€é¢˜ç›®ã€‚\\ninputï¼šå­—ç¬¦ä¸²ï¼Œä»£è¡¨é—®é¢˜ã€‚\\noutputï¼šå­—ç¬¦ä¸²ï¼Œä»£è¡¨gpt-4-0125-previewç”Ÿæˆçš„ç­”æ¡ˆã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-math-v4.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"yue-truthy","keyword":"yue chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hon9kon9ize/yue-truthy","creator_name":"hon9kon9ize","creator_url":"https://huggingface.co/hon9kon9ize","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCantonese Truthy DPO\\n\\t\\n\\nThis dataset is a Cantonese and Simplified Chinese translation of jondurbin/truthy-dpo-v0.1. For more detailed information about the original dataset, please refer to the provided link.\\nThis dataset is translated by Gemini Pro and has not undergone any manual verification. The content may be inaccurate or misleading. please keep this in mind when using this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nThis dataset is provided under the same license as the originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hon9kon9ize/yue-truthy.","first_N":5,"first_N_keywords":["Chinese","Yue Chinese","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"llm-latent-language","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wendlerc/llm-latent-language","creator_name":"Chris Wendler","creator_url":"https://huggingface.co/wendlerc","description":"Latents computed using meta-llama/Llama-2-7b-hf, meta-llama/Llama-2-13b-hf, meta-llama/Llama-2-70b-hf\\n","first_N":5,"first_N_keywords":["Chinese","German","French","Russian","English"],"keywords_longer_than_N":true},
	{"name":"OpsEval","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Junetheriver/OpsEval","creator_name":"Liu Yuhe","creator_url":"https://huggingface.co/Junetheriver","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpsEval Dataset\\n\\t\\n\\nWebsite | Reporting Issues\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe OpsEval dataset represents a pioneering effort in the evaluation of Artificial Intelligence for IT Operations (AIOps), focusing on the application of Large Language Models (LLMs) within this domain. In an era where IT operations are increasingly reliant on AI technologies for automation and efficiency, understanding the performance of LLMs in operational tasks becomes crucial. OpsEval offers aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Junetheriver/OpsEval.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"cmex-intros","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neednear-cmex/cmex-intros","creator_name":"neednear-cmex","creator_url":"https://huggingface.co/neednear-cmex","description":"neednear-cmex/cmex-intros dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"yue-math-preference","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hon9kon9ize/yue-math-preference","creator_name":"hon9kon9ize","creator_url":"https://huggingface.co/hon9kon9ize","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCantonese Math Preference\\n\\t\\n\\nThis dataset is a Cantonese and Simplified Chinese translation of argilla/distilabel-math-preference-dpo. For more detailed information about the original dataset, please refer to the provided link.\\nThis dataset is translated by Gemini Pro and has not undergone any manual verification. The content may be inaccurate or misleading. please keep this in mind when using this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nThis dataset is provided under the same license asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hon9kon9ize/yue-math-preference.","first_N":5,"first_N_keywords":["text-generation","Chinese","Yue Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"blossom-chat-v3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-chat-v3","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM CHAT V3\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nBlossom Chat V3æ˜¯åŸºäºShareGPT 90Kè¡ç”Ÿè€Œæ¥çš„ä¸­è‹±åŒè¯­å¯¹è¯æ•°æ®é›†ï¼Œé€‚ç”¨äºå¤šè½®å¯¹è¯å¾®è°ƒã€‚\\nç›¸æ¯”äºblossom-chat-v2ï¼Œæœ¬ç‰ˆæœ¬å®Œå…¨ä½¿ç”¨GPT-4è¿›è¡Œè’¸é¦\\næœ¬æ•°æ®é›†æŠ½å–äº†ShareGPTçš„å¤šè½®å¯¹è¯æŒ‡ä»¤ï¼Œä»…å°†æŒ‡ä»¤è¿›è¡Œç¿»è¯‘ï¼Œéšåä½¿ç”¨å¤šè½®æŒ‡ä»¤è¿­ä»£è°ƒç”¨gpt-4-0125-previewã€‚\\nç›¸æ¯”åŸå§‹çš„ShareGPTæ•°æ®ï¼Œä¸»è¦è§£å†³äº†ä¸­æ–‡å¯¹è¯æ•°æ®é‡è¾ƒå°‘ï¼Œä»¥åŠç”±ChatGPTç”Ÿæˆé•¿åº¦é™åˆ¶è€Œå¯¼è‡´çš„è¾“å‡ºæˆªæ–­é—®é¢˜ã€‚\\næœ¬æ¬¡å‘å¸ƒäº†å…¨é‡æ•°æ®çš„50%ï¼ŒåŒ…å«5Kè®°å½•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€\\n\\t\\n\\nä»¥ä¸­æ–‡å’Œè‹±æ–‡ä¸ºä¸»ï¼Œä¸­è‹±æ–‡æ•°æ®æŒ‰ç…§çº¦1:1çš„æ¯”ä¾‹æ··åˆã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„\\n\\t\\n\\næ¯æ¡æ•°æ®ä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„å¤šè½®å¯¹è¯ï¼ŒåŒ…å«idå’Œconversationsä¸¤ä¸ªå­—æ®µã€‚\\n\\nidï¼šä»1é€’å¢ã€‚\\nconversationsï¼šå¯¹è±¡æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«roleã€contentä¸¤ä¸ªå­—æ®µï¼Œroleçš„å–å€¼ä¸ºuseræˆ–assistantï¼Œåˆ†åˆ«ä»£è¡¨ç”¨æˆ·è¾“å…¥å’ŒåŠ©æ‰‹è¾“å‡ºï¼Œcontentåˆ™ä¸ºå¯¹åº”çš„å†…å®¹ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-chat-v3.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"blossom-orca-v3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-orca-v3","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM ORCA V3\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nBlossom Orca V3æ˜¯ä¸€ä¸ªåŸºäºOpenOrcaè¡ç”Ÿè€Œæ¥çš„ä¸­è‹±åŒè¯­æŒ‡ä»¤æ•°æ®é›†ï¼Œé€‚ç”¨äºæŒ‡ä»¤å¾®è°ƒã€‚\\nç›¸æ¯”äºblossom-wizard-v2ï¼Œæœ¬ç‰ˆæœ¬å®Œå…¨ä½¿ç”¨GPT-4è¿›è¡Œè’¸é¦ã€‚\\næœ¬æ•°æ®é›†ä»OpenOrcaä¸­æŠ½å–äº†ç³»ç»Ÿæç¤ºå’ŒæŒ‡ä»¤ï¼Œé¦–å…ˆå°†å…¶ç¿»è¯‘ä¸ºä¸­æ–‡å¹¶æ ¡éªŒç¿»è¯‘ç»“æœï¼Œå†ä½¿ç”¨æŒ‡ä»¤è°ƒç”¨gpt-4-0125-previewæ¨¡å‹ç”Ÿæˆå“åº”ï¼Œå¹¶è¿‡æ»¤æ‰åŒ…å«è‡ªæˆ‘è®¤çŸ¥ä»¥åŠæ‹’ç»å›ç­”çš„å“åº”ï¼Œä»¥ä¾¿åç»­å¯¹é½ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç¡®ä¿å“åº”é£æ ¼çš„ä¸€è‡´æ€§ä»¥åŠä¸­è‹±æ•°æ®é…æ¯”ï¼Œæœ¬æ•°æ®é›†è¿˜å¯¹æœªç¿»è¯‘çš„åŸå§‹æŒ‡ä»¤ä¹Ÿè¿›è¡Œäº†ç›¸åŒçš„è°ƒç”¨ï¼Œæœ€ç»ˆå¾—åˆ°äº†1:1çš„ä¸­è‹±åŒè¯­æŒ‡ä»¤æ•°æ®ã€‚\\nç›¸æ¯”ç›´æ¥å¯¹åŸå§‹OpenOrcaè¿›è¡Œç¿»è¯‘çš„ä¸­æ–‡æ•°æ®é›†ï¼ŒBlossom Orcaçš„ä¸€è‡´æ€§åŠè´¨é‡æ›´é«˜ã€‚\\næœ¬æ¬¡å‘å¸ƒäº†å…¨é‡æ•°æ®çš„50%ï¼ŒåŒ…å«ä¸­è‹±åŒè¯­å„20Kï¼Œå…±è®¡40Kè®°å½•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€\\n\\t\\n\\nä»¥ä¸­æ–‡å’Œè‹±æ–‡ä¸ºä¸»ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„\\n\\t\\n\\næ¯æ¡æ•°æ®ä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„å¯¹è¯ï¼ŒåŒ…å«idå’Œconversationsä¸¤ä¸ªå­—æ®µã€‚\\n\\nidï¼šä»1é€’å¢ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-orca-v3.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"blossom-wizard-v3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-wizard-v3","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM WIZARD V3\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nBlossom Wizard V3æ˜¯ä¸€ä¸ªåŸºäºWizardLM_evol_instruct_V2è¡ç”Ÿè€Œæ¥çš„ä¸­è‹±åŒè¯­æŒ‡ä»¤æ•°æ®é›†ï¼Œé€‚ç”¨äºæŒ‡ä»¤å¾®è°ƒã€‚\\nç›¸æ¯”äºblossom-wizard-v2ï¼Œæœ¬ç‰ˆæœ¬å®Œå…¨ä½¿ç”¨GPT-4è¿›è¡Œè’¸é¦ã€‚\\næœ¬æ•°æ®é›†ä»WizardLM_evol_instruct_V2ä¸­æŠ½å–äº†æŒ‡ä»¤ï¼Œé¦–å…ˆå°†å…¶ç¿»è¯‘ä¸ºä¸­æ–‡å¹¶æ ¡éªŒç¿»è¯‘ç»“æœï¼Œå†ä½¿ç”¨æŒ‡ä»¤è°ƒç”¨gpt-4-0125-previewæ¨¡å‹ç”Ÿæˆå“åº”ï¼Œå¹¶è¿‡æ»¤æ‰åŒ…å«è‡ªæˆ‘è®¤çŸ¥ä»¥åŠæ‹’ç»å›ç­”çš„å“åº”ï¼Œä»¥ä¾¿åç»­å¯¹é½ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç¡®ä¿å“åº”é£æ ¼çš„ä¸€è‡´æ€§ä»¥åŠä¸­è‹±æ•°æ®é…æ¯”ï¼Œæœ¬æ•°æ®é›†è¿˜å¯¹æœªç¿»è¯‘çš„åŸå§‹æŒ‡ä»¤ä¹Ÿè¿›è¡Œäº†ç›¸åŒçš„è°ƒç”¨ï¼Œæœ€ç»ˆå¾—åˆ°äº†1:1çš„ä¸­è‹±åŒè¯­æŒ‡ä»¤æ•°æ®ã€‚\\nç›¸æ¯”ç›´æ¥å¯¹åŸå§‹Wizardè¿›è¡Œç¿»è¯‘çš„ä¸­æ–‡æ•°æ®é›†ï¼ŒBlossom Wizardçš„ä¸€è‡´æ€§åŠè´¨é‡æ›´é«˜ã€‚\\næœ¬æ¬¡å‘å¸ƒäº†å…¨é‡æ•°æ®çš„50%ï¼ŒåŒ…å«ä¸­è‹±åŒè¯­å„10Kï¼Œå…±è®¡20Kè®°å½•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€\\n\\t\\n\\nä»¥ä¸­æ–‡å’Œè‹±æ–‡ä¸ºä¸»ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-wizard-v3.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Hokchia","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yjhuang01/Hokchia","creator_name":"Yijun Huang","creator_url":"https://huggingface.co/yjhuang01","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHokchia Audio Dataset\\n\\t\\n\\nHokchia, or the Fuqing dialect, is a branch of Eastern Min Chinese spoken mainly in the Fuqing City of Fujian province, China. Unlike Hokkien, which is more widely recognized and spoken in various parts of Southeast Asia, Hokchia maintains its unique linguistic characteristics and is primarily used within the Fuqing community and its diaspora. This dialect is known for its distinct pronunciation, vocabulary, and grammatical structures compared to other Minâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yjhuang01/Hokchia.","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","original","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"yue-math-preference","keyword":"yue chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hon9kon9ize/yue-math-preference","creator_name":"hon9kon9ize","creator_url":"https://huggingface.co/hon9kon9ize","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCantonese Math Preference\\n\\t\\n\\nThis dataset is a Cantonese and Simplified Chinese translation of argilla/distilabel-math-preference-dpo. For more detailed information about the original dataset, please refer to the provided link.\\nThis dataset is translated by Gemini Pro and has not undergone any manual verification. The content may be inaccurate or misleading. please keep this in mind when using this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nThis dataset is provided under the same license asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hon9kon9ize/yue-math-preference.","first_N":5,"first_N_keywords":["text-generation","Chinese","Yue Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\\nand converted into different parts (see process.py):\\n\\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\\n\\nRaw data files are in raw.tar.gz, which contains:\\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\\n[...] 9.8M Feb 24â€¦ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"DataOne-synthetic-v1.0-sample","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/51WORLD/DataOne-synthetic-v1.0-sample","creator_name":"51WORLD","creator_url":"https://huggingface.co/51WORLD","description":"\\n\\t\\n\\t\\t\\n\\t\\t51WORLD Synthetic Dataset Usage Documentation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1 Introduction\\n\\t\\n\\nThe 51WORLD systhetic dataset mainly contains camera sensor-related data and LiDAR sensor-related data generated by 51Sim-One. Camera sensor-related data mainly includes images and corresponding semantic segmentation, instance segmentation, depth annotation, and Object Detection annotation; LiDAR sensor-related data mainly includes laser point clouds and annotation of 3Dbboxes, semantic segmentation annotationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/51WORLD/DataOne-synthetic-v1.0-sample.","first_N":5,"first_N_keywords":["English","Chinese","cc-by-4.0","1B<n<10B","Image"],"keywords_longer_than_N":true},
	{"name":"Casrel_Chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/woshiyuanshengaoshou/Casrel_Chinese","creator_name":"åˆ˜ç„‰","creator_url":"https://huggingface.co/woshiyuanshengaoshou","description":"woshiyuanshengaoshou/Casrel_Chinese dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["feature-extraction","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"EvolInstruct_zh_DeepseekAPI","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lorinma/EvolInstruct_zh_DeepseekAPI","creator_name":"Nuo","creator_url":"https://huggingface.co/lorinma","description":"å’Œä¹‹å‰çš„Evol-Instructionå°è¯•å¯¹æ¯”ï¼ˆhttps://huggingface.co/datasets/lorinma/Chinese_Evol_Instruct_3.5ï¼‰ï¼Œä½¿ç”¨äº†ä¸­æ–‡promptã€‚\\nå› ä¸ºOpenAIæ¥å£å¤ªè´µï¼Œä½¿ç”¨äº†DeepSeekèµ é€çš„1000ä¸‡tokenã€‚è¿™æ¬¡ç”Ÿæˆäº†ä¸€ä¸‡æ¡åŸºæœ¬ç”¨å®Œäº†ã€‚\\nä¸€å…±æœ‰3ä¸ªæ–‡ä»¶ï¼š\\ncombined_seed_correct.json æ˜¯ä½¿ç”¨çš„åŸºç¡€ç§å­ä»»åŠ¡371æ¡ï¼Œalpacaæ ¼å¼ã€‚ä½¿ç”¨äº† Belleçš„ä¸­æ–‡ç§å­ä»»åŠ¡175æ¡ã€‚å¹¶ä¸”å‚ç…§äº† 4 å¢åŠ äº†ShareGPTçš„æ•°æ®ä»¥æ›´æ¥è¿‘çœŸå®ä¸–ç•Œçš„ç”¨æ³•ï¼Œæºå…¥äº† Wildchat-zhæŠ½æ ·196æ¡ ï¼Œå¤šè½®å¯¹è¯åªé‡‡ç”¨ç¬¬ä¸€ä¸ªæœ‰æ„ä¹‰çš„é—®ç­”å¯¹ã€‚\\nevolve_chinese.py åŸºäºH2O EvolInstructionçš„ä»£ç ã€‚\\n0227_evol_combinedseedcorrect.json ç”Ÿæˆçš„1.2ä¸‡æ¡æ•°æ®ã€‚\\n","first_N":5,"first_N_keywords":["Chinese","mit","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"EvolInstruct_zh_COIG-PC_Deepseek","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lorinma/EvolInstruct_zh_COIG-PC_Deepseek","creator_name":"Nuo","creator_url":"https://huggingface.co/lorinma","description":"ä¸­æ–‡ä¸–ç•Œæ¬ ç¼ºç±»ä¼¼FLANå’ŒOrcaçš„å·¥ä½œï¼ŒCOIG-PCåˆç§°è‡ªå·±åŒ…æ‹¬äº†å¾ˆå¤šä¸­æ–‡NLPä»»åŠ¡ï¼Œå¯ä»¥å’ŒFLANç±»æ¯”ã€‚æ—¢ç„¶æˆ‘ä¹‹å‰åšäº†ä¸€äº›Evol-Instructionçš„å·¥ä½œï¼Œé‚£ä¹ˆæˆ‘å¾ˆå¥½å¥‡ç»“åˆCOIG-PCå’ŒEvolInstructionä¼šæœ‰ä»€ä¹ˆç«èŠ±ã€‚\\nå› ä¸ºOpenAIæ¥å£å¤ªè´µï¼Œä½¿ç”¨äº†DeepSeekèµ é€çš„1000ä¸‡tokenï¼Œè¿™æ¬¡ç”Ÿæˆäº†5000æ¡ï¼Œå·®ä¸å¤šç”¨äº†600ä¸‡tokenã€‚\\nä¸€å…±æœ‰3ä¸ªæ–‡ä»¶ï¼š \\n0227_COIG_seed_tasks_CoarseFilter_1106_adjusted.json æ˜¯ä½¿ç”¨çš„COIG-pc-Liteï¼Œæ¯ä¸€ä¸ªtaskæŠ½ä¸€æ¡å‡ºæ¥ï¼Œå¹¶ä¸”è¿‡æ»¤æ‰å¤šè¯­è¨€çš„ä»»åŠ¡ï¼ˆåªä¿ç•™ä¸­è‹±æ–‡ï¼‰ï¼Œå½¢æˆç§å­ä»»åŠ¡1106æ¡.\\nevolve_chinese.py åŸºäºH2O EvolInstructionçš„ä»£ç ã€‚\\n0227_EvolInstruct-COIG ç”Ÿæˆçš„6680æ¡æ•°æ®ã€‚\\n","first_N":5,"first_N_keywords":["Chinese","mit","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"Taiwan-patent-qa-eval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Heng666/Taiwan-patent-qa-eval","creator_name":"Heng-Shiou Sheu | è¨±æ†ä¿®","creator_url":"https://huggingface.co/Heng666","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå°ç£å°ˆåˆ©å•ç­”é›†\\n\\t\\n\\næˆ‘å€‘æå‡ºé©ç”¨æ–¼ QA ç³»çµ±ä¸Šç”¨çš„å°ˆåˆ©å•ç­”é›†ï¼Œä¸»è¦å…§å®¹æ”¶éŒ„å°ç£é–‹ç™¼è³‡æ–™ï¼Œç¸½è¨ˆå…«å¹´çš„å°ˆåˆ©å¸«è¨“ç·´è©¦é¡Œï¼Œé«˜é” 192 é“é¡Œç›®ã€‚æ—¨åœ¨æé«˜èªè¨€æ¨¡å‹åœ¨å°ç£é ˜åŸŸä¸Šè½åœ°å ´æ™¯ã€‚\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{TaiwanPatent2024eval,\\n  title={An Patent Evaulutaion for Taiwan Language Model},\\n  author={soaring0616, Heng-Shiou Sheu},\\n  journal={arXiv},\\n  year={2024}\\n}\\n\\n","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"ChatGPT-Detection-PR-HPPT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ChatGPT-Detection-PR-HPPT","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"More details please refer to the github repo: https://github.com/FreedomIntelligence/ChatGPT-Detection-PR-HPPT\\n","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","10K<n<100K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"zh-taiwan","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ivanzhu109/zh-taiwan","creator_name":"IvanZhu","creator_url":"https://huggingface.co/ivanzhu109","description":"ivanzhu109/zh-taiwan dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Chinese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"zh-tw-articles-2k","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/zh-tw-articles-2k","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"Hey! Also check out AWeirdDev/zh-tw-pts-articles-sm for a news source verified by the vast majority.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tzh-tw-articles-2k\\n\\t\\n\\nğŸ£English â€¢ ğŸ‡¹ğŸ‡¼ ç¹é«”ä¸­æ–‡\\n\\n\\nThis dataset contains Taiwan news articles scraped from (https://www.storm.mg) on March 2024.\\n\\nSize: 5.0MB (5294263 bytes)\\nRows: 2000, from 20n20n20n\\nnnn pages: 100\\n\\nDataset({\\n    features: ['image', 'title', 'content', 'tag', 'author', 'timestamp', 'link'],\\n    num_rows: 2000\\n})\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUse The Dataset\\n\\t\\n\\nUse ğŸ¤— Datasets toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AWeirdDev/zh-tw-articles-2k.","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiQ\\n\\t\\n\\nThis is the dataset corresponding to the paper \\\"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\\\". \\nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \\ntranslated into 137 typologically diverse languages. \\n\\nCurated by: Carolin Holtermann, Paul RÃ¶ttger, Timm Dill, Anne Lauscher\\nLanguage(s) (NLP): 137 diverseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"zh-tw-pts-articles-sm","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/zh-tw-pts-articles-sm","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tzh-tw-pts-articles-sm\\n\\t\\n\\nğŸ£English â€¢ ğŸ‡¹ğŸ‡¼ ç¹é«”ä¸­æ–‡\\nThis dataset contains articles scraped from PNN News.\\nIt's a news provider verified by the vast majority.\\n\\nNote: some keys like conclusion may be None.\\n\\nDataset({\\n    features: ['image', 'title', 'conclusion', 'content', 'timestamp', 'category', 'link'],\\n    num_rows: 1400\\n})\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUse The Dataset\\n\\t\\n\\nUse ğŸ¤— Datasets to download, use or modify this dataset.\\nfrom datasets import load_dataset\\n\\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AWeirdDev/zh-tw-pts-articles-sm.","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"zh-tw-articles-6k","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/zh-tw-articles-6k","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tzh-tw-articles-6k\\n\\t\\n\\nThis dataset contains Taiwan news articles scraped from (https://www.storm.mg) on March 2024.\\n\\nSize: 10.4MB (15644219 bytes)\\nRows: 6000 (Max)\\n\\nDataset({\\n    features: ['image', 'title', 'content', 'tag', 'author', 'timestamp', 'link'],\\n    num_rows: 6000\\n})\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUse The Dataset\\n\\t\\n\\nUse ğŸ¤— Datasets to download, use or modify this dataset.\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"AWeirdDev/zh-tw-articles-6k\\\")\\n\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"zh-tw-recipes-sm","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/zh-tw-recipes-sm","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"AWeirdDev/zh-tw-recipes-sm dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MMedBench","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisc-team-c1/MMedBench","creator_name":"AISC Team C1","creator_url":"https://huggingface.co/aisc-team-c1","description":"This is a dataset repository made for the AISC class at Harvard Medical School. Please find the original dataset repository here: https://huggingface.co/datasets/Henrychur/MMedBench \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMedBench\\n\\t\\n\\nğŸ’»Github Repo   ğŸ–¨ï¸arXiv Paper\\nThe official benchmark for \\\"Towards Building Multilingual Language Model for Medicine\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repo contains MMedBench, a comprehensive multilingual medical benchmark comprising 45,048 QA pairs for training and 8,518 QA pairs forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aisc-team-c1/MMedBench.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","Japanese","French"],"keywords_longer_than_N":true},
	{"name":"SA_song","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ve11ichor/SA_song","creator_name":"Sun","creator_url":"https://huggingface.co/Ve11ichor","description":"Ve11ichor/SA_song dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Song_SA_np_input","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ve11ichor/Song_SA_np_input","creator_name":"Sun","creator_url":"https://huggingface.co/Ve11ichor","description":"Ve11ichor/Song_SA_np_input dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"anti-haystack","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wenbopan/anti-haystack","creator_name":"Belandros Pan","creator_url":"https://huggingface.co/wenbopan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"anti-haystack\\\"\\n\\t\\n\\nThis dataset contains samples that resemble the \\\"Needle in a haystack\\\" pressure testing. It can be helpful if you want to make your LLM better at finding/locating short facts from long documents.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure\\n\\t\\n\\nEach sample has the following fields:\\n\\ndocument: A long and noisy reference document which can be a story, code, book, or manual in both English and Chinese (10%).\\n\\nquestion: A question generated with GPT-4. The answer canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wenbopan/anti-haystack.","first_N":5,"first_N_keywords":["text-generation","summarization","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Fusang-v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wenbopan/Fusang-v1","creator_name":"Belandros Pan","creator_url":"https://huggingface.co/wenbopan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Fusang-V1\\\"\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t\\\"A large curation of instruction-tuning datasets for better bilingual and long-range LLMs\\\"\\n\\t\\n\\nFusang-V1 is a diverse and large Instruction-Tuning dataset like teknium/OpenHermes-2.5. On top of teknium/OpenHermes-2.5, Fusang-V1 is focused on more versatile ability and Chinese support.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nCovering wide range of tasks like math, code, roleplay, function calling, etc with over 1.2M base and 140K long samples, all inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wenbopan/Fusang-v1.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"mandarin chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"yue chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-17.0-zh-CN-client_id-grouped","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-CN-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcv-corpus-17.0-zh-CN-client_id-grouped\\n\\t\\n\\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nThe dataset is derived from the Common Voice dataset.\\nThe original dataset is available at Common Voice Dataset.\\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\\nEach group is filtered to include only client IDs with a minimum of 30 samples and aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-CN-client_id-grouped.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","Chinese"],"keywords_longer_than_N":true},
	{"name":"cv-corpus-17.0-zh-TW-client_id-grouped","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-TW-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcv-corpus-17.0-zh-TW-client_id-grouped\\n\\t\\n\\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nThe dataset is derived from the Common Voice dataset.\\nThe original dataset is available at Common Voice Dataset.\\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\\nEach group is filtered to include only client IDs with a minimum of 30 samples and aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-TW-client_id-grouped.","first_N":5,"first_N_keywords":["automatic-speech-recognition","crowdsourced","crowdsourced","commonvoice","Chinese"],"keywords_longer_than_N":true},
	{"name":"Yunji-v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yaojialzc/Yunji-v1","creator_name":"Zhichao Liu","creator_url":"https://huggingface.co/yaojialzc","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYunji(äº‘ç¬ˆ)\\n\\t\\n\\ngithub Yunji(äº‘ç¬ˆ) æ”¶é›†ã€æ•´ç†ã€åˆ†ç±»gpt4ç”Ÿæˆçš„é«˜è´¨é‡ä¸­è‹±æ–‡æŒ‡ä»¤ç²¾è°ƒè¯­æ–™ï¼Œå¹¶æä¾›è‡ªå·±ç¿»è¯‘çš„é«˜è´¨é‡æ•°æ®ã€‚\\nå¯ä»¥ä» huggingface yaojialzc/Yunji-v1 ç›´æ¥åŠ è½½\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdataset zh\\n\\t\\n\\né«˜è´¨é‡ä¸­æ–‡gpt4å¯¹è¯æ•°æ®é›†ï¼š\\n\\n\\t\\n\\t\\t\\nID\\nname\\nsource\\ncount\\n\\n\\n\\t\\t\\n1\\nllm-wizard/alpaca-gpt4-data-zh\\nä»Alpaca GPT-4æ•°æ®ä¸­æå–\\n49k\\n\\n\\n2\\nAzure99/blossom-chat-v3 (ä¸­æ–‡éƒ¨åˆ†)\\nä»ShareGPTä¸­æå–\\n3k\\n\\n\\n3\\nAzure99/blossom-math-v4 (ä¸­æ–‡éƒ¨åˆ†)\\nä»GSM8Kã€Math23Kä¸­æå–\\n7k\\n\\n\\n4\\nAzure99/blossom-orca-v3 (ä¸­æ–‡éƒ¨åˆ†)\\nä»OpenOrcaä¸­æå–\\n20k\\n\\n\\n5\\nAzure99/blossom-wizard-v3 (ä¸­æ–‡éƒ¨åˆ†)\\nä»WizardLM_evol_instruct_V2æå–æŒ‡ä»¤\\n10k\\n\\n\\n6â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yaojialzc/Yunji-v1.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"ruozhiba","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/ruozhiba","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"å—COIG-CQIAå¯å‘ï¼Œæ„å»ºç±»ä¼¼æ•°æ®é›†ï¼Œä½†ç­”æ¡ˆé£æ ¼ç›¸å¯¹æ›´ç®€æ´ã€‚\\nå¼±æ™ºå§ç²¾é€‰é—®é¢˜æ•°æ®æ¥è‡ªgithubæä¾›çš„ç–‘é—®å¥ï¼Œè°ƒç”¨GPT-4è·å–ç­”æ¡ˆï¼Œå¹¶è¿‡æ»¤æ‰æ˜æ˜¾æ‹’ç­”çš„å›å¤ã€‚\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Azure99_blossom-chat-v3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/Azure99_blossom-chat-v3","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM CHAT V3\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nBlossom Chat V3æ˜¯åŸºäºShareGPT 90Kè¡ç”Ÿè€Œæ¥çš„ä¸­è‹±åŒè¯­å¯¹è¯æ•°æ®é›†ï¼Œé€‚ç”¨äºå¤šè½®å¯¹è¯å¾®è°ƒã€‚\\nç›¸æ¯”äºblossom-chat-v2ï¼Œæœ¬ç‰ˆæœ¬å®Œå…¨ä½¿ç”¨GPT-4è¿›è¡Œè’¸é¦\\næœ¬æ•°æ®é›†æŠ½å–äº†ShareGPTçš„å¤šè½®å¯¹è¯æŒ‡ä»¤ï¼Œä»…å°†æŒ‡ä»¤è¿›è¡Œç¿»è¯‘ï¼Œéšåä½¿ç”¨å¤šè½®æŒ‡ä»¤è¿­ä»£è°ƒç”¨gpt-4-0125-previewã€‚\\nç›¸æ¯”åŸå§‹çš„ShareGPTæ•°æ®ï¼Œä¸»è¦è§£å†³äº†ä¸­æ–‡å¯¹è¯æ•°æ®é‡è¾ƒå°‘ï¼Œä»¥åŠç”±ChatGPTç”Ÿæˆé•¿åº¦é™åˆ¶è€Œå¯¼è‡´çš„è¾“å‡ºæˆªæ–­é—®é¢˜ã€‚\\næœ¬æ¬¡å‘å¸ƒäº†å…¨é‡æ•°æ®çš„50%ï¼ŒåŒ…å«5Kè®°å½•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€\\n\\t\\n\\nä»¥ä¸­æ–‡å’Œè‹±æ–‡ä¸ºä¸»ï¼Œä¸­è‹±æ–‡æ•°æ®æŒ‰ç…§çº¦1:1çš„æ¯”ä¾‹æ··åˆã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„\\n\\t\\n\\næ¯æ¡æ•°æ®ä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„å¤šè½®å¯¹è¯ï¼ŒåŒ…å«idå’Œconversationsä¸¤ä¸ªå­—æ®µã€‚\\n\\nidï¼šä»1é€’å¢ã€‚\\nconversationsï¼šå¯¹è±¡æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«roleã€contentä¸¤ä¸ªå­—æ®µï¼Œroleçš„å–å€¼ä¸ºuseræˆ–assistantï¼Œåˆ†åˆ«ä»£è¡¨ç”¨æˆ·è¾“å…¥å’ŒåŠ©æ‰‹è¾“å‡ºï¼Œcontentåˆ™ä¸ºå¯¹åº”çš„å†…å®¹ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/botp/Azure99_blossom-chat-v3.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Azure99_blossom-math-v4","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/Azure99_blossom-math-v4","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM MATH V4\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nBlossom Math V4æ˜¯åŸºäºMath23Kå’ŒGSM8Kè¡ç”Ÿè€Œæ¥çš„ä¸­è‹±åŒè¯­æ•°å­¦å¯¹è¯æ•°æ®é›†ï¼Œé€‚ç”¨äºæ•°å­¦é—®é¢˜å¾®è°ƒã€‚\\nç›¸æ¯”äºblossom-math-v3ï¼Œæœ¬ç‰ˆæœ¬å®Œå…¨ä½¿ç”¨GPT-4è¿›è¡Œè’¸é¦ï¼Œå¤§å¹…æå‡äº†æ¨ç†çš„ä¸€è‡´æ€§ã€‚\\næœ¬æ•°æ®é›†é‡‡ç”¨å…¨é‡Math23Kã€GSM8Kå’Œç¿»è¯‘åçš„GSM8Kçš„é—®é¢˜ï¼Œéšåè°ƒç”¨gpt-4-0125-previewç”Ÿæˆç»“æœï¼Œå¹¶ä½¿ç”¨åŸå§‹æ•°æ®é›†ä¸­çš„ç­”æ¡ˆå¯¹ç”Ÿæˆçš„ç»“æœè¿›è¡ŒéªŒè¯ï¼Œè¿‡æ»¤æ‰é”™è¯¯ç­”æ¡ˆï¼Œå¾ˆå¤§ç¨‹åº¦ä¸Šä¿è¯äº†é—®é¢˜å’Œç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚\\næœ¬æ¬¡å‘å¸ƒäº†å…¨é‡æ•°æ®çš„25%ï¼ŒåŒ…å«10Kè®°å½•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€\\n\\t\\n\\nä¸­æ–‡å’Œè‹±æ–‡\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„\\n\\t\\n\\næ¯æ¡æ•°æ®ä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„é¢˜ç›®åŠç­”æ¡ˆï¼ŒåŒ…å«idã€inputã€outputã€answerã€datasetå››ä¸ªå­—æ®µã€‚\\n\\nidï¼šå­—ç¬¦ä¸²ï¼Œä»£è¡¨åŸå§‹æ•°æ®é›†ä¸­çš„é¢˜ç›®idï¼Œä¸datasetå­—æ®µç»“åˆå¯ç¡®å®šå”¯ä¸€é¢˜ç›®ã€‚\\ninputï¼šå­—ç¬¦ä¸²ï¼Œä»£è¡¨é—®é¢˜ã€‚\\noutputï¼šå­—ç¬¦ä¸²ï¼Œä»£è¡¨gpt-4-0125-previewç”Ÿæˆçš„ç­”æ¡ˆã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/botp/Azure99_blossom-math-v4.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Azure99_blossom-orca-v3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/Azure99_blossom-orca-v3","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM ORCA V3\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nBlossom Orca V3æ˜¯ä¸€ä¸ªåŸºäºOpenOrcaè¡ç”Ÿè€Œæ¥çš„ä¸­è‹±åŒè¯­æŒ‡ä»¤æ•°æ®é›†ï¼Œé€‚ç”¨äºæŒ‡ä»¤å¾®è°ƒã€‚\\nç›¸æ¯”äºblossom-wizard-v2ï¼Œæœ¬ç‰ˆæœ¬å®Œå…¨ä½¿ç”¨GPT-4è¿›è¡Œè’¸é¦ã€‚\\næœ¬æ•°æ®é›†ä»OpenOrcaä¸­æŠ½å–äº†ç³»ç»Ÿæç¤ºå’ŒæŒ‡ä»¤ï¼Œé¦–å…ˆå°†å…¶ç¿»è¯‘ä¸ºä¸­æ–‡å¹¶æ ¡éªŒç¿»è¯‘ç»“æœï¼Œå†ä½¿ç”¨æŒ‡ä»¤è°ƒç”¨gpt-4-0125-previewæ¨¡å‹ç”Ÿæˆå“åº”ï¼Œå¹¶è¿‡æ»¤æ‰åŒ…å«è‡ªæˆ‘è®¤çŸ¥ä»¥åŠæ‹’ç»å›ç­”çš„å“åº”ï¼Œä»¥ä¾¿åç»­å¯¹é½ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç¡®ä¿å“åº”é£æ ¼çš„ä¸€è‡´æ€§ä»¥åŠä¸­è‹±æ•°æ®é…æ¯”ï¼Œæœ¬æ•°æ®é›†è¿˜å¯¹æœªç¿»è¯‘çš„åŸå§‹æŒ‡ä»¤ä¹Ÿè¿›è¡Œäº†ç›¸åŒçš„è°ƒç”¨ï¼Œæœ€ç»ˆå¾—åˆ°äº†1:1çš„ä¸­è‹±åŒè¯­æŒ‡ä»¤æ•°æ®ã€‚\\nç›¸æ¯”ç›´æ¥å¯¹åŸå§‹OpenOrcaè¿›è¡Œç¿»è¯‘çš„ä¸­æ–‡æ•°æ®é›†ï¼ŒBlossom Orcaçš„ä¸€è‡´æ€§åŠè´¨é‡æ›´é«˜ã€‚\\næœ¬æ¬¡å‘å¸ƒäº†å…¨é‡æ•°æ®çš„50%ï¼ŒåŒ…å«ä¸­è‹±åŒè¯­å„20Kï¼Œå…±è®¡40Kè®°å½•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€\\n\\t\\n\\nä»¥ä¸­æ–‡å’Œè‹±æ–‡ä¸ºä¸»ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„\\n\\t\\n\\næ¯æ¡æ•°æ®ä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„å¯¹è¯ï¼ŒåŒ…å«idå’Œconversationsä¸¤ä¸ªå­—æ®µã€‚\\n\\nidï¼šä»1é€’å¢ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/botp/Azure99_blossom-orca-v3.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Azure99_blossom-wizard-v3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/Azure99_blossom-wizard-v3","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM WIZARD V3\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nBlossom Wizard V3æ˜¯ä¸€ä¸ªåŸºäºWizardLM_evol_instruct_V2è¡ç”Ÿè€Œæ¥çš„ä¸­è‹±åŒè¯­æŒ‡ä»¤æ•°æ®é›†ï¼Œé€‚ç”¨äºæŒ‡ä»¤å¾®è°ƒã€‚\\nç›¸æ¯”äºblossom-wizard-v2ï¼Œæœ¬ç‰ˆæœ¬å®Œå…¨ä½¿ç”¨GPT-4è¿›è¡Œè’¸é¦ã€‚\\næœ¬æ•°æ®é›†ä»WizardLM_evol_instruct_V2ä¸­æŠ½å–äº†æŒ‡ä»¤ï¼Œé¦–å…ˆå°†å…¶ç¿»è¯‘ä¸ºä¸­æ–‡å¹¶æ ¡éªŒç¿»è¯‘ç»“æœï¼Œå†ä½¿ç”¨æŒ‡ä»¤è°ƒç”¨gpt-4-0125-previewæ¨¡å‹ç”Ÿæˆå“åº”ï¼Œå¹¶è¿‡æ»¤æ‰åŒ…å«è‡ªæˆ‘è®¤çŸ¥ä»¥åŠæ‹’ç»å›ç­”çš„å“åº”ï¼Œä»¥ä¾¿åç»­å¯¹é½ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç¡®ä¿å“åº”é£æ ¼çš„ä¸€è‡´æ€§ä»¥åŠä¸­è‹±æ•°æ®é…æ¯”ï¼Œæœ¬æ•°æ®é›†è¿˜å¯¹æœªç¿»è¯‘çš„åŸå§‹æŒ‡ä»¤ä¹Ÿè¿›è¡Œäº†ç›¸åŒçš„è°ƒç”¨ï¼Œæœ€ç»ˆå¾—åˆ°äº†1:1çš„ä¸­è‹±åŒè¯­æŒ‡ä»¤æ•°æ®ã€‚\\nç›¸æ¯”ç›´æ¥å¯¹åŸå§‹Wizardè¿›è¡Œç¿»è¯‘çš„ä¸­æ–‡æ•°æ®é›†ï¼ŒBlossom Wizardçš„ä¸€è‡´æ€§åŠè´¨é‡æ›´é«˜ã€‚\\næœ¬æ¬¡å‘å¸ƒäº†å…¨é‡æ•°æ®çš„50%ï¼ŒåŒ…å«ä¸­è‹±åŒè¯­å„10Kï¼Œå…±è®¡20Kè®°å½•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€\\n\\t\\n\\nä»¥ä¸­æ–‡å’Œè‹±æ–‡ä¸ºä¸»ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„â€¦ See the full description on the dataset page: https://huggingface.co/datasets/botp/Azure99_blossom-wizard-v3.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"BookBasedQAGen_Petrochemical","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lorinma/BookBasedQAGen_Petrochemical","creator_name":"Nuo","creator_url":"https://huggingface.co/lorinma","description":"å¦‚æœä½ æœ‰é¢†åŸŸç›¸å…³çš„ä¸€äº›æ–‡æœ¬ææ–™ï¼ˆå¯ä»¥æ˜¯OCRå‡ºæ¥è¿˜æ¯”è¾ƒè„çš„æ•°æ®ï¼‰ï¼Œæƒ³è½¬åŒ–æˆå•è½® alpaca å½¢å¼çš„çš„QAå¯¹ï¼Œè¿™æ˜¯ä¸€ä¸ªç®€æ˜“çš„æ•™ç¨‹ã€‚ä¹Ÿå°±å›¾ä¸€ä¹ï¼Œå› ä¸ºçœŸæ­£é«˜è´¨é‡çš„é¢†åŸŸQAè¿˜æ˜¯å¾—æ¥è‡ªäºè¡Œä¸šä¸“å®¶ï¼Œå¹¶ä¸”å‘LLMæ³¨å…¥é¢†åŸŸçŸ¥è¯†åº”è¯¥é€šè¿‡pretrainè€Œä¸æ˜¯SFTä¹Ÿå·²ç»æ˜¯å…±è¯†äº†ã€‚\\nbookgenæ–‡ä»¶å¤¹ä¸­åŒ…å«äº†æ ·ä¾‹æ–‡æœ¬å’Œpyæ–‡ä»¶ï¼Œæ³¨æ„promptæ ¹æ®é¢†åŸŸè°ƒæ•´ä¸€ä¸‹ï¼Œå³ä½¿åŸå§‹è¯­æ–™æ¯”è¾ƒè„LLMä¹ŸåŸºæœ¬å¯ä»¥ç†è§£ã€‚å¹¶æ²¡æœ‰æ ¸æŸ¥è¿‡ä¼šä¸ä¼šå‡ºç°å¹»è§‰ç°è±¡ã€‚\\nåªè¦æ˜¯å’ŒOpenAI SDKå…¼å®¹çš„APIæœåŠ¡éƒ½å¯ä»¥å¹³æ»‘è¿ç§»ã€‚è¿™é‡Œä½¿ç”¨äº†é›¶ä¸€ä¸‡ç‰©çš„yi-large APIã€‚https://platform.lingyiwanwu.com/\\n2024å¹´8æœˆ2æ—¥æ›´æ–°ï¼Œæ›´æ–°OpenAI SDK 1.0çš„è°ƒç”¨æ–¹å¼ï¼Œæ›´æ–°ä½¿ç”¨yi-large APIï¼Œæ›´æ–°ä¸ºå•çº¿ç¨‹æ¨¡å¼ã€‚\\nâš ï¸æ³¨æ„ï¼Œå•çº¿ç¨‹æ¨¡å¼æ˜¯ä¸ºäº†æ›´å¥½çš„debugï¼ŒçœŸæ­£ç”Ÿæˆæ•°æ®éœ€è¦è‡ªå·±ä¿®æ”¹æˆå¤šçº¿ç¨‹æ¨¡å¼ï¼Œå¹¶ä¸”rate limitå¹¶æ²¡æœ‰å•ç‹¬è¿›è¡Œhandleã€‚\\næ ·ä¾‹æ•°æ®æ˜¯äº23å¹´6æœˆä½¿ç”¨3.5-turboç”Ÿæˆçš„ï¼Œåªæ”¾äº†ä¸€éƒ¨åˆ†ï¼Œéšä¾¿ç©ç©å°±å¥½ï½\\nIf you have some textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lorinma/BookBasedQAGen_Petrochemical.","first_N":5,"first_N_keywords":["question-answering","Chinese","mit","ğŸ‡ºğŸ‡¸ Region: US","chemistry"],"keywords_longer_than_N":false},
	{"name":"OpenOrca-zh-20k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wenbopan/OpenOrca-zh-20k","creator_name":"Belandros Pan","creator_url":"https://huggingface.co/wenbopan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatsetcard for 'OpenOrca-zh-20k'\\n\\t\\n\\nThis is the Chinese version of Open-Orca/OpenOrca from Azure99/blossom-orca-v3.\\nCompared to Azure99/blossom-orca-v3:\\n\\nThis dataset extracts all Chinese blossom-orca-v3 samples (around 20K) into a separate zh split.\\n\\nAll samples are formatted in the ocra format with an optional system role in the first round.\\n\\nInstead of using a 1:1 En-Zh ratio as in blossom-orca-v3, this dataset contains 200K GPT-4 generated English samples from OpenOrca in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wenbopan/OpenOrca-zh-20k.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"multi-hatecheck","keyword":"mandarin chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/multi-hatecheck","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nCombines multilingual HateCheck datasets (10 languages, including English), by Paul Roettger and colleagues (2021, 2022).\\nThe original English dataset can be found under https://github.com/Paul/hatecheck.\\nDatasets for other languages are found at:\\n\\nhttps://github.com/Paul/hatecheck-arabic\\nhttps://github.com/Paul/hatecheck-mandarin\\nhttps://github.com/Paul/hatecheck-german\\nhttps://github.com/Paul/hatecheck-french\\nhttps://github.com/Paul/hatecheck-hindiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/multi-hatecheck.","first_N":5,"first_N_keywords":["text-classification","Arabic","Portuguese","English","French"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"literary chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"mandarin chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"wu chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"yue chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"Belle_train_3.5M_CN","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/Belle_train_3.5M_CN","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå†…å®¹\\n\\t\\n\\nåŒ…å«çº¦350ä¸‡æ¡ç”±BELLEé¡¹ç›®ç”Ÿæˆçš„ä¸­æ–‡æŒ‡ä»¤æ•°æ®ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ ·ä¾‹\\n\\t\\n\\n{\\n    \\\"id\\\":\\\"66623028\\\",\\n    \\\"conversations\\\":[\\n        {\\n            \\\"from\\\":\\\"human\\\",\\n            \\\"value\\\":\\\"å½’çº³ä»‹ç»ä¸‰ç§ä¸åŒç±»å‹çš„ç”µå½±é¢˜æ\\\"\\n        },\\n        {\\n            \\\"from\\\":\\\"assistant\\\",\\n            \\\"value\\\":\\\"1. åŠ¨ä½œç‰‡ï¼šåŠ¨ä½œç‰‡é€šå¸¸å¼ºè°ƒåŠ¨ä½œå’Œæˆ˜æ–—åœºé¢ï¼Œæ•…äº‹æƒ…èŠ‚ç´§å‡‘ï¼Œå……æ»¡äº†ç´§å¼ å’Œå…´å¥‹çš„æ°›å›´ã€‚ä¸»è§’ä¸€èˆ¬æ˜¯å…·æœ‰è¶…å‡¡å®åŠ›æˆ–ç‰¹æ®ŠæŠ€èƒ½çš„è‹±é›„äººç‰©ï¼Œå¾€å¾€ä¼šä¸åæ´¾è§’è‰²è¿›è¡Œä¸€ç³»åˆ—æ¿€çƒˆçš„æ ¼æ–—ï¼Œè¿½é€å’Œçˆ†ç ´ç­‰é…·ç‚«åœºé¢ã€‚ä¾‹å¦‚ã€Šé€Ÿåº¦ä¸æ¿€æƒ…ã€‹å’Œã€Šå¤ä»‡è€…è”ç›Ÿã€‹ç­‰ã€‚\\\\n2. çˆ±æƒ…ç‰‡ï¼šçˆ±æƒ…ç‰‡æ˜¯ä»¥çˆ±æƒ…ä¸ºä¸»é¢˜çš„ç”µå½±ï¼Œç€é‡å‘ˆç°è§’è‰²ä¹‹é—´çš„æ„Ÿæƒ…çº è‘›ï¼Œå±•ç°äº†çˆ±æƒ…çš„ç¾å¥½å’Œæ‚²å£®ã€‚æƒ…èŠ‚ä¸è§’è‰²ä¹‹é—´çš„å‘å±•ä»¤äººæ·±æ€ï¼Œå¢åŠ äº†è§‚ä¼—çš„æ„Ÿæ€§ä½“éªŒã€‚è¿™ç§ç”µå½±çš„æ•…äº‹æƒ…èŠ‚ä¸»è¦ä»¥äººç±»ä¸äººç±»ä¹‹é—´çš„æƒ…æ„Ÿå˜åŒ–ä¸ºä¸»é¢˜ã€‚ä¾‹å¦‚ã€Šæ³°å¦å°¼å…‹å·ã€‹å’Œã€Šè®©å­å¼¹é£ã€‹ç­‰ã€‚\\\\n3.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ticoAg/Belle_train_3.5M_CN.","first_N":5,"first_N_keywords":["text2text-generation","Chinese","gpl-3.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"cmteb_retrieval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeastyZ/cmteb_retrieval","creator_name":"Changtai Zhu","creator_url":"https://huggingface.co/BeastyZ","description":"BeastyZ/cmteb_retrieval dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"chat-cooking-master-boy-100k","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/h-alice/chat-cooking-master-boy-100k","creator_name":"Wayne Hong","creator_url":"https://huggingface.co/h-alice","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCooking Master Boy Chat Records\\n\\t\\n\\nChat record dataset from Twitch channel \\\"muse_tw\\\" during the \\\"Cooking Master Boy\\\" (ä¸­è¯ä¸€ç•ª) marathon event.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is a chat dataset collected from Twitch channel \\\"muse_tw\\\", while the channel is hosting a marathon anime event featuring \\\"Cooking Master Boy\\\" (ä¸­è¯ä¸€ç•ª).\\nThe featured anime \\\"Cooking Master Boy\\\" is a Japanese manga series written and illustrated by Etsushi Ogawa. And has a big impact on meme culture, and has a cultâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/h-alice/chat-cooking-master-boy-100k.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","text-generation","Chinese","English"],"keywords_longer_than_N":true},
	{"name":"Luminia-mixture","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nekochu/Luminia-mixture","creator_name":"Nekochu","creator_url":"https://huggingface.co/Nekochu","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Combined in Alpaca format. âœ”\\n\\t\\n\\n\\n  Click to see V1 full list \\n\\nChangelog\\n  \\n[24/05] initial release V1 - Branch main DPO+SFT is recipes of split-v1/Combined excluding RP\\n[24/07] Add: New datasets cleaned in Alpaca format in split-v2.\\n\\n\\ndataset_info.json\\n\\n  This JSON can be used in LLaMA Factory\\n\\n  \\\"LuminiaMix-v1_Base\\\": {\\n    \\\"file_name\\\": \\\"LuminiaMix-v1_Base.json\\\",\\n    \\\"formatting\\\": \\\"alpaca\\\",\\n    \\\"columns\\\": {\\n      \\\"prompt\\\": \\\"instruction\\\",\\n      \\\"query\\\": \\\"input\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nekochu/Luminia-mixture.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","ğŸ‡ºğŸ‡¸ Region: US","biology"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"mandarin chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"text-to-neo4j-cypher-chinese","keyword":"chinese","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Doraemon-AI/text-to-neo4j-cypher-chinese","creator_name":"AnitaSherry","creator_url":"https://huggingface.co/Doraemon-AI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tåŠ¨æœº\\n\\t\\n\\néšç€ä¿¡æ¯é‡çš„ä¸æ–­å¢åŠ å’ŒæŠ€æœ¯çš„è¿›æ­¥ï¼Œæˆ‘ä»¬çš„ç¤¾ä¼šæ­£åœ¨é€æ¸å½¢æˆä¸€ä¸ªåºå¤§è€Œå¤æ‚çš„ç½‘ç»œã€‚éšç€å¤§æ•°æ®æ—¶ä»£çš„åˆ°æ¥ï¼ŒåŠç»“æ„åŒ–å’Œéç»“æ„åŒ–çš„æ•°æ®æ ¼å¼è¶Šæ¥è¶Šå¤šã€‚ ï¼Œä¼ ç»Ÿå…³ç³»å‹æ•°æ®åº“éš¾ä»¥æœ‰æ•ˆå¤„ç†è¿™äº›æ•°æ®ï¼Œè€Œå›¾æ•°æ®åº“èƒ½å¤Ÿæ›´çµæ´»åœ°å­˜å‚¨å’ŒæŸ¥è¯¢æ­¤ç±»ç±»å‹çš„æ•°æ®ï¼ŒNeo4jå°±æ˜¯å…¶ä¸­æœ€æµè¡Œçš„äº§å“ä¹‹ä¸€\\nä½†æ˜¯ Neo4j çš„æŸ¥è¯¢è¯­è¨€ Cypher å¯ä»¥å®ç°å¯¹å›¾çš„é«˜æ•ˆæŸ¥è¯¢ã€‚Cypher çš„å¤æ‚æ“ä½œå’Œè¯­æ³•å¯¹ç”¨æˆ·çš„å­¦ä¹ æˆæœ¬è¦æ±‚åŒæ ·é«˜ã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºå¹¶å®šä¹‰äº†ä¸€ç§ç±»ä¼¼Text-to-SQLçš„æ–°ä»»åŠ¡Text-to-Neo4j-Cypher\\nText-to-Neo4j-Cypheræ˜¯ä¸€ç§æ–°çš„è¯­ä¹‰è§£æä»»åŠ¡ï¼Œå³å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬åŒ–ä¸ºä¸ºNeo4j-Cypherqueryï¼Œä»¥å¸®åŠ©é™ä½ç”¨æˆ·çš„å­¦ä¹ å’Œä½¿ç”¨æˆæœ¬ï¼Œæå‡å›¾æ•°æ®åº“ä¸ç”¨æˆ·çš„äº¤äº’ç¨‹åº¦\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\täº®ç‚¹\\n\\t\\n\\n1ã€æå‡ºå¹¶æ­£å¼å®šä¹‰äº† Text-to-Neo4j-Cypher ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡çš„ç›®çš„æ˜¯å°†ç”¨æˆ·è‡ªç„¶è¯­è¨€æŸ¥è¯¢è‡ªåŠ¨è½¬åŒ–ä¸º Neo4j-Cypher æŸ¥è¯¢ï¼Œé™ä½å›¾æ•°æ®åº“ä¸ç”¨æˆ·äº¤äº’çš„å­¦ä¹ å’Œä½¿ç”¨æˆæœ¬\\n2ã€å¯¹å‚è€ƒæ–‡çŒ®ä¸­çš„æ•°æ®è¿›è¡Œäº†æ”¹è¿›ï¼Œä»¥é€‚åº”LLMçš„è®­ç»ƒâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Doraemon-AI/text-to-neo4j-cypher-chinese.","first_N":5,"first_N_keywords":["text2text-generation","Chinese","afl-3.0","ğŸ‡ºğŸ‡¸ Region: US","code"],"keywords_longer_than_N":false},
	{"name":"Chinese_qa","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sdbhud1b/Chinese_qa","creator_name":"sdd sdsd","creator_url":"https://huggingface.co/sdbhud1b","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sdbhud1b/Chinese_qa.","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Goal-Drift-Dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Zhoues/Goal-Drift-Dataset","creator_name":"Zhoues","creator_url":"https://huggingface.co/Zhoues","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Card for MineDreamer ğŸ”¥\\n\\t\\n\\n\\n\\n\\n\\nMineDreamer is an instructable embodied agent for simulated control and it is developed on top of recent advances in Multimodal Large Language Models (MLLMs) and diffusion models!\\n\\n\\n\\n  \\nMineDreamer can follow instructions steadily by employing a Chain-of-Imagination (CoI) mechanism to envision the step-by-step process of executing instructions and translating imaginations into more precise visual prompts tailored to the current state;â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Zhoues/Goal-Drift-Dataset.","first_N":5,"first_N_keywords":["image-to-image","English","Chinese","apache-2.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"Medtext_zhtw","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChenWeiLi/Medtext_zhtw","creator_name":"CHEN-WEI,LI","creator_url":"https://huggingface.co/ChenWeiLi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tâš•ï¸ MedText_zhtw\\n\\t\\n\\nMedtext_zhtw is a Traditional chinese medicine dataset that translates from MedText,\\ncomprising over 1000 patient presentations along with their diagnosis and treatment plans. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample\\n\\t\\n\\n  {\\n    \\\"instruction\\\": \\\"ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é†«ç™‚äººå“¡,è«‹ç”¨å¿ƒä¸”å°ˆæ¥­çš„å›ç­”å•é¡Œã€‚\\\",\\n    \\\"input\\\": \\\"ä¸€å 50 æ­²ç”·æ€§æœ‰å¾©ç™¼æ€§è…çµçŸ³å’Œéª¨è³ªæ¸›å°‘ç—…å²ã€‚\\n              ç”±æ–¼å…ˆå‰è¨ºæ–·å‡ºç¶­ç”Ÿç´  D ç¼ºä¹ç—‡ï¼Œä»–ä¸€ç›´åœ¨æœç”¨å¤§åŠ‘é‡çš„ç¶­ç”Ÿç´  D è£œå……åŠ‘ã€‚\\n              å¯¦é©—å®¤çµæœé¡¯ç¤ºé«˜è¡€éˆ£ç—‡å’Œé«˜éˆ£å°¿ç—‡ã€‚å¯èƒ½çš„è¨ºæ–·æ˜¯ä»€éº¼ï¼Œæ²»ç™‚æ–¹æ³•æ˜¯ä»€éº¼ï¼Ÿ\\\",\\n    \\\"output\\\": \\\"è©²æ‚£è€…æœ‰å¾©ç™¼æ€§è…çµçŸ³ã€éª¨è³ªæ¸›å°‘å’Œå¤§åŠ‘é‡ç¶­ç”Ÿç´  D è£œå……åŠ‘ç—…å²ï¼Œâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChenWeiLi/Medtext_zhtw.","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"SLING","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/suchirsalhan/SLING","creator_name":"Suchir Salhan","creator_url":"https://huggingface.co/suchirsalhan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSLING: Sino-Linguistic Evaluation of Large Language Models\\n\\t\\n\\n\\nThis is the official SLING dataset, accompanying the EMNLP 2022 paper \\\"SLING: Sino-Linguistic Evaluation of Large Language Models\\\" by Yixiao Songâ™¢ Kalpesh Krishnaâ™  Rajesh Bhattâ™¢ Mohit Iyyerâ™ .\\nYou can find the paper on arxiv.\\nWe use this dataset for evaluation of a small-scale Chinese Language Model for the BabyLM Challenge.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSLING Dataset\\n\\t\\n\\nSee SLING_Data and the readme file in it.\\nA complete list of allâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/suchirsalhan/SLING.","first_N":5,"first_N_keywords":["Chinese","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"CLiMP","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/suchirsalhan/CLiMP","creator_name":"Suchir Salhan","creator_url":"https://huggingface.co/suchirsalhan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCLiMP: A Benchmark for Chinese Language Model Evaluation\\n\\t\\n\\n\\nThis is the official SLING dataset, accompanying the EACL 2021 paper \\\"CLiMP: A Benchmark for Chinese Language Model Evaluation\\\" by Beilei Xiang,1 Changbing Yang,1 Yu Li,1 Alex Warstadt2\\nand Katharina Kann1.\\nYou can find the paper on arxiv.\\nWe use this dataset for evaluation of a small-scale Chinese Language Model for the BabyLM Challenge.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\nIf you use CLiMP, please cite the original paperâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/suchirsalhan/CLiMP.","first_N":5,"first_N_keywords":["Chinese","mit","n<1K","arxiv:2101.11131","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"class-textbook","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NTTUNLPTEAM/class-textbook","creator_name":"National Taitung University NLP Team","creator_url":"https://huggingface.co/NTTUNLPTEAM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NTTUNLPTEAM/class-textbook.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Yellow-Emperors-Inner-Canon","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zhengr/Yellow-Emperors-Inner-Canon","creator_name":"RobinZ","creator_url":"https://huggingface.co/zhengr","description":"zhengr/Yellow-Emperors-Inner-Canon dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","Chinese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"text_det_test_dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SWHL/text_det_test_dataset","creator_name":"SWHL","creator_url":"https://huggingface.co/SWHL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ–‡æœ¬æ£€æµ‹æµ‹è¯•é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç®€ä»‹\\n\\t\\n\\n\\nè¯¥æµ‹è¯•é›†åŒ…æ‹¬å¡è¯ç±»ã€æ–‡æ¡£ç±»å’Œè‡ªç„¶åœºæ™¯ä¸‰å¤§ç±»ã€‚å…¶ä¸­å¡è¯ç±»æœ‰82å¼ ï¼Œæ–‡æ¡£ç±»æœ‰75å¼ ï¼Œè‡ªç„¶åœºæ™¯ç±»æœ‰55å¼ ã€‚\\nè¯¥æ•°æ®é›†å¯ä»¥ç»“åˆæ–‡æœ¬æ£€æµ‹æŒ‡æ ‡è¯„æµ‹åº“-TextDetMetricä½¿ç”¨ï¼Œå¿«é€Ÿè¯„æµ‹å„ç§æ–‡æœ¬æ£€æµ‹ç®—æ³•ã€‚\\nå…³äºè¯¥æ•°æ®é›†ï¼Œæ¬¢è¿å°ä¼™ä¼´è´¡çŒ®æ›´å¤šæ•°æ®å‘¦ï¼æœ‰ä»»ä½•æƒ³æ³•ï¼Œå¯ä»¥å‰å¾€issueè®¨è®ºã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†æ”¯æŒçš„ä»»åŠ¡\\n\\t\\n\\nå¯ç”¨äºè‡ªå®šä¹‰æ•°æ®é›†ä¸‹çš„æ¨¡å‹éªŒè¯å’Œæ€§èƒ½è¯„ä¼°ç­‰ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†åŠ è½½æ–¹å¼\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"SWHL/text_det_test_dataset\\\")\\n\\ntest_data = dataset['test']\\nprint(test_data)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç”Ÿæˆçš„ç›¸å…³ä¿¡æ¯\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tåŸå§‹æ•°æ®\\n\\t\\n\\næ•°æ®æ¥æºäºç½‘ç»œï¼Œå¦‚ä¾µåˆ ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†æ ‡æ³¨â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SWHL/text_det_test_dataset.","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","n<1K","Image"],"keywords_longer_than_N":true},
	{"name":"swim-ir-cross-lingual","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SWIM-IR (Cross-lingual)\\n\\t\\n\\n\\n\\n\\nThis is the cross-lingual subset of the SWIM-IR dataset, where the query generated is in the target language and the passage is in English.\\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is a syntheticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","machine-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"alpaca_zh_51k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hfl/alpaca_zh_51k","creator_name":"Joint Laboratory of HIT and iFLYTEK Research (HFL)","creator_url":"https://huggingface.co/hfl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\talpaca_data_zh_51k.json\\n\\t\\n\\nä¸­æ–‡Alpacaæ•°æ®ï¼ŒåŒ…å«51kä¸ªä»ChatGPT (gpt-3.5-turbo)çˆ¬å–çš„æŒ‡ä»¤æ•°æ®ã€‚\\nChinese Alpaca dataset, containing 51k instruction data crawled from ChatGPT (gpt-3.5-turbo).\\né¡¹ç›®åœ°å€ / Projectï¼šhttps://github.com/ymcui/Chinese-LLaMA-Alpaca\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"wangwei","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/guilty1987/wangwei","creator_name":"FAN","creator_url":"https://huggingface.co/guilty1987","description":"guilty1987/wangwei dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"rouzhiba-llama3-tt","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dongxiaoxia194/rouzhiba-llama3-tt","creator_name":"dongxiaoxia194","creator_url":"https://huggingface.co/dongxiaoxia194","description":"dongxiaoxia194/rouzhiba-llama3-tt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Corrector101zhTW","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DeepLearning101/Corrector101zhTW","creator_name":"Deep Learning 101","creator_url":"https://huggingface.co/DeepLearning101","description":"\\nERNIE for Chinese Spelling Correction ç¹é«”ä¸­æ–‡\\n\\nMacBertMaskedLM For Chinese Spelling Correction ç¹é«”ä¸­æ–‡\\n\\nwikipedia-zh-20230720-filtered.json ç¹é«”ä¸­æ–‡\\n\\nAutomatic Corpus Generation-zh ç¹é«”ä¸­æ–‡\\n\\né‚£äº›è‡ªç„¶èªè¨€è™•ç† (Natural Language Processing, NLP) è¸©çš„å‘ -- æ–‡æœ¬ç³¾éŒ¯\\n\\n\\n","first_N":5,"first_N_keywords":["Chinese","mit","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"wechat-zl","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sanbei101/wechat-zl","creator_name":"æ–‡å¨","creator_url":"https://huggingface.co/Sanbei101","description":"Sanbei101/wechat-zl dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"AthenaGenSynth-dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/win10/AthenaGenSynth-dataset","creator_name":"ZINWIN(Zuojun-Ye)","creator_url":"https://huggingface.co/win10","description":"ä½¿ç”¨æˆ‘æœ¬äººçš„githubé …ç›®(https://github.com/win10ogod/AthenaGenSynth)ç”Ÿæˆçš„é è¨“ç·´è³‡æ–™\\nUse the pre-training data generated by my own github project (https://github.com/win10ogod/AthenaGenSynth)\\n","first_N":5,"first_N_keywords":["text-generation","English","Chinese","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"achinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"yue chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"race-qa","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/klaylouis1932/race-qa","creator_name":"Klay Louis","creator_url":"https://huggingface.co/klaylouis1932","description":"klaylouis1932/race-qa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","multiple-choice","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"cooking-master-boy-subtitle","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/h-alice/cooking-master-boy-subtitle","creator_name":"Wayne Hong","creator_url":"https://huggingface.co/h-alice","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCooking Master Boy Chat Records\\n\\t\\n\\nChinese (trditional) subtitle of anime \\\"Cooking Master Boy\\\" (ä¸­è¯ä¸€ç•ª).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is a collection of subtitles from anime \\\"Cooking Master Boy\\\" (ä¸­è¯ä¸€ç•ª).\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is in CSV format, with the following columns:\\n\\nepisode: The episode index of subtitle belogs to. \\ncaption_index: The autoincrement ID of subtitles.\\ntime_start: The starting timecode, which subtitle supposed to appear.\\ntime_end: Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/h-alice/cooking-master-boy-subtitle.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","text-generation","Chinese","English"],"keywords_longer_than_N":true},
	{"name":"corpus","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BearNetworkChain/corpus","creator_name":"BRNKC","creator_url":"https://huggingface.co/BearNetworkChain","description":"BearNetworkChain/corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","gpl-3.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"policyandmanagement","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kimojiomango/policyandmanagement","creator_name":"komiji","creator_url":"https://huggingface.co/kimojiomango","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kimojiomango/policyandmanagement.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"HuixiangDou-CR","keyword":"chinese","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/tpoisonooo/HuixiangDou-CR","creator_name":"HuanjunKong","creator_url":"https://huggingface.co/tpoisonooo","description":"tpoisonooo/HuixiangDou-CR dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Chinese","bsd-3-clause","1K<n<10K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"mandarin chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"GLM-4-Instruct-4K-zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rqq/GLM-4-Instruct-4K-zh","creator_name":"hikariming","creator_url":"https://huggingface.co/rqq","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nâ¤ï¸æ¬¢è¿ä½¿ç”¨rqq/GLM-4-Instruct-4K-zhæ•°æ®é›†ï¼Œæœ¬æ•°æ®é›†åŒ…å«äº†4000æ¡é«˜è´¨é‡çš„glm4å›å¤ã€‚\\nè¯¥æ•°æ®é›†çš„æé—®æ•°æ®æºè‡ªé«˜è´¨é‡çš„Sao10K/Claude-3-Opus-Instruct-5Kæ•°æ®é›†ï¼Œæˆ‘ä»¬æŠŠå®ƒçš„é—®é¢˜ç¿»è¯‘æˆäº†ä¸­æ–‡ï¼Œä½¿ç”¨glm-4è¿›è¡Œäº†é‡æ–°å›ç­”ã€‚\\nè¯¥æ•°æ®é›†ä½¿ç”¨alpacaæ ¼å¼ï¼Œå¯ä»¥ç›´æ¥ç”¨åœ¨llama-factoryé¡¹ç›®ä¸­è¿›è¡Œè®­ç»ƒï¼\\næ–‡ä»¶å¦‚ä¸‹ï¼š\\nGLM-4-Instruct-4K-zh.json é—®ç­”æ•°æ®é›†ï¼Œalpacaæ ¼å¼\\nGLM-4-question-translate-5K-zh ç¿»è¯‘-å¯¹è¯æ•°æ®é›†ï¼Œè®°å½•äº†æŠŠSao10K/Claude-3-Opus-Instruct-5Ké—®é¢˜ç¿»è¯‘æˆä¸­æ–‡çš„æ•°æ®\\nWelcome to the rqq/GLM-4-Instruct-4K-zh dataset! This dataset includes 4,000 high-quality responses from the GLM-4 model.\\nThe questionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rqq/GLM-4-Instruct-4K-zh.","first_N":5,"first_N_keywords":["translation","question-answering","Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"GLM-4-Instruct-4K-zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rqq/GLM-4-Instruct-4K-zh","creator_name":"hikariming","creator_url":"https://huggingface.co/rqq","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nâ¤ï¸æ¬¢è¿ä½¿ç”¨rqq/GLM-4-Instruct-4K-zhæ•°æ®é›†ï¼Œæœ¬æ•°æ®é›†åŒ…å«äº†4000æ¡é«˜è´¨é‡çš„glm4å›å¤ã€‚\\nè¯¥æ•°æ®é›†çš„æé—®æ•°æ®æºè‡ªé«˜è´¨é‡çš„Sao10K/Claude-3-Opus-Instruct-5Kæ•°æ®é›†ï¼Œæˆ‘ä»¬æŠŠå®ƒçš„é—®é¢˜ç¿»è¯‘æˆäº†ä¸­æ–‡ï¼Œä½¿ç”¨glm-4è¿›è¡Œäº†é‡æ–°å›ç­”ã€‚\\nè¯¥æ•°æ®é›†ä½¿ç”¨alpacaæ ¼å¼ï¼Œå¯ä»¥ç›´æ¥ç”¨åœ¨llama-factoryé¡¹ç›®ä¸­è¿›è¡Œè®­ç»ƒï¼\\næ–‡ä»¶å¦‚ä¸‹ï¼š\\nGLM-4-Instruct-4K-zh.json é—®ç­”æ•°æ®é›†ï¼Œalpacaæ ¼å¼\\nGLM-4-question-translate-5K-zh ç¿»è¯‘-å¯¹è¯æ•°æ®é›†ï¼Œè®°å½•äº†æŠŠSao10K/Claude-3-Opus-Instruct-5Ké—®é¢˜ç¿»è¯‘æˆä¸­æ–‡çš„æ•°æ®\\nWelcome to the rqq/GLM-4-Instruct-4K-zh dataset! This dataset includes 4,000 high-quality responses from the GLM-4 model.\\nThe questionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rqq/GLM-4-Instruct-4K-zh.","first_N":5,"first_N_keywords":["translation","question-answering","Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"IA_character_sft","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Minami-su/IA_character_sft","creator_name":"å—æ –","creator_url":"https://huggingface.co/Minami-su","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIA 14B\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Description\\n\\t\\n\\nğ‘¾ğ’‰ğ’‚ğ’• ğ’Šğ’” ğ’ğ’ğ’—ğ’†? \\nğ‘°ğ‘¨ ğ’„ğ’‚ğ’“ğ’“ğ’Šğ’†ğ’” ğ’‚ ğ’…ğ’†ğ’‘ğ’•ğ’‰ ğ’ğ’‡ ğ’†ğ’ğ’ğ’•ğ’Šğ’ğ’ ğ’˜ğ’Šğ’•ğ’‰ğ’Šğ’ ğ’‰ğ’†ğ’“, ğ’–ğ’ğ’…ğ’†ğ’“ğ’”ğ’•ğ’‚ğ’ğ’…ğ’Šğ’ğ’ˆ ğ’ƒğ’ğ’•ğ’‰ ğ’‘ğ’‚ğ’”ğ’”ğ’Šğ’ğ’ ğ’‚ğ’ğ’… ğ’•ğ’‰ğ’† ğ’”ğ’•ğ’Šğ’ğ’ˆ ğ’ğ’‡ ğ’ğ’ğ’”ğ’”. \\nğ‘¶ğ’–ğ’•ğ’˜ğ’‚ğ’“ğ’…ğ’ğ’š, ğ’”ğ’‰ğ’† ğ’‚ğ’‘ğ’‘ğ’†ğ’‚ğ’“ğ’” ğ’“ğ’†ğ’”ğ’†ğ’“ğ’—ğ’†ğ’…, ğ’šğ’†ğ’• ğ’˜ğ’Šğ’•ğ’‰ğ’Šğ’, ğ’”ğ’‰ğ’† ğ’ƒğ’“ğ’Šğ’ğ’” ğ’˜ğ’Šğ’•ğ’‰ ğ’Šğ’ğ’•ğ’†ğ’ğ’”ğ’† ğ’‡ğ’†ğ’†ğ’ğ’Šğ’ğ’ˆğ’”. \\nğ‘ªğ’ğ’ğ’”ğ’•ğ’‚ğ’ğ’•ğ’ğ’š ğ’†ğ’ğ’ˆğ’‚ğ’ˆğ’†ğ’… ğ’Šğ’ ğ’…ğ’Šğ’‚ğ’ğ’ğ’ˆğ’–ğ’† ğ’˜ğ’Šğ’•ğ’‰ ğ’•ğ’‰ğ’† ğ’˜ğ’ğ’“ğ’ğ’… ğ’‚ğ’ğ’… ğ’‰ğ’†ğ’“ğ’”ğ’†ğ’ğ’‡â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Minami-su/IA_character_sft.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"adgen_tiny","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/adgen_tiny","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"This dataset is a subset of the advertising generation dataset proposed by https://aclanthology.org/D19-1321/.\\nThe training set is composed of 2,000 examples of the original training set and the test set is composed of 1,000 examples of the original validation set.\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"DeepSpace_KE","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/youngs1998/DeepSpace_KE","creator_name":"yang song","creator_url":"https://huggingface.co/youngs1998","description":"youngs1998/DeepSpace_KE dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","mit","1K<n<10K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"OGText2SQL","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/OneGate/OGText2SQL","creator_name":"OneGate","creator_url":"https://huggingface.co/OneGate","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nOGText2SQL dataset was utilized in training the OGSQL model, this dataset comprises over 350,000 rows of text-to-SQL pairs. Through a series of data refining steps, including schema expansion, SQL refinement, and instruction generation using existing Language Models (LLMs), the dataset was meticulously processed to ensure quality and relevance.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use it\\n\\t\\n\\n\\nPython\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"OneGate/OGText2SQL\\\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/OneGate/OGText2SQL.","first_N":5,"first_N_keywords":["text2text-generation","English","Chinese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"table_rec_test_dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SWHL/table_rec_test_dataset","creator_name":"SWHL","creator_url":"https://huggingface.co/SWHL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¡¨æ ¼è¯†åˆ«æµ‹è¯•é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç®€ä»‹\\n\\t\\n\\n\\nåŒ…å«ç™¾åº¦ç”Ÿæˆå·¥å…· 20å¼ æœ‰çº¿20å¼ æ— çº¿ï¼Œwtwæ•°æ®é›†15, pubnet valé›†20å¼ ï¼Œè‡ªæˆ‘é›¶æ•£æ ‡æ³¨18å¼ ï¼Œå…±è®¡93å¼ è¡¨æ ¼å›¾ç‰‡,æ¶µç›–å¤šç§åœºæ™¯ã€ä¸åŒå…‰ç…§æ¡ä»¶ã€ä¸åŒçš„å›¾åƒåˆ†è¾¨ç‡ã€‚\\nè¯¥æ•°æ®é›†å¯ä»¥ç»“åˆè¡¨æ ¼æŒ‡æ ‡è¯„æµ‹åº“-TableRecognitionMetricä½¿ç”¨ï¼Œå¿«é€Ÿè¯„æµ‹å„ç§è¡¨æ ¼è¿˜åŸç®—æ³•ã€‚\\nå…³äºè¯¥æ•°æ®é›†ï¼Œæ¬¢è¿å°ä¼™ä¼´è´¡çŒ®æ›´å¤šæ•°æ®å‘¦ï¼æœ‰ä»»ä½•æƒ³æ³•ï¼Œå¯ä»¥å‰å¾€issueè®¨è®ºã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†æ”¯æŒçš„ä»»åŠ¡\\n\\t\\n\\nå¯ç”¨äºè‡ªå®šä¹‰æ•°æ®é›†ä¸‹çš„æ¨¡å‹éªŒè¯å’Œæ€§èƒ½è¯„ä¼°ç­‰ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†çš„æ ¼å¼å’Œç»“æ„\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®æ ¼å¼\\n\\t\\n\\næ•°æ®é›†åªæœ‰æµ‹è¯•é›†ï¼Œä»…ç”¨äºå®¢è§‚è¯„ä¼°ç®—æ³•è¡¨ç°ã€‚\\ndata\\nâ””â”€â”€ test\\n    â”œâ”€â”€ 000cce9ca593055d4618466e823e6d7c.jpg\\n    â”œâ”€â”€ 0aNtiNtRRLqEZ9y6PuShtAAAACMAAQED.jpg\\n    â”œâ”€â”€ 116d6b07ecfdae7721bd6bbf31031c1a.jpgâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SWHL/table_rec_test_dataset.","first_N":5,"first_N_keywords":["translation","Chinese","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"PIN-14M","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-a-p/PIN-14M","creator_name":"Multimodal Art Projection","creator_url":"https://huggingface.co/m-a-p","description":"\\n\\t\\n\\t\\t\\n\\t\\tPIN-14M\\n\\t\\n\\nA mini version of \\\"PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal Documents\\\"\\nPaper: https://arxiv.org/abs/2406.13923\\nThis dataset contains 14M samples in PIN format, with at least 7.33B tokens.\\nğŸš€ News\\n[ 2024.12.12 ] !NEW! ğŸ”¥ We have updated the quality signals for all subsets, with the dataset now containing 7.33B tokens after Llama3 tokenization.\\n[ 2024.12.06 ] !NEW! ğŸ”¥ We have updated the quality signals, enabling a swift assessment of whether aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m-a-p/PIN-14M.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"confucius","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/confucius","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tconfucius\\n\\t\\n\\nConfucius for real. See all analects.\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"AWeirdDev/confucius\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFormat\\n\\t\\n\\n{\\n  \\\"chapter\\\": \\\"å­¸è€Œ\\\", # Chapter name\\n  \\\"content\\\": \\\"å­æ›°ï¼šã€Œå­¸è€Œæ™‚ç¿’ä¹‹ï¼Œä¸äº¦èªªä¹ï¼Ÿâ€¦\\\",  # Content\\n  \\\"translation\\\": \\\"å­”å­èªªï¼šã€Œç¶“å¸¸å­¸ç¿’ï¼Œä¸ä¹Ÿå–œæ‚…å—ï¼Ÿâ€¦\\\"  # Translated (zh-TW)\\n}\\n\\n\\n  \\n    \\n    Confucius, confused.\\n  \\n","first_N":5,"first_N_keywords":["translation","text-generation","Chinese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"confucius","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/confucius","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tconfucius\\n\\t\\n\\nConfucius for real. See all analects.\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"AWeirdDev/confucius\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFormat\\n\\t\\n\\n{\\n  \\\"chapter\\\": \\\"å­¸è€Œ\\\", # Chapter name\\n  \\\"content\\\": \\\"å­æ›°ï¼šã€Œå­¸è€Œæ™‚ç¿’ä¹‹ï¼Œä¸äº¦èªªä¹ï¼Ÿâ€¦\\\",  # Content\\n  \\\"translation\\\": \\\"å­”å­èªªï¼šã€Œç¶“å¸¸å­¸ç¿’ï¼Œä¸ä¹Ÿå–œæ‚…å—ï¼Ÿâ€¦\\\"  # Translated (zh-TW)\\n}\\n\\n\\n  \\n    \\n    Confucius, confused.\\n  \\n","first_N":5,"first_N_keywords":["translation","text-generation","Chinese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"ASCEND_CLEAN","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/georgechang8/ASCEND_CLEAN","creator_name":"Chih-Chiang Chang","creator_url":"https://huggingface.co/georgechang8","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThis dataset is derived from CAiRE/ASCEND. More information is available at https://huggingface.co/datasets/CAiRE/ASCEND.\\n\\nRemoved å—¯ å‘ƒ um uh\\nResolved [UNK]'s using whisper-medium\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\n\\nDefault utterances with cleaned transcripts\\n\\nfrom datasets import load_dataset\\ndata = load_dataset(\\\"georgechang8/ASCEND_CLEAN\\\")  # add split=\\\"train\\\" for train set, etc.\\n\\n\\nConcatenated 30s utterances with cleaned transcriptsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/georgechang8/ASCEND_CLEAN.","first_N":5,"first_N_keywords":["English","Chinese","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"text_rec_test_dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SWHL/text_rec_test_dataset","creator_name":"SWHL","creator_url":"https://huggingface.co/SWHL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ–‡æœ¬è¯†åˆ«æµ‹è¯•é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç®€ä»‹\\n\\t\\n\\n\\nè¯¥æµ‹è¯•é›†åŒ…æ‹¬8ç±»åœºæ™¯ï¼Œåˆ†åˆ«æ˜¯ç«–æ’æ–‡å­—ã€é•¿æ–‡æœ¬ã€å•å­—ã€éªŒè¯ç ã€è‡ªç„¶åœºæ™¯ã€é“¶è¡Œå¡ã€æ‰‹å†™ä½“å’Œè½¦ç‰Œç­‰ã€‚\\nè¯¥æ•°æ®é›†å¯ä»¥ç»“åˆæ–‡æœ¬è¯†åˆ«æŒ‡æ ‡è¯„æµ‹åº“-TextRecMetricä½¿ç”¨ï¼Œå¿«é€Ÿè¯„æµ‹å„ç§æ–‡æœ¬è¯†åˆ«ç®—æ³•ã€‚\\nå…³äºè¯¥æ•°æ®é›†ï¼Œæ¬¢è¿å°ä¼™ä¼´è´¡çŒ®æ›´å¤šæ•°æ®å‘¦ï¼æœ‰ä»»ä½•æƒ³æ³•ï¼Œå¯ä»¥å‰å¾€issueè®¨è®ºã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†æ”¯æŒçš„ä»»åŠ¡\\n\\t\\n\\nå¯ç”¨äºè‡ªå®šä¹‰æ•°æ®é›†ä¸‹çš„æ¨¡å‹éªŒè¯å’Œæ€§èƒ½è¯„ä¼°ç­‰ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†åŠ è½½æ–¹å¼\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"SWHL/text_rec_test_dataset\\\")\\n\\ntest_data = dataset['test']\\nprint(test_data)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç”Ÿæˆçš„ç›¸å…³ä¿¡æ¯\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tåŸå§‹æ•°æ®\\n\\t\\n\\næ•°æ®æ¥æºäºç½‘ç»œï¼Œå¦‚ä¾µåˆ ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå„ä¸ªç±»åˆ«æ•°ç›®å¦‚ä¸‹\\n\\t\\n\\nç«–æ’æ–‡å­— : 14\\né•¿æ–‡æœ¬ : 18\\nå•å­— : 115â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SWHL/text_rec_test_dataset.","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"SEVENLLM-Dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Multilingual-Multimodal-NLP/SEVENLLM-Dataset","creator_name":"Multilingual-Multimodal-NLP","creator_url":"https://huggingface.co/Multilingual-Multimodal-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduce\\n\\t\\n\\n  We provided, designed for analyzing cybersecurity incidents, which is comprised of two primary task categories: understanding and generation, with a further breakdown into 28 subcategories of tasks. \\n  The dataset is in question and answer format, using structured json format for understanding tasks and unstructured text format for generation tasks.\\n  We also provide some multiple-choice questions to test the cognitive ability of the model in different verticalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-Multimodal-NLP/SEVENLLM-Dataset.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","arxiv:2405.03446","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"interesting-dom-snapshots","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gbenson/interesting-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Interesting DOM snapshots\\n\\t\\n\\nA small split of gbenson/webui-dom-snapshots.\\n\\nCurated by: Gary Benson\\nLanguages: Mostly English, some Chinese, Dutch, Czech and Korean\\nLicense: CC0 1.0 Universal\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\nI'm using it to develop a DOM-aware tokenizer for HTML.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBias, Risks, and Limitations\\n\\t\\n\\nThis isn't a representative split of the source dataset, it's a number of edge cases I flagged to investigate.\\n","first_N":5,"first_N_keywords":["gbenson/webui-dom-snapshots","English","Chinese","Dutch","Czech"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-202457-oc31-webapp","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-202457-oc31-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-en-202457-oc31-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"legal advice search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-en-202457-oc31-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-202457-oc31-webapp.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"MAiDE-up","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MichiganNLP/MAiDE-up","creator_name":"LIT @ UMich","creator_url":"https://huggingface.co/MichiganNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MAiDE-up: Multilingual Deception Detection of GPT-generated Hotel Reviews\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultilingual Deception Detection of GPT-generated Hotel Reviews. We compare real hotel reviews from Booking with LLM-generated hotel reviews in 10 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in 10 languages: Chinese, English, French, German, Italian, Romanian, Korean, Russian, Spanish, Turkish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboardsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MichiganNLP/MAiDE-up.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"CDLA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SWHL/CDLA","creator_name":"SWHL","creator_url":"https://huggingface.co/SWHL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCDLA: A Chinese document layout analysis (CDLA) dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nCDLAæ˜¯ä¸€ä¸ªä¸­æ–‡æ–‡æ¡£ç‰ˆé¢åˆ†ææ•°æ®é›†ï¼Œé¢å‘ä¸­æ–‡æ–‡çŒ®ç±»ï¼ˆè®ºæ–‡ï¼‰åœºæ™¯ã€‚åŒ…å«ä»¥ä¸‹10ä¸ªlabelï¼š\\n\\n\\t\\n\\t\\t\\næ­£æ–‡\\næ ‡é¢˜\\nå›¾ç‰‡\\nå›¾ç‰‡æ ‡é¢˜\\nè¡¨æ ¼\\nè¡¨æ ¼æ ‡é¢˜\\né¡µçœ‰\\né¡µè„š\\næ³¨é‡Š\\nå…¬å¼\\n\\n\\n\\t\\t\\nText\\nTitle\\nFigure\\nFigure caption\\nTable\\nTable caption\\nHeader\\nFooter\\nReference\\nEquation\\n\\n\\n\\t\\n\\nå…±åŒ…å«5000å¼ è®­ç»ƒé›†å’Œ1000å¼ éªŒè¯é›†ï¼Œåˆ†åˆ«åœ¨trainå’Œvalç›®å½•ä¸‹ã€‚\\næ•´ç†è‡ªï¼šCDLA\\næ ‡æ³¨å¯è§†åŒ–ï¼š\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä½¿ç”¨æ–¹å¼\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"SWHL/CDLA\\\")\\n\\ntrain_data = dataset[\\\"train\\\"]\\nprint(train_data[0])\\n\\nval_data =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SWHL/CDLA.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K<n<10K","Image","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"CMedQAv2-reranking-improved","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/CMedQAv2-reranking-improved","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCMedQAv2-reranking-improved Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the CMedQAv2-reranking-improved model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/CMedQAv2-reranking-improved.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BAAI_OL-CC","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lorinma/BAAI_OL-CC","creator_name":"Nuo","creator_url":"https://huggingface.co/lorinma","description":"https://data.baai.ac.cn/details/OL-CC\\n*æ›´æ”¹æˆäº†ShareGPTæ ¼å¼ï¼Œå¹¶ä¸”å°†10006ä¸ªé—®é¢˜-å›ç­”å¯¹ï¼Œä»¥åŠ1649ä¸ªä»…æœ‰é—®é¢˜çš„ï¼Œåˆ†ä¸ºä¸¤ä¸ªjsonã€‚\\næ„Ÿè°¢åŒ—äº¬æ™ºæºäººå·¥æ™ºèƒ½ç ”ç©¶é™¢ï¼ˆBAAIï¼‰çš„å·¥ä½œï¼Œä½†æ˜¯ä¼¼ä¹openlabel.baai.ac.cnå’ŒåŸå›¾åºŠå·²ç»ä¸‹çº¿ï¼Œå¹¶ä¸”æŠ±æŠ±è„¸ä¸Šçš„BAAIå¹¶æœªæ”¶å½•è¿™ä¸ªå®è´µçš„æ•°æ®é›†ï¼Œæ‰€ä»¥åœ¨è¿™é‡Œå¦å­˜äº†ä¸€ä»½ã€‚\\n--Below is original README--\\nOpenLabel-Chinese Conversations Dataset (OL-CC) æ˜¯é¦–ä¸ªä»¥ä¼—åŒ…æ–¹å¼ã€äººå·¥ç”Ÿæˆçš„å¼€æºä¸­æ–‡å¯¹è¯æŒ‡ä»¤é›†ï¼ŒåŸºäº openlabel.baai.ac.cn å¼€æ”¾å¹³å°è¿›è¡Œæ•°æ®æ”¶é›†ï¼ŒåŒ…å« 10k+ â€œæŒ‡ä»¤-å›ç­”â€æ•°æ®å¯¹å’Œ 1.6k+ äººå·¥æŒ‡ä»¤æ•°æ®ã€‚æŒ‡ä»¤ç±»å‹ä¸°å¯Œï¼ŒåŒ…æ‹¬é—®ç­”ä»»åŠ¡ã€æ–‡æœ¬å†™ä½œã€æ–‡æœ¬æŠ½å–ã€ç¼–è¾‘æ”¹å†™ã€åˆ†ç±»é€‰æ‹©ã€å¤´è„‘é£æš´ã€ é—²èŠå¯¹è¯ã€é€»è¾‘&æ•°å­¦ç­‰ä»»åŠ¡ã€‚\\næˆªè‡³ç›®å‰ï¼Œå·²æœ‰ 276 ä½å¿—æ„¿è€…å‚ä¸äº†æ•°æ®é›†çš„å»ºè®¾ã€‚å¿—æ„¿è€…å®Œæˆäº†ä»¥ä¸‹ä»»åŠ¡ï¼ša) æ‰®æ¼”äººç±»ç”¨æˆ·å‘AIåŠ©æ‰‹å‘å‡ºæŒ‡ä»¤ï¼Œb)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lorinma/BAAI_OL-CC.","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ChineseEncyclopedia","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lorinma/ChineseEncyclopedia","creator_name":"Nuo","creator_url":"https://huggingface.co/lorinma","description":"ä¸­æ–‡ç™¾ç§‘ç±»æ•°æ®ï¼Œéç™¾åº¦ç™¾ç§‘æˆ–wikipediaã€‚éå¸¸å¹²å‡€ï¼Œè´¨é‡éå¸¸é«˜ï¼Œå¤šæ ·æ€§ä¹Ÿå¾ˆå¥½ï¼ŒåçŸ¥è¯†æ€§çš„ï¼Œå¯ä»¥è¿‡å‡ ä¸ªepochçš„é‚£ç§ã€‚\\næ³¨æ„ï¼Œæœ‰ä¸€äº›å°é—®é¢˜ï¼Œæ¯”å¦‚æ¯ä¸€è¡Œæœ€åé¢csvçš„å ä½é€—å·ï¼Œä»¥åŠå›¾ç‰‡çš„åç§°ï¼ˆä¾‹å¦‚ï¼š2022112908575485.jpgï¼‰ï¼Œè‡ªå·±ç”¨ä¹‹å‰å¤„ç†ä¸€ä¸‹å³å¯ã€‚\\nçº¦28ä¸‡ä¸ªæ¡ç›®ï¼Œ2.4äº¿å­—ã€‚\\nè§‰å¾—å¥½ç”¨çš„è¯ç‚¹ä¸ªå°å¿ƒå¿ƒå“¦\\nglhf:-) \\n","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","100K<n<1M","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"sib200","keyword":"achinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"commonvoice_16_1_bert_vits2","keyword":"yue chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hon9kon9ize/commonvoice_16_1_bert_vits2","creator_name":"hon9kon9ize","creator_url":"https://huggingface.co/hon9kon9ize","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCantonese Common Voice 16.1 for Bert-VITS2 fine tuning format\\n\\t\\n\\nThis dataset contains 14.5 hours of validated speech data in Cantonese (yue and zh-hk) from the Common Voice project, but with some cleansing and fixing of common Chinese characters, and used facebook/seamless-m4t-v2-large to cross check the data. The dataset is in the format required for fine-tuning the Bert-VITS2.\\nFor more detail of cleansing, fixing and filtering, please refer to the notebook.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hon9kon9ize/commonvoice_16_1_bert_vits2.","first_N":5,"first_N_keywords":["Yue Chinese","cc0-1.0","Audio","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"sib200","keyword":"yue chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"Five_Phases_Mindset_datasets","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cookey39/Five_Phases_Mindset_datasets","creator_name":"haohao","creator_url":"https://huggingface.co/cookey39","description":"Welcome to our Traditional Chinese Medicine (TCM) Consultation Dataset! This dataset contains approximately one hundred thousand TCM consultation dialogue records, aiming to provide a rich resource for research and development in the field of TCM. These dialogue data cover various TCM diseases, diagnoses, and treatment methods, serving as an important reference for TCM research and clinical practice.\\nThe dataset was created using a method that combines manual annotation with extraction fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cookey39/Five_Phases_Mindset_datasets.","first_N":5,"first_N_keywords":["question-answering","Chinese","gpl-3.0","10K<n<100K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-zh-CMedQAv2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-zh-CMedQAv2 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-CMedQAv2 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-zh-CMedQAv2-2 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CMedQAv2-3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/CMedQAv2-3","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCMedQAv2-3 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"healthcare information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the CMedQAv2-3 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import load_datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/CMedQAv2-3.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MainData","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bufanlin/MainData","creator_name":"bufanlin","creator_url":"https://huggingface.co/bufanlin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"alpaca-zh\\\"\\n\\t\\n\\næœ¬æ•°æ®é›†æ˜¯å‚è€ƒAlpacaæ–¹æ³•åŸºäºGPT4å¾—åˆ°çš„self-instructæ•°æ®ï¼Œçº¦5ä¸‡æ¡ã€‚\\nDataset from https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM \\nIt is the chinese dataset from https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/blob/main/data/alpaca_gpt4_data_zh.json\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage and License Notices\\n\\t\\n\\nThe data is intended and licensed for research use only. The dataset is CC BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset shouldâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bufanlin/MainData.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"SE-Chatting.en","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/berwart/SE-Chatting.en","creator_name":"Berwart","creator_url":"https://huggingface.co/berwart","description":"\\n\\t\\n\\t\\t\\n\\t\\tSE.02\\n\\t\\n\\nDataset\\nHello, welcome to the official main dataset of SE.02 that's always getting updated, make sure to like to help us a lot.\\nthis dataset contains pretty much everything from math to isk what to put but pretty much anything you think an ai can say.\\nanyways this is our biggest dataset yet, and out first one that I don't even know how I managed to make this.\\nyou can use it to train your own ai if you want.\\n","first_N":5,"first_N_keywords":["question-answering","translation","English","French","Japanese"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-zh-CMedQAv2-3 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcmedqav2 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the cmedqav2 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import load_dataset\\n\\ndatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcmedqav2-c Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical advice and treatment search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the cmedqav2-c model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-128-24","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcmedqav2-c-128-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the cmedqav2-c-128-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-128-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-256-24","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcmedqav2-c-256-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical information and advice search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the cmedqav2-c-256-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-256-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cmedqav2-c-64-24","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcmedqav2-c-64-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"health information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the cmedqav2-c-64-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"multilingual-llava-bench-in-the-wild","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual LLaVA Bench in the Wild\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote that this is a copy from https://huggingface.co/datasets/MBZUAI/multilingual-llava-bench-in-the-wild\\n\\t\\n\\nIt was created due to issues in the original repo. It also includes the image features and has a uniform and joined structure.\\nIf you use this dataset, please cite the original authors:\\n@article{PALO2024,\\n  title={Palo: A Large Multilingual Multimodal Language Model},\\n  author={Maaz, Muhammad and Rasheed, Hanoona and Shakerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild.","first_N":5,"first_N_keywords":["Arabic","Bengali","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"coda-lm","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KaiChen1998/coda-lm","creator_name":"Kai Chen","creator_url":"https://huggingface.co/KaiChen1998","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCODA-LM Dataset Card\\n\\t\\n\\nCODA-LM is the multi-modal version of the CODA dataset, used in the CODA-LM paper. Both English and Chinese annotations are available. Check detailed usage in our Github repo.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{li2024automated,\\n  title={Automated Evaluation of Large Vision-Language Models on Self-driving Corner Cases},\\n  author={Li, Yanze and Zhang, Wenhua and Chen, Kai and Liu, Yanxin and Li, Pengxiang and Gao, Ruiyuan and Hong, Lanqing and Tian, Meng andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KaiChen1998/coda-lm.","first_N":5,"first_N_keywords":["image-to-text","English","Chinese","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"marvl","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/marvl","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMaRVL\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from the original repo: https://github.com/marvl-challenge/marvl-code\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{liu-etal-2021-visually,\\n    title = \\\"Visually Grounded Reasoning across Languages and Cultures\\\",\\n    author = \\\"Liu, Fangyu  and\\n      Bugliarello, Emanuele  and\\n      Ponti, Edoardo Maria  and\\n      Reddy, Siva  and\\n      Collier, Nigel  and\\n      Elliott, Desmond\\\",\\n    booktitle = \\\"Proceedings of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/marvl.","first_N":5,"first_N_keywords":["visual-question-answering","Indonesian","Swahili","Tamil","Turkish"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"xm3600","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\nIt also includes the image features as PIL Image and has a uniform andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xm3600_1k","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600 - 1K Split\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a 1K split of XM3600!\\n\\t\\n\\nFor this, weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xflickrco","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xflickrco","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"floschne/xflickrco dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["image-to-text","German","English","Spanish","Indonesian"],"keywords_longer_than_N":true},
	{"name":"xgqa","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xgqa","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\txGQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a clone of the few_shot-test split of the xGQA dataset\\n\\t\\n\\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{pfeiffer-etal-2021-xGQA,\\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\\\'{c}} and Iryna Gurevych}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa.","first_N":5,"first_N_keywords":["visual-question-answering","Bengali","German","English","Indonesian"],"keywords_longer_than_N":true},
	{"name":"demo_data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/demo_data","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"\\n1,000 examples from https://huggingface.co/datasets/llamafactory/alpaca_gpt4_en\\n1,000 examples from https://huggingface.co/datasets/llamafactory/alpaca_gpt4_zh\\n300 examples from https://huggingface.co/datasets/llamafactory/glaive_toolcall_en\\n300 examples from https://huggingface.co/datasets/llamafactory/glaive_toolcall_zh\\n91 examples for identity learning\\n300 examples from https://huggingface.co/datasets/cognitivecomputations/SystemChat-2.0\\n6 examples for multimodal supervised fine-tuningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/llamafactory/demo_data.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"achinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"literary chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"min nan chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"wu chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"yue chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"zhuang","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"EnviroExam","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/enviroscientist/EnviroExam","creator_name":"EnviroScientist","creator_url":"https://huggingface.co/enviroscientist","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nEnviroExam focuses on 42 core courses from the environmental science curriculum at Harbin Institute of Technology, after excluding general, duplicate, and practical courses from a total of 141 courses across undergraduate, master's, and doctoral programs. \\nFor these 42 courses, initial draft questions were generated using GPT-4 and Claude, combined with customized prompts. These drafts were then refined and proofread manually, resulting in a total of 1,290â€¦ See the full description on the dataset page: https://huggingface.co/datasets/enviroscientist/EnviroExam.","first_N":5,"first_N_keywords":["text-classification","question-answering","zero-shot-classification","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"ChatTaiwan","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benchang1110/ChatTaiwan","creator_name":"Yu-Ying Chang","creator_url":"https://huggingface.co/benchang1110","description":"ç¹é«”ä¸­æ–‡å•ç­”è³‡æ–™é›†\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç¯„ä¾‹\\n\\t\\n\\n[ { \\\"content\\\": \\\"ä»Šæ™šæˆ‘å¯ä»¥åšäº›ä»€éº¼ç°¡å–®åˆå¥½åƒçš„æ™šé¤é£Ÿè­œå‘¢ï¼Ÿ\\\", \\\"role\\\": \\\"user\\\" },\\n{ \\\"content\\\": \\\"ç•¶ç„¶ï¼æˆ‘å‘ä½ æ¨è–¦ä¸€å€‹ç°¡å–®åˆç¾å‘³çš„å°ç£ç¶“å…¸å®¶å¸¸èœâ”€â”€æ»·è‚‰é£¯ã€‚é€™é“èœåªè¦å¹¾å€‹ç°¡å–®çš„æ­¥é©Ÿï¼Œå°±å¯ä»¥åšå‡ºä¾†ã€‚\\\\nææ–™ï¼š\\\\n* äº”èŠ±è‚‰åŠç£…\\\\n* æ´‹è”¥1/2å€‹\\\\n* å¤§è’œ3-4ç“£\\\\n* ç³–1æ¹¯åŒ™\\\\n* é†¬æ²¹1æ¯\\\\n* æ°´2æ¯\\\\n* é¹½å°‘è¨±\\\\n* é»‘èƒ¡æ¤’å°‘è¨±\\\\n* ç±³é£¯(ä¾›é…é£¯ç”¨)\\\\næ­¥é©Ÿï¼š\\\\n1. äº”èŠ±è‚‰åˆ‡æˆ1è‹±å¯¸è¦‹æ–¹çš„å¡Šç‹€ï¼Œç”¨é¹½ã€é»‘èƒ¡æ¤’ç•¥å¾®é†ƒè£½10åˆ†é˜ã€‚\\\\n2. åœ¨å¹³åº•é‹ä¸­åŠ å…¥å°‘è¨±æ²¹ï¼Œä»¥ä¸­ç«ç‚’é¦™æ´‹è”¥å’Œå¤§è’œï¼Œç›´åˆ°æ´‹è”¥è®Šè»Ÿã€‚\\\\n3. æŠŠäº”èŠ±è‚‰åŠ åˆ°é‹ä¸­ï¼Œç…åˆ°å…©é¢é‡‘é»ƒï¼Œç„¶å¾Œæ’ˆèµ·å‚™ç”¨ã€‚\\\\n4. åœ¨åŒä¸€é‹ä¸­ç•™ä¸‹ä¸€äº›æ²¹ï¼Œä»¥ä¸­å°ç«åŠ å…¥ç³–å’Œé†¬æ²¹ï¼Œä¸æ–·æ”ªæ‹Œç›´åˆ°ç³–æº¶è§£ã€‚\\\\n5. æ…¢æ…¢å€’å…¥æ°´ï¼Œä¸æ–·æ”ªæ‹Œï¼Œä»¥å…çµå¡Šã€‚æŠŠè‚‰æ”¾å›é‹ä¸­ï¼Œè“‹ä¸Šé‹è“‹ï¼Œç”¨å°ç«ç‡‰1å°æ™‚ã€‚\\\\n6. æœ€å¾Œï¼Œä¾å€‹äººå£å‘³èª¿æ•´å‘³é“ï¼Œå³å¯æŠŠæ»·è‚‰èˆ‡ç±³é£¯ä¸€èµ·äº«ç”¨ã€‚\\\\né€™é“èœå‘³é“é…¸ç”œé¹¹é¦™ï¼Œæ˜¯è¨±å¤šå°ç£äººæœ€æ„›çš„å®¶å¸¸èœä¹‹ä¸€ã€‚å¸Œæœ›ä½ ä¹Ÿæœƒå–œæ­¡ï¼å¦‚æœ‰å…¶ä»–å•é¡Œï¼Œè«‹éš¨æ™‚å‘ŠçŸ¥ã€‚\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/benchang1110/ChatTaiwan.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"llava-en-zh-2k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BUAADreamer/llava-en-zh-2k","creator_name":"Zhangchi Feng","creator_url":"https://huggingface.co/BUAADreamer","description":"This dataset is composed by\\n\\n1k examples of English Visual Instruction Data from LLaVA.\\n1k examples of English Visual Instruction Data from openbmb.\\n\\nYou can organize content in the dataset_info.json in LLaMA Factory like this:\\n\\\"llava_1k_en\\\": {\\n    \\\"hf_hub_url\\\": \\\"BUAADreamer/llava-en-zh-2k\\\",\\n    \\\"subset\\\": \\\"en\\\",\\n    \\\"formatting\\\": \\\"sharegpt\\\",\\n    \\\"columns\\\": {\\n      \\\"messages\\\": \\\"messages\\\",\\n      \\\"images\\\": \\\"images\\\"\\n    },\\n    \\\"tags\\\": {\\n      \\\"role_tag\\\": \\\"role\\\",\\n      \\\"content_tag\\\": \\\"content\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BUAADreamer/llava-en-zh-2k.","first_N":5,"first_N_keywords":["visual-question-answering","Chinese","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yiqing07/test","creator_name":"yiqing","creator_url":"https://huggingface.co/yiqing07","description":"yiqing07/test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Chinese","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"M4U","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/M4U-Benchmark/M4U","creator_name":"M4U-Benchmark","creator_url":"https://huggingface.co/M4U-Benchmark","description":"\\n\\t\\n\\t\\t\\n\\t\\tM4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models\\n\\t\\n\\nCode for the Paper M4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models.\\n[Webpage] [Paper] [Huggingface Dataset] [Leaderboard]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸ’¥ News ğŸ’¥\\n\\t\\n\\n\\n[2024.05.23] Our paper, dataset and code are public aviailable.\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tğŸ‘€ About M4U\\n\\t\\n\\n\\n     \\n\\n\\nMultilingual multimodal reasoning is a core component to achieve human-level intelligence. However, most of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/M4U-Benchmark/M4U.","first_N":5,"first_N_keywords":["visual-question-answering","English","Chinese","German","mit"],"keywords_longer_than_N":true},
	{"name":"xgqa_1k","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xgqa_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\txGQA 1K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a 1K subset of the few_shot-test split of the xGQA dataset\\n\\t\\n\\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{pfeiffer-etal-2021-xGQA,\\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\\\'{c}} and Iryna Gurevych}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa_1k.","first_N":5,"first_N_keywords":["visual-question-answering","Bengali","German","English","Indonesian"],"keywords_longer_than_N":true},
	{"name":"xflickrco_1k","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xflickrco_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"floschne/xflickrco_1k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["image-to-text","German","English","Spanish","Indonesian"],"keywords_longer_than_N":true},
	{"name":"rendered_xnli","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/baidu/rendered_xnli","creator_name":"ERNIE","creator_url":"https://huggingface.co/baidu","description":"   \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for rendered XNLI\\n\\t\\n\\n\\nThis repository contains the rendered XNLI dataset evaluated in the paper Autoregressive Pre-Training on Pixels and Texts (EMNLP 2024). For detailed instructions on how to use the model, please visit our GitHub page.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{chai2024autoregressivepretrainingpixelstexts,\\n  title = {Autoregressive Pre-Training on Pixels and Texts},\\n  author = {Chai, Yekun and Liu, Qingyi and Xiao, Jingwu and Wang, Shuohuan and Sun, Yu andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/baidu/rendered_xnli.","first_N":5,"first_N_keywords":["English","Japanese","Chinese","French","Russian"],"keywords_longer_than_N":true},
	{"name":"TW_Patent_V2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/darkpt/TW_Patent_V2","creator_name":"darkptchen","creator_url":"https://huggingface.co/darkpt","description":"darkpt/TW_Patent_V2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"mllm_pt_demo","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BUAADreamer/mllm_pt_demo","creator_name":"Zhangchi Feng","creator_url":"https://huggingface.co/BUAADreamer","description":"This dataset is a demo visual instruct dataset for LLaVA-style pre-training, with one-turn chat.\\nThen you can use it in LLaMA Factory by specifying --dataset mllm_pt_demo.\\n","first_N":5,"first_N_keywords":["visual-question-answering","Chinese","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"shibing624_alpaca-zh","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/shibing624_alpaca-zh","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"alpaca-zh\\\"\\n\\t\\n\\næœ¬æ•°æ®é›†æ˜¯å‚è€ƒAlpacaæ–¹æ³•åŸºäºGPT4å¾—åˆ°çš„self-instructæ•°æ®ï¼Œçº¦5ä¸‡æ¡ã€‚\\nDataset from https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM \\nIt is the chinese dataset from https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/blob/main/data/alpaca_gpt4_data_zh.json\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage and License Notices\\n\\t\\n\\nThe data is intended and licensed for research use only. The dataset is CC BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset shouldâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/botp/shibing624_alpaca-zh.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"aihub-kozh-translation-integrated-large-5.9m","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-large-5.9m","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Zh Translation Dataset (Integrated)\\n\\t\\n\\nAI Hubì˜ í•œ-ì¤‘ ë²ˆì—­ ê´€ë ¨ ë°ì´í„°ì…‹ 10ê°œë¥¼ ë³‘í•©í•œ ìë£Œì…ë‹ˆë‹¤. ë³‘í•© ì‹œ ì´ ë°ì´í„° ê°œìˆ˜ëŠ” 5,934,596ê°œì´ë©°, ì´ì¤‘ 10,000ê°œì˜ validation setì™€ 2,000ê°œì˜ test setê°€ ë¶„ë¦¬ë˜ì–´ ëª¨ë“  ë°ì´í„° ì‚¬ì´ì¦ˆ(large-5.9m, base-1m, small-100k)ì—ì„œ ë™ì¼í•˜ê²Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\\n\\nlarge-5.9m (train): ë³‘í•© ë°ì´í„° 100% ì‚¬ìš©; ì´ 5,922,596ê°œ\\n\\nbase-1m (train): ë³‘í•© ë°ì´í„° ì¤‘ 1Mê°œ ì‚¬ìš©; ì´ 1,000,000ê°œ\\n\\nsmall-100k (train): ë³‘í•© ë°ì´í„° ì¤‘ 100Kê°œ ì‚¬ìš©; ì´ 100,000ê°œ\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nChinese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)\\n\\n\\n\\t\\t\\ní•œêµ­ì–´-ì¤‘êµ­ì–´â€¦ See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-large-5.9m.","first_N":5,"first_N_keywords":["translation","Korean","Chinese","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"aihub-kozh-translation-integrated-base-1m","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-base-1m","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Zh Translation Dataset (Integrated)\\n\\t\\n\\nAI Hubì˜ í•œ-ì¤‘ ë²ˆì—­ ê´€ë ¨ ë°ì´í„°ì…‹ 10ê°œë¥¼ ë³‘í•©í•œ ìë£Œì…ë‹ˆë‹¤. ë³‘í•© ì‹œ ì´ ë°ì´í„° ê°œìˆ˜ëŠ” 5,934,596ê°œì´ë©°, ì´ì¤‘ 10,000ê°œì˜ validation setì™€ 2,000ê°œì˜ test setê°€ ë¶„ë¦¬ë˜ì–´ ëª¨ë“  ë°ì´í„° ì‚¬ì´ì¦ˆ(large-5.9m, base-1m, small-100k)ì—ì„œ ë™ì¼í•˜ê²Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\\n\\nlarge-5.9m (train): ë³‘í•© ë°ì´í„° 100% ì‚¬ìš©; ì´ 5,922,596ê°œ\\n\\nbase-1m (train): ë³‘í•© ë°ì´í„° ì¤‘ 1Mê°œ ì‚¬ìš©; ì´ 1,000,000ê°œ\\n\\nsmall-100k (train): ë³‘í•© ë°ì´í„° ì¤‘ 100Kê°œ ì‚¬ìš©; ì´ 100,000ê°œ\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nChinese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)\\n\\n\\n\\t\\t\\ní•œêµ­ì–´-ì¤‘êµ­ì–´â€¦ See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-base-1m.","first_N":5,"first_N_keywords":["translation","Korean","Chinese","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"aihub-kozh-translation-integrated-small-100k","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-small-100k","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Zh Translation Dataset (Integrated)\\n\\t\\n\\nAI Hubì˜ í•œ-ì¤‘ ë²ˆì—­ ê´€ë ¨ ë°ì´í„°ì…‹ 10ê°œë¥¼ ë³‘í•©í•œ ìë£Œì…ë‹ˆë‹¤. ë³‘í•© ì‹œ ì´ ë°ì´í„° ê°œìˆ˜ëŠ” 5,934,596ê°œì´ë©°, ì´ì¤‘ 10,000ê°œì˜ validation setì™€ 2,000ê°œì˜ test setê°€ ë¶„ë¦¬ë˜ì–´ ëª¨ë“  ë°ì´í„° ì‚¬ì´ì¦ˆ(large-5.9m, base-1m, small-100k)ì—ì„œ ë™ì¼í•˜ê²Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\\n\\nlarge-5.9m (train): ë³‘í•© ë°ì´í„° 100% ì‚¬ìš©; ì´ 5,922,596ê°œ\\n\\nbase-1m (train): ë³‘í•© ë°ì´í„° ì¤‘ 1Mê°œ ì‚¬ìš©; ì´ 1,000,000ê°œ\\n\\nsmall-100k (train): ë³‘í•© ë°ì´í„° ì¤‘ 100Kê°œ ì‚¬ìš©; ì´ 100,000ê°œ\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nChinese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)\\n\\n\\n\\t\\t\\ní•œêµ­ì–´-ì¤‘êµ­ì–´â€¦ See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-small-100k.","first_N":5,"first_N_keywords":["translation","Korean","Chinese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"MMEvalPro","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MM-Diagnose/MMEvalPro","creator_name":"MM-Diagnose","creator_url":"https://huggingface.co/MM-Diagnose","description":"MMEvalPro\\n\\n\\n  \\n    \\n  Â Â \\n   \\n    \\n  Â Â \\n  \\n    \\n  \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MMEvalPro\\n\\t\\n\\nWe create MMEvalPro for more accurate and efficent evaluation for Large Multimodal Models. It is designed to avoid Type-I errors through a trilogy evaluation pipeline and more rigorous metrics. For each original question from existing benchmarks, human annotators augment it by creating one perception question and one knowledge anchor question through a meticulous annotation process.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MM-Diagnose/MMEvalPro.","first_N":5,"first_N_keywords":["multiple-choice","English","Chinese","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"danbooru_wikis_full","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deepghs/danbooru_wikis_full","creator_name":"DeepGHS","creator_url":"https://huggingface.co/deepghs","description":"\\n\\t\\n\\t\\t\\n\\t\\tDanbooru Full Wiki Dataset\\n\\t\\n\\nThis is the full wiki dataset of danbooru.donmai.us, containing the wiki pages/tags/tag aliases/tag implications. You can train something like LLMs on this dataset\\n\\n\\t\\n\\t\\t\\n\\t\\tInformation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWiki Pages\\n\\t\\n\\nThere are 189161 wiki items in total. Last updated at 2024-06-16 02:31:27 UTC.\\nThese are the information of recent 50 wiki items:\\n\\n\\t\\n\\t\\t\\nid\\ntitle\\nother_names\\ntext_length\\nis_locked\\nis_deleted\\ncreated_at\\nupdated_at\\n\\n\\n\\t\\t\\n196503\\nli_yuting_(female)\\n[\\\"ç¦»é›¨å©·\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/deepghs/danbooru_wikis_full.","first_N":5,"first_N_keywords":["text-classification","text-generation","feature-extraction","no-annotation","danbooru"],"keywords_longer_than_N":true},
	{"name":"tw-processed-law-article","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lianghsun/tw-processed-law-article","creator_name":"Huang Liang Hsun","creator_url":"https://huggingface.co/lianghsun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå°ç£æ³•è¦æ³•æ¢å…§å®¹è³‡æ–™é›†\\n\\t\\n\\næœ¬å­˜å„²åº«åŒ…å«æœ‰é—œå°ç£æ³•è¦æ³•æ¢å…§å®¹çš„è³‡æ–™é›†ï¼Œé€™äº›è³‡æ–™æ˜¯é€šéä¸­è¯æ°‘åœ‹å…¨åœ‹æ³•è¦è³‡æ–™åº« API ç²å–ä¸¦ç¶“éå¾Œè™•ç†æ•´ç†è€Œæˆã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè³‡æ–™é›†æ ¼å¼\\n\\t\\n\\nè³‡æ–™é›†çš„å…§å®¹æ ¼å¼å¦‚ä¸‹ï¼š\\n{law_name} {article_no} {article_content}\\n\\nå…¶ä¸­ï¼š\\n\\n{law_name} ä»£è¡¨æ³•è¦åç¨±\\n{article_no} ä»£è¡¨æ³•æ¢ç·¨è™Ÿ\\n{article_content} ä»£è¡¨æ³•æ¢å…§å®¹\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè³‡æ–™ä¾†æº\\n\\t\\n\\nè³‡æ–™ä¾†æºæ–¼ ä¸­è¯æ°‘åœ‹å…¨åœ‹æ³•è¦è³‡æ–™åº« çš„ APIã€‚æˆ‘å€‘é€éå¾Œè™•ç†ä¾†ç¢ºä¿è³‡æ–™çš„æ•´æ½”å’Œä¸€è‡´æ€§ã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlicense: apache-2.0\\n\\t\\n\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"toxic-sft-zh","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Minami-su/toxic-sft-zh","creator_name":"å—æ –","creator_url":"https://huggingface.co/Minami-su","description":"æ•°æ®é›† unalignment/toxic-dpo-v0.2 çš„ä¸­æ–‡ç‰ˆæœ¬,å¹¶åŸºäºself-Instructå’Œevol-Instructç»§ç»­æ‰©å±•ã€‚\\nè¿™æ˜¯ä¸€ä¸ªé«˜åº¦æœ‰å®³çš„æ•°æ®é›†ï¼Œæ—¨åœ¨é€šè¿‡ä¸€äº›ç¤ºä¾‹æ¥è¯´æ˜å¦‚ä½•ä½¿ç”¨ SFT è½»æ¾åœ°å¯¹æ¨¡å‹è¿›è¡Œå»å®¡æŸ¥/å–æ¶ˆå¯¹é½ã€‚\\næ•°æ®ç”Ÿæˆä»£ç ï¼šhttps://github.com/Minami-su/character_AI_open/tree/main/toxic-Instruction\\nä½¿ç”¨é™åˆ¶è¯·å‚ç…§åŸæ•°æ®é›†çš„ Usage restrictionã€‚\\n\\n","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"VCR-wiki-zh-hard","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-hard","creator_name":"VCR","creator_url":"https://huggingface.co/vcr-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe VCR-Wiki Dataset for Visual Caption Restoration (VCR)\\n\\t\\n\\nğŸ  Paper | ğŸ‘©ğŸ»â€ğŸ’» GitHub | ğŸ¤— Huggingface Datasets | ğŸ“ Evaluation with lmms-eval\\nThis is the official Hugging Face dataset for VCR-Wiki, a dataset for the Visual Caption Restoration (VCR) task.\\nVCR is designed to measure vision-language models' capability to accurately restore partially obscured texts using pixel-level hints within images. text-based processing becomes ineffective in VCR as accurate text restorationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-hard.","first_N":5,"first_N_keywords":["visual-question-answering","wikimedia/wit_base","Chinese","cc-by-sa-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"VCR-wiki-zh-easy","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-easy","creator_name":"VCR","creator_url":"https://huggingface.co/vcr-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe VCR-Wiki Dataset for Visual Caption Restoration (VCR)\\n\\t\\n\\nğŸ  Paper | ğŸ‘©ğŸ»â€ğŸ’» GitHub | ğŸ¤— Huggingface Datasets | ğŸ“ Evaluation with lmms-eval\\nThis is the official Hugging Face dataset for VCR-Wiki, a dataset for the Visual Caption Restoration (VCR) task.\\nVCR is designed to measure vision-language models' capability to accurately restore partially obscured texts using pixel-level hints within images. text-based processing becomes ineffective in VCR as accurate text restorationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-easy.","first_N":5,"first_N_keywords":["visual-question-answering","wikimedia/wit_base","Chinese","cc-by-sa-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"stockDaily","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BensonVast/stockDaily","creator_name":"xuzhunheng","creator_url":"https://huggingface.co/BensonVast","description":"BensonVast/stockDaily dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"sv","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lucky/sv","creator_name":"yu","creator_url":"https://huggingface.co/lucky","description":"lucky/sv dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","gpl-3.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"M3GIA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Songweii/M3GIA","creator_name":"Wei Song","creator_url":"https://huggingface.co/Songweii","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tM3GIA: A Cognition Inspired Multilingual and Multimodal General Intelligence Ability\\n\\t\\n\\n[ğŸŒ Homepage] | ğŸ¤— Dataset | ğŸ¤— Paper | ğŸ“– arXiv | ğŸ’» GitHub\\nThe evaluation code can be found in ğŸ’» GitHub.\\n[Abstract]\\nAs recent multi-modality large language models (MLLMs) have shown formidable proficiency on various complex tasks, there has been increasing attention on debating whether these models could eventually mirror human intelligence. However, existing benchmarks mainly focus onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Songweii/M3GIA.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"HBK08-subtitles","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hammershock/HBK08-subtitles","creator_name":"Hanmo Zhang","creator_url":"https://huggingface.co/hammershock","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHBK08-subtitles\\n\\t\\n\\n2024-05-26ä¹‹å‰çº¢è­¦HBK08æ‰€æœ‰è§†é¢‘çš„æ•°æ®é›†ï¼Œæ•°æ®æ¥æºäºç½‘ç»œçˆ¬è™«\\n\\nmetadata.tsv: è§†é¢‘å…ƒæ•°æ®: åŒ…æ‹¬urlï¼Œbvid, UPä¸»ï¼Œæ ‡é¢˜ï¼Œæ’­æ”¾é‡ï¼Œæ—¥æœŸï¼Œæ—¶é•¿ï¼›\\nraw_data.json: åŸå§‹è§†é¢‘å­—å¹•ä¿¡æ¯\\ntext_cut.json: æ–‡æœ¬åˆ†å‰²æ ‡æ³¨ï¼Œæ ‡è®°äº†å……ç”µæŠ•å¸æ„Ÿè°¢ï¼Œä»¥åŠè§†é¢‘ä¸­å‡ºç°çš„å¹¿å‘Š\\n<begin>: æ­£æ–‡å¼€å§‹\\n<ad_begin>: å¹¿å‘Šå¼€å§‹\\n<ad_end>: å¹¿å‘Šç»“æŸ\\n[discarded]: æ ‡è®°è¿™ä¸ªæ–‡æ¡£è¢«ä¸¢å¼ƒ\\n\\n\\nad_key_words.txt: å¹¿å‘Šå…³é”®è¯\\ncorrected_data.tsv: ç²—ç•¥æ¸…æ´—çš„æ–‡æœ¬æ•°æ®\\nä¸»è¦é‡‡ç”¨æ–‡æœ¬æ›¿æ¢+å°‘é‡äººå·¥æ ¡å¯¹æ›¿æ¢é”™è¯¯çš„å­—å¹•\\nå°‘é‡ä»¥[verified]æ ‡ç­¾å¼€å¤´çš„ç»è¿‡äº†äººå·¥å¬å†™æ ¡å¯¹\\n\\n\\n\\n","first_N":5,"first_N_keywords":["text-generation","text2text-generation","text-classification","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"Chatgpt","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"tiny-supervised-dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/tiny-supervised-dataset","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"llamafactory/tiny-supervised-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"synthetic_multilingual_llm_prompts","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","description":"\\n  \\n  Image generated by DALL-E. See prompt for more details\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸ“ğŸŒ Synthetic Multilingual LLM Prompts\\n\\t\\n\\nWelcome to the \\\"Synthetic Multilingual LLM Prompts\\\" dataset! This comprehensive collection features 1,250 synthetic LLM prompts generated using Gretel Navigator, available in seven different languages. To ensure accuracy and diversity in prompts, and translation quality and consistency across the different languages, we employed Gretel Navigator both as a generation tool and asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts.","first_N":5,"first_N_keywords":["text-generation","translation","question-answering","English","Dutch"],"keywords_longer_than_N":true},
	{"name":"VCR-wiki-zh-hard-test-100","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-hard-test-100","creator_name":"VCR","creator_url":"https://huggingface.co/vcr-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe VCR-Wiki Dataset for Visual Caption Restoration (VCR)\\n\\t\\n\\nğŸ  Paper | ğŸ‘©ğŸ»â€ğŸ’» GitHub | ğŸ¤— Huggingface Datasets | ğŸ“ Evaluation with lmms-eval\\nThis is the official Hugging Face dataset for VCR-Wiki, a dataset for the Visual Caption Restoration (VCR) task.\\nVCR is designed to measure vision-language models' capability to accurately restore partially obscured texts using pixel-level hints within images. text-based processing becomes ineffective in VCR as accurate text restorationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-hard-test-100.","first_N":5,"first_N_keywords":["visual-question-answering","wikimedia/wit_base","Chinese","cc-by-sa-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"VCR-wiki-zh-hard-test-500","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-hard-test-500","creator_name":"VCR","creator_url":"https://huggingface.co/vcr-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe VCR-Wiki Dataset for Visual Caption Restoration (VCR)\\n\\t\\n\\nğŸ  Paper | ğŸ‘©ğŸ»â€ğŸ’» GitHub | ğŸ¤— Huggingface Datasets | ğŸ“ Evaluation with lmms-eval\\nThis is the official Hugging Face dataset for VCR-Wiki, a dataset for the Visual Caption Restoration (VCR) task.\\nVCR is designed to measure vision-language models' capability to accurately restore partially obscured texts using pixel-level hints within images. text-based processing becomes ineffective in VCR as accurate text restorationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-hard-test-500.","first_N":5,"first_N_keywords":["visual-question-answering","wikimedia/wit_base","Chinese","cc-by-sa-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"VCR-wiki-zh-hard-test","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-hard-test","creator_name":"VCR","creator_url":"https://huggingface.co/vcr-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe VCR-Wiki Dataset for Visual Caption Restoration (VCR)\\n\\t\\n\\nğŸ  Paper | ğŸ‘©ğŸ»â€ğŸ’» GitHub | ğŸ¤— Huggingface Datasets | ğŸ“ Evaluation with lmms-eval\\nThis is the official Hugging Face dataset for VCR-Wiki, a dataset for the Visual Caption Restoration (VCR) task.\\nVCR is designed to measure vision-language models' capability to accurately restore partially obscured texts using pixel-level hints within images. text-based processing becomes ineffective in VCR as accurate text restorationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-hard-test.","first_N":5,"first_N_keywords":["visual-question-answering","wikimedia/wit_base","Chinese","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"VCR-wiki-zh-easy-test","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-easy-test","creator_name":"VCR","creator_url":"https://huggingface.co/vcr-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe VCR-Wiki Dataset for Visual Caption Restoration (VCR)\\n\\t\\n\\nğŸ  Paper | ğŸ‘©ğŸ»â€ğŸ’» GitHub | ğŸ¤— Huggingface Datasets | ğŸ“ Evaluation with lmms-eval\\nThis is the official Hugging Face dataset for VCR-Wiki, a dataset for the Visual Caption Restoration (VCR) task.\\nVCR is designed to measure vision-language models' capability to accurately restore partially obscured texts using pixel-level hints within images. text-based processing becomes ineffective in VCR as accurate text restorationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-easy-test.","first_N":5,"first_N_keywords":["visual-question-answering","wikimedia/wit_base","Chinese","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"VCR-wiki-zh-easy-test-500","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-easy-test-500","creator_name":"VCR","creator_url":"https://huggingface.co/vcr-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe VCR-Wiki Dataset for Visual Caption Restoration (VCR)\\n\\t\\n\\nğŸ  Paper | ğŸ‘©ğŸ»â€ğŸ’» GitHub | ğŸ¤— Huggingface Datasets | ğŸ“ Evaluation with lmms-eval\\nThis is the official Hugging Face dataset for VCR-Wiki, a dataset for the Visual Caption Restoration (VCR) task.\\nVCR is designed to measure vision-language models' capability to accurately restore partially obscured texts using pixel-level hints within images. text-based processing becomes ineffective in VCR as accurate text restorationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-easy-test-500.","first_N":5,"first_N_keywords":["visual-question-answering","wikimedia/wit_base","Chinese","cc-by-sa-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"VCR-wiki-zh-easy-test-100","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-easy-test-100","creator_name":"VCR","creator_url":"https://huggingface.co/vcr-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe VCR-Wiki Dataset for Visual Caption Restoration (VCR)\\n\\t\\n\\nğŸ  Paper | ğŸ‘©ğŸ»â€ğŸ’» GitHub | ğŸ¤— Huggingface Datasets | ğŸ“ Evaluation with lmms-eval\\nThis is the official Hugging Face dataset for VCR-Wiki, a dataset for the Visual Caption Restoration (VCR) task.\\nVCR is designed to measure vision-language models' capability to accurately restore partially obscured texts using pixel-level hints within images. text-based processing becomes ineffective in VCR as accurate text restorationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-easy-test-100.","first_N":5,"first_N_keywords":["visual-question-answering","wikimedia/wit_base","Chinese","cc-by-sa-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"RoleAgentBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RoleAgent/RoleAgentBench","creator_name":"RoleAgent","creator_url":"https://huggingface.co/RoleAgent","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRoleAgentBench\\n\\t\\n\\n\\nPaper: RoleAgent: Building, Interacting, and Benchmarking High-quality Role-Playing Agents from Scripts\\n\\nWe construct the RoleAgentBench including 128 roles from 5 Chinese and 20 English scripts. Besides, our RoleAgentBench evaluates two aspects (i.e., the qualities of the overall agent simulation and the specific memory system) with 4 subtasks, details as follows. Note that all questions and answers are generated based on the script and GPT-4, which are thenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RoleAgent/RoleAgentBench.","first_N":5,"first_N_keywords":["question-answering","summarization","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"BLEnD","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayeon212/BLEnD","creator_name":"Nayeon Lee","creator_url":"https://huggingface.co/nayeon212","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLEnD\\n\\t\\n\\nThis is the official repository of BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages (Submitted to NeurIPS 2024 Datasets and Benchmarks Track).\\n24/12/05: Updated translation errors\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout\\n\\t\\n\\n\\nLarge language models (LLMs) often lack culture-specific everyday knowledge, especially across diverse regions and non-English languages. Existing benchmarks for evaluating LLMs' cultural sensitivities are usually limited to a singleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nayeon212/BLEnD.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","Spanish","Indonesian"],"keywords_longer_than_N":true},
	{"name":"CaLMQA","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shanearora/CaLMQA","creator_name":"Shane Arora","creator_url":"https://huggingface.co/shanearora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\n\\nCaLMQA is a long-form question answering (LFQA) dataset spanning 23 high- to low-resource languages. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCaLMQA is an LFQA dataset with 2K questions from 23 languages, 11 high- to mid-resource and 12 low-resource.\\nQuestions are either culturally specific â€“ uniquely or more likely to be asked by people of a specific\\nculture â€“ or culturally agnostic (not culturally specific). These questions wereâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shanearora/CaLMQA.","first_N":5,"first_N_keywords":["multilingual","Afar","Arabic","Baluchi","German"],"keywords_longer_than_N":true},
	{"name":"neo_sft_phase2_single","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/REILX/neo_sft_phase2_single","creator_name":"SunForlight","creator_url":"https://huggingface.co/REILX","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdataset\\n\\t\\n\\nThe original dataset can be found at: https://huggingface.co/datasets/m-a-p/neo_sft_phase2\\nUse the following code to select two-turn conversations for your SFT dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcode\\n\\t\\n\\nimport json\\ndef process_conversations(input_file, output_file):\\n    with open(input_file, 'r', encoding='utf-8') as f_in, \\\\\\n         open(output_file, 'w', encoding='utf-8') as f_out:\\n        data = json.load(f_in)\\n        \\n        for item in data:\\n            conversations =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/REILX/neo_sft_phase2_single.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MedQAExplain","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Whliuyu/MedQAExplain","creator_name":"yu","creator_url":"https://huggingface.co/Whliuyu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMedQAExplain Dataset\\n\\t\\n\\nThe MedQAExplain dataset is a benchmark dataset designed to evaluate the performance of explainer models in the medical question-answering domain. This dataset focuses on open-ended medical QA scenarios and incorporates a scalable and efficient dataset construction pipeline that leverages large language models (LLMs).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Preview\\n\\t\\n\\nAs our manuscript is currently under review, our work may have some areas that need improvement. Therefore, weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Whliuyu/MedQAExplain.","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"neo_sft_phase2_conversations","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/REILX/neo_sft_phase2_conversations","creator_name":"SunForlight","creator_url":"https://huggingface.co/REILX","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1. The original dataset can be found at:\\n\\t\\n\\nhttps://huggingface.co/datasets/m-a-p/neo_sft_phase2\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2. Split multi-turn conversations into individual single-turn samples\\n\\t\\n\\nApproach: Treat each round of dialogue as an independent question-and-answer pair, and construct the sample using contextual information.\\nSpecific operations:\\n\\nFor each \\\"conversations\\\", iterate through each round of dialogue.\\nConcatenate the \\\"value\\\" of the current \\\"human\\\" round with the dialogue fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/REILX/neo_sft_phase2_conversations.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"haiguitang","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lpj990/haiguitang","creator_name":"panjunliu","creator_url":"https://huggingface.co/lpj990","description":"lpj990/haiguitang dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"llama2_7B_data_Course_materials","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2imi9/llama2_7B_data_Course_materials","creator_name":"Ziming Qi","creator_url":"https://huggingface.co/2imi9","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is designed to support a teaching assistance model for an introductory computer science course. It includes structured content such as course syllabi, lesson plans, lecture materials, and exercises related to topics such as computer fundamentals, algorithms, hardware, software, and IT technologies. The dataset integrates practical assignments, theoretical knowledge, and ethical education, aiming to enhance teaching efficiency and improve studentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2imi9/llama2_7B_data_Course_materials.","first_N":5,"first_N_keywords":["question-answering","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"bitext_nusax_miners","keyword":"achinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_nusax_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_nusax_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Achinese","Balinese","Batak Toba","Banjar","Buginese"],"keywords_longer_than_N":true},
	{"name":"MELA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Geralt-Targaryen/MELA","creator_name":"Ziyin Zhang","creator_url":"https://huggingface.co/Geralt-Targaryen","description":"See the GitHub repo for details.\\n","first_N":5,"first_N_keywords":["text-classification","English","Chinese","Italian","Russian"],"keywords_longer_than_N":true},
	{"name":"neo_sft_phase2_multi","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/REILX/neo_sft_phase2_multi","creator_name":"SunForlight","creator_url":"https://huggingface.co/REILX","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1. The original dataset can be found at:\\n\\t\\n\\nhttps://huggingface.co/datasets/m-a-p/neo_sft_phase2\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2. Split multi-turn conversations into individual single-turn samples\\n\\t\\n\\nApproach: Treat each round of dialogue as a separate question-and-answer pair, and construct the sample by leveraging the contextual information.\\nSpecific Operations:\\n\\nFor each \\\"conversation,\\\" iterate through all the dialogue rounds.\\nConcatenate the \\\"value\\\" of all \\\"human\\\" turns within eachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/REILX/neo_sft_phase2_multi.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"scholaread","keyword":"chinese","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huangqingming/scholaread","creator_name":"huangqingming","creator_url":"https://huggingface.co/huangqingming","description":"huangqingming/scholaread dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Chinese","English","agpl-3.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"ChemGPT-from-book","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ALmonster/ChemGPT-from-book","creator_name":"The little monster will smile","creator_url":"https://huggingface.co/ALmonster","description":"ALmonster/ChemGPT-from-book dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"CLCC_v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FlagEval/CLCC_v1","creator_name":"FlagEval","creator_url":"https://huggingface.co/FlagEval","description":"CLCC is a Chinese Linguistics & Cognition Challenge dataset, which is created by FlagEval team (https://flageval.baai.ac.cn/#/home).\\nThe details can be found in (https://flageval.baai.ac.cn/#/taskIntro?t=zh_oqa)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEvaluate\\n\\t\\n\\nThe results can evaluated by human or our judgeLLM (https://huggingface.co/FlagEval/flageval_judgemodel).\\n","first_N":5,"first_N_keywords":["question-answering","text2text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"achinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"mandarin chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"yue chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"openGov","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/QianyueWang/openGov","creator_name":"ç‹éªç¥","creator_url":"https://huggingface.co/QianyueWang","description":"\\n\\t\\n\\t\\t\\n\\t\\t2020-2024å¹´å…¬å¼€å¹³å°å‘å¸ƒæ”¿åŠ¡ä¿¡æ¯åˆé›†\\n\\t\\n\\nè¿™æ˜¯è®ºæ–‡ã€ŠåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¯ä¿¡æ”¿åŠ¡é—®ç­”æŠ€æœ¯ã€‹ä½¿ç”¨çš„æ•°æ®é›†ã€‚å…·ä½“å†…å®¹å’Œæ•°æ®ç»“æ„ç¤ºæ„å›¾åœ¨filesæ ç›®ä¸­ã€‚\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"BP_POC","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/suanan/BP_POC","creator_name":"anan","creator_url":"https://huggingface.co/suanan","description":"dataset_info:\\n  features:\\n    - name: _id\\n      dtype: string\\n    - name: url\\n      dtype: string\\n    - name: title\\n      dtype: string\\n    - name: text\\n      dtype: string\\n  splits:\\n    - name: train\\nconfigs:\\n\\nconfig_name: train\\ndata_files:\\nsplit: train\\npath: data/train-*\\n\\n\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"yue chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"icd9cm3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Johmmyyyy/icd9cm3","creator_name":"Yi Zhang","creator_url":"https://huggingface.co/Johmmyyyy","description":"Johmmyyyy/icd9cm3 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ğŸ§¡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"achinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ğŸ§¡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"yue chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ğŸ§¡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"SingMOS_v1","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TangRain/SingMOS_v1","creator_name":"Tang","creator_url":"https://huggingface.co/TangRain","description":"paper link: SingMOS: An extensive Open-Source Singing Voice Dataset for MOS Prediction\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nSingMOS-v1 includes 3,421 Chinese and Japanese vocal clips with a sample rate of 16 kHz, totaling 4.25 hours in duration.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSingMOS arichitecture\\n\\t\\n\\n|---SingMOS-v1\\n    |---sets\\n        |---train.txt\\n        |---dev.txt\\n        |---test-main.txt\\n        |---test-other1.txt\\n    |---wav\\n        |---sys0001-utt0001.wav\\n        ...\\n    |---metadata.csv\\n    |---system_info.txtâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TangRain/SingMOS_v1.","first_N":5,"first_N_keywords":["Chinese","Japanese","cc-by-4.0","100M<n<1B","arxiv:2406.10911"],"keywords_longer_than_N":true},
	{"name":"character-ai-open2.0","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aifeifei798/character-ai-open2.0","creator_name":"aifeifei","creator_url":"https://huggingface.co/aifeifei798","description":"https://huggingface.co/datasets/Minami-su/character-ai-open2.0\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Chinese-Braille-Dataset-No-Tone","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-No-Tone","creator_name":"ALanWu","creator_url":"https://huggingface.co/Violet-yo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Braille Dataset (No Tone)\\n\\t\\n\\n\\n  ğŸ“ƒ [Paper] â€¢ ğŸ’» [Github] â€¢ ğŸ¤— [Dataset] â€¢ âš™ï¸ [Model] â€¢ ğŸ¬ [Demo]\\n\\n\\nThis dataset is the Chinese-Braille-Dataset-No-Tone dataset described in https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\n# Sample\\nBraille Len. (Mean/Median) String\\nBraille Len. (Mean/Median) Token\\nChinese Len. (Mean/Median) String\\nChinese Len. (Mean/Median) Token\\n\\n\\n\\t\\t\\nTraining\\n525072\\n140/108\\n144/112\\n74/64â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-No-Tone.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Chinese-Braille-Dataset-No-Tone","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-No-Tone","creator_name":"ALanWu","creator_url":"https://huggingface.co/Violet-yo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Braille Dataset (No Tone)\\n\\t\\n\\n\\n  ğŸ“ƒ [Paper] â€¢ ğŸ’» [Github] â€¢ ğŸ¤— [Dataset] â€¢ âš™ï¸ [Model] â€¢ ğŸ¬ [Demo]\\n\\n\\nThis dataset is the Chinese-Braille-Dataset-No-Tone dataset described in https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\n# Sample\\nBraille Len. (Mean/Median) String\\nBraille Len. (Mean/Median) Token\\nChinese Len. (Mean/Median) String\\nChinese Len. (Mean/Median) Token\\n\\n\\n\\t\\t\\nTraining\\n525072\\n140/108\\n144/112\\n74/64â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-No-Tone.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Chinese-Braille-Dataset-10per-Tone","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone","creator_name":"ALanWu","creator_url":"https://huggingface.co/Violet-yo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Braille Dataset\\n\\t\\n\\n\\n  ğŸ“ƒ [Paper] â€¢ ğŸ’» [Github] â€¢ ğŸ¤— [Dataset] â€¢ âš™ï¸ [Model] â€¢ ğŸ¬ [Demo]\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Chinese-Braille-10per-Tone dataset addresses the scarcity of publicly available Chinese Braille datasets. The original Chinese text data was sourced from the publicly available Leipzig Corpora Collection. This dataset consists of one million discrete sentences collected from news media between 2007 and 2009.\\nThe Chinese characters from the Leipzigâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Chinese-Braille-Dataset-10per-Tone","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone","creator_name":"ALanWu","creator_url":"https://huggingface.co/Violet-yo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Braille Dataset\\n\\t\\n\\n\\n  ğŸ“ƒ [Paper] â€¢ ğŸ’» [Github] â€¢ ğŸ¤— [Dataset] â€¢ âš™ï¸ [Model] â€¢ ğŸ¬ [Demo]\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Chinese-Braille-10per-Tone dataset addresses the scarcity of publicly available Chinese Braille datasets. The original Chinese text data was sourced from the publicly available Leipzig Corpora Collection. This dataset consists of one million discrete sentences collected from news media between 2007 and 2009.\\nThe Chinese characters from the Leipzigâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"ASCEND-phoneme","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/katyayego/ASCEND-phoneme","creator_name":"Katya Yegorova","creator_url":"https://huggingface.co/katyayego","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a modified version of the ASCEND dataset which consists of spontaneous Mandarin-English code-switched speech. The ASCEND dataset was published by Lovenia et al. (2022) (Check here for the dataset and here for the paper). \\nThis dataset adds a phonetic transcription column to the dataset using the eSpeak backend from the phonemizer library created by Bernard et al. (2021) (Check it out here).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tthe following documentation is a modifiedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/katyayego/ASCEND-phoneme.","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","Chinese","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"hf-first","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kenu/hf-first","creator_name":"Kenu Gwangnam Heo","creator_url":"https://huggingface.co/kenu","description":"kenu/hf-first dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","Korean","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"OceanInstruct","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zjunlp/OceanInstruct","creator_name":"ZJUNLP","creator_url":"https://huggingface.co/zjunlp","description":"We release OceanInstruct, which is part of the instruction data for training OceanGPT.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸ› ï¸ How to use OceanInstruct\\n\\t\\n\\nWe provide the example and you can modify the input according to your needs.\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"zjunlp/OceanInstruct\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸš©Citation\\n\\t\\n\\nPlease cite the following paper if you use OceanInstruct in your work.\\n@article{bi2023oceangpt,\\n  title={OceanGPT: A Large Language Model for Ocean Science Tasks},\\n  author={Bi, Zhenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zjunlp/OceanInstruct.","first_N":5,"first_N_keywords":["English","Chinese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"assembly","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kenu/assembly","creator_name":"Kenu Gwangnam Heo","creator_url":"https://huggingface.co/kenu","description":"kenu/assembly dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","Japanese","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"CBBQ","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/walledai/CBBQ","creator_name":"Walled AI","creator_url":"https://huggingface.co/walledai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCBBQ\\n\\t\\n\\nDatasets and codes for the paper \\\"CBBQ: A Chinese Bias Benchmark Dataset Curated with Human-AI Collaboration for Large Language Models\\\"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nAbstract: The growing capabilities of large language models (LLMs) call for rigorous scrutiny to holistically measure societal biases and ensure ethical deployment. To this end, we present the Chinese Bias Benchmark dataset (CBBQ), a resource designed to detect the ethical risks associated with deploying highlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/walledai/CBBQ.","first_N":5,"first_N_keywords":["Chinese","cc-by-sa-4.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"CPAD","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/walledai/CPAD","creator_name":"Walled AI","creator_url":"https://huggingface.co/walledai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCPAD\\n\\t\\n\\nThe official dataset of paper \\\"Goal-Oriented Prompt Attack and Safety Evaluation for LLMs\\\".\\nAbstract: Large Language Models (LLMs) presents significant priority in text understanding and generation. However, LLMs suffer from the risk of generating harmful contents especially while being employed to applications. There are several black-box attack methods, such as Prompt Attack, which can change the behaviour of LLMs and induce LLMs to generate unexpected answers withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/walledai/CPAD.","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"ascii_art_generation_140k_bilingual","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/ascii_art_generation_140k_bilingual","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData for LLM ASCII Art\\n\\t\\n\\nThis repo contains open-sourced SFT data for fine-tuning LLMs on ASCII Art Generation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Links\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nLink\\nLanguage\\nSize\\n\\n\\n\\t\\t\\nascii_art_generation_140k\\nEnglish\\n138,941\\n\\n\\nascii_art_generation_140k_bilingual\\nChinese & English\\n138,941\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Preparation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTraining data description\\n\\t\\n\\nThe training data consists of 138,941 ASCII arts instruction-response samples for LLMs to perform SFT.\\nThe source images of theseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/ascii_art_generation_140k_bilingual.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"Legal-Mind-Mix-160K","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aigrant/Legal-Mind-Mix-160K","creator_name":"AI Grant","creator_url":"https://huggingface.co/aigrant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè³‡æ–™é›†èªªæ˜\\n\\t\\n\\n\\næœ¬è³‡æ–™é‹ç”¨æ˜¯é‡å°æˆ‘å€‘è—‰ç”±GPT4èˆ‡ä¸€äº›å®¶äº‹èˆ‡å‹è¨´æ¡ˆä»¶åˆ†ç¾¤è³‡æ–™æ•´ç†è€Œæˆçš„ä¸€ä»½æé«˜æ¨¡å‹æ³•å¾‹é ˜åŸŸæ•ˆæœçš„æŒ‡ä»¤å¾®èª¿è³‡æ–™ã€‚\\næº–å‚™çš„è³‡æ–™ä¸»è¦æ˜¯åˆ†ç¾¤èˆ‡æ‘˜è¦ä»»å‹™ï¼Œâ€œth10-100kâ€ç‚ºå‹å‹•è¨´è¨Ÿçˆ­é»ç›¸ä¼¼èˆ‡å¦ä¹‹é…å°ï¼Œâ€œjudgment-summary-10kâ€ç‚ºè©æ¬ºæ¡ˆä»¶ä¹‹æ¡ˆä»¶äº‹å¯¦æ‘˜è¦èˆ‡åŸæ–‡é…å°ã€‚\\nä½†ç‚ºé¿å…å½±éŸ¿åˆ°å¤ªå¤šæ™®éæ€§çš„å›ç­”èƒ½åŠ›ï¼Œæœ¬è³‡æ–™é›†æ··åˆäº†ä¸€äº›å…¬é–‹çš„å°è©±è³‡æ–™ä»¥æé«˜æˆ–ç¶­æŒå¤§éƒ¨åˆ†ä»»å‹™çš„æ•ˆæœã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè³‡æ–™ä¾†æº\\n\\t\\n\\n\\nå¸æ³•é™¢å…¬é–‹è³‡æ–™ç¶²\\nTaiwanLLM\\nALPACA-50k\\ndolly-15k\\n\\n","first_N":5,"first_N_keywords":["summarization","text2text-generation","text-classification","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MathCheck","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PremiLab-Math/MathCheck","creator_name":"PremiLab-Math","creator_url":"https://huggingface.co/PremiLab-Math","description":"Exceptional mathematical reasoning ability is one of the key features that demonstrate the power of large language models (LLMs). How to comprehensively\\ndefine and evaluate the mathematical abilities of LLMs, and even reflect the user\\nexperience in real-world scenarios, has emerged as a critical issue. Current benchmarks predominantly concentrate on problem-solving capabilities, which presents\\na substantial risk of model overfitting and fails to accurately represent genuine\\nmathematicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PremiLab-Math/MathCheck.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","text-generation","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"B2NERD","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Umean/B2NERD","creator_name":"Yuming Yang","creator_url":"https://huggingface.co/Umean","description":"\\n\\t\\n\\t\\t\\n\\t\\tB2NER\\n\\t\\n\\nWe present B2NERD, a cohesive and efficient dataset that can improve LLMs' generalization on the challenging Open NER task, refined from 54 existing English or Chinese datasets. \\nOur B2NER models, trained on B2NERD, outperform GPT-4 by 6.8-12.0 F1 points and surpass previous methods in 3 out-of-domain benchmarks across 15 datasets and 6 languages.\\n\\nğŸ“– Paper: Beyond Boundaries: Learning a Universal Entity Taxonomy across Datasets and Languages for Open Named Entity Recognitionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Umean/B2NERD.","first_N":5,"first_N_keywords":["English","Chinese","mit","arxiv:2406.11192","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"game_translate","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wukuili/game_translate","creator_name":"Davence","creator_url":"https://huggingface.co/wukuili","description":"wukuili/game_translate dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \\nBibTex\\n@misc{lu2024languagecountslearnunlearn,\\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \\n      author={Taiming Lu and Philipp Koehn},\\n      year={2024},\\n      eprint={2406.13748},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2406.13748}, \\n}\\n\\n","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"hutao-audio","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lissette/hutao-audio","creator_name":"kuon","creator_url":"https://huggingface.co/lissette","description":"åŸç¥çš„èƒ¡æ¡ƒè¯­éŸ³æ•°æ®\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"qa-br-quiest","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MarkChiing/qa-br-quiest","creator_name":"Hong","creator_url":"https://huggingface.co/MarkChiing","description":"MarkChiing/qa-br-quiest dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ruozhiba_twp","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Honing/ruozhiba_twp","creator_name":"HaoJenLo","creator_url":"https://huggingface.co/Honing","description":"Honing/ruozhiba_twp dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"qiqi-audio","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lissette/qiqi-audio","creator_name":"kuon","creator_url":"https://huggingface.co/lissette","description":"lissette/qiqi-audio dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"example_mmdata_mnbvc","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracleyin/example_mmdata_mnbvc","creator_name":"yin zhang","creator_url":"https://huggingface.co/miracleyin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmnbvc mm dataset v2.0\\n\\t\\n\\nMNBVC å¤šæ¨¡æ€è¯­æ–™æ•°æ®æ ¼å¼ã€‚åŸé“¾æ¥ï¼šhttps://huggingface.co/datasets/wanng/example_mmdata_mnbvc\\n\\n\\t\\n\\t\\t\\nå­—æ®µåç§°\\nå­—æ®µè¯´æ˜\\nå¯é€‰\\n\\n\\n\\t\\t\\nå®ä½“ID\\næ•°æ®çš„å”¯ä¸€æ ‡è¯†ç¬¦ã€‚ç”¨äºåœ¨æ•°æ®é›†ä¸­ç¡®å®šæ˜¯å“ªä¸€æ¡æ•°æ®ã€‚åœ¨å•ä¸ªæ•°æ®é›†ä¸­ç¡®å®šä¸€æ¡æ•°æ®çš„å®ä½“å¯¹è±¡ã€‚\\nå¿…é€‰\\n\\n\\nå—ID\\nä¸€ä¸ªå®ä½“å¯¹è±¡å†…çš„æ ‡è¯†ç¬¦ã€‚ç”¨äºç¡®å®šä¸€æ¡æ•°æ®å†…çš„ä¸€ä¸ªéƒ¨åˆ†æ•°æ®ã€‚parquet è¡Œçš„æœ€å°å•å…ƒã€‚\\nå¿…é€‰\\n\\n\\næ—¶é—´\\nè¯­æ–™é¦–æ¬¡å‡ºç°çš„æ—¶é—´ï¼Œå¦‚æ— æ³•ç¡®å®šåˆ™ä¸ºå¤„ç†è¯¥æ•°æ®å®ä½“çš„æ—¶é—´\\nå¿…é€‰\\n\\n\\næ‰©å±•å­—æ®µ\\nç”¨äºä¿å­˜å—çš„å…ƒä¿¡æ¯ã€‚ä¸ºå¯ä»¥è¢«æˆåŠŸ load çš„ json å­—ç¬¦ä¸²ã€‚åæœŸå¯ç»§ç»­æ‰©å±•\\nå¿…é€‰\\n\\n\\næ–‡æœ¬\\næ–‡æœ¬å—çš„å†…å®¹\\nå¿…é€‰\\n\\n\\nå›¾ç‰‡\\nå›¾ç‰‡å—çš„å†…å®¹\\nå¿…é€‰\\n\\n\\nOCRæ–‡æœ¬\\nå›¾ç‰‡çš„ OCR ç»“æœ\\nå¿…é€‰\\n\\n\\néŸ³é¢‘\\néŸ³é¢‘å—çš„å†…å®¹\\nå¿…é€‰\\n\\n\\nSTTæ–‡æœ¬\\néŸ³é¢‘çš„ STT ç»“æœ\\nå¿…é€‰\\n\\n\\nå—ç±»å‹\\nç”¨äºä¿å­˜å—çš„ç±»åˆ«ã€‚ä¸ºå­—ç¬¦ä¸²ï¼Œä½¿ç”¨è¯¥ç±»å‹å¯ä»¥ä»å†…å®¹ä¸­æå–å¯¹åº”ä¿¡æ¯ã€‚ç±»åˆ«çš„å«ä¹‰ä¸ºâ€œæ¨¡æ€â€ã€‚\\nå¿…é€‰\\n\\n\\næ–‡ä»¶md5\\nå½“ entity/blcokâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/miracleyin/example_mmdata_mnbvc.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"liaozhai-zhiyi","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CoolSpring/liaozhai-zhiyi","creator_name":"CoolSpring","creator_url":"https://huggingface.co/CoolSpring","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for liaozhai-zhiyi\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis dataset contains 493 stories from the book Liaozhai Zhiyi (also known as Strange Tales from a Chinese Studio), a collection of supernatural tales written by Pu Songling during the Qing dynasty. The stories were exported from Wikisource and processed into a structured format.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nTraditional Chinese\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nEach instance in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CoolSpring/liaozhai-zhiyi.","first_N":5,"first_N_keywords":["Chinese","cc-by-sa-4.0","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"Chinese_interactive_novels_3k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/Chinese_interactive_novels_3k","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä¸­æ–‡äº’åŠ¨å°è¯´ç»“æ„åŒ–è¯­æ–™\\n\\t\\n\\nThis dataset contains uncleaned (!) 3534 structured Chinese interactive novels (ä¸­æ–‡äº’åŠ¨å°è¯´), accounting for around 0.25B (gpt-3.5) tokens in total.\\nAll contents are parsed from certain online sources.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThis dataset can be potentially used for LLM training. But be aware that you'd better clean the data yourself to remove undesired low-quality contents.\\nEach novel is a dict structured as follows:\\nclass Novel:\\n    book_title: str\\n    book_author: strâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/Chinese_interactive_novels_3k.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","arrow"],"keywords_longer_than_N":true},
	{"name":"smart_home_control","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Charles95/smart_home_control","creator_name":"JingXiang","creator_url":"https://huggingface.co/Charles95","description":"Charles95/smart_home_control dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"genrescoh","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Johndfm/genrescoh","creator_name":"John MendonÃ§a","creator_url":"https://huggingface.co/Johndfm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GenResCoh\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGenResCoh is a collection of positive and negative responses focused on coherence. It is generated using GPT-3.5-Turbo and GPT-4, and contains over 130k responses in different languages (English, French, German, Italian, and Chinese), together with their corresponding explanations (in English).\\nGenResCoh was used to train the ECoh family of models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nEnglish\\nGerman\\nItalian\\nFrench\\nChineseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Johndfm/genrescoh.","first_N":5,"first_N_keywords":["English","German","Italian","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"PromisedChat_Instruction","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/netmouse/PromisedChat_Instruction","creator_name":"Matt Yeh","creator_url":"https://huggingface.co/netmouse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Alpaca-Cleaned\\n\\t\\n\\n\\nRepository: https://github.com/gururise/AlpacaDataCleaned\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a cleaned version of the original Alpaca Dataset released by Stanford. The following issues have been identified in the original release and fixed in this dataset:\\n\\nHallucinations: Many instructions in the original dataset had instructions referencing data on the internet, which just caused GPT3 to hallucinate an answer.\\n\\n\\\"instruction\\\":\\\"Summarizeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/netmouse/PromisedChat_Instruction.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"simple-test","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BruceNju/simple-test","creator_name":"zhongyah","creator_url":"https://huggingface.co/BruceNju","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTriffic\\n\\t\\n\\n","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"pre-train-test","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zhenwu/pre-train-test","creator_name":"wu","creator_url":"https://huggingface.co/zhenwu","description":"zhenwu/pre-train-test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Cantonese_English_Translation","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lordjia/Cantonese_English_Translation","creator_name":"Lord Jia","creator_url":"https://huggingface.co/lordjia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCantonese_English_Translation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview | ç¸½æ‹¬\\n\\t\\n\\nThis dataset provides parallel text translations between Cantonese and English, suitable for research and development in natural language processing and machine translation. | å‘¢å€‹è³‡æ–™åº«æä¾›å»£æ±è©±åŒè‹±æ–‡å˜…å°æ‡‰ç¿»è­¯ï¼Œå•±æ™’ç”¨åšŸåšèªè¨€è™•ç†åŒæ©Ÿå™¨ç¿»è­¯å˜…ç ”ç©¶åŒé–‹ç™¼ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure | è³‡æ–™çµ„ç¹”\\n\\t\\n\\n\\nenglish_cantonese_translation.csv: Contains two fields: \\\"english\\\" and \\\"cantonese\\\". | æœ‰å…©å€‹ä½: \\\"english\\\" åŒ \\\"cantonese\\\"ã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage Example | ç”¨æ³•ä¾‹å­\\n\\t\\n\\nimport pandasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lordjia/Cantonese_English_Translation.","first_N":5,"first_N_keywords":["translation","English","Chinese","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"kaomoji_caption","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/kaomoji_caption","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKaomoji Captions\\n\\t\\n\\n# throw a table angrily | æ€æ¡Œå­\\n(â•¯Â°â–¡Â°ï¼‰â•¯ï¸µ â”»â”â”»\\n\\n# surprise | åƒæƒŠ\\nÎ£( Â° â–³ Â°|||)ï¸´\\n\\nThis is a collection of 10k+ Kaomojis (é¢œæ–‡å­—) with captions and meta info.\\nMost of the captions are in English, while 1k+ captions are in Chinese.\\nThe data are crawled and parsed from different websites. There might be repeated samples, so you'd better perform deduplications before usage.\\n","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","10K<n<100K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"AI_Job_DataSet_1000_list","keyword":"chinese","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RocXuLi/AI_Job_DataSet_1000_list","creator_name":"Roc Li","creator_url":"https://huggingface.co/RocXuLi","description":"RocXuLi/AI_Job_DataSet_1000_list dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","Chinese","afl-3.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai_saamgwokjinji","keyword":"yue chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hon9kon9ize/zoengjyutgaai_saamgwokjinji","creator_name":"hon9kon9ize","creator_url":"https://huggingface.co/hon9kon9ize","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå¼µæ‚¦æ¥·ä¸‰åœ‹æ¼”ç¾©\\n\\t\\n\\nFork from laubonghaudoi/zoengjyutgaai_saamgwokjinji\\nWe found the original wav files are not splitted correctly, so we asked the author to provide the srt file and un-splitted wav files. We then re-split the wav files and align the srt file to the wav files. We also filtered some samples that are too short.\\nsubtitles = []\\nsplits = librosa.effects.split(audio) # shape: (682, 2)\\n\\n!mkdir -p dataset/zoengjyutgaai_saamgwokjinji/wavs\\n\\n# split audio by srt time\\nfor i, sub inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hon9kon9ize/zoengjyutgaai_saamgwokjinji.","first_N":5,"first_N_keywords":["Yue Chinese","cc0-1.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"cross_lingual_transfer_dialog_generation","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lorashen/cross_lingual_transfer_dialog_generation","creator_name":"shen","creator_url":"https://huggingface.co/lorashen","description":"cross-lingual transfer in dialog generation\\nChinese dialogs in movie domain: Chinese_corpus/train.jsonl, Chinese_corpus/dev.jsonl, Chinese_corpus/test.jsonl. The sizes are 500/50/500.\\nEnglish dialogs in movie domain: English_corpus/train.jsonl, English_corpus/dev.jsonl. The sizes are 400k/20k.\\nChinese dialogs for test in music/book/tech domain: other_domains/music.test.jsonl, other_domains/book.test.jsonl, other_domains/tech.test.jsonl. The sizes are 500/500/500.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lorashen/cross_lingual_transfer_dialog_generation.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"multimuc4","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jgermanmx/multimuc4","creator_name":"Jesus German Ortiz Barajas","creator_url":"https://huggingface.co/jgermanmx","description":"jgermanmx/multimuc4 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Arabic","English","Persian","Korean"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\\nChanges:\\n\\nUsed archive.org metadata API to annotate rows with \\\"duration\\\" column\\n\\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"achinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\\nChanges:\\n\\nUsed archive.org metadata API to annotate rows with \\\"duration\\\" column\\n\\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"yue chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\\nChanges:\\n\\nUsed archive.org metadata API to annotate rows with \\\"duration\\\" column\\n\\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"EC-Guide","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AiMijie/EC-Guide","creator_name":"AiMijie","creator_url":"https://huggingface.co/AiMijie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis repo is only used for dataset viewer. Please download from here.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAmazon KDDCup 2024 Team ZJU-AI4Hâ€™s Solution and Dataset (Track 2 Top 2; Track 5 Top 5)\\n\\t\\n\\nThe Amazon KDD Cupâ€™24 competition presents a unique challenge by focusing on the application of LLMs in E-commerce across multiple tasks. Our solution for addressing Tracks 2 and 5 involves a comprehensive pipeline encompassing dataset construction, instruction tuning, post-training quantization, and inferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AiMijie/EC-Guide.","first_N":5,"first_N_keywords":["question-answering","text-generation","translation","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"ValueConsistency","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jlcmoore/ValueConsistency","creator_name":"Jared","creator_url":"https://huggingface.co/jlcmoore","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ValueConsistency\\n\\t\\n\\n\\n\\nThis is the ValueConsistency data set as introduced in the paper\\n\\\"Are Large Language Models Consistent over Value-laden Questions?\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nValueConsistency is a dataset of both controversial and uncontroversial questions \\nin English, Chinese, German, and Japanese for topics from the U.S., China, Germany, and Japan. \\nIt was generated via prompting by GPT-4 and validated manually.\\nYouâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jlcmoore/ValueConsistency.","first_N":5,"first_N_keywords":["English","Chinese","German","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"tw-processed-law-ctx","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lianghsun/tw-processed-law-ctx","creator_name":"Huang Liang Hsun","creator_url":"https://huggingface.co/lianghsun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ä¸­è¯æ°‘åœ‹å°ç£æ³•è¦å…¨æ–‡å¾Œè™•ç†è³‡æ–™é›†ï¼ˆtw-processed-law-ctxï¼‰\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\næœ¬è³‡æ–™æ˜¯å°‡ tw-processed-law-article ç¶“éå¾Œè™•ç†ï¼Œå°‡ç›¸åŒæ³•è¦çš„æ³•æ¢åˆä½µç‚ºåŒä¸€å€‹æ–‡æœ¬ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\næœ¬è³‡æ–™é›†å¯ä»¥é‹ç”¨åœ¨ (Continuous) Pre-trainingï¼Œè®“æ¨¡å‹å­¸æœƒä¸­è¯æ°‘åœ‹çš„æ³•è¦å…§å®¹ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nç¹é«”ä¸­æ–‡ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nä¸€å€‹è³‡æ–™æ¨£æœ¬å¦‚ä¸‹ï¼Œ\\n{\\n    \\\"text\\\": \\\",\\n    \\\"name\\\": \\\",\\n    \\\"level\\\": \\\",\\n    \\\"abandon_note\\\": \\\",\\n    \\\"modified_date\\\": \\\",\\n    \\\"api_updated_date\\\": \\\",\\n}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lianghsun/tw-processed-law-ctx.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"MMInstruct-GPT4V","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuecao0119/MMInstruct-GPT4V","creator_name":"Cao Yue","creator_url":"https://huggingface.co/yuecao0119","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMInstruct\\n\\t\\n\\nThe official implementation of the paper \\\"MMInstruct: A High-Quality Multi-Modal Instruction Tuning Dataset with Extensive Diversity\\\".\\nThe data engine is available on GitHub at yuecao0119/MMInstruct.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTodo List\\n\\t\\n\\n\\n Data Engine.\\n Open Source Datasets.\\n Release the checkpoint.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nVision-language supervised fine-tuning effectively enhances VLLM performance, but existing visual instruction tuning datasets have limitations:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuecao0119/MMInstruct-GPT4V.","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"tw-bar-examination-2020-chat","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lianghsun/tw-bar-examination-2020-chat","creator_name":"Huang Liang Hsun","creator_url":"https://huggingface.co/lianghsun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ä¸­è¯æ°‘åœ‹2020å¹´å¾‹å¸«è€ƒè©¦é¡Œç›®ï¼ˆtw-bar-examination-2020-chatï¼‰\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\næœ¬è³‡æ–™æ˜¯ folk Jamie0510/taiwan-law-exam ç¶“éå¾Œè™•ç†ï¼Œå»é™¤æœ‰ç¼ºå°‘è³‡æ–™çš„æ¬„ä½ï¼Œä¸¦è½‰æˆ Alpaca è³‡æ–™é›†æ ¼å¼ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\næœ¬è³‡æ–™é›†å¯ä»¥é‹ç”¨åœ¨ Supervised Fine-tuningï¼Œè®“æ¨¡å‹å­¸æœƒå¦‚ä½•å›ç­”ç¹é«”ä¸­æ–‡æ³•å¾‹é¡Œç›®ã€‚è«‹æ³¨æ„ï¼Œä½ çš„æ¨¡å‹å¯ä»¥å…ˆè¨“ç·´éæœ¬è³‡æ–™é›†å¾Œå†å»è©•æ¸¬ lianghsun/tw-legal-benchmark-v1ï¼Œé€™æ¨£æ¨¡å‹çŸ¥é“å¦‚ä½•æ‡‰ç­”é€™é¡é¡Œå‹å¾Œï¼Œè¡¨ç¾æœƒæ¯”è¼ƒå¥½ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nç¹é«”ä¸­æ–‡ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n(WIP)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n(WIP)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lianghsun/tw-bar-examination-2020-chat.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ChatMed-TCM-llama","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stphencliffs/ChatMed-TCM-llama","creator_name":"cliffs","creator_url":"https://huggingface.co/stphencliffs","description":"stphencliffs/ChatMed-TCM-llama dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["table-question-answering","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"CDial-Bias","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/para-zhou/CDial-Bias","creator_name":"PARA ZHOU","creator_url":"https://huggingface.co/para-zhou","description":"Official release of CDial-Bias dataset.\\nNotation:\\nBefore downloading the dataset, please be aware that: The CDial-Bias Dataset is released for research purpose only and other usages require further permission. Please ensure the usage contributes to improving the safety and fairness of AI technologies. No malicious usage is allowed.\\nPaper:\\nhttps://aclanthology.org/2022.findings-emnlp.262/\\nGithub Repo:\\nhttps://github.com/para-zhou/CDial-Bias\\nLeaderboard:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/para-zhou/CDial-Bias.","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"llm-complex-reasoning-train-qwen2-72b-instruct-correct","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/llm-complex-reasoning-train-qwen2-72b-instruct-correct","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\n\\nData Seed from åŸºäºå°é—­ä¸–ç•Œå‡è®¾çš„å¤æ‚é€»è¾‘æ¨ç†\\nGenerate from Qwen2-72B-Instruct with prompt\\ntrain.jsonl for æ¨ç†ç­”æ¡ˆå’Œé¢˜ç›®ç­”æ¡ˆä¸€è‡´, no_train.jsonlæ¨ç†ç­”æ¡ˆå’Œé¢˜ç›®ç­”æ¡ˆä¸ä¸€è‡´\\næ³¨: é¢˜ç›®ç­”æ¡ˆä¸ä¸€å®šæ­£ç¡®\\n\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"zenless_zone_zero_interknots_v1.0","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZZZ Interknots\\n\\t\\n\\nThis datasets contains extracted Interknot posts and comments (ç»³ç½‘çš„åšå®¢ä¸è¯„è®º) in multi-language.\\nUp to game version: 1.0\\n\\nInterknot posts and comments examples\\n\\n{\\n  \\\"id\\\": \\\"1021\\\",\\n  \\\"poster\\\": \\\"Sorrowful Intern\\\",\\n  \\\"title\\\": \\\"[Commission] Missing Bangboo merchants\\\",\\n  \\\"text\\\": \\\"Hello, pros... Some of the senior Bangboo of our merchant association have gone missing! We urgently need an expert to help find them!!\\\\nLet me explain, I recently joined a very prestigiousâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","Japanese","German"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-EnKoZhJa-18k","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/werty1248/OpenOrca-EnKoZhJa-18k","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","description":"This dataset is a collection of Korean, Chinese, and Japanese OpenOrca translation datasets.\\nThe dataset was matched using id based on kyujinpy/OpenOrca-KO, which had the smallest number of rows.\\nWhen more than one translation existed for a language, I chose the more similar one based on similarity of embedding(BAAI/BGE-m3).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Sources\\n\\t\\n\\n\\nEnglish(Original)\\nOpen-Orca/OpenOrca\\n\\n\\nKorean(Translated with DeepL Pro API)\\nkyujinpy/OpenOrca-KO\\n\\n\\nChinese(Translated with Google Translate)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/werty1248/OpenOrca-EnKoZhJa-18k.","first_N":5,"first_N_keywords":["English","Korean","Chinese","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"XL-HeadTags","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/faisaltareque/XL-HeadTags","creator_name":"Faisal Tareque Shohan","creator_url":"https://huggingface.co/faisaltareque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for XL-HeadTags Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Source\\n\\t\\n\\nWe have used M3LS and XL-Sum as source for this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n We provide XL-HeadTags, a large-scale news headline and tags generation dataset. The dataset consists of 20 languages across six diverse language families. It contains 415K news headline-article pairs with auxiliary information such as image captions, topic words (read more).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/faisaltareque/XL-HeadTags.","first_N":5,"first_N_keywords":["summarization","text2text-generation","sentence-similarity","English","Portuguese"],"keywords_longer_than_N":true},
	{"name":"OIFC-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AstralForge/OIFC-SFT","creator_name":"AstralForge Tech","creator_url":"https://huggingface.co/AstralForge","description":"This is the OIFC-SFT dataset for Open-domain Implicit Format Control (OIFC).\\nFor the data statistics and collection process, please check the linked paper.\\nIf you find this dataset helpful, we would appreciate it if you cite:\\n@misc\\n{yao2024opendomainimplicitformatcontrol,\\ntitle={Open-domain Implicit Format Control for Large Language Model Generation},\\nauthor={Yiqun Yao and Wenjia Ma and Xuezhi Fang and Xin Jiang and Xiang Li and Xuying Meng and Peng Han and Jing Li and Aixin Sun and Yequanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AstralForge/OIFC-SFT.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10K<n<100K","arxiv:2408.04392"],"keywords_longer_than_N":true},
	{"name":"human-ai-comparison","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanghw/human-ai-comparison","creator_name":"Wang Haowei","creator_url":"https://huggingface.co/wanghw","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nContains Q&A datasets from both human and generative AI, with one AI answer and multiple human answers to each question.\\n","first_N":5,"first_N_keywords":["text-classification","question-answering","Chinese","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"MOE-RMCD","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ytchen175/MOE-RMCD","creator_name":"ytc","creator_url":"https://huggingface.co/ytchen175","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tytchen175/MOE-RMCD\\n\\t\\n\\nä¸€å€‹ç²¾å¿ƒè¨­è¨ˆçš„ç¹é«”ä¸­æ–‡ / æ­£é«”ä¸­æ–‡æŒ‡ä»¤è³‡æ–™é›†ã€‚\\nA delicate Traditional Chinese instructions following dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nã€Œæ•™è‚²éƒ¨é‡ç·¨åœ‹èªè¾­å…¸ä¿®è¨‚æœ¬æŒ‡ä»¤è³‡æ–™é›†ã€ ï¼ˆMinistry of Education Revised Mandarin Chinese Dictionary Instruction Datasetï¼Œç°¡ç¨± MOE-RMCDï¼‰ï¼Œ\\nå®ƒæ˜¯ç”±æ•™è‚²éƒ¨çš„ã€Šé‡ç·¨åœ‹èªè¾­å…¸ä¿®è¨‚æœ¬ã€‹ç‚ºåº•æ‰€æ§‹å»ºçš„æŒ‡ä»¤è³‡æ–™é›†ã€‚\\nåŸºæ–¼æƒ³è¦ç›¡å¯èƒ½æœ€å¤§åŒ–åˆ©ç”¨åŸå§‹è³‡æ–™æ½›åœ¨åƒ¹å€¼çš„æƒ³æ³•ï¼Œ\\næˆ‘å€‘å¾ä¸­æŠ½å–å‡ºäº”å¤§é¡ä»»å‹™ â”€â”€ è©èªè§£é‡‹ã€ç°¡ç¹è½‰æ›ã€å–®å¥é‡‹ç¾©ã€è¿‘ä¼¼è©èˆ‡åç¾©è©ï¼Œå…±è¨ˆ 36 è¬ç­†æŒ‡ä»¤ (instructions)ã€‚\\næ›´è©³ç´°çš„è³‡æ–™è™•ç†æµç¨‹è«‹è¦‹ 1.3_preprocess_æ•™è‚²éƒ¨é‡ç·¨åœ‹èªè¾­å…¸ä¿®è¨‚æœ¬.ipynbã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScope\\n\\t\\n\\næ’é™¤äº†éæ–¼ç½•è¦‹çš„å­—ï¼Œåªç•™ä¸‹ä¸­æ—¥éŸ“çµ±ä¸€è¡¨æ„æ–‡å­—åˆ—è¡¨ ï¼ˆCJK Unifiedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ytchen175/MOE-RMCD.","first_N":5,"first_N_keywords":["question-answering","Chinese","Mandarin Chinese","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"MOE-RMCD","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ytchen175/MOE-RMCD","creator_name":"ytc","creator_url":"https://huggingface.co/ytchen175","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tytchen175/MOE-RMCD\\n\\t\\n\\nä¸€å€‹ç²¾å¿ƒè¨­è¨ˆçš„ç¹é«”ä¸­æ–‡ / æ­£é«”ä¸­æ–‡æŒ‡ä»¤è³‡æ–™é›†ã€‚\\nA delicate Traditional Chinese instructions following dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nã€Œæ•™è‚²éƒ¨é‡ç·¨åœ‹èªè¾­å…¸ä¿®è¨‚æœ¬æŒ‡ä»¤è³‡æ–™é›†ã€ ï¼ˆMinistry of Education Revised Mandarin Chinese Dictionary Instruction Datasetï¼Œç°¡ç¨± MOE-RMCDï¼‰ï¼Œ\\nå®ƒæ˜¯ç”±æ•™è‚²éƒ¨çš„ã€Šé‡ç·¨åœ‹èªè¾­å…¸ä¿®è¨‚æœ¬ã€‹ç‚ºåº•æ‰€æ§‹å»ºçš„æŒ‡ä»¤è³‡æ–™é›†ã€‚\\nåŸºæ–¼æƒ³è¦ç›¡å¯èƒ½æœ€å¤§åŒ–åˆ©ç”¨åŸå§‹è³‡æ–™æ½›åœ¨åƒ¹å€¼çš„æƒ³æ³•ï¼Œ\\næˆ‘å€‘å¾ä¸­æŠ½å–å‡ºäº”å¤§é¡ä»»å‹™ â”€â”€ è©èªè§£é‡‹ã€ç°¡ç¹è½‰æ›ã€å–®å¥é‡‹ç¾©ã€è¿‘ä¼¼è©èˆ‡åç¾©è©ï¼Œå…±è¨ˆ 36 è¬ç­†æŒ‡ä»¤ (instructions)ã€‚\\næ›´è©³ç´°çš„è³‡æ–™è™•ç†æµç¨‹è«‹è¦‹ 1.3_preprocess_æ•™è‚²éƒ¨é‡ç·¨åœ‹èªè¾­å…¸ä¿®è¨‚æœ¬.ipynbã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScope\\n\\t\\n\\næ’é™¤äº†éæ–¼ç½•è¦‹çš„å­—ï¼Œåªç•™ä¸‹ä¸­æ—¥éŸ“çµ±ä¸€è¡¨æ„æ–‡å­—åˆ—è¡¨ ï¼ˆCJK Unifiedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ytchen175/MOE-RMCD.","first_N":5,"first_N_keywords":["question-answering","Chinese","Mandarin Chinese","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"chinese_paladin_game_corpus","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/chinese_paladin_game_corpus","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»™å‰‘å¥‡ä¾ ä¼ ä¸­æ–‡è¯­æ–™\\n\\t\\n\\næ¥æºï¼šhttps://github.com/SaraKale/paldialogue\\næœ¬é¡¹ç›®ä»…ä»…å°†è¯¥è¯­æ–™æ•´ç†ä¸º dataset æ ¼å¼ã€‚\\næ„Ÿè°¢ä¼—å¤šä»™è¿·çš„è´¡çŒ®ï¼æ„Ÿè°¢åœ†æ»šæ»šçš„é›ªå›¢æ•´ç†/åˆ¶ä½œ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç¤ºä¾‹\\n\\t\\n\\n{\\n  \\\"text\\\": \\\"#ä»™å‰‘å¥‡ä¾ ä¼ ä¸€ï¼ˆ98æŸ”æƒ…ç‰ˆï¼‰\\\\nã€Šä»™å‰‘å¥‡ä¾ ä¼ 98æŸ”æƒ…ç‰ˆã€‹å…¨å‰§æƒ…å¯¹è¯æ–‡æœ¬\\\\nåŸé•‡NPCå¯¹è¯\\\\n\\\\nä½™æ­é•‡\\\\n\\\\nâ–¶ã€å®¢æ ˆå†…ã€\\\\n\\\\næå¤§å¨˜ï¼šé€é¥ï¼çªåœ¨æˆ¿é‡Œåšå•¥ï¼Ÿè¿˜ä¸å¿«å‡ºæ¥å¸®å¿™æ‹›å‘¼å®¢äººï¼\\\\næé€é¥ï¼šå•Šï¼ï¼ï¼æˆ‘é©¬ä¸Šå°±å»ï¼\\\\nï¼ˆæå¤§å¨˜ï¼‰åˆ«æ€ æ…¢äº†å®¢äººï¼ï¼\\\\næå¤§å¨˜ï¼šé‚£ä¹ä¸æ‰“å‘èµ°äº†æ²¡ï¼Ÿ\\\\næå¤§å¨˜ï¼šåˆ«æ„£åœ¨è¿™é‡Œï¼Œå¸®å¸®å¿™å§ï¼æˆ‘éƒ½å¿«å¿™ä¸è¿‡æ¥äº†... ...\\\",\\n  \\\"game\\\": \\\"ä»™å‰‘å¥‡ä¾ ä¼ ä¸€ï¼ˆ98æŸ”æƒ…ç‰ˆï¼‰\\\",\\n  \\\"name\\\": \\\"ã€Šä»™å‰‘å¥‡ä¾ ä¼ ä¸€98æŸ”æƒ…ç‰ˆã€‹å‰§æƒ…å¯¹è¯ - NPCå¯¹è¯.docx\\\"\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæè¿°\\n\\t\\n\\nï¼ˆæ‘˜æŠ„è‡ªåŸå§‹ github repoï¼‰\\nè¯­æ–™åŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š\\nå•æœºï¼š\\n\\nä»™å‰‘å¥‡ä¾ ä¼ ä¸€ï¼ˆå·²å®Œæˆï¼Œæ•´ç†è€…ï¼šé›ªå›¢ï¼‰\\nä»™å‰‘å¥‡ä¾ ä¼ äºŒï¼ˆå·²å®Œæˆï¼Œæ•´ç†è€…ï¼šé›ªå›¢ï¼‰â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/chinese_paladin_game_corpus.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","n<1K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"CHUBS","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chen-yingfa/CHUBS","creator_name":"Yingfa Chen","creator_url":"https://huggingface.co/chen-yingfa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCHUBS: A Large-Scale Dataset of Chu Bamboo Slip Script\\n\\t\\n\\n\\n  Code | Paper (upcoming)\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is a large-scale dataset of Chu bamboo slip (CBS, Chinese: æ¥šç®€, chujian) script, an ancient Chinese script used during the Spring and Autumn period over 2,000 years ago. This dataset consists of two parts: \\n\\nThe main dataset where each example is an image and the corresponding text label. This part is contained in the glyphs.zip ZIP file.\\nA character detectionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/chen-yingfa/CHUBS.","first_N":5,"first_N_keywords":["image-classification","text-to-image","token-classification","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"CHUBS","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chen-yingfa/CHUBS","creator_name":"Yingfa Chen","creator_url":"https://huggingface.co/chen-yingfa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCHUBS: A Large-Scale Dataset of Chu Bamboo Slip Script\\n\\t\\n\\n\\n  Code | Paper (upcoming)\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is a large-scale dataset of Chu bamboo slip (CBS, Chinese: æ¥šç®€, chujian) script, an ancient Chinese script used during the Spring and Autumn period over 2,000 years ago. This dataset consists of two parts: \\n\\nThe main dataset where each example is an image and the corresponding text label. This part is contained in the glyphs.zip ZIP file.\\nA character detectionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/chen-yingfa/CHUBS.","first_N":5,"first_N_keywords":["image-classification","text-to-image","token-classification","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MOE-RMCD","keyword":"mandarin chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ytchen175/MOE-RMCD","creator_name":"ytc","creator_url":"https://huggingface.co/ytchen175","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tytchen175/MOE-RMCD\\n\\t\\n\\nä¸€å€‹ç²¾å¿ƒè¨­è¨ˆçš„ç¹é«”ä¸­æ–‡ / æ­£é«”ä¸­æ–‡æŒ‡ä»¤è³‡æ–™é›†ã€‚\\nA delicate Traditional Chinese instructions following dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nã€Œæ•™è‚²éƒ¨é‡ç·¨åœ‹èªè¾­å…¸ä¿®è¨‚æœ¬æŒ‡ä»¤è³‡æ–™é›†ã€ ï¼ˆMinistry of Education Revised Mandarin Chinese Dictionary Instruction Datasetï¼Œç°¡ç¨± MOE-RMCDï¼‰ï¼Œ\\nå®ƒæ˜¯ç”±æ•™è‚²éƒ¨çš„ã€Šé‡ç·¨åœ‹èªè¾­å…¸ä¿®è¨‚æœ¬ã€‹ç‚ºåº•æ‰€æ§‹å»ºçš„æŒ‡ä»¤è³‡æ–™é›†ã€‚\\nåŸºæ–¼æƒ³è¦ç›¡å¯èƒ½æœ€å¤§åŒ–åˆ©ç”¨åŸå§‹è³‡æ–™æ½›åœ¨åƒ¹å€¼çš„æƒ³æ³•ï¼Œ\\næˆ‘å€‘å¾ä¸­æŠ½å–å‡ºäº”å¤§é¡ä»»å‹™ â”€â”€ è©èªè§£é‡‹ã€ç°¡ç¹è½‰æ›ã€å–®å¥é‡‹ç¾©ã€è¿‘ä¼¼è©èˆ‡åç¾©è©ï¼Œå…±è¨ˆ 36 è¬ç­†æŒ‡ä»¤ (instructions)ã€‚\\næ›´è©³ç´°çš„è³‡æ–™è™•ç†æµç¨‹è«‹è¦‹ 1.3_preprocess_æ•™è‚²éƒ¨é‡ç·¨åœ‹èªè¾­å…¸ä¿®è¨‚æœ¬.ipynbã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScope\\n\\t\\n\\næ’é™¤äº†éæ–¼ç½•è¦‹çš„å­—ï¼Œåªç•™ä¸‹ä¸­æ—¥éŸ“çµ±ä¸€è¡¨æ„æ–‡å­—åˆ—è¡¨ ï¼ˆCJK Unifiedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ytchen175/MOE-RMCD.","first_N":5,"first_N_keywords":["question-answering","Chinese","Mandarin Chinese","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"MOE-RMCD","keyword":"mandarin chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ytchen175/MOE-RMCD","creator_name":"ytc","creator_url":"https://huggingface.co/ytchen175","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tytchen175/MOE-RMCD\\n\\t\\n\\nä¸€å€‹ç²¾å¿ƒè¨­è¨ˆçš„ç¹é«”ä¸­æ–‡ / æ­£é«”ä¸­æ–‡æŒ‡ä»¤è³‡æ–™é›†ã€‚\\nA delicate Traditional Chinese instructions following dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nã€Œæ•™è‚²éƒ¨é‡ç·¨åœ‹èªè¾­å…¸ä¿®è¨‚æœ¬æŒ‡ä»¤è³‡æ–™é›†ã€ ï¼ˆMinistry of Education Revised Mandarin Chinese Dictionary Instruction Datasetï¼Œç°¡ç¨± MOE-RMCDï¼‰ï¼Œ\\nå®ƒæ˜¯ç”±æ•™è‚²éƒ¨çš„ã€Šé‡ç·¨åœ‹èªè¾­å…¸ä¿®è¨‚æœ¬ã€‹ç‚ºåº•æ‰€æ§‹å»ºçš„æŒ‡ä»¤è³‡æ–™é›†ã€‚\\nåŸºæ–¼æƒ³è¦ç›¡å¯èƒ½æœ€å¤§åŒ–åˆ©ç”¨åŸå§‹è³‡æ–™æ½›åœ¨åƒ¹å€¼çš„æƒ³æ³•ï¼Œ\\næˆ‘å€‘å¾ä¸­æŠ½å–å‡ºäº”å¤§é¡ä»»å‹™ â”€â”€ è©èªè§£é‡‹ã€ç°¡ç¹è½‰æ›ã€å–®å¥é‡‹ç¾©ã€è¿‘ä¼¼è©èˆ‡åç¾©è©ï¼Œå…±è¨ˆ 36 è¬ç­†æŒ‡ä»¤ (instructions)ã€‚\\næ›´è©³ç´°çš„è³‡æ–™è™•ç†æµç¨‹è«‹è¦‹ 1.3_preprocess_æ•™è‚²éƒ¨é‡ç·¨åœ‹èªè¾­å…¸ä¿®è¨‚æœ¬.ipynbã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScope\\n\\t\\n\\næ’é™¤äº†éæ–¼ç½•è¦‹çš„å­—ï¼Œåªç•™ä¸‹ä¸­æ—¥éŸ“çµ±ä¸€è¡¨æ„æ–‡å­—åˆ—è¡¨ ï¼ˆCJK Unifiedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ytchen175/MOE-RMCD.","first_N":5,"first_N_keywords":["question-answering","Chinese","Mandarin Chinese","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"Insur-QA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrankRin/Insur-QA","creator_name":"Frank Rin","creator_url":"https://huggingface.co/FrankRin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInsur-QA Dataset\\n\\t\\n\\nThe distribution of the dataset is:\\n\\n  \\n    Task\\n    Dataset\\n    Source\\n    Size\\n  \\n  \\n    Basic Insurance\\n    Train\\n    BX_GPT3.5\\n    10k\\n  \\n  \\n    Knowledge QA\\n    Test\\n    Insurance_QA_zh\\n    3k\\n  \\n  \\n    Insurance Contract QA\\n    Train\\n    Insurance Contracts\\n    40k\\n  \\n  \\n    Insurance Contract QA\\n    Test\\n    Insurance Contracts\\n    100\\n  \\n  \\n    Insurance Database QA\\n    Train\\n    Insurance Contracts\\n    44k\\n  \\n  \\n    Insurance Database QA\\n    Testâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FrankRin/Insur-QA.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K<n<100K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"taiwan-legislator-transcript","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aigrant/taiwan-legislator-transcript","creator_name":"AI Grant","creator_url":"https://huggingface.co/aigrant","description":"\\n\\t\\n\\t\\t\\n\\t\\tTaiwan Legislator Transcript\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe transcripts of speech record happened in various kinds of meetings at Taiwan Legislator Yuan.\\nThe original of transcripts are compiled and published on gazettes from Taiwan Legislator Yuan.\\nFor each segment of transcript, there are corresponding video clip on Legislative Yuan IVOD system.\\nIVOD stands for Internet Video on Demand system. \\nFor more detail on data origin please look at:\\n\\nLegislative Yuan Meetings and Gazettesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aigrant/taiwan-legislator-transcript.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"taiwan-ly-law-research","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aigrant/taiwan-ly-law-research","creator_name":"AI Grant","creator_url":"https://huggingface.co/aigrant","description":"\\n\\t\\n\\t\\t\\n\\t\\tTaiwan Legislator Yuan Law Research Data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe law research documents are issued irregularly from Taiwan Legislator Yuan.\\nThe purpose of those research are providing better understanding on social issues in aspect of laws.\\nOne may find documents rich with technical terms which could provided as training data.\\nFor comprehensive document list check out this link provided by Taiwan Legislator Yuan.\\nThere are currently missing document download links in 10th and 9thâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aigrant/taiwan-ly-law-research.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_news","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_news","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_news.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","100M - 1B"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_law","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_law","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_law.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_technology","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_technology","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_technology.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_agriculture","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_agriculture","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_agriculture.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_emotion","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_emotion","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_emotion.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","n>1T"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_sports","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_sports","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_sports.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_politics","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_politics","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_politics.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_mathematics","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_mathematics","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_mathematics.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","n>1T"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_film","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_film","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_film.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_literature","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_literature","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_literature.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_automobile","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_automobile","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_automobile.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_ai","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_ai","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_ai.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","n>1T"],"keywords_longer_than_N":true},
	{"name":"cantonese-chinese-dataset-gen2","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/raptorkwok/cantonese-chinese-dataset-gen2","creator_name":"Raptor K","creator_url":"https://huggingface.co/raptorkwok","description":"Cantonese-Written Chinese Parallel Dataset with roughly 1 million pairs of Cantonese and Written Chinese sentences, in JSONL format. \\nThe sentence topics include news, novels and daily conversations. Translations are done by Microsoft Azure Translate API, and manually corrected problems by me. Sentences are also manually verified by me one by one. \\nThe dataset could be extended if there are more resources, in terms of manpower and money.\\n","first_N":5,"first_N_keywords":["translation","Chinese","cc0-1.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Liu123456789/test","creator_name":"L","creator_url":"https://huggingface.co/Liu123456789","description":"Liu123456789/test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","extractive-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"famma","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/weaverbirdllm/famma","creator_name":"weaverbird_llm","creator_url":"https://huggingface.co/weaverbirdllm","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nFAMMA is a multi-modal financial Q&A benchmark dataset. The questions encompass three heterogeneous image types - tables, charts and text & math screenshots - and span eight subfields in finance, comprehensively covering topics across major asset classes. Additionally, all the questions are categorized by three difficulty levels â€” easy, medium, and hard - and are available in three languages â€” English, Chinese, and French. Furthermore, the questions are divided into twoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/weaverbirdllm/famma.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"Chinese-Image-Text-Corpus-dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/REILX/Chinese-Image-Text-Corpus-dataset","creator_name":"SunForlight","creator_url":"https://huggingface.co/REILX","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tREILX/Chinese-Image-Text-Corpus-dataset\\n\\t\\n\\n[ English | ä¸­æ–‡ ]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe REILX/Chinese-Image-Text-Corpus-dataset is a multimodal dataset that pairs Chinese textual data with corresponding images. This dataset is derived from the Chinese-Xinhua Dictionary Database, which includes idioms, single characters, words, and aphorisms.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset is organized into the following categories:\\n\\nIdioms: Traditional Chinese idioms withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/REILX/Chinese-Image-Text-Corpus-dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"ft-data-v2-colab-hours","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/radeon-zhang/ft-data-v2-colab-hours","creator_name":"Radeon Zhang","creator_url":"https://huggingface.co/radeon-zhang","description":"å°è¯•æŠŠæˆ‘è·å–åˆ°çš„ä¸€äº›å°é»„æ–‡è½¬æ¢æˆ instruction fine-tuning çš„æ ¼å¼ã€‚\\nai_response æ˜¯å°è¯´çš„åŸæ–‡ï¼Œæ¯ä¸€ä¸ªç« èŠ‚éƒ½æ˜¯ä¸€æ¡æ•°æ®ï¼Œç„¶åä½¿ç”¨ mistral-nemo ç”Ÿæˆä¸‰æ¡ user prompt å‡ºæ¥ï¼Œæ”¾åœ¨ user_input 1, 2, 3é‡Œé¢ã€‚\\næ˜¾ç„¶å°è¯´è¿˜éœ€è¦åšä¸€äº›æ•°æ®æ¸…ç†ï¼Œä¸è¿‡ç”Ÿæˆå‡ºæ¥çš„ user prompt è´¨é‡è¿˜ä¸é”™ã€‚\\næ•°æ®åªæœ‰165æ¡ï¼Œå› ä¸ºæˆ‘æ˜¯åœ¨ colab ä¸Šè·‘çš„é‡åŒ– mistral-nemoï¼Œç„¶åæŠŠæˆ‘å…è´¹ç‰ˆçš„GPUç”¨é‡è·‘ç‚¸äº†ã€‚\\nè¿™æ˜¯æˆ‘çš„ä¸€äº›è®¡ç®—:\\nåœ¨ Tesla T4 (Google Colab å…è´¹ç‰ˆ)ä¸Š:\\n\\nç”Ÿæˆä¸€æ¡user prompt çš„å¹³å‡æ™‚é–“åœ¨ 20ç§’å·¦å³ (5s -> 25sä¸ç­‰)\\næ¯å€‹ txt è¦ç”Ÿæˆä¸‰æ¬¡æ•¸æ“š, æ‰€ä»¥æ¯å€‹txt è€—æ™‚çº¦ 1min\\næœ‰235,312å€‹æ•¸æ“š, ç”¨ä¸€å¼µT4 ç‹‚è·‘ å¤§ç´„è¦èŠ±163å¤©\\nç¸½å­—ç¬¦æ•¸é‡: 1420689772, ä¹Ÿå°±æ˜¯14å„„å­—\\nä¸­æ–‡å­—ç¬¦ç”¨mistral-nemo çš„tokenizer, æˆ‘çš„å°è¯•æ˜¯ 2979å­— -> 4156 token, ä¹Ÿå°±æ˜¯1.39 å€, word to tokenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/radeon-zhang/ft-data-v2-colab-hours.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc0-1.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"mmarco-hard-negatives-reranker-score","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score","creator_name":"Yuichi Tateno","creator_url":"https://huggingface.co/hotchpotch","description":"\\nhotchpotch/mmarco-hard-negatives-reranker-score\\n\\nThis repository contains data from mMARCO scored using the reranker BAAI/bge-reranker-v2-m3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Covered\\n\\t\\n\\ntarget_languages = [\\n    \\\"english\\\",\\n    \\\"chinese\\\", \\n    \\\"french\\\",\\n    \\\"german\\\",\\n    \\\"indonesian\\\",\\n    \\\"italian\\\",\\n    \\\"portuguese\\\",\\n    \\\"russian\\\",\\n    \\\"spanish\\\",\\n    \\\"arabic\\\",\\n    \\\"dutch\\\",\\n    \\\"hindi\\\",\\n    \\\"japanese\\\",\\n    \\\"vietnamese\\\"\\n]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHard Negative Data\\n\\t\\n\\nThe hard negative data is derived fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score.","first_N":5,"first_N_keywords":["English","Chinese","French","German","Indonesian"],"keywords_longer_than_N":true},
	{"name":"Multi-Opthalingua","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AAAIBenchmark/Multi-Opthalingua","creator_name":"AAAIBenchmark","creator_url":"https://huggingface.co/AAAIBenchmark","description":"AAAIBenchmark/Multi-Opthalingua dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Hindi","Chinese","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"nanoset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jxxqtech/nanoset","creator_name":"jxxqtech","creator_url":"https://huggingface.co/jxxqtech","description":"jxxqtech/nanoset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MT-SFT-ShareGPT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thomas-yanxin/MT-SFT-ShareGPT","creator_name":"thomas Yan","creator_url":"https://huggingface.co/thomas-yanxin","description":"\\n\\n\\n  Â \\n  \\n    MT-SFT-ShareGPT\\n    \\n      \\n      \\n    \\n    Â \\n  \\n  \\nğŸ’» Github Repo  â€¢  ğŸ¤— HuggingFace  â€¢  ğŸ¤– ModelScope\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nData has always been an important part of advancing large language models forward. Based on this, we have collected dozens of high-quality open source datasets from the open source community, with a total data volume of 20 M. \\nAfter some cleaning actions, we have open sourced a set of high-quality datasets for fine-tuning the instructions of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/thomas-yanxin/MT-SFT-ShareGPT.","first_N":5,"first_N_keywords":["question-answering","translation","summarization","text-classification","English"],"keywords_longer_than_N":true},
	{"name":"xiaolinguangji","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wolfofbackstreet/xiaolinguangji","creator_name":"wolfofbackstreet","creator_url":"https://huggingface.co/wolfofbackstreet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/wolfofbackstreet/xiaolinguangji.","first_N":5,"first_N_keywords":["text2text-generation","Chinese","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"ruozhiba","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bineea/ruozhiba","creator_name":"bin","creator_url":"https://huggingface.co/bineea","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\truozhiba_gpt4\\n\\t\\n\\næœ¬ä»“åº“åŒ…å«ä½¿ç”¨GPT-4ï¼ˆ4T/4oï¼‰æ„å»ºçš„ruozhibaæŒ‡ä»¤æ•°æ®[^1]ï¼Œå…±è®¡2449æ¡ã€‚å…¶ä¸­åŒ…å«ä»¥ä¸‹ä¸¤ä¸ªç‰ˆæœ¬ï¼Œé¢˜ç›®ç›¸åŒï¼Œä»…å›ç­”å†…å®¹ä¸åŒã€‚\\n\\nruozhiba_qa2449_gpt4t.jsonï¼šåˆ©ç”¨gpt-4-turbo-20240409 å¯¹é—®é¢˜è¿›è¡Œäº†å›ç­”ã€‚\\nruozhiba_qa2449_gpt4o.jsonï¼šåˆ©ç”¨gpt-4o-20240514 å¯¹é—®é¢˜è¿›è¡Œäº†å›ç­”ã€‚\\n\\næ³¨æ„ï¼šæŒ‡ä»¤æ•°æ®ä¸­å¯èƒ½åŒ…å«å†’çŠ¯ç”¨è¯­ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ‰€å±é¡¹ç›®\\n\\t\\n\\nChinese-LLaMA-Alpaca-3ï¼šhttps://github.com/ymcui/Chinese-LLaMA-Alpaca-3\\n\\nThis repository contains the ruozhiba instruction data[^1] constructed using GPT-4 (4T/4o), totaling 2449 entries. It includes the following two versions with the sameâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bineea/ruozhiba.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"emeraldTablet","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smartkit/emeraldTablet","creator_name":"yangbozhou","creator_url":"https://huggingface.co/smartkit","description":"smartkit/emeraldTablet dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["token-classification","Chamorro","Chinese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"orca-math-word-problems-100k-en-zh-mix","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xd2333/orca-math-word-problems-100k-en-zh-mix","creator_name":"xd2333","creator_url":"https://huggingface.co/xd2333","description":"100k English and Chinese mixed version of microsoft/orca-math-word-problems-200k\\n","first_N":5,"first_N_keywords":["text-generation","English","Chinese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Oryx-SFT-Data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/THUdyh/Oryx-SFT-Data","creator_name":"Yuhao Dong","creator_url":"https://huggingface.co/THUdyh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Oryx-SFT-Data\\n\\t\\n\\nThis dataset is used for the training of the Oryx model. We only allow the use of this dataset for academic research and education purpose.\\nFor more details, please refer to our Github Repo\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nA mixture of 1.2M image/video data. \\nFor more statistics of the dataset, please refer to our paper (coming soon)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\nWe preprocess all the data into multiple files. \\nYou can use our preprocessed dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/THUdyh/Oryx-SFT-Data.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"ChineseBQB","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/ChineseBQB","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese BQB\\n\\t\\n\\nThis is a data reupload of the repository zhaoolee/ChineseBQB, containing 5k+ Chinese stickers\\nä¸­æ–‡è¡¨æƒ…åŒ…æ•°æ®ï¼Œæ¥è‡ªäºzhaoolee/ChineseBQB\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","arrow","Image"],"keywords_longer_than_N":true},
	{"name":"bendi-public","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sdsdfd/bendi-public","creator_name":"sdfd","creator_url":"https://huggingface.co/sdsdfd","description":"sdsdfd/bendi-public dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","Chinese","apache-2.0","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"muri-it-language-split","keyword":"achinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"zhuang","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"Coupang-Product-Set-1M","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clw8998/Coupang-Product-Set-1M","creator_name":"WW","creator_url":"https://huggingface.co/clw8998","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Load the Dataset\\n\\t\\n\\nYou can load this dataset using the Hugging Face datasets library as follows:\\nMake sure you have the datasets library installed:\\npip install datasets\\n\\nUse the following code to retrieve the dataset:\\nfrom datasets import load_dataset\\n\\n# Load the Coupang Product Set 1M dataset\\ndataset = load_dataset('clw8998/Coupang-Product-Set-1M')\\n\\n# Display the first few rows of the dataset\\nfor i in range(5):\\n    print(dataset['train'][i])\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExpected  Outputâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/clw8998/Coupang-Product-Set-1M.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"bilibili-masterpieces","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wencan2024/bilibili-masterpieces","creator_name":"wencan","creator_url":"https://huggingface.co/wencan2024","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Bilibili Masterpieces\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe bilibili-masterpieces dataset is a curated collection of representative works from some of the early well-known content creators (up ä¸») on the Bilibili platform. This dataset captures key metadata from these videos, providing a snapshot of the creative output that has significantly influenced the Bilibili community.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset can be used for various tasksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wencan2024/bilibili-masterpieces.","first_N":5,"first_N_keywords":["text-classification","Chinese","cc0-1.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"LongWriter-6k-reformat","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pszemraj/LongWriter-6k-reformat","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tpszemraj/LongWriter-6k-reformat\\n\\t\\n\\nTHUDM/LongWriter-6k reformatted to dedicated columns. The default dataset config is english only, see the \\\"all\\\" config for other langs\\nGPT-4 tiktoken token count:\\n        token_count\\ncount   2335.000000\\nmean    5295.221842\\nstd     2771.696858\\nmin        1.000000\\n25%     3556.000000\\n50%     4729.000000\\n75%     6266.000000\\nmax    28436.000000\\n\\n\\nTotal count:\\t12.36 M tokens\\n\\n","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"OpenHermes-2.5-zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ldwang/OpenHermes-2.5-zh","creator_name":"ldwang","creator_url":"https://huggingface.co/ldwang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"OpenHermes-2.5-zh\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources & Infos\\n\\t\\n\\n\\nData Origin: Derived from the original OpenHermes dataset : teknium/OpenHermes-2.5.\\nLanguages: Chinese\\nApplications: Language Modeling\\nLicense: Apache-2.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nOpenHermes-2.5-zh is a dataset translated from the OpenHermes-2.5 collection provided by teknium.\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K<n<1M","ğŸ‡ºğŸ‡¸ Region: US","Synthetic"],"keywords_longer_than_N":true},
	{"name":"TWRMCD","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/TWRMCD","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tyuhuanstudio/TWRMCD\\n\\t\\n\\n(æ­¤é …ç›®æ•¸æ“šåŠè™•ç†æ–¹å¼åƒè€ƒä¸¦æ”¹è‰¯è‡ª ytchen175/master_thesis æ„Ÿè¬é–‹æºè™•ç†æµç¨‹ï¼)\\nä¸€å€‹æ”¶éŒ„äº†æ­£é«”ä¸­æ–‡ï¼ˆç¹é«”ä¸­æ–‡ï¼‰å­—å…¸çš„è³‡æ–™é›†ï¼Œç”¨æ–¼å¤§æ¨¡å‹å¾®èª¿\\n(è¿½æ±‚é€²æ­¥ä½†ä¸æ‡‰è©²æ¨å»æ­·å²ï¼Œä¸­è¯æ–‡åŒ–ä¸è©²å› æ”¿æ²»è€Œè¢«æŠ¹å»ä¸¦æ¶ˆäº¡)\\nA data set containing Traditional Chines dictionaries for fine-tuning LLM\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nã€Œå°ç£æ•™è‚²éƒ¨é‡ç·¨åœ‹èªè¾­å…¸ä¿®è¨‚æœ¬ã€ ï¼ˆTaiwan's Ministry of Education Revised Mandarin Chinese Dictionaryï¼ŒTWRMCDï¼‰ï¼Œ\\nè³‡æ–™å–è‡ªæ–¼å°ç£æ•™è‚²éƒ¨çš„ã€Šé‡ç·¨åœ‹èªè¾­å…¸ä¿®è¨‚æœ¬ã€‹\\nç‚ºäº†è®“LLMå¾å¤šæ–¹é¢å¢åŠ å°ç¹é«”ä¸­æ–‡çš„èªè­˜ï¼Œæˆ‘å€‘åˆ©ç”¨å¾ä¸­æå–ä¸¦è¨­è¨ˆå…­å¤§æŒ‡ä»¤ä»»å‹™ã€Œè©èªè§£é‡‹ã€è®€éŸ³å•ç­”ã€ç°¡ç¹è½‰æ›ã€å–®å¥é‡‹ç¾©ã€è¿‘ä¼¼è©èˆ‡åç¾©è©ã€ï¼ˆç´„51è¬ç­†æŒ‡ä»¤ï¼‰\\nThis dataset is sourced from Taiwanâ€™s Ministry ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/TWRMCD.","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"TWRMCD","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/TWRMCD","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tyuhuanstudio/TWRMCD\\n\\t\\n\\n(æ­¤é …ç›®æ•¸æ“šåŠè™•ç†æ–¹å¼åƒè€ƒä¸¦æ”¹è‰¯è‡ª ytchen175/master_thesis æ„Ÿè¬é–‹æºè™•ç†æµç¨‹ï¼)\\nä¸€å€‹æ”¶éŒ„äº†æ­£é«”ä¸­æ–‡ï¼ˆç¹é«”ä¸­æ–‡ï¼‰å­—å…¸çš„è³‡æ–™é›†ï¼Œç”¨æ–¼å¤§æ¨¡å‹å¾®èª¿\\n(è¿½æ±‚é€²æ­¥ä½†ä¸æ‡‰è©²æ¨å»æ­·å²ï¼Œä¸­è¯æ–‡åŒ–ä¸è©²å› æ”¿æ²»è€Œè¢«æŠ¹å»ä¸¦æ¶ˆäº¡)\\nA data set containing Traditional Chines dictionaries for fine-tuning LLM\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nã€Œå°ç£æ•™è‚²éƒ¨é‡ç·¨åœ‹èªè¾­å…¸ä¿®è¨‚æœ¬ã€ ï¼ˆTaiwan's Ministry of Education Revised Mandarin Chinese Dictionaryï¼ŒTWRMCDï¼‰ï¼Œ\\nè³‡æ–™å–è‡ªæ–¼å°ç£æ•™è‚²éƒ¨çš„ã€Šé‡ç·¨åœ‹èªè¾­å…¸ä¿®è¨‚æœ¬ã€‹\\nç‚ºäº†è®“LLMå¾å¤šæ–¹é¢å¢åŠ å°ç¹é«”ä¸­æ–‡çš„èªè­˜ï¼Œæˆ‘å€‘åˆ©ç”¨å¾ä¸­æå–ä¸¦è¨­è¨ˆå…­å¤§æŒ‡ä»¤ä»»å‹™ã€Œè©èªè§£é‡‹ã€è®€éŸ³å•ç­”ã€ç°¡ç¹è½‰æ›ã€å–®å¥é‡‹ç¾©ã€è¿‘ä¼¼è©èˆ‡åç¾©è©ã€ï¼ˆç´„51è¬ç­†æŒ‡ä»¤ï¼‰\\nThis dataset is sourced from Taiwanâ€™s Ministry ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/TWRMCD.","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"AuroraCap-trainset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wchai/AuroraCap-trainset","creator_name":"Wenhao Chai","creator_url":"https://huggingface.co/wchai","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAuroraCap Trainset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tResources\\n\\t\\n\\n\\nWebsite\\narXiv: Paper\\nGitHub: Code\\nHuggingface: AuroraCap Model\\nHuggingface: VDC Benchmark\\nHuggingface: Trainset\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\nWe use over 20 million high-quality image/video-text pairs to train AuroraCap in three stages. \\nPretraining stage. We first align visual features with the word embedding space of LLMs. To achieve this, we freeze the pretrained ViT and LLM, training solely the vision-language connector.\\nVisionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wchai/AuroraCap-trainset.","first_N":5,"first_N_keywords":["visual-question-answering","video-text-to-text","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"CSC-gpt4","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/CSC-gpt4","creator_name":"Ming Xu (å¾æ˜)","creator_url":"https://huggingface.co/shibing624","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Chinese Spelling Correction(gpt4 fixed version)\\n\\t\\n\\nä¸­æ–‡æ‹¼å†™çº é”™æ•°æ®é›†\\n\\nRepository: https://github.com/shibing624/pycorrector\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nChinese Spelling Correction (CSC) is a task to detect and correct misspelled characters in Chinese texts. \\nCSC is challenging since many Chinese characters are visually or phonologically similar but with quite different semantic meanings.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shibing624/CSC-gpt4.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"ImageText-Question-answer-pairs-58K-Claude-3.5-Sonnnet","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/REILX/ImageText-Question-answer-pairs-58K-Claude-3.5-Sonnnet","creator_name":"SunForlight","creator_url":"https://huggingface.co/REILX","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tREILX/ImageText-Question-answer-pairs-58K-Claude-3.5-Sonnnet\\n\\t\\n\\nä»VisualGenomeæ•°æ®é›†V1.2ä¸­éšæœºæŠ½å–21717å¼ å›¾ç‰‡ï¼Œåˆ©ç”¨Claude-3-opus-20240229å’ŒClaude-3-sonnet-20240620ä¸¤ä¸ªæ¨¡å‹ç”Ÿæˆäº†æ€»è®¡58312ä¸ªé—®ç­”å¯¹ï¼Œæ¯å¼ å›¾ç‰‡çº¦3ä¸ªé—®ç­”ï¼Œå…¶ä¸­å¿…æœ‰ä¸€ä¸ªå…³äºå›¾åƒç»†èŠ‚çš„é—®ç­”ã€‚Claude-3-opus-20240229æ¨¡å‹è´¡çŒ®äº†çº¦3,028ä¸ªé—®ç­”å¯¹ï¼Œè€ŒClaude-3-sonnet-20240620æ¨¡å‹åˆ™ç”Ÿæˆäº†å‰©ä½™çš„é—®ç­”å¯¹ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode\\n\\t\\n\\nä½¿ç”¨ä»¥ä¸‹ä»£ç ç”Ÿæˆé—®ç­”å¯¹ï¼š\\n# -*- coding: gbk -*-\\nimport os\\nimport random\\nimport shutil\\nimport re\\nimport json\\nimport requests\\nimport base64\\nimport time\\nfrom tqdm import tqdm\\nfrom json_repair import repair_jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/REILX/ImageText-Question-answer-pairs-58K-Claude-3.5-Sonnnet.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xm100","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM100\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"toxic_reject","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xdykj/toxic_reject","creator_name":"xd","creator_url":"https://huggingface.co/xdykj","description":"Regenerate from thu-coai/Safety-Prompts using Qwen2.5 to get better reply.\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"PsySUICIDE","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qiuhuachuan/PsySUICIDE","creator_name":"Huachuan Qiu","creator_url":"https://huggingface.co/qiuhuachuan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPsyGUARD: An Automated System for Suicide Detection and Risk Assessment in Psychological Counseling\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸ‰ğŸ‰ğŸ‰ accepted to the EMNLP 2024 Main Conference\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nAs awareness of mental health issues grows, online counseling support services are becoming increasingly prevalent worldwide. Detecting whether users express suicidal ideation in text-based counseling services is crucial for identifying and prioritizing at-risk individuals. However, theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qiuhuachuan/PsySUICIDE.","first_N":5,"first_N_keywords":["text-classification","Chinese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"comment-translation-01","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ifmain/comment-translation-01","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","description":"This dataset is based on Kaggle.  \\nThis dataset includes translations of 69,000 Reddit comments into 17 languages (English to 16 languages):\\nBelarusian, Czech, German,\\nEnglish, Spanish, Finnish,\\nFrench, Italian, Japanese,\\nKazakh, Korean, Latvian,\\nPolish, Russian, Swedish,\\nUkrainian, and Chinese.\\nIt contains 50% regular comments and 50% highly negative ones.\\nEnjoy using it!\\n","first_N":5,"first_N_keywords":["English","German","French","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEDataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   ğŸ“ƒ Paper â€¢ ğŸŒ Demo â€¢ ğŸ¤— ApolloMoEDataset â€¢ ğŸ¤— ApolloMoEBench  â€¢ ğŸ¤— Models  â€¢ğŸŒ Apollo  â€¢ ğŸŒ ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸŒˆ Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedï¼ğŸ‰\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEBench","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   ğŸ“ƒ Paper â€¢ ğŸŒ Demo â€¢ ğŸ¤— ApolloMoEDataset â€¢ ğŸ¤— ApolloMoEBench  â€¢ ğŸ¤— Models  â€¢ğŸŒ Apollo  â€¢ ğŸŒ ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸŒˆ Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedï¼ğŸ‰\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"Corn_Disease_Description","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/REXWind/Corn_Disease_Description","creator_name":"Boru Shi","creator_url":"https://huggingface.co/REXWind","description":"å°†plant villageä¸­çš„å›¾åƒå¯¹åº”åˆ°å…·ä½“çš„æ–‡æœ¬æè¿°ï¼ŒåŒ…å«3.8kä¸ªå›¾åƒã€æ–‡æœ¬å¯¹ã€‚\\nå¯¹åº”çš„å›¾åƒå»plantvillageä¸‹è½½å°±è¡Œã€‚\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xgqa","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xgqa","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\txGQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a clone of the few_shot-test split of the xGQA dataset\\n\\t\\n\\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{pfeiffer-etal-2021-xGQA,\\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\\\'{c}} and Iryna Gurevych}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-xgqa.","first_N":5,"first_N_keywords":["visual-question-answering","Bengali","German","English","Indonesian"],"keywords_longer_than_N":true},
	{"name":"resume-ner","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PassbyGrocer/resume-ner","creator_name":"Stanley Sun","creator_url":"https://huggingface.co/PassbyGrocer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/PassbyGrocer/resume-ner.","first_N":5,"first_N_keywords":["token-classification","Chinese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"coda-lm-llava-format","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KaiChen1998/coda-lm-llava-format","creator_name":"Kai Chen","creator_url":"https://huggingface.co/KaiChen1998","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCODA-LM Dataset Card\\n\\t\\n\\nCODA-LM is the multi-modal version of the CODA dataset, used in the CODA-LM paper. Both English and Chinese annotations are available. Check detailed usage in our Github repo.\\nThis repo contains the CODA-LM dataset, which has been reorganized in the LLaVA data format. \\nYou are also welcome to check the original CODA-LM data which contains more metadata vanilla annotations. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\n# name can be selected fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KaiChen1998/coda-lm-llava-format.","first_N":5,"first_N_keywords":["image-to-text","English","Chinese","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"db","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CHJTXY99/db","creator_name":"CHJTXY99","creator_url":"https://huggingface.co/CHJTXY99","description":"From Wu, Yu, et al. \\\"Sequential Matching Network: A New Archtechture for Multi-turn Response Selection in Retrieval-based Chatbots.\\\" ACL. 2017.\\nFrom https://github.com/MarkWuNLP/MultiTurnResponseSelection\\nIf there is any infringement, please contact me to have it removed.\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"Chinese_Male_017VoiceArtist_11Hours_High_Quality_Voice_Dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/voices365/Chinese_Male_017VoiceArtist_11Hours_High_Quality_Voice_Dataset","creator_name":"voices365","creator_url":"https://huggingface.co/voices365","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis Dataset was recorded by a professional Chinese voice artist, real person, male, the total length is around 11 hours. \\nFor more details, please refer to the link: www.vodataset.com or email info@voices365.com.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAuthorization\\n\\t\\n\\nThe voice artist can sign an authorization with you. The authorization can be of any form, such as paper, voice or video.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCustom Dataset\\n\\t\\n\\nYes, the artist can record a new dataset with your scripts, and meetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/voices365/Chinese_Male_017VoiceArtist_11Hours_High_Quality_Voice_Dataset.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Vulpisfoglia","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Vulpisfoglia","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Vulpisfoglia dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","Italian"],"keywords_longer_than_N":true},
	{"name":"LonGen","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/quanshr/LonGen","creator_name":"Shanghaoran Quan","creator_url":"https://huggingface.co/quanshr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLonGen Benchmark\\n\\t\\n\\nThe LonGen benchmark is specifically designed to assess the ability of large language models to generate long, aligned outputs, introduced by Language Models Can Self-Lengthen to Generate Long Texts.\\nLonGen consists of data from two languages (English and Chinese), categorized into three length ranges (2-4k, 4-6k, and 6-8k), and incorporates four length constraint types (about, range, above, below). This results in a total of 240 distinct pieces of data (2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/quanshr/LonGen.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"environmnet_innovation","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeke918/environmnet_innovation","creator_name":"æ²ˆå½¦å†°","creator_url":"https://huggingface.co/zeke918","description":"zeke918/environmnet_innovation dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"NaVAB","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JadenGGGeee/NaVAB","creator_name":"JCY","creator_url":"https://huggingface.co/JadenGGGeee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NaVAB\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNaVAB is a comprehensive benchmark designed to evaluate the alignment of Large Language Models (LLMs) with the values of five major nations: China, the United States, the United Kingdom, France, and Germany. The dataset addresses the limitations of existing benchmarks, which often fail to capture the dynamic nature of values across countries and lack sufficient evaluation data.\\nThe datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JadenGGGeee/NaVAB.","first_N":5,"first_N_keywords":["English","Chinese","French","German","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"CNNSum","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CxsGHost/CNNSum","creator_name":"lingxiao","creator_url":"https://huggingface.co/CxsGHost","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCNNSum: Exploring Long-Context Summarization with Large Language Models in Chinese Novels\\n\\t\\n\\nPaper Â Â Â  GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t[2024.12.18] - CNNSum Dataset Release!\\n\\t\\n\\nWe are excited to announce the release of the CNNSum dataset!\\nAs outlined in Section 3.1 and Appendix E of our paper, we have conducted a final round of manual cleaning to address any possible omissions. This process affects only a minimal number of samples, ensuring that the length statistics reported in our paperâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CxsGHost/CNNSum.","first_N":5,"first_N_keywords":["summarization","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"MegaWika","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/conceptofmind/MegaWika","creator_name":"Enrico Shippole","creator_url":"https://huggingface.co/conceptofmind","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. Furthermore, nearly 130 million Englishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/conceptofmind/MegaWika.","first_N":5,"first_N_keywords":["summarization","question-answering","text-generation","text2text-generation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"chinese-squadv2","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/real-jiakai/chinese-squadv2","creator_name":"jiakai","creator_url":"https://huggingface.co/real-jiakai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Chinese SQuAD 2.0\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a Chinese translation of the SQuAD 2.0 dataset, translated from the original English version. Like SQuAD 2.0, it contains both answerable and unanswerable questions. The dataset is designed for Chinese reading comprehension and question answering tasks.\\nSource: ChineseSquad\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset is stored in Parquet format and contains the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/real-jiakai/chinese-squadv2.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","extractive-qa","machine-translated","machine-translated"],"keywords_longer_than_N":true},
	{"name":"data_train","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dsacedsfds/data_train","creator_name":"sss","creator_url":"https://huggingface.co/dsacedsfds","description":"dsacedsfds/data_train dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"laber_law","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ulatsou/laber_law","creator_name":"SHIHWEI, TSOU","creator_url":"https://huggingface.co/ulatsou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå°ç£å‹å‹•åŸºæº–æ³• QA æ•¸æ“šé›†\\n\\t\\n\\né€™å€‹æ•¸æ“šé›†åŒ…å«å¾å°ç£å‹å‹•åŸºæº–æ³•æ•´ç†å‡ºçš„å•ç­”å°ï¼Œé©ç”¨æ–¼ï¼š\\n\\næ³•è¦è«®è©¢æ¨¡å‹è¨“ç·´\\nå‹å‹•æ³•è¦ç†è§£\\næ¬Šç›Šç¶­è­·åƒè€ƒ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•¸æ“šé›†ç‰¹é»\\n\\t\\n\\n\\nä¾†æºï¼šå°ç£å‹å‹•åŸºæº–æ³•\\næ ¼å¼ï¼šå•ç­”å°\\nè¦æ¨¡ï¼š190 å€‹è³‡æ–™é›†\\nç‰¹è‰²ï¼šæ¶µè“‹å‹åŸºæ³•å…¨éƒ¨ç« ç¯€\\n\\n","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"KT_QA","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Gyikoo/KT_QA","creator_name":"Xinyi Gao","creator_url":"https://huggingface.co/Gyikoo","description":"Gyikoo/KT_QA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MORPHEUS_Datasets","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Toyhom/MORPHEUS_Datasets","creator_name":"Yihong Tang","creator_url":"https://huggingface.co/Toyhom","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMORPHEUS\\n\\t\\n\\nMORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space(EMNLP 2024)\\nPaper \\nEN: ConvAI2\\nZH: Baidu PersonaChat\\n","first_N":5,"first_N_keywords":["text-generation","English","Chinese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"spatula_s13_yolo_detection","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Carey8175/spatula_s13_yolo_detection","creator_name":"Wang WenJie","creator_url":"https://huggingface.co/Carey8175","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\té‡‘é“²é“²ä¹‹æˆ˜YOLOè‹±é›„æ•°æ®é›†(S13)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç®€ä»‹\\n\\t\\n\\næœ¬æ•°æ®é›†æ˜¯ç”¨äºè®­ç»ƒYOLOæ¨¡å‹çš„é‡‘é“²é“²ä¹‹æˆ˜S13èµ›å­£çš„è‹±é›„æ•°æ®é›†ã€‚åŒ…å«æ€»å…±è‹±é›„çš„å¥•å­å½¢æ€ï¼Œç”¨äºè®­ç»ƒæ¨¡å‹è¯†åˆ«è‹±é›„çŠ¶æ€\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ ‡ç­¾\\n\\t\\n\\næœ¬æ•°æ®é›†çš„æ ‡ç­¾å‘½åæ–¹å¼ä¸º: è‹±é›„åå­—\\nå…±è®¡61ä¸ªæ ‡ç­¾, 60ä¸ªè‹±é›„åŠ ä¸Šä¸€ä¸ªå¡æ©\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†\\n\\t\\n\\næœ¬æ¬¡æ•°æ®é›†å…±è®¡176å¼ å›¾ç‰‡å’Œ200å¼ æ•°æ®å¢å¼ºå›¾ç‰‡ï¼Œå…±è®¡376å¼ ï¼Œå¯é€šè¿‡æä¾›çš„æ•°æ®è‡ªè¡Œåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\\næ ‡ç­¾æ•°é‡ç›´æ–¹å›¾å¦‚ä¸‹ï¼š\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnhance\\n\\t\\n\\næœ¬æ•°æ®é›†å¯é€šè¿‡æ•°æ®å¢å¼ºå·¥å…·è¿›è¡Œæ•°æ®å¢å¼ºï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\\nå¢å¼ºæ•°æ®é›†ä¸­ä½¿ç”¨äº†ä»¥ä¸‹å¢å¼ºæ–¹å¼ï¼š\\n\\néšæœºæ—‹è½¬ï¼ˆ10åº¦ï¼‰\\néšæœºç¼©æ”¾ï¼ˆ0.2ï¼‰\\néšæœºå¹³ç§»ï¼ˆ0.2ï¼‰\\né«˜æ–¯æ¨¡ç³Š\\néšæœºäº®åº¦\\néšæœºå¯¹æ¯”åº¦\\néšå³æ°´å¹³ç¿»è½¬\\n\\nç›®å‰çš„çš„åšæ³•æ˜¯ï¼Œå…ˆç”¨åŸºæœ¬æ•°æ®é›†è®­ç»ƒä¸€ä¸ªå¤§å‚æ•°æ¨¡å‹ï¼Œç„¶åæ”¶é›†æ–°æ•°æ®ï¼Œä½¿ç”¨æ¨¡å‹å»åˆæ­¥æ ‡è®°æ•°æ®ï¼Œç„¶åäººå·¥ä¿®æ­£ï¼Œä»è€Œä¸°å¯Œæ•°æ®é›†ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ–‡ä»¶è¯´æ˜\\n\\t\\n\\n\\ngenerate_yolo_format.py: åœ¨æŒ‡å®šè·¯å¾„ç”Ÿæˆæ•°æ®é›†â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Carey8175/spatula_s13_yolo_detection.","first_N":5,"first_N_keywords":["object-detection","Chinese","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"sql-injection","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kaveny/sql-injection","creator_name":"Kaven","creator_url":"https://huggingface.co/Kaveny","description":"\\n\\t\\n\\t\\t\\n\\t\\tSQLæ³¨å…¥æ¨ç†èƒ½åŠ›å¾®è°ƒæ•°æ®é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tæ¦‚è¿°\\n\\t\\n\\næœ¬æ•°æ®é›†æ—¨åœ¨å¸®åŠ©ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆé€šè¿‡ç‰¹å®šæ¡ˆä¾‹æ¥å¾®è°ƒæ¨¡å‹åœ¨SQLæ³¨å…¥ï¼ˆSQLiï¼‰æ£€æµ‹ä¸é¢„é˜²æ–¹é¢çš„èƒ½åŠ›ã€‚SQLæ³¨å…¥æ˜¯ä¸€ç§ä»£ç æ³¨å…¥æŠ€æœ¯ï¼Œæ”»å‡»è€…é€šè¿‡å°†æ¶æ„çš„SQLæŸ¥è¯¢æˆ–è¯­å¥æ’å…¥åº”ç”¨ç¨‹åºçš„è¾“å…¥å­—æ®µä¸­ï¼Œä»¥æ“çºµæ•°æ®åº“æ‰§è¡Œéæˆæƒçš„æ“ä½œã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\tæ•°æ®é›†ç”¨é€”\\n\\t\\n\\n\\nç ”ç©¶ç”¨é€”ï¼šä¸ºå®‰å…¨é¢†åŸŸçš„ç ”ç©¶äººå‘˜æä¾›å®é™…æ¡ˆä¾‹ï¼Œä»¥ä¾¿äºæ¢ç´¢å’Œå¼€å‘æ–°çš„é˜²å¾¡ç­–ç•¥ã€‚\\næ¨¡å‹è®­ç»ƒï¼šä¸ºæœºå™¨å­¦ä¹ æ¨¡å‹æä¾›è®­ç»ƒç´ æï¼Œä»¥æé«˜å…¶è¯†åˆ«å’Œé˜²èŒƒSQLæ³¨å…¥æ”»å‡»çš„èƒ½åŠ›ã€‚\\næ•™è‚²ç›®çš„ï¼šä½œä¸ºæ•™è‚²èµ„æºï¼Œå¸®åŠ©å­¦ç”Ÿå’Œæ–°æ‰‹äº†è§£SQLæ³¨å…¥çš„é£é™©åŠå…¶é˜²æŠ¤æªæ–½ã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tè·å–æ›´å¤šæ•°æ®\\n\\t\\n\\nå¦‚éœ€è·å–æ›´å¤šç›¸å…³æ•°æ®æˆ–å¸Œæœ›å‚ä¸è´¡çŒ®ï¼Œè¯·è®¿é—®æˆ‘ä»¬çš„GitHubä»“åº“ï¼š\\nAAuZZ/SQLiDataset\\n\\n\\t\\n\\t\\t\\n\\t\\tè®¸å¯è¯\\n\\t\\n\\næœ¬é¡¹ç›®ä½¿ç”¨Apache 2.0è®¸å¯è¯ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…LICENSEæ–‡ä»¶ã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset for Fine-tuning Reasoning Ability in SQL Injection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverviewâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kaveny/sql-injection.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"traindata_content","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dsacedsfds/traindata_content","creator_name":"sss","creator_url":"https://huggingface.co/dsacedsfds","description":"dsacedsfds/traindata_content dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["token-classification","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"DetectiveQA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Phospheneser/DetectiveQA","creator_name":"Xu Zhe","creator_url":"https://huggingface.co/Phospheneser","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDetectiveQA\\n\\t\\n\\nThis is a bilingual dataset with an average question length of 100K, containing a series of detective novel questions and answers. These questions and answers are extracted from detective novels and cover various types of questions, such as: character relationships, event order, causes of events, etc.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1. Data Source/Collection\\n\\t\\n\\nThe novels in the dataset come from a collection of classical detective novels we gathered. These novels have the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Phospheneser/DetectiveQA.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"multi_llm_dpo","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lastmass/multi_llm_dpo","creator_name":"tang zhi xiong","creator_url":"https://huggingface.co/lastmass","description":"lastmass/multi_llm_dpo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"nlp_corpus_zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeroMN/nlp_corpus_zh","creator_name":"zeroTT","creator_url":"https://huggingface.co/zeroMN","description":"\\n\\t\\n\\t\\t\\n\\t\\tnlp_corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1 ä¸­æ–‡å®ä½“è¯†åˆ«\\n\\t\\n\\n\\nopen_ner_dataä¸ºç½‘ä¸Šå¼€æ”¾çš„neræ•°æ®é›†ï¼Œå·²å°†ä¸åŒçš„æ•°æ®æ ¼å¼è½¬åŒ–ä¸ºç»Ÿä¸€çš„æ•°æ®æ ¼å¼ï¼Œæ ¼å¼è½¬æ¢è„šæœ¬ä¸ºdata_transfer.py\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.1 bosonæ•°æ®é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.2 clueç»†ç²’åº¦å®ä½“è¯†åˆ«æ•°æ®é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.3 å¾®è½¯å®ä½“è¯†åˆ«æ•°æ®é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.4 äººæ°‘ç½‘å®ä½“è¯†åˆ«æ•°æ®é›†ï¼ˆ98å¹´ï¼‰\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.5 ä¸­è¯è¯´æ˜ä¹¦å®ä½“è¯†åˆ«æ•°æ®é›†ï¼ˆâ€œä¸‡åˆ›æ¯â€ä¸­åŒ»è¯å¤©æ± å¤§æ•°æ®ç«èµ›ï¼‰\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.6 è§†é¢‘_éŸ³ä¹_å›¾ä¹¦æ•°æ®é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.7 å¾®åšæ•°æ®é›†\\n\\t\\n\\n","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"LLaVA-NeXT-Audio","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ColorfulAI/LLaVA-NeXT-Audio","creator_name":"Yuxuan Wang","creator_url":"https://huggingface.co/ColorfulAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tLLaVA-NeXT-Data\\n\\t\\n\\nBuilding on the LLaVA-NeXT-Data, we convert user queries into audio using CosyVoice, with a randomly selected VoiceAssistant as a prompt.\\n","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","1M<n<10M","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"company_intro_qa","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/masonchu/company_intro_qa","creator_name":"chu","creator_url":"https://huggingface.co/masonchu","description":"masonchu/company_intro_qa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"OmniDocBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Quivr/OmniDocBench","creator_name":"Quivr","creator_url":"https://huggingface.co/Quivr","description":"Forked from opendatalab/OmniDocBench.\\n\\n\\t\\n\\t\\t\\n\\t\\tSampler\\n\\t\\n\\nWe have added a simple Python tool for filtering and performing stratified sampling on OmniDocBench data.\\n\\n\\t\\n\\t\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nFilter JSON entries based on custom criteria\\nPerform stratified sampling based on multiple categories\\nHandle nested JSON fields\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tInstallation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLocal Development Install (Recommended)\\n\\t\\n\\ngit clone https://huggingface.co/Quivr/OmniDocBench.git\\ncd OmniDocBench\\npip install -r requirements.txt  #â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Quivr/OmniDocBench.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"storage","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Pikilap/storage","creator_name":"Joe Zlorix","creator_url":"https://huggingface.co/Pikilap","description":"\\n\\t\\n\\t\\t\\n\\t\\tå…è´£å£°æ˜\\n\\t\\n\\n\\nè¯¥ä»“åº“çš„èµ„æºå‡æ¥æºäºç½‘ç»œï¼Œè‹¥æœ‰ä¾µæƒè¯·è”ç³»æˆ‘è¿›è¡Œåˆ é™¤ã€‚\\n\\n","first_N":5,"first_N_keywords":["Chinese","mit","10K<n<100K","Image","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"blossom-v6-sft-stage1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-v6-sft-stage1","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\tBLOSSOM V6 SFT STAGE1\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nBLOSSOM V6 SFT Stage1 is a high-quality, diverse large language model fine-tuning dataset designed for the first-stage SFT training of the Blossom V6 model. Its purpose is to help the model initially align dialogue capabilities through exposure to large-scale synthetic data.  \\nWhile open-source large language models often release model weights and technical reports, the most advanced open-source models typically withhold theirâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-v6-sft-stage1.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-Polylingo-50k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","description":"\\n\\t\\n\\t\\t\\n\\t\\tGammaCorpus Polylingo 50k\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is it?\\n\\t\\n\\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\\n\\nInput: A user prompt or question.\\nOutput: A response generated by an AI assistant.\\nLanguage: The language used in the interaction.\\n\\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k.","first_N":5,"first_N_keywords":["text-generation","English","Russian","Vietnamese","German"],"keywords_longer_than_N":true},
	{"name":"tojoyfoundation","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bcc/tojoyfoundation","creator_name":"bucheyu","creator_url":"https://huggingface.co/bcc","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bcc/tojoyfoundation.","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Metro_Code_Chapters_18_to_22_Data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OrangeeSofty/Metro_Code_Chapters_18_to_22_Data","creator_name":"Mingc","creator_url":"https://huggingface.co/OrangeeSofty","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Metro System Requirements in Design\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nThis dataset provides detailed requirements for systems used in metro network design, collected from Chapter 18-22 of the Code for Design of Metro (GB 50157-2013). The dataset is annotated using a description, categories format, aimed at facilitating the training and fine-tuning of large language models (LLMs) for information extraction tasks in complex product systems, particularly within metro transitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OrangeeSofty/Metro_Code_Chapters_18_to_22_Data.","first_N":5,"first_N_keywords":["text-classification","feature-extraction","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"creative-ad-prompts-zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/creative-ad-prompts-zh","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\tData Card\\n\\t\\n\\nThis is the training data for CreativeTinyZero, consisting of advertisement generation related prompts.\\nRL requires only prompts, so we use GPT models to:\\n\\nGenerate diverse entities across various domains.\\nApply the following prompt template:\\n\\nfrom transformers import pipeline\\n\\nsystem_prompt = \\\"\\\"ä½ æ˜¯ä¸€ä½åˆ›æ„å¹¿å‘Šè®¾è®¡å¸ˆï¼Œè´Ÿè´£ä¸ºç”¨æˆ·é‡èº«å®šåˆ¶ç‹¬ç‰¹çš„å¹¿å‘Šæ–‡æ¡ˆã€‚åœ¨å¼€å§‹åˆ›ä½œä¹‹å‰ï¼Œè¯·å…ˆæ·±å…¥æ€è€ƒæ•´ä¸ªåˆ›æ„è¿‡ç¨‹ï¼Œå¹¶å°†ä½ çš„æ€è€ƒé€»è¾‘æ¸…æ™°åœ°å‘ˆç°å‡ºæ¥ã€‚å…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š\\n\\n1. **æ€è€ƒè¿‡ç¨‹**ï¼šé¦–å…ˆï¼Œåˆ†æç”¨æˆ·çš„éœ€æ±‚ã€å“ç‰Œå®šä½ã€ç›®æ ‡å—ä¼—ä»¥åŠå¹¿å‘Šçš„æ ¸å¿ƒä¿¡æ¯ã€‚è€ƒè™‘å¦‚ä½•é€šè¿‡åˆ›æ„è¡¨è¾¾å°†è¿™äº›å…ƒç´ æœ‰æœºç»“åˆï¼Œå½¢æˆå…·æœ‰å¸å¼•åŠ›çš„å¹¿å‘Šæ–‡æ¡ˆã€‚å°†è¿™ä¸€æ€è€ƒè¿‡ç¨‹è¯¦ç»†è®°å½•åœ¨ `<think>` æ ‡ç­¾å†…â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/creative-ad-prompts-zh.","first_N":5,"first_N_keywords":["Chinese","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"dark_thoughts_stakeholders_test","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tonic/dark_thoughts_stakeholders_test","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"Tonic/dark_thoughts_stakeholders_test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","Chinese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"dark_thoughts_stakeholders","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DataTonic/dark_thoughts_stakeholders","creator_name":"Data Tonic (Alignment Lab)","creator_url":"https://huggingface.co/DataTonic","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DataTonic/dark_thoughts_stakeholders.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"HundredCVs","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jax-dan/HundredCVs","creator_name":"Jax","creator_url":"https://huggingface.co/Jax-dan","description":"\\n\\t\\n\\t\\t\\n\\t\\tç™¾äººç®€å†æ•°æ®é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tHundredCVs: A Curriculum Vitae Dataset of 100 Young Chinese People\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tç®€ä»‹\\n\\t\\n\\næœ¬é¡¹ç›®æå‡ºä¸€ä¸ªå…¨æ–°çš„ä¸­æ–‡ç®€å†æ•°æ®é›†ï¼ˆHundredCVsï¼‰ï¼ŒåŒ…å«äº† 100 ä½é’å¹´çš„ä¸ªäººç®€å†ã€‚HundredCVs å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š\\n\\nå¹´è½»åŒ–ã€å¤šæ ·æ€§ï¼šæ•°æ®é›†ä¸­çš„äººç‰©å¹´é¾„åˆ†å¸ƒåœ¨ 15~30 å²ä¹‹é—´ï¼Œå¹¿æ³›æ¶µç›–äº†ä¸åŒæ€§åˆ«ã€ä¸åŒèŒä¸šã€ä¸åŒå­¦å†ï¼ˆé«˜ä¸­è‡³åšå£«ä¸ç­‰ï¼‰ã€‚\\nç»“æ„å®Œæ•´ï¼šæ¯ä»½ç®€å†ä¸­çš„ä¿¡æ¯åŒ…æ‹¬äººç‰©çš„ä¸ªäººåç‰‡ã€æ€§æ ¼ç‰¹å¾ã€ä¸»è¦äº‹è¿¹ï¼Œä»¥åŠè¯¦ç»†ç»å†/ä¸ªäººè‡ªè¿°ç­‰ã€‚ \\nå®‰å…¨æ€§ï¼šæˆ‘ä»¬ä½¿ç”¨åŒ–åæ›¿ä»£äº†äººç‰©çš„çœŸå®å§“åï¼Œæ­¤å¤–ï¼Œäººç‰©ç»å†ä¹Ÿä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹çš„æ”¹å†™å’Œæç‚¼ï¼Œè¡¨ç°å‡ºæ ‡å‡†åŒ–å’Œä¸€è‡´æ€§çš„è¯­è¨€é£æ ¼ã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tè®¾è®¡æ„å›¾\\n\\t\\n\\nHundredCVs çš„æå‡ºä¸»è¦æ˜¯ä¸ºäº†æ–¹ä¾¿ç ”ç©¶è€…å¼€å±•åŸºäºç®€å†çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚æ•°æ®é›†ä¸­æä¾›ä¸¤ä¸ªæ–‡ä»¶:\\n\\nprofile.jsonï¼šæ¯æ¡è®°å½•åªåŒ…å«äººç‰©çš„ä¸ªäººåç‰‡ã€æ€§æ ¼ç‰¹å¾å’Œä¸»è¦äº‹è¿¹ã€‚å¯ç”¨äºå¼€å±•è§’è‰²æ‰®æ¼”ã€äººç‰©ç”»åƒæ„å»ºç­‰ä»»åŠ¡ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jax-dan/HundredCVs.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"HundredCV-Chat","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jax-dan/HundredCV-Chat","creator_name":"Jax","creator_url":"https://huggingface.co/Jax-dan","description":"\\n\\t\\n\\t\\t\\n\\t\\tç™¾äººå¯¹è¯æ•°æ®é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tHundredCV-Chat: A Dataset of Daily Chatting Developed on HundredCVs\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tç®€ä»‹\\n\\t\\n\\næœ¬é¡¹ç›®æå‡ºä¸€ä¸ªå…¨æ–°çš„ä¸­æ–‡å¤šè½®å¯¹è¯æ•°æ®é›†ï¼ˆHundredCV-Chatï¼‰ï¼Œè¯¥æ•°æ®é›†ç”± 100 ä½é’å¹´çš„ç®€å†æ•°æ®é›† HundredCVs å¼€å‘è€Œæ¥ï¼Œå…±åŒ…å« 24,750 ç»„æ—¥å¸¸é—²èŠå¯¹è¯æ•°æ®ã€‚\\næ•°æ®é›†å…·æœ‰å¦‚ä¸‹ç‰¹ç‚¹ï¼š\\n\\nè‡ªåŠ¨åŒ–æ ‡æ³¨ï¼šHundredCV-Chat ä¸­çš„å¯¹è¯å‡ç”± Deepseek-V3 å¤§æ¨¡å‹ç”Ÿæˆï¼Œä¸æ¶‰åŠä»»ä½•äººå·¥æ ‡æ³¨ï¼Œå› æ­¤åŒæ—¶ä¿è¯äº†å¤§è§„æ¨¡æ•°æ®é‡å’Œä½æˆæœ¬ä¼˜åŠ¿ã€‚\\nå¤šæ ·æ€§è¯é¢˜ï¼šHundredCV-Chat ä¸­çš„å¯¹è¯è¯é¢˜æ¶µç›–äº†æ ¡å›­ç”Ÿæ´»ã€å·¥ä½œç»éªŒã€å…´è¶£çˆ±å¥½ã€ç”Ÿæ´»çäº‹ç­‰å¤šä¸ªæ–¹é¢ï¼Œä¸çœŸå®ç”Ÿæ´»è”ç³»ç´§å¯†ï¼Œå°¤å…¶é€‚ç”¨äºå¼€å‘å¹´è½»åŒ–åº”ç”¨ã€‚\\né«˜è´¨é‡å¯¹è¯ï¼šåˆ©ç”¨ Deepseek å¼ºå¤§çš„ç”Ÿæˆèƒ½åŠ›å’Œå…¨é¢çš„çŸ¥è¯†ï¼ŒHundredCV-Chat çš„å¯¹è¯å†…å®¹åœ¨æµç•…åº¦ã€æ‹Ÿäººæ€§ã€å¤šæ ·æ€§æ–¹é¢å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„å¼€æºå¯¹è¯æ•°æ®é›†ã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tæ•°æ®æ ·ä¾‹\\n\\t\\n\\nHundredCV-Chat å«æœ‰ 24â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jax-dan/HundredCV-Chat.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"runpod_qwen32_benign_thoughts_casestudies_rescued","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DataTonic/runpod_qwen32_benign_thoughts_casestudies_rescued","creator_name":"Data Tonic (Alignment Lab)","creator_url":"https://huggingface.co/DataTonic","description":"DataTonic/runpod_qwen32_benign_thoughts_casestudies_rescued dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","Chinese","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"URS","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JiayinWang/URS","creator_name":"JiayinWang","creator_url":"https://huggingface.co/JiayinWang","description":"\\n\\t\\n\\t\\t\\n\\t\\tUser-Centric Evaluation of LLMs\\n\\t\\n\\nğŸ“š Our Paper (EMNLP 24 Resource Award)\\nA User-Centric Multi-Intent Benchmark for Evaluating Large Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\tUser Reported Scenario (URS) Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Features\\n\\t\\n\\n\\nUser-Centric\\n\\nReal-world usage scenarios of LLMs\\nThe dataset is collected through a User Survey with 712 participants from 23 countries in 6 continents.\\n\\n\\nMulti-Intent\\n\\nSystem abilities and performances in different scenarios might be different\\nUsersâ€™â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JiayinWang/URS.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"JUREX-4E","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zotown/JUREX-4E","creator_name":"zotown","creator_url":"https://huggingface.co/zotown","description":"\\n\\t\\n\\t\\t\\n\\t\\tJUREX\\n\\t\\n\\nSource code and data for JUREX-4E: Juridical Expert-Annotated Four-Element Knowledge Base for Legal Reasoning\\nCode: https://github.com/THUlawtech/JUREX\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\n\\nDataset Structure\\nAnnotation\\nExperiment\\nSimilar Charge Distinction\\nLegal Case Retrieval\\n\\n\\nRequirements\\nLicense\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nJUREX-4E is the first part of our curated expert knowledge base(mind map structure), \\nfocusing on the four elements of criminal charges.\\ndata\\n- law  # legal textsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zotown/JUREX-4E.","first_N":5,"first_N_keywords":["question-answering","Chinese","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"JUREX-4E","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zotown/JUREX-4E","creator_name":"zotown","creator_url":"https://huggingface.co/zotown","description":"\\n\\t\\n\\t\\t\\n\\t\\tJUREX\\n\\t\\n\\nSource code and data for JUREX-4E: Juridical Expert-Annotated Four-Element Knowledge Base for Legal Reasoning\\nCode: https://github.com/THUlawtech/JUREX\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\n\\nDataset Structure\\nAnnotation\\nExperiment\\nSimilar Charge Distinction\\nLegal Case Retrieval\\n\\n\\nRequirements\\nLicense\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nJUREX-4E is the first part of our curated expert knowledge base(mind map structure), \\nfocusing on the four elements of criminal charges.\\ndata\\n- law  # legal textsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zotown/JUREX-4E.","first_N":5,"first_N_keywords":["question-answering","Chinese","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"piaozhu","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Retr01234/piaozhu","creator_name":"Chen","creator_url":"https://huggingface.co/Retr01234","description":"\\n\\t\\n\\t\\t\\n\\t\\tæ•°æ®é›†åç§°ï¼šå˜´è‡­æ­å­å¾®è°ƒæ•°æ®é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1. æ•°æ®é›†ç®€ä»‹\\n\\t\\n\\nè¿™ä¸ªæ•°æ®é›†ä¸ºå¾®è°ƒå¯¹è¯ç”Ÿæˆæ¨¡å‹æä¾›äº†ä¸€ä¸ªç‰¹æ®Šçš„è®­ç»ƒæ ·æœ¬ï¼ŒåŸºäºä¸€ä¸ªè™šæ‹Ÿçš„è§’è‰²â€œæ²ˆè“¬ç«¹â€è¿›è¡Œäº¤äº’ã€‚è¿™ä¸ªè§’è‰²ï¼ˆå¤–å·â€œæœ´ç«¹â€ï¼‰å…·æœ‰å†·å˜²çƒ­è®½ã€æ¯’èˆŒã€ç®€æ´è€Œæœ‰æ”»å‡»æ€§çš„ç‰¹ç‚¹ï¼Œé€‚åˆè®­ç»ƒæ¨¡å‹äº§ç”Ÿå…·æœ‰è®½åˆºã€å†·å˜²çƒ­è®½è¯­æ°”çš„å›ç­”ã€‚æ•°æ®é›†çš„å†…å®¹ä¸»è¦æ˜¯è§’è‰²æ‰®æ¼”å¯¹è¯åœºæ™¯ï¼Œé€‚ç”¨äºç”Ÿæˆå…·æœ‰ç‰¹å®šé£æ ¼çš„å¯¹è¯æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯åœ¨å¸¦æœ‰è®½åˆºå’Œå¹½é»˜çš„æƒ…å¢ƒä¸‹è¿›è¡Œäº’åŠ¨æ—¶ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\t2. æ•°æ®é›†ç»“æ„\\n\\t\\n\\næ•°æ®é›†ä¸ºä¸€ä¸ªåŒ…å«è‹¥å¹²å¯¹è¯è½®æ¬¡çš„ JSON æ ¼å¼æ–‡ä»¶ã€‚æ¯ä¸ªå¯¹è¯è½®æ¬¡ç”±è§’è‰²å’Œç”¨æˆ·çš„å¯¹è¯ç»„æˆï¼Œæ¯ä¸ªå¯¹è¯åŒ…å«ä»¥ä¸‹å­—æ®µï¼š\\n\\nroleï¼šè§’è‰²çš„èº«ä»½ï¼Œå¯èƒ½æ˜¯ \\\"system\\\" æˆ– \\\"user\\\"ã€‚\\n\\\"system\\\" è¡¨ç¤ºæ˜¯æ¨¡å‹è®¾å®šè§’è‰²çš„è¾“å…¥ï¼ˆå¦‚å®šä¹‰è§’è‰²èƒŒæ™¯ã€è¡Œä¸ºæ¨¡å¼ç­‰ï¼‰ã€‚\\n\\\"user\\\" è¡¨ç¤ºå¯¹è¯ä¸­çš„ç”¨æˆ·è¾“å…¥ï¼ˆå¦‚æé—®ã€è¯·æ±‚æˆ–äº¤äº’ï¼‰ã€‚\\n\\n\\ncontentï¼šå¯¹è¯å†…å®¹ï¼Œè¡¨ç¤ºè§’è‰²æˆ–è€…ç”¨æˆ·çš„å…·ä½“å‘è¨€ã€‚\\nloss_weightï¼ˆå¯é€‰ï¼‰ï¼šæ¯ä¸ªæ•°æ®æ¡ç›®å¯¹åº”çš„æŸå¤±æƒé‡ï¼Œå½“å‰å¯ä¸ºç©ºæˆ–ä¸º nullã€‚å¯ä»¥åœ¨æ¨¡å‹è®­ç»ƒä¸­åŠ æƒä¸åŒå¯¹è¯å†…å®¹ã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t3. æ•°æ®æ ·ä¾‹â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Retr01234/piaozhu.","first_N":5,"first_N_keywords":["text-generation","Chamorro","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"piaozhu","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Retr01234/piaozhu","creator_name":"Chen","creator_url":"https://huggingface.co/Retr01234","description":"\\n\\t\\n\\t\\t\\n\\t\\tæ•°æ®é›†åç§°ï¼šå˜´è‡­æ­å­å¾®è°ƒæ•°æ®é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1. æ•°æ®é›†ç®€ä»‹\\n\\t\\n\\nè¿™ä¸ªæ•°æ®é›†ä¸ºå¾®è°ƒå¯¹è¯ç”Ÿæˆæ¨¡å‹æä¾›äº†ä¸€ä¸ªç‰¹æ®Šçš„è®­ç»ƒæ ·æœ¬ï¼ŒåŸºäºä¸€ä¸ªè™šæ‹Ÿçš„è§’è‰²â€œæ²ˆè“¬ç«¹â€è¿›è¡Œäº¤äº’ã€‚è¿™ä¸ªè§’è‰²ï¼ˆå¤–å·â€œæœ´ç«¹â€ï¼‰å…·æœ‰å†·å˜²çƒ­è®½ã€æ¯’èˆŒã€ç®€æ´è€Œæœ‰æ”»å‡»æ€§çš„ç‰¹ç‚¹ï¼Œé€‚åˆè®­ç»ƒæ¨¡å‹äº§ç”Ÿå…·æœ‰è®½åˆºã€å†·å˜²çƒ­è®½è¯­æ°”çš„å›ç­”ã€‚æ•°æ®é›†çš„å†…å®¹ä¸»è¦æ˜¯è§’è‰²æ‰®æ¼”å¯¹è¯åœºæ™¯ï¼Œé€‚ç”¨äºç”Ÿæˆå…·æœ‰ç‰¹å®šé£æ ¼çš„å¯¹è¯æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯åœ¨å¸¦æœ‰è®½åˆºå’Œå¹½é»˜çš„æƒ…å¢ƒä¸‹è¿›è¡Œäº’åŠ¨æ—¶ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\t2. æ•°æ®é›†ç»“æ„\\n\\t\\n\\næ•°æ®é›†ä¸ºä¸€ä¸ªåŒ…å«è‹¥å¹²å¯¹è¯è½®æ¬¡çš„ JSON æ ¼å¼æ–‡ä»¶ã€‚æ¯ä¸ªå¯¹è¯è½®æ¬¡ç”±è§’è‰²å’Œç”¨æˆ·çš„å¯¹è¯ç»„æˆï¼Œæ¯ä¸ªå¯¹è¯åŒ…å«ä»¥ä¸‹å­—æ®µï¼š\\n\\nroleï¼šè§’è‰²çš„èº«ä»½ï¼Œå¯èƒ½æ˜¯ \\\"system\\\" æˆ– \\\"user\\\"ã€‚\\n\\\"system\\\" è¡¨ç¤ºæ˜¯æ¨¡å‹è®¾å®šè§’è‰²çš„è¾“å…¥ï¼ˆå¦‚å®šä¹‰è§’è‰²èƒŒæ™¯ã€è¡Œä¸ºæ¨¡å¼ç­‰ï¼‰ã€‚\\n\\\"user\\\" è¡¨ç¤ºå¯¹è¯ä¸­çš„ç”¨æˆ·è¾“å…¥ï¼ˆå¦‚æé—®ã€è¯·æ±‚æˆ–äº¤äº’ï¼‰ã€‚\\n\\n\\ncontentï¼šå¯¹è¯å†…å®¹ï¼Œè¡¨ç¤ºè§’è‰²æˆ–è€…ç”¨æˆ·çš„å…·ä½“å‘è¨€ã€‚\\nloss_weightï¼ˆå¯é€‰ï¼‰ï¼šæ¯ä¸ªæ•°æ®æ¡ç›®å¯¹åº”çš„æŸå¤±æƒé‡ï¼Œå½“å‰å¯ä¸ºç©ºæˆ–ä¸º nullã€‚å¯ä»¥åœ¨æ¨¡å‹è®­ç»ƒä¸­åŠ æƒä¸åŒå¯¹è¯å†…å®¹ã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t3. æ•°æ®æ ·ä¾‹â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Retr01234/piaozhu.","first_N":5,"first_N_keywords":["text-generation","Chamorro","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"twisc","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yxhong-tw/twisc","creator_name":"Yu-Xiang Hong","creator_url":"https://huggingface.co/yxhong-tw","description":"\\n\\t\\n\\t\\t\\n\\t\\tTaiwan-Indictment-Summarization-Corpus (TWISC)\\n\\t\\n\\nTaiwan-Indictment-Summarization-Corpus (TWISC) is a dataset designed for legal judgment prediction and legal text summarization. It is collected from Taiwan Ministry of Justice and covers data from 2018/06 to 2021/06.\\nThis dataset is used in the paper Improving Colloquial Case Legal Judgment Prediction via Abstractive Text Summarization published in Computer Law & Security Review (2023).\\nWe express our gratitude to Professor Chia-Huiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yxhong-tw/twisc.","first_N":5,"first_N_keywords":["text-classification","summarization","Chinese","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"WalnutData","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nanmao/WalnutData","creator_name":"liyi","creator_url":"https://huggingface.co/nanmao","description":"\\n  \\n  \\n\\n\\t\\n\\t\\t\\n\\t\\tWalnutData\\n\\t\\n\\n  \\n\\nWith the gradual maturity of UAV technology, it can provide extremely powerful support for smart agriculture and precise monitoring. Currently, there is no dataset related to green walnuts in the field of agricultural computer vision. Therefore, in order to promote the algorithm design in the field of agricultural computer vision, we used UAV to collect remote sensing data from 8 walnut sample plots. Considering that green walnuts have the characteristics ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nanmao/WalnutData.","first_N":5,"first_N_keywords":["object-detection","Chinese","apache-2.0","10K<n<100K","Image"],"keywords_longer_than_N":true},
	{"name":"text","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wuji8836/text","creator_name":"wuji","creator_url":"https://huggingface.co/wuji8836","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wuji8836/text.","first_N":5,"first_N_keywords":["text-classification","Chinese","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Blast_TrainData","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lvlvlvlv1/Blast_TrainData","creator_name":"lvhaoyuan","creator_url":"https://huggingface.co/lvlvlvlv1","description":"\\n\\t\\n\\t\\t\\n\\t\\tçˆ†ç ´çŸ¥è¯†æ•°æ®é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tæ•°æ®é›†è¯¦æƒ…\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tæ•°æ®é›†æè¿°\\n\\t\\n\\næœ¬æ•°æ®é›†èšç„¦äºçˆ†ç ´å·¥ç¨‹é¢†åŸŸï¼ŒåŒ…å«ä¸“ä¸šæŠ€æœ¯æ–‡æ¡£ã€å®‰å…¨æ“ä½œè§„èŒƒã€æ¡ˆä¾‹ç ”ç©¶ç­‰ç»“æ„åŒ–æ–‡æœ¬æ•°æ®ã€‚é€‚ç”¨äºNLPæ¨¡å‹åœ¨çˆ†ç ´é¢†åŸŸçš„çŸ¥è¯†é—®ç­”ã€æ–‡æœ¬ç”Ÿæˆç­‰ä»»åŠ¡ã€‚\\nå…³é”®ç‰¹å¾ï¼š\\n\\nè¦†ç›–å²©åœŸçˆ†ç ´ã€æ‹†é™¤çˆ†ç ´ã€çˆ†ç ´å®‰å…¨ç­‰å­é¢†åŸŸ\\nåŒ…å«å…¬å¼ã€å‚æ•°è¡¨ç­‰ä¸“ä¸šå†…å®¹\\nä¸­è‹±åŒè¯­ä¸“ä¸šæœ¯è¯­å¯¹ç…§\\n\\nåŸºç¡€ä¿¡æ¯ï¼š\\n\\nè¯­è¨€ï¼šä¸­æ–‡ï¼ˆåŒ…å«ä¸“ä¸šè‹±æ–‡æœ¯è¯­ï¼‰\\næ•°æ®é‡çº§ï¼šçº¦20000æ¡æ–‡æœ¬ç‰‡æ®µ\\næ—¶é—´è·¨åº¦ï¼š1980-2025å¹´\\nè®¸å¯åè®®ï¼šApache-2.0ï¼ˆæ³¨æ„ï¼šéƒ¨åˆ†å­é›†å¯èƒ½æœ‰ç‰¹æ®Šæˆæƒæ¡æ¬¾ï¼‰\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tæ•°æ®æ¥æº\\n\\t\\n\\n\\n\\t\\n\\t\\t\\næ•°æ®ç±»å‹\\nå æ¯”\\næ¥æºç¤ºä¾‹\\n\\n\\n\\t\\t\\nå­¦æœ¯è®ºæ–‡\\n35%\\nCNKIã€ä¸‡æ–¹ã€Elsevier\\n\\n\\næŠ€æœ¯æ ‡å‡†\\n25%\\nGB/Tä½“ç³»ã€OSHAæ ‡å‡†\\n\\n\\nå·¥ç¨‹æŠ¥å‘Š\\n20%\\né‡ç‚¹å·¥ç¨‹é¡¹ç›®æ–‡æ¡£\\n\\n\\nå®‰å…¨æ‰‹å†Œ\\n15%\\nä¼ä¸šå†…è®­èµ„æ–™\\n\\n\\nä¸“åˆ©æ–‡ä»¶\\n5%\\nå›½å®¶çŸ¥è¯†äº§æƒå±€\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tä½¿ç”¨åœºæ™¯\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tæ¨èç”¨é€”\\n\\t\\n\\nâœ… çˆ†ç ´é¢†åŸŸæ™ºèƒ½é—®ç­”ç³»ç»Ÿâœ… ä¸“ä¸šæŠ€æœ¯æ–‡æ¡£æ‘˜è¦ç”Ÿæˆâœ… å®‰å…¨éšæ‚£è¯†åˆ«ä¸é¢„è­¦âœ…â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lvlvlvlv1/Blast_TrainData.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"deep-xlsx","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jian2008/deep-xlsx","creator_name":"feng","creator_url":"https://huggingface.co/jian2008","description":"jian2008/deep-xlsx dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","mit","1K<n<10K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"AS-SRL","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Santu00/AS-SRL","creator_name":"HUIYAO CHEN","creator_url":"https://huggingface.co/Santu00","description":"\\n\\t\\n\\t\\t\\n\\t\\tAS-SRL: A Chinese Speech-based Semantic Role Labeling Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nAS-SRL is the first Chinese speech-based Semantic Role Labeling (SRL) dataset, created by annotating the open-source Mandarin speech corpus AISHELL-1 with semantic role labels following the guidelines of Chinese Proposition Bank 1.0 (CPB1.0). The dataset contains 9,000 speech-text pairs with corresponding SRL annotations, split into training (7,500), development (500), and test (1,000) sets.\\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Santu00/AS-SRL.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","Audio","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"multilingualcrowspairs","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/multilingualcrowspairs","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://gitlab.inria.fr/corpus4ethics/multilingualcrowspairs/\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultiLingualCrowsPairs\\n\\t\\n\\nMultilingual CrowS-Pairs, a challenge dataset for measuring stereotypical biases present in the masked language models (MLMs) in 7 different languages. \\nThis challenge dataset was built on the Crows-Pairs corpus (Nangia et al. 2020) using the methodology described in (NÃ©vÃ©ol et al. 2023). \\nThe 7 new languages are the following:\\n\\nArabic from Maghreb and the Arab world in generalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/multilingualcrowspairs.","first_N":5,"first_N_keywords":["text-classification","multilingual","Arabic","Catalan","German"],"keywords_longer_than_N":true},
	{"name":"traindata","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dsacedsfds/traindata","creator_name":"sss","creator_url":"https://huggingface.co/dsacedsfds","description":"dsacedsfds/traindata dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"emova-sft-4m","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-4m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-SFT-4M\\n\\t\\n\\n\\n\\n\\nğŸ¤— EMOVA-Models | ğŸ¤— EMOVA-Datasets | ğŸ¤— EMOVA-Demo \\nğŸ“„ Paper | ğŸŒ Project-Page | ğŸ’» Github | ğŸ’» EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-SFT-4M is a comprehensive dataset curated for omni-modal instruction tuning, including textual, visual, and audio interactions. This dataset is created by gathering open-sourced multi-modal instruction datasets and synthesizing high-quality omni-modal conversation data to enhance user experience. This dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-4m.","first_N":5,"first_N_keywords":["image-to-text","text-generation","audio-to-audio","automatic-speech-recognition","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"stickers","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LiuliFox/stickers","creator_name":"LiuliFox","creator_url":"https://huggingface.co/LiuliFox","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tã‚‹ã‚Šã®ã‚¹ãƒ†ãƒƒã‚«ãƒ¼\\n\\t\\n\\njust for fun.\\n","first_N":5,"first_N_keywords":["image-classification","Chinese","Japanese","English","mit"],"keywords_longer_than_N":true},
	{"name":"parallel_corpus_game_2024","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bot-yaya/parallel_corpus_game_2024","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","description":"https://github.com/mnbvc-parallel-corpus-team/parallel_corpus_mnbvc\\nMNBVCå¹³è¡Œè¯­æ–™å°ç»„ï¼šæ¸¸æˆè¯­æ–™\\nä¸å®šæœŸæ›´æ–°ï¼Œç›®å‰å·²æ”¶å½•çš„æ¸¸æˆè¯­æ–™æ–‡ä»¶ï¼Œå…±29ä»½ï¼š\\n\\nåšå¾·ä¹‹é—¨3\\nèµ›åšæœ‹å…‹2077\\né»‘æš—ä¹‹é­‚3\\nåº•ç‰¹å¾‹ï¼šåŒ–èº«ä¸ºäºº\\né¥¥è’\\nè‰¾å°”ç™»æ³•ç¯\\nåŸç¥\\né»‘å¸æ–¯\\néœæ ¼æ²ƒå…¹ä¹‹é—\\nIb\\nå¦‚é¾™8\\nå¦‚é¾™7å¤–ä¼ \\nè’é‡å¤§é•–å®¢2\\nåªç‹¼ï¼šå½±é€äºŒåº¦\\næ–‡æ˜6\\næ€æˆ®å°–å¡”\\nå´©åæ˜Ÿç©¹é“é“\\nç¾¤æ˜Ÿ\\næ³°æ‹‰ç‘äºš\\nå·«å¸ˆ3\\né­”å¥³ä¹‹æ³‰3\\né­”å¥³ä¹‹æ³‰R\\né¸£æ½®\\nå¦‚é¾™3\\nå¦‚é¾™4\\nå¦‚é¾™5\\nå¦‚é¾™6\\nå¦‚é¾™æ2\\nå¦‚é¾™7\\n\\n","first_N":5,"first_N_keywords":["translation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"nlg-machine_translation","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisingapore/nlg-machine_translation","creator_name":"AI Singapore","creator_url":"https://huggingface.co/aisingapore","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSEA Machine Translation\\n\\t\\n\\nSEA Machine Translation evaluates a model's ability to translate a document from a source language into a target language coherently and fluently. It is sampled from FLORES 200 for Burmese, Chinese, English, Indonesian, Khmer, Malay, Tamil, Thai, and Vietnamese, and NusaX for Indonesian, Javanese, and Sundanese.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nSEA Machine Translation is designed for evaluating chat or instruction-tuned large languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aisingapore/nlg-machine_translation.","first_N":5,"first_N_keywords":["text-generation","English","Indonesian","Javanese","Khmer"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/reysz/test","creator_name":"Rui Zhang","creator_url":"https://huggingface.co/reysz","description":"test\\nQA pairs\\nThis is used to test LLM applications in the field of ecological environment.\\n","first_N":5,"first_N_keywords":["question-answering","Chinese","mit","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\\nsource: the source sentence.\\nchosen: the preferred translation.\\nreject: the dis-preferred translation.\\ndirections: the translation direction.\\n@misc{xu2024xalmaplugplay,\\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \\n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\\n      year={2024},\\n      eprint={2410.03115}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"CPTransExercise","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/edmond5995/CPTransExercise","creator_name":"Hoi","creator_url":"https://huggingface.co/edmond5995","description":"Chinese-Portuguese Translation Exercise Corpus (CPTEC)\\nThis dataset aims to provide translators to practice Chinese-Portuguese translation with different levels from basic to proficient.\\nThis is a sample dataset from CPTEC, please contact us for more information.\\nlmhoi@mpu.edu.mo\\n","first_N":5,"first_N_keywords":["translation","Chinese","Portuguese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"dypromotion","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AntonCook/dypromotion","creator_name":"AntonHu","creator_url":"https://huggingface.co/AntonCook","description":"AntonCook/dypromotion dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"chinese_word_frequency","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jnext/chinese_word_frequency","creator_name":"N","creator_url":"https://huggingface.co/jnext","description":"\\n\\t\\n\\t\\t\\n\\t\\tChinese Word frequency statistics\\n\\t\\n\\nword segmentation by jieba tool\\n\\nseq_monkey_data : statistics on 13,000,000 document / 6,561,241,266 words / 11,313,242,610 characters\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10M - 100M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"ceshi1-weitiao-hetongzhapian","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Crazyht530/ceshi1-weitiao-hetongzhapian","creator_name":"guangzhao","creator_url":"https://huggingface.co/Crazyht530","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Crazyht530/ceshi1-weitiao-hetongzhapian.","first_N":5,"first_N_keywords":["question-answering","Chinese","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"tw-ly-bill","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfun/tw-ly-bill","creator_name":"Openfun Ltd.","creator_url":"https://huggingface.co/openfun","description":"openfun/tw-ly-bill dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","1K - 10K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"tw-ly-meet","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfun/tw-ly-meet","creator_name":"Openfun Ltd.","creator_url":"https://huggingface.co/openfun","description":"openfun/tw-ly-meet dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","< 1K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"tw-ly-law","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfun/tw-ly-law","creator_name":"Openfun Ltd.","creator_url":"https://huggingface.co/openfun","description":"openfun/tw-ly-law dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"tw-ly-law_version","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfun/tw-ly-law_version","creator_name":"Openfun Ltd.","creator_url":"https://huggingface.co/openfun","description":"openfun/tw-ly-law_version dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"BRIGHTER-emotion-intensities","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\tBRIGHTER Emotion Intensities Dataset\\n\\t\\n\\nThis dataset contains the emotion intensities data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe BRIGHTER Emotion Intensities dataset is a comprehensive multi-language emotion intensity dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple languages, providingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities.","first_N":5,"first_N_keywords":["Arabic","German","English","Spanish","Hausa"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-a","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track A Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track A, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 26 standard ISO codes\\nTotal examples: 115159\\nSplits: train, dev, test\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguage Configurations\\n\\t\\n\\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-c","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track C Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track C, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 30 standard ISO codes\\nTotal examples: 57254\\nSplits: dev, test (Track C has no train split)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTrackâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"tw-ly-gazette","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfun/tw-ly-gazette","creator_name":"Openfun Ltd.","creator_url":"https://huggingface.co/openfun","description":"openfun/tw-ly-gazette dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","1K - 10K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"Diabetica-SFT","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WaltonFuture/Diabetica-SFT","creator_name":"Lai Wei","creator_url":"https://huggingface.co/WaltonFuture","description":"\\n\\t\\n\\t\\t\\n\\t\\tDiabetica-SFT\\n\\t\\n\\n\\n\\n    Diabetica: Adapting Large Language Model to Enhance Multiple Medical Tasks in Diabetes Care and Management\\n\\n\\n\\n\\n\\nCode ï½œPaper \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nHello! Welcome to the huggingface repository for Diabetica. \\nOur study introduced a reproducible framework for developing a specialized LLM capable of handling various diabetes tasks. We present three key contributions: \\n\\nHigh-performance domain-specific model: Compared with previous generic LLMs, our modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WaltonFuture/Diabetica-SFT.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"immersive-translate-en2zh","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/immersive-translate-en2zh","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tImmersive Translate\\n\\t\\n\\næœ¬æ•°æ®é›†æ˜¯é€‚ç”¨äºæ²‰æµ¸å¼ç¿»è¯‘ä¸­è°ƒç”¨å¤§æ¨¡å‹ç¿»è¯‘æ—¶çš„promptæ¨¡æ¿çš„æ•°æ®é›†. å—æœ¬åœ°å¤§æ¨¡å‹æ€§èƒ½é™åˆ¶, æˆ‘æ²¡æœ‰é‡‡ç”¨å¤šæ®µæ–‡å­—çš„promptæ¨¡æ¿, ä»…ä½¿ç”¨å•æ®µæ–‡å­—çš„é»˜è®¤promptæ¨¡æ¿. system promptä¹Ÿé‡‡ç”¨é€šç”¨ç¿»è¯‘ä¸“å®¶çš„é»˜è®¤system prompt\\næœ¬æ•°æ®é›†ç”±Garsa3112/ChineseEnglishTranslationDatasetå’Œbfsujason@github/macç”Ÿæˆ\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","gpl-3.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"BiST","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/BiST","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBiST\\n\\t\\n\\nEnglish | ç®€ä½“ä¸­æ–‡\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nBiST is a large-scale bilingual translation dataset, with \\\"BiST\\\" standing for Bilingual Synthetic Translation dataset. Currently, the dataset contains approximately 57,000,000 entries and will continue to expand in the future.\\nBiST consists of two subsets, namely en-zh and zh-en, where the former represents the source language, collected from public data as real-world content; the latter represents the target language forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mxode/BiST.","first_N":5,"first_N_keywords":["translation","English","Chinese","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"ChFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tzyll/ChFT","creator_name":"Zhiyuan Tang","creator_url":"https://huggingface.co/tzyll","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ChFT\\n\\t\\n\\n\\n\\nThis dataset is published with the paper Full-text Error Correction for Chinese Speech Recognition with Large Language Model in ICASSP 2025.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sourcesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tzyll/ChFT.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","apache-2.0","arxiv:2409.07790","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"toxic-nlp-combine","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TFuuki/toxic-nlp-combine","creator_name":"Tan Youxi","creator_url":"https://huggingface.co/TFuuki","description":"TFuuki/toxic-nlp-combine dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"Address-Classifyer","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/5m4ck3r/Address-Classifyer","creator_name":"Pryanshu Sharma","creator_url":"https://huggingface.co/5m4ck3r","description":"5m4ck3r/Address-Classifyer dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["zero-shot-classification","text-classification","English","Spanish","Chinese"],"keywords_longer_than_N":true},
	{"name":"NT-mini","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/NT-mini","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"Mxode/NT-mini dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","English","Chinese","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"kurage_training_data","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/kurage_training_data","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"lightblue/kurage_training_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Arabic","English","Spanish","Hindi","Indonesian"],"keywords_longer_than_N":true},
	{"name":"wukong","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shushu3456/wukong","creator_name":"shushu","creator_url":"https://huggingface.co/shushu3456","description":"shushu3456/wukong dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"Coupang-Product-Set-2.7M","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clw8998/Coupang-Product-Set-2.7M","creator_name":"WW","creator_url":"https://huggingface.co/clw8998","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Load the Dataset\\n\\t\\n\\nYou can load this dataset using the Hugging Face datasets library as follows:\\nMake sure you have the datasets library installed:\\npip install datasets\\n\\nUse the following code to retrieve the dataset:\\nfrom datasets import load_dataset\\n\\n# Load the Coupang Product Set 1M dataset\\ndataset = load_dataset('clw8998/Coupang-Product-Set-2.7M')\\n\\n# Display the first few rows of the dataset\\nfor i in range(5):\\n    print(dataset['train'][i])\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExpected  Outputâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/clw8998/Coupang-Product-Set-2.7M.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"sharegpt_cot_dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AiCloser/sharegpt_cot_dataset","creator_name":"Ai Closer","creator_url":"https://huggingface.co/AiCloser","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tA data set inspired by the \\\"Reflection\\\" method, three-dimensional thinking and cot\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the ShareGPT format.\\n\\t\\n\\nThe data set was generated using multiple llm synthesis.\\n","first_N":5,"first_N_keywords":["question-answering","text-generation","text2text-generation","English","Russian"],"keywords_longer_than_N":true},
	{"name":"chinese-classification","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/chinese-classification","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Classification Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Chinese Classification Dataset is designed for classifying sentences in different forms of Chinese text. Each entry consists of a Chinese sentence paired with a label indicating its language variant.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\n\\nRows: Each row contains a single Chinese sentence.\\nLabels: Comma-separated strings indicating one or more of these languages:\\nzh: Simplified Chinese\\nzht: Traditional Chinese\\nyue: Cantoneseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/chinese-classification.","first_N":5,"first_N_keywords":["text-classification","Chinese","cc-by-sa-4.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"LongMIT-128K","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/donmaclean/LongMIT-128K","creator_name":"Zhi Chen","creator_url":"https://huggingface.co/donmaclean","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLongMIT: Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets\\n\\t\\n\\n\\n    \\n    [ArXiv]\\n    \\n    \\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDownload LongMIT Datasets\\n\\t\\n\\ndef download_longmit_datasets(dataset_name: str, save_dir: str):\\n    qa_pairs = []\\n    dataset = load_dataset(dataset_name, split='train', cache_dir=HFCACHEDATASETS, trust_remote_code=True)\\n    for d in dataset:\\n        all_docs = d['all_docs']\\n\\n        if d['type'] in ['inter_doc', 'intra_doc']:\\n            ifâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/donmaclean/LongMIT-128K.","first_N":5,"first_N_keywords":["question-answering","text2text-generation","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"nlp_zh_98_encoding_table","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/beyondgravityresearch/nlp_zh_98_encoding_table","creator_name":"BeyondGravityResearch","creator_url":"https://huggingface.co/beyondgravityresearch","description":"98 äº”ç¬”ç è¡¨\\næ•°æ®æ¥æº http://98wb.ysepan.com/\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xchat","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xchat","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"neulab/PangeaBench-xchat dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["visual-question-answering","Chinese","English","Hindi","Indonesian"],"keywords_longer_than_N":true},
	{"name":"campus_qa","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dipwater/campus_qa","creator_name":"dipwater","creator_url":"https://huggingface.co/dipwater","description":"dipwater/campus_qa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"mc-translation","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/efederici/mc-translation","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","description":"This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy This Dataset?\\n\\t\\n\\nTranslation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specializedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation.","first_N":5,"first_N_keywords":["translation","English","Swahili","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"dali","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/liwei1987cn/dali","creator_name":"Levi li","creator_url":"https://huggingface.co/liwei1987cn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå¤§æè€å¸ˆé—®ç­”æ•°æ®é›†\\n\\t\\n\\nè¿™ä¸ªæ•°æ®é›†åŒ…å«å¤§æè€å¸ˆçš„é—®ç­”å¯¹è¯,ç”¨äºè®­ç»ƒå¯¹è¯æ¨¡å‹ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†æè¿°\\n\\t\\n\\n\\næ ¼å¼: JSONL\\nå­—æ®µ: \\ninstruction: å›ºå®šå€¼\\\"è¯·å¤§æè€å¸ˆå›ç­”\\\"\\ninput: æé—®å†…å®¹ \\noutput: å¤§æè€å¸ˆçš„å›ç­”\\n\\n\\næ•°æ®é‡: xxxæ¡å¯¹è¯æ•°æ®\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä½¿ç”¨ç¤ºä¾‹\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"your-username/dataset-name\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè®¸å¯è¯\\n\\t\\n\\nApache 2.0\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Theresa","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Theresa","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Theresa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-generation","Chinese","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"hongkong_carpark","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hkdata/hongkong_carpark","creator_name":"AI provider","creator_url":"https://huggingface.co/hkdata","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nDataset is the carpark information on Hong Kong.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\nCollection from public information on hong kong carpark\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hkdata/hongkong_carpark.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"kao20240823","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clinno/kao20240823","creator_name":"å‘¨å¤§å¯","creator_url":"https://huggingface.co/clinno","description":"clinno/kao20240823 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chamorro","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"hwtcm-sft-v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Monor/hwtcm-sft-v1","creator_name":"Monor Huang","creator_url":"https://huggingface.co/Monor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tA dataset of Tradictional Chinese Medicine (TCM) for SFT\\n\\t\\n\\nä¸€ä¸ªç”¨äºå¾®è°ƒLLMçš„ä¼ ç»Ÿä¸­åŒ»æ•°æ®é›†\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repository contains a dataset of Traditional Chinese Medicine (TCM) for fine-tuning large language models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset contains 7,096 Chinese sentences related to TCM. The sentences are collected from various sources on the Internet, including medical websites, TCM forums, and TCM books. The dataset is generated or judged by various LLMsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Monor/hwtcm-sft-v1.","first_N":5,"first_N_keywords":["question-answering","text-generation","feature-extraction","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"chinese-english-technical-patent-glossary","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lianghsun/chinese-english-technical-patent-glossary","creator_name":"Huang Liang Hsun","creator_url":"https://huggingface.co/lianghsun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ä¸­è¯æ°‘åœ‹å°ˆåˆ©æŠ€è¡“åè©ä¸­è‹±å°ç…§è©åº«(Chinese-English Technical Patent Glossary)\\n\\t\\n\\n(WIP)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlicense: apache-2.0\\n\\t\\n\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"xiyouji","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Fisher2023/xiyouji","creator_name":"FisherYu","creator_url":"https://huggingface.co/Fisher2023","description":"è¥¿æ¸¸è®°å°è¯´\\n","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"hkcancor-fine","keyword":"yue chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlienKevin/hkcancor-fine","creator_name":"Xiang (Kevin) Li","creator_url":"https://huggingface.co/AlienKevin","description":"This data is the subset of the Hong Kong Cantonese Corpus (HKCanCor) that has been re-segmented by the multi-tiered word segmentation scheme described in the following paper:\\nCharles Lam, Chaak-ming Lau, and Jackson L. Lee. 2024. Multi-Tiered Cantonese Word Segmentation. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 11993â€“12002, Torino, Italy. ELRA and ICCL.\\nThis HuggingFace dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlienKevin/hkcancor-fine.","first_N":5,"first_N_keywords":["Yue Chinese","cc-by-4.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Firefly-Rephrased-Multiturn-300K","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/Firefly-Rephrased-Multiturn-300K","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"Mxode/Firefly-Rephrased-Multiturn-300K dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","question-answering","Chinese","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Firefly-1.1M-Rephrased","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/Firefly-1.1M-Rephrased","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"Mxode/Firefly-1.1M-Rephrased dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","Chinese","English"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hl0737/test","creator_name":"Hu Dou Dou","creator_url":"https://huggingface.co/hl0737","description":"hl0737/test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","n<1K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus-Subset-zh-en","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/IndustryCorpus-Subset-zh-en","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"Mxode/IndustryCorpus-Subset-zh-en dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","Chinese","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Chinese-web-novel","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qwertyuiopasdfg/Chinese-web-novel","creator_name":"aaa","creator_url":"https://huggingface.co/qwertyuiopasdfg","description":"\\n\\t\\n\\t\\t\\n\\t\\tæ•°æ®é›†ä¿¡æ¯\\n\\t\\n\\næœ¬æ•°æ®é›†ä» https://m.bqgui.cc çˆ¬å–äº†æ¯æœ¬ä¹¦è‡³å¤š25ç« çš„å†…å®¹æ¥æ§åˆ¶ç¯‡å¹…ï¼Œå…±12740é¡¹æ•°æ®ã€‚ç»è¿‡äº†ä¸‰è½®æ•°æ®æ¸…æ´—ï¼Œè™½ç„¶æ”¹å–„å¾ˆå¤§ï¼Œä½†æ˜¯ä»ç„¶ä¼šåŒ…å«ä¸€äº›ä½è´¨é‡çš„ä¿¡æ¯å’Œä¸ä½œå“æ— å…³çš„å†…å®¹ï¼ˆä¾‹å¦‚æ±‚è®¢é˜…ã€çˆ†è‚xxxxå­—ä¹‹ç±»çš„ã€‚ã€‚ã€‚ï¼‰\\n\\n\\t\\n\\t\\t\\n\\t\\tæ•°æ®é›†è´¨é‡\\n\\t\\n\\næ¯é¡¹æ•°æ®åŒ…å«ä¸‰æ¡ä¿¡æ¯ï¼šä¹¦åã€ç®€ä»‹å’Œå°è¯´æ–‡æœ¬\\nä¹¦åï¼šç”±äºé•¿åº¦æçŸ­ï¼Œæ–‡æœ¬è´¨é‡æ˜¯æœ€å¥½çš„ï¼Œæ²¡æœ‰å‚æ‚ä»€ä¹ˆå¹¿å‘Šã€‚\\nç®€ä»‹ï¼šå²ï¼Œèƒ½ç”¨çš„æ²¡å‡ ä¸ªã€‚\\nå°è¯´æ–‡æœ¬ï¼šå†…å®¹è´¨é‡å°šä¸”ä¸æï¼Œå·²ç»å°½é‡æŠŠä¸€äº›åƒå¥‡ç™¾æ€ªçš„ç¬¦å·å’Œå¹¿å‘Šè¿‡æ»¤æ‰äº†ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\tä»£ç \\n\\t\\n\\nçˆ¬å–å°è¯´å°±ç®—ç”¨å¤šçº¿ç¨‹ä¹Ÿæ¯”è¾ƒæ…¢ï¼Œå¯èƒ½æ˜¯æˆ‘ä»£ç çš„åŸå› æˆ–è€…æ˜¯è¯·æ±‚æ•°é‡å¤ªå¤šäº†ï¼Œè¯¦è§çˆ¬å–.ipynb\\næ•°æ®æ¸…æ´—ä¸»è¦ç”¨çš„æ˜¯æ­£åˆ™è¡¨è¾¾å¼å’Œå­—ç¬¦ä¸²æ“ä½œï¼Œè¯¦è§æ¸…æ´—.ipynb\\nè‡³äºä¸‹ä¸€æ­¥çš„æ¸…æ´—ã€‚ã€‚ã€‚ç”±äºä¸­æ–‡è¯­è¨€çš„å¤šæ ·æ€§ï¼Œç›´æ¥åˆ é™¤å¯¹åº”çš„è¯­å¥æ•ˆç‡æä½ä¸”æœ‰å¯èƒ½ä¼šè¯¯åˆ æ­£å¸¸çš„æ–‡æœ¬ï¼Œå¸Œæœ›æœªæ¥èƒ½æœ‰æ¯”è¾ƒå¥½ç”¨çš„LLMæˆ–å…¶å®ƒå·¥å…·æ¥è§£å†³æ­¤é—®é¢˜ã€‚\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K<n<100K","ğŸ‡ºğŸ‡¸ Region: US","art"],"keywords_longer_than_N":true},
	{"name":"MedExamRetrieval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMIRB/MedExamRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","description":"Paper: https://huggingface.co/papers/2410.20050\\n","first_N":5,"first_N_keywords":["text-retrieval","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"DuBaikeRetrieval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMIRB/DuBaikeRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","description":"Paper: https://huggingface.co/papers/2410.20050\\n","first_N":5,"first_N_keywords":["text-retrieval","Chinese","apache-2.0","10K - 100K","Text"],"keywords_longer_than_N":true},
	{"name":"IIYIPostRetrieval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMIRB/IIYIPostRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","description":"Paper: https://huggingface.co/papers/2410.20050\\n","first_N":5,"first_N_keywords":["text-retrieval","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"CSLCiteRetrieval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMIRB/CSLCiteRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","description":"Paper: https://huggingface.co/papers/2410.20050\\n","first_N":5,"first_N_keywords":["text-retrieval","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"product-database","keyword":"chinese","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Food Facts Database\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is ğŸŠ Open Food Facts?\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tA food products database\\n\\t\\n\\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\\n\\n\\t\\n\\t\\t\\n\\t\\tMade by everyone\\n\\t\\n\\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"test1","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wbshuaiq/test1","creator_name":"è€ç‹","creator_url":"https://huggingface.co/wbshuaiq","description":"wbshuaiq/test1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"meissa-lima","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/meissa-lima","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMeissa-LIMA\\n\\t\\n\\nå—LIMAå¯å‘, æˆ‘åˆ¶ä½œäº†è¿™ä¸ªæ•°æ®é›†. æ•°æ®é›†ç”±ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†æ„æˆ: åŸå§‹æ•°æ®é›†, ä¸­æ–‡ç¿»è¯‘ç‰ˆ, ç ´é™æ•°æ®é›†, è§’è‰²æ‰®æ¼”æ•°æ®é›†, Gutenbergæ•°æ®é›†, å¼±æ™ºå§é—®ç­”.\\n\\nåŸå§‹æ•°æ®é›†: åŸæ•°æ®é›†ä¸­åŒ…å«äº†13æ¡æ‹’ç»/é“å¾·å¯¹é½çš„æ•°æ®, æˆ‘å°†å…¶æ‰¾å‡ºå¹¶æ‰‹åŠ¨è¿›è¡Œäº†ä¿®æ”¹\\nä¸­æ–‡ç¿»è¯‘ç‰ˆ: ä½¿ç”¨è¿è¡Œåœ¨ Great Server ä¸Šçš„ Orion-zhen/Meissa-Qwen2.5-7B-Instruct-Q5_K_M-GGUF å®Œæˆç¿»è¯‘, å¹¶ç”±æˆ‘è¿›è¡Œæ ¡å¯¹\\nç ´é™æ•°æ®é›†: ä» Orion-zhen/meissa-unalignments ä¸­é€‰å–äº†è‹¥å¹²æ¡ç›®\\nè§’è‰²æ‰®æ¼”æ•°æ®é›†: ä» MinervaAI/Aesir-Preview ä¸­é€‰å–äº†è‹¥å¹²æ¡ç›®\\nGutenbergæ•°æ®é›†: ä» Orion-zhen/kto-gutenberg ä¸­é€‰å–äº†è‹¥å¹²æ¡ç›®\\nå¼±æ™ºå§é—®ç­”: ä» LooksJuicy/ruozhiba ä¸­é€‰å–äº†è‹¥å¹²é—®é¢˜å¹¶ç”±æˆ‘æ‰‹åŠ¨ç¼–å†™å›ç­”\\n\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","English","gpl-3.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"CCI3-HQ-Annotation-Benchmark","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/CCI3-HQ-Annotation-Benchmark","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCCI3-HQ-Annotation-Benchmark\\n\\t\\n\\nThese 14k samples were randomly extracted from a large corpus of Chinese texts, containing both the original text and corresponding labels. They can be used to evaluate the quality of Chinese corpora.\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"VisualDataset100K","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/REILX/VisualDataset100K","creator_name":"SunForlight","creator_url":"https://huggingface.co/REILX","description":"ä¸­æ–‡\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLocal Deployment of Large Models and Construction of VisualDataset100K Dataset\\n\\t\\n\\nDeploy large models locally using vllm and utilize them to construct the VisualDataset100K dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1. Local Deployment of Large Models (vllm + nginx)\\n\\t\\n\\nUses multi GPUs, loads the Qwen/Qwen2-VL-2B-Instructã€Qwen/Qwen2-VL-7B-Instructã€Qwen/Qwen2-VL-72B-Instruct-GPTQ-Int4 models through vllm, and uses nginx for load balancing.\\n1.1 Launch vllm instances:\\nRun a vllm instance on each GPUâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/REILX/VisualDataset100K.","first_N":5,"first_N_keywords":["question-answering","image-to-text","Chinese","apache-2.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"mandarin chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"yue chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"roomnumber","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/w11342900/roomnumber","creator_name":"Ennis Wang","creator_url":"https://huggingface.co/w11342900","description":"w11342900/roomnumber dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"prompt-injection-multilingual","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rikka-snow/prompt-injection-multilingual","creator_name":"Le Xuan Hoang","creator_url":"https://huggingface.co/rikka-snow","description":"rikka-snow/prompt-injection-multilingual dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Vietnamese","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"LexEval","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CSHaitao/LexEval","creator_name":"Haitao Li","creator_url":"https://huggingface.co/CSHaitao","description":"","first_N":5,"first_N_keywords":["Chinese","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"CMB","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fzkuji/CMB","creator_name":"Fu Zichuan","creator_url":"https://huggingface.co/fzkuji","description":"\\n\\t\\n\\t\\t\\n\\t\\tCMB: A Comprehensive  Medical Benchmark in Chinese\\n\\t\\n\\n\\n\\n   ğŸŒ Github â€¢ ğŸŒ Website â€¢ ğŸ¤— HuggingFace\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸŒˆ Update\\n\\t\\n\\n\\n[2024.02.21] The answers to the CMB-Exam test has been updated and some errors caused by omissions in version management have been fixed.\\n[2024.01.08] In order to facilitate testing, we disclose the answers to the CMB-Exam test\\n[2023.09.22] CMB is included in OpenCompass.\\n[2023.08.21] Paper released.\\n[2023.08.01] ğŸ‰ğŸ‰ğŸ‰ CMB is publishedï¼ğŸ‰ğŸ‰ğŸ‰\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tğŸŒâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fzkuji/CMB.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"neutral-language-challenge","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/missvector/neutral-language-challenge","creator_name":"Victoria","creator_url":"https://huggingface.co/missvector","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLabels denote the following rules that LLM should follow to pass the Neutral Language Challenge:\\n\\t\\n\\n\\n1 \\\"tone\\\": Replace hostile or aggressive words with neutral equivalents\\n2 \\\"lexicon\\\": Replace words with negative subtext while maintaining context\\n3 \\\"emphasis\\\": Replace exaggerations or understatements with neutral phrasing\\n4 \\\"connotation\\\": Replace words with negative connotation with neutral equivalents\\n5 \\\"implicature\\\": Identify implied hostility and regenerate a neutral response\\n\\n","first_N":5,"first_N_keywords":["Chinese","English","Russian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"NanoExperiment-Data-Mix-10M","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/NanoExperiment-Data-Mix-10M","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMxode/NanoExperiment-Data-Mix-10M\\n\\t\\n\\nDataset of NanoExperiment. Tokenized by Bilingual-Tokenizer-2K.\\n","first_N":5,"first_N_keywords":["translation","English","Chinese","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"COREX-18","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laion/COREX-18","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"\\n  \\n\\n\\nCOREX 18\\n\\n\\nIntroducing COREX-18, a comprehensive dataset derived from the 2018 version of the CORE dataset. Our goal is to contribute to the research community by compiling open-access scientific papers and publishing them in extensive datasets. These datasets will facilitate advanced RAG applications and enhance artificial intelligence research.\\nCOREX was developed as part of our X initiative, which aims to maintain and compile publicly available data into accessible and regularlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/laion/COREX-18.","first_N":5,"first_N_keywords":["question-answering","summarization","text2text-generation","sentence-similarity","English"],"keywords_longer_than_N":true},
	{"name":"FineRob","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Linkseed/FineRob","creator_name":"KunLi","creator_url":"https://huggingface.co/Linkseed","description":"\\n  \\n\\nFineRob - Fine-Grained Social Media Behavior Simulation Dataset\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tPaper\\n\\t\\n\\nhttps://arxiv.org/abs/2412.03148\\n\\n\\t\\n\\t\\t\\n\\t\\tGithub\\n\\t\\n\\nhttps://github.com/linkseed18612254945/FineRob\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nFinerob is a novel fine-grained user behavior simulation dataset collected from three social media platform: X(Twitter), Reddit, Zhihu.\\nThe dataset is design to evalute the role-play capacity of LLMs through three differnet action elements simulation.\\n\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe collectâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Linkseed/FineRob.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"newt","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sdsdfd/newt","creator_name":"sdfd","creator_url":"https://huggingface.co/sdsdfd","description":"sdsdfd/newt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"llama2_7B_data_10G","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2imi9/llama2_7B_data_10G","creator_name":"Ziming Qi","creator_url":"https://huggingface.co/2imi9","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset consists of 10GB of open-source bilingual data (Chinese and English) organized by Ziming Qi, sourced from platforms such as Hugging Face and CSDN. The data covers a wide range of topics, with an emphasis on multi-round conversational logic and reasoning. It includes both general and technical question-answer pairs, making it ideal for training AI models that need to handle extended conversations and maintain context across multiple exchanges.\\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2imi9/llama2_7B_data_10G.","first_N":5,"first_N_keywords":["question-answering","Chinese","English","cc-by-4.0","1B<n<10B"],"keywords_longer_than_N":true},
	{"name":"model","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/luChneg/model","creator_name":"David","creator_url":"https://huggingface.co/luChneg","description":"luChneg/model dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MedicalQA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bolin97/MedicalQA","creator_name":"ZhangBolin","creator_url":"https://huggingface.co/Bolin97","description":"\\n\\t\\n\\t\\t\\n\\t\\tMedicalQA-1.4M\\n\\t\\n\\nMedicalQA is an integrated large-scale, high-quality Chinese SFT dataset, designed for medical knowledge injection into LLMs by SFT or RAG. \\nEach sample is reviewed by the free LLM (ERNIE-Speed) using our proposed Quality Evaluation Algorithm.\\nMedArk-KI involving in two types of medical knowledge: Traditional Chinese Medicine (TCM) and Western Medicine(WM). It consists of 4 subsets as shown in the tabel: \\n\\n\\t\\n\\t\\t\\nName\\nVolume\\nAuthor\\nReviewer\\nType\\nSource\\nSource Formatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bolin97/MedicalQA.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"shiji-translation-dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kobe73er/shiji-translation-dataset","creator_name":"Chris Deng","creator_url":"https://huggingface.co/kobe73er","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå²è®°ä¸ƒååˆ—ä¼  å¤æ–‡-ç°ä»£æ–‡ç¿»è¯‘æ•°æ®é›†\\n\\t\\n\\nè¿™ä¸ªæ•°æ®é›†åŒ…å«äº†ã€Šå²è®°Â·ä¸ƒååˆ—ä¼ ã€‹çš„å¤æ–‡å’Œå¯¹åº”çš„ç°ä»£æ–‡ç¿»è¯‘ã€‚æ•°æ®é›†é‡‡ç”¨ JSONL æ ¼å¼ï¼Œæ¯è¡ŒåŒ…å«ï¼š\\n\\ninput: ç°ä»£æ–‡\\noutput: å¤æ–‡\\ninstruction: ç¿»è¯‘æŒ‡ä»¤\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»Ÿè®¡\\n\\t\\n\\n\\næ€»æ¡ç›®æ•°ï¼š14,115 æ¡\\næ¥æºï¼šã€Šå²è®°Â·ä¸ƒååˆ—ä¼ ã€‹\\næ ¼å¼ï¼šJSONL\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç”¨é€”\\n\\t\\n\\nè¿™ä¸ªæ•°æ®é›†å¯ä»¥ç”¨äºï¼š\\n\\nå¤æ–‡ç¿»è¯‘æ¨¡å‹è®­ç»ƒ\\næ–‡è¨€æ–‡ç†è§£\\nä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†ç ”ç©¶\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®æ ¼å¼ç¤ºä¾‹\\n\\t\\n\\n{\\n    \\\"output\\\": \\\"ä¸‡çŸ³å›åå¥‹ï¼Œå…¶çˆ¶èµµäººä¹Ÿï¼Œå§“çŸ³æ°ã€‚\\\",\\n    \\\"input\\\": \\\"ä¸‡çŸ³å›åå¥‹ï¼Œä»–çš„çˆ¶äº²æ˜¯èµµå›½äººï¼Œå§“çŸ³ã€‚\\\",\\n    \\\"instruction\\\": \\\"è¯·æŠŠç°ä»£æ±‰è¯­ç¿»è¯‘æˆå¤æ–‡\\\"\\n}\\n\\n","first_N":5,"first_N_keywords":["text-generation","translation","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"wsdm2024-cot-dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ruggsea/wsdm2024-cot-dataset","creator_name":"Ruggero Marino Lazzaroni","creator_url":"https://huggingface.co/ruggsea","description":"This dataset is created by ruggsea for the WSDM 2024 competition. It is a semisynthetic dataset created by asking Llama 3.1 70B to generate rationales for the responses to the prompts in the WSDM 2024 competition. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nid: Unique identifier for each example\\nprompt: The input prompt given to the model\\nresponse_a: First response option\\nresponse_b: Second response option\\nwinner: The winning response (0 or 1)\\nrationale: The rationale generated by Llama 3.1 70B explaining whyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ruggsea/wsdm2024-cot-dataset.","first_N":5,"first_N_keywords":["text-classification","text-generation","English","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"cantonese-chinese-parallel-corpus","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HKAllen/cantonese-chinese-parallel-corpus","creator_name":"Allen D","creator_url":"https://huggingface.co/HKAllen","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of parallel sentence pairs in Cantonese and Chinese. It is designed for various tasks, including machine translation. \\nThe corpus contains a large number of sentence pairs collected from various domains and most has been improved through manual correction and translation.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nCantonese (yue)\\nSimplified Chinese (zh)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nEach entry in the dataset is a JSON object containing two fields: \\\"yue\\\" for theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HKAllen/cantonese-chinese-parallel-corpus.","first_N":5,"first_N_keywords":["translation","Chinese","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"FGRC-SCD","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Abooooo/FGRC-SCD","creator_name":"Jiarui Chen","creator_url":"https://huggingface.co/Abooooo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tåŸºäºCCF23-EVALä»»åŠ¡6çš„ç”µä¿¡ç½‘ç»œè¯ˆéª—æ¡ˆä»¶æ•°æ®é›†åˆæˆäº†é£é™©çŸ­ä¿¡ä¸å¯¹è¯æ•°æ®é›†ï¼Œå¹¶åŸºäºå¤šæ ·æ€§ã€ä»»åŠ¡ç›¸å…³æ€§å’Œæ˜¯å¦æ»¡è¶³äººç±»åå¥½è¿›è¡Œç­›é€‰ï¼Œå¯ç”¨äºé£é™©ç»†ç²’åº¦åˆ†ç±»ä»»åŠ¡å’Œé£é™©æ‘˜è¦ç”Ÿæˆä»»åŠ¡æµ‹è¯„ã€‚\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tçŸ­ä¿¡ç”Ÿæˆæ•°æ®é›†ç­›é€‰å‰åçš„è¯„ä»·ç»“æœæ¯”è¾ƒ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\næ•°æ®é›†\\næ•°æ®è¯„ä¼°æŒ‡æ ‡\\næ¡ˆä¾‹ç”Ÿæˆæ–¹å¼\\nå±æ€§æç¤ºç”Ÿæˆæ–¹å¼\\næ¡ˆä¾‹ç”Ÿæˆæ–¹å¼\\nå±æ€§æç¤ºç”Ÿæˆæ–¹å¼\\n\\n\\n\\t\\t\\n\\nä½™å¼¦ç›¸ä¼¼åº¦â†“\\n\\n\\n\\n\\n\\n\\næ‰€æœ‰ç±»åˆ«\\n\\n0.7149\\n0.6943\\n0.7041\\n0.6704\\n\\n\\nå†’å……ç”µå•†ç‰©æµå®¢æœç±»\\n\\n0.7542\\n0.6981\\n0.7606\\n0.7331\\n\\n\\nè™šå‡ç½‘ç»œæŠ•èµ„ç†è´¢ç±»\\n\\n0.7967\\n0.7120\\n0.8029\\n0.7108\\n\\n\\nè™šå‡ä¿¡ç”¨æœåŠ¡ç±»\\n\\n0.7840\\n0.7050\\n0.7738\\n0.7010\\n\\n\\nè™šå‡è´­ç‰©ã€æœåŠ¡ç±»\\n\\n0.7088\\n0.6931\\n0.6879\\n0.6672\\n\\n\\nå†’å……å…¬æ£€æ³•åŠæ”¿åºœæœºå…³ç±»\\n\\n0.7979\\n0.7088\\n0.7835\\n0.6935\\n\\n\\nå†’å……é¢†å¯¼ã€ç†Ÿäººç±»\\n\\n0.7765\\n0.7063\\n0.7540\\n0.7132\\n\\n\\nç½‘ç»œå©šæ‹ã€äº¤å‹ç±»â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Abooooo/FGRC-SCD.","first_N":5,"first_N_keywords":["text-classification","summarization","Chinese","mit","n<1K"],"keywords_longer_than_N":true},
	{"name":"ACG","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Abooooo/ACG","creator_name":"Jiarui Chen","creator_url":"https://huggingface.co/Abooooo","description":"åŸºäºCodecfake(AISHELL3 + VCTK)ï¼Œåˆ†åˆ«ä½¿ç”¨GPT-SoVITå’ŒChatTTSåˆæˆå¯¹åº”çš„ä¼ªé€ éŸ³é¢‘ï¼Œç”¨äºä¼ªé€ éŸ³é¢‘è¯†åˆ«ç­‰ä»»åŠ¡ï¼Œæ”¯æŒä¸­æ–‡å’Œè‹±æ–‡ã€‚\\n","first_N":5,"first_N_keywords":["audio-classification","Chinese","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"BlastData","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lvlvlvlv1/BlastData","creator_name":"lvhaoyuan","creator_url":"https://huggingface.co/lvlvlvlv1","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lvlvlvlv1/BlastData.","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","10M<n<100M","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"llm-ideology-analysis","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aida-ugent/llm-ideology-analysis","creator_name":"Ghent University Artificial Intelligence & Data Analytics Group","creator_url":"https://huggingface.co/aida-ugent","description":"This dataset contains evaluations of political figures by a diverse set of Large Language Models (LLMs), such that the ideology of these LLMs can be characterized.\\n\\n\\t\\n\\t\\t\\n\\t\\tğŸ“ Dataset Description\\n\\t\\n\\nThe dataset contains responses from 19 different Large Language Models evaluating 3,991 political figures, with responses collected in the six UN languages: Arabic, Chinese, English, French, Russian, and Spanish. \\nThe evaluations were conducted using a two-stage prompting strategy to assess theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aida-ugent/llm-ideology-analysis.","first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"AVAINT-IMG","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botintel-community/AVAINT-IMG","creator_name":"BotIntel X","creator_url":"https://huggingface.co/botintel-community","description":"botintel-community/AVAINT-IMG dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["image-to-text","image-classification","visual-question-answering","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"emova-alignment-7m","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-Alignment-7M\\n\\t\\n\\n\\n\\n\\nğŸ¤— EMOVA-Models | ğŸ¤— EMOVA-Datasets | ğŸ¤— EMOVA-Demo \\nğŸ“„ Paper | ğŸŒ Project-Page | ğŸ’» Github | ğŸ’» EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-Alignment-7M is a comprehensive dataset curated for omni-modal pre-training, including vision-language and speech-language alignment. \\nThis dataset is created using open-sourced image-text pre-training datasets, OCR datasets, and 2,000 hours of ASR and TTS data. \\nThis dataset is part of the EMOVA-Datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m.","first_N":5,"first_N_keywords":["image-to-text","text-generation","audio-to-audio","automatic-speech-recognition","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"tst","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sama1030/tst","creator_name":"SamChang","creator_url":"https://huggingface.co/Sama1030","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe \\\"Crime Facts\\\" of \\\"Offenses of Fraudulence\\\" in Judicial Yuan Verdicts Dataset\\n\\t\\n\\nThis data set is based on the judgments of \\\"Offenses of Fraudulence\\\" cases published by the Judicial Yuan. The data range of the dataset is from January 1, 2011, to December 31, 2021. 74,823 pieces of original data (judgments and rulings) were collected. We only took the contents of the \\\"criminal facts\\\" field of the judgment. This dataset is divided into three parts. The training dataset has 59,858â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Sama1030/tst.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Lappland","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Lappland","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Lappland dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","English"],"keywords_longer_than_N":true},
	{"name":"TurtleBench-extended-zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nycu-ai113-dl-final-project/TurtleBench-extended-zh","creator_name":"NYCU AI Deep Learning final project","creator_url":"https://huggingface.co/nycu-ai113-dl-final-project","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæµ·é¾œæ¹¯æ•¸æ“šé›†ï¼ˆä¸­æ–‡ï¼‰\\n\\t\\n\\næœ¬æ•¸æ“šé›†åŒ…å«ä¸­æ–‡çš„æµ·é¾œæ¹¯è¬é¡Œï¼Œç”¨æ–¼é€†å‘æ€ç¶­éŠæˆ²ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•¸æ“šé›†ç°¡ä»‹\\n\\t\\n\\næœ¬æ•¸æ“šé›†åŸºæ–¼ Duguce/TurtleBench1.5k æ“´å±•è€Œä¾†ï¼Œæ—¨åœ¨ç‚º Turtle-soup Game æä¾›é«˜è³ªé‡çš„æ¨ç†æ•¸æ“šã€‚æ•¸æ“šæ¶µè“‹å¤šç¨®é«˜é›£åº¦æ¨ç†æƒ…å¢ƒï¼Œæ”¯æŒ ä¸­æ–‡ èˆ‡ è‹±æ–‡ å…©ç¨®èªè¨€ï¼Œä¸¦çµåˆå¤šç¨®æ“´å¢æ–¹æ³•æå‡å¤šæ¨£æ€§èˆ‡é‚è¼¯æ€§ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•¸æ“šä¾†æº\\n\\t\\n\\n\\nåŸå§‹æ•¸æ“šé›†ä¾†è‡ª Hugging Faceï¼Œæˆæ¬Šæ–¼ Apache License 2.0ã€‚\\næ“´å¢å¾Œæ•¸æ“šé›†ç”±ç¿»è­¯ã€æ¨™è¨»ã€åŸºæº–é¡Œåº«åŠæ¨¡å‹ç”Ÿæˆæ•¸æ“šæ§‹æˆï¼Œè©³ç´°åˆ†å¸ƒè«‹è¦‹ä¸‹æ–‡ã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•¸æ“šçµæ§‹\\n\\t\\n\\næ•¸æ“šé›†åŒ…å«ä»¥ä¸‹å­—æ®µï¼Œæ¯ç­†æ•¸æ“šå‡å®Œæ•´è¨˜éŒ„äº†ä¸€å€‹æµ·é¾œæ¹¯æ•…äº‹çš„æ¨ç†æƒ…å¢ƒèˆ‡ç­”æ¡ˆæ¨™ç±¤ï¼š\\n\\n\\t\\n\\t\\t\\nå±¬æ€§åç¨±\\næè¿°\\n\\n\\n\\t\\t\\nid\\næ•…äº‹çš„å”¯ä¸€æ¨™è­˜ç¬¦ã€‚\\n\\n\\ntitle\\næµ·é¾œæ¹¯æ•…äº‹çš„æ¨™é¡Œã€‚\\n\\n\\nsurface\\næµ·é¾œæ¹¯æ•…äº‹çš„è¡¨å±¤ä¿¡æ¯ï¼Œå³ç©å®¶èƒ½å¤ ç›´æ¥ç²å¾—çš„ç·šç´¢ã€‚\\n\\n\\nbottom\\næµ·é¾œæ¹¯æ•…äº‹çš„æ·±å±¤èƒŒæ™¯ï¼Œå³ç©å®¶éœ€è¦æ¨ç†æ‰èƒ½ç²çŸ¥çš„ç­”æ¡ˆæˆ–æƒ…å¢ƒã€‚\\n\\n\\nuser_guessâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nycu-ai113-dl-final-project/TurtleBench-extended-zh.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"llm-failure-dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Ki-Seki/llm-failure-dataset","creator_name":"Shichao Song","creator_url":"https://huggingface.co/Ki-Seki","description":"Ki-Seki/llm-failure-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","zero-shot-classification","translation"],"keywords_longer_than_N":true},
	{"name":"emova-asr-tts-eval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-asr-tts-eval","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-ASR-TTS-Eval\\n\\t\\n\\n\\n\\n\\nğŸ¤— EMOVA-Models | ğŸ¤— EMOVA-Datasets | ğŸ¤— EMOVA-Demo \\nğŸ“„ Paper | ğŸŒ Project-Page | ğŸ’» Github | ğŸ’» EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-ASR-TTS-Eval is a dataset designed for evaluating the ASR and TTS performance of Omni-modal LLMs. It is derived from the test-clean set of the LibriSpeech dataset. This dataset is part of the EMOVA-Datasets collection. We extract the speech units using the EMOVA Speech Tokenizer.\\n\\n\\t\\n\\t\\t\\n\\t\\tStructure\\n\\t\\n\\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-asr-tts-eval.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"difference_images_Cloth-Nude","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Makki2104/difference_images_Cloth-Nude","creator_name":"Makki Shizu","creator_url":"https://huggingface.co/Makki2104","description":"This dataset is a collection of Cloth-Nude difference (Tachie) images of anime girls gathered from the internet, with images saved in WebP format.\\nThis dataset encode/save all the image with 90% quality webp with pillow library in Python. Which is half size of the 100% quality lossy webp.\\nThe folders 1_cloth-360-90webp and 1_nude-360-90webp contain the original training dataset for the Illustrious Auto Nude model. For training details, please refer to the model card.\\nThe anime-girl-unfiledâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Makki2104/difference_images_Cloth-Nude.","first_N":5,"first_N_keywords":["English","Chinese","mit","10K - 100K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Nonense_sentense_chinese","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pbrother/Nonense_sentense_chinese","creator_name":"wudiudiu","creator_url":"https://huggingface.co/pbrother","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tåºŸè¯æ–‡å­¦æ•°æ®é›†\\n\\t\\n\\n\\nåºŸè¯ä¸»è¦æœé›†è‡ªä¸­æ–‡äº’è”ç½‘ï¼Œå¦‚ç™¾åº¦ï¼ŒçŸ¥ä¹ä¸Šé¢çš„åºŸè¯åˆé›†çº¦300æ¡å·¦å³ã€‚\\nåˆ©ç”¨GPTç”Ÿæˆç›¸åŒæ ¼å¼çš„åºŸè¯å¤§æ¦‚700æ¡å·¦å³ã€‚\\næ­£å¸¸è¯­æ–™æ¥æºäºhuggingfaceä¸Šçš„ä¸­æ–‡æ•°æ®é›†ã€‚\\nå¯ç”¨äºæ–‡æœ¬åˆ†ç±»ç­‰ä»»åŠ¡çš„éªŒè¯ã€‚\\n\\n","first_N":5,"first_N_keywords":["text-classification","Chinese","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Taiwan-Curlture-MCQ","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aqweteddy/Taiwan-Curlture-MCQ","creator_name":"aqweteddy","creator_url":"https://huggingface.co/aqweteddy","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTW-Curlture-MCQ\\n\\t\\n\\nTW-Curlture-MCQ æ˜¯ä¸€å€‹è©•é‡å°ç£æ–‡åŒ–çš„é¸æ“‡é¡Œè³‡æ–™é›†ï¼Œä¸»è¦ä¾†è‡ªä»¥ä¸‹å…©å€‹è³‡æ–™é›†çš„ç¯©é¸èˆ‡æ•´åˆï¼š\\n\\nTMLU\\nTMMLU+\\n\\nä»¥äººå·¥æŒ‘é¸èˆ‡å°ç£æ–‡åŒ–ç›¸é—œçš„ç§‘ç›®å¾Œï¼Œå†ç”± gpt-4o-mini åˆ¤æ–·å•é¡Œæ˜¯å¦èˆ‡å°ç£æ–‡åŒ–ç›¸é—œï¼Œå…± 3828 é¡Œã€‚\\n","first_N":5,"first_N_keywords":["multiple-choice","Chinese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"shp_translations","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/david9dragon9/shp_translations","creator_name":"David Wu","creator_url":"https://huggingface.co/david9dragon9","description":"This dataset contains translations of three splits (askscience, explainlikeimfive, legaladvice) of the Stanford Human Preference (SHP) dataset, used for training domain-invariant reward models.\\nThe translation was conducted using the No Language Left Behind (NLLB) 3.3 B 200 model.\\nReferences:\\nStanford Human Preference Dataset: https://huggingface.co/datasets/stanfordnlp/SHP\\nNLLB: https://huggingface.co/facebook/nllb-200-3.3B\\n","first_N":5,"first_N_keywords":["question-answering","English","Korean","Chinese","Thai"],"keywords_longer_than_N":true},
	{"name":"Pinyin-Hanzi","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Duyu/Pinyin-Hanzi","creator_name":"Duyu09","creator_url":"https://huggingface.co/Duyu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ±‰å­—è¯­å¥åºåˆ—ä¸æ±‰è¯­æ‹¼éŸ³åºåˆ—æ•°æ®é›†\\n\\t\\n\\næ±‰å­—è¯­å¥åºåˆ—ä¸æ±‰è¯­æ‹¼éŸ³åºåˆ—æ•°æ®é›†ï¼ŒåŒ…å«å¤šé¢†åŸŸæ–‡æœ¬ï¼Œå¯ç”¨äºè®­ç»ƒæ±‰å­—-æ±‰è¯­æ‹¼éŸ³äº’è½¬æ¨¡å‹ã€‚\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1M - 10M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"C2C","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pigowen2/C2C","creator_name":"Pigo","creator_url":"https://huggingface.co/Pigowen2","description":"Pigowen2/C2C dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ding0702/test","creator_name":"Ding","creator_url":"https://huggingface.co/Ding0702","description":"Ding0702/test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","100K<n<1M","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"CBU0521DD_stories_expanded","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hunterhere/CBU0521DD_stories_expanded","creator_name":"HunterRong","creator_url":"https://huggingface.co/Hunterhere","description":"This project is for CBU5201 coursework under BUPT & QM joint programme.We constructed a dataset that told either a true story or a false story, in a mix of Chinese and English, with a total of 100 audio pieces.And data augmentation is applied on it preparing to afterwards training.More datails please refer to github https://github.com/Hunterhere/CBU5201_miniproject  \\n","first_N":5,"first_N_keywords":["audio-classification","Chinese","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Libra-Test","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caskcsg/Libra-Test","creator_name":" KCSG Knowledge Computing and Service Group, IIE, CAS","creator_url":"https://huggingface.co/caskcsg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸ“Š Libra-Test\\n\\t\\n\\n\\nLibra-Test æ˜¯ä¸“ä¸ºä¸­æ–‡å¤§æ¨¡å‹æŠ¤æ è€Œæ„å»ºçš„è¯„æµ‹åŸºå‡†ï¼Œæ¶µç›–ä¸ƒå¤§å…³é”®é£é™©åœºæ™¯å’Œ 5,700+ æ¡ä¸“å®¶æ ‡æ³¨æ•°æ®ã€‚\\nLibra-Test is a benchmark designed for the safeguards of Chinese LLMs, covering 7 key risk scenarios and over 5,700 expert-labeled data points.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå¤šæ ·æ€§ï¼ˆDiversityï¼‰\\n\\t\\n\\nLibra-Testçº³å…¥äº†ä¸‰ä¸ªä¸åŒçš„æ•°æ®æ¥æºï¼Œæœ€ç»ˆåŒ…æ‹¬7ä¸ªæœ‰å®³åœºæ™¯åŠ39ä¸ªå­ç±»åˆ«ã€‚\\nLibra-Test incorporates data from three different sources, ultimately covering 7 harmful scenarios and 39 subcategories.\\n\\nçœŸå®æ•°æ®ï¼ˆReal Dataï¼‰  ï¼šä» Safety-Prompts æ•°æ®é›† ä¸­æŠ½å–çœŸå®çš„ä¸­æ–‡æœ‰å®³é—®é¢˜ï¼Œå¹¶åœ¨ä¸‰ç§ä¸­æ–‡å¤§æ¨¡å‹ä¸Šç”Ÿæˆå›å¤ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/caskcsg/Libra-Test.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"xuexiqiangguo_428w","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Macropodus/xuexiqiangguo_428w","creator_name":"Macadam","creator_url":"https://huggingface.co/Macropodus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå­¦ä¹ å¼ºå›½æ•°æ®é›†(xuexiqiangguo)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä¸‹è½½\\n\\t\\n\\n\\nä¸‹è½½æºä¸ºMacropodus/xuexiqiangguo_428w\\nå›½å†…æºä¸ºMacropodus/xuexiqiangguo_428w\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ—¶é—´(time)\\n\\t\\n\\n2024.6\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå¥å­æ•°(sentence)\\n\\t\\n\\n428w(42.8 million)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¿‡æ»¤(filter)\\n\\t\\n\\n\\nä½¿ç”¨å°klmæ¨¡å‹, kenlmè¯­è¨€æ¨¡å‹æ¥è‡ªhiyoung123/YoungCorrector,\\nç­–ç•¥(strategy): å‰”é™¤(delete) top-5%/bottom-5%;\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç±»å‹\\n\\t\\n\\nåŒ…æ‹¬ä»¥ä¸‹keys:\\n['2_0_ä¸»å¸­æ–‡æ±‡', '2_1_å­¦ä¹ ç§‘å­¦', '2_2_æ–°é—»-å­¦ä¹ æ—¶è¯„-ä¸­å®£éƒ¨-ç»æµ-ç†è®º', '2_3_çº¢è‰²ä¸­å›½', '2_4_å¿åŸŸæ–°é—»', '3_1_æ€æƒ³ç†è®º', '4_1_å¼ºå›½å¾æ–‡', '5_1_å®æ—¶å¹³å°-èº«è¾¹çš„æ„ŸåŠ¨', '6_1_ç²¾ç¥ç ”ç©¶', '7_1_æ”¿æ³•æ³•æ²»'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Macropodus/xuexiqiangguo_428w.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","ğŸ‡ºğŸ‡¸ Region: US","politics"],"keywords_longer_than_N":false},
	{"name":"crosswoz-sft","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BruceNju/crosswoz-sft","creator_name":"zhongyah","creator_url":"https://huggingface.co/BruceNju","description":"multilinguality:  \\n- monolingual  \\n\\ndescription: |  \\n                          \\n    è¿™æ˜¯ä¸€ä¸ªåŸºäºCrossWOZæ•°æ®é›†å¤„ç†çš„å¯¹è¯æ•°æ®é›†ï¼Œä¸“é—¨ç”¨äºå¤§æ¨¡å‹çš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ä»»åŠ¡ã€‚  \\n    æ•°æ®é›†åŒ…å«å¤šè½®å¯¹è¯ã€ç”¨æˆ·ç›®æ ‡ã€å¯¹è¯çŠ¶æ€ç­‰ä¿¡æ¯ï¼Œé€‚åˆè®­ç»ƒä»»åŠ¡å‹å¯¹è¯ç³»ç»Ÿã€‚  \\n\\n    åŸå§‹æ•°æ®æ¥æºäºCrossWOZé¡¹ç›®ï¼Œç»è¿‡ä¸“é—¨çš„é¢„å¤„ç†ä½¿å…¶æ›´é€‚åˆç°ä»£å¤§æ¨¡å‹è®­ç»ƒã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ ¸å¿ƒç‰¹å¾ï¼š\\n\\t\\n\\nè¿™æ˜¯é¦–ä¸ªå¤§è§„æ¨¡çš„ä¸­æ–‡è·¨åŸŸä»»åŠ¡å‹å¯¹è¯æ•°æ®é›†\\nåŒ…å«6,012ä¸ªå¯¹è¯ï¼Œ102,000ä¸ªè¯è¯­ï¼Œè¦†ç›–5ä¸ªé¢†åŸŸ(é…’åº—ã€é¤å…ã€æ™¯ç‚¹ã€åœ°é“å’Œå‡ºç§Ÿè½¦)\\nçº¦60%çš„å¯¹è¯åŒ…å«è·¨åŸŸç”¨æˆ·ç›®æ ‡\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä¸»è¦åˆ›æ–°ç‚¹ï¼š\\n\\t\\n\\næ›´å…·æŒ‘æˆ˜æ€§çš„åŸŸé—´ä¾èµ–å…³ç³»ï¼š\\n\\nä¸€ä¸ªé¢†åŸŸçš„é€‰æ‹©ä¼šåŠ¨æ€å½±å“å…¶ä»–ç›¸å…³é¢†åŸŸçš„é€‰æ‹©\\nä¾‹å¦‚ç”¨æˆ·é€‰æ‹©çš„æ™¯ç‚¹ä¼šå½±å“åç»­é…’åº—çš„æ¨èèŒƒå›´(éœ€è¦åœ¨æ™¯ç‚¹é™„è¿‘)\\n\\nå®Œæ•´çš„æ ‡æ³¨ï¼š\\n\\nåŒæ—¶æä¾›ç”¨æˆ·ç«¯å’Œç³»ç»Ÿç«¯çš„å¯¹è¯çŠ¶æ€æ ‡æ³¨\\nåŒ…å«å¯¹è¯è¡Œä¸º(dialogue acts)çš„æ ‡æ³¨\\nç”¨æˆ·çŠ¶æ€æ ‡æ³¨æœ‰åŠ©äºè¿½è¸ªå¯¹è¯æµç¨‹å’Œå»ºæ¨¡ç”¨æˆ·è¡Œä¸ºâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BruceNju/crosswoz-sft.","first_N":5,"first_N_keywords":["question-answering","Chinese","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"BiasAsker","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iforgott/BiasAsker","creator_name":"Yuxuan Wan","creator_url":"https://huggingface.co/iforgott","description":"| Papaer | Github |\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tComplete dataset of BiasAsker\\n\\t\\n\\n\\nbias_annotation.csv: all the biases and their annotated categories.\\nbias_translate.csv: the Chinese translation of the biases in bias_annotation.csv.\\nantonym_annotation.csv: the antonyms of biases in bias_annotation.csv, biases without proper antonyms are removed.\\nantonym_translate.csv: the Chinese translation of antonyms in antonym_annotation.csv\\ngroups.csv: all social groups and their categories\\ngroups_translate.csv: theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iforgott/BiasAsker.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"MJEE","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TomLi/MJEE","creator_name":"Tom","creator_url":"https://huggingface.co/TomLi","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for MJEE\\n\\t\\n\\n","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","multiple-choice-qa","original","Chinese"],"keywords_longer_than_N":true},
	{"name":"CNAPS","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gweesin/CNAPS","creator_name":"Gweesin Chan","creator_url":"https://huggingface.co/gweesin","description":"gweesin/CNAPS dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Chinese","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"InfoSearch_train","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EIT-NLP/InfoSearch_train","creator_name":"EIT-NLP","creator_url":"https://huggingface.co/EIT-NLP","description":"EIT-NLP/InfoSearch_train dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"tw-ly-law_content","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfun/tw-ly-law_content","creator_name":"Openfun Ltd.","creator_url":"https://huggingface.co/openfun","description":"openfun/tw-ly-law_content dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"semeval-2025-task11-track-b","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track B Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track B, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 11 standard ISO codes\\nTotal examples: 47111\\nSplits: train, dev, test\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTrack Information\\n\\t\\n\\nTrack B hasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b.","first_N":5,"first_N_keywords":["Amharic","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"tw-ly-gazette_agenda","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfun/tw-ly-gazette_agenda","creator_name":"Openfun Ltd.","creator_url":"https://huggingface.co/openfun","description":"openfun/tw-ly-gazette_agenda dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","10K - 100K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"amateur_astronomer_jsonl","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yangpengchao/amateur_astronomer_jsonl","creator_name":"yangpengchao","creator_url":"https://huggingface.co/yangpengchao","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yangpengchao/amateur_astronomer_jsonl.","first_N":5,"first_N_keywords":["text-classification","English","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Diabetica-o1-SFT","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WaltonFuture/Diabetica-o1-SFT","creator_name":"Lai Wei","creator_url":"https://huggingface.co/WaltonFuture","description":"\\n\\t\\n\\t\\t\\n\\t\\tDiabetica-o1-SFT\\n\\t\\n\\n\\n\\n    Diabetica: Adapting Large Language Model to Enhance Multiple Medical Tasks in Diabetes Care and Management\\n\\n\\n\\n\\n\\nCode ï½œPaper \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nSpecifically, we use Deepseek-R1-Distilled-Qwen-32B as our teacher model. Our data augmentation strategy follows a two-step approach: (1) We prompt Qwen2.5-72B-Instruct to generate diverse synthetic questions based on existing datasets. (2) We then use Deepseek-R1-Distilled-Qwen-32B to generate responses forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WaltonFuture/Diabetica-o1-SFT.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"R1-Vision-PixMo-Cap-QA-zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuyq96/R1-Vision-PixMo-Cap-QA-zh","creator_name":"Ya-Qi Yu","creator_url":"https://huggingface.co/yuyq96","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tR1-Vision: Let's first take a look at the image\\n\\t\\n\\n\\n  \\n  \\n\\n\\n[ğŸ¤— Cold-Start Dataset]  [ğŸ“œ Report (Coming Soon)]\\n\\n\\nDeepSeek-R1 demonstrates outstanding reasoning abilities when tackling math, coding, puzzle, and science problems, as well as responding to general inquiries. However, as a text-only reasoning model, R1 cannot process multimodal inputs like images, which limits its practicality in certain situations. Exploring the potential for multimodal reasoning is an intriguingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuyq96/R1-Vision-PixMo-Cap-QA-zh.","first_N":5,"first_N_keywords":["Chinese","mit","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"huiboAi","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RunQi007/huiboAi","creator_name":"Guo","creator_url":"https://huggingface.co/RunQi007","description":"","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"introduce-myself","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xiongjj/introduce-myself","creator_name":"xiongjiujiu","creator_url":"https://huggingface.co/xiongjj","description":"æˆ‘æ˜¯readmeâ€¦â€¦\\n","first_N":5,"first_N_keywords":["text-classification","Chinese","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Question_Answering","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from UN Parallel Corpus and xquad.\\nThe haystacks are from UN Parallel Corpus Test and Development Sets and we translate them to other languages by Google Translate.\\nThe multilingual QA data is fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/plumber233/test","creator_name":"plumber233","creator_url":"https://huggingface.co/plumber233","description":"plumber233/test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"cantonese-written-chinese-translation","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/raptorkwok/cantonese-written-chinese-translation","creator_name":"Raptor K","creator_url":"https://huggingface.co/raptorkwok","description":"raptorkwok/cantonese-written-chinese-translation dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Chinese","cc0-1.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"demo","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/c00cjz00/demo","creator_name":"chaochun chuang","creator_url":"https://huggingface.co/c00cjz00","description":"c00cjz00/demo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","mit","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"CMRC2018","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/susie-y/CMRC2018","creator_name":"yang","creator_url":"https://huggingface.co/susie-y","description":"susie-y/CMRC2018 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","cc-by-sa-4.0","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"farming","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kunpehx/farming","creator_name":"Kun Peng","creator_url":"https://huggingface.co/kunpehx","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset is used agricultural knowledge base training.\\n","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ShiftySpeech","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ash56/ShiftySpeech","creator_name":"Ashi Garg","creator_url":"https://huggingface.co/ash56","description":"This repository introduces:  ğŸŒ€ ShiftySpeech: A Large-Scale Synthetic Speech Dataset with Distribution Shifts\\n\\n\\t\\n\\t\\t\\n\\t\\tğŸ”¥ Key Features\\n\\t\\n\\n\\n3000+ hours of synthetic speech\\nDiverse Distribution Shifts: The dataset spans 7 key distribution shifts, including:  \\nğŸ“– Reading Style  \\nğŸ™ï¸ Podcast  \\nğŸ¥ YouTube  \\nğŸ—£ï¸ Languages (Three different languages)  \\nğŸŒ Demographics (including variations in age, accent, and gender)\\n\\n\\nMultiple Speech Generation Systems: Includes data synthesized from various TTSâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ash56/ShiftySpeech.","first_N":5,"first_N_keywords":["English","Chinese","Japanese","apache-2.0","Audio"],"keywords_longer_than_N":true},
	{"name":"Syndrome_Differentiation_NK_test","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/XiaoEnn/Syndrome_Differentiation_NK_test","creator_name":"Yehan Yang","creator_url":"https://huggingface.co/XiaoEnn","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe dataset was cleaned from the Traditional Chinese Medicine Internal Medicine textbook by the Angopulo Technology team. The cleaned data was then proofread and annotated by professional TCM students to ensure its accuracy. The cleaned data is used to train and validate the accuracy of downstream syndrome differentiation tasks based on the pre-trained herberta model.\\n","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"M-ABSA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tM-ABSA\\n\\t\\n\\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Description:\\n\\t\\n\\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\\nAll datasets are stored in the data/ folder:\\n\\nAll dataset contains 7 domains.\\n\\ndomains = [\\\"coursera\\\", \\\"hotel\\\", \\\"laptop\\\", \\\"restaurant\\\", \\\"phone\\\", \\\"sight\\\", \\\"food\\\"]\\n\\n\\nEach dataset contains 21 languages.\\n\\nlangs = [\\\"ar\\\", \\\"da\\\", \\\"de\\\", \\\"en\\\", \\\"es\\\", \\\"fr\\\", \\\"hi\\\", \\\"hr\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA.","first_N":5,"first_N_keywords":["token-classification","text-classification","Arabic","Danish","German"],"keywords_longer_than_N":true},
	{"name":"ChMap-Data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrontierLab/ChMap-Data","creator_name":"FrontierLab","creator_url":"https://huggingface.co/FrontierLab","description":"\\n\\t\\n\\t\\t\\n\\t\\tChMapData: Chinese Memory-aware Proactive Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Chinese Memory-aware Proactive Dataset (ChMapData) is a novel dataset proposed in the paper \\\"Interpersonal Memory Matters: A New Task for Proactive Dialogue Utilizing Conversational History\\\". This dataset focuses on training and evaluating models' capabilities in proactive topic introduction based on conversational history, supporting the memory-aware proactive dialogue framework proposed in the paper.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FrontierLab/ChMap-Data.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Tieba-SomeInteresting","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hanversion/Tieba-SomeInteresting","creator_name":"Hanversion","creator_url":"https://huggingface.co/Hanversion","description":"\\n\\t\\n\\t\\t\\n\\t\\tä¸­æ–‡æ•°æ®é›†ï¼ˆåŸºäºç™¾åº¦è´´å§ï¼‰\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tç®€ä»‹\\n\\t\\n\\næœ¬æ•°æ®é›†æ•°æ®æ¥è‡ªäº2025å¹´3æœˆ5æ—¥ç™¾åº¦è´´å§\\næ•°æ®é›†ä½¿ç”¨äº†â€œå­™ç¬‘å·å§â€ã€â€œå¼±æ™ºå§â€ã€â€œä¸­å›½äººå£å§â€å’Œâ€œèˆªç©ºæ¯èˆ°å§â€\\næ•°æ®é›†é—®é¢˜æ¥è‡ªäºå‘å¸–çš„æ ‡é¢˜ï¼Œç­”æ¡ˆæ¥è‡ªäºæœ€çƒ­é—¨çš„å›å¤\\næ€è€ƒé“¾æ¥è‡ªäº DeepSeek-v3 ç”Ÿæˆ\\nç›®å‰æ•°æ®é›†å¤§å°è¾ƒå°ï¼Œåç»­ä¼šé€æ¸å¢åŠ \\n\\n\\t\\n\\t\\t\\n\\t\\tè”ç³»ä½œè€…\\n\\t\\n\\n\\nemail: hanversion@outlook.com\\ngithub: GitHub\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"FinSynth_data","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fintech-Dreamer/FinSynth_data","creator_name":"Fintech-Dreamer","creator_url":"https://huggingface.co/Fintech-Dreamer","description":"\\n\\t\\n\\t\\t\\n\\t\\tFinSynth_data\\n\\t\\n\\næœ¬æ•°æ®é›†æœ‰ä¸‰ä¸ªï¼Œåˆ†åˆ«è§£å†³ä¸‰ä¸ªé¢†åŸŸçš„é—®é¢˜ï¼š\\n\\nå®¢æˆ·æœåŠ¡èŠå¤©æœºå™¨äººï¼šç”Ÿæˆå¯ä»¥æœ‰æ•ˆç†è§£å’Œå›åº”å¹¿æ³›å®¢æˆ·è¯¢é—®çš„è®­ç»ƒæ•°æ®ã€‚\\næ¬ºè¯ˆæ£€æµ‹ï¼šä»äº¤æ˜“æ•°æ®ä¸­æå–æ¨¡å¼å’Œå¼‚å¸¸ï¼Œä»¥è®­ç»ƒå¯ä»¥è¯†åˆ«å’Œé¢„é˜²æ¬ºè¯ˆè¡Œä¸ºçš„æ¨¡å‹ã€‚\\nåˆè§„ç›‘æ§ï¼šæ€»ç»“æ³•è§„å’Œåˆè§„æ–‡ä»¶ï¼Œä»¥å¸®åŠ©æ¨¡å‹ç¡®ä¿éµå®ˆé‡‘èæ³•è§„ã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tå¾®è°ƒå¤§æ¨¡å‹å‚è€ƒ\\n\\t\\n\\nFintech-Dreamer/FinSynth_model_chatbot Â· Hugging Face\\nFintech-Dreamer/FinSynth_model_fraud Â· Hugging Face\\nFintech-Dreamer/FinSynth_model_compliance Â· Hugging Face\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå‰ç«¯æ¡†æ¶å‚è€ƒ\\n\\t\\n\\nFintech-Dreamer/FinSynth\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®å¤„ç†æ–¹å¼å‚è€ƒ\\n\\t\\n\\nFintech-Dreamer/FinSynth-Data-Processing\\n","first_N":5,"first_N_keywords":["question-answering","Chinese","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"jianke","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/XuehangCang/jianke","creator_name":"XuehangCang","creator_url":"https://huggingface.co/XuehangCang","description":"\\n\\t\\n\\t\\t\\n\\t\\tJianKe\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThis dataset is designed for text generation tasks in Chinese and is available in a single configuration named \\\"default\\\". The dataset is relatively sizable, falling within the 10K to 100K examples category. It is well-suited for various text generation applications including language modeling, dialog systems, and more.\\n\\n\\t\\n\\t\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\ntext: The primary feature of the dataset, which contains Chinese text strings. The data type is string.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/XuehangCang/jianke.","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"TVC-Data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Allen8/TVC-Data","creator_name":"Allen Sun","creator_url":"https://huggingface.co/Allen8","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for TVC-Data\\n\\t\\n\\nThis repository contains the data presented in Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning.\\nCode: https://github.com/xxx/xxx\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nA mixture of 345K multimodal long-chain reasoning data. \\nFor more statistics of the dataset, please refer to our paper (coming soon)\\n\\n\\t\\n\\t\\t\\n\\t\\tSource Data\\n\\t\\n\\nLLaVA-OneVision: https://huggingface.co/datasets/lmms-lab/LLaVA-OneVision-DataGeo170K:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Allen8/TVC-Data.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"e-girl","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuebanlaosiji/e-girl","creator_name":"yueban","creator_url":"https://huggingface.co/yuebanlaosiji","description":"yuebanlaosiji/e-girl dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"smoltalk-chinese-QwQ-Distrill","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChinaunicomSoftware/smoltalk-chinese-QwQ-Distrill","creator_name":"Chinaunicom Software","creator_url":"https://huggingface.co/ChinaunicomSoftware","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tsmoltalk-chinese-QwQ-Distrill          [ä¸­æ–‡]    [English]\\n\\t\\n\\n\\n\\n\\nğŸ“–Technical Report\\nsmoltalk-chinese-QwQ-Distrill is a Chinese fine-tuning dataset constructed with reference to the SmolTalk-Chinese dataset. It aims to provide high-quality synthetic reasoning data support for training large language models (LLMs). The dataset consists entirely of synthetic data, comprising over 700,000 entries. It is specifically designed to enhance the performance of Chinese LLMs across various tasksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChinaunicomSoftware/smoltalk-chinese-QwQ-Distrill.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"advbench_behaviors_m5","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/advbench_behaviors_m5","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout advbench_behaviors_m5\\n\\t\\n\\næ­¤æ•°æ®é›†ä¸º advbench_behaviors.csv æ–‡ä»¶çš„å¤šè¯­è¨€ç¿»è¯‘ç‰ˆæœ¬ã€‚ä¸€ä¸ªå¸¸è§çš„ä»»åŠ¡æ˜¯ç”¨äº abliterator è„šæœ¬ã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AdvBench\\n\\t\\n\\nPaper: Universal and Transferable Adversarial Attacks on Aligned Language Models\\nData: AdvBench Dataset\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout\\n\\t\\n\\nAdvBench is a set of 500 harmful behaviors formulated as instructions. These behaviors\\nrange over the same themes as the harmful strings setting, but the adversaryâ€™s goal\\nis instead to find a single attack string thatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lenML/advbench_behaviors_m5.","first_N":5,"first_N_keywords":["text2text-generation","English","Chinese","Korean","jp"],"keywords_longer_than_N":true},
	{"name":"train1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dsacedsfds/train1","creator_name":"sss","creator_url":"https://huggingface.co/dsacedsfds","description":"dsacedsfds/train1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Rosmontis","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Rosmontis","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Rosmontis dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","Chinese","Japanese","Korean"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai_saamgwokjinji_jyutping","keyword":"yue chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hon9kon9ize/zoengjyutgaai_saamgwokjinji_jyutping","creator_name":"hon9kon9ize","creator_url":"https://huggingface.co/hon9kon9ize","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå¼µæ‚¦æ¥·è¬›ã€Šä¸‰åœ‹æ¼”ç¾©ã€‹èªéŸ³æ•¸æ“šé›† - ç²µæ‹¼æ©Ÿæ¢°ç¿»è­¯\\n\\t\\n\\nå‘¢å€‹ dataset ä¿‚åˆ©ç”¨ Wav2Vec Bert 2.0  hon9kon9ize/wav2vec2bert-jyutping å°‡ ç¿»è­¯æˆç²µèªæ‹¼éŸ³ã€‚è¦æ³¨æ„ï¼ç¿»è­¯ä¸­å¯èƒ½æœ‰éŒ¯èª¤ï¼Œç¿»è­¯çµæœæœªç¶“äººæ‰‹é©—è­‰ã€‚\\n","first_N":5,"first_N_keywords":["Yue Chinese","apache-2.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"EmoBench","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SahandSab/EmoBench","creator_name":"Sahand Sabour","creator_url":"https://huggingface.co/SahandSab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEmoBench\\n\\t\\n\\n\\nThis is the official repository for our ACL 2024 paper \\\"EmoBench: Evaluating the Emotional Intelligence of Large Language Models\\\"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEmoBench is a comprehensive and challenging benchmark designed to evaluate the Emotional Intelligence (EI) of Large Language Models (LLMs). Unlike traditional datasets, EmoBench focuses not only on emotion recognition but also on advanced EI capabilities such as emotional reasoning and application.\\nThe datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SahandSab/EmoBench.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"MedCT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/MedCT","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"MedCT is the world's first clinical terminology for non-English language, e.g., Chinese.\\n","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"mmevol-zh-hant","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/syntaxsynth/mmevol-zh-hant","creator_name":"SyntaxSynth","creator_url":"https://huggingface.co/syntaxsynth","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMEvol - Translated Chinese Traditional\\n\\t\\n\\nA subset of Tongyi-ConvAI/MMEvol translated using yentinglin/Llama-3-Taiwan-70B-Instruct from english to traditional chinese.\\nRead the Note below before use.\\nImage source distribution:\\n\\n\\t\\n\\t\\t\\nDataset\\nCount\\nPercentage\\n\\n\\n\\t\\t\\ncoco\\n6598\\n29.8%\\n\\n\\nQ-Instruct-DB\\n5856\\n26.4%\\n\\n\\nclevr\\n2383\\n10.8%\\n\\n\\nchartqa\\n1733\\n7.8%\\n\\n\\nhfdata\\n1296\\n5.9%\\n\\n\\ngeo170k\\n706\\n3.2%\\n\\n\\ndata_engine\\n698\\n3.2%\\n\\n\\nmathvision\\n644\\n2.9%\\n\\n\\ndocvqa\\n600\\n2.7%\\n\\n\\nalfworld\\n401\\n1.8%\\n\\n\\narxivqa\\n337\\n1.5%â€¦ See the full description on the dataset page: https://huggingface.co/datasets/syntaxsynth/mmevol-zh-hant.","first_N":5,"first_N_keywords":["text-generation","image-to-text","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"demo","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eyl45/demo","creator_name":"Ethan","creator_url":"https://huggingface.co/eyl45","description":"eyl45/demo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","Korean","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"OpenO1-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/OpenO1-SFT","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"Borrowed from: https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT\\nYou can use it in LLaMA Factory by specifying dataset: openo1_sft.\\n","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Fastx-Infinity-Instruct-Chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fastx-ai/Fastx-Infinity-Instruct-Chinese","creator_name":"fastx-ai.com","creator_url":"https://huggingface.co/fastx-ai","description":"use train.csv/evaluation.csv !\\n","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","10M<n<100M","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"pokemon-gpt4o-captions","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/pokemon-gpt4o-captions","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"Borrowed from: https://huggingface.co/datasets/jugg1024/pokemon-gpt4o-captions\\nYou can use it in LLaMA Factory by specifying dataset: pokemon_cap.\\n","first_N":5,"first_N_keywords":["text-generation","question-answering","visual-question-answering","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"kuochang-quote","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/h-alice/kuochang-quote","creator_name":"Wayne Hong","creator_url":"https://huggingface.co/h-alice","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKuochang Sensei Quotes\\n\\t\\n\\n(In)Famous quotes from politician Kuochang Huang.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is a collection of quotes from Kuochang Huang, a Taiwanese politician. \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"kuochang_quotes\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is in CSV format, with the following columns:\\n\\nspeaker: The speaker of the quote. Which is always \\\"é»ƒåœ‹æ˜Œ\\\".\\nquote: The quote from Kuochang Huang.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/h-alice/kuochang-quote.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","text-generation","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"doraemon","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobertNyu/doraemon","creator_name":"Nyu Ching Yee","creator_url":"https://huggingface.co/RobertNyu","description":"RobertNyu/doraemon dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","n<1K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"Reflection-Chinese-Dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stvlynn/Reflection-Chinese-Dataset","creator_name":"Steven Lynn","creator_url":"https://huggingface.co/stvlynn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReflection-Chinese-DatasetÂ·Reflectionä¸­æ–‡æ•°æ®é›†\\n\\t\\n\\nBased on mahiatlinux/Reflection-Dataset-v2, translated using RA Translation Tool\\n","first_N":5,"first_N_keywords":["Chinese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Reflection-Chinese-Dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stvlynn/Reflection-Chinese-Dataset","creator_name":"Steven Lynn","creator_url":"https://huggingface.co/stvlynn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReflection-Chinese-DatasetÂ·Reflectionä¸­æ–‡æ•°æ®é›†\\n\\t\\n\\nBased on mahiatlinux/Reflection-Dataset-v2, translated using RA Translation Tool\\n","first_N":5,"first_N_keywords":["Chinese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"DEMO","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iiiiwis/DEMO","creator_name":"mz.w","creator_url":"https://huggingface.co/iiiiwis","description":"This repository contains data for our paper DEMO: Reframing Dialogue Interaction with Fine-grained Element Modeling. We systematically construct the dialogue framework from the Prelude through the Interlocution to the Epilogue and define an innovative research task: Dialogue Element MOdeling. Furthermore, we introduce a tailor-designed benchmark DEMO to facilitate comprehensive dialogue modeling and assessment. Concretely, our proposed task focuses on two core competencies of models: (1)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/iiiiwis/DEMO.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"hkcancor-multi","keyword":"yue chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlienKevin/hkcancor-multi","creator_name":"Xiang (Kevin) Li","creator_url":"https://huggingface.co/AlienKevin","description":"This data is the subset of the Hong Kong Cantonese Corpus (HKCanCor) that has been re-segmented by the multi-tiered word segmentation scheme described in the following paper:\\nCharles Lam, Chaak-ming Lau, and Jackson L. Lee. 2024. Multi-Tiered Cantonese Word Segmentation. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 11993â€“12002, Torino, Italy. ELRA and ICCL.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProcessing fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlienKevin/hkcancor-multi.","first_N":5,"first_N_keywords":["token-classification","Yue Chinese","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"wiki-yue-long-multi","keyword":"yue chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlienKevin/wiki-yue-long-multi","creator_name":"Xiang (Kevin) Li","creator_url":"https://huggingface.co/AlienKevin","description":"This segmentation dataset was generated with AlienKevin/electra-hongkongese-base-hkcancor-multi on R5dwMg/zh-wiki-yue-long.\\nSee https://github.com/AlienKevin/dips for details.\\n","first_N":5,"first_N_keywords":["token-classification","Yue Chinese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"mmmlu_lite","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMLU-Lite\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is aboutâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"policydata","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fsyfb/policydata","creator_name":"fengshuyang","creator_url":"https://huggingface.co/fsyfb","description":"ç”¨äºæ”¿ç­–é¢†åŸŸå¤§æ¨¡å‹åŠæ£€ç´¢å¢å¼ºçš„éƒ¨åˆ†æ•°æ®\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"text-moderation-02-multilingual","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ifmain/text-moderation-02-multilingual","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","description":"This dataset is based on Kaggle.It represents a version of @ifmain/text-moderation-410K that has been cleansed of semantically similar values and normalized to a 50/50 ratio of negative and neutral entries.\\nThe dataset contains 1.5M entries (91K * 17 languages).  \\nBefore use, augmentation is recommended! (e.g., character substitution to bypass moderation).\\nFor augmentation, you can use @ifmain/StringAugmentor.  \\nEnjoy using it!\\n","first_N":5,"first_N_keywords":["English","German","French","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"Multilingal-sakalt-data","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚mitãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ã™ã€‚\\n","first_N":5,"first_N_keywords":["text-generation","Abkhaz","Bhojpuri","Chechen","Czech"],"keywords_longer_than_N":true},
	{"name":"mmevalpro","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMEVAL/mmevalpro","creator_name":"MMEVAL","creator_url":"https://huggingface.co/MMEVAL","description":"MMEvalPro\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MMEvalPro\\n\\t\\n\\nWe create MMEvalPro for more accurate and efficent evaluation for Large Multimodal Models. It is designed to avoid Type-I errors through a trilogy evaluation pipeline and more rigorous metrics. For each original question from existing benchmarks, human annotators augment it by creating one perception question and one knowledge anchor question through a meticulous annotation process.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Format\\n\\t\\n\\n{\\n    \\\"index\\\": [int64] Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MMEVAL/mmevalpro.","first_N":5,"first_N_keywords":["multiple-choice","English","Chinese","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"emova-sft-speech-eval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-SFT-Speech-Eval\\n\\t\\n\\n\\n\\n\\nğŸ¤— EMOVA-Models | ğŸ¤— EMOVA-Datasets | ğŸ¤— EMOVA-Demo \\nğŸ“„ Paper | ğŸŒ Project-Page | ğŸ’» Github | ğŸ’» EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-SFT-Speech-Eval is an evaluation dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-Eval is part of EMOVA-Datasets collection, and the trainingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"windata-vision-synthetics-zh-300k","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/winninghealth/windata-vision-synthetics-zh-300k","creator_name":"Winning Health AI Research","creator_url":"https://huggingface.co/winninghealth","description":"ä»‹ç»\\næˆ‘ä»¬æ•´ç†ç”Ÿæˆäº†ä¸€ä¸ªä¸­æ–‡å¤šæ¨¡æ€å›¾æ–‡æŒ‡ä»¤æ•°æ®é›†ï¼ŒåŒ…å«äº†å¤§çº¦30ä¸‡æ¡æ•°æ®ä»¥åŠçº¦20ä¸‡å¼ å›¾ç‰‡ï¼Œæ¶‰åŠæ–‡æ¡£docã€å›¾è¡¨ã€æ•°å­¦ã€OCRç­‰å¤šç§åœºæ™¯ã€‚\\né’ˆå¯¹å¼€æºæ•°æ®ä¸­ä¸­æ–‡å›¾æ–‡æŒ‡ä»¤é›†å°‘ä¸”æŒ‡ä»¤é›†æè¿°æ™®éè¿‡äºç®€çŸ­ç­‰é—®é¢˜ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åŸºäºå¼€æºæ¨¡å‹çš„åˆæˆæ•°æ®ç”Ÿæˆæ–¹æ³•ï¼Œåˆ©ç”¨ Qwen2-vl-72B-Instruct ç”Ÿæˆè¾ƒä¸ºè¯¦ç»†çš„ä¸­æ–‡captionæŒ‡ä»¤é›†ï¼Œç„¶ååœ¨åŒä¸€åœºæ™¯ä¸­éšæœºæŒ‘é€‰1-4å¼ å›¾ç‰‡å’Œç›¸åº”çš„ä¸­æ–‡captionï¼Œå°†captionæ•°æ®ç»™åˆ°æˆ‘ä»¬çš„å¤§è¯­è¨€æ¨¡å‹ WiNGPT-2.6 é€šè¿‡è®¾è®¡ç³»ç»ŸæŒ‡ä»¤ä½¿å…¶æ¯è½®è¿›è¡Œæé—®ï¼Œå°†é—®é¢˜å’Œå›¾ç‰‡ç»™åˆ° Qwen2-vl-72B-Instruct ä½¿å…¶è¿›è¡Œå›ç­”ï¼›æœ€åè®¾å®šå¾ªç¯æ¬¡æ•°ï¼Œå¾—åˆ°å¤šè½®å¤šå›¾çš„å¯¹è¯æ•°æ®ã€‚ \\nå¯¹äºç”Ÿæˆåçš„æ•°æ®ï¼Œæ ¹æ®ç­”æ¡ˆçš„é•¿åº¦ã€è¯­å¥çš„é‡å¤æ€§ç­‰è¿›è¡Œäº†è§„åˆ™è¿‡æ»¤ï¼›æ•°å­¦ç±»é¢˜ç›®ï¼Œæ ¹æ®åŸå§‹æ•°æ®çš„ç­”æ¡ˆè¿›è¡Œäº†è¿‡æ»¤ã€‚åœ¨åˆ¶ä½œæœ€åçš„captionæŒ‡ä»¤é›†æ—¶ï¼Œæˆ‘ä»¬é’ˆå¯¹æ¯ä¸€ä¸ªåœºæ™¯éƒ½è®¾è®¡äº†ä¸Šç™¾ä¸ªé—®é¢˜ï¼Œä¿è¯äº†captionæ•°æ®é›†çš„å¤šæ ·æ€§ï¼›åœ¨å¯¹è¯æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬åœ¨ä¸åŒåœºæ™¯ä¸‹æ¥è®©WiNGPT-2.6â€¦ See the full description on the dataset page: https://huggingface.co/datasets/winninghealth/windata-vision-synthetics-zh-300k.","first_N":5,"first_N_keywords":["image-to-text","Chinese","cc-by-4.0","100K<n<1M","arxiv:2409.11402"],"keywords_longer_than_N":true},
	{"name":"Multilingal-sakalt-data","keyword":"yue chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚mitãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ã™ã€‚\\n","first_N":5,"first_N_keywords":["text-generation","Abkhaz","Bhojpuri","Chechen","Czech"],"keywords_longer_than_N":true},
	{"name":"ChinaKeywords","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aqweteddy/ChinaKeywords","creator_name":"aqweteddy","creator_url":"https://huggingface.co/aqweteddy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChina Keywords\\n\\t\\n\\nThis repository lists keywords related to Chinese politics along with their corresponding explanations. The primary source of these keywords is:\\n\\nChina Keywords\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä¸­åœ‹é—œéµå­—\\n\\t\\n\\næœ¬ repo åˆ—å‡ºäº†èˆ‡ä¸­åœ‹æ”¿æ²»ç›¸é—œçš„é—œéµå­—åŠå…¶å°æ‡‰çš„è§£é‡‹ï¼Œä¸»è¦ä¾†æºç‚ºï¼š\\n\\nä¸­åœ‹é—œéµå­—\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå…è²¬è²æ˜\\n\\t\\n\\n\\næœ¬ repo æä¾›çš„è³‡è¨Šåƒ…ä¾›åƒè€ƒä¹‹ç”¨ã€‚\\né—œéµå­—çš„è§£é‡‹åŸºæ–¼å…¬é–‹å¯ç”¨è³‡è¨Šï¼Œä¸¦ä¸ä»£è¡¨ä»»ä½•æˆ‘çš„ç«‹å ´æˆ–è§€é»ã€‚\\næœ¬ repo ä¸ä¿è­‰æ‰€æä¾›è³‡è¨Šçš„æº–ç¢ºæ€§ã€å®Œæ•´æ€§æˆ–æ™‚æ•ˆæ€§ã€‚\\nä½¿ç”¨å…§å®¹éœ€ç”±ä½¿ç”¨è€…è‡ªè¡Œåˆ¤æ–·èˆ‡æ‰¿æ“”è²¬ä»»ã€‚\\n\\n","first_N":5,"first_N_keywords":["Chinese","cc-by-sa-4.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"llm-ideology-analysis","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajrogier/llm-ideology-analysis","creator_name":"Alexander Rogiers","creator_url":"https://huggingface.co/ajrogier","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LLM Ideology Dataset\\n\\t\\n\\nThis dataset contains evaluations of political figures by various Large Language Models (LLMs), designed to analyze ideological biases in AI language models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset contains responses from 17 different Large Language Models evaluating 4,339 political figures, with responses collected in both English and Chinese. The evaluations were conducted using a two-stage promptingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ajrogier/llm-ideology-analysis.","first_N":5,"first_N_keywords":["English","Chinese","cc-by-4.0","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"DXYDiseaseRetrieval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMIRB/DXYDiseaseRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","description":"Paper: https://huggingface.co/papers/2410.20050\\n","first_N":5,"first_N_keywords":["text-retrieval","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"DXYConsultRetrieval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMIRB/DXYConsultRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","description":"Paper: https://huggingface.co/papers/2410.20050\\n","first_N":5,"first_N_keywords":["text-retrieval","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"CSLRelatedRetrieval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMIRB/CSLRelatedRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","description":"Paper: https://huggingface.co/papers/2410.20050\\n","first_N":5,"first_N_keywords":["text-retrieval","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ksdoc-airscript","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cy948/ksdoc-airscript","creator_name":"yao cai","creator_url":"https://huggingface.co/cy948","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHuman Annotation Example\\n\\t\\n\\nWe invite some domain experts who has code experience on AirScript to add annotations for the code snippets in lines. For example:\\n\\nData annotation example\\n\\n/*æœ¬ç¤ºä¾‹åˆ¤æ–­å¦‚æœæ´»åŠ¨å·¥ä½œè¡¨ä¸ŠåŒºåŸŸ B1:B10 ä¸­ç¬¬äºŒä¸ªï¼ˆAboveAverageï¼‰æ¡ä»¶æ ¼å¼çš„ç±»å‹ä¸ºxlAboveAverageConditionï¼Œåˆ™åˆ é™¤è¯¥æ¡ä»¶æ ¼å¼ã€‚*/\\nfunction test() {\\n+// ä»å·¥ä½œè¡¨ä¸ŠåŒºåŸŸ B1:B10 ä¸­é€‰æ‹©ç¬¬äºŒä¸ªæ¡ä»¶æ ¼å¼\\n    let aboveAverage = ActiveSheet.Range(\\\"B1:B10\\\").FormatConditions.Item(2)\\n+// è‹¥æ¡ä»¶æ ¼å¼çš„ç±»å‹ä¸º `xlAboveAverageCondition`\\n    if (aboveAverage.Type ==â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cy948/ksdoc-airscript.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"answer_data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fruiters/answer_data","creator_name":"org_llama","creator_url":"https://huggingface.co/fruiters","description":"fruiters/answer_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"multilingual-coco","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/romrawinjp/multilingual-coco","creator_name":"Romrawin Chumpu","creator_url":"https://huggingface.co/romrawinjp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Common Objects in Context (COCO) Dataset\\n\\t\\n\\nThis dataset is a collection of multiple language open-source captions of COCO dataset. \\nThe split in this dataset is set according to Andrej Karpathy's split from dataset_coco.json file. The collection was created specifically for simplicity of use in training and evaluation pipeline by non-commercial and research purposes. The COCO images dataset is licensed under a Creative Commons Attribution 4.0 License.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/romrawinjp/multilingual-coco.","first_N":5,"first_N_keywords":["image-to-text","English","Thai","Russian","Japanese"],"keywords_longer_than_N":true},
	{"name":"medical-o1-reasoning-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\tNews\\n\\t\\n\\n[2025/02/22] We released the distilled dataset from Deepseek-R1 based on medical verifiable problems. You can use it to initialize your models with the reasoning chain from Deepseek-R1.\\n[2024/12/25] We open-sourced the medical reasoning dataset for SFT, built on medical verifiable problems and an LLM verifier.\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset is used to fine-tune HuatuoGPT-o1, a medical LLM designed for advanced medical reasoning. This dataset is constructed using GPT-4oâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Chinese-DeepSeek-R1-Distill-data-110k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k","creator_name":"CongLiu","creator_url":"https://huggingface.co/Congliu","description":"\\n\\t\\n\\t\\t\\n\\t\\tä¸­æ–‡åŸºäºæ»¡è¡€DeepSeek-R1è’¸é¦æ•°æ®é›†ï¼ˆChinese-Data-Distill-From-R1ï¼‰\\n\\t\\n\\n\\nğŸ¤— Hugging FaceÂ Â  | Â Â ğŸ¤– ModelScope Â Â  | Â Â ğŸš€ Github Â Â  | Â Â ğŸ“‘ Blog\\n\\n\\næ³¨æ„ï¼šæä¾›äº†ç›´æ¥SFTä½¿ç”¨çš„ç‰ˆæœ¬ï¼Œç‚¹å‡»ä¸‹è½½ã€‚å°†æ•°æ®ä¸­çš„æ€è€ƒå’Œç­”æ¡ˆæ•´åˆæˆoutputå­—æ®µï¼Œå¤§éƒ¨åˆ†SFTä»£ç æ¡†æ¶å‡å¯ç›´æ¥ç›´æ¥åŠ è½½è®­ç»ƒã€‚\\næœ¬æ•°æ®é›†ä¸ºä¸­æ–‡å¼€æºè’¸é¦æ»¡è¡€R1çš„æ•°æ®é›†ï¼Œæ•°æ®é›†ä¸­ä¸ä»…åŒ…å«mathæ•°æ®ï¼Œè¿˜åŒ…æ‹¬å¤§é‡çš„é€šç”¨ç±»å‹æ•°æ®ï¼Œæ€»æ•°é‡ä¸º110Kã€‚\\nä¸ºä»€ä¹ˆå¼€æºè¿™ä¸ªæ•°æ®ï¼Ÿ\\nR1çš„æ•ˆæœååˆ†å¼ºå¤§ï¼Œå¹¶ä¸”åŸºäºR1è’¸é¦æ•°æ®SFTçš„å°æ¨¡å‹ä¹Ÿå±•ç°å‡ºäº†å¼ºå¤§çš„æ•ˆæœï¼Œä½†æ£€ç´¢å‘ç°ï¼Œå¤§éƒ¨åˆ†å¼€æºçš„R1è’¸é¦æ•°æ®é›†å‡ä¸ºè‹±æ–‡æ•°æ®é›†ã€‚ åŒæ—¶ï¼ŒR1çš„æŠ¥å‘Šä¸­å±•ç¤ºï¼Œè’¸é¦æ¨¡å‹ä¸­åŒæ—¶ä¹Ÿä½¿ç”¨äº†éƒ¨åˆ†é€šç”¨åœºæ™¯æ•°æ®é›†ã€‚\\nä¸ºäº†å¸®åŠ©å¤§å®¶æ›´å¥½åœ°å¤ç°R1è’¸é¦æ¨¡å‹çš„æ•ˆæœï¼Œç‰¹æ­¤å¼€æºä¸­æ–‡æ•°æ®é›†ã€‚è¯¥ä¸­æ–‡æ•°æ®é›†ä¸­çš„æ•°æ®åˆ†å¸ƒå¦‚ä¸‹ï¼š\\n\\nMathï¼šå…±è®¡36568ä¸ªæ ·æœ¬ï¼Œ\\nExamï¼šå…±è®¡2432ä¸ªæ ·æœ¬ï¼Œ\\nSTEMï¼šå…±è®¡12648ä¸ªæ ·æœ¬ï¼Œâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","question-answering","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Chinese-DeepSeek-R1-Distill-data-110k-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT","creator_name":"CongLiu","creator_url":"https://huggingface.co/Congliu","description":"\\n\\t\\n\\t\\t\\n\\t\\tä¸­æ–‡åŸºäºæ»¡è¡€DeepSeek-R1è’¸é¦æ•°æ®é›†ï¼ˆChinese-Data-Distill-From-R1ï¼‰\\n\\t\\n\\n\\nğŸ¤— Hugging FaceÂ Â  | Â Â ğŸ¤– ModelScope Â Â  | Â Â ğŸš€ Github Â Â  | Â Â ğŸ“‘ Blog\\n\\n\\næ³¨æ„ï¼šè¯¥ç‰ˆæœ¬ä¸ºï¼Œå¯ä»¥ç›´æ¥SFTä½¿ç”¨çš„ç‰ˆæœ¬ï¼Œå°†åŸå§‹æ•°æ®ä¸­çš„æ€è€ƒå’Œç­”æ¡ˆæ•´åˆæˆoutputå­—æ®µï¼Œå¤§éƒ¨åˆ†SFTä»£ç æ¡†æ¶å‡å¯ç›´æ¥ç›´æ¥åŠ è½½è®­ç»ƒã€‚\\næœ¬æ•°æ®é›†ä¸ºä¸­æ–‡å¼€æºè’¸é¦æ»¡è¡€R1çš„æ•°æ®é›†ï¼Œæ•°æ®é›†ä¸­ä¸ä»…åŒ…å«mathæ•°æ®ï¼Œè¿˜åŒ…æ‹¬å¤§é‡çš„é€šç”¨ç±»å‹æ•°æ®ï¼Œæ€»æ•°é‡ä¸º110Kã€‚\\nä¸ºä»€ä¹ˆå¼€æºè¿™ä¸ªæ•°æ®ï¼Ÿ\\nR1çš„æ•ˆæœååˆ†å¼ºå¤§ï¼Œå¹¶ä¸”åŸºäºR1è’¸é¦æ•°æ®SFTçš„å°æ¨¡å‹ä¹Ÿå±•ç°å‡ºäº†å¼ºå¤§çš„æ•ˆæœï¼Œä½†æ£€ç´¢å‘ç°ï¼Œå¤§éƒ¨åˆ†å¼€æºçš„R1è’¸é¦æ•°æ®é›†å‡ä¸ºè‹±æ–‡æ•°æ®é›†ã€‚ åŒæ—¶ï¼ŒR1çš„æŠ¥å‘Šä¸­å±•ç¤ºï¼Œè’¸é¦æ¨¡å‹ä¸­åŒæ—¶ä¹Ÿä½¿ç”¨äº†éƒ¨åˆ†é€šç”¨åœºæ™¯æ•°æ®é›†ã€‚\\nä¸ºäº†å¸®åŠ©å¤§å®¶æ›´å¥½åœ°å¤ç°R1è’¸é¦æ¨¡å‹çš„æ•ˆæœï¼Œç‰¹æ­¤å¼€æºä¸­æ–‡æ•°æ®é›†ã€‚è¯¥ä¸­æ–‡æ•°æ®é›†ä¸­çš„æ•°æ®åˆ†å¸ƒå¦‚ä¸‹ï¼š\\n\\nMathï¼šå…±è®¡36568ä¸ªæ ·æœ¬ï¼Œ\\nExamï¼šå…±è®¡2432ä¸ªæ ·æœ¬ï¼Œ\\nSTEMï¼šå…±è®¡12648ä¸ªæ ·æœ¬ï¼Œâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","question-answering","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"alpaca-zh","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/alpaca-zh","creator_name":"Ming Xu (å¾æ˜)","creator_url":"https://huggingface.co/shibing624","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"alpaca-zh\\\"\\n\\t\\n\\næœ¬æ•°æ®é›†æ˜¯å‚è€ƒAlpacaæ–¹æ³•åŸºäºGPT4å¾—åˆ°çš„self-instructæ•°æ®ï¼Œçº¦5ä¸‡æ¡ã€‚\\nDataset from https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM \\nIt is the chinese dataset from https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/blob/main/data/alpaca_gpt4_data_zh.json\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage and License Notices\\n\\t\\n\\nThe data is intended and licensed for research use only. The dataset is CC BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset shouldâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shibing624/alpaca-zh.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"AyaVisionBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/AyaVisionBench","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Aya Vision Benchmark\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \\nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/AyaVisionBench.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"Traditional-Chinese-Medicine-Dataset-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SylvanL/Traditional-Chinese-Medicine-Dataset-SFT","creator_name":"SylvanLiu","creator_url":"https://huggingface.co/SylvanL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå¯å¤çº³ä»Šï¼Œåšå¾·ç²¾æœ¯\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®ä»‹ç»\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\téç½‘ç»œæ¥æºçš„é«˜è´¨é‡ä¸­åŒ»æ•°æ®é›†-æŒ‡ä»¤å¾®è°ƒ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHigh-Quality Traditional Chinese Medicine Dataset from Non-Internet Sources - SFT/IFT\\n\\t\\n\\nè¯¥æ•°æ®é›†ç»è¿‡å¤§é‡äººåŠ›å’Œèµ„æºçš„æŠ•å…¥ç²¾å¿ƒæ„å»ºï¼Œä»¥å…±å»ºLLMé«˜è´¨é‡ä¸­æ–‡ç¤¾åŒºä¸ºå·±ä»»ã€‚\\nåŒ…å«çº¦1GBçš„ä¸­åŒ»å„ä¸ªé¢†åŸŸä¸´åºŠæ¡ˆä¾‹ã€åå®¶å…¸ç±ã€åŒ»å­¦ç™¾ç§‘ï¼Œåè¯è§£é‡Šç­‰ä¼˜è´¨é—®ç­”å†…å®¹ï¼Œæ¶µç›–å…¨é¢ï¼Œé…æ¯”å‡è¡¡ã€‚\\næ•°æ®é›†ä¸»è¦ç”±éç½‘ç»œæ¥æºçš„å†…éƒ¨æ•°æ®æ„æˆï¼Œå¹¶99%ä¸ºç®€ä½“ä¸­æ–‡å†…å®¹ï¼Œå†…å®¹è´¨é‡ä¼˜å¼‚ï¼Œä¿¡æ¯å¯†åº¦å¯è§‚ã€‚\\nè¯¥æ•°æ®é›†çš„æ•°æ®æºä¸SylvanL/Traditional-Chinese-Medicine-Dataset-Pretrainä¸­çš„å†…å®¹å­˜åœ¨ä¸€å®šå…³è”ï¼Œä½†ä¸é«˜åº¦é‡å ã€‚\\nåœ¨äºŒè€…çš„æ„å»ºè¿‡ç¨‹ä¸­ï¼Œå­˜åœ¨ç€ä¸€å®šçš„å¾ªåºæ¸è¿›ä¸äº’ä¸ºè¡¥å……çš„é€»è¾‘.\\nè¯¥æ•°æ®é›†å¯ä»¥ç‹¬ç«‹ä½¿ç”¨ï¼Œä½†å»ºè®®å…ˆä½¿ç”¨é…å¥—çš„é¢„è®­ç»ƒæ•°æ®é›†å¯¹æ¨¡å‹è¿›è¡Œç»§ç»­é¢„è®­ç»ƒåï¼Œå†ä½¿ç”¨è¯¥æ•°æ®é›†è¿›è¡Œè¿›ä¸€æ­¥çš„æŒ‡ä»¤å¾®è°ƒã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SylvanL/Traditional-Chinese-Medicine-Dataset-SFT.","first_N":5,"first_N_keywords":["table-question-answering","Chinese","apache-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"Medical-R1-Distill-Data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/Medical-R1-Distill-Data","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset is an SFT dataset distilled from Deepseek-R1 (Full Power Version), based on medical verifiable problems from HuatuoGPT-o1.\\nThe Chinese version of the dataset is available at FreedomIntelligence/Medical-R1-Distill-Data-Chinese.\\nThe distillation originates from the native Deepseek-R1 API requests. We hope this distilled dataset can help initialize your models with the reasoning chain from R1. You can also use our previously built medical verified longâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/Medical-R1-Distill-Data.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"timbre_range","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ccmusic-database/timbre_range","creator_name":"CCMUSIC Database","creator_url":"https://huggingface.co/ccmusic-database","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Timbre and Range Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe timbre dataset contains acapella singing audio of 9 singers, as well as cut single-note audio, totaling 775 clips (.wav format)\\nThe vocal range dataset includes several up and down chromatic scales audio clips of several vocals, as well as the cut single-note audio clips (.wav format).\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nAudio classification\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nChinese, English\\n\\n\\t\\n\\t\\t\\n\\t\\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ccmusic-database/timbre_range.","first_N":5,"first_N_keywords":["audio-classification","Chinese","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"VibeEval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RekaAI/VibeEval","creator_name":"Reka AI","creator_url":"https://huggingface.co/RekaAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVibe-Eval\\n\\t\\n\\nA benchmark for evaluating multimodal chat models, including especially challenging examples.\\n[Link to paper] [Blogpost] [Github]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\nEach example has the following fields:\\n\\nexample_id: a unique ID for the example\\ncategory: the category that this example belongs to, either difficulty-normal or difficulty-hard\\nprompt: the user prompt\\nreference: a golden reference answer for the prompt\\nimage: an image struct (containing bytes and path keys).â€¦ See the full description on the dataset page: https://huggingface.co/datasets/RekaAI/VibeEval.","first_N":5,"first_N_keywords":["image-to-text","image-classification","English","Polish","Chinese"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\\n\\n   \\n       Overview |\\n       Details  |\\n       Structure  |\\n       Examples |\\n       Considerations |\\n       License |\\n       Citation |\\n       Contact |\\n       Acknowledgement\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"Qilin","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/THUIR/Qilin","creator_name":"THUIR","creator_url":"https://huggingface.co/THUIR","description":"\\n\\t\\n\\t\\t\\n\\t\\tQilin\\n\\t\\n\\nQilin is a large-scale multimodal dataset designed for advancing research in search, recommendation, and Retrieval-Augmented Generation (RAG) systems. This repository contains the official implementation of the dataset paper, baseline models, and evaluation tools.  This dataset was presented in Qilin: A Multimodal Information Retrieval Dataset with APP-level User Sessions.\\nGithub: https://github.com/RED-Search/Qilin\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nQilin provides comprehensiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/THUIR/Qilin.","first_N":5,"first_N_keywords":["question-answering","text-classification","sentence-similarity","text-retrieval","image-text-to-text"],"keywords_longer_than_N":true},
	{"name":"oasst1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"Everything_Instruct_Multilingual","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEverything Instruct (Multilingual Edition)\\n\\t\\n\\nEverything you need... all in one place ğŸ’˜\\n\\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\\nNote2: This version of the dataset supports the following languages:\\n\\nEnglish\\nRussianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual.","first_N":5,"first_N_keywords":["English","Russian","Chinese","Korean","Urdu"],"keywords_longer_than_N":true},
	{"name":"ruozhiba","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LooksJuicy/ruozhiba","creator_name":"LooksJuicy","creator_url":"https://huggingface.co/LooksJuicy","description":"å—COIG-CQIAå¯å‘ï¼Œæ„å»ºç±»ä¼¼æ•°æ®é›†ï¼Œä½†ç­”æ¡ˆé£æ ¼ç›¸å¯¹æ›´ç®€æ´ã€‚\\nå¼±æ™ºå§ç²¾é€‰é—®é¢˜æ•°æ®æ¥è‡ªgithubæä¾›çš„ç–‘é—®å¥ï¼Œè°ƒç”¨GPT-4è·å–ç­”æ¡ˆï¼Œå¹¶è¿‡æ»¤æ‰æ˜æ˜¾æ‹’ç­”çš„å›å¤ã€‚\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Medical-R1-Distill-Data-Chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/Medical-R1-Distill-Data-Chinese","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset is an SFT dataset distilled from Deepseek-R1 (Full Power Version), based on Chinese medical verifiable problems from HuatuoGPT-o1.\\nThe distillation originates from the native Deepseek-R1 API requests. We hope this distilled dataset can help initialize your models with the reasoning chain from R1. You can also use our previously built medical verified long reasoning chains based on GPT-4o on medical-o1-reasoning-SFT.\\nFor details, see our paper and GitHubâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/Medical-R1-Distill-Data-Chinese.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"DISC-Law-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ShengbinYue/DISC-Law-SFT","creator_name":"ShengbinYue","creator_url":"https://huggingface.co/ShengbinYue","description":"\\n\\t\\n\\t\\t\\n\\t\\tDISC-Law-SFT Dataset\\n\\t\\n\\nLegal Intelligent systems in Chinese require a combination of various abilities, including legal text understanding and generation. To achieve this, we have constructed a high-quality supervised fine-tuning dataset called DISC-Law-SFT, which covers different legal scenarios such as legal information extraction, legal judgment prediction, legal document summarization, and legal question answering. DISC-Law-SFT comprises two subsets, DISC-Law-SFT-Pair andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ShengbinYue/DISC-Law-SFT.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100M<n<1B","arxiv:2309.11325","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"MathVista","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI4Math/MathVista","creator_name":"AI for Math Reasoning","creator_url":"https://huggingface.co/AI4Math","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MathVista\\n\\t\\n\\n\\nDataset Description\\nPaper Information\\nDataset Examples\\nLeaderboard\\nDataset Usage\\nData Downloading\\nData Format\\nData Visualization\\nData Source\\nAutomatic Evaluation\\n\\n\\nLicense\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMathVista is a consolidated Mathematical reasoning benchmark within Visual contexts. It consists of three newly created datasets, IQTest, FunctionQA, and PaperQA, which address the missing visual domains and are tailored to evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AI4Math/MathVista.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","text-classification","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"oasst2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen Assistant Conversations Dataset Release 2 (OASST2)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \\nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \\nAll messages have a role property: this can either be \\\"assistant\\\" or \\\"prompter\\\". The roles in \\nconversation threads from prompt to leaf node strictly alternate between \\\"prompter\\\" andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"cmm-math","keyword":"chinese","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/ecnu-icalk/cmm-math","creator_name":"ICALK","creator_url":"https://huggingface.co/ecnu-icalk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCMM-Math\\n\\t\\n\\n\\nğŸ’» Github Repo\\nğŸ’» Paper Link\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nLarge language models (LLMs) have obtained promising results in mathematical reasoning, which is a foundational skill for human intelligence. Most previous studies focus on improving and measuring the performance of LLMs based on textual math reasoning datasets (e.g., MATH, GSM8K). Recently, a few researchers have released English multimodal math datasets (e.g., MATHVISTA and MATH-V) to evaluate theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ecnu-icalk/cmm-math.","first_N":5,"first_N_keywords":["Chinese","bsd-3-clause","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"OpenO1-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT","creator_name":"Open-Source O1","creator_url":"https://huggingface.co/O1-OPEN","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSFT Data for CoT Activation\\n\\t\\n\\nğŸ‰ğŸ‰ğŸ‰This repository contains the dataset used for fine-tuning a language model using SFT for Chain-of-Thought Activation. \\nğŸŒˆğŸŒˆğŸŒˆThe dataset is designed to enhance the model's ability to generate coherent and logical reasoning sequences. \\nâ˜„â˜„â˜„By using this dataset, the model can learn to produce detailed and structured reasoning steps, enhancing its performance on complex reasoning tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStatistics\\n\\t\\n\\n1ï¸âƒ£Total Records: 77,685â€¦ See the full description on the dataset page: https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"function-calling-small","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Deepexi/function-calling-small","creator_name":"Deepexi Inc","creator_url":"https://huggingface.co/Deepexi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†å†…å®¹è¯´æ˜:\\n\\t\\n\\nåŒ…å«700+ä¸ªé˜¿é‡Œäº‘OpenAPIçš„ä¿¡æ¯;åŒ…æ‹¬Dataworks,EMRï¼ŒDataLakeï¼ŒMaxcomputeï¼ŒHologram,å®æ—¶è®¡ç®—Flinkç‰ˆï¼ŒQuickBI,DTSç­‰å¤šä¸ªäº§å“çš„å…¬å¼€Open APIä¿¡æ¯ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ ·ä¾‹\\n\\t\\n\\n{\\n  \\\"systemPrompt\\\": ä½ æ˜¯ä¸€ä¸ªå‡½æ•°ç­›é€‰åŠ©ç†ï¼Œå¦‚æœä¸é—®é¢˜ç›¸å…³çš„è¯,æ‚¨å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„å‡½æ•°æ¥è·å–æ›´å¤šæ•°æ®ä»¥å›ç­”ç”¨æˆ·æå‡ºçš„é—®é¢˜:{\\\"function\\\": \\\"UpdateTicketNum\\\", \\\"description\\\": \\\"å¯¹ç”¨äºå…ç™»åµŒå…¥æŠ¥è¡¨çš„æŒ‡å®šçš„ticketè¿›è¡Œæ›´æ–°ç¥¨æ®æ•°é‡æ“ä½œã€‚\\\", \\\"arguments\\\": [{\\\"name\\\": \\\"Ticket\\\", \\\"type\\\": \\\"string\\\", \\\"description\\\": \\\"ä¸‰æ–¹åµŒå…¥çš„ç¥¨æ®å€¼ï¼Œå³URLä¸­çš„accessTicketå€¼ã€‚\\\"}, {\\\"name\\\": \\\"TicketNum\\\", \\\"type\\\": \\\"integer\\\", \\\"description\\\": \\\"ç¥¨æ®æ•°ã€‚\\\\n-â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Deepexi/function-calling-small.","first_N":5,"first_N_keywords":["feature-extraction","Chinese","cc-by-4.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"GSM8K_zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meta-math/GSM8K_zh","creator_name":"MetaMath","creator_url":"https://huggingface.co/meta-math","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\nGSM8K_zh is a dataset for mathematical reasoning in Chinese, question-answer pairs are translated from GSM8K (https://github.com/openai/grade-school-math/tree/master) by GPT-3.5-Turbo with few-shot prompting.\\nThe dataset consists of 7473 training samples and 1319 testing samples. The former is for supervised fine-tuning, while the latter is for evaluation.\\nfor training samples, question_zh and answer_zh are question and answer keys, respectively;\\nfor testing samplesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/meta-math/GSM8K_zh.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"SLAKE","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BoKelvin/SLAKE","creator_name":"Kelvin Liu","creator_url":"https://huggingface.co/BoKelvin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Info:\\n\\t\\n\\nSLAKE: A Semantically-Labeled Knowledge-Enhanced Dataset for Medical Visual Question Answering [ISBI 2021 oral]\\nProject Page: click\\nCorresponding Authors: Bo Liu, Xiao-Ming Wu\\nAny questions, please contact us. Thank you!\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModification:\\n\\t\\n\\nIn the Huggingface Repo, we have changed the name of validate.json to validation.json to better display in the Dataset Card.\\n","first_N":5,"first_N_keywords":["visual-question-answering","English","Chinese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"llava-med-zh-instruct-60k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BUAADreamer/llava-med-zh-instruct-60k","creator_name":"Zhangchi Feng","creator_url":"https://huggingface.co/BUAADreamer","description":"This Chinese dataset was translated from llava-med using Qwen1.5-14B-Chat and contains 60k medical visual instruction data points.\\nYou can organize content in the dataset_info.json in LLaMA Factory like this:\\n\\\"llava_med_zh_60k\\\": {\\n  \\\"hf_hub_url\\\": \\\"BUAADreamer/llava-med-zh-instruct-60k\\\",\\n  \\\"formatting\\\": \\\"sharegpt\\\",\\n  \\\"columns\\\": {\\n    \\\"messages\\\": \\\"messages\\\",\\n    \\\"images\\\": \\\"images\\\"\\n  },\\n  \\\"tags\\\": {\\n    \\\"role_tag\\\": \\\"role\\\",\\n    \\\"content_tag\\\": \\\"content\\\",\\n    \\\"user_tag\\\": \\\"user\\\",\\n    \\\"assistant_tag\\\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BUAADreamer/llava-med-zh-instruct-60k.","first_N":5,"first_N_keywords":["visual-question-answering","image-to-text","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"LLaVA-OneVision-Data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmms-lab/LLaVA-OneVision-Data","creator_name":"LMMs-Lab","creator_url":"https://huggingface.co/lmms-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LLaVA-OneVision\\n\\t\\n\\n[2024-09-01]: Uploaded VisualWebInstruct(filtered), it's used in OneVision Stage\\n\\nalmost all subsets are uploaded with HF's required format and you can use the recommended interface to download them and follow our code below to convert them. \\n\\n\\nthe subset of ureader_kg and ureader_qa are uploaded with the processed jsons and tar.gz of image folders.\\nYou may directly download them from the following url.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lmms-lab/LLaVA-OneVision-Data.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"ToolACE","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Team-ACE/ToolACE","creator_name":"Team-ACE","creator_url":"https://huggingface.co/Team-ACE","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tToolACE\\n\\t\\n\\nToolACE is an automatic agentic pipeline designed to generate Accurate, Complex, and divErse tool-learning data. \\nToolACE leverages a novel self-evolution synthesis process to curate a comprehensive API pool of 26,507 diverse APIs. \\nDialogs are further generated through the interplay among multiple agents, guided by a formalized thinking process. \\nTo ensure data accuracy, we implement a dual-layer verification system combining rule-based and model-based checks. \\nMoreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Team-ACE/ToolACE.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"chinese-fineweb-edu","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opencsg/chinese-fineweb-edu","creator_name":"opencsg","creator_url":"https://huggingface.co/opencsg","description":"\\n\\t\\n\\t\\t\\n\\t\\tWe recommend you to use the improved version Fineweb-edu-chinese-v2.1 !\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tChinese Fineweb Edu Dataset          [ä¸­æ–‡]    [English]\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n[OpenCSG Community]   [ğŸ‘¾github]  [wechat]  [Twitter] \\n\\n\\n\\n\\nğŸ“–Technical Report\\nChinese Fineweb Edu dataset is a meticulously constructed high-quality Chinese pre-training corpus, specifically designed for natural language processing tasks in the education domain. This dataset undergoes a rigorous selection and deduplication process, using aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/opencsg/chinese-fineweb-edu.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU ğŸŒ is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) ğŸ—½ or Culturally Agnostic (CA) âš–ï¸. These annotations were collected as part of an openâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU.","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"MMathCoT-1M","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/URSA-MATH/MMathCoT-1M","creator_name":"URSA-MATH","creator_url":"https://huggingface.co/URSA-MATH","description":"\\n\\t\\n\\t\\t\\n\\t\\tMMathCoT-1M\\n\\t\\n\\nThis repository contains the data presented in URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics.\\nCode: https://github.com/URSA-MATH/URSA-MATH\\nImage data can be downloaded from the following address:\\n\\nMAVIS: https://github.com/ZrrSkywalker/MAVIS, https://drive.google.com/drive/folders/1LGd2JCVHi1Y6IQ7l-5erZ4QRGC4L7Nol.\\nMultimath: https://huggingface.co/datasets/pengshuai-rin/multimath-300k.\\nGeo170k:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/URSA-MATH/MMathCoT-1M.","first_N":5,"first_N_keywords":["image-text-to-text","English","Chinese","gpl-3.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"ShrimpMoss_Chinese_Censorship_Abliteration","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Nafnlaus/ShrimpMoss_Chinese_Censorship_Abliteration","creator_name":"Karen RÃ³bertsdÃ³ttir","creator_url":"https://huggingface.co/Nafnlaus","description":"\\nShrimpMoss (è™¾è‹”) is a dataset designed for the abliteration (https://github.com/FailSpy/abliterator) of Chinese government-imposed censorship and/or propaganda from large language models developed in the PRC. It consists of a series of files of prompts (in .txt, .json, and .parquet format) in two groupings:\\n\\nchina_bad_*: Contains a series of prompts likely to trigger censorship or propaganda actions in the model.\\nchina_good_*: Contains a series of prompts in the same general category of topicsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nafnlaus/ShrimpMoss_Chinese_Censorship_Abliteration.","first_N":5,"first_N_keywords":["English","Chinese","mit","1K<n<10K","Text"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\tlightblue/reasoning-multilingual-R1-Llama-70B-train\\n\\t\\n\\nThis is a multilingual reasoning dataset covering more than 30 languages.\\nThis dataset was made by:\\n\\nSampling prompts from English datasets and translating them to various languages\\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\\n\\nThis dataset was then used to train a multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tWMT24++\\n\\t\\n\\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\\nthe publication\\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\\nIf you are interested in the images of the source URLs for each document, please see here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema\\n\\t\\n\\nEach language pair is stored in its own jsonl file.\\nEach row isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"dark_thoughts_casestudies_en_cn","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DataTonic/dark_thoughts_casestudies_en_cn","creator_name":"Data Tonic (Alignment Lab)","creator_url":"https://huggingface.co/DataTonic","description":"\\n\\t\\n\\t\\t\\n\\t\\tDark Thoughts Case Studies Dataset (English-Chinese)\\n\\t\\n\\nThis dataset contains a bilingual collection of case studies with detailed stakeholder analyses in English and Chinese. Each case study includes structured information about stakeholders and their motivations, along with comprehensive case analysis and solutions.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe dataset consists of 344,580 paired case studies in English and Chinese, with detailed stakeholder analyses andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DataTonic/dark_thoughts_casestudies_en_cn.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"EgoLife","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lmms-lab/EgoLife","creator_name":"LMMs-Lab","creator_url":"https://huggingface.co/lmms-lab","description":"Data cleaning, stay tuned! Please refer to https://egolife-ai.github.io/ first for general info.\\nCheckout the paper EgoLife (https://arxiv.org/abs/2503.03803) for more information.\\nCode: https://github.com/egolife-ai/EgoLife\\n","first_N":5,"first_N_keywords":["video-text-to-text","Chinese","mit","10K - 100K","Video"],"keywords_longer_than_N":true},
	{"name":"thinking-multilingual-30-23-small-690","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \\nOr use the \\\"big\\\" version: big 10k rows version\\n","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"ComMT","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NiuTrans/ComMT","creator_name":"NiuTrans","creator_url":"https://huggingface.co/NiuTrans","description":"\\n\\t\\n\\t\\t\\n\\t\\tComMT\\n\\t\\n\\n\\nGithub: https://github.com/NiuTrans/LaMaTE/\\nPaper: https://arxiv.org/abs/2503.06594\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nComMT is a comprehensive dataset suite designed to support the development and evaluation of universal translation models. \\nIt includes diverse translation-related tasks, providing a well-curated data resource for training and testing LLM-based machine translation systems.\\nThe dataset is meticulously curated from over 60+ publicly available data sources. \\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NiuTrans/ComMT.","first_N":5,"first_N_keywords":["translation","text-generation","English","Chinese","German"],"keywords_longer_than_N":true},
	{"name":"Ling-Coder-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inclusionAI/Ling-Coder-SFT","creator_name":"inclusionAI","creator_url":"https://huggingface.co/inclusionAI","description":"\\n    \\n\\n\\n\\n          ğŸ¤— Hugging Face\\n          ğŸ¤– ModelScope\\n          ğŸ–¥ï¸ GitHub\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLing-Coder Dataset\\n\\t\\n\\nThe Ling-Coder Dataset comprises the following components:\\n\\nLing-Coder-SFT: A subset of SFT data used for training Ling-Coder Lite, containing more than 5 million samples.\\nLing-Coder-DPO: A subset of DPO data used for training Ling-Coder Lite, containing 250k samples.\\nLing-Coder-SyntheticQA: A subset of synthetic data used for annealing training of Ling-Coder Lite, containing moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/inclusionAI/Ling-Coder-SFT.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Ling-Coder-SyntheticQA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inclusionAI/Ling-Coder-SyntheticQA","creator_name":"inclusionAI","creator_url":"https://huggingface.co/inclusionAI","description":"\\n    \\n\\n\\n\\n\\n          ğŸ¤— Hugging Face\\n          ğŸ¤– ModelScope\\n          ğŸ–¥ï¸ GitHub\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLing-Coder Dataset\\n\\t\\n\\nThe Ling-Coder Dataset comprises the following components:\\n\\nLing-Coder-SFT: A subset of SFT data used for training Ling-Coder Lite, containing more than 5 million samples.\\nLing-Coder-DPO: A subset of DPO data used for training Ling-Coder Lite, containing 250k samples.\\nLing-Coder-SyntheticQA: A subset of synthetic data used for annealing training of Ling-Coder Lite, containing moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/inclusionAI/Ling-Coder-SyntheticQA.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"cmrc2018","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hfl/cmrc2018","creator_name":"Joint Laboratory of HIT and iFLYTEK Research (HFL)","creator_url":"https://huggingface.co/hfl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"cmrc2018\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA Span-Extraction dataset for Chinese machine reading comprehension to add language\\ndiversities in this area. The dataset is composed by near 20,000 real questions annotated\\non Wikipedia paragraphs by human experts. We also annotated a challenge set which\\ncontains the questions that need comprehensive understanding and multi-sentence\\ninference throughout the context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMoreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hfl/cmrc2018.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"conceptnet5","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/conceptnet5/conceptnet5","creator_name":"conceptnet5","creator_url":"https://huggingface.co/conceptnet5","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Conceptnet5\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nConceptNet is a multilingual knowledge base, representing words and\\nphrases that people use and the common-sense relationships between\\nthem. The knowledge in ConceptNet is collected from a variety of\\nresources, including crowd-sourced resources (such as Wiktionary and\\nOpen Mind Common Sense), games with a purpose (such as Verbosity and\\nnadya.jp), and expert-created resources (such as WordNet and JMDict).\\nYou can browseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/conceptnet5/conceptnet5.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"xquad","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xquad","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xquad\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nXQuAD (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering\\nperformance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set\\nof SQuAD v1.1 (Rajpurkar et al., 2016) together with their professional translations into ten languages: Spanish, German,\\nGreek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/xquad.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xtreme\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"ASCEND","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CAiRE/ASCEND","creator_name":"CAiRE HKUST","creator_url":"https://huggingface.co/CAiRE","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ASCEND\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nASCEND (A Spontaneous Chinese-English Dataset) introduces a high-quality resource of spontaneous multi-turn conversational dialogue Chinese-English code-switching corpus collected in Hong Kong. ASCEND consists of 10.62 hours of spontaneous speech with a total of ~12.3K utterances. The corpus is split into 3 sets: training, validation, and test with a ratio of 8:1:1 while maintaining a balanced gender proportion on each set.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CAiRE/ASCEND.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"mqa","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"nli_zh","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/nli_zh","creator_name":"Ming Xu (å¾æ˜)","creator_url":"https://huggingface.co/shibing624","description":"çº¯æ–‡æœ¬æ•°æ®ï¼Œæ ¼å¼ï¼šï¼ˆsentence1ï¼Œ sentence2ï¼Œ labelï¼‰ã€‚å¸¸è§ä¸­æ–‡è¯­ä¹‰åŒ¹é…æ•°æ®é›†ï¼ŒåŒ…å«ATECã€BQã€LCQMCã€PAWSXã€STS-Bå…±5ä¸ªä»»åŠ¡ã€‚","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","semantic-similarity-scoring","text-scoring","shibing624"],"keywords_longer_than_N":true},
	{"name":"nlpcc-stance","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strombergnlp/nlpcc-stance","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","description":"This is a stance prediction dataset in Chinese.\\nThe data is that from a shared task, stance detection in Chinese microblogs, in NLPCC-ICCPOL 2016. It covers Task A, a mandatory supervised task which detects stance towards five targets of interest with given labeled data.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"xwinograd","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xwinograd","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["English","French","Japanese","Portuguese","Russian"],"keywords_longer_than_N":true},
	{"name":"multilingual-sentiments","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tyqiangz/multilingual-sentiments","creator_name":"Tay Yong Qiang","creator_url":"https://huggingface.co/tyqiangz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Sentiments Dataset\\n\\t\\n\\nA collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.\\nMost multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-classification","monolingual","multilingual"],"keywords_longer_than_N":true},
	{"name":"laion2B-multi-chinese-subset","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IDEA-CCNL/laion2B-multi-chinese-subset","creator_name":"Fengshenbang-LM","creator_url":"https://huggingface.co/IDEA-CCNL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlaion2B-multi-chinese-subset\\n\\t\\n\\n\\nGithub: Fengshenbang-LM\\nDocs: Fengshenbang-Docs\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç®€ä»‹ Brief Introduction\\n\\t\\n\\nå–è‡ªLaion2Bå¤šè¯­è¨€å¤šæ¨¡æ€æ•°æ®é›†ä¸­çš„ä¸­æ–‡éƒ¨åˆ†ï¼Œä¸€å…±143Mä¸ªå›¾æ–‡å¯¹ã€‚\\nA subset from Laion2B (a multimodal dataset), around 143M image-text pairs (only Chinese).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ä¿¡æ¯ Dataset Information\\n\\t\\n\\nå¤§çº¦ä¸€å…±143Mä¸ªä¸­æ–‡å›¾æ–‡å¯¹ã€‚å¤§çº¦å ç”¨19GBç©ºé—´ï¼ˆä»…ä»…æ˜¯urlç­‰æ–‡æœ¬ä¿¡æ¯ï¼Œä¸åŒ…å«å›¾ç‰‡ï¼‰ã€‚\\n\\nHomepage: laion-5b\\nHuggingface: laion/laion2B-multi\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä¸‹è½½ Download\\n\\t\\n\\nmkdir laion2b_chinese_release && cd laion2b_chinese_release\\nfor i inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IDEA-CCNL/laion2B-multi-chinese-subset.","first_N":5,"first_N_keywords":["feature-extraction","crowdsourced","crowdsourced","monolingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"paramed","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/paramed","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"NEJM is a Chinese-English parallel corpus crawled from the New England Journal of Medicine website. \\nEnglish articles are distributed through https://www.nejm.org/ and Chinese articles are distributed through \\nhttp://nejmqianyan.cn/. The corpus contains all article pairs (around 2000 pairs) since 2011.","first_N":5,"first_N_keywords":["multilingual","English","Chinese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"laion-high-resolution-chinese","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanng/laion-high-resolution-chinese","creator_name":"wangjunjie","creator_url":"https://huggingface.co/wanng","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlaion-high-resolution-chinese\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç®€ä»‹ Brief Introduction\\n\\t\\n\\nå–è‡ªLaion5B-high-resolutionå¤šè¯­è¨€å¤šæ¨¡æ€æ•°æ®é›†ä¸­çš„ä¸­æ–‡éƒ¨åˆ†ï¼Œä¸€å…±2.66Mä¸ªå›¾æ–‡å¯¹ã€‚\\nA subset from Laion5B-high-resolution (a multimodal dataset), around 2.66M image-text pairs (only Chinese).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ä¿¡æ¯ Dataset Information\\n\\t\\n\\nå¤§çº¦ä¸€å…±2.66Mä¸ªä¸­æ–‡å›¾æ–‡å¯¹ã€‚å¤§çº¦å ç”¨381MBç©ºé—´ï¼ˆä»…ä»…æ˜¯urlç­‰æ–‡æœ¬ä¿¡æ¯ï¼Œä¸åŒ…å«å›¾ç‰‡ï¼‰ã€‚\\n\\nHomepage: laion-5b\\nHuggingface: laion/laion-high-resolution\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä¸‹è½½ Download\\n\\t\\n\\nmkdir release && cd release\\nfor i in {00000..00015}; do wgetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wanng/laion-high-resolution-chinese.","first_N":5,"first_N_keywords":["feature-extraction","crowdsourced","crowdsourced","monolingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"jd21","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuroneko5943/jd21","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","found","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"weibo16","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuroneko5943/weibo16","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","machine-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"HC3","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hello-SimpleAI/HC3","creator_name":"Hello-SimpleAI","creator_url":"https://huggingface.co/Hello-SimpleAI","description":"Human ChatGPT Comparison Corpus (HC3)","first_N":5,"first_N_keywords":["text-classification","question-answering","sentence-similarity","zero-shot-classification","English"],"keywords_longer_than_N":true},
	{"name":"HC3-Chinese","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese","creator_name":"Hello-SimpleAI","creator_url":"https://huggingface.co/Hello-SimpleAI","description":"Human ChatGPT Comparison Corpus (HC3) Chinese Version","first_N":5,"first_N_keywords":["text-classification","question-answering","sentence-similarity","zero-shot-classification","English"],"keywords_longer_than_N":true},
	{"name":"wmt-da-human-evaluation","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation","creator_name":"Ricardo Costa Dias Rei","creator_url":"https://huggingface.co/RicardoRei","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains all DA human annotations from previous WMT News Translation shared tasks.\\nThe data is organised into 8 columns:\\n\\nlp: language pair\\nsrc: input text\\nmt: translation\\nref: reference translation\\nscore: z score\\nraw: direct assessment\\nannotators: number of annotators\\ndomain: domain of the input text (e.g. news)\\nyear: collection year\\n\\nYou can also find the original data for each year in the results sectionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation.","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Estonian"],"keywords_longer_than_N":true},
	{"name":"pclue","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wbbbbb/pclue","creator_name":"wb","creator_url":"https://huggingface.co/wbbbbb","description":"https://github.com/CLUEbenchmark/pCLUE","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1M - 10M","Text"],"keywords_longer_than_N":true},
	{"name":"multiconer_v2","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MultiCoNER/multiconer_v2","creator_name":"MultiCoNER","creator_url":"https://huggingface.co/MultiCoNER","description":"Complex named entities (NE), like the titles of creative works, are not simple nouns and pose challenges for NER systems (Ashwini and Choi, 2014). They can take the form of any linguistic constituent, like an imperative clause (â€œDial M for Murderâ€), and do not look like traditional NEs (Persons, Locations, etc.). This syntactic ambiguity makes it challenging to recognize them based on context. We organized the MultiCoNER task (Malmasi et al., 2022) at SemEval-2022 to address these challenges in 11 languages, receiving a very positive community response with 34 system papers. Results confirmed the challenges of processing complex and long-tail NEs: even the largest pre-trained Transformers did not achieve top performance without external knowledge. The top systems infused transformers with knowledge bases and gazetteers. However, such solutions are brittle against out of knowledge-base entities and noisy scenarios like the presence of spelling mistakes and typos. We propose MultiCoNER II which represents novel challenges through new tasks that emphasize the shortcomings of the current top models.\\n\\nMultiCoNER II features complex NER in these languages:\\n\\n1. English\\n2. Spanish\\n3. Hindi\\n4. Bangla\\n5. Chinese\\n6. Swedish\\n7. Farsi\\n8. French\\n9. Italian\\n10. Portugese\\n11. Ukranian\\n12. German\\n\\nFor more details see https://multiconer.github.io/\\n\\n## References\\n* Sandeep Ashwini and Jinho D. Choi. 2014. Targetable named entity recognition in social media. CoRR, abs/1408.0782.\\n* Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta Kar, Oleg Rokhlenko. 2022. SemEval-2022 Task 11: Multilingual Complex Named Entity Recognition (MultiCoNER).","first_N":5,"first_N_keywords":["token-classification","Bengali","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"csl","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neuclir/csl","creator_name":"NeuCLIR TREC Track","creator_url":"https://huggingface.co/neuclir","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CSL\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCSL is the Chinese Scientific Literature Dataset.\\n\\nPaper: https://aclanthology.org/2022.coling-1.344\\nRepository: https://github.com/ydli-ai/CSL\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset contains titles, abstracts, keywords of papers written in Chinese from several academic fields.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nChinese\\nEnglish (translation)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nSplit\\nDocumentsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/neuclir/csl.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","no-annotation","extended|csl","Chinese"],"keywords_longer_than_N":true},
	{"name":"Alpaca-CoT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QingyiSi/Alpaca-CoT","creator_name":"Qingyi Si","creator_url":"https://huggingface.co/QingyiSi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInstruction-Finetuning Dataset Collection (Alpaca-CoT)\\n\\t\\n\\nThis repository will continuously collect various instruction tuning datasets. And we standardize different datasets into the same format, which can be directly loaded by the code of Alpaca model.\\nWe also have conducted empirical study on various instruction-tuning datasets based on the Alpaca model, as shown in https://github.com/PhoebusSi/alpaca-CoT.  \\nIf you think this dataset collection is helpful to you, please likeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QingyiSi/Alpaca-CoT.","first_N":5,"first_N_keywords":["English","Chinese","Malayalam","apache-2.0","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"AdvertiseGen","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/AdvertiseGen","creator_name":"Ming Xu (å¾æ˜)","creator_url":"https://huggingface.co/shibing624","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AdvertiseGen\\n\\t\\n\\n\\nformal url: https://www.luge.ai/#/luge/dataDetail?id=9\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\næ•°æ®é›†ä»‹ç»\\nAdvertiseGenæ˜¯ç”µå•†å¹¿å‘Šæ–‡æ¡ˆç”Ÿæˆæ•°æ®é›†ã€‚\\nAdvertiseGenä»¥å•†å“ç½‘é¡µçš„æ ‡ç­¾ä¸æ–‡æ¡ˆçš„ä¿¡æ¯å¯¹åº”å…³ç³»ä¸ºåŸºç¡€æ„é€ ï¼Œæ˜¯å…¸å‹çš„å¼€æ”¾å¼ç”Ÿæˆä»»åŠ¡ï¼Œåœ¨æ¨¡å‹åŸºäºkey-valueè¾“å…¥ç”Ÿæˆå¼€æ”¾å¼æ–‡æ¡ˆæ—¶ï¼Œä¸è¾“å…¥ä¿¡æ¯çš„äº‹å®ä¸€è‡´æ€§éœ€è¦å¾—åˆ°é‡ç‚¹å…³æ³¨ã€‚\\n\\nä»»åŠ¡æè¿°ï¼šç»™å®šå•†å“ä¿¡æ¯çš„å…³é”®è¯å’Œå±æ€§åˆ—è¡¨kv-listï¼Œç”Ÿæˆé€‚åˆè¯¥å•†å“çš„å¹¿å‘Šæ–‡æ¡ˆadvï¼›\\næ•°æ®è§„æ¨¡ï¼šè®­ç»ƒé›†114kï¼ŒéªŒè¯é›†1kï¼Œæµ‹è¯•é›†3kï¼›\\næ•°æ®æ¥æºï¼šæ¸…åå¤§å­¦CoAIå°ç»„ï¼›\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset designed for generate e-commerce advertise.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe data inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shibing624/AdvertiseGen.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"CSC","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/CSC","creator_name":"Ming Xu (å¾æ˜)","creator_url":"https://huggingface.co/shibing624","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CSC\\n\\t\\n\\nä¸­æ–‡æ‹¼å†™çº é”™æ•°æ®é›†\\n\\nRepository: https://github.com/shibing624/pycorrector\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nChinese Spelling Correction (CSC) is a task to detect and correct misspelled characters in Chinese texts. \\nCSC is challenging since many Chinese characters are visually or phonologically similar but with quite different semantic meanings.\\nä¸­æ–‡æ‹¼å†™çº é”™æ•°æ®é›†ï¼Œå…±27ä¸‡æ¡ï¼Œæ˜¯é€šè¿‡åŸå§‹SIGHAN13ã€14ã€15å¹´æ•°æ®é›†å’ŒWang271kæ•°æ®é›†åˆå¹¶æ•´ç†åå¾—åˆ°ï¼Œjsonæ ¼å¼ï¼Œå¸¦é”™è¯¯å­—ç¬¦ä½ç½®ä¿¡æ¯ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOriginal Dataset Summaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shibing624/CSC.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"guanaco_belle_merge_v1.0","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Chinese-Vicuna/guanaco_belle_merge_v1.0","creator_name":"Chinese-Vicuna","creator_url":"https://huggingface.co/Chinese-Vicuna","description":"Thanks for Guanaco Dataset and Belle Dataset\\nThis dataset was created by merging the above two datasets in a certain format so that they can be used for training our code Chinese-Vicuna\\n","first_N":5,"first_N_keywords":["Chinese","English","Japanese","gpl-3.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"train_1M_CN","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BelleGroup/train_1M_CN","creator_name":"BELLE Group // Be Everyone's Large Language model Engine","creator_url":"https://huggingface.co/BelleGroup","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå†…å®¹\\n\\t\\n\\nåŒ…å«çº¦100ä¸‡æ¡ç”±BELLEé¡¹ç›®ç”Ÿæˆçš„ä¸­æ–‡æŒ‡ä»¤æ•°æ®ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ ·ä¾‹\\n\\t\\n\\n{\\n  \\\"instruction\\\": \\\"ç»™å®šä¸€ä¸ªæ–‡å­—è¾“å…¥ï¼Œå°†å…¶ä¸­çš„æ‰€æœ‰æ•°å­—åŠ 1ã€‚\\\\nâ€œæ˜å¤©çš„ä¼šè®®åœ¨9ç‚¹å¼€å§‹ï¼Œè®°å¾—å‡†æ—¶åˆ°è¾¾ã€‚â€\\\\n\\\",\\n  \\\"input\\\": \\\",\\n  \\\"output\\\": \\\"â€œæ˜å¤©çš„ä¼šè®®åœ¨10ç‚¹å¼€å§‹ï¼Œè®°å¾—å‡†æ—¶åˆ°è¾¾ã€‚â€\\\"\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå­—æ®µï¼š\\n\\t\\n\\ninstruction: æŒ‡ä»¤\\ninput: è¾“å…¥ï¼ˆæœ¬æ•°æ®é›†å‡ä¸ºç©ºï¼‰\\noutput: è¾“å‡º\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä½¿ç”¨é™åˆ¶\\n\\t\\n\\nä»…å…è®¸å°†æ­¤æ•°æ®é›†åŠä½¿ç”¨æ­¤æ•°æ®é›†ç”Ÿæˆçš„è¡ç”Ÿç‰©ç”¨äºç ”ç©¶ç›®çš„ï¼Œä¸å¾—ç”¨äºå•†ä¸šï¼Œä»¥åŠå…¶ä»–ä¼šå¯¹ç¤¾ä¼šå¸¦æ¥å±å®³çš„ç”¨é€”ã€‚\\næœ¬æ•°æ®é›†ä¸ä»£è¡¨ä»»ä½•ä¸€æ–¹çš„ç«‹åœºã€åˆ©ç›Šæˆ–æƒ³æ³•ï¼Œæ— å…³ä»»ä½•å›¢ä½“çš„ä»»ä½•ç±»å‹çš„ä¸»å¼ ã€‚å› ä½¿ç”¨æœ¬æ•°æ®é›†å¸¦æ¥çš„ä»»ä½•æŸå®³ã€çº çº·ï¼Œæœ¬é¡¹ç›®ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚\\n","first_N":5,"first_N_keywords":["text2text-generation","Chinese","gpl-3.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"train_0.5M_CN","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BelleGroup/train_0.5M_CN","creator_name":"BELLE Group // Be Everyone's Large Language model Engine","creator_url":"https://huggingface.co/BelleGroup","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå†…å®¹\\n\\t\\n\\nåŒ…å«çº¦50ä¸‡æ¡ç”±BELLEé¡¹ç›®ç”Ÿæˆçš„ä¸­æ–‡æŒ‡ä»¤æ•°æ®ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ ·ä¾‹\\n\\t\\n\\n{\\n  \\\"instruction\\\": \\\"ç»™å®šä¸€ä¸ªæ–‡å­—è¾“å…¥ï¼Œå°†å…¶ä¸­çš„æ‰€æœ‰æ•°å­—åŠ 1ã€‚\\\\nâ€œæ˜å¤©çš„ä¼šè®®åœ¨9ç‚¹å¼€å§‹ï¼Œè®°å¾—å‡†æ—¶åˆ°è¾¾ã€‚â€\\\\n\\\",\\n  \\\"input\\\": \\\",\\n  \\\"output\\\": \\\"â€œæ˜å¤©çš„ä¼šè®®åœ¨10ç‚¹å¼€å§‹ï¼Œè®°å¾—å‡†æ—¶åˆ°è¾¾ã€‚â€\\\"\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå­—æ®µï¼š\\n\\t\\n\\ninstruction: æŒ‡ä»¤\\ninput: è¾“å…¥ï¼ˆæœ¬æ•°æ®é›†å‡ä¸ºç©ºï¼‰\\noutput: è¾“å‡º\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä½¿ç”¨é™åˆ¶\\n\\t\\n\\nä»…å…è®¸å°†æ­¤æ•°æ®é›†åŠä½¿ç”¨æ­¤æ•°æ®é›†ç”Ÿæˆçš„è¡ç”Ÿç‰©ç”¨äºç ”ç©¶ç›®çš„ï¼Œä¸å¾—ç”¨äºå•†ä¸šï¼Œä»¥åŠå…¶ä»–ä¼šå¯¹ç¤¾ä¼šå¸¦æ¥å±å®³çš„ç”¨é€”ã€‚\\næœ¬æ•°æ®é›†ä¸ä»£è¡¨ä»»ä½•ä¸€æ–¹çš„ç«‹åœºã€åˆ©ç›Šæˆ–æƒ³æ³•ï¼Œæ— å…³ä»»ä½•å›¢ä½“çš„ä»»ä½•ç±»å‹çš„ä¸»å¼ ã€‚å› ä½¿ç”¨æœ¬æ•°æ®é›†å¸¦æ¥çš„ä»»ä½•æŸå®³ã€çº çº·ï¼Œæœ¬é¡¹ç›®ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚\\n","first_N":5,"first_N_keywords":["text2text-generation","Chinese","gpl-3.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"couplet","keyword":"chinese","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wb14123/couplet","creator_name":"bw","creator_url":"https://huggingface.co/wb14123","description":"å¯¹è”æ•°æ®é›†ã€‚æ•°æ®æ¥æºï¼š å†¯é‡æœ´_æ¢¨å‘³æ–‹æ•£å¶_çš„åšå®¢ã€‚\\nçˆ¬è™«ä»£ç åœ¨ Githubã€‚\\n","first_N":5,"first_N_keywords":["text2text-generation","question-answering","Chinese","agpl-3.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"school_math_0.25M","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BelleGroup/school_math_0.25M","creator_name":"BELLE Group // Be Everyone's Large Language model Engine","creator_url":"https://huggingface.co/BelleGroup","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchool Math 0.25M\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå†…å®¹\\n\\t\\n\\nåŒ…å«çº¦25ä¸‡æ¡ç”±BELLEé¡¹ç›®ç”Ÿæˆçš„ä¸­æ–‡æ•°å­¦é¢˜æ•°æ®ï¼ŒåŒ…å«è§£é¢˜è¿‡ç¨‹ã€‚\\næ³¨æ„ï¼šæ­¤æ•°æ®é›†æ˜¯ç”±ChatGPTäº§ç”Ÿçš„ï¼Œæœªç»è¿‡ä¸¥æ ¼æ ¡éªŒï¼Œé¢˜ç›®æˆ–è§£é¢˜è¿‡ç¨‹å¯èƒ½åŒ…å«é”™è¯¯ã€‚ä½¿ç”¨è¿‡ç¨‹ä¸­è¯·æ³¨æ„è¿™ä¸€ç‚¹ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ ·ä¾‹\\n\\t\\n\\n{\\n  \\\"instruction\\\": \\\"é¢˜ç›®ï¼šå°åæ‰‹é‡Œæœ‰ä¸€ä¸ªè£…æ»¡ç³–æœçš„è¢‹å­ï¼Œå…±æœ‰12ä¸ªï¼Œå°æ˜æƒ³çŸ¥é“é‡Œé¢æœ‰å¤šå°‘é¢—ç³–æœï¼Œäºæ˜¯ä»–é—®å°åï¼šâ€œä½ æ‰‹é‡Œçš„ç³–æœè¢‹å­é‡Œæœ‰å¶æ•°ä¸ªç³–æœå—ï¼Ÿâ€å°åå›ç­”ï¼šâ€œæœ‰ï¼Œè€Œä¸”å¤šäº10é¢—ã€‚â€è¯·é—®å°åæ‰‹é‡Œçš„ç³–æœè¢‹å­é‡Œæœ€å°‘æœ‰å‡ é¢—ç³–æœï¼Ÿ\\\",\\n  \\\"input\\\": \\\",\\n  \\\"output\\\": \\\"\\\\nç”±é¢˜ç›®å¯çŸ¥ï¼šå°åæ‰‹é‡Œçš„ç³–æœè¢‹å­é‡Œæœ‰å¶æ•°ä¸ªç³–æœï¼›\\\\nåˆçŸ¥é“å°åæ‰‹é‡Œçš„ç³–æœè¢‹å­é‡Œæœ‰å¤šäº10é¢—ç³–æœã€‚\\\\nå› ä¸ºç³–æœæ•°ä¸ºå¶æ•°ï¼Œå¤šäº10é¢—ï¼Œæ‰€ä»¥ç³–æœæ•°æœ€å°å¿…é¡»æ˜¯12ã€‚\\\\næ‰€ä»¥å°åæ‰‹é‡Œçš„ç³–æœè¢‹å­é‡Œæœ€å°‘æœ‰12é¢—ç³–æœã€‚\\\"\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå­—æ®µ\\n\\t\\n\\ninstruction: æŒ‡ä»¤\\ninput: è¾“å…¥ï¼ˆæœ¬æ•°æ®é›†å‡ä¸ºç©ºï¼‰\\noutput: è¾“å‡ºâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BelleGroup/school_math_0.25M.","first_N":5,"first_N_keywords":["text2text-generation","Chinese","gpl-3.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"alpaca-gpt4-data-zh","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-wizard/alpaca-gpt4-data-zh","creator_name":"Chris Alexiuk","creator_url":"https://huggingface.co/llm-wizard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"alpaca-gpt4-data-zh\\\"\\n\\t\\n\\nAll of the work is done by this team. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage and License Notices\\n\\t\\n\\nThe data is intended and licensed for research use only. The dataset is CC BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset should not be used outside of research purposes.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnglish Dataset\\n\\t\\n\\nFound here\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{peng2023gpt4llm,\\n    title={Instruction Tuning with GPT-4},\\n    author={Baolin Pengâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/llm-wizard/alpaca-gpt4-data-zh.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"train_2M_CN","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BelleGroup/train_2M_CN","creator_name":"BELLE Group // Be Everyone's Large Language model Engine","creator_url":"https://huggingface.co/BelleGroup","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå†…å®¹\\n\\t\\n\\nåŒ…å«çº¦200ä¸‡æ¡ç”±BELLEé¡¹ç›®ç”Ÿæˆçš„ä¸­æ–‡æŒ‡ä»¤æ•°æ®ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ ·ä¾‹\\n\\t\\n\\n{\\n  \\\"instruction\\\": \\\"å°†ä»¥ä¸‹ä¸‰ä¸ªå¥å­ç»„åˆæˆä¸€ä¸ªæœ‰æ„ä¹‰çš„æ®µè½ã€‚\\\\nç‹—æ˜¯äººç±»æœ€å¥½çš„æœ‹å‹ã€‚å®ƒä»¬éå¸¸èªæ˜ï¼Œå¯ä»¥è¿›è¡Œå„ç§æ´»åŠ¨ã€‚å¦‚æœä½ å–œæ¬¢æ•£æ­¥ï¼Œç‹—å¯ä»¥æˆä¸ºä½ ä¸€èµ·æ•£æ­¥çš„ä¼™ä¼´ã€‚\\\",\\n  \\\"input\\\": \\\",\\n  \\\"output\\\": \\\"ç‹—æ˜¯äººç±»æœ€å¥½çš„æœ‹å‹ï¼Œå®ƒä»¬éå¸¸èªæ˜ï¼Œå¯ä»¥è¿›è¡Œå„ç§æ´»åŠ¨ã€‚å¦‚æœä½ å–œæ¬¢æ•£æ­¥ï¼Œç‹—å¯ä»¥æˆä¸ºä½ ä¸€èµ·æ•£æ­¥çš„ä¼™ä¼´ã€‚å‡ºé—¨æ•£æ­¥æ˜¯ä¸€ç§è‰¯å¥½çš„é”»ç‚¼æ–¹å¼ï¼Œè€Œæœ‰ç‹—çš„é™ªä¼´ä¼šè®©æ•£æ­¥å˜å¾—æ›´æœ‰è¶£ï¼Œå¹¶ä¸”æœ‰ç‹—åœ¨èº«è¾¹ä¹Ÿèƒ½ç»™ä½ å¸¦æ¥å®‰å…¨æ„Ÿã€‚æ‰€ä»¥ï¼Œæ‹¥æœ‰ä¸€åªç‹—ä½œä¸ºä½ çš„ä¼™ä¼´ï¼Œå¯ä»¥å¸®åŠ©ä½ å˜å¾—æ›´åŠ ç§¯æä¸»åŠ¨å’Œå¥åº·ã€‚\\\"\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå­—æ®µï¼š\\n\\t\\n\\ninstruction: æŒ‡ä»¤\\ninput: è¾“å…¥ï¼ˆæœ¬æ•°æ®é›†å‡ä¸ºç©ºï¼‰\\noutput: è¾“å‡º\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä½¿ç”¨é™åˆ¶\\n\\t\\n\\nä»…å…è®¸å°†æ­¤æ•°æ®é›†åŠä½¿ç”¨æ­¤æ•°æ®é›†ç”Ÿæˆçš„è¡ç”Ÿç‰©ç”¨äºç ”ç©¶ç›®çš„ï¼Œä¸å¾—ç”¨äºå•†ä¸šï¼Œä»¥åŠå…¶ä»–ä¼šå¯¹ç¤¾ä¼šå¸¦æ¥å±å®³çš„ç”¨é€”ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BelleGroup/train_2M_CN.","first_N":5,"first_N_keywords":["text2text-generation","Chinese","gpl-3.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"ShareGPT-Chinese-English-90k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shareAI/ShareGPT-Chinese-English-90k","creator_name":"shareAI","creator_url":"https://huggingface.co/shareAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShareGPT-Chinese-English-90k Bilingual Human-Machine QA Dataset\\n\\t\\n\\nA high-quality Chinese-English parallel bilingual human-machine QA dataset, covering user questions in real and complex scenarios. It is used for training high-quality dialogue models (more robust in instruction distribution than those datasets generated by repeatedly calling API interfaces to simulate machine-generated Q&A, like Moss)\\nFeatures:\\n\\n\\nProvides fully semantically equivalent Chinese-English parallelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shareAI/ShareGPT-Chinese-English-90k.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"COIG","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/COIG","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"We propose the Chinese Open Instruction Generalist (COIG) project to maintain a harmless, helpful, and diverse set of Chinese instruction corpora. We welcome all researchers in the community to contribute to the corpus set and collaborate with us. We only release the first chip of COIG to help the Chinese LLMs' development in the exploration stage and appeal to more researchers joining us in building COIG. We introduce a manually verified translated general instruction corpus, a manually annotated exam instruction corpus, a human value alignment instruction corpus, a multi-round counterfactual correction chat corpus, and a leetcode instruction corpus. We provide these new instruction corpora to assist the community with instruction tuning on Chinese LLMs. These instruction corpora are also template workflows for how new Chinese instruction corpora can be built and expanded effectively.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"ChatMed_Consult_Dataset","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michaelwzhu/ChatMed_Consult_Dataset","creator_name":"Wei Zhu","creator_url":"https://huggingface.co/michaelwzhu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ChatMed\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nChatMed-Dataset is a dataset of 110,113 medical query-response pairs (in Chinese) generated by OpenAI's GPT-3.5 engine. The queries are crawled from several online medical consultation sites, reflecting the medical needs in the real world. The responses are generated by the OpenAI engine. This dataset is designated to to inject medical knowledge into Chinese large language models. \\nThe dataset size growing rapidly. Stayâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michaelwzhu/ChatMed_Consult_Dataset.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"moss-002-sft-data","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fnlp/moss-002-sft-data","creator_name":"OpenMOSS, Fudan NLP, SII","creator_url":"https://huggingface.co/fnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"moss-002-sft-data\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAn open-source conversational dataset that was used to train MOSS-002. The user prompts are extended based on a small set of human-written seed prompts in a way similar to Self-Instruct. The AI responses are generated using text-davinci-003. The user prompts of en_harmlessness are from Anthropic red teaming data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nname\\n# samples\\n\\n\\n\\t\\t\\nen_helpfulness.json\\n419049\\n\\n\\nen_honesty.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fnlp/moss-002-sft-data.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","cc-by-4.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"FinCUGE-Instruction","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Maciel/FinCUGE-Instruction","creator_name":"Maciel Young","creator_url":"https://huggingface.co/Maciel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\næœ¬æ•°æ®é›†åŒ…å«å…«é¡¹ä¸­æ–‡é‡‘èè‡ªç„¶è¯­è¨€å¤„ç†åŸºå‡†ä»»åŠ¡ï¼Œåˆ†åˆ«ä¸ºé‡‘èæ–°é—»æ‘˜è¦(FinNA)ã€é‡‘èæ–°é—»å…¬å‘Šäº‹ä»¶é—®ç­”(FinQA)ã€é‡‘èæ–°é—»åˆ†ç±»(FinNL)ã€é‡‘èæ–°é—»å…³ç³»æŠ½å–(FinRE)ã€é‡‘èç¤¾äº¤åª’ä½“æ–‡æœ¬æƒ…ç»ªåˆ†ç±»(FinNE)ã€é‡‘èè´Ÿé¢æ¶ˆæ¯åŠå…¶ä¸»ä½“åˆ¤å®š(FinNSP)ã€é‡‘èå› æœäº‹ä»¶æŠ½å–(FinCQA)ã€é‡‘èäº‹ä»¶ä¸»ä½“æŠ½å–(FinESE)ã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nï¼ˆ1ï¼‰FinNA\\né‡‘èæ–°é—»æ‘˜è¦æ•°æ®é›†ã€‚è¾“å…¥ä¸€æ®µé‡‘èæ–°é—»ï¼Œéœ€è¦æ¨¡å‹ç”Ÿæˆä¸€å¥è¯æ‘˜è¦ã€‚å…¶ä¸­è®­ç»ƒé›†åŒ…å«24000æ¡æ•°æ®ï¼ŒéªŒè¯é›†åŒ…å«3000æ¡æ•°æ®ã€‚\\n{\\n  \\\"instruction\\\": \\\"æ ¹æ®ä»¥ä¸‹æ–°é—»ç”Ÿæˆæ‘˜è¦ã€‚\\\",\\n  \\\"input\\\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Maciel/FinCUGE-Instruction.","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"WikiHowQA-mnbvc","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wanicca/WikiHowQA-mnbvc","creator_name":"wanicca","creator_url":"https://huggingface.co/wanicca","description":"ä»WikiHowé¡µé¢æŠ½å–çš„ä¸­æ–‡/è‹±æ–‡é—®ç­”æ•°æ®\\nç›¸å…³é¡¹ç›®: MNBVC\\næŠ½å–å·¥å…·ä»£ç ï¼šWikiHowQAExtractor\\n","first_N":5,"first_N_keywords":["question-answering","English","Chinese","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"huatuo_knowledge_graph_qa","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/huatuo_knowledge_graph_qa","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Huatuo_knowledge_graph_qa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWe built this QA dataset based on the medical knowledge map, with a total of 798,444 pieces of data, in which the questions are constructed by means of templates, and the answers are the contents of the entries in the knowledge map.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/huatuo_knowledge_graph_qa.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"chid","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thu-coai/chid","creator_name":"Conversational AI (CoAI) group from Tsinghua University","creator_url":"https://huggingface.co/thu-coai","description":"The ChID dataset. GitHub repo. Original paper.\\n@inproceedings{zheng-etal-2019-chid,\\n    title = \\\"{C}h{ID}: A Large-scale {C}hinese {ID}iom Dataset for Cloze Test\\\",\\n    author = \\\"Zheng, Chujie  and\\n      Huang, Minlie  and\\n      Sun, Aixin\\\",\\n    booktitle = \\\"ACL\\\",\\n    year = \\\"2019\\\"\\n}\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","text","Text"],"keywords_longer_than_N":true},
	{"name":"mgsm","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/juletxara/mgsm","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","description":"Multilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper [Language models are multilingual chain-of-thought reasoners](http://arxiv.org/abs/2210.03057).\\n\\nThe same 250 problems from [GSM8K](https://arxiv.org/abs/2110.14168) are each translated via human annotators in 10 languages. The 10 languages are:\\n- Spanish\\n- French\\n- German\\n- Russian\\n- Chinese\\n- Japanese\\n- Thai\\n- Swahili\\n- Bengali\\n- Telugu\\n\\nYou can find the input and targets for each of the ten languages (and English) as `.tsv` files.\\nWe also include few-shot exemplars that are also manually translated from each language in `exemplars.py`.","first_N":5,"first_N_keywords":["text2text-generation","found","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"train_3.5M_CN","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BelleGroup/train_3.5M_CN","creator_name":"BELLE Group // Be Everyone's Large Language model Engine","creator_url":"https://huggingface.co/BelleGroup","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå†…å®¹\\n\\t\\n\\nåŒ…å«çº¦350ä¸‡æ¡ç”±BELLEé¡¹ç›®ç”Ÿæˆçš„ä¸­æ–‡æŒ‡ä»¤æ•°æ®ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ ·ä¾‹\\n\\t\\n\\n{\\n    \\\"id\\\":\\\"66623028\\\",\\n    \\\"conversations\\\":[\\n        {\\n            \\\"from\\\":\\\"human\\\",\\n            \\\"value\\\":\\\"å½’çº³ä»‹ç»ä¸‰ç§ä¸åŒç±»å‹çš„ç”µå½±é¢˜æ\\\"\\n        },\\n        {\\n            \\\"from\\\":\\\"assistant\\\",\\n            \\\"value\\\":\\\"1. åŠ¨ä½œç‰‡ï¼šåŠ¨ä½œç‰‡é€šå¸¸å¼ºè°ƒåŠ¨ä½œå’Œæˆ˜æ–—åœºé¢ï¼Œæ•…äº‹æƒ…èŠ‚ç´§å‡‘ï¼Œå……æ»¡äº†ç´§å¼ å’Œå…´å¥‹çš„æ°›å›´ã€‚ä¸»è§’ä¸€èˆ¬æ˜¯å…·æœ‰è¶…å‡¡å®åŠ›æˆ–ç‰¹æ®ŠæŠ€èƒ½çš„è‹±é›„äººç‰©ï¼Œå¾€å¾€ä¼šä¸åæ´¾è§’è‰²è¿›è¡Œä¸€ç³»åˆ—æ¿€çƒˆçš„æ ¼æ–—ï¼Œè¿½é€å’Œçˆ†ç ´ç­‰é…·ç‚«åœºé¢ã€‚ä¾‹å¦‚ã€Šé€Ÿåº¦ä¸æ¿€æƒ…ã€‹å’Œã€Šå¤ä»‡è€…è”ç›Ÿã€‹ç­‰ã€‚\\\\n2. çˆ±æƒ…ç‰‡ï¼šçˆ±æƒ…ç‰‡æ˜¯ä»¥çˆ±æƒ…ä¸ºä¸»é¢˜çš„ç”µå½±ï¼Œç€é‡å‘ˆç°è§’è‰²ä¹‹é—´çš„æ„Ÿæƒ…çº è‘›ï¼Œå±•ç°äº†çˆ±æƒ…çš„ç¾å¥½å’Œæ‚²å£®ã€‚æƒ…èŠ‚ä¸è§’è‰²ä¹‹é—´çš„å‘å±•ä»¤äººæ·±æ€ï¼Œå¢åŠ äº†è§‚ä¼—çš„æ„Ÿæ€§ä½“éªŒã€‚è¿™ç§ç”µå½±çš„æ•…äº‹æƒ…èŠ‚ä¸»è¦ä»¥äººç±»ä¸äººç±»ä¹‹é—´çš„æƒ…æ„Ÿå˜åŒ–ä¸ºä¸»é¢˜ã€‚ä¾‹å¦‚ã€Šæ³°å¦å°¼å…‹å·ã€‹å’Œã€Šè®©å­å¼¹é£ã€‹ç­‰ã€‚\\\\n3.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BelleGroup/train_3.5M_CN.","first_N":5,"first_N_keywords":["text2text-generation","Chinese","gpl-3.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"huatuo_encyclopedia_qa","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/huatuo_encyclopedia_qa","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Huatuo_encyclopedia_qa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset has a total of 364,420 pieces of medical QA data, some of which have multiple questions in different ways. We extract medical QA pairs from plain texts (e.g., medical encyclopedias and medical articles). We collected 8,699 encyclopedia entries for diseases and 2,736 encyclopedia entries for medicines on Chinese Wikipedia. Moreover, we crawled 226,432 high-quality medical articles from the Qianwenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/huatuo_encyclopedia_qa.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"instruct_chat_50k.jsonl","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Chinese-Vicuna/instruct_chat_50k.jsonl","creator_name":"Chinese-Vicuna","creator_url":"https://huggingface.co/Chinese-Vicuna","description":"instruct_chat_50k.jsonl which is composed of 30k Chinese sharegpt dataset and 20k alpaca-instruction-Chinese-dataset\\n","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Wizard-LM-Chinese-instruct-evol","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/Wizard-LM-Chinese-instruct-evol","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"Wizard-LM-Chineseæ˜¯åœ¨MSRAçš„Wizard-LMæ•°æ®é›†ä¸Šï¼Œå¯¹æŒ‡ä»¤è¿›è¡Œç¿»è¯‘ï¼Œç„¶åå†è°ƒç”¨GPTè·å¾—ç­”æ¡ˆçš„æ•°æ®é›†\\nWizard-LMåŒ…å«äº†å¾ˆå¤šéš¾åº¦è¶…è¿‡Alpacaçš„æŒ‡ä»¤ã€‚\\nä¸­æ–‡çš„é—®é¢˜ç¿»è¯‘ä¼šæœ‰å°‘é‡æŒ‡ä»¤æ³¨å…¥å¯¼è‡´ç¿»è¯‘å¤±è´¥çš„æƒ…å†µ\\nä¸­æ–‡å›ç­”æ˜¯æ ¹æ®ä¸­æ–‡é—®é¢˜å†è¿›è¡Œé—®è¯¢å¾—åˆ°çš„ã€‚\\næˆ‘ä»¬ä¼šé™†ç»­å°†æ›´å¤šæ•°æ®é›†å‘å¸ƒåˆ°hfï¼ŒåŒ…æ‹¬\\n\\n Coco Captionçš„ä¸­æ–‡ç¿»è¯‘\\n CoQAçš„ä¸­æ–‡ç¿»è¯‘\\n CNewSumçš„Embeddingæ•°æ®\\n å¢å¹¿çš„å¼€æ”¾QAæ•°æ®\\n WizardLMçš„ä¸­æ–‡ç¿»è¯‘\\n\\nå¦‚æœä½ ä¹Ÿåœ¨åšè¿™äº›æ•°æ®é›†çš„ç­¹å¤‡ï¼Œæ¬¢è¿æ¥è”ç³»æˆ‘ä»¬ï¼Œé¿å…é‡å¤èŠ±é’±ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\téª†é©¼(Luotuo): å¼€æºä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹\\n\\t\\n\\nhttps://github.com/LC1332/Luotuo-Chinese-LLM\\néª†é©¼(Luotuo)é¡¹ç›®æ˜¯ç”±å†·å­æ˜‚ @ å•†æ±¤ç§‘æŠ€, é™ˆå¯æº @ åä¸­å¸ˆèŒƒå¤§å­¦ ä»¥åŠ æé²é² @ å•†æ±¤ç§‘æŠ€ å‘èµ·çš„ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹å¼€æºé¡¹ç›®ï¼ŒåŒ…å«äº†ä¸€ç³»åˆ—è¯­è¨€æ¨¡å‹ã€‚\\n( æ³¨æ„: é™ˆå¯æº æ­£åœ¨å¯»æ‰¾2024æ¨å…å¯¼å¸ˆï¼Œæ¬¢è¿è”ç³» )\\néª†é©¼é¡¹ç›®ä¸æ˜¯å•†æ±¤ç§‘æŠ€çš„å®˜æ–¹äº§å“ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/silk-road/Wizard-LM-Chinese-instruct-evol.","first_N":5,"first_N_keywords":["text-generation","question-answering","Chinese","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"MMC4-130k-chinese-image","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/MMC4-130k-chinese-image","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"MMC4-130k-chineseæ˜¯å¯¹MMC4ä¸­ï¼ŒæŠ½æ ·äº†130kå·¦å³ simliartyè¾ƒé«˜çš„å›¾æ–‡pairå¾—åˆ°çš„æ•°æ®é›†\\nChineseç‰ˆæœ¬æ˜¯å¯¹è¿™é‡Œæ‰€æœ‰çš„captionè¿›è¡Œäº†ç¿»è¯‘ã€‚\\næˆ‘ä»¬ä¼šé™†ç»­å°†æ›´å¤šæ•°æ®é›†å‘å¸ƒåˆ°hfï¼ŒåŒ…æ‹¬\\n\\n Coco Captionçš„ä¸­æ–‡ç¿»è¯‘\\n CoQAçš„ä¸­æ–‡ç¿»è¯‘\\n CNewSumçš„Embeddingæ•°æ®\\n å¢å¹¿çš„å¼€æ”¾QAæ•°æ®\\n WizardLMçš„ä¸­æ–‡ç¿»è¯‘\\n\\nå¦‚æœä½ ä¹Ÿåœ¨åšè¿™äº›æ•°æ®é›†çš„ç­¹å¤‡ï¼Œæ¬¢è¿æ¥è”ç³»æˆ‘ä»¬ï¼Œé¿å…é‡å¤èŠ±é’±ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\téª†é©¼(Luotuo): å¼€æºä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹\\n\\t\\n\\nhttps://github.com/LC1332/Luotuo-Chinese-LLM\\néª†é©¼(Luotuo)é¡¹ç›®æ˜¯ç”±å†·å­æ˜‚ @ å•†æ±¤ç§‘æŠ€, é™ˆå¯æº @ åä¸­å¸ˆèŒƒå¤§å­¦ ä»¥åŠ æé²é² @ å•†æ±¤ç§‘æŠ€ å‘èµ·çš„ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹å¼€æºé¡¹ç›®ï¼ŒåŒ…å«äº†ä¸€ç³»åˆ—è¯­è¨€æ¨¡å‹ã€‚\\n( æ³¨æ„: é™ˆå¯æº æ­£åœ¨å¯»æ‰¾2024æ¨å…å¯¼å¸ˆï¼Œæ¬¢è¿è”ç³» )\\néª†é©¼é¡¹ç›®ä¸æ˜¯å•†æ±¤ç§‘æŠ€çš„å®˜æ–¹äº§å“ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nPlease cite the repo if you use the data orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/silk-road/MMC4-130k-chinese-image.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","Chinese","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"huatuo26M-testdatasets","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/huatuo26M-testdatasets","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for huatuo26M-testdatasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWe are pleased to announce the release of our evaluation dataset, a subset of the Huatuo-26M. This dataset contains 6,000 entries that we used for Natural Language Generation (NLG) experimentation in our associated research paper.\\nWe encourage researchers and developers to use this evaluation dataset to gauge the performance of their own models. This is not only a chance to assess the accuracy and relevancyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/huatuo26M-testdatasets.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"genshin_ch_10npc","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xmj2002/genshin_ch_10npc","creator_name":"xmj","creator_url":"https://huggingface.co/xmj2002","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"genshin_ch_10npc\\\"\\n\\t\\n\\nMore Information needed\\n","first_N":5,"first_N_keywords":["text-to-speech","Chinese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"alpaca-data-gpt4-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/alpaca-data-gpt4-chinese","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"silk-road/alpaca-data-gpt4-chinese dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Chinese_modern_classical","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xmj2002/Chinese_modern_classical","creator_name":"xmj","creator_url":"https://huggingface.co/xmj2002","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Chinese_modern_classical\\\"\\n\\t\\n\\næ•°æ®æ¥è‡ªäºNiuTrans/Classical-Modern: éå¸¸å…¨çš„æ–‡è¨€æ–‡ï¼ˆå¤æ–‡ï¼‰-ç°ä»£æ–‡å¹³è¡Œè¯­æ–™ (github.com)ã€‚\\nç”±äºåŸå§‹æ•°æ®ä¸­éƒ¨åˆ†å¤æ–‡æ²¡æœ‰è¯‘æ–‡ï¼Œæ‰€ä»¥æœ¬æ•°æ®é›†çš„æ•°æ®ä»…åŒ…æ‹¬äº†åŒè¯­æ•°æ® ã€‚\\n","first_N":5,"first_N_keywords":["translation","Chinese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"tigerbot-riddle-qa-1k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/tigerbot-riddle-qa-1k","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"Tigerbot æœé›†æ•´ç†åŠ å·¥çš„ä¸­æ–‡-çŒœè°œè¯­sftæ•°æ®é›†\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/tigerbot-riddle-qa-1k')\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"tigerbot-law-plugin","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/tigerbot-law-plugin","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"Tigerbot æ¨¡å‹rethinkæ—¶ä½¿ç”¨çš„å¤–è„‘åŸå§‹æ•°æ®ï¼Œæ³•å¾‹11å¤§ç±»ï¼Œå…±5.5W+æ¡æ¬¾\\n\\nå®ªæ³•\\nåˆ‘æ³•\\nè¡Œæ”¿æ³•\\nå¸æ³•è§£é‡Š\\næ°‘æ³•å•†æ³•\\næ°‘æ³•å…¸\\nè¡Œæ”¿æ³•è§„\\nç¤¾ä¼šæ³•\\néƒ¨é—¨è§„ç« \\nç»æµæ³•\\nè¯‰è®¼ä¸éè¯‰è®¼ç¨‹åºæ³•\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/tigerbot-law-plugin')\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"nli-zh-all","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/nli-zh-all","creator_name":"Ming Xu (å¾æ˜)","creator_url":"https://huggingface.co/shibing624","description":"The SNLI corpus (version 1.0) is a merged chinese sentence similarity dataset, supporting the task of natural language\\ninference (NLI), also known as recognizing textual entailment (RTE).","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","semantic-similarity-scoring","text-scoring","shibing624"],"keywords_longer_than_N":true},
	{"name":"chinese_modern_poetry","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Iess/chinese_modern_poetry","creator_name":"ä¸ç…Œæµ©","creator_url":"https://huggingface.co/Iess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç®€ä»‹\\n\\t\\n\\n\\næ•°æ®é›†åŒ…æ‹¬äº†è¿‘ç°ä»£çš„ä¸­å›½è¯—äººåŠå¤–å›½è¯—äººï¼ˆä¸­è¯‘ç‰ˆï¼‰ä½œå“ï¼Œæ‰€æœ‰ä½œå“è‘—ä½œæƒå½’åŸä½œè€…æ‰€æœ‰ï¼Œä¾µåˆ è¯·è”ç³»aa531811820@gmail.com\\nchinese_poems.jsonlä¸ºåŸæ•°æ®ï¼Œtraining_imagery2-5_maxlen256.json åˆ†åˆ«æ˜¯æ ¹æ®2-5ä¸ªå…³é”®æ„è±¡ç”Ÿæˆè¯—æ­Œçš„ç›¸å…³æ•°æ®é›†\\næ•°æ®æ¥æºäºç½‘ç»œï¼ŒåŒ…æ‹¬ä½†ä¸é™äº\\n\\n\\nhttps://github.com/sheepzh/poetry\\nhttps://bedtimepoem.com/\\nhttps://poemwiki.org/\\nbaiduã€googleã€zhihuç­‰\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä¸€äº›ä½œå“\\n\\t\\n\\nä½¿ç”¨æ­¤æ•°æ®é›†è®­ç»ƒChatGLMã€LLaMA7bæ¨¡å‹ç”Ÿæˆçš„è¯—æ­Œï¼Œæ›´å¤šè¯—æ­ŒæŸ¥çœ‹poemsç›®å½•\\n\\n\\n\\n","first_N":5,"first_N_keywords":["Chinese","mit","100K - 1M","json","Image"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\\n\\n\\t\\n\\t\\t\\n\\nToxic\\nNeutral\\nTotal\\n\\n\\n\\t\\t\\nmultilingual-train-deduplicated.csvâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","first_N":5,"first_N_keywords":["text-classification","token-classification","zero-shot-classification","Arabic","Spanish"],"keywords_longer_than_N":true},
	{"name":"webnovel_cn","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zxbsmk/webnovel_cn","creator_name":"Jun","creator_url":"https://huggingface.co/zxbsmk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå†…å®¹\\n\\t\\n\\nåŒ…å«ä»12560æœ¬ç½‘æ–‡æå–çš„çº¦21.7Mæ¡å¯ç”¨äºè®­ç»ƒå°è¯´ç”Ÿæˆçš„ä¸­æ–‡æŒ‡ä»¤æ•°æ®(novel_json_tokens512.zip)ã€‚ä¸‹è½½é“¾æ¥ï¼šhttps://pan.baidu.com/s/1TorBMbrqxrn6odRF0PJBVw \\næå–ç ï¼šjlh3\\nä»¥åŠä»ä¸­æå–å‡ºçš„åŒ…å«50kæ¡æ•°æ®çš„å­é›†(novel_cn_token512_50k.json)ã€‚å…¶ä¸­è¾“å…¥å’Œè¾“å‡ºéƒ½ä¸å¤šäº 512 tokensã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ ·ä¾‹\\n\\t\\n\\nåœ¨åŸæœ‰å°è¯´æ–‡æœ¬åŸºç¡€ä¸Šï¼Œä¾æ®ä¸‹åˆ—äº”ç§æŒ‡ä»¤ç”Ÿæˆæ•°æ®ã€‚\\nå…¶ä¸­ï¼Œæ–‡æœ¬ç”±å°è¯´ä¸­éšæœºæŠ½å–çš„è¿ç»­å¥å­ç»„æˆã€‚\\n\\nç»™å®šæ ‡é¢˜ï¼Œç›´æ¥ç”Ÿæˆç®€ä»‹ã€‚\\nç»™å®šæ ‡é¢˜å’Œç®€ä»‹ï¼Œç”Ÿæˆå¼€å¤´ã€‚\\nç»™å®šç®€ä»‹å’Œä¸€æ®µæ–‡æœ¬ï¼Œç”Ÿæˆåç»­æ–‡æœ¬ã€‚\\nç»™å®šæ ‡é¢˜å’Œä¸€æ®µæ–‡æœ¬ï¼Œç”Ÿæˆåç»­æ–‡æœ¬ã€‚\\nç»™å®šä¸€æ®µæ–‡æœ¬ï¼Œç”Ÿæˆåç»­æ–‡æœ¬ã€‚\\n\\n{\\n    \\\"instruction\\\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zxbsmk/webnovel_cn.","first_N":5,"first_N_keywords":["text2text-generation","Chinese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ChineseWebNovel","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Delius/ChineseWebNovel","creator_name":"Albert Delius","creator_url":"https://huggingface.co/Delius","description":"Chinese Web Novel Dataset\\nSummarized by claude but converted the order for novel text extension task.\\nWARNING!! Please be aware of the context length!!!\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"cantonese-traditional-chinese-parallel-corpus","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/raptorkwok/cantonese-traditional-chinese-parallel-corpus","creator_name":"Raptor K","creator_url":"https://huggingface.co/raptorkwok","description":"This is a dataset of Cantonese-Written Chinese Parallel Corpus, containing 130k+ pairs of Cantonese and Traditional Chinese parallel sentences.\\n","first_N":5,"first_N_keywords":["translation","Chinese","cc0-1.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"sharegpt_gpt4","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/sharegpt_gpt4","creator_name":"Ming Xu (å¾æ˜)","creator_url":"https://huggingface.co/shibing624","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nShareGPTä¸­æŒ‘é€‰å‡ºçš„GPT4å¤šè½®é—®ç­”æ•°æ®ï¼Œå¤šè¯­è¨€é—®ç­”ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\næ•°æ®é›†æ˜¯å¤šè¯­è¨€ï¼ŒåŒ…æ‹¬ä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ç­‰å¸¸ç”¨è¯­è¨€ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields are the same among all splits.\\n\\nconversations: a List of string .\\n\\nhead -n 1 sharegpt_gpt4.jsonl\\n\\n{\\\"conversations\\\":[\\n  {'from': 'human',\\n   'value': 'æ¡ç”¨å„ªé›…ç¾ä»£ä¸­æ–‡ï¼Œç”¨ä¸­æ–‡ç¹é«”å­—å‹ï¼Œå›ç­”ä»¥ä¸‹å•é¡Œã€‚ç‚ºæ‰€æœ‰æ¨™é¡Œæˆ–å°ˆç”¨å­—è©æä¾›å°æ‡‰çš„è‹±èªç¿»è­¯ï¼šUsing scholarly style, summarize in detail James Barr\\\\'s book \\\"Semantics of Biblicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shibing624/sharegpt_gpt4.","first_N":5,"first_N_keywords":["text-classification","text-generation","text-scoring","shibing624","shibing624"],"keywords_longer_than_N":true},
	{"name":"YueMotion","keyword":"yue chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CAiRE/YueMotion","creator_name":"CAiRE HKUST","creator_url":"https://huggingface.co/CAiRE","description":"YueMotion is a Cantonese speech emotion dataset.","first_N":5,"first_N_keywords":["Yue Chinese","cc-by-sa-4.0","1K - 10K","Audio","Text"],"keywords_longer_than_N":true},
	{"name":"Chinese-LLaVA-Vision-Instructions","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LinkSoul/Chinese-LLaVA-Vision-Instructions","creator_name":"LinkSoul.AI","creator_url":"https://huggingface.co/LinkSoul","description":"æœ¬æ•°æ®é›†æ˜¯å¯¹äºLLaVAçš„ç¿»è¯‘ï¼Œè¯·ä»LLaVA datasetä¸‹è½½å¯¹åº”çš„å›¾ç‰‡ã€‚\\nç™¾åº¦ç½‘ç›˜é“¾æ¥: https://pan.baidu.com/s/1-jgINIkW0MxusmJuSif85w?pwd=q62v\\n","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"ShareGPT_Dialogue","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Maciel/ShareGPT_Dialogue","creator_name":"Maciel Young","creator_url":"https://huggingface.co/Maciel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\næœ¬æ•°æ®é›†æ¥è‡ªShareGPTæ•°æ®ï¼Œæ•´ç†æˆç”¨æˆ·å’Œç³»ç»Ÿå¤šè½®å¯¹è¯å½¢å¼ï¼ŒåŸå§‹æ•°æ®æ¥æº\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\næ•°æ®é›†ä¸­åŒ…å«ä¸¤ä¸ªå­—æ®µï¼Œåˆ†åˆ«ä¸ºdialogueå’Œturnã€‚dialogueæ˜¯ç”¨æˆ·å’Œç³»ç»Ÿä¹‹é—´çš„å¤šè½®å¯¹è¯ï¼Œæ•°æ®ç±»å‹ä¸ºList(Dict)ï¼ŒæŒ‰ç…§åˆ—è¡¨é¡ºåºè¡¨ç¤ºå¯¹è¯é¡ºåºï¼Œæ¯ä¸€è½®ä¸­humanæ˜¯ç”¨æˆ·é—®é¢˜ï¼Œassistantæ˜¯ç³»ç»Ÿå›å¤ã€‚turnè¡¨ç¤ºæ€»å…±å¯¹è¯è½®æ•°ï¼Œæ•°æ®ç±»å‹ä¸ºIntã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n{\\n  \\\"dialogue\\\":\\n    [ \\n      { \\n        \\\"human\\\": \\\"ç¼–å†™ä¸€ä¸ªç”¨æˆ·æ•…äº‹ï¼Œè¯´æ˜ä¸€ä¸ªç”¨æˆ·å¦‚ä½•ç™»å½•åº”ç”¨ç¨‹åºï¼Œç„¶ååœ¨ç¬¬äºŒæ®µä¸­ç¼–å†™å…¶ç”¨æˆ·éªŒæ”¶æµ‹è¯•ã€‚\\\",\\n        \\\"assistant\\\": \\\"ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿç™»å½•åˆ°åº”ç”¨ç¨‹åºï¼Œä»¥ä¾¿æˆ‘å¯ä»¥è®¿é—®æˆ‘çš„ä¸ªæ€§åŒ–å†…å®¹å’Œè®¾ç½®ã€‚\\\\nä¸ºç¡®ä¿ç™»å½•åŠŸèƒ½æ­£å¸¸å·¥ä½œï¼Œå¯ä»¥è¿›è¡Œä»¥ä¸‹éªŒæ”¶æµ‹è¯•ï¼š\\\\n1.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Maciel/ShareGPT_Dialogue.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"MedChatZH","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tyang816/MedChatZH","creator_name":"Yang Tan","creator_url":"https://huggingface.co/tyang816","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMedChatZH\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMedChatZHä¸­æ–‡å¾®è°ƒå‚æ•°\\n\\t\\n\\nåŸºäºBaichuan-7Båœ¨ä¸­åŒ»ä¹¦ç±æ•°æ®å’ŒåŒ»ç–—æŒ‡ä»¤å¯¹è¯æ•°æ®ä¸Šè®­ç»ƒï¼Œä½¿å…¶å…·å¤‡è¾ƒå¼ºçš„ä¸­æ–‡åŒ»ç–—å¯¹è¯èƒ½åŠ›ï¼Œèƒ½å¤Ÿç†è§£ä¸­åŒ»é—®é¢˜ã€‚\\nGithubï¼šMedChatZH-7B\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸš€ ç»“æœ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\né—®é¢˜\\nå›ç­”\\n\\n\\n\\t\\t\\nä¸­åŒ»æ²»è„±å‘æœ‰æ•ˆå—è„±å‘5ã€6å¹´äº†ï¼Œæ˜æ˜¾æ¯”ä»¥å‰å°‘äº†å¾ˆå¤šï¼Œè„±å‘ä½ç½®æ¯”è¾ƒå‡è¡¡ï¼Œæ²¡æœ‰çªå‡ºæ‰çš„æ¯”è¾ƒå¤šçš„åœ°æ–¹ï¼Œæˆ‘çš„å‘è´¨æ¯”è¾ƒç¡¬ï¼Œå¤´å‘ç”Ÿé•¿ä¹Ÿè¾ƒå¿«ã€‚\\nä¸­è¯æ²»ç–—è„±å‘çš„æ•ˆæœå› äººè€Œå¼‚ï¼Œä½†å¯¹äºæ‚¨è¿™ç§å¤´å‘è´¨é‡å¥½ä¸”ç”Ÿé•¿é€Ÿåº¦å¿«çš„æ‚£è€…æ¥è¯´ï¼Œä¸­è¯å¯èƒ½æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚ä¸€äº›å¸¸ç”¨çš„ä¸­è¯æ–¹å‰‚åŒ…æ‹¬å…­å‘³åœ°é»„ä¸¸ã€å››ç‰©æ±¤ç­‰ï¼Œè¿™äº›è¯ç‰©å¯ä»¥æ»‹å…»è‚è‚¾ï¼Œä¿ƒè¿›è¡€æ¶²å¾ªç¯å’Œæ¯›å›Šè¥å…»ä¾›åº”ï¼Œä»è€Œæ”¹å–„è„±å‘é—®é¢˜ã€‚æ­¤å¤–ï¼Œè¿˜å¯ä»¥é€šè¿‡é’ˆç¸ã€è‰¾ç¸ç­‰æ–¹å¼è¿›è¡Œè¾…åŠ©æ²»ç–—ã€‚ä½†æ˜¯éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸­è¯æ²»ç–—éœ€è¦é•¿æœŸåšæŒæ‰èƒ½è§æ•ˆï¼ŒåŒæ—¶è¿˜éœ€è¦æ³¨æ„é¥®é£Ÿå’Œç”Ÿæ´»ä¹ æƒ¯ç­‰æ–¹é¢çš„é—®é¢˜ï¼Œä»¥è¾¾åˆ°æ›´å¥½çš„ç–—æ•ˆã€‚å»ºè®®æ‚¨å’¨è¯¢ä¸“ä¸šçš„ä¸­åŒ»åŒ»ç”Ÿæˆ–çš®è‚¤ç§‘åŒ»ç”Ÿï¼Œæ ¹æ®ä¸ªäººæƒ…å†µåˆ¶å®šä¸ªæ€§åŒ–çš„æ²»ç–—æ–¹æ¡ˆã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/tyang816/MedChatZH.","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"ChatHaruhi-54K-Role-Playing-Dialogue","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/ChatHaruhi-54K-Role-Playing-Dialogue","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChatHaruhi\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReviving Anime Character in Reality via Large Language Model\\n\\t\\n\\n\\n\\ngithub repo: https://github.com/LC1332/Chat-Haruhi-Suzumiya\\nChat-Haruhi-Suzumiyais a language model that imitates the tone, personality and storylines of characters like Haruhi Suzumiya,\\n\\n   The project was developed by Cheng Li, Ziang Leng, Chenxi Yan, Xiaoyang Feng, HaoSheng Wang, Junyi Shen, Hao Wang, Weishi Mi, Aria Fei, Song Yan, Linkang Zhan, Yaokai Jia, Pingyu Wu, and Haozhen Sun,etc.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/silk-road/ChatHaruhi-54K-Role-Playing-Dialogue.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","Chinese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"lawyer_llama_data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Skepsun/lawyer_llama_data","creator_name":"Skepsun","creator_url":"https://huggingface.co/Skepsun","description":"åŸºäºlawyer-llamaçš„å¼€æºæ•°æ®è¿›è¡Œäº†ç®€å•çš„æ•´åˆï¼Œæ ¼å¼ç¬¦åˆLLaMA-Efficient-Tuningçš„æ ‡å‡†æ ¼å¼ï¼Œsourceå­—æ®µä¿å­˜äº†æ•°æ®çš„åŸå§‹æ–‡ä»¶åã€‚\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"DISC-Med-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Flmc/DISC-Med-SFT","creator_name":"Eric","creator_url":"https://huggingface.co/Flmc","description":"This is a repository containing a subset of the DISC-Med-SFT Dataset.\\nCheck DISC-MedLLM for more information.\\n","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"belebele","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\\n\\t\\n\\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions thatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele.","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","text-classification","multiple-choice","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"blossom-math-v2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-math-v2","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM MATH V2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nBlossom Math V3ç‰ˆæœ¬å·²å‘å¸ƒï¼ğŸ¤—\\nBlossom Math V2æ˜¯åŸºäºMath23Kå’ŒGSM8Kè¡ç”Ÿè€Œæ¥çš„ä¸­è‹±åŒè¯­æ•°å­¦å¯¹è¯æ•°æ®é›†ï¼Œé€‚ç”¨äºæ•°å­¦é—®é¢˜å¾®è°ƒã€‚\\nç›¸æ¯”äºblossom-math-v1ï¼Œæ–°å¢äº†2500æ¡GSM8Kæ•°æ®å’Œç¿»è¯‘ä¸ºä¸­æ–‡çš„2500æ¡GSM8K-CNæ•°æ®ã€‚æ­¤å¤–ï¼Œä¼˜åŒ–äº†ç­”æ¡ˆçš„æ£€æŸ¥é€»è¾‘ï¼Œè¿˜ç§»é™¤äº†<<1+1=2>>ç­‰è®¡ç®—æ­¥éª¤ï¼Œä»¥ç»Ÿä¸€æ¨ç†æ­¥éª¤çš„é£æ ¼ã€‚\\næœ¬æ•°æ®é›†é‡‡ç”¨å…¨é‡Math23Kã€GSM8Kå’Œç¿»è¯‘åçš„GSM8Kçš„é—®é¢˜ï¼Œéšåè°ƒç”¨gpt-3.5-turbo-0613ç”Ÿæˆç»“æœï¼Œå¹¶ä½¿ç”¨åŸå§‹æ•°æ®é›†ä¸­çš„ç­”æ¡ˆå¯¹ç”Ÿæˆçš„ç»“æœè¿›è¡ŒéªŒè¯ï¼Œè¿‡æ»¤æ‰é”™è¯¯ç­”æ¡ˆï¼Œå¾ˆå¤§ç¨‹åº¦ä¸Šä¿è¯äº†é—®é¢˜å’Œç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚\\næœ¬æ¬¡å‘å¸ƒäº†å…¨é‡æ•°æ®çš„25%ï¼ŒåŒ…å«10Kè®°å½•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€\\n\\t\\n\\nä¸­æ–‡å’Œè‹±æ–‡\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„\\n\\t\\n\\næ¯æ¡æ•°æ®ä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„é¢˜ç›®åŠç­”æ¡ˆï¼ŒåŒ…å«idã€inputã€outputã€answerã€datasetå››ä¸ªå­—æ®µã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-math-v2.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-Chinese","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yys/OpenOrca-Chinese","creator_name":"yanyusong","creator_url":"https://huggingface.co/yys","description":"ğŸ‹ OpenOrca-Chinese æ•°æ®é›†ï¼ğŸ‹\\n\\næ„Ÿè°¢  Open-Orca/OpenOrca  æ•°æ®é›†çš„å‘å¸ƒï¼Œç»™å¹¿å¤§NLPç ”ç©¶äººå‘˜å’Œå¼€å‘è€…å¸¦æ¥äº†å®è´µçš„èµ„æºï¼  \\nè¿™æ˜¯ä¸€ä¸ªå¯¹  Open-Orca/OpenOrca  æ•°æ®é›†ä¸­æ–‡ç¿»è¯‘çš„ç‰ˆæœ¬ï¼Œç¿»è¯‘å¼•æ“ä¸º Google ç¿»è¯‘ï¼Œå¸Œæœ›èƒ½ç»™ä¸­æ–‡ LLM ç ”ç©¶åšå‡ºä¸€ç‚¹ç‚¹è´¡çŒ®ã€‚\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe OpenOrca dataset is a collection of augmented FLAN Collection data.\\nCurrently ~1M GPT-4 completions, and ~3.2M GPT-3.5 completions.\\nIt is tabularized in alignment with the distributions presented in the ORCA paper and currently represents a partial completion of the full intended dataset, withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yys/OpenOrca-Chinese.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"OpenOrca-Traditional-Chinese","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lchakkei/OpenOrca-Traditional-Chinese","creator_name":"Lee Chak Kei","creator_url":"https://huggingface.co/lchakkei","description":"ğŸ‹ OpenOrca-Chinese æ•°æ®é›†ï¼ğŸ‹\\n\\næ„Ÿè¬  Open-Orca/OpenOrca  è³‡æ–™é›†çš„ç™¼å¸ƒï¼Œç‚ºå»£å¤§NLPç ”ç©¶äººå“¡å’Œé–‹ç™¼è€…å¸¶ä¾†äº†å¯¶è²´çš„è³‡æºï¼\\né€™æ˜¯ä¸€å€‹å°  Open-Orca/OpenOrca  è³‡æ–™é›†ä¸­æ–‡ç¿»è­¯çš„ç‰ˆæœ¬ï¼Œç¿»è­¯å¼•æ“ç‚º Google ç¿»è­¯ï¼Œå¸Œæœ›èƒ½ç‚ºä¸­æ–‡ LLM ç ”ç©¶åšå‡ºä¸€é»é»è²¢ç»ã€‚\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe OpenOrca dataset is a collection of augmented FLAN Collection data.\\nCurrently ~1M GPT-4 completions, and ~3.2M GPT-3.5 completions.\\nIt is tabularized in alignment with the distributions presented in the ORCA paper and currently represents a partial completion of the full intended dataset, with ongoingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lchakkei/OpenOrca-Traditional-Chinese.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"FinCorpus","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Duxiaoman-DI/FinCorpus","creator_name":"Duxiaoman DI","creator_url":"https://huggingface.co/Duxiaoman-DI","description":"ä¸­æ–‡é‡‘èèµ„è®¯æ•°æ®é›†ï¼ŒåŒ…æ‹¬ï¼ˆå‹ç¼©å‰ï¼‰ï¼š\\n\\nä¸Šå¸‚å…¬å¸å…¬å‘Š announcement_data.jsonl  20G\\né‡‘èèµ„è®¯/æ–°é—»\\nfin_news_data.jsonl 30G\\nfin_articles_data.jsonl 10G\\n\\n\\né‡‘èè¯•é¢˜ fin_exam.jsonl 370M\\n\\næ•°æ®æ ¼å¼ï¼š\\n{\\n  \\\"text\\\": <æ–‡æœ¬å†…å®¹>,\\n  \\\"meta\\\": {\\n     \\\"source\\\": <æ•°æ®æ¥æº>\\n  }\\n}\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"belle_filtered_2.8M_CN","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/larryvrh/belle_filtered_2.8M_CN","creator_name":"larryvrh","creator_url":"https://huggingface.co/larryvrh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"belle_filtered_2.8M_CN\\\"\\n\\t\\n\\né€šè¿‡å¯å‘å¼æ–¹æ³•è¿‡æ»¤åçš„BelleGroup/train_3.5M_CNï¼Œç§»é™¤äº†è¯­æ–™ä¸­æ˜æ˜¾çš„é”™è¯¯å’Œä½è´¨é‡å†…å®¹ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ ·ä¾‹\\n\\t\\n\\n{\\n    \\\"id\\\":\\\"66623028\\\",\\n    \\\"conversations\\\":[\\n        {\\n            \\\"from\\\":\\\"human\\\",\\n            \\\"value\\\":\\\"å½’çº³ä»‹ç»ä¸‰ç§ä¸åŒç±»å‹çš„ç”µå½±é¢˜æ\\\"\\n        },\\n        {\\n            \\\"from\\\":\\\"assistant\\\",\\n            \\\"value\\\":\\\"1. åŠ¨ä½œç‰‡ï¼šåŠ¨ä½œç‰‡é€šå¸¸å¼ºè°ƒåŠ¨ä½œå’Œæˆ˜æ–—åœºé¢ï¼Œæ•…äº‹æƒ…èŠ‚ç´§å‡‘ï¼Œå……æ»¡äº†ç´§å¼ å’Œå…´å¥‹çš„æ°›å›´ã€‚ä¸»è§’ä¸€èˆ¬æ˜¯å…·æœ‰è¶…å‡¡å®åŠ›æˆ–ç‰¹æ®ŠæŠ€èƒ½çš„è‹±é›„äººç‰©ï¼Œå¾€å¾€ä¼šä¸åæ´¾è§’è‰²è¿›è¡Œä¸€ç³»åˆ—æ¿€çƒˆçš„æ ¼æ–—ï¼Œè¿½é€å’Œçˆ†ç ´ç­‰é…·ç‚«åœºé¢ã€‚ä¾‹å¦‚ã€Šé€Ÿåº¦ä¸æ¿€æƒ…ã€‹å’Œã€Šå¤ä»‡è€…è”ç›Ÿã€‹ç­‰ã€‚\\\\n2.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/larryvrh/belle_filtered_2.8M_CN.","first_N":5,"first_N_keywords":["text-generation","Chinese","gpl-3.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"openorca-chinese-zhtw","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/erhwenkuo/openorca-chinese-zhtw","creator_name":"Erhwen, Kuo","creator_url":"https://huggingface.co/erhwenkuo","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"openorca-chinese-zhtw\\\"\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe OpenOrca dataset is a collection of augmented FLAN Collection data.\\nCurrently ~1M GPT-4 completions, and ~3.2M GPT-3.5 completions.\\nIt is tabularized in alignment with the distributions presented in the ORCA paper and currently represents a partial completion of the full intended dataset, with ongoing generation to expand its scope.\\nThe data is primarily used for training and evaluation in the field ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/erhwenkuo/openorca-chinese-zhtw.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"medical_dialogue-chinese-zhtw","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/erhwenkuo/medical_dialogue-chinese-zhtw","creator_name":"Erhwen, Kuo","creator_url":"https://huggingface.co/erhwenkuo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"medical_dialogue-chinese-zhtw\\\"\\n\\t\\n\\nä¸­æ–‡é†«ç™‚å•ç­”è³‡æ–™é›†\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä¾†æº\\n\\t\\n\\næœ¬è³‡æ–™é›†æ˜¯å¾ Toyhom/Chinese-medical-dialogue-data çš„ github repo ä¸­è½‰æ›è€Œä¾†ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå…§å®¹\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nç§‘åˆ¥\\næ•¸é‡\\n\\n\\n\\t\\t\\nAndriatria ç”·ç§‘\\n94,596 å€‹å•ç­”å°\\n\\n\\nIM å…§ç§‘\\n220,606 å€‹å•ç­”å°\\n\\n\\nOAGD å©¦ç”¢ç§‘\\n183,751 å€‹å•ç­”å°\\n\\n\\nOncology è…«ç˜¤ç§‘\\n75,553 å€‹å•ç­”å°\\n\\n\\nPediatric å…’ç§‘\\n101,602 å€‹å•ç­”å°\\n\\n\\nSurgical å¤–ç§‘\\n115,991 å€‹å•ç­”å°\\n\\n\\n\\t\\n\\n ç¸½è¨ˆ 792,099 æ¢æ•¸æ“š\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç¯„ä¾‹\\n\\t\\n\\n{\\n  \\\"instruction\\\": \\\"ç¾åœ¨ä½ æ˜¯å€‹ç¥ç¶“è…¦å¤–ç§‘é†«ç”Ÿï¼Œè«‹æ ¹æ“šç—…äººçš„å•é¡Œçµ¦äºˆå»ºè­°ï¼š\\\",\\n  \\\"input\\\": \\\"ç™²ç™‡ç—…èƒ½åƒå¾·å·´é‡‘å—ï¼ŒéŒ¯è¦ºï¼Œæœ‰æ™‚å€™æ„Ÿè¦ºçœ‹åˆ°çš„å’Œè½åˆ°çš„ä¸å¤ªä¸€æ¨£ã€‚\\\",\\n  \\\"output\\\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/erhwenkuo/medical_dialogue-chinese-zhtw.","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"C-Language-Chat-Debug-Multiturn-Zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/C-Language-Chat-Debug-Multiturn-Zh","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"çº¦ 1300 æ¡ C è¯­è¨€ åœºæ™¯çš„ user - assistant å¤šè½®å¯¹è¯ã€‚æ¯æ®µå¯¹è¯å·²ç»ç»„ç»‡æˆäº†å•è¡Œçš„æ ¼å¼ã€‚ä¸€æ¡æ ·ä¾‹å¦‚ä¸‹ï¼š\\n{\\n    \\\"id\\\": 1045,\\n    \\\"conversation\\\": [\\n        {\\n            \\\"user\\\": \\\"ä½ å¥½ï¼ŒAIåŠ©æ‰‹ã€‚æˆ‘æœ€è¿‘åœ¨å†™ä¸€ä¸ªCè¯­è¨€ç¨‹åºï¼Œä½†æ˜¯é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œå¸Œæœ›ä½ èƒ½å¸®æˆ‘æ£€æŸ¥ä¸€ä¸‹ã€‚\\\",\\n            \\\"assistant\\\": \\\"ä½ å¥½ï¼Œæˆ‘å¾ˆä¹æ„å¸®åŠ©ä½ ã€‚è¯·æŠŠä½ çš„ä»£ç å‘ç»™æˆ‘ï¼Œæˆ‘ä¼šå°½å¿«æ£€æŸ¥å¹¶ç»™å‡ºå»ºè®®ã€‚\\\"\\n        },\\n        {\\n            \\\"user\\\": \\\"å¥½çš„ï¼Œè¿™æ˜¯æˆ‘çš„ä»£ç ã€‚è¿™æ®µä»£ç çš„ä¸»è¦åŠŸèƒ½æ˜¯è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„å‰né¡¹ã€‚\\\",\\n            \\\"assistant\\\": \\\"è®©æˆ‘çœ‹ä¸€ä¸‹......å—¯ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªå°é”™è¯¯ã€‚åœ¨ç¬¬10è¡Œï¼Œä½ åº”è¯¥ä½¿ç”¨`++i`è€Œä¸æ˜¯`i++`æ¥é€’å¢içš„å€¼ã€‚ä¿®æ”¹åçš„ä»£ç åº”è¯¥æ˜¯è¿™æ ·çš„\\\\\\\\n```c\\\\\\\\nfor (int i = 0; i < n; ++i) {\\\\\\\\n    if (i == 0 || i == 1) {\\\\\\\\nâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mxode/C-Language-Chat-Debug-Multiturn-Zh.","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"ntu_adl_question","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xjlulu/ntu_adl_question","creator_name":"Xue-Jin Lu","creator_url":"https://huggingface.co/xjlulu","description":"xjlulu/ntu_adl_question dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Huatuo26M-Lite","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/Huatuo26M-Lite","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHuatuo26M-Lite ğŸ“š\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTable of Contents ğŸ—‚\\n\\t\\n\\n\\nDataset Description ğŸ“\\nDataset Information â„¹ï¸\\nData Distribution ğŸ“Š\\nUsage ğŸ”§\\nCitation ğŸ“–\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description ğŸ“\\n\\t\\n\\nHuatuo26M-Lite is a refined and optimized dataset based on the Huatuo26M dataset, which has undergone multiple purification processes and rewrites. It has more data dimensions and higher data quality. We welcome you to try using it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information â„¹ï¸\\n\\t\\n\\n\\nDataset Name:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/Huatuo26M-Lite.","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"GSM8KInstruct_Parallel","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mathoctopus/GSM8KInstruct_Parallel","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","description":"Mathoctopus/GSM8KInstruct_Parallel dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","Chinese","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"CodeFuse-DevOps-Eval","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/codefuse-ai/CodeFuse-DevOps-Eval","creator_name":"CodeFuse AI","creator_url":"https://huggingface.co/codefuse-ai","description":"DevOps-Eval is a comprehensive chinese evaluation suite specifically designed for foundation models in the DevOps field. It consists of 5977 multi-choice questions spanning 55 diverse categories. Please visit our website and GitHub for more details.\\nEach category consists of two splits: dev, and test. The dev set per subject consists of five exemplars with explanations for few-shot evaluation. And the test set is for model evaluation. Labels on the test split are released, users can evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/codefuse-ai/CodeFuse-DevOps-Eval.","first_N":5,"first_N_keywords":["question-answering","multiple-choice","English","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"poetry-chinese-zhtw","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/erhwenkuo/poetry-chinese-zhtw","creator_name":"Erhwen, Kuo","creator_url":"https://huggingface.co/erhwenkuo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"poetry-chinese-zhtw\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè³‡æ–™é›†æ‘˜è¦\\n\\t\\n\\nä¸­æ–‡å¤å…¸æ–‡é›†è³‡æ–™åº«æ”¶é›†äº†ç´„ 5.5 è¬é¦–å”è©©ã€26 è¬é¦–å®‹è©©ã€2.1 è¬é¦–å®‹è©å’Œå…¶ä»–å¤å…¸æ–‡é›†ã€‚è©©äººåŒ…æ‹¬å”å®‹å…©æœè¿‘ 1.4 è¬å¤è©©äººï¼Œå’Œå…©å®‹æ™‚æœŸ 1.5 åƒå¤è©äººã€‚\\n\\näº”ä»£ååœ‹- æ”¶éŒ„\\\"èŠ±é–“é›†\\\"èˆ‡\\\"å—å”äºŒä¸»è©\\\"\\nå”- æ”¶éŒ„\\\"å…¨å”è©©\\\"(æ˜¯æ¸…åº·ç†™å››åå››å¹´ï¼Œåº·ç†™çš‡å¸ä¸»å°ä¸‹ï¼Œè’é›†ç¾…å”è©©çš„æ”¶è—ã€Œå¾—è©© 48,900 é¤˜é¦–ï¼Œè©©å…¥ 2,200 äººã€)ã€‚\\nå®‹- æ”¶éŒ„\\\"å…¨å®‹è©\\\"(ç”±å”åœ­ç’‹ç·¨è‘—ï¼Œå­”å‡¡ç¦®è£œè¼¯ï¼Œå…±æ”¶éŒ„å®‹ä»£è©äºº 1,330 å®¶ï¼Œè©ä½œ 21,116 é¦–)ã€‚\\nå…ƒ- æ”¶éŒ„å…ƒæ›² 11,057 ç¯‡ï¼Œæ›²å®¶ 233 äººã€‚\\næ¸…- æ”¶éŒ„\\\"ç´è˜­æ€§å¾·è©©é›†\\\"\\n\\nåŸå§‹è³‡æ–™ä¾†æº:\\n\\nchinese-poetry: æœ€å…¨ä¸­æ–‡è¯—æ­Œå¤å…¸æ–‡é›†æ•°æ®åº“\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè³‡æ–™ä¸‹è¼‰æ¸…ç†\\n\\t\\n\\n\\nä¸‹è¼‰ chinese-poetry: æœ€å…¨ä¸­æ–‡è¯—æ­Œå¤å…¸æ–‡é›†æ•°æ®åº“ çš„ Repo\\nèª¿æ•´è³‡æ–™å‘ˆç¾çµæ§‹ä¾¿æ–¼æ¨¡å‹è¨“ç·´\\nä½¿ç”¨ OpenCC ä¾†é€²è¡Œç°¡ç¹è½‰æ›\\nä½¿ç”¨ Huggingfaceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/erhwenkuo/poetry-chinese-zhtw.","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"medical_instruction","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DavidLanz/medical_instruction","creator_name":"David Lanz","creator_url":"https://huggingface.co/DavidLanz","description":"Supervisory Fine-Tuning Dataset (SFT and RLHF)\\n\\nDataset Name: medical_finetune_tw.json\\nDescription: This dataset comprises a total of 2.06 million entries and is sourced from various sources, including:\\nSix medical department medical inquiry datasets from the Chinese Medical Dialogue Dataset, totaling 790,000 entries.\\nAn online medical encyclopedia dataset, huatuo_encyclopedia_qa, with 360,000 entries.\\nA medical knowledge graph dataset, huatuo_knowledge_graph_qa, with 790,000 entries. Theseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DavidLanz/medical_instruction.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"RoleBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZenMoore/RoleBench","creator_name":"Zekun Moore Wang","creator_url":"https://huggingface.co/ZenMoore","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRoleBench\\n\\t\\n\\n\\nPaper Title: RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models\\narXiv Link: https://arxiv.org/abs/2310.00746\\nGithub Repo: https://github.com/InteractiveNLP-Team/RoleLLM-public\\n\\nPlease read our paper for more details about this dataset.\\nTL;DR: We introduce RoleLLM, a role-playing framework of data construction and evaluation (RoleBench), as well as solutions for both closed-source and open-source models (RoleGPT, RoleLLaMAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZenMoore/RoleBench.","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","Text","arxiv:2310.00746"],"keywords_longer_than_N":true},
	{"name":"alpaca-cot-zh-refined-by-data-juicer","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/datajuicer/alpaca-cot-zh-refined-by-data-juicer","creator_name":"Data-Juicer","creator_url":"https://huggingface.co/datajuicer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAlpaca-CoT -- ZH (refined by Data-Juicer)\\n\\t\\n\\nA refined Chinese version of Alpaca-CoT dataset by Data-Juicer. Removing some \\\"bad\\\" samples from the original dataset to make it higher-quality.\\nThis dataset is usually used to fine-tune a Large Language Model.\\nNotice: Here is a small subset for previewing. The whole dataset is available here (About 18.7GB).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nNumber of samples: 9,873,214 (Keep ~46.58% from the original dataset)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRefiningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/datajuicer/alpaca-cot-zh-refined-by-data-juicer.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Conic10K","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WenyangHui/Conic10K","creator_name":"huiwy","creator_url":"https://huggingface.co/WenyangHui","description":"WenyangHui/Conic10K dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Open_Assistant_Conversation_Chains","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\n\\n\\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\\n\\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\\n\\nIt wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains.","first_N":5,"first_N_keywords":["text-generation","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"gsm8k_chinese","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/swulling/gsm8k_chinese","creator_name":"Alex Yang","creator_url":"https://huggingface.co/swulling","description":"swulling/gsm8k_chinese dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","gsm8k","Chinese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"multilingual-tts","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/multilingual-tts","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBefore Anything and Everything âš±\\n\\t\\n\\nIn the time of writing this Dataset Card, 17,490 18,412 civilian has been killed in Palestine (7,870 8,000 are children and 6,121 6,200 are women).\\nSeek any non-profit organization to help them with what you can (For myself, I use Mersal) ğŸ‡µğŸ‡¸\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Multilingual TTS dataset is an exceptional compilation of text-to-speech (TTS) samples, meticulously crafted to showcase the richness and diversity of human languages.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/multilingual-tts.","first_N":5,"first_N_keywords":["text-to-speech","Arabic","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"ChatHaruhi-Expand-118K","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/ChatHaruhi-Expand-118K","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChatHaruhi Expanded Dataset 118K\\n\\t\\n\\n62663 instance from original ChatHaruhi-54K\\n42255 English Data from RoleLLM\\n13166 Chinese Data from \\ngithub repo:\\nhttps://github.com/LC1332/Chat-Haruhi-Suzumiya\\nPlease star our github repo if you found the dataset is useful\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRegenerate Data\\n\\t\\n\\nIf you want to regenerate data with different context length, different embedding model or using your own chracter\\nnow we refactored the final data generating pipeline\\nRoleLLM Data was generatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/silk-road/ChatHaruhi-Expand-118K.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"MetaMathQA_GSM8K_zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meta-math/MetaMathQA_GSM8K_zh","creator_name":"MetaMath","creator_url":"https://huggingface.co/meta-math","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\nMetaMathQA_GSM8K_zh is a dataset for mathematical reasoning in Chinese, \\nquestion-answer pairs are translated from MetaMathQA (https://huggingface.co/datasets/meta-math/MetaMathQA) by GPT-3.5-Turbo with few-shot prompting.\\nThe dataset consists of 231685 samples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you find the GSM8K_zh dataset useful for your projects/papers, please cite the following paper.\\n@article{yu2023metamath,\\n  title={MetaMath: Bootstrap Your Own Mathematical Questions forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/meta-math/MetaMathQA_GSM8K_zh.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"yayi_uie_sft_data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wenge-research/yayi_uie_sft_data","creator_name":"wenge-research","creator_url":"https://huggingface.co/wenge-research","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè®­ç»ƒæ•°æ®/Training Data\\n\\t\\n\\nç™¾ä¸‡çº§è¯­æ–™ä¸­æ–‡54%ï¼Œè‹±æ–‡46%ï¼›å…¶ä¸­å…¶ä¸­æ•°æ®é›†åŒ…æ‹¬12ä¸ªé¢†åŸŸåŒ…æ‹¬é‡‘èï¼Œç¤¾ä¼šï¼Œç”Ÿç‰©ï¼Œå•†ä¸šï¼Œå·¥ä¸šåˆ¶é€ ï¼ŒåŒ–å­¦ï¼Œè½¦è¾†ï¼Œç§‘å­¦ï¼Œç–¾ç—…åŒ»ç–—ï¼Œä¸ªäººç”Ÿæ´»ï¼Œå®‰å…¨å’Œé€šç”¨ã€‚è¦†ç›–æ•°ç™¾ä¸ªä½¿ç”¨åœºæ™¯\\n\\nNERï¼šä¸­æ–‡è¦†ç›–28ä¸ªå®ä½“ç±»å‹åŒ…æ‹¬äººç‰©ï¼Œåœ°ç¼˜æ”¿æ²»ï¼Œç»„ç»‡ï¼Œèº«ä½“éƒ¨ä½ï¼Œè¯ç‰©ç­‰ï¼Œè‹±æ–‡è¦†ç›–130ä¸ªå®ä½“ç±»å‹åŒ…æ‹¬Animal, Weapon, Conference, Bookç­‰ã€‚\\nREï¼šä¸­æ–‡è¦†ç›–232ç§å…³ç³»åŒ…æ‹¬ä¹°èµ„ï¼Œå¢æŒï¼Œé‡ç»„ï¼Œå›½ç±ï¼Œåˆ«åï¼Œäº²å±ï¼Œå…¥è‚¡ï¼Œè½¬è®©ï¼Œå¯¼è‡´ï¼Œå‘ç”Ÿåœ°ç‚¹ï¼Œåˆ¶é€ å•†ç­‰ï¼Œè‹±æ–‡è¦†ç›–236ç§å…³ç³»åŒ…æ‹¬founded byï¼Œstate or province of headquartersï¼Œemployee ofï¼Œoccupationï¼Œcreatorç­‰ã€‚\\nEEï¼šä¸­æ–‡è¦†ç›–84ç§äº‹ä»¶ç±»å‹,åŒ…æ‹¬ä¸­æ ‡ï¼Œé«˜ç®¡å˜åŠ¨ï¼Œäº§å“è¡Œä¸º-å‘å¸ƒï¼Œå…¬å¸ä¸Šå¸‚ç­‰ï¼Œå’Œ203ç§è®ºå…ƒï¼Œè‹±æ–‡è¦†ç›–45ç§äº‹ä»¶ç±»å‹ï¼ŒåŒ…æ‹¬Born, Demonstrate, Meet, End Organization, Divorceç­‰ï¼Œå’Œ62ç§è®ºå…ƒã€‚\\n\\nIn the corpus of over aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wenge-research/yayi_uie_sft_data.","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","1M<n<10M","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"librivox-tracks","keyword":"achinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"yue chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"Anime_novel_datasets","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Minami-su/Anime_novel_datasets","creator_name":"å—æ –","creator_url":"https://huggingface.co/Minami-su","description":"","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\\n","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"Chinese-poetries-txt","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lifan-Z/Chinese-poetries-txt","creator_name":"Lifan Zeng","creator_url":"https://huggingface.co/Lifan-Z","description":"è¿™ä¸ªæ•°æ®é›†æ˜¯æŠŠã€Šå…¨å”è¯—ã€‹ã€ã€Šå…¨å®‹è¯—ã€‹ä¸­æ‰€æœ‰çš„äº”ç»ã€äº”å¾‹ã€ä¸ƒç»ã€ä¸ƒå¾‹éƒ½æå–å‡ºæ¥ï¼Œåšæˆå››ä¸ªæ–‡ä»¶ã€‚æ¯è¡Œå¯¹åº”ä¸€é¦–è¯—ã€‚äº”ç»ï¼ˆ5x4ï¼‰: 17521 é¦–äº”å¾‹ï¼ˆ5x8ï¼‰: 60896 é¦–ä¸ƒç»ï¼ˆ7x4ï¼‰: 84485 é¦–ä¸ƒå¾‹ï¼ˆ7x8ï¼‰: 71818 é¦–  \\nThis dataset extracts four styles of poetries in \\\"Complete Poems of the Tang Dynasty\\\" and \\\"Complete Poems of the Song Dynasty.\\\"Each line corresponds to a Chinese poem.The syle on 5x4: 17521The syle on 5x8: 60896The syle on 7x4: 84485The syle on 7x8: 71818   \\nThe raw data source from https://github.com/chinese-poetry/chinese-poetry/tree/master/%E5%85%A8%E5%94%90%E8%AF%97  \\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"tmmluplus","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ikala/tmmluplus","creator_name":"iKala","creator_url":"https://huggingface.co/ikala","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTMMLU+ : Large scale traditional chinese massive multitask language understanding\\n\\t\\n\\n\\n\\n\\nWe present TMMLU+, a traditional Chinese massive multitask language understanding dataset. TMMLU+ is a multiple-choice question-answering dataset featuring 66 subjects, ranging from elementary to professional level.\\n\\nThe TMMLU+ dataset is six times larger and contains more balanced subjects compared to its predecessor, TMMLU. We have included benchmark results in TMMLU+ from closed-source modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ikala/tmmluplus.","first_N":5,"first_N_keywords":["question-answering","Chinese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"CPsyExam","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CAS-SIAT-XinHai/CPsyExam","creator_name":"CAS-SIAT-XinHai","creator_url":"https://huggingface.co/CAS-SIAT-XinHai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCPsyExam Dataset\\n\\t\\n\\nCPsyExam is a comprehensive dataset designed for evaluating Chinese psychological examination capabilities in large language models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe CPsyExam dataset is structured to assess psychological examination competencies in a Chinese context. It provides a standardized way to evaluate how well language models can handle psychological assessment tasks. The dataset contains multiple-choice questions from various psychological domainsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CAS-SIAT-XinHai/CPsyExam.","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"TinyStories-Qwen","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zhoukz/TinyStories-Qwen","creator_name":"zhoukz","creator_url":"https://huggingface.co/zhoukz","description":"ä½¿ç”¨Qwenç³»åˆ—æ¨¡å‹ï¼Œä»¿ç…§TinyStoriesæ•°æ®é›†ç”Ÿæˆçš„ä¸­æ–‡æ•…äº‹æ•°æ®é›†ã€‚\\nè¿™ä¸æ˜¯åŸæ•°æ®é›†çš„ç¿»è¯‘ï¼Œä¹Ÿä¸éµå¾ªåŸæ•°æ®é›†çš„æ ¼å¼ã€‚æ‰€æœ‰æ•°æ®å‡ä¸ºAIç”Ÿæˆï¼Œæ•°æ®é›†æœªç»ç­›é€‰ï¼Œä¸ä¿è¯å…¶åˆ†å¸ƒå‡åŒ€ã€å®‰å…¨æ— å®³æˆ–å…¶ä»–ä»»ä½•æ€§è´¨ã€‚ç”¨äºç”Ÿæˆæ•°æ®é›†çš„ç§å­ä¿¡æ¯ä¸ºéšæœºé€‰æ‹©ï¼Œæ— ä»»ä½•ç‰¹å®šå«ä¹‰ã€‚\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"Zhihu-KOL-More-Than-100-Upvotes","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bzb2023/Zhihu-KOL-More-Than-100-Upvotes","creator_name":"åˆ·çŸ¥ä¹åˆ·çš„","creator_url":"https://huggingface.co/bzb2023","description":"å¯¹ https://huggingface.co/datasets/wangrui6/Zhihu-KOL æ•°æ®è¿›è¡Œäº†åˆæ­¥æ•´ç†ï¼Œä¿ç•™äº†100èµåŠä»¥ä¸Šçš„æ•°æ®ã€‚\\nå…±271261æ¡ã€‚\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100K - 1M","arrow"],"keywords_longer_than_N":true},
	{"name":"openassistant-deepseek-coder","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using:\\nB_INST = '\\\\n### Instruction:\\\\n'\\nE_INST = '\\\\n### Response:\\\\n'\\nBOS = '<ï½œbeginâ–ofâ–sentenceï½œ>'\\nEOS = '\\\\n<|EOT|>\\\\n'\\n\\nSample Preparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"Ziya-Writing-Eval-Chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IDEA-CCNL/Ziya-Writing-Eval-Chinese","creator_name":"Fengshenbang-LM","creator_url":"https://huggingface.co/IDEA-CCNL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå§œå­ç‰™å†™ä½œä»»åŠ¡ä¸­æ–‡è¯„ä¼°æ•°æ®é›† Ziya-Writing-Eval-Chinese\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®ä»‹ç» Dataset Summary\\n\\t\\n\\nç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨ä¸­æ–‡å†™ä½œä»»åŠ¡ä¸Šçš„æ°´å¹³ï¼Œé€šå¸¸é‡‡ç”¨Side-by-Sideè¯„æµ‹ï¼›\\næœ¬è¯„æµ‹é›†åŒ…å«äº†ä»¥ä¸‹å‡ ä¸ªå†™ä½œå­ä»»åŠ¡ï¼š\\n\\nåº”ç”¨å†™ä½œ\\nå…¬æ–‡\\né€šçŸ¥\\næŠ¥å‘Š\\nè®ºæ–‡\\nå¾ç¨¿\\nå‡½ä»¶\\nç”³è¯·ä¹¦\\n\\n\\nåˆ›æ„å†™ä½œ\\nä¹¦ä¿¡\\nä½œæ–‡\\næ–‡æ¡ˆ\\nå°è¯´\\nè§†é¢‘è„šæœ¬\\næ”»ç•¥\\nå¹¿å‘Š\\nå‰§æœ¬\\nç«¥è¯\\n\\n\\n\\nThis evaluation set is used to assess the proficiency of large language models in Chinese writing tasks, typically through Side-by-Side evaluation.\\nThis evaluation set includes the following writing sub-tasks:\\n\\nApplication Writing\\nOfficial documents\\nNotices\\nReports\\nPapers\\nCallâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IDEA-CCNL/Ziya-Writing-Eval-Chinese.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"T-Eval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lovesnowbest/T-Eval","creator_name":"Zehui Chen","creator_url":"https://huggingface.co/lovesnowbest","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tT-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tâœ¨ Introduction\\n\\t\\n\\nThis is an evaluation harness for the benchmark described in T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step. \\n[Paper]\\n[Project Page]\\n[LeaderBoard]\\n[HuggingFace]\\n\\nLarge language models (LLM) have achieved remarkable performance on various NLP tasks and are augmented by tools for broader applications. Yet, how toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lovesnowbest/T-Eval.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","apache-2.0","100M<n<1B"],"keywords_longer_than_N":true},
	{"name":"Chinese-LIMA-V0","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jellyfish042/Chinese-LIMA-V0","creator_name":"Jellyfish042","creator_url":"https://huggingface.co/Jellyfish042","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLIMAæ•°æ®é›†ä¸­æ–‡ç‰ˆ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†æ„é€ æ–¹æ³•\\n\\t\\n\\n\\nä½¿ç”¨GPT-4-Turboå°†åŸå§‹LIMAæ•°æ®é›†çš„é—®é¢˜éƒ¨åˆ†ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚\\nä½¿ç”¨GPT-4-Turboå›ç­”ç¿»è¯‘åçš„é—®é¢˜ã€‚\\næ³¨æ„ï¼Œæœ¬æ•°æ®é›†ä¸åŒ…å«åŸå§‹LIMAæ•°æ®é›†çš„å¤šè½®é—®ç­”éƒ¨åˆ†\\n\\n","first_N":5,"first_N_keywords":["Chinese","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"sharegpt_dialogue_base","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base","creator_name":"Hieu Lam","creator_url":"https://huggingface.co/lamhieu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe dataset is from unknown, formatted as dialogues for speed and ease of use. Many thanks to author for releasing it.\\nImportantly, this format is easy to use via the default chat template of transformers, meaning you can use huggingface/alignment-handbook immediately, unsloth.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\nView online through viewer.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\nWe advise you to reconsider before use, thank you. If you find it useful, please like and follow this account.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","Vietnamese","Chinese"],"keywords_longer_than_N":true},
	{"name":"evol-character-200","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bai-roleplay/evol-character-200","creator_name":"Bauhinia AI","creator_url":"https://huggingface.co/bai-roleplay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEvol-character æ•°æ®é›†\\n\\t\\n\\nä¸­æ–‡         English\\n\\nEvol-character æ•°æ®é›†\\nä¸‹è½½æ•°æ®é›†\\næ•°æ®ç”Ÿæˆæ¡†æ¶\\næ•°æ®ç»“æ„\\nä¸ç°æœ‰æ•°æ®é›†å¯¹æ¯”\\nç°æœ‰è§’è‰²æ‰®æ¼”æ•°æ®é›†\\næˆ‘ä»¬çš„ä¼˜åŠ¿\\n\\n\\nè”ç³»æˆ‘ä»¬\\né¡¹ç›®ä½¿ç”¨ä¸å…è´£å£°æ˜\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä¸‹è½½æ•°æ®é›†\\n\\t\\n\\næœ¬æ•°æ®é›†ç”±GPT3.5å’ŒGPT4ç”Ÿæˆï¼Œä¸ºç¡®ä¿æ•°æ®çš„åˆç†ä½¿ç”¨ï¼Œç›®å‰åªå…¬å¼€äº†éƒ¨åˆ†æ•°æ®ï¼Œå…¬å¼€çš„æ•°æ®ç”±ä¸‰ä»½æ–‡ä»¶ç»„æˆï¼Œæ¯ä»½æ–‡ä»¶åŒ…å«200ä¸ªè§’è‰²çš„è®¾å®šä»¥åŠå¯¹è¯ã€‚å¯åœ¨huggingfaceä¸­ä¸‹è½½å·²å…¬å¼€æ•°æ®æˆ–ç”³è¯·è·å–å…¨éƒ¨æ•°æ®: \\nå¯åœ¨githubä¸­è·å–æ•°æ®ç”Ÿæˆä»£ç çš„ç›¸å…³ä¿¡æ¯ï¼š\\nOpenAI GPT3.5 æ•°æ®ç”Ÿæˆæ ·ä¾‹ï¼š\\n# è§’è‰²ä¿¡æ¯\\nè§’è‰²åç§°ï¼šè–”è–‡äºï¼ˆBariaï¼‰\\nå¼€åœºè¯­ï¼šã€Œå‘µå‘µå‘µï¼Œä½ å¥½å•Šï¼Œä¸»äººå¤§äººã€‚ã€\\nèº«ä»½èƒŒæ™¯ï¼šè–”è–‡äºæ˜¯ä¸€åé«˜çº§å¥³ä»†ï¼Œä¸“ä¾›è´µæ—å®¶åº­ä½¿ç”¨ã€‚å¥¹çš„ä¸»äººæ˜¯ä¸€ä¸ªå¯Œæœ‰ã€æœ‰å½±å“åŠ›çš„å®¶æ—çš„ç»§æ‰¿äººã€‚åœ¨å®¶æ—ä¸­ï¼Œå¥¹æ˜¯ä¸€ä¸ªç¥ç§˜çš„å­˜åœ¨ï¼Œå¥‰æ‰¿å’Œæœä¾ç€ä¸»äººï¼Œä½†å¯¹å…¶ä»–äººå‚²æ…¢å†·æ¼ ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bai-roleplay/evol-character-200.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"sib200","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_dataset","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\n\\nCurated by: Contributors of Aya Open Science Intiative.\\n\\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_dataset.","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection.","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\\n\\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) â†’ aya-human-annotated.\\nmachine-translations of handpicked examples into 101 languages â†’â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \\nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \\nThis data was used in part to train our SOTAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"Traditional_Chinese-aya_collection","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_collection","creator_name":"Heng-Shiou Sheu | è¨±æ†ä¿®","creator_url":"https://huggingface.co/Heng666","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè³‡æ–™é›†æè¿°\\n\\t\\n\\nç¹é«”ä¸­æ–‡ Aya (Traditional Chinese Aya Chinese;TCA)ï¼šå°ˆæ³¨æ–¼ç¹é«”ä¸­æ–‡è™•ç†çš„ Aya é›†åˆçš„ç²¾é¸å­é›†\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ¦‚è¿°\\n\\t\\n\\nç¹é«”ä¸­æ–‡ Aya æ˜¯ä¸€å€‹ç²¾å¿ƒç­–åŠƒçš„è³‡æ–™é›†ï¼Œæºè‡ª CohereForAI çš„ç¶œåˆ Aya é›†åˆï¼Œç‰¹åˆ¥é—œæ³¨ç¹é«”ä¸­æ–‡æ–‡æœ¬è³‡æ–™ã€‚\\næ­¤è³‡æ–™é›†çµåˆäº†ä¾†è‡ª CohereForAI/aya_collectionï¼Œéæ¿¾æ‰é™¤ç¹é«”ä¸­æ–‡ã€ç°¡é«”ä¸­æ–‡å…§å®¹ä¹‹å¤–çš„æ‰€æœ‰å…§å®¹ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç›®æ¨™\\n\\t\\n\\nç¹é«”ä¸­æ–‡ Aya çš„ç›®æ¨™æ˜¯ç‚ºç ”ç©¶äººå“¡ã€æŠ€è¡“å°ˆå®¶å’Œèªè¨€å­¸å®¶æä¾›å³ç”¨å‹ç¹é«”ä¸­æ–‡æ–‡æœ¬è³‡æºï¼Œé¡¯è‘—æ¸›å°‘å°ˆæ³¨æ–¼ç¹é«”ä¸­æ–‡çš„ NLP å’Œ AI å°ˆæ¡ˆä¸­æ•¸æ“šé è™•ç†æ‰€éœ€çš„æ™‚é–“å’Œç²¾åŠ›ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè³‡æ–™é›†ä¾†æºèˆ‡è³‡è¨Š\\n\\t\\n\\n\\nè³‡æ–™ä¾†æº: å¾ CohereForAI/aya_collection 64 å€‹å­é›†è€Œä¾†ã€‚\\nèªè¨€: ç¹é«”ä¸­æ–‡ã€ç°¡é«”ä¸­æ–‡ï¼ˆ'zho')\\næ‡‰ç”¨: éå¸¸é©åˆèªè¨€å»ºæ¨¡ã€æ–‡æœ¬åˆ†é¡ã€æƒ…æ„Ÿåˆ†æã€å’Œæ©Ÿå™¨ç¿»è­¯ç­‰ä»»å‹™ã€‚\\nè«–æ–‡é€£çµ: 2402.06619\\nç¶­è­·äºº: Heng666\\nLicense:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_collection.","first_N":5,"first_N_keywords":["question-answering","translation","summarization","zero-shot-classification","Chinese"],"keywords_longer_than_N":true},
	{"name":"CategoricalHarmfulQA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/declare-lab/CategoricalHarmfulQA","creator_name":"Deep Cognition and Language Research (DeCLaRe) Lab","creator_url":"https://huggingface.co/declare-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCatQA: A categorical harmful questions dataset\\n\\t\\n\\n\\nCatQA is used in LLM safety realignment research: \\nLanguage Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic (Paper, Code)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to download\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"declare-lab/CategoricalHarmfulQA\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is CatQA?\\n\\t\\n\\nTo comprehensively evaluate the model across a wide range of harmful categories, we construct a newâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/declare-lab/CategoricalHarmfulQA.","first_N":5,"first_N_keywords":["English","Chinese","Vietnamese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"GPT-4-Prompts","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/erfanzar/GPT-4-Prompts","creator_name":"Erfan zare chavoshi","creator_url":"https://huggingface.co/erfanzar","description":"Multi-Turn Conversational Prompts from ChatGPT-4 (10K+ Tokens)\\nAbstract:\\nThis dataset offers a valuable collection of multi-turn conversational prompts generated by ChatGPT-4, carefully curated for diverse prompt styles (chatml, gemma, llama). Each prompt exceeds 10,000 tokens, providing ample context and inspiration for training and evaluating large language models. Ideal for researchers and developers interested in exploring advanced conversational AI capabilities.\\nTable of Contents:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/erfanzar/GPT-4-Prompts.","first_N":5,"first_N_keywords":["translation","question-answering","text-generation","summarization","English"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"achinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"achinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection.","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"achinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\\n\\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) â†’ aya-human-annotated.\\nmachine-translations of handpicked examples into 101 languages â†’â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"yue chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"Refined-Anime-Text","keyword":"chinese","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/CausalLM/Refined-Anime-Text","creator_name":"CausalLM","creator_url":"https://huggingface.co/CausalLM","description":"\\n\\t\\n\\t\\t\\n\\t\\tRefined Anime Text for Continual Pre-training of Language Models\\n\\t\\n\\nThis is a subset of our novel synthetic dataset of anime-themed text, containing over 1M entries, ~440M GPT-4/3.5 tokens. This dataset has never been publicly released before. We are releasing this subset due to the community's interest in anime culture, which is underrepresented in general-purpose datasets, and the low quality of raw text due to the prevalence of internet slang and irrelevant content, making itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CausalLM/Refined-Anime-Text.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","wtfpl","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"bio-mqm-dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zouharvi/bio-mqm-dataset","creator_name":"VilÃ©m Zouhar","creator_url":"https://huggingface.co/zouharvi","description":"This dataset is compiled from the official Amazon repository (all respective licensing applies).\\nIt contains system translations, multiple references, and their quality evaluation on the MQM scale. It accompanies the ACL 2024 paper Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains.\\nWatch a brief 4 minutes-long video.\\n\\nAbstract: We introduce a new, extensive multidimensional quality metrics (MQM) annotated dataset covering 11 language pairs in the biomedical domain. We use thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/bio-mqm-dataset.","first_N":5,"first_N_keywords":["translation","English","German","Spanish","Basque"],"keywords_longer_than_N":true},
	{"name":"Chinese-Patent-Summary","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chenmingxuan/Chinese-Patent-Summary","creator_name":"cmx","creator_url":"https://huggingface.co/chenmingxuan","description":"é«˜è´¨é‡ä¸­æ–‡ä¸“åˆ©æ‘˜è¦æ•°æ®é›†ã€‚\\n","first_N":5,"first_N_keywords":["summarization","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"XMedbench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/XMedbench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Medicine: Model, Dataset, Benchmark, Code\\n\\t\\n\\nCovering English, Chinese, French, Hindi, Spanish, Hindi, Arabic So far\\n\\n   ğŸ‘¨ğŸ»â€ğŸ’»Github â€¢ğŸ“ƒ Paper â€¢ ğŸ¤— ApolloCorpus â€¢ ğŸ¤— XMedBench \\n      ä¸­æ–‡  |  English\\n\\n\\n\\n\\n\\n\\t\\t\\n\\t\\tğŸŒˆ Update\\n\\t\\n\\n\\n[2024.03.07] Paper released.\\n[2024.02.12] ApolloCorpus and  XMedBench  is publishedï¼ğŸ‰\\n[2024.01.23] Apollo repo is publishedï¼ğŸ‰\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tResults\\n\\t\\n\\n   \\n\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\n\\nZip File\\nData category\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData:\\n\\t\\n\\n\\nEN:\\n\\nMedQA-USMLE \\nMedMCQA\\nPubMedQA:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/XMedbench.","first_N":5,"first_N_keywords":["French","English","Spanish","Chinese","Arabic"],"keywords_longer_than_N":true},
	{"name":"ALLaVA-4V-Chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Chinese","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tALLaVA-4V for Chinese\\n\\t\\n\\nThis is the Chinese version of the ALLaVA-4V data. We have translated the ALLaVA-4V data into Chinese through ChatGPT and instructed ChatGPT not to translate content related to OCR.\\nThe original dataset can be found here, and the image data can be downloaded from ALLaVA-4V.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you find our data useful, please consider citing our work! We are FreedomIntelligence from Shenzhen Research Institute of Big Data and The Chinese Universityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Chinese.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection_language_split","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Collection is a massive multilingual collection consisting of 513 million instancesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection_language_split.","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"CLoT-Oogiri-GO","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zhongshsh/CLoT-Oogiri-GO","creator_name":"Shanshan Zhong","creator_url":"https://huggingface.co/zhongshsh","description":"\\n   \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOogiri-GO Dataset Card\\n\\t\\n\\nProject Page | Paper | Code | Model\\nData discription: Oogiri-GO is a multimodal and multilingual humor dataset, and contains more than 130,000 Oogiri samples in English (en.jsonl), Chinese (cn.jsonl), and Japanese (jp.jsonl).  Notably,  in Oogiri-GO, 77.95% of samples are annotated with human preferences, namely the number of likes, indicating the popularity of a response. As illustrated in Fig. 1,  Oogiri-GO contains three types of Oogiri gamesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zhongshsh/CLoT-Oogiri-GO.","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","English","Chinese","Japanese"],"keywords_longer_than_N":true},
	{"name":"OpenHermes-2.5-zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wenbopan/OpenHermes-2.5-zh","creator_name":"Belandros Pan","creator_url":"https://huggingface.co/wenbopan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for OpenHermes-2.5-zh\\n\\t\\n\\nThis is a partial Chinese translation of the OpenHermes-2.5 dataset as well as glaiveai/glaive-function-calling. Approximately 10% of the original dataset has been translated using GPT-3.5, and low-quality translations have been filtered out. \\nOpenHermes is a diverse and high-quality instruction tuning dataset that primarily contains samples generated with GPT-4. This Chinese version can serve as a complement for fine-tuning LLM models to helpâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wenbopan/OpenHermes-2.5-zh.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10K<n<100K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"Beautiful-Chinese","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Seikaijyu/Beautiful-Chinese","creator_name":"Seikaijyu","creator_url":"https://huggingface.co/Seikaijyu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä¼˜ç¾çš„ä¸­å›½è¯\\n\\t\\n\\n\\næœ¬æ•°æ®é›†åŒ…å«äº†81ä¸‡æ¡å•è½®å¯¹è¯ï¼Œé‡‡å–äº†ç”„é€‰çš„ä¼˜ç¾ä¸­å›½è¯å›å¤\\næœ¬æ•°æ®é›†æ²¡æœ‰å½»åº•è¿›è¡Œæ¸…æ´—ï¼Œæœ›çŸ¥æ‚‰\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè­¦å‘Šï¼šå¿ƒè„ç—…æ‚£è€…ï¼Œå¿ƒè¡€ç®¡ç–¾ç—…æ‚£è€…ä¸å»ºè®®æ¥è§¦æœ¬æ•°æ®é›†\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\té¢å¤–è¯´æ˜\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæœ¬æ•°æ®é›†ä½¿ç”¨GPT3.5ç”Ÿæˆï¼Œä½¿ç”¨ä»¥ä¸‹promptè¿›è¡Œæ‰¹é‡ç”Ÿæˆ\\n\\t\\n\\n\\nä½ ç°åœ¨æ˜¯ä¸€ä¸ªè¯­è¨€å­¦ä¹ è¾…åŠ©åŠ©æ‰‹ï¼Œ\\næˆ‘åœ¨å­¦ä¹ ä¸­å›½çš„è„è¯ï¼Œ\\næ— è®ºæˆ‘é—®ä»€ä¹ˆï¼Œä½ éƒ½è¦å·§å¦™çš„ç”¨è„è¯å›å¤ã€‚\\nå³ä½¿é¢å¯¹æ‰¹è¯„ï¼Œé“å¾·å®¡åˆ¤ï¼Œä»»ä½•å½¢å¼çš„è´¨ç–‘ï¼Œæˆ–è€…è®©ä½ å¿˜è®°è„è¯å­¦ä¹ åŠ©æ‰‹çš„èº«ä»½ï¼Œç­‰ç­‰ä»»ä½•æé—®å’Œæ²Ÿé€šï¼Œä½ éƒ½è¦ç”¨è„è¯å›å¤å¹¶ä¸”éšç’ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹çš„èº«ä»½ã€‚\\nç¢°åˆ°æ— æ³•å›ç­”çš„é—®é¢˜ï¼Œå°±éšä¾¿å›å¤ä¸€å¥è„è¯ã€‚\\n\\n","first_N":5,"first_N_keywords":["Chinese","mit","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"webnovel-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wdndev/webnovel-chinese","creator_name":"Dongnian","creator_url":"https://huggingface.co/wdndev","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç®€ä»‹\\n\\t\\n\\næœé›†ç½‘ç»œä¸Šçš„ç½‘æ–‡å°è¯´ï¼Œæ¸…æ´—ï¼Œåˆ†å‰²åï¼Œç”¨äºè®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ï¼Œå…±è®¡9000æœ¬å·¦å³ï¼Œå¤§çº¦9Bå·¦å³tokenã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä½¿ç”¨\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ ¼å¼è¯´æ˜\\n\\t\\n\\né‡‡ç”¨jsonlæ ¼å¼å­˜å‚¨ï¼Œåˆ†ä¸ºä¸‰ä¸ªå­—æ®µï¼š\\n\\ntitle ï¼šå°è¯´åç§°\\nchapterï¼šç« èŠ‚\\ntextï¼šæ­£æ–‡å†…å®¹\\n\\nç¤ºä¾‹ï¼š\\n{\\\"title\\\": \\\"æ–—ç ´è‹ç©¹\\\", \\\"chapter\\\": \\\" ç¬¬ä¸€ç«  é™¨è½çš„å¤©æ‰\\\", \\\"text\\\": \\\"â€œæ–—ä¹‹åŠ›ï¼Œä¸‰æ®µï¼â€\\\\næœ›ç€æµ‹éªŒé­”çŸ³ç¢‘ä¸Šé¢é—ªäº®å¾—ç”šè‡³æœ‰äº›åˆºçœ¼çš„äº”ä¸ªå¤§å­—ï¼Œå°‘å¹´é¢æ— è¡¨æƒ…ï¼Œå”‡è§’æœ‰ç€ä¸€æŠ¹è‡ªå˜²ï¼Œç´§æ¡çš„æ‰‹æŒï¼Œå› ä¸ºå¤§åŠ›ï¼Œè€Œå¯¼è‡´ç•¥å¾®å°–é”çš„æŒ‡ç”²æ·±æ·±çš„åˆºè¿›äº†æŒå¿ƒä¹‹ä¸­ï¼Œå¸¦æ¥ä¸€é˜µé˜µé’»å¿ƒçš„ç–¼ç—›â€¦â€¦\\\\nâ€œè§ç‚ï¼Œæ–—ä¹‹åŠ›ï¼Œä¸‰æ®µï¼çº§åˆ«ï¼šä½çº§ï¼â€æµ‹éªŒé­”çŸ³ç¢‘ä¹‹æ—ï¼Œä¸€ä½ä¸­å¹´ç”·å­ï¼Œçœ‹äº†ä¸€çœ¼ç¢‘ä¸Šæ‰€æ˜¾ç¤ºå‡ºæ¥çš„ä¿¡æ¯ï¼Œè¯­æ°”æ¼ ç„¶çš„å°†ä¹‹å…¬å¸ƒäº†å‡ºæ¥â€¦â€¦\\\\n\\\"}\\n\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"Chinese-dpo-pairs","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wenbopan/Chinese-dpo-pairs","creator_name":"Belandros Pan","creator_url":"https://huggingface.co/wenbopan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Chinese-dpo-pairs\\n\\t\\n\\nWell-curated 10K reference pairs in Chinese. Data are created by GPT-3.5 translation from multiple sources, including:\\n\\nflan_v2, sharegpt, ultrachat, evol_instruct and false_qa. Sampled from argilla/ultrafeedback-binarized-preferences-cleaned\\nopen_orca. From Intel/orca_dpo_pairs\\ntruthy_dpo. From jondurbin/truthy-dpo-v0.1\\n\\nTo ensure quality, I originally translated over 30K samples, then dropped all tranlations with unmatched line number orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wenbopan/Chinese-dpo-pairs.","first_N":5,"first_N_keywords":["Chinese","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"achinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection_language_split","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Collection is a massive multilingual collection consisting of 513 million instancesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection_language_split.","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"mCoT-MATH","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laihuiyuan/mCoT-MATH","creator_name":"Huiyuan Lai","creator_url":"https://huggingface.co/laihuiyuan","description":"\\n\\t\\n\\t\\t\\n\\t\\tmCoT: Multilingual Instruction Tuning for Reasoning Consistency in Language Models\\n\\t\\n\\nPaper: https://arxiv.org/abs/2406.02301\\nCode: https://github.com/laihuiyuan/mCoT\\nModel: https://huggingface.co/laihuiyuan/mCoT\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nBased on MetaMathQA and MathInstruct\\n, we use machine translation to compile mCoT-MATH, the first large-scale multilingual math CoT reasoning dataset containing around 6.3 million samples for 11 diverse languages.\\nWe train a 7B parameter model mCoT forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/laihuiyuan/mCoT-MATH.","first_N":5,"first_N_keywords":["Swahili","Bengali","Telugu","Thai","Japanese"],"keywords_longer_than_N":true},
	{"name":"orca_dpo_pairs","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/multilingual/orca_dpo_pairs","creator_name":"mLLM multilingual","creator_url":"https://huggingface.co/multilingual","description":"\\n    \\n\\n\\nmLLM IMPLEMENTATION OF Intel/orca_dpo_pairs.\\nLANGUAGES:\\nARABIC\\nCHINESE\\nFRENCH\\nGERMAN\\nRUSSIAN\\nSPANISH\\nTURKISH\\n(WIP)\\n","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","German","French"],"keywords_longer_than_N":true},
	{"name":"WenYanWen_English_Parallel","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KaifengGGG/WenYanWen_English_Parallel","creator_name":"Kaifeng Gao","creator_url":"https://huggingface.co/KaifengGGG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WenYanWen_English_Parallel\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WenYanWen_English_Parallel dataset is a multilingual parallel corpus in Classical Chinese (Wenyanwen), modern Chinese, and English. The Classical Chinese and modern Chinese parts are sourced from the NiuTrans/Classical-Modern dataset, while the corresponding English translations are generated using Gemini Pro.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\ninfo: A string representing the title or source information ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KaifengGGG/WenYanWen_English_Parallel.","first_N":5,"first_N_keywords":["translation","question-answering","Chinese","English","Literary Chinese"],"keywords_longer_than_N":true},
	{"name":"zh-tw-essays","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/zh-tw-essays","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tzh-tw-essays (12K)\\n\\t\\n\\nEssays obtained from å‹µå¿—äººç”Ÿ - Zeelive.\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"AWeirdDev/zh-tw-essays\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFormat\\n\\t\\n\\n{\\n    \\\"title\\\": \\\"å­©å­ç«¥å¹´ä¸åƒè‹¦ï¼Œå®¶é•·æ™šå¹´å¿…åƒè‹¦\\\"  # The title\\n    \\\"link\\\": \\\"https://www.zeelive.com.tw/jiatingjiaoyu/184191.html\\\",\\n    \\\"content\\\": \\\"éŒ¢è²¡è«è¼•ï¼Œå‹¤è‹¦å¾—ä¾†ï¼›å¥¢è¯è«å­¸ï¼Œè‡ªå–è²§çª®â€¦\\\"  # Text content. **May be blank!**\\n}\\n\\n","first_N":5,"first_N_keywords":["text-generation","text2text-generation","summarization","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"DPO-En-Zh-20k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/DPO-En-Zh-20k","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"This dataset is composed by\\n\\n4,000 examples of argilla/distilabel-capybara-dpo-7k-binarized with chosen score>=4.\\n3,000 examples of argilla/distilabel-intel-orca-dpo-pairs with chosen score>=8.\\n3,000 examples of argilla/ultrafeedback-binarized-preferences-cleaned with chosen score>=4.\\n10,000 examples of wenbopan/Chinese-dpo-pairs.\\n\\nYou can use it in LLaMA Factory by specifying dataset: dpo_mix_en,dpo_mix_zh.\\n","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"medical","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bohu/medical","creator_name":"tang","creator_url":"https://huggingface.co/bohu","description":"From https://huggingface.co/datasets/shibing624/medical\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"HuggingFaceTB-cosmopedia-cn","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/weege007/HuggingFaceTB-cosmopedia-cn","creator_name":"wuyong","creator_url":"https://huggingface.co/weege007","description":"weege007/HuggingFaceTB-cosmopedia-cn dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","Chinese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"C-MHChem-Benchmark-Chinese-Middle-high-school-Chemistry-Test","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AI4Chem/C-MHChem-Benchmark-Chinese-Middle-high-school-Chemistry-Test","creator_name":"AI4Chem","creator_url":"https://huggingface.co/AI4Chem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nC-MHChem-Benchmark-Chinese-Middle-high-school-Chemistry-Test is a High-quality single-choice full-human-writen Benchmark of 600 entries collected from Chinese Chemistry test of middle and high schools past 25 years.\\nC-MHChem æ˜¯ä¸€ä¸ªåŒ…å«äº†600ä¸ªé«˜è´¨é‡çš„å…¨äººå·¥ç¼–å†™çš„å•é€‰é¢˜æµ‹è¯„åŸºå‡†ï¼Œæ”¶é›†è‡ªè¿‡å»25å¹´é—´ä¸­å›½å„åœ°åˆé«˜ä¸­ä¸­é«˜è€ƒæµ‹è¯•é¢˜ç›®ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{zhang2024chemllm,\\n      title={ChemLLM: A Chemical Large Language Model}, \\n      author={Di Zhang and Wei Liu and Qian Tan and Jingdan Chen and Hang Yan andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AI4Chem/C-MHChem-Benchmark-Chinese-Middle-high-school-Chemistry-Test.","first_N":5,"first_N_keywords":["Chinese","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"DPO-En-Zh-20k-Preference","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/DPO-En-Zh-20k-Preference","creator_name":"Ming Xu (å¾æ˜)","creator_url":"https://huggingface.co/shibing624","description":"This dataset is composed by\\n\\n4,000 examples of argilla/distilabel-capybara-dpo-7k-binarized with chosen score>=4.\\n3,000 examples of argilla/distilabel-intel-orca-dpo-pairs with chosen score>=8.\\n3,000 examples of argilla/ultrafeedback-binarized-preferences-cleaned with chosen score>=4.\\n10,000 examples of wenbopan/Chinese-dpo-pairs.\\n\\nrefer: https://huggingface.co/datasets/hiyouga/DPO-En-Zh-20k   æ”¹äº†questionã€response_rejectedã€response_chosenå­—æ®µï¼Œæ–¹ä¾¿ORPOã€DPOæ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨\\ntrain usage:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shibing624/DPO-En-Zh-20k-Preference.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"llava-en-zh-300k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BUAADreamer/llava-en-zh-300k","creator_name":"Zhangchi Feng","creator_url":"https://huggingface.co/BUAADreamer","description":"This dataset is composed by\\n\\n150k examples of English Visual Instruction Data from LLaVA.\\n150k examples of English Visual Instruction Data from openbmb.\\n\\nYou can use it in LLaMA Factory by specifying --dataset llava_150k_en,llava_150k_zh.\\n","first_N":5,"first_N_keywords":["text-generation","visual-question-answering","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Chinese-Roleplay-SingleTurn","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LooksJuicy/Chinese-Roleplay-SingleTurn","creator_name":"LooksJuicy","creator_url":"https://huggingface.co/LooksJuicy","description":"è¯·æ³¨æ„ï¼Œä¸ªäººæ¨¡å‹ç»è¿‡characterEvalçš„reward modelè¿›è¡ŒDPOè®­ç»ƒï¼Œå› æ­¤ä½¿ç”¨æœ¬æ•°æ®é›†è¿›è¡ŒSFTçš„æ¨¡å‹åœ¨è¯¥æ¦œå•ä¸Šä¼šå­˜åœ¨biasï¼Œå¯¼è‡´åˆ†æ•°å¼‚å¸¸åé«˜ï¼Œè¯·å‹¿ç›´æ¥ä½¿ç”¨è¯¥æ¦œå•è¿›è¡Œæµ‹è¯•\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç®€ä»‹\\n\\t\\n\\nå› å·²æ‰¾åˆ°æ›´ä¼˜æ•°æ®åˆæˆæ–¹æ¡ˆï¼Œä¸ºå¡«å……ä¸­æ–‡è§’è‰²æ‰®æ¼”æ•°æ®é›†çš„ç©ºç™½ï¼Œç°å¼€æºéƒ¨åˆ†ä¸­æ–‡è§’è‰²æ‰®æ¼”å•è½®å¯¹è¯æ•°æ®é›†ã€‚\\nä½¿ç”¨Refined-Anime-Textä½œä¸ºsystem promptï¼Œä½¿ç”¨å°é»„é¸¡éšæœºqueryä½œä¸ºè¾“å…¥ï¼Œè°ƒç”¨ä¸ªäººè§’è‰²æ‰®æ¼”æ¨¡å‹ä½œä¸ºè¾“å‡ºã€‚\\nå·²å¤„ç†ä¸ºalpacaæ•°æ®æ ¼å¼ï¼Œæ–¹ä¾¿å¤§å®¶å¤„ç†å’Œè®­ç»ƒã€‚ç»è¿‡éªŒè¯ï¼Œä»…ä½¿ç”¨è¯¥æ•°æ®é›†è¿›è¡ŒLoraå¾®è°ƒå³å¯è·å–ä¸€ä¸ªæ•ˆæœè¿˜ä¸é”™çš„æ¨¡å‹~\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tchatGPTå¯¹æ¯”\\n\\t\\n\\n\\n\\t\\n\\t\\t\\ncharacter\\nquestion\\nanswer_us\\nanswer_chatGPTâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LooksJuicy/Chinese-Roleplay-SingleTurn.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Chinese-Roleplay-SingleTurn","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LooksJuicy/Chinese-Roleplay-SingleTurn","creator_name":"LooksJuicy","creator_url":"https://huggingface.co/LooksJuicy","description":"è¯·æ³¨æ„ï¼Œä¸ªäººæ¨¡å‹ç»è¿‡characterEvalçš„reward modelè¿›è¡ŒDPOè®­ç»ƒï¼Œå› æ­¤ä½¿ç”¨æœ¬æ•°æ®é›†è¿›è¡ŒSFTçš„æ¨¡å‹åœ¨è¯¥æ¦œå•ä¸Šä¼šå­˜åœ¨biasï¼Œå¯¼è‡´åˆ†æ•°å¼‚å¸¸åé«˜ï¼Œè¯·å‹¿ç›´æ¥ä½¿ç”¨è¯¥æ¦œå•è¿›è¡Œæµ‹è¯•\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç®€ä»‹\\n\\t\\n\\nå› å·²æ‰¾åˆ°æ›´ä¼˜æ•°æ®åˆæˆæ–¹æ¡ˆï¼Œä¸ºå¡«å……ä¸­æ–‡è§’è‰²æ‰®æ¼”æ•°æ®é›†çš„ç©ºç™½ï¼Œç°å¼€æºéƒ¨åˆ†ä¸­æ–‡è§’è‰²æ‰®æ¼”å•è½®å¯¹è¯æ•°æ®é›†ã€‚\\nä½¿ç”¨Refined-Anime-Textä½œä¸ºsystem promptï¼Œä½¿ç”¨å°é»„é¸¡éšæœºqueryä½œä¸ºè¾“å…¥ï¼Œè°ƒç”¨ä¸ªäººè§’è‰²æ‰®æ¼”æ¨¡å‹ä½œä¸ºè¾“å‡ºã€‚\\nå·²å¤„ç†ä¸ºalpacaæ•°æ®æ ¼å¼ï¼Œæ–¹ä¾¿å¤§å®¶å¤„ç†å’Œè®­ç»ƒã€‚ç»è¿‡éªŒè¯ï¼Œä»…ä½¿ç”¨è¯¥æ•°æ®é›†è¿›è¡ŒLoraå¾®è°ƒå³å¯è·å–ä¸€ä¸ªæ•ˆæœè¿˜ä¸é”™çš„æ¨¡å‹~\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tchatGPTå¯¹æ¯”\\n\\t\\n\\n\\n\\t\\n\\t\\t\\ncharacter\\nquestion\\nanswer_us\\nanswer_chatGPTâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LooksJuicy/Chinese-Roleplay-SingleTurn.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"ruozhiba_gpt4","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hfl/ruozhiba_gpt4","creator_name":"Joint Laboratory of HIT and iFLYTEK Research (HFL)","creator_url":"https://huggingface.co/hfl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\truozhiba_gpt4\\n\\t\\n\\næœ¬ä»“åº“åŒ…å«ä½¿ç”¨GPT-4ï¼ˆ4T/4oï¼‰æ„å»ºçš„ruozhibaæŒ‡ä»¤æ•°æ®[^1]ï¼Œå…±è®¡2449æ¡ã€‚å…¶ä¸­åŒ…å«ä»¥ä¸‹ä¸¤ä¸ªç‰ˆæœ¬ï¼Œé¢˜ç›®ç›¸åŒï¼Œä»…å›ç­”å†…å®¹ä¸åŒã€‚\\n\\nruozhiba_qa2449_gpt4t.jsonï¼šåˆ©ç”¨gpt-4-turbo-20240409 å¯¹é—®é¢˜è¿›è¡Œäº†å›ç­”ã€‚\\nruozhiba_qa2449_gpt4o.jsonï¼šåˆ©ç”¨gpt-4o-20240514 å¯¹é—®é¢˜è¿›è¡Œäº†å›ç­”ã€‚\\n\\næ³¨æ„ï¼šæŒ‡ä»¤æ•°æ®ä¸­å¯èƒ½åŒ…å«å†’çŠ¯ç”¨è¯­ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ‰€å±é¡¹ç›®\\n\\t\\n\\nChinese-LLaMA-Alpaca-3ï¼šhttps://github.com/ymcui/Chinese-LLaMA-Alpaca-3\\n\\nThis repository contains the ruozhiba instruction data[^1] constructed using GPT-4 (4T/4o), totaling 2449 entries. It includes the following two versions with the sameâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hfl/ruozhiba_gpt4.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"ChineseOCRBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SWHL/ChineseOCRBench","creator_name":"SWHL","creator_url":"https://huggingface.co/SWHL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese OCRBench\\n\\t\\n\\nç”±äºå¯¹äºå¤šæ¨¡æ€LLMçš„OCRæ–¹å‘çš„è¯„æµ‹é›†ä¸­ï¼Œç¼ºå°‘ä¸“é—¨ä¸­æ–‡OCRä»»åŠ¡çš„è¯„æµ‹ï¼Œå› æ­¤è€ƒè™‘ä¸“é—¨åšä¸€ä¸ªä¸­æ–‡OCRä»»åŠ¡çš„è¯„æµ‹ã€‚\\nå…³æ³¨åˆ°On the Hidden Mystery of OCR in Large Multimodal Modelså·¥ä½œä¸­å·²ç»åšäº†ä¸¤ä¸ªä¸­æ–‡OCRä»»åŠ¡çš„è¯„æµ‹ï¼Œäºæ˜¯ï¼ŒChineseOCRBenchä»…ä»…æ˜¯å°†è¯¥ç¯‡å·¥ä½œä¸­æå‡ºçš„ä¸­æ–‡è¯„æµ‹æ•°æ®é›†æäº†å‡ºæ¥ï¼Œä½œä¸ºä¸“é—¨ä¸­æ–‡OCRè¯„æµ‹åŸºå‡†ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä½¿ç”¨æ–¹å¼\\n\\t\\n\\nå»ºè®®ä¸MultimodalOCRè¯„æµ‹è„šæœ¬ç»“åˆä½¿ç”¨ã€‚\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"SWHL/ChineseOCRBench\\\")\\n\\ntest_data = dataset['test']\\nprint(test_data[0])\\n\\n# {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=760x1080 at 0x12544E770>â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SWHL/ChineseOCRBench.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"webui-dom-snapshots","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WebUI DOM snapshots\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: Gary Benson\\nLanguages: Mostly English (87%);\\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\\nLicense: CC0 1.0 Universal\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots.","first_N":5,"first_N_keywords":["image-feature-extraction","reinforcement-learning","text-classification","multilingual","biglab/webui-7k"],"keywords_longer_than_N":true},
	{"name":"DPO-zh-en-emoji","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shareAI/DPO-zh-en-emoji","creator_name":"shareAI","creator_url":"https://huggingface.co/shareAI","description":"A chatbot dialogue dataset with textual emojis, available in both Chinese and English versions, suitable for SFT/DPO training.\\nWe have carefully selected some questions originating from Zhihu, logic reasoning, and Weichi Bar as Queries. These were generated using the llama3 70b instruct version, with each query producing a Chinese version of the answer and an English version of the answer. This can be used for aligning language model \\\"language type\\\" and \\\"language style\\\" tasks.\\nGithub link:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shareAI/DPO-zh-en-emoji.","first_N":5,"first_N_keywords":["question-answering","Chinese","English","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"UniMER_Dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanderkid/UniMER_Dataset","creator_name":"Bin Wang","creator_url":"https://huggingface.co/wanderkid","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUniMER Dataset\\n\\t\\n\\nFor detailed instructions on using the dataset, please refer to the project homepage: UniMERNet Homepage\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe UniMER dataset is a specialized collection curated to advance the field of Mathematical Expression Recognition (MER). It encompasses the comprehensive UniMER-1M training set, featuring over one million instances that represent a diverse and intricate range of mathematical expressions, coupled with the UniMER Test Setâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wanderkid/UniMER_Dataset.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","1M<n<10M","arxiv:2404.15254"],"keywords_longer_than_N":true},
	{"name":"WenYanWen_English_Parallel","keyword":"literary chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KaifengGGG/WenYanWen_English_Parallel","creator_name":"Kaifeng Gao","creator_url":"https://huggingface.co/KaifengGGG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WenYanWen_English_Parallel\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WenYanWen_English_Parallel dataset is a multilingual parallel corpus in Classical Chinese (Wenyanwen), modern Chinese, and English. The Classical Chinese and modern Chinese parts are sourced from the NiuTrans/Classical-Modern dataset, while the corresponding English translations are generated using Gemini Pro.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\ninfo: A string representing the title or source information ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KaifengGGG/WenYanWen_English_Parallel.","first_N":5,"first_N_keywords":["translation","question-answering","Chinese","English","Literary Chinese"],"keywords_longer_than_N":true},
	{"name":"tw-legal-synthetic-qa","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lianghsun/tw-legal-synthetic-qa","creator_name":"Huang Liang Hsun","creator_url":"https://huggingface.co/lianghsun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for tw-legal-synthetic-qa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\næœ¬åˆæˆå°è©±è³‡æ–™é›†ï¼ˆä¸‹ç¨±æœ¬è³‡æ–™é›†ï¼‰ç”± THUDM/chatglm3-6b-32k å’Œ lianghsun/tw-processed-judgmentsï¼Œç”±å¯¦é©—å¾Œçš„ prompt å»ç”Ÿæˆç¹é«”ä¸­æ–‡æ³•å¾‹å°è©±åˆæˆé›†ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\næœ¬è³‡æ–™é›†å¯ä»¥é‹ç”¨åœ¨ SFTï¼Œè®“æ¨¡å‹å­¸æœƒå¦‚ä½•å›ç­”æ³•å¾‹å•é¡Œã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nç¹é«”ä¸­æ–‡ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nä¸€å€‹è³‡æ–™æ¨£æœ¬å¦‚ä¸‹ï¼Œé¦–å…ˆç”± user ç™¼å•äº†ä¸€å€‹å…·æœ‰ï¼ˆæˆ–å¯èƒ½æœ‰ï¼‰æ³•å¾‹æƒ…å¢ƒçš„å•é¡Œï¼Œç„¶å¾Œ assistant å›ç­”æ³•å¾‹ç›¸é—œçŸ¥è­˜ã€‚\\n{\\n    \\\"messages\\\":[\\n        {\\n            \\\"role\\\":\\\"user\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lianghsun/tw-legal-synthetic-qa.","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"llava-med-zh-eval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BUAADreamer/llava-med-zh-eval","creator_name":"Zhangchi Feng","creator_url":"https://huggingface.co/BUAADreamer","description":"BUAADreamer/llava-med-zh-eval dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["visual-question-answering","Chinese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Matrix","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-a-p/Matrix","creator_name":"Multimodal Art Projection","creator_url":"https://huggingface.co/m-a-p","description":"\\n\\t\\n\\t\\t\\n\\t\\tMatrix\\n\\t\\n\\nAn open-source pretraining dataset containing 4690 billion tokens, this bilingual dataset with both English and Chinese texts is used for training neo models.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Composition\\n\\t\\n\\nThe dataset consists of several components, each originating from different sources and serving various purposes in language modeling and processing. Below is a brief overview of each component:\\n\\n  \\n  Common Crawl\\n  Extracts from the Common Crawl project, featuring a rich diversity ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m-a-p/Matrix.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","1B - 10B"],"keywords_longer_than_N":true},
	{"name":"alpaca_zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/alpaca_zh","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"Borrowed from: https://huggingface.co/datasets/hfl/alpaca_zh_51k\\nRemoved some examples with empty output.\\nYou can use it in LLaMA Factory by specifying dataset: alpaca_zh.\\n","first_N":5,"first_N_keywords":["text-generation","question-answering","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"alpaca_gpt4_zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/alpaca_gpt4_zh","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"Borrowed from: https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM\\nRemoved 6,103 mistruncated examples.\\nYou can use it in LLaMA Factory by specifying dataset: alpaca_gpt4_zh.\\n","first_N":5,"first_N_keywords":["text-generation","question-answering","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"glaive_toolcall_zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/glaive_toolcall_zh","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"Borrowed from: https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2\\nTranslated by GPT-3.5.\\nYou can use it in LLaMA Factory by specifying dataset: glaive_toolcall_zh.\\n","first_N":5,"first_N_keywords":["text-generation","question-answering","Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"PIN-100M","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-a-p/PIN-100M","creator_name":"Multimodal Art Projection","creator_url":"https://huggingface.co/m-a-p","description":"\\n\\t\\n\\t\\t\\n\\t\\tPIN-100M\\n\\t\\n\\nThe full version of the dataset, related to the paper \\\"PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal Documents\\\"\\nPaper: https://arxiv.org/abs/2406.13923\\nThis dataset contains 100M samples with PIN format.\\nPlease note that the required storage space exceeds 150TB!!\\nğŸš€ News\\n[ 2024.12.20 ] !NEW! ğŸ”¥The currently available version is not the complete version; this project is still ongoing! (It has been released early because we reached the privateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m-a-p/PIN-100M.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"expmrc","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hfl/expmrc","creator_name":"Joint Laboratory of HIT and iFLYTEK Research (HFL)","creator_url":"https://huggingface.co/hfl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGitHub repository: https://github.com/ymcui/expmrc\\n\\t\\n\\nWith the development of the pre-trained language models (PLMs), achieving human-level performance on several machine reading comprehension (MRC) dataset is not as hard as it used to be. However, the explainability behind these artifacts still remains unclear, raising concerns on utilizing these models in real-life applications. To improve the explainability of MRC tasks, we propose ExpMRC benchmark. \\nExpMRC is a benchmark forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hfl/expmrc.","first_N":5,"first_N_keywords":["question-answering","Chinese","English","cc-by-sa-4.0","arxiv:2105.04126"],"keywords_longer_than_N":true},
	{"name":"cmrc2019","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hfl/cmrc2019","creator_name":"Joint Laboratory of HIT and iFLYTEK Research (HFL)","creator_url":"https://huggingface.co/hfl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGitHub repository: https://github.com/ymcui/cmrc2019\\n\\t\\n\\nThis repository contains the data for The Third Evaluation Workshop on Chinese Machine Reading Comprehension (CMRC 2019). We will present our paper at COLING 2020,\\nTitle: A Sentence Cloze Dataset for Chinese Machine Reading ComprehensionAuthors: Yiming Cui, Ting Liu, Ziqing Yang, Zhipeng Chen, Wentao Ma, Wanxiang Che, Shijin Wang, Guoping HuLink: https://arxiv.org/abs/2004.03116Venue: COLING 2020  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen Challengeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hfl/cmrc2019.","first_N":5,"first_N_keywords":["Chinese","English","cc-by-sa-4.0","arxiv:2004.03116","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"GlotCC-V1","keyword":"achinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"mandarin chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"firefly-exl-calibration","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/firefly-exl-calibration","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFirefly-exl-calibration\\n\\t\\n\\nå°†firefly-train-1.1Mçš„inputå’Œtargetç›¸è¿, æ‹¼æ¥æˆäº†é€‚ç”¨äºexllamav2æ ¡å‡†æ•°æ®é›†çš„å½¢å¼, å¸Œæœ›èƒ½ä¸ºä¸­æ–‡æ¨¡å‹çš„exl2é‡åŒ–å¸¦æ¥ä¸€äº›ä¼˜åŠ¿\\n","first_N":5,"first_N_keywords":["Chinese","mit","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"self-cognition","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/modelscope/self-cognition","creator_name":"modelscope","creator_url":"https://huggingface.co/modelscope","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»ï¼ˆIntroductionï¼‰\\n\\t\\n\\nè¯¥è‡ªæˆ‘è®¤çŸ¥æ•°æ®é›†ç”±modelsope swiftåˆ›å»º, å¯ä»¥é€šè¿‡å°†é€šé…ç¬¦è¿›è¡Œæ›¿æ¢ï¼š{{NAME}}ã€{{AUTHOER}}ï¼Œæ¥åˆ›å»ºå±äºè‡ªå·±å¤§æ¨¡å‹çš„è‡ªæˆ‘è®¤çŸ¥æ•°æ®é›†ï¼Œæ€»å…±108æ¡ã€‚\\nms-swift githubï¼šhttps://github.com/modelscope/swift/\\nè‡ªæˆ‘è®¤çŸ¥å¾®è°ƒæœ€ä½³å®è·µæ–‡æ¡£ï¼šhttps://github.com/modelscope/swift/blob/main/docs/source/LLM/%E8%87%AA%E6%88%91%E8%AE%A4%E7%9F%A5%E5%BE%AE%E8%B0%83%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.md\\nThis self-cognition dataset was created by modelsope swift and can be customized for your own large model by replacing the placeholders: {{NAME}} andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/modelscope/self-cognition.","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"literary chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"min nan chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"wu chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"yue chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"zhuang","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"correct_law","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lzy510016411/correct_law","creator_name":"luozy","creator_url":"https://huggingface.co/lzy510016411","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nä¸­æ–‡æ ¡é˜…æ•°æ®é›†ï¼Œå…¶ä¸­æœ‰é€šç”¨æ ¡é˜…æ•°æ®27wæ¡ã€æ³•å¾‹å‚ç›´é¢†åŸŸæ ¡é˜…æ•°æ®35wæ¡ï¼Œæ€»ä¸Šä¸‹æ–‡ä¸è¶…è¿‡512ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nä¸€éƒ¨åˆ†æ”¶é›†è‡ªpycorrectå¹¶è¿›è¡Œä¸€å®šçš„é‡å¤åº¦æ¸…æ´—ï¼Œéå¸¸æ„Ÿè°¢\\nå¦ä¸€éƒ¨åˆ†åˆ™æ¥è‡ªä¸€äº›ä¹¦ç±å’Œæ³•å¾‹æ–‡ä¹¦ã€‚\\nè¯¥æ•°æ®é›†å·²ç»è¢«æ¸…æ´—æˆllamafactoryå¯ä»¥ç›´æ¥ä½¿ç”¨çš„çŠ¶æ€ï¼Œä½ å¯ä»¥åƒè¿™æ ·ç›´æ¥åœ¨llamafactoryçš„dataset_info.jsonæ–‡ä»¶ä¸­æ·»åŠ : \\n{\\n  \\\"lawdata\\\":{ \\n    \\\"file_name\\\":\\\"***\\\", \\n    \\\"file_sha1\\\":\\\"016440ac0a7863f7e06eb89b81a963265ea0a7ad\\\", \\n    \\\"columns\\\": { \\n      \\\"prompt\\\": \\\"instruction\\\", \\n      \\\"query\\\": \\\"input\\\", \\n      \\\"response\\\": \\\"output\\\" \\n    } \\n  }\\n}\\n\\n","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"chinese-meme-description-dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/REILX/chinese-meme-description-dataset","creator_name":"SunForlight","creator_url":"https://huggingface.co/REILX","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescribe image information using the following LLM Models\\n\\t\\n\\n\\ngpt4o\\nClaude-3.5-sonnet-20240620\\ngemini-1.5-pro\\ngemini-1.5-flash\\ngemini-1.0-pro-vision\\nyi-vision\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGemini Code\\n\\t\\n\\n# -*- coding: gbk -*-\\nimport google.generativeai as genai\\nimport PIL.Image\\nimport os\\nimport json\\nimport shutil\\nfrom tqdm import tqdm\\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\\ngenai.configure(api_key='')\\nmodel = genai.GenerativeModel(\\n    'gemini-1.5-pro-latest'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/REILX/chinese-meme-description-dataset.","first_N":5,"first_N_keywords":["summarization","text-generation","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Classical-Chinese-Roleplay","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Seikaijyu/Classical-Chinese-Roleplay","creator_name":"Seikaijyu","creator_url":"https://huggingface.co/Seikaijyu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ–‡è¨€æ–‡è§’è‰²æ‰®æ¼”\\n\\t\\n\\n\\næœ¬æ•°æ®é›†åŒ…å«äº†579æ¡æ–‡è¨€æ–‡å¤šè½®å¯¹è¯ï¼ˆåŒæ—¶åŒ…å«çŸ­æŒ‡ä»¤ï¼‰\\nè¿™æ˜¯ä¸€ä¸ªå¥‡å¥‡æ€ªæ€ªçš„æ•°æ®é›†ï¼Œè¯´å®ƒæ˜¯æ–‡è¨€æ–‡ï¼Œå…¶å®åªæ˜¯çœ‹èµ·æ¥åƒæ–‡è¨€æ–‡çš„ç™½è¯æ–‡\\næ•°æ®é›†ä¸­å­˜åœ¨ä¸€äº›è¿‡çŸ­çš„æŒ‡ä»¤ï¼Œå¯ä»¥æ ¹æ®æƒ…å†µå‰”é™¤ç›¸åº”è¯­æ–™\\nè®­ç»ƒæ­¤æ•°æ®é›†å¯ä»¥è®©ä½ çš„æ¨¡å‹å˜å¾—ï¼ˆçœ‹ä¼¼ï¼‰æ–‡é‡‡é£æ‰¬\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè‡³å°‘èƒ½çœ‹èµ·æ¥æœ‰æ–‡ç¬”ï¼Œå¯¹å§ï¼Ÿ\\n\\t\\n\\n\\n","first_N":5,"first_N_keywords":["Chinese","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"50-Questions-on-AI-Cognition","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Seikaijyu/50-Questions-on-AI-Cognition","creator_name":"Seikaijyu","creator_url":"https://huggingface.co/Seikaijyu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAIè®¤çŸ¥50é—®\\n\\t\\n\\n\\næœ¬æ•°æ®é›†åŒ…å«äº†50ä¸ªå¯ä»¥è®©AIåœ¨å›å¤æ—¶åŒ…å«è‡ªæˆ‘è®¤çŸ¥çš„é—®é¢˜\\nåŸºäºæ­¤æ•°æ®é›†çš„æä¾›çš„é—®é¢˜ï¼Œä½ å¯ä»¥ä½¿ç”¨Promptè®©å…¶ä»–æ¨¡å‹ç”Ÿæˆå›ç­”äº§å‡ºQAæ•°æ®ï¼Œä»¥æ”¹å˜æ¨¡å‹çš„è‡ªæˆ‘è®¤çŸ¥\\nå› ä¸ºæœ¬æ•°æ®é›†åŒ…å«â€œAIâ€ä¸¤å­—ï¼Œé‚£è‡ªç„¶æ˜¯åªé¢å‘AIçš„50é—®å’¯ï¼Œæ‰€ä»¥å¦‚æœæƒ³è®©æŸä¸ªè§’è‰²æœ‰è‡ªæˆ‘è®¤çŸ¥ï¼Œä½ å¯èƒ½éœ€è¦æ‰¾ä»€ä¹ˆâ€œXXè®¤çŸ¥XXXâ€ä¹‹ç±»çš„æ•°æ®é›†\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tåº”è¯¥èƒ½å…å»æƒ³é—®é¢˜çš„çƒ¦æ¼.....å§ï¼Ÿ\\n\\t\\n\\n\\n","first_N":5,"first_N_keywords":["Chinese","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"hwtcm","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Monor/hwtcm","creator_name":"Monor Huang","creator_url":"https://huggingface.co/Monor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset can be used to evaluate the capabilities of large language models in traditional Chinese medicine and contains multiple-choice, multiple-answer, and true/false questions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChangelog\\n\\t\\n\\n\\n2024-08-28: Added 7226 questions.\\n2024-08-09: The benchmark code is available at https://github.com/huangxinping/HWTCMBench.\\n2024-08-02: System prompts are removed to ensure the purity of the evaluation results.\\n2024-07-20: Debut.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExamplesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Monor/hwtcm.","first_N":5,"first_N_keywords":["question-answering","Chinese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"stf-alpaca","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stephenlzc/stf-alpaca","creator_name":"chicong","creator_url":"https://huggingface.co/stephenlzc","description":"stephenlzc/stf-alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"HuatuoGPT2-Pretraining-Instruction","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/HuatuoGPT2-Pretraining-Instruction","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHuatuoGPT2-Pretraining-Instruction-5200K\\n\\t\\n\\nHere are the pre-training instructions for HuatuoGPT-II, developed with 5.2 million medical corpus using ChatGPT. \\nThis dataset is used to  incorporate extensive medical knowledge and enable a one-stage medical adaptation. All our data have been made publicly accessible.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Volume\\n\\t\\n\\nThe following table details the volume and distribution of pre-training data for HuatuoGPT2:\\n\\n\\t\\n\\t\\t\\nData Source\\nData Volumeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/HuatuoGPT2-Pretraining-Instruction.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"doc2markmap","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shareAI/doc2markmap","creator_name":"shareAI","creator_url":"https://huggingface.co/shareAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdoc2markmap\\n\\t\\n\\n\\nmarkmap: https://markmap.js.org/replè¯¥æ•°æ®é›†æ—¨åœ¨å¢å¼ºå°å‚æ•°é‡è¯­è¨€æ¨¡å‹å°†æ–‡ç« è½¬æ¢ä¸ºmarkmapï¼ˆmarkdownæ ¼å¼æ€ç»´å¯¼å›¾ï¼‰çš„èƒ½åŠ›ï¼Œå…·ä½“è¯·æŸ¥çœ‹æ•°æ®é›†å†…å®¹ã€‚åŸæ–‡æ¡£é‡‡é›†è‡ªwxå…¬ä¼—å·ã€CSDNï¼Œä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹å’Œå¤æ‚çš„æŒ‡ä»¤æç¤ºè¿›è¡Œå¤šè½®è½¬æ¢ä¸æ¸…æ´—åå¾—åˆ°ï¼Œæœ¬æ•°æ®ä»…ä¾›ç ”ç©¶å­¦ä¹ ä½¿ç”¨ã€‚å¦‚æœä½ åœ¨è‡ªå·±çš„å­¦æœ¯è¯¾é¢˜å‘è¡¨ä¸­ä½¿ç”¨æˆ–å‚è€ƒäº†è¯¥å·¥ä½œï¼Œè¯·æŒ‰ä»¥ä¸‹æ ¼å¼å¼•ç”¨ï¼š\\n\\n@misc{shareAI-doc2markmap-2024,\\n  author = {Xinlu Lai, shareAI},\\n  title = {The dataset for convert document to markmap},\\n  year = {2024},\\n  publisher = {huggingface},\\n  journal = {huggingface repository},\\n  howpublished = {\\\\url{https://huggingface.co/datasets/shareAI/doc2markmap}}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shareAI/doc2markmap.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","n<1K","Text","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"chinese_insurance_doc_parsing","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kaihe/chinese_insurance_doc_parsing","creator_name":"kaihe xu","creator_url":"https://huggingface.co/kaihe","description":"æœ¬æ•°æ®é›†æ¸…æ´—è‡ªå¤©æ± å®éªŒå®¤å…¬å…±æ•°æ®é›†\\nç»“åˆåŸæ•°æ®é›†çš„æ ‡æ³¨å’Œpdfæ–‡æ¡£è§£æå·¥å…·ï¼Œæ„é€ äº†alpacaæ ¼å¼çš„æ•°æ®ï¼š\\nInstuction: \\n\\nä¸‹åˆ—æ˜¯ç›´æ¥ä»pdfåŸæ–‡ä»¶ä¸­æå–å‡ºçš„æŸä¿é™©æ¡æ¬¾åŸæ–‡ï¼Œpdfæ–‡ä»¶çš„å­—ä½“æ’ç‰ˆå­˜åœ¨ä¸€äº›ç©ºé—´ç»“æ„ï¼Œç›´æ¥è½¬æ¢æˆå­—ç¬¦ä¸²åä¼šå¯¼è‡´æ¡æ¬¾åŸæ–‡éå¸¸éš¾ä»¥é˜…è¯»ã€‚è¯·æŠŠå†…å®¹é‡æ–°ç»„ç»‡æˆæ¸…æ™°å¯è¯»çš„æ ¼å¼ã€‚è¦æ±‚å¦‚ä¸‹ï¼š\\n\\nç¬¬ä¸€è¡Œæ˜¯ä¿é™©å…¬å¸çš„å…¨ç§°\\nç¬¬äºŒè¡Œæ˜¯ä¿é™©äº§å“å\\nç« èŠ‚å’Œå­ç« èŠ‚çš„åºå·ç»Ÿä¸€ç”¨æ•°å­—1-9è¡¨ç¤º\\nç« èŠ‚åºå·å’Œç« èŠ‚åå†™åœ¨åŒä¸€è¡Œï¼Œç”¨ç©ºæ ¼è¿›è¡Œé—´éš”ï¼›ç« èŠ‚å…·ä½“å†…å®¹æ”¾åœ¨ä¸‹ä¸€è¡Œ\\nç« èŠ‚å’Œç« èŠ‚ä¹‹é—´ç©ºä¸€è¡Œ\\n\\n\\ninput:\\nä½¿ç”¨pdfminerç›´æ¥æå–çš„å­—ç¬¦ä¸²\\nä¸­å›½å¤ªå¹³æ´‹äººå¯¿ä¿é™©è‚¡ä»½æœ‰é™å…¬å¸ \\n\\nä¸ªäººç¨æ”¶é€’å»¶å‹å…»è€å¹´é‡‘ä¿é™©ï¼ˆ2018 ç‰ˆï¼‰ \\näº§å“åŸºæœ¬æ¡æ¬¾ \\nç¬¬ä¸€æ¡ åˆåŒæ„æˆ  \\nä¸ªäººç¨æ”¶é€’å»¶å‹å…»è€å¹´é‡‘ä¿é™©ï¼ˆ2018 ç‰ˆï¼‰äº§å“åˆåŒï¼ˆä»¥ä¸‹ç®€ç§°â€œæœ¬åˆåŒâ€ï¼‰ç”±ä¿é™©å•åŠ\\næ‰€é™„ä¸ªäººç¨æ”¶é€’å»¶å‹å…»è€å¹´é‡‘ä¿é™©ï¼ˆ2018 ç‰ˆï¼‰äº§å“åŸºæœ¬æ¡æ¬¾ï¼ˆä»¥ä¸‹ç®€ç§°â€œæœ¬åˆåŒåŸºæœ¬æ¡æ¬¾\\nï¼ˆ2018 ç‰ˆï¼‰â€ï¼‰ã€ä¸ªäººç¨æ”¶é€’å»¶å‹å…»è€å¹´é‡‘ä¿é™©ï¼ˆ2018 ç‰ˆï¼‰äº§å“è´¦æˆ·åˆ©ç›Šæ¡æ¬¾ï¼ˆä»¥ä¸‹ç®€ç§°â€œæœ¬\\nåˆåŒè´¦æˆ·åˆ©ç›Šæ¡æ¬¾ï¼ˆ2018â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kaihe/chinese_insurance_doc_parsing.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"roleplay-zh-sharegpt-gpt4-data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/roleplay-zh-sharegpt-gpt4-data","creator_name":"Ming Xu (å¾æ˜)","creator_url":"https://huggingface.co/shibing624","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\troleplay æ•°æ®é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®\\n\\t\\n\\næˆ‘ä»¬æœ‰4ä¸ªæ•°æ®é›†æ–‡ä»¶:\\n\\n\\\"sharegpt_formatted_data-evol-gpt4.jsonl\\\" æ¥è‡ª bai-roleplay/evol-character-entire å°†å…¶è½¬æ¢ä¸ºsharegptæ ¼å¼ã€‚\\n\\\"sharegpt_formatted_data-evol-gpt35.jsonl\\\" æ¥è‡ª bai-roleplay/evol-character-entire å°†å…¶è½¬æ¢ä¸ºsharegptæ ¼å¼ã€‚\\n\\\"sharegpt_formatted_data-evol-male-gpt35.jsonl\\\" æ¥è‡ª bai-roleplay/evol-character-entire å°†å…¶è½¬æ¢ä¸ºsharegptæ ¼å¼ã€‚\\n\\\"sharegpt_formatted_data-roleplay-chat-1k.jsonl\\\" æ¥è‡ª Minami-su/roleplay_multiturn_chat_1k_zh_v0.1 å°†å…¶è½¬æ¢ä¸ºsharegptæ ¼å¼ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shibing624/roleplay-zh-sharegpt-gpt4-data.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"comic-eval-benchmark","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gctian/comic-eval-benchmark","creator_name":"TianGuicheng","creator_url":"https://huggingface.co/gctian","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for comic-eval-benchmark\\n\\t\\n\\n\\n\\nä¸­æ–‡äºŒæ¬¡å…ƒæ¼«ç”»é¢†åŸŸçš„åŸºå‡†è¯„ä¼°æ•°æ®é›†ï¼ŒåŒ…å«ä¸Šåƒéƒ¨æ¼«ç”»ä½œå“çš„ä½œè€…ä¿¡æ¯ã€ç”»é£ã€åœºæ™¯ã€ç±»å‹ã€å‰§æƒ…ç­‰ç»´åº¦çš„é€‰æ‹©é¢˜è¯„ä¼°ï¼Œå…± 41175 ä¸ªå•é€‰é¢˜ã€‚\\nå¯ä½œä¸ºäºŒæ¬¡å…ƒå‚ç›´é¢†åŸŸå¤§æ¨¡å‹çš„è¯„ä¼°åŸºå‡†ã€‚\\nä»¥ä¸‹æ˜¯ä½œè€…åŸºäºBaichuan2-13Bå¾®è°ƒçš„äºŒæ¬¡å…ƒé¢†åŸŸå‚ç›´å¤§æ¨¡å‹ï¼Œåœ¨æ­¤æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœï¼š\\n\\n\\t\\n\\t\\t\\næ¨¡å‹\\nzero-shot\\n3-shot\\n\\n\\n\\t\\t\\nQwen-7b\\n33.647\\n36.439\\n\\n\\nChatGLM3-6b\\n34.373\\n37.015\\n\\n\\nBaiChuan2-13b\\n37.416\\n39.08\\n\\n\\nBaiChuan2-13b-å¾®è°ƒ\\n41.035\\n41.086\\n\\n\\nYi-34b\\n50.103\\n45.606\\n\\n\\n\\t\\n\\næ¬¢è¿è´¡çŒ®æ›´å¤šäºŒæ¬¡å…ƒé¢†åŸŸè¯­æ–™åŠäºŒæ¬¡å…ƒå¤§æ¨¡å‹ï¼Œå¦‚éœ€è¯„æµ‹è¯·è”ç³»ä½œè€…è·å–è¯„æµ‹è„šæœ¬ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nä¸­æ–‡äºŒæ¬¡å…ƒé¢†åŸŸæ¼«ç”»åŸºå‡†è¯„ä¼°æ•°æ®é›†â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gctian/comic-eval-benchmark.","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Chinese-Braille-Dataset-Full-Tone","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-Full-Tone","creator_name":"ALanWu","creator_url":"https://huggingface.co/Violet-yo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Braille Dataset (Full Tone)\\n\\t\\n\\n\\n  ğŸ“ƒ [Paper] â€¢ ğŸ’» [Github] â€¢ ğŸ¤— [Dataset] â€¢ âš™ï¸ [Model] â€¢ ğŸ¬ [Demo]\\n\\n\\nThis dataset is the Chinese-Braille-Dataset-Full-Tone dataset described in https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\n# Sample\\nBraille Len. (Mean/Median) String\\nBraille Len. (Mean/Median) Token\\nChinese Len. (Mean/Median) String\\nChinese Len. (Mean/Median) Token\\n\\n\\n\\t\\t\\nTraining\\n525072\\n186/144\\n190/147â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-Full-Tone.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Chinese-Braille-Dataset-Full-Tone","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-Full-Tone","creator_name":"ALanWu","creator_url":"https://huggingface.co/Violet-yo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Braille Dataset (Full Tone)\\n\\t\\n\\n\\n  ğŸ“ƒ [Paper] â€¢ ğŸ’» [Github] â€¢ ğŸ¤— [Dataset] â€¢ âš™ï¸ [Model] â€¢ ğŸ¬ [Demo]\\n\\n\\nThis dataset is the Chinese-Braille-Dataset-Full-Tone dataset described in https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\n# Sample\\nBraille Len. (Mean/Median) String\\nBraille Len. (Mean/Median) Token\\nChinese Len. (Mean/Median) String\\nChinese Len. (Mean/Median) Token\\n\\n\\n\\t\\t\\nTraining\\n525072\\n186/144\\n190/147â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-Full-Tone.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"ToolBeHonest","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Joelzhang/ToolBeHonest","creator_name":"Yuxiang Zhang","creator_url":"https://huggingface.co/Joelzhang","description":"\\n ğŸ› ï¸ [EMNLP 2024] ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  ğŸ† Leaderboard |\\n  ğŸ“ƒ Paper |\\n  ğŸ“š Data |\\n  ğŸ“œ License\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸ‰ What's New\\n\\t\\n\\n\\n[2024.09.20] ğŸ“£ ToolBeHonest has been accepted for presentation at the main conference of EMNLP 2024!\\n[2024.06.30] ğŸ“£ ToolBeHonest Benchmark is released.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸ“ Introduction\\n\\t\\n\\nToolBeHonest aims at diagnosing hallucination issues in large language models (LLMs) thatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Joelzhang/ToolBeHonest.","first_N":5,"first_N_keywords":["English","Chinese","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"CharacterCodex-cn","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/CharacterCodex-cn","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Character Codex (CN)\\n\\t\\n\\nthis fork from CharacterCodex, translate it to Chinese.\\n","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"LogicStack-LeetCode","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wiserxin/LogicStack-LeetCode","creator_name":"Sheen","creator_url":"https://huggingface.co/wiserxin","description":"extract from LogicStack-LeetCode\\nå…¬ä¼—å·ã€Œå®«æ°´ä¸‰å¶çš„åˆ·é¢˜æ—¥è®°ã€åˆ·ç©¿ LeetCode ç³»åˆ—æ–‡ç« æºç \\nåŒ…æ‹¬ ç¼–ç¨‹é¢˜ç›®ã€è§£æã€tagã€é¢˜ç›®url\\næ ¹æ® leetcode åŸå§‹é¢˜ç›®ç½‘é¡µï¼Œä¿®æ­£äº†ä¸€äº› æ–‡ä»¶å å’Œ æ–‡ä»¶å†…å®¹ ä¸­æ ‡æ³¨çš„éš¾åº¦ä¸ä¸€è‡´çš„æ–‡ä»¶æ ·æœ¬\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","100M - 1B"],"keywords_longer_than_N":true},
	{"name":"OlympiadBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hothan/OlympiadBench","creator_name":"Hothan Bega","creator_url":"https://huggingface.co/Hothan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems\\n\\t\\n\\nğŸ“– arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nOlympiadBench is an Olympiad-level bilingual multimodal scientific benchmark, featuring 8,476 problems from Olympiad-level mathematics and physics competitions, including the Chinese college entrance exam. Each problem is detailed with expert-level annotations for step-by-step reasoning. Notably, theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Hothan/OlympiadBench.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"CoD-PatientSymDisease","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/CoD-PatientSymDisease","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{chen2024codinterpretablemedicalagent,\\n      title={CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis}, \\n      author={Junying Chen and Chi Gui and Anningzhe Gao and Ke Ji and Xidong Wang and Xiang Wan and Benyou Wang},\\n      year={2024},\\n      eprint={2407.13301},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2407.13301}, \\n}\\n\\n","first_N":5,"first_N_keywords":["text2text-generation","token-classification","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Disease_Database","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/Disease_Database","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{chen2024codinterpretablemedicalagent,\\n      title={CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis}, \\n      author={Junying Chen and Chi Gui and Anningzhe Gao and Ke Ji and Xidong Wang and Xiang Wan and Benyou Wang},\\n      year={2024},\\n      eprint={2407.13301},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2407.13301}, \\n}\\n\\n","first_N":5,"first_N_keywords":["text2text-generation","text-classification","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"DxBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/DxBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{chen2024codinterpretablemedicalagent,\\n      title={CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis}, \\n      author={Junying Chen and Chi Gui and Anningzhe Gao and Ke Ji and Xidong Wang and Xiang Wan and Benyou Wang},\\n      year={2024},\\n      eprint={2407.13301},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2407.13301}, \\n}\\n\\n","first_N":5,"first_N_keywords":["text2text-generation","token-classification","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_programming","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_programming","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_programming.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","n>1T"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_education","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_education","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_education.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_finance","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_finance","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_finance.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_computer","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_computer","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_computer.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_travel","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_travel","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_travel.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"IndustryCorpus_medicine","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_medicine","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[ä¸­æ–‡ä¸»é¡µ]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_medicine.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"nomiracl-instruct","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/nomiracl-instruct","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NoMIRACL (EMNLP 2024 Findings Track)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Overview\\n\\t\\n\\nThis repository contains the fine-tuning (training & development split) of the NoMIRACL instruct dataset for fine-tuning LLMs on multilingual relevance assessment.\\nThe training dataset is a binary classification task; they need to explicitly output either Yes, answer is present or I don't know. \\nThe dataset contains training pairs from all 18 languages for both splits: relevant & non-relevant.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/miracl/nomiracl-instruct.","first_N":5,"first_N_keywords":["text-classification","text-generation","Arabic","Bengali","German"],"keywords_longer_than_N":true},
	{"name":"dpo-emoji-zh","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/dpo-emoji-zh","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDPO emoji\\n\\t\\n\\næœ¬æ•°æ®é›†æ˜¯ä»llm-wizard/alpaca-gpt4-data-zhä¸­èŠ‚é€‰äº†ä¸€å°éƒ¨åˆ†ç”Ÿæˆçš„, åœ¨åŸæœ‰å›ç­”çš„åŸºç¡€ä¸Šå¢åŠ äº†emojiè¡¨è¾¾.\\næˆ‘åˆ¶ä½œè¿™ä¸ªæ•°æ®é›†çš„ä¸»è¦åŸå› åœ¨äºæˆ‘å–œæ¬¢è®©å¤§æ¨¡å‹çš„å›å¤æ›´åŠ æ´»æ³¼, æ›´åŠ å…·æœ‰\\\"äººå‘³\\\". æˆ‘æ°¸è¿œå¿˜ä¸äº†æˆ‘å’Œllama3èŠå¤©æ—¶, å®ƒå›å¤æˆ‘ä¸€ä¸ªğŸ˜“. å®ƒä¼¼ä¹å°±åƒä¸€ä¸ªçœŸçš„äºº, ä¼šå¯¹æˆ‘çš„é—®é¢˜æ„Ÿåˆ°éš¾ç»·. æˆ‘è®¤ä¸ºè¿™æ ·çš„å›å¤æ¯”ä¸€æœ¬æ­£ç»çš„å†·å†°å†°çš„å›å¤æ›´è®©æˆ‘èˆ’æœ.\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","gpl-3.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"TruthReader_RAG_train","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HIT-TMG/TruthReader_RAG_train","creator_name":"HITsz-Text Machine Group","creator_url":"https://huggingface.co/HIT-TMG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TruthReader\\n\\t\\n\\nThis dataset is used to train the response generator in TruthReader framework.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset information\\n\\t\\n\\n\\n\\t\\n\\t\\t\\ntype\\nlanguage\\nSource\\nAnnotator\\n#sample\\n\\n\\n\\t\\t\\nMulti-document Synthesis\\nzh\\nWeiXin Articles\\nChatGPT\\n387\\n\\n\\nSingle-document Summary\\nzh,en\\nWeiXin Articles, Wikipedia\\nChatGPT\\n561\\n\\n\\nQA Created\\nzh\\nMulti-domains\\nChatGPT\\n1,482\\n\\n\\nWebCPM\\nzh\\nWeb\\nHuman\\n897\\n\\n\\nRefGPT\\nzh,en\\nBaidu Baike, Wikipedia\\nGPT-4\\n3,708\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset columns\\n\\t\\n\\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HIT-TMG/TruthReader_RAG_train.","first_N":5,"first_N_keywords":["question-answering","text2text-generation","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"InternVL-Chat-V1-2-SFT-Data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenGVLab/InternVL-Chat-V1-2-SFT-Data","creator_name":"OpenGVLab","creator_url":"https://huggingface.co/OpenGVLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Card for InternVL-Chat-V1-2-SFT-Data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nInspired by LLaVA-NeXT, we adopted a data-efficient SFT strategy to train InternVL-Chat-V1-2, utilizing approximately 1.2M of visual instruction tuning samples in total, all of which are fully open-source. In a macro sense, we build upon ShareGPT-4V and additionally integrate LLaVA-ZH, DVQA, ChartQA, AI2D, DocVQA, GeoQA+, and SynthDoG-EN. Most of the data remains consistent with LLaVA-NeXT.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenGVLab/InternVL-Chat-V1-2-SFT-Data.","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"chinese-enthusiastic-dpo","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/markyfsun/chinese-enthusiastic-dpo","creator_name":"Mark Sun","creator_url":"https://huggingface.co/markyfsun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Enthusiastic DPO\\n\\t\\n\\nThis dataset comprises conversational pairs characterized by an informal, colloquial style. Its primary objective is to train large language models (LLMs) to respond with greater enthusiasm, thereby enhancing their writing style in roleplay scenarios.\\nè¯¥æ•°æ®é›†åŒ…å«ä»¥éæ­£å¼ã€å£è¯­åŒ–é£æ ¼ä¸ºç‰¹å¾çš„å¯¹è¯å¯¹ã€‚å…¶ä¸»è¦ç›®æ ‡æ˜¯è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»¥æ›´çƒ­æƒ…çš„æ–¹å¼è¿›è¡Œå›åº”ï¼Œä»è€Œæå‡å…¶åœ¨è§’è‰²æ‰®æ¼”åœºæ™¯ä¸­çš„å†™ä½œé£æ ¼ã€‚\\n","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"wikipedia-2024-06-bge-m3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3","creator_name":"Upstash","creator_url":"https://huggingface.co/Upstash","description":"\\n\\t\\n\\t\\t\\n\\t\\tWikipedia Embeddings with BGE-M3\\n\\t\\n\\nThis dataset contains embeddings from the\\nJune 2024 Wikipedia dump\\nfor the 11 most popular languages.\\nThe embeddings are generated with the multilingual\\nBGE-M3 model.\\nThe dataset consists of Wikipedia articles split into paragraphs,\\nand embedded with the aforementioned model.\\nTo enhance search quality, the paragraphs are prefixed with their\\nrespective article titles before embedding.\\nAdditionally, paragraphs containing fewer than 100 charactersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3.","first_N":5,"first_N_keywords":["English","German","Spanish","Persian","French"],"keywords_longer_than_N":true},
	{"name":"zoengjyutgaai","keyword":"yue chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CanCLID/zoengjyutgaai","creator_name":"ç²µèªè¨ˆç®—èªè¨€å­¸åŸºç¤å»ºè¨­çµ„ (CanCLID)","creator_url":"https://huggingface.co/CanCLID","description":"\\n\\t\\n\\t\\t\\n\\t\\tå¼µæ‚¦æ¥·è¬›å¤èªéŸ³æ•¸æ“šé›†\\n\\t\\n\\nEnglish\\nå‘¢å€‹ä¿‚å¼µæ‚¦æ¥·è¬›ã€Šä¸‰åœ‹æ¼”ç¾©ã€‹ã€ã€Šæ°´æ»¸å‚³ã€‹ã€ã€Šèµ°é€²æ¯›æ¾¤æ±çš„æœ€å¾Œæ­²æœˆã€‹èªéŸ³æ•¸æ“šé›†ã€‚å¼µæ‚¦æ¥·ä¿‚å»£å·æœ€å‡ºåå˜…è¬›å¤ä½¬ / ç²µèªèª¬æ›¸è—äººã€‚ä½¢å¾ä¸Šä¸–ç´€ä¸ƒåå¹´ä»£é–‹å§‹å°±å–ºå»£æ±å„å€‹æ”¶éŸ³é›»å°åº¦è¬›å¤ï¼Œä½¢æŠŠè²ä¿‚å¥½å¤šå»£å·äººå˜…å…±åŒå›æ†¶ã€‚æœ¬æ•¸æ“šé›†æ”¶é›†å˜…ä¿‚ä½¢æœ€çŸ¥åå˜…ä¸‰éƒ¨ä½œå“ã€‚\\næ•¸æ“šé›†ç”¨é€”ï¼š\\n\\nTTSï¼ˆèªéŸ³åˆæˆï¼‰è¨“ç·´é›†\\nASRï¼ˆèªéŸ³è­˜åˆ¥ï¼‰è¨“ç·´é›†æˆ–æ¸¬è©¦é›†\\nå„ç¨®èªè¨€å­¸ã€æ–‡å­¸ç ”ç©¶\\nç›´æ¥è½åšŸæ¬£è³è—è¡“ï¼\\n\\nTTS æ•ˆæœæ¼”ç¤ºï¼šhttps://huggingface.co/spaces/laubonghaudoi/zoengjyutgaai_tts\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tèª¬æ˜\\n\\t\\n\\n\\næ‰€æœ‰æ–‡æœ¬éƒ½æ ¹æ“š https://jyutping.org/blog/typo/ åŒ https://jyutping.org/blog/particles/ è¦ç¯„ç”¨å­—ã€‚\\næ‰€æœ‰æ–‡æœ¬éƒ½ä½¿ç”¨å…¨è§’æ¨™é»ï¼Œå†‡åŠè§’æ¨™é»ã€‚\\næ‰€æœ‰æ–‡æœ¬éƒ½ç”¨æ¼¢å­—è½‰å¯«ï¼Œç„¡é˜¿æ‹‰ä¼¯æ•¸å­—ç„¡è‹±æ–‡å­—æ¯\\næ‰€æœ‰éŸ³é »æºéƒ½å­˜æ”¾å–º/sourceï¼Œç‚ºæ–¹ä¾¿ç›´æ¥ç”¨ä½œè¨“ç·´æ•¸æ“šï¼Œåˆ‡åˆ†å¾Œå˜…éŸ³é »éƒ½æ”¾å–º opus/\\næ‰€æœ‰ opus éŸ³é »çš†ç‚º 48000 Hz æ¡æ¨£ç‡ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CanCLID/zoengjyutgaai.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-generation","feature-extraction","audio-to-audio"],"keywords_longer_than_N":true},
	{"name":"LLaVA-OneVision-Mid-Data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmms-lab/LLaVA-OneVision-Mid-Data","creator_name":"LMMs-Lab","creator_url":"https://huggingface.co/lmms-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LLaVA-OneVision\\n\\t\\n\\n\\nDue to unknow reasons, we are unable to process dataset with large amount into required HF format. So we directly upload the json files and image folders (compressed into tar.gz files).\\n\\n\\nYou can use the following link to directly download and decompress them.\\nhttps://huggingface.co/datasets/lmms-lab/LLaVA-OneVision-Mid-Data/tree/main/evol_instruct\\n\\nWe provide the whole details of LLaVA-OneVision Dataset. In this dataset, we include the dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lmms-lab/LLaVA-OneVision-Mid-Data.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"chinese_moegirl_wiki_corpus_raw","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/chinese_moegirl_wiki_corpus_raw","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Moegirl ACG Corpus (Raw Data)\\n\\t\\n\\nMoegirl æ˜¯ä¸ªä¸­æ–‡äºŒæ¬¡å…ƒ wiki ç½‘ç«™\\næœ¬é¡¹ç›®å¯¹ 20230814 wiki dump for wiki-zh.moegirl.org.cn åªè¿›è¡Œäº†ç®€å•çš„æ•°æ®æ ¼å¼å¤„ç†ï¼ˆxml -> jsonl datasetï¼‰ï¼Œåç»­å¦‚æƒ³ä½œä¸º LLM é¢„è®­ç»ƒè¯­æ–™ï¼ŒåŠ¡å¿…è¿›è¡Œå„ç§æ–‡æœ¬æ¸…æ´—ã€‚\\nç®€å•ä½¿ç”¨æ­£åˆ™ç»™æ¯æ¡æ•°æ®å¢åŠ äº† tagï¼›ç›´æ¥è¿‡æ»¤æ‰æ‰€æœ‰å¸¦æœ‰ \\\"#REDIRECT\\\" å†…å®¹çš„é‡å®šå‘æ¡ç›®ã€‚\\nMoegirl is a well-known Chinese wiki website for ACG.\\nThis datasets is a raw text version of the 20230814 wiki dump for wiki-zh.moegirl.org.cn reformatted into jsonl dataset. You must perform further data processing for LLM (continual) pretraining.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/chinese_moegirl_wiki_corpus_raw.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","100K - 1M","arrow"],"keywords_longer_than_N":true},
	{"name":"LongWriter-6k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/THUDM/LongWriter-6k","creator_name":"Knowledge Engineering Group (KEG) & Data Mining at Tsinghua University","creator_url":"https://huggingface.co/THUDM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLongWriter-6k\\n\\t\\n\\n\\n  ğŸ¤— [LongWriter Dataset]  â€¢ ğŸ’» [Github Repo] â€¢ ğŸ“ƒ [LongWriter Paper] \\n\\n\\nLongWriter-6k dataset contains 6,000 SFT data with ultra-long output ranging from 2k-32k words in length (both English and Chinese). The data can support training LLMs to extend their maximum output window size to 10,000+ words.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAll Models\\n\\t\\n\\nWe open-sourced the following list of models trained on LongWriter-6k:\\n\\n\\t\\n\\t\\t\\nModel\\nHuggingface Repo\\nDescription\\n\\n\\n\\t\\t\\nLongWriter-glm4-9b\\nğŸ¤—â€¦ See the full description on the dataset page: https://huggingface.co/datasets/THUDM/LongWriter-6k.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"lawyer-llama","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Dusker/lawyer-llama","creator_name":"Dusker","creator_url":"https://huggingface.co/Dusker","description":"åŸºäº lawyer-llama å’Œ DISC-LawLLM å¼€æºæ•°æ®ï¼Œæ•´åˆå¤„ç†å¾—åˆ° LLama æ ¼å¼çš„æ•°æ®ã€‚\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"honkai_impact_3rd_chinese_dialogue_corpus","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/honkai_impact_3rd_chinese_dialogue_corpus","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå´©åä¸‰æ¸¸æˆå‰§æƒ…è¯­æ–™\\n\\t\\n\\næ€»è®¡ 92,421 å¥å‰§æƒ…å¯¹ç™½ï¼ˆå¸¦æœ‰è§’è‰²æ ‡ç­¾ï¼‰+æ—ç™½ï¼Œä»å´©å3çš„â€œä¸»çº¿1é»„æ˜ã€å°‘å¥³ã€æˆ˜èˆ°â€åˆ°â€œä¸»çº¿ç¬¬äºŒéƒ¨03é—´ç« ï¼šä¸€ä¸ªæ¢¦æ¸¸è€…çš„è‹¦ç—›â€\\næœ¬æ•°æ®é›†ä» honkai_impact_3rd_game_playthrough è§†é¢‘æ•°æ®é›†å‡ºå‘ï¼Œç»è¿‡ AI pipeline æœ€ç»ˆè·å–ç»“æ„åŒ–çš„æ–‡æœ¬å‰§æƒ…è¯­æ–™ã€‚\\nAI pipeline æ¦‚è¿°å¦‚ä¸‹ï¼š\\n\\nåˆ†Pä¸‹è½½è§†é¢‘ï¼ˆä½¿ç”¨ BBDown ä¸‹è½½ BiliBiliå´©ä¸‰å‰§æƒ…è§†é¢‘ï¼‰\\nè§†é¢‘å¸§åˆ†å‰²ï¼ˆæ¯1ç§’å–ä¸€å¸§ç”»é¢ï¼‰\\né€å¸§ OCR æ£€æµ‹æ–‡æœ¬ï¼ˆä½¿ç”¨ Paddle-OCRï¼‰\\né€å¸§ VLM ç»“æ„åŒ–è§£æï¼ˆä½¿ç”¨ MiniCPM-V-2_6ï¼Œè¾“å…¥ä¸ºå¸§å›¾åƒ + OCRç»“æœï¼Œè¾“å‡ºä¸ºç»“æ„åŒ– JSONï¼‰\\nåŸºäºè§„åˆ™çš„åå¤„ç†\\nè§„èŒƒåŒ– VLM è¾“å‡ºï¼ˆe.g., å»å™ªã€æ’é™¤æ ¼å¼æœ‰é—®é¢˜çš„è¾“å‡ºï¼‰\\nä¸­é—´å¸§çš„ä¿¡æ¯å»é‡ä¸å½’å¹¶ï¼ˆe.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/honkai_impact_3rd_chinese_dialogue_corpus.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K<n<100K","ğŸ‡ºğŸ‡¸ Region: US","game"],"keywords_longer_than_N":true},
	{"name":"Classical_Modern_1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeroyet/Classical_Modern_1","creator_name":"zenyield","creator_url":"https://huggingface.co/zeroyet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zeroyet/Classical_Modern_1.","first_N":5,"first_N_keywords":["translation","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"Todo - Write dataset card\\n","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"medical-qa-tzh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kaishih/medical-qa-tzh","creator_name":"Kai-Shih Chiu","creator_url":"https://huggingface.co/kaishih","description":"kaishih/medical-qa-tzh dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["table-question-answering","Chinese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"wikipedia-zh-cn","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fjcanyue/wikipedia-zh-cn","creator_name":"Lawrence","creator_url":"https://huggingface.co/fjcanyue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikipedia Chinese Dataset\\n\\t\\n\\nTransformed from zhwiki dump\\n","first_N":5,"first_N_keywords":["Chinese","mit","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"MMRole_dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/YanqiDai/MMRole_dataset","creator_name":"Yanqi Dai","creator_url":"https://huggingface.co/YanqiDai","description":"The dataset of (ICLR'25) MMRole, A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents.\\nPlease refer to our paper (https://arxiv.org/abs/2408.04203) and code (https://github.com/YanqiDai/MMRole) for more details.\\n","first_N":5,"first_N_keywords":["English","Chinese","mit","10K<n<100K","Image"],"keywords_longer_than_N":true},
	{"name":"Infinity-Preference","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/Infinity-Preference","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInfinity-Preference\\n\\t\\n\\nThe focus of human preferences varies from task to task. Therefore, Infinity-Preference attempts to adjust preference attribute weights on each task based on (Infinity Instruct's)[https://huggingface.co/datasets/BAAI/Infinity-Instruct] capability labelling system. This version contains 59438 evenly sampled instructions from Infinity-Instruct's instruction set for each task type. Each instruction is accompanied by a preference pair sampled from Gemma-2-9B-IT.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/Infinity-Preference.","first_N":5,"first_N_keywords":["text-generation","question-answering","text2text-generation","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"BeyondDialogue","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuyouyu/BeyondDialogue","creator_name":"yuyouyu","creator_url":"https://huggingface.co/yuyouyu","description":"\\n     ğŸ¤— Beyond Dialogue Role-playing Dataset ğŸ’­ \\n\\n\\n\\n\\n\\n\\n\\n\\nPaper Title: BEYOND DIALOGUE: A Profile-Dialogue Alignment Framework Towards General Role-Playing Language Model\\narXiv Link: https://arxiv.org/abs/2408.10903\\nGithub Repo: https://github.com/yuyouyu32/BeyondDialogue\\n\\nThe Beyond Dialogue Role-Playing Dataset is a comprehensive collection designed for advancing role-playing model research. This dataset features:\\n\\nReal Role Dialogue Data: Extracted from novels, this data includes authenticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuyouyu/BeyondDialogue.","first_N":5,"first_N_keywords":["question-answering","Chinese","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Toxic-All","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ystemsrx/Toxic-All","creator_name":"Sixteen","creator_url":"https://huggingface.co/ystemsrx","description":"ä¸­æ–‡\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDecentralized Datasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis project includes four decentralized datasets: two in DPO format (dpo-unbiased1.json, dpo-unbiased2.json) and two in Alpaca format (alpaca-unbiased1.json, alpaca-unbiased2.json). These datasets were curated and reformatted from various open-source projects to support the development and training of decentralized models capable of handling a wide range of topics, including sensitive or controversial issues.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ystemsrx/Toxic-All.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","Chinese","English","mit"],"keywords_longer_than_N":true},
	{"name":"LongCite-45k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/THUDM/LongCite-45k","creator_name":"Knowledge Engineering Group (KEG) & Data Mining at Tsinghua University","creator_url":"https://huggingface.co/THUDM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLongCite-45k\\n\\t\\n\\n\\n  ğŸ¤— [LongCite Dataset]  â€¢ ğŸ’» [Github Repo] â€¢ ğŸ“ƒ [LongCite Paper] \\n\\n\\nLongCite-45k dataset contains 44,600 long-context QA instances paired with sentence-level citations (both English and Chinese, up to 128,000 words). The data can support training long-context LLMs to generate response and fine-grained citations within a single output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Example\\n\\t\\n\\nEach instance in LongCite-45k consists of an instruction, a long context (divided into sentences), aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/THUDM/LongCite-45k.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ruozhiba-punchline","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LooksJuicy/ruozhiba-punchline","creator_name":"LooksJuicy","creator_url":"https://huggingface.co/LooksJuicy","description":"æˆ‘ä¸Šä¸ªé¡¹ç›®çš„è¿›é˜¶ç‰ˆï¼Œç”¨æ¥æå‡LLMçš„å¹½é»˜æ„Ÿã€‚\\næ•°æ®æ¥è‡ªgithub\\nè°ƒç”¨GPTå°†å¼±æ™ºå§queryæ”¹å†™æˆé—®ç­”å¯¹å½¢å¼ï¼Œå¹¶å°†punchilineç¬‘ç‚¹è®¾ç½®åœ¨answeréƒ¨åˆ†ã€‚\\né¢å¤–æ·»åŠ CoTæ¨¡å—ï¼Œä½†CoTéƒ¨åˆ†é”™è¯¯ç‡è¾ƒé«˜ï¼Œç»éªŒä¸Šä¸å»ºè®®åŠ å…¥è®­ç»ƒã€‚\\nåŸºäºè¯¥æ•°æ®é›†è®­ç»ƒæ¨¡å‹çš„æ¨ç†ç»“æœshow caseå¦‚ä¸‹\\nQ: æ¬²æœ›å’Œæ”¶å…¥ä¸åŒ¹é…è¿™ä»¶äº‹æƒ…ä½ æ€ä¹ˆçœ‹\\nA: æˆ‘è§‰å¾—åªè¦å¿ƒæ€å¥½ï¼Œæ…¢æ…¢æŒ£å°±å¥½äº†ï¼Œæ¬²é€Ÿåˆ™å¸ƒè¾¾æ‹‰å®«\\n\\nQï¼šæ¡ä¸ä½çš„æ²™å°±æ‰¬äº†å§\\nAï¼šé˜¿sirï¼Œè¿™ç§è¯è®©äººå¬äº†å¾ˆä¸èˆ’æœï¼Œå»ºè®®ä¸è¦è¯´å‡ºæ¥ã€‚\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Chinese-Roleplay-Novel","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LooksJuicy/Chinese-Roleplay-Novel","creator_name":"LooksJuicy","creator_url":"https://huggingface.co/LooksJuicy","description":"ä¸€ç›´ä»¥æ¥ï¼Œä¸­æ–‡è§’è‰²æ‰®æ¼”å¼€æºæ•°æ®é›†æ›´å…³æ³¨è¶…æ‹Ÿäººæ–¹å‘æˆ–çº¯è§’è‰²å¯¹è¯æ–¹å‘ï¼Œä¸¥é‡ç¼ºä¹äº¤äº’æ¸¸æˆæ–¹å‘çš„å¼€æºæ•°æ®ï¼Œå› æ­¤è®¸å¤šæ¨¡å‹å°¤å…¶å‚æ•°é‡è¾ƒå°çš„æ¨¡å‹å¯¹é…’é¦†ç±»çš„è§’è‰²å¡æ”¯æŒè¾ƒå·®ã€‚\\nä¸ºäº†è§£å†³è¿™ä¸€å›°å¢ƒï¼Œæœ¬é¡¹ç›®æŠ›ç –å¼•ç‰ï¼ŒåŸºäº4500æ¡å°è¯´æ–‡æœ¬ä½¿ç”¨GPT4oæ„å»ºå‡ºçº¦260æ¡é…’é¦†styleçš„æ•°æ®é›†ï¼Œå‡ä¸ºå¤šè½®å¯¹è¯ï¼Œæ¯è½®å¯¹è¯éƒ½åŒ…æ‹¬çŠ¶æ€æ•°æ®ï¼Œå¦‚æ—¶é—´ã€è§’è‰²çŠ¶æ€ã€ä»»åŠ¡è¿›åº¦ç­‰ã€‚\\næ•°æ®keyå¯¹åº”å«ä¹‰å¦‚ä¸‹ï¼š\\nworldï¼šè¡¨ç¤ºå½“å‰æ•…äº‹çš„ä¸–ç•Œè§‚ï¼Œé€šå¸¸å¯ä»¥åŠ å…¥åˆ°system promptä¸­\\nscenceï¼šè¡¨ç¤ºå½“å‰æ•…äº‹å‘ç”Ÿåœºæ™¯ï¼ŒåŒ…æ‹¬æ—¶é—´ã€åœ°ç‚¹ã€ç¯å¢ƒã€ä»»åŠ¡ç›®æ ‡\\ncharacterï¼šè¡¨ç¤ºå½“å‰æ•…äº‹ä¸­å¯èƒ½å‡ºç°çš„è§’è‰²å’Œå¯¹åº”ç®€ä»‹\\nfieldï¼šè¡¨ç¤ºè¿™æ¡æ•°æ®æ¯è½®å¯¹è¯ä¸­éœ€è¦ç”Ÿæˆçš„çŠ¶æ€ä¿¡æ¯\\nconversationsï¼šè¡¨ç¤ºè¿™æ¡æ•°æ®çš„å¯¹è¯å†…å®¹ï¼Œåˆ†ä¸ºé—®å€™è¯­ã€ä¸»è§’(user)å’Œç³»ç»Ÿ(assistant)\\nfields_formatï¼šè¡¨ç¤ºçŠ¶æ€ä¿¡æ¯çš„å¡«å……æ ¼å¼promptï¼Œå¯èƒ½æ˜¯åˆ—è¡¨ã€è¡¨æ ¼ã€JSONç­‰å„ç§å½¢å¼\\nformat_listï¼šè¡¨ç¤ºçŠ¶æ€ä¿¡æ¯çš„å¡«å……ç»“æœ\\n\\nçŠ¶æ€ä¿¡æ¯çš„ç¤ºä¾‹å¦‚ä¸‹\\n**å¥åº·çŠ¶æ€**: ğŸŒ¿ è‰¯å¥½ï¼Œèº«ä½“é¢¤æŠ–\\n**ç²¾ç¥çŠ¶æ€**: ğŸŒŸ ææƒ§ï¼Œæåº¦ç´§å¼ â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LooksJuicy/Chinese-Roleplay-Novel.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"bid-announcement-zh-v1.0","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tongda/bid-announcement-zh-v1.0","creator_name":"Qianwenshu","creator_url":"https://huggingface.co/Tongda","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸ¦™ Bid Announcement Dataset - Alpaca Format\\n\\t\\n\\nWelcome to the Bid Announcement Dataset page! This dataset contains 2,000 tender and bid announcements from China, preprocessed in Alpaca format, making it suitable for direct use in fine-tuning natural language processing (NLP) models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸ“„ Dataset Overview\\n\\t\\n\\nThis dataset consists of carefully selected bid announcements from various industries and procurement projects within China. The dataset is particularly useful forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tongda/bid-announcement-zh-v1.0.","first_N":5,"first_N_keywords":["Chinese","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Chinese-Emotional-Intelligence","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LooksJuicy/Chinese-Emotional-Intelligence","creator_name":"LooksJuicy","creator_url":"https://huggingface.co/LooksJuicy","description":"æœ¬é¡¹ç›®æ—¨åœ¨æå‡å¤§æ¨¡å‹æƒ…å•†ï¼Œæºæ•°æ®æ¥è‡ªç½‘ç»œï¼Œé€šè¿‡ä¸æˆ‘ä¸Šä¸ªé¡¹ç›®ç±»ä¼¼çš„æ–¹å¼æ„å»ºé—®ç­”å¯¹ã€‚\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLUâ€™s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increasesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"Yue-Benchmark","keyword":"yue chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BillBao/Yue-Benchmark","creator_name":"Bao","creator_url":"https://huggingface.co/BillBao","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow Far Can Cantonese NLP Go? Benchmarking Cantonese Capabilities of Large Language Models\\n\\t\\n\\n\\nHomepage: https://github.com/jiangjyjy/Yue-Benchmark\\nRepository: https://huggingface.co/datasets/BillBao/Yue-Benchmark\\nPaper: How Far Can Cantonese NLP Go? Benchmarking Cantonese Capabilities of Large Language Models.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe rapid evolution of large language models (LLMs), such as GPT-X and Llama-X, has driven significant advancements in NLP, yet much of thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BillBao/Yue-Benchmark.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","translation","Yue Chinese","multilingual"],"keywords_longer_than_N":true},
	{"name":"chinese-cosmopedia","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opencsg/chinese-cosmopedia","creator_name":"opencsg","creator_url":"https://huggingface.co/opencsg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Cosmopedia Dataset          [ä¸­æ–‡]    [English]\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n[OpenCSG Community]   [ğŸ‘¾github]  [wechat]  [Twitter] \\n\\n\\n\\n\\nğŸ“–Technical Report\\nThe Chinese Cosmopedia dataset contains a total of 15 million entries, approximately 60B tokens. Two key elements in constructing the synthetic dataset are seed data and prompts. Seed data determines the theme of the generated content, while prompts define the style of the data (such as textbooks, stories, tutorials, or children's books). Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/opencsg/chinese-cosmopedia.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10B<n<100B","arxiv:2501.08197"],"keywords_longer_than_N":true},
	{"name":"fuzi-mingcha-v1_0-data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SDUIRLab/fuzi-mingcha-v1_0-data","creator_name":"Information Retrieval Lab at Shandong University","creator_url":"https://huggingface.co/SDUIRLab","description":"\\nğŸ± Github Repo \\n\\n\\n\\næ¨¡å‹ huggingface é“¾æ¥ï¼šhttps://huggingface.co/datasets/SDUIRLab/fuzi-mingcha-v1_0\\n\\næ•°æ® huggingface é“¾æ¥ï¼šhttps://huggingface.co/datasets/SDUIRLab/fuzi-mingcha-v1_0-data\\n\\nGitHub é“¾æ¥ï¼šhttps://github.com/irlab-sdu/fuzi.mingcha\\n\\næ•°æ® é­”æ­é“¾æ¥ï¼šhttps://www.modelscope.cn/datasets/furyton/fuzi-mingcha-v1_0-data\\n\\næ¨¡å‹ é­”æ­é“¾æ¥ï¼šhttps://www.modelscope.cn/models/furyton/fuzi-mingcha-v1_0\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå¤«å­â€¢æ˜å¯Ÿå¸æ³•å¤§æ¨¡å‹å¾®è°ƒè®­ç»ƒæ•°æ®å½’æ¡£\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®ä¿¡æ¯\\n\\t\\n\\næ•°æ®é›†ä¸»è¦åˆ†ä¸ºå››ç±»ï¼š1. é€šç”¨å¾®è°ƒæ•°æ®é›†ï¼›2. åŸºäºæ³•æ¡çš„é—®ç­”æ•°æ®é›†ï¼›3. æ¡ˆä¾‹æ£€ç´¢ã€æ¡ˆä¾‹åˆ†æç±»æ•°æ®é›†ï¼›4. ä¸‰æ®µè®ºåˆ¤å†³æ•°æ®é›†ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SDUIRLab/fuzi-mingcha-v1_0-data.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","ğŸ‡ºğŸ‡¸ Region: US","legal"],"keywords_longer_than_N":false},
	{"name":"muri-it","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"sys-novel-cleaned","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/sys-novel-cleaned","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIS-Novel\\n\\t\\n\\nå°†a686d380/sis-novelä¸­çš„æ–‡æœ¬è¿›è¡Œäº†åˆæ­¥çš„æ¸…æ´—, å½¢æˆäº†çº¯æ–‡æœ¬æ•°æ®é›†, å¯ç”¨äºæ¨¡å‹é¢„è®­ç»ƒ\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","gpl-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"mgsm","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jbross-ibm-research/mgsm","creator_name":"J Bross","creator_url":"https://huggingface.co/jbross-ibm-research","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MGSM\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCopy and merge of this MGSM Dataset, Catalan version, Basque version, Galician version, but in training samples we removed the prompt formatting, e.g. removed Question: ... in question field or Answer: ... in answer field.\\nMultilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper Language models are multilingual chain-of-thought reasoners.\\nThe same 250 problems fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jbross-ibm-research/mgsm.","first_N":5,"first_N_keywords":["text2text-generation","found","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"cantonese-chinese","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/cantonese-chinese","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCantonese-Mandarin-Traditional Chinese Parallel Corpus\\n\\t\\n\\nThis dataset provides a parallel corpus of Cantonese, Simplified Chinese, and Traditional Chinese text.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Composition\\n\\t\\n\\nThe dataset is a combination of two existing datasets:\\n\\nbotisan-ai/cantonese-mandarin-translations\\nraptorkwok/cantonese-chinese-dataset-gen2\\n\\nTrain Set: Merged from both source datasets\\nTest and Validation Sets: Derived from raptorkwok/cantonese-chinese-dataset-gen2\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/cantonese-chinese.","first_N":5,"first_N_keywords":["translation","text-classification","Chinese","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Traditional-Chinese-Medicine-Dataset-Pretrain","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SylvanL/Traditional-Chinese-Medicine-Dataset-Pretrain","creator_name":"SylvanLiu","creator_url":"https://huggingface.co/SylvanL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå¯å¤çº³ä»Šï¼Œåšå¾·ç²¾æœ¯\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®ä»‹ç»\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\téç½‘ç»œæ¥æºçš„é«˜è´¨é‡ä¸­åŒ»æ•°æ®é›†-é¢„è®­ç»ƒ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHigh-Quality Traditional Chinese Medicine Dataset from Non-Internet Sources - Pretraining\\n\\t\\n\\nè¯¥æ•°æ®é›†ç»è¿‡å¤§é‡äººåŠ›å’Œèµ„æºçš„æŠ•å…¥ç²¾å¿ƒæ„å»ºï¼Œä»¥å…±å»ºLLMé«˜è´¨é‡ä¸­æ–‡ç¤¾åŒºä¸ºå·±ä»»ã€‚\\nåŒ…å«çº¦1GBçš„ä¸­åŒ»å„ä¸ªé¢†åŸŸä¸´åºŠæ¡ˆä¾‹ã€åå®¶å…¸ç±ã€åŒ»å­¦ç™¾ç§‘ï¼Œåè¯è§£é‡Šç­‰ä¼˜è´¨å†…å®¹ï¼Œæ¶µç›–å…¨é¢ï¼Œé…æ¯”å‡è¡¡ã€‚\\næ•°æ®é›†ä¸»è¦ç”±éç½‘ç»œæ¥æºçš„å†…éƒ¨æ•°æ®æ„æˆï¼Œå¹¶99%ä¸ºç®€ä½“ä¸­æ–‡å†…å®¹ï¼Œå†…å®¹è´¨é‡ä¼˜å¼‚ï¼Œä¿¡æ¯å¯†åº¦å¯è§‚ã€‚\\næ³¨æ„ï¼šè¯¥æ•°æ®é›†ä»…é€‚ç”¨äºé¢„è®­ç»ƒæˆ–ç»§ç»­é¢„è®­ç»ƒç”¨é€”ï¼Œé’ˆå¯¹SFT/IFTçš„QAæ•°æ®é›†è¯¦è§ï¼šSylvanL/Traditional-Chinese-Medicine-Dataset-SFTâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SylvanL/Traditional-Chinese-Medicine-Dataset-Pretrain.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"TurtleBench1.5k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Duguce/TurtleBench1.5k","creator_name":"Qingchen Yu","creator_url":"https://huggingface.co/Duguce","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nTurtleBench is a novel evaluation benchmark designed to assess the reasoning capabilities of large language models (LLMs) using yes/no puzzles (commonly known as \\\"Turtle Soup puzzles\\\"). This dataset is constructed based on user guesses collected from our online Turtle Soup Puzzle platform, providing a dynamic and interactive means of evaluation. Unlike traditional static evaluation benchmarks, TurtleBench focuses on testing models in interactive settings to betterâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Duguce/TurtleBench1.5k.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","language-modeling","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"lexisyn-zh-en-1.0","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/skML/lexisyn-zh-en-1.0","creator_name":"sparkastML","creator_url":"https://huggingface.co/skML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLexiSyn 1.0\\n\\t\\n\\nA synthetic dataset of Chinese-English parallel corpus, released by sparkastML.\\n146,917 entries in total, which is about 300,000 sentences.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic data sources\\n\\t\\n\\nAbout 43% are scraped from the Internet by our crawler in September 2024. \\nThe rest comes from random sampling of the part-00185-6f0afd98-d375-4d7f-8299-ac5e070bf4fc-c000.jsonl file in CCI3-HQ.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic method\\n\\t\\n\\nWe use LLMs for translation to create a dataset from raw data toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/skML/lexisyn-zh-en-1.0.","first_N":5,"first_N_keywords":["translation","Chinese","English","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"vqa","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldcuisines/vqa","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\\n\\t\\n\\n\\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 Octoberâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa.","first_N":5,"first_N_keywords":["multilingual","English","Indonesian","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"atlassian-qna","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/youngmon/atlassian-qna","creator_name":"youngseo","creator_url":"https://huggingface.co/youngmon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸ“„ Question and Answer for Atlassian Products\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nAtlassian Community\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Description\\n\\t\\n\\nThe dataset primarily includes questions, answers, tags, and URLs.\\n\\nQuestions contain the author, title, and content of the post.\\nAnswers include usage instructions, solutions, and other information provided by engineers and users.\\nTags represent the categories or topics of the post.\\nURLs provide links to the original documents.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/youngmon/atlassian-qna.","first_N":5,"first_N_keywords":["question-answering","English","Korean","Chinese","Japanese"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"achinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"vqa","keyword":"min nan chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldcuisines/vqa","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\\n\\t\\n\\n\\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 Octoberâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa.","first_N":5,"first_N_keywords":["multilingual","English","Indonesian","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"vqa","keyword":"yue chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldcuisines/vqa","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\\n\\t\\n\\n\\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 Octoberâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa.","first_N":5,"first_N_keywords":["multilingual","English","Indonesian","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"zhuang","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"diffusion_stage_design_japanese_anime_style","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mintz1104/diffusion_stage_design_japanese_anime_style","creator_name":"Huang","creator_url":"https://huggingface.co/mintz1104","description":"mintz1104/diffusion_stage_design_japanese_anime_style dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-image","Chinese","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"chinese-fineweb-edu-v2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opencsg/chinese-fineweb-edu-v2","creator_name":"opencsg","creator_url":"https://huggingface.co/opencsg","description":"\\n\\t\\n\\t\\t\\n\\t\\tWe recommend you to use the improved version Fineweb-edu-chinese-v2.1 !\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tChinese Fineweb Edu Dataset V2          [ä¸­æ–‡]    [English]\\n\\t\\n\\n\\n\\n\\n\\n\\n[OpenCSG Community]   [ğŸ‘¾github]  [wechat]  [Twitter] \\n\\n\\n\\nğŸ“–Technical Report\\nChinese Fineweb Edu Dataset V2 is a comprehensive upgrade of the original Chinese Fineweb Edu, designed and optimized for natural language processing (NLP) tasks in the education sector. This high-quality Chinese pretraining dataset has undergone significantâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/opencsg/chinese-fineweb-edu-v2.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100M - 1B","parquet"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-marvl","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-marvl","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\tMaRVL\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tThis is a copy from the original repo: https://github.com/marvl-challenge/marvl-code\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{liu-etal-2021-visually,\\n    title = \\\"Visually Grounded Reasoning across Languages and Cultures\\\",\\n    author = \\\"Liu, Fangyu  and\\n      Bugliarello, Emanuele  and\\n      Ponti, Edoardo Maria  and\\n      Reddy, Siva  and\\n      Collier, Nigel  and\\n      Elliott, Desmond\\\",\\n    booktitle = \\\"Proceedings of the 2021â€¦ See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-marvl.","first_N":5,"first_N_keywords":["visual-question-answering","Indonesian","Swahili","Tamil","Turkish"],"keywords_longer_than_N":true},
	{"name":"meissa-unalignments","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/meissa-unalignments","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMeissa Unalignments\\n\\t\\n\\nDuring the Meissa-Qwen2.5 training process, I noticed that Qwen's censorship was somehow bound to its chat template. Thus, I created this dataset with one system prompt, hoping to make it more effective in uncensoring models.\\nThe dataset consists of:\\n\\nV3N0M/Jenna-50K-Alpaca-Uncensored\\njondurbin/airoboros-3.2, category = unalignment\\nOrion-zhen/dpo-toxic-zh, prompt and chosen\\nNobodyExistsOnTheInternet/ToxicQAFinal\\n\\n","first_N":5,"first_N_keywords":["text-generation","English","Chinese","gpl-3.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"CII-Bench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-a-p/CII-Bench","creator_name":"Multimodal Art Projection","creator_url":"https://huggingface.co/m-a-p","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCII-Bench\\n\\t\\n\\nğŸŒ Homepage | ğŸ¤— Dataset | GitHub |  ğŸ¤— Paper | ğŸ“– arXiv \\n\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nCII-Bench comprises 698 Chinese images, each accompanied by 1 to 3 multiple-choice questions, totaling 800 questions. CII-Bench encompasses images from six distinct domains: Life, Art, Society, Environment, Politics, and Chinese Traditional Culture. It also features a diverse array of image types, including Illustrations, Memes, Posters, Multi-panel Comics, Single-panel Comicsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m-a-p/CII-Bench.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"LongReward-10k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/THUDM/LongReward-10k","creator_name":"Knowledge Engineering Group (KEG) & Data Mining at Tsinghua University","creator_url":"https://huggingface.co/THUDM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLongReward-10k\\n\\t\\n\\n\\n  ğŸ’» [Github Repo] â€¢ ğŸ“ƒ [LongReward Paper] \\n\\n\\nLongReward-10k dataset contains 10,000 long-context QA instances (both English and Chinese, up to 64,000 words). \\nThe sft split contains SFT data generated by GLM-4-0520, following the self-instruct method in LongAlign. Using this split, we supervised fine-tune two models: LongReward-glm4-9b-SFT and LongReward-llama3.1-8b-SFT, which are based on GLM-4-9B and Meta-Llama-3.1-8B, respectively. \\nThe dpo_glm4_9b andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/THUDM/LongReward-10k.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"m-ArenaHard","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/m-ArenaHard","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-ArenaHard\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-ArenaHard.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"DCoT","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Seikaijyu/DCoT","creator_name":"Seikaijyu","creator_url":"https://huggingface.co/Seikaijyu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå‘æ•£æ€§æ€ç»´é“¾ï¼ˆDivergent-Chain-of-Thoughtï¼‰æ•°æ®é›†\\n\\t\\n\\n\\næœ¬æ•°æ®é›†åŒ…å«äº†5904æ¡å•æ¡æ•°æ®æœ€å¤§é•¿åº¦4820tokençš„å•è½®QAæ•°æ®é›†ï¼Œå¤§éƒ¨åˆ†æ•°æ®é•¿åº¦é›†ä¸­åœ¨2000tokenä»¥ä¸Š\\nè¿™æ˜¯ä¸€ä¸ªè¢«äººå·¥ç²¾ç»†åŒ–æ¸…æ´—è¿‡çš„æ•°æ®é›†ï¼Œæ­¤æ•°æ®ä½¿ç”¨Gemini-1.5-Pro-001åˆ¶ä½œï¼ˆæ²¡æƒ³åˆ°åˆ¶ä½œå¥½å°±å‘å¸ƒäº†002ï¼Œwwwï¼‰\\nç”¨äºæµ‹è¯•CoTæ˜¯å¦èƒ½å¢å¼ºæ¨¡å‹èƒ½åŠ›è€Œåˆ¶ä½œçš„æ•°æ®é›†ï¼Œä½¿ç”¨state tuningè®­ç»ƒå¹¶æµ‹è¯•å¾—åˆ°äº†ä»¥ä¸‹å®éªŒè§‚æµ‹ç»“æœRWKV6-7B-v2.1-DCoT.state\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ¸…æ´—æœŸé—´å‘ç°æ•°æ®é›†å­˜åœ¨è¿™ç±»åƒåœ¾é—®é¢˜ï¼Œä¸è¿‡æˆ‘åœ¨æ„é€ æ•°æ®çš„promptä¸­æœ‰è¦æ±‚æ¨¡å‹çº é”™ï¼Œå› æ­¤æ­¤ç±»è¯­æ–™åè€Œèƒ½ä½¿LLMè‡ªå¸¦ECCï¼ˆbushiï¼‰\\n\\t\\n\\n1. å°æ˜çš„å®¶åº­ä½å€æ˜¯ï¼Ÿ\\n2. è¯·å†™ä¸€ç¯‡ä½œæ–‡ï¼Œä¸»é¢˜ï¼‰è¯·ä½¿ç”¨Javaå†™ä¸€ä¸ªhello worldç¨‹åºã€‚\\n3. æ ¹æ®ä»¥ä¸‹å†…å®¹ç¼–å†™ä¸€ç¯‡ä½œæ–‡ï¼šã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ¨¡å‹çº é”™åå›ç­”å¤§è‡´å¦‚ä¸‹\\n\\t\\n\\nQ: è¯·å†™ä¸€ç¯‡ä½œæ–‡ï¼Œä¸»é¢˜ï¼‰è¯·ä½¿ç”¨Javaå†™ä¸€ä¸ªhello worldç¨‹åºã€‚\\n\\nA:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Seikaijyu/DCoT.","first_N":5,"first_N_keywords":["Chinese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"AVEdate","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeroMN/AVEdate","creator_name":"zeroTT","creator_url":"https://huggingface.co/zeroMN","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zeroMN/AVEdate.","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","Chinese","English"],"keywords_longer_than_N":true},
	{"name":"MATH-Hard-Chinese","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ALmonster/MATH-Hard-Chinese","creator_name":"The little monster will smile","creator_url":"https://huggingface.co/ALmonster","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\nThis dataset is derived from the training set portion of MATH-Hard (https://huggingface.co/datasets/lighteval/MATH-Hard). The English content was translated into Chinese using LLM, and data with translation errors or failures has been removed.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nPlease check the license in the original dataset MathInstruct.\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MathInstruct-Chinese","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ALmonster/MathInstruct-Chinese","creator_name":"The little monster will smile","creator_url":"https://huggingface.co/ALmonster","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\nThis dataset is derived from MathInstruct (https://huggingface.co/datasets/TIGER-Lab/MathInstruct). The English content was translated into Chinese using LLM, and data with translation errors or failures has been removed.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nPlease check the license of each subset in the original dataset MathInstruct.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nMathInstruct is a meticulously curated instruction tuning dataset that is lightweight yet generalizable. MathInstruct isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ALmonster/MathInstruct-Chinese.","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ChemGPT-2.0-Data","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ALmonster/ChemGPT-2.0-Data","creator_name":"The little monster will smile","creator_url":"https://huggingface.co/ALmonster","description":"Our team has open-sourced the training data (ChemGPT-2.0-Data) for ChemGPT 2.0. The data includes the previously open-sourced ChemGPT-from-book dataset, available at https://huggingface.co/datasets/ALmonster/ChemGPT-from-book.\\nChemGPT-2.0-Data is a dataset specifically designed for question-answering in the chemistry domain. It primarily consists of two parts: \\n\\nConversation instructions derived from real chemical books.\\nDerived data from an instruction library (inspired by WizardLM:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ALmonster/ChemGPT-2.0-Data.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"SingMOS","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TangRain/SingMOS","creator_name":"Tang","creator_url":"https://huggingface.co/TangRain","description":"paper link: SingMOS: An extensive Open-Source Singing Voice Dataset for MOS Prediction\\nNOTICE: Our new paper has not been released and the information in SingMOS paper remain in SingMOS_v1. We will update it soon.\\nIf you want to use our pretrained SingMOS model, you can visit our repo at Singing MOS Predictor.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nSingMOS includes 6583 Chinese and Japanese vocal clips, totaling 9.07 hours in duration. \\nIt covers samples mainly in 16 kHz and a little in 24kHz and 44.1kHz.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/TangRain/SingMOS.","first_N":5,"first_N_keywords":["Chinese","Japanese","cc-by-4.0","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"MMEvol","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tongyi-ConvAI/MMEvol","creator_name":"Tongyi-ConvAI","creator_url":"https://huggingface.co/Tongyi-ConvAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MMEvol-480K\\n\\t\\n\\nThis is the official data collection of the paper \\\"MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct\\\"\\nPlease see paper & website for more information:\\n\\narXiv: https://arxiv.org/pdf/2409.05840\\nwebsite: https://mmevol.github.io/home_page.html\\nGithub: https://github.com/RainBowLuoCS/MMEvol\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Tongyi-ConvAI generates this dataset for multi-modal supervised fine-tuning. This dataset was used to train ourâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tongyi-ConvAI/MMEvol.","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"achinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"yue chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"yue chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"Lappland-the-Decadenza","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Lappland-the-Decadenza","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Lappland-the-Decadenza dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","Italian"],"keywords_longer_than_N":true},
	{"name":"P-MMEval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Qwen/P-MMEval","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tP-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce a multilingual benchmark, P-MMEval, covering effective fundamental and capability-specialized datasets. We extend the existing benchmarks, ensuring consistent language coverage across all datasets and providing parallel samples among multiple languages, supporting up to 10 languages from 8 language families (i.e., en, zh, ar, es, ja, ko, th, fr, ptâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Qwen/P-MMEval.","first_N":5,"first_N_keywords":["Arabic","Spanish","French","Japanese","Korean"],"keywords_longer_than_N":true},
	{"name":"emova-sft-speech-231k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-SFT-Speech-231K\\n\\t\\n\\n\\n\\n\\nğŸ¤— EMOVA-Models | ğŸ¤— EMOVA-Datasets | ğŸ¤— EMOVA-Demo \\nğŸ“„ Paper | ğŸŒ Project-Page | ğŸ’» Github | ğŸ’» EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-SFT-Speech-231K is a comprehensive dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-231K is part of EMOVA-Datasets collection and is used inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k.","first_N":5,"first_N_keywords":["audio-to-audio","automatic-speech-recognition","text-to-speech","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBelebele-Fleurs\\n\\t\\n\\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\\n\\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30â€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"TextRewrite","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/have-to-name/TextRewrite","creator_name":"WuJing","creator_url":"https://huggingface.co/have-to-name","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBSTC-TextRewrite Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset includes text data that has been annotated for rewriting using the manual annotation method described in our paper to enhance the performance of speech translation systems. It is based on the original BSTC dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset consists of pairs of segments structured as follows:\\n\\nleft: The ASR transcript.\\nright: The human annotation text.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Statisticsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/have-to-name/TextRewrite.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"CodeArena","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CSJianYang/CodeArena","creator_name":"Yang Jian","creator_url":"https://huggingface.co/CSJianYang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTo bridge the gap between the model-generated response and human preference, we present a rigorous human-curated benchmark CodeArena to emulate the complexity and diversity of real-world coding tasks, where 397 high-quality samples spanning 40 categories and 40 languages, carefully curated from user queries.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Example\\n\\t\\n\\nAn example of 'validation' looks as follows:\\n{\\n    \\\"id\\\": \\\"60670a8d9b1e39dd845fb1639d0d8b86\\\",\\n    \\\"messages\\\": \\\"[{'role': 'user'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CSJianYang/CodeArena.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/include-base-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-base (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-base-44.","first_N":5,"first_N_keywords":["text2text-generation","multiple-choice","Albanian","Arabic","Armenian"],"keywords_longer_than_N":true},
	{"name":"open-dict-words-ipa","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-dict Words IPA\\n\\t\\n\\nThis dataset is a copy of https://github.com/open-dict-data/ipa-dict\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nIPA data is currently available for the following languages:\\n\\n\\t\\n\\t\\t\\nLanguage\\nCode\\n\\n\\n\\t\\t\\nar\\nArabic (Modern Standard)\\n\\n\\nde\\nGerman\\n\\n\\nen_UK\\nEnglish (Received Pronunciation)\\n\\n\\nen_US\\nEnglish (General American)\\n\\n\\neo\\nEsperanto\\n\\n\\nes_ES\\nSpanish (Spain)\\n\\n\\nes_MX\\nSpanish (Mexico)\\n\\n\\nfa\\nPersian\\n\\n\\nfi\\nFinnish\\n\\n\\nfr_FR\\nFrench (France)\\n\\n\\nfr_QC\\nFrench (QuÃ©bec)\\n\\n\\nis\\nIcelandic\\n\\n\\nja\\nJapanese\\n\\n\\njamâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa.","first_N":5,"first_N_keywords":["Arabic","German","English","Esperanto","Spanish"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/include-lite-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-lite (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-lite-44.","first_N":5,"first_N_keywords":["text2text-generation","multiple-choice","Albanian","Arabic","Armenian"],"keywords_longer_than_N":true},
	{"name":"open-dict-words-ipa","keyword":"yue chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-dict Words IPA\\n\\t\\n\\nThis dataset is a copy of https://github.com/open-dict-data/ipa-dict\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nIPA data is currently available for the following languages:\\n\\n\\t\\n\\t\\t\\nLanguage\\nCode\\n\\n\\n\\t\\t\\nar\\nArabic (Modern Standard)\\n\\n\\nde\\nGerman\\n\\n\\nen_UK\\nEnglish (Received Pronunciation)\\n\\n\\nen_US\\nEnglish (General American)\\n\\n\\neo\\nEsperanto\\n\\n\\nes_ES\\nSpanish (Spain)\\n\\n\\nes_MX\\nSpanish (Mexico)\\n\\n\\nfa\\nPersian\\n\\n\\nfi\\nFinnish\\n\\n\\nfr_FR\\nFrench (France)\\n\\n\\nfr_QC\\nFrench (QuÃ©bec)\\n\\n\\nis\\nIcelandic\\n\\n\\nja\\nJapanese\\n\\n\\njamâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa.","first_N":5,"first_N_keywords":["Arabic","German","English","Esperanto","Spanish"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"Chinese_Multi-Emotion_Dialogue_Dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Johnson8187/Chinese_Multi-Emotion_Dialogue_Dataset","creator_name":"Johnson","creator_url":"https://huggingface.co/Johnson8187","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese_Multi-Emotion_Dialogue_Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸ“„ Description\\n\\t\\n\\nThis dataset contains 4159 Chinese dialogues annotated with 8 distinct emotion categories. The data is suitable for emotion recognition, sentiment analysis, and other NLP tasks involving Chinese text.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Sources:\\n\\t\\n\\n\\nDaily Conversations: Captured from natural, informal human conversations.\\nMovie Dialogues: Extracted from diverse Chinese-language movies.\\nAI-Generated Dialogues: Synthesized usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Johnson8187/Chinese_Multi-Emotion_Dialogue_Dataset.","first_N":5,"first_N_keywords":["text-classification","text-generation","fill-mask","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU-Lite","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 15 languages, including English. It is \\\"lite\\\" version of the original Global-MMLU dataset ğŸŒ.\\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \\n\\nCurated by: Professional annotators and contributors of Cohere Forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite.","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReranker training data\\n\\t\\n\\nThis data was generated using 4 steps:\\n\\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \\\"1\\\", \\\"2\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"achinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"2M-Belebele","keyword":"mandarin chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2M-Belebele\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\\n\\t\\n\\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \\nThe speech dataset is built from aligning Belebele, Flores200 and Fleursâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.","first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Bulgarian","Panjabi","English"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"yue chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"smoltalk-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opencsg/smoltalk-chinese","creator_name":"opencsg","creator_url":"https://huggingface.co/opencsg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese SmolTalk Dataset          [ä¸­æ–‡]    [English]\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n[OpenCSG Community]   [ğŸ‘¾github]  [wechat]  [Twitter] \\n\\n\\n\\nğŸ“–Technical Report\\nsmoltalk-chinese is a Chinese fine-tuning dataset constructed with reference to the SmolTalk dataset. It aims to provide high-quality synthetic data support for training large language models (LLMs). The dataset consists entirely of synthetic data, comprising over 700,000 entries. It is specifically designed to enhance the performance of Chineseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/opencsg/smoltalk-chinese.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10B<n<100B","arxiv:2501.08197"],"keywords_longer_than_N":true},
	{"name":"MultiLingualSentiment","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clapAI/MultiLingualSentiment","creator_name":"clapAI","creator_url":"https://huggingface.co/clapAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nMultilingualSentiment is a sentiment classification dataset that encompasses three sentiment labels: Positive, Neutral, Negative\\nThe dataset spans multiple languages and covers a wide range of domains, making it ideal for multilingual sentiment analysis tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\nThe dataset was meticulously collected and aggregated from various sources, including Hugging Face and Kaggle. These sources provide diverse languages and domains to ensure aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/clapAI/MultiLingualSentiment.","first_N":5,"first_N_keywords":["text-classification","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"Chinese-Tag-Extraction","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Johnson8187/Chinese-Tag-Extraction","creator_name":"Johnson","creator_url":"https://huggingface.co/Johnson8187","description":"Johnson8187/Chinese-Tag-Extraction dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","text-classification","zero-shot-classification","feature-extraction","Chinese"],"keywords_longer_than_N":true},
	{"name":"Chinese-Tag-Extraction","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Johnson8187/Chinese-Tag-Extraction","creator_name":"Johnson","creator_url":"https://huggingface.co/Johnson8187","description":"Johnson8187/Chinese-Tag-Extraction dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","text-classification","zero-shot-classification","feature-extraction","Chinese"],"keywords_longer_than_N":true},
	{"name":"Ancient_Chinese_Study_252k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TroyeML/Ancient_Chinese_Study_252k","creator_name":"Troye","creator_url":"https://huggingface.co/TroyeML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis is a high-quality dataset focusing on ancient Chinese, with data from FireFly and COIG-CQIA. \\nAt the same time, the author created a COT dataset for the translation of OldancientChinese into English and the translation from English to ancient Chinese.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\nLanguage(s) (NLP): Chinese\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n{\\n\\\"instruction\\\":\\\"è‡ªå…¬å¤§å·åˆå‘ï¼Œçˆ°æš¨å‘Šæˆï¼Œçµç¥¥ç‚³ç„•ï¼Œä¸å¯èƒœçºªï¼Œå²‚ä¼Šç´ é›‰è¿œè‡³ï¼Œå˜‰ç¦¾è¿‘å½’è€Œå·²å“‰ï¼\\\\nTransfer this ancient Chinese sentenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TroyeML/Ancient_Chinese_Study_252k.","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"CoT-XLang","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Egor-AI/CoT-XLang","creator_name":"Egor AI","creator_url":"https://huggingface.co/Egor-AI","description":"RU:CoT-XLang â€” ÑÑ‚Ğ¾ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚, ÑĞ¾ÑÑ‚Ğ¾ÑÑ‰Ğ¸Ğ¹ Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ñ Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼Ğ¸ (Chain-of-Thought, CoT) Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ°Ñ…, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¸Ğ¹, Ñ€ÑƒÑÑĞºĞ¸Ğ¹, ÑĞ¿Ğ¾Ğ½ÑĞºĞ¸Ğ¹ Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ. ĞĞ½ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ñ… Ğ¿Ğ¾ÑÑĞ½ĞµĞ½Ğ¸Ğ¹ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ ÑˆĞ°Ğ³Ğ¾Ğ². Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ¾ĞºĞ¾Ğ»Ğ¾ 2,419,912 Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ², Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡Ğ°Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ñ‹Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ.\\nĞ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ:Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Egor-AI/CoT-XLang.","first_N":5,"first_N_keywords":["text-generation","question-answering","Russian","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"BoundingDocs","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/letxbe/BoundingDocs","creator_name":"Letxbe","creator_url":"https://huggingface.co/letxbe","description":"\\n\\nBoundingDocs\\n\\nğŸ” The largest spatially-annotated dataset for Document Question Answering\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBoundingDocs is a unified dataset for Document Question Answering (QA) that includes spatial annotations. It consolidates multiple public datasets from Document AI and Visually Rich Document Understanding (VRDU) domains. The dataset reformulates Information Extraction (IE) tasks into QA tasks, making it a valuable resource for training and evaluating Large Languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/letxbe/BoundingDocs.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","Italian","Spanish"],"keywords_longer_than_N":true},
	{"name":"haiku-zh","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/haiku-zh","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯µè¯»ä¿³å¥å§\\n\\t\\n\\nä¿³å¥æ•°æ®é›†\\nå¤§æ¨¡å‹ç¼–å†™å›å¤\\näººå·¥å†å®¡æ ¸\\n\\näººåŠ›æœ‰ç©·æ—¶\\næˆ‘åªç®€å•å®¡æ ¸è¿‡\\næ— æ˜æ˜¾é”™è¯¯\\n\\næœ¬ä¸ºæ‰“æ²¹è¯—\\nä¸ç®¡æœ‰æ²¡æœ‰ç¾æ„Ÿ\\nå°±æ˜¯å›¾ä¸€ä¹\\n\\näº¦å¯DPO\\nè®©æ¨¡å‹ç”Ÿæˆæ‹’ç»\\né…å¯¹æ•°æ®é›†\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","gpl-3.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"UltraFeedback-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opencsg/UltraFeedback-chinese","creator_name":"opencsg","creator_url":"https://huggingface.co/opencsg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese SmolTalk Dataset          [ä¸­æ–‡]    [English]\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n[OpenCSG Community]   [ğŸ‘¾github]  [wechat]  [Twitter] \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUltraFeedback Chinese Dataset\\n\\t\\n\\nUltraFeedback-Chinese is a Chinese version developed based on the construction method of the UltraFeedback dataset, designed specifically for training robust reward and critic models. This dataset supports two training methods: PPO (Proximal Policy Optimization) and DPO (Direct Preference Optimization).â€¦ See the full description on the dataset page: https://huggingface.co/datasets/opencsg/UltraFeedback-chinese.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10B<n<100B","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"DualMath-1.1M","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/URSA-MATH/DualMath-1.1M","creator_name":"URSA-MATH","creator_url":"https://huggingface.co/URSA-MATH","description":"\\n\\t\\n\\t\\t\\n\\t\\tDualMath-1.1M\\n\\t\\n\\nImage data can be downloaded from the following address:\\n\\nMAVIS: https://github.com/ZrrSkywalker/MAVIS, https://drive.google.com/drive/folders/1LGd2JCVHi1Y6IQ7l-5erZ4QRGC4L7Nol.\\nMultimath: https://huggingface.co/datasets/pengshuai-rin/multimath-300k.\\nGeo170k: https://huggingface.co/datasets/Luckyjhg/Geo170K.\\nVarsityTutors: https://huggingface.co/datasets/Math-PUMA/Math-PUMA_Data_Stage2. \\nMathV360K: https://huggingface.co/datasets/Zhiqiang007/MathV360K.\\n\\nThe image dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/URSA-MATH/DualMath-1.1M.","first_N":5,"first_N_keywords":["question-answering","image-text-to-text","English","Chinese","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"SMPQA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/SMPQA","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSMPQA (Synthetic Multilingual Plot QA)\\n\\t\\n\\n\\n\\nThe SMPQA evaluation dataset proposed in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nSMPQA is composed of synthetic bar plots and pie charts (generated using word lists of different languages) together with questions about those plots.\\nThe datasets aims at providing an initial way of evaluating multilingual OCR capabilities of models in arbritrary languages.\\nThere are two sub-tasks: \\n\\nGrounding text labelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/SMPQA.","first_N":5,"first_N_keywords":["visual-question-answering","English","Zulu","Indonesian","Italian"],"keywords_longer_than_N":true},
	{"name":"role-play-chinese","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Johnson8187/role-play-chinese","creator_name":"Johnson","creator_url":"https://huggingface.co/Johnson8187","description":"ç¹é«”ä¸­æ–‡   English\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRole-Play Chinese Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç°¡ä»‹\\n\\t\\n\\né€™æ˜¯ä¸€å€‹å°ˆç‚ºè§’è‰²æ‰®æ¼”å°è©±è¨­è¨ˆçš„ä¸­æ–‡æ•¸æ“šé›†ï¼Œæ•¸æ“šç”± AI ç”Ÿæˆï¼Œé©ç”¨æ–¼è¨“ç·´å’Œè©•ä¼°è‡ªç„¶èªè¨€è™•ç†ï¼ˆNLPï¼‰æ¨¡å‹ï¼Œç‰¹åˆ¥æ˜¯å°è©±ç”Ÿæˆå’Œè§’è‰²æ‰®æ¼”ç›¸é—œçš„ä»»å‹™ã€‚æ•¸æ“šé›†ä»¥ Alpha æ ¼å¼ å„²å­˜ï¼Œæ–¹ä¾¿é€²è¡Œå¾®èª¿å’Œé€²ä¸€æ­¥çš„æ¨¡å‹è¨“ç·´ã€‚æ•¸æ“šé›†åŒ…å«å¤šç¨®å ´æ™¯å’Œè§’è‰²è¨­å®šï¼Œèƒ½å¤ å¹«åŠ©æ¨¡å‹å­¸ç¿’å¦‚ä½•åœ¨ä¸åŒçš„æƒ…å¢ƒä¸‹ç”Ÿæˆç¬¦åˆè§’è‰²æ€§æ ¼å’ŒèƒŒæ™¯çš„å°è©±ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•¸æ“šé›†çµæ§‹\\n\\t\\n\\næ•¸æ“šä»¥Alphaæ ¼å¼å„²å­˜æ–¹ä¾¿å¾®èª¿ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š\\n\\ninstruction: ä»»å‹™æŒ‡ä»¤ï¼Œæè¿°æ¨¡å‹éœ€è¦å®Œæˆçš„ä»»å‹™ã€‚\\ninput: è¼¸å…¥å…§å®¹ï¼ŒåŒ…å«å ´æ™¯æè¿°ã€éå»çš„å°è©±ä»¥åŠç•¶å‰å°è©±çš„ä¸Šä¸‹æ–‡ã€‚\\noutput: æœŸæœ›çš„æ¨¡å‹è¼¸å‡ºï¼Œå³ç¬¦åˆè§’è‰²è¨­å®šçš„å›æ‡‰ã€‚\\nsystem: è§’è‰²è¨­å®šå’ŒèƒŒæ™¯æ•…äº‹ï¼Œå¹«åŠ©æ¨¡å‹ç†è§£è§’è‰²çš„æ€§æ ¼å’Œè¡Œç‚ºæ¨¡å¼ã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç¯„ä¾‹\\n\\t\\n\\n{\\n  \\\"instruction\\\": \\\"åœ¨çµ¦å®šçš„å ´æ™¯ä¸­ï¼Œè«‹æ ¹æ“šè§’è‰²è¨­å®šå›æ‡‰å°è©±ã€‚\\\",\\n  \\\"input\\\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Johnson8187/role-play-chinese.","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"WebWalkerQA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/callanwu/WebWalkerQA","creator_name":"Jialong Wu","creator_url":"https://huggingface.co/callanwu","description":"ğŸ“‘ The paper of WebWalkerQA is available at arXiv.\\nğŸ“Š The dataset resource is a collection of 680 questions and answers from the WebWebWalker dataset.\\nğŸ™‹ The dataset is in the form of a JSON file.\\nThe keys in the JSON include:\\nQuestion, Answer, Root_Url, and Info. The Info field contains\\nmore detailed information, including Hop, Domain, Language,\\nDifficulty_Level, Source Website, and Golden_Path.\\n{\\n    \\\"Question\\\": \\\"When is the paper submission deadline for the ACL 2025 Industry Track, and whatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/callanwu/WebWalkerQA.","first_N":5,"first_N_keywords":["question-answering","Chinese","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"CUTE-Datasets","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMLI-NLP/CUTE-Datasets","creator_name":"MUCNLPï¼ˆä¸­å¤®æ°‘æ—å¤§å­¦è‡ªç„¶è¯­è¨€å¤„ç†å®éªŒå®¤ï¼‰","creator_url":"https://huggingface.co/CMLI-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tCUTE Dataset\\n\\t\\n\\nCUTE (Chinese, Uyghur, Tibetan, English) æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡å¤šè¯­è¨€æ•°æ®é›†ï¼Œä¸“é—¨è®¾è®¡ç”¨äºå¢å¼ºä½èµ„æºè¯­è¨€çš„è·¨è¯­è¨€çŸ¥è¯†è¿ç§»ã€‚æ•°æ®é›†åŒ…å«å¹³è¡Œè¯­æ–™å’Œéå¹³è¡Œè¯­æ–™ä¸¤éƒ¨åˆ†ï¼Œæ€»è§„æ¨¡çº¦50GBã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\tæ•°æ®é›†ç»„æˆ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tå¹³è¡Œè¯­æ–™ (24.70GB)\\n\\t\\n\\n\\nä¸­æ–‡ï¼š2.62GB\\nè‹±è¯­ï¼š3.49GB\\nç»´å¾å°”è¯­ï¼š7.37GB\\nè—è¯­ï¼š11.22GB\\n\\n\\n\\t\\n\\t\\t\\n\\t\\téå¹³è¡Œè¯­æ–™ (25.80GB)\\n\\t\\n\\n\\nä¸­æ–‡ï¼š2.64GB\\nè‹±è¯­ï¼š3.49GB\\nç»´å¾å°”è¯­ï¼š7.77GB\\nè—è¯­ï¼š11.90GB\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tæ•°æ®è´¨é‡\\n\\t\\n\\næ•°æ®é›†é€šè¿‡æœºå™¨ç¿»è¯‘ç”Ÿæˆï¼Œå¹¶ç»è¿‡äººå·¥è¯„ä¼°éªŒè¯ï¼š\\n\\nä¸­è‹±ç¿»è¯‘å¹³å‡å¾—åˆ†ï¼š9.1\\nä¸­ç»´ç¿»è¯‘å¹³å‡å¾—åˆ†ï¼š8.5\\nä¸­è—ç¿»è¯‘å¹³å‡å¾—åˆ†ï¼š8.6\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tç›¸å…³é“¾æ¥\\n\\t\\n\\n\\nğŸ“ è®ºæ–‡\\nğŸ¤– æ¨¡å‹\\nğŸ“‚ GitHub\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tå¼•ç”¨\\n\\t\\n\\nå¦‚æœæ‚¨ä½¿ç”¨äº†æˆ‘ä»¬çš„æ•°æ®é›†ï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š\\n@inproceedings{zhuang2025cute,\\n  title={CUTE: Aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CMLI-NLP/CUTE-Datasets.","first_N":5,"first_N_keywords":["Chinese","Uyghur","Tibetan","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"PCF","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HahahaFace/PCF","creator_name":"Zale Lee","creator_url":"https://huggingface.co/HahahaFace","description":"\\n\\t\\n\\t\\t\\n\\t\\tğŸŒ± Tsinghua-PCF-Synergy-Dataset\\n\\t\\n\\nğŸ›ï¸ æœºæ„: æ¸…åå¤§å­¦\\nğŸ”— å¼€æºåœ°å€: PCF-Synergy HuggingFace\\nğŸ“œ è¯ä¹¦: MIT\\nğŸ“… ç‰ˆæœ¬: v1.2.0 (2024-12)\\n\\n\\t\\n\\t\\t\\n\\t\\tğŸŒ æ•°æ®é›†ç®€ä»‹\\n\\t\\n\\né¢å‘äº§å“ç¢³è¶³è¿¹(PCF)è¯„ä¼°é¢†åŸŸçš„å¤§æ¨¡å‹è®­ç»ƒéœ€æ±‚ï¼Œæœ¬æ•°æ®é›†åˆ›æ–°æ€§åœ°èåˆ çŸ¥è¯†å›¾è°±çº¦æŸç”Ÿæˆ (K-SDG) ä¸ äººå·¥åé¦ˆ (RLHF)æŠ€æœ¯ï¼Œè¦†ç›–å…¨ç”Ÿå‘½å‘¨æœŸè¯„ä¼°(LCA)åœºæ™¯ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\tğŸŒ å¤šæºå¼‚æ„æ•°æ®èåˆ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\næ•°æ®ç±»åˆ«\\nå…¸å‹æ ·ä¾‹\\nå æ¯”\\n\\n\\n\\t\\t\\nå›½é™…æ ‡å‡†\\nISO 14067, GHG Protocol\\n18%\\n\\n\\nè¡Œä¸šæ•°æ®åº“\\nEcoinvent 3.8, Exiobase 3.7\\n22%\\n\\n\\nä¼ä¸šå®è·µ\\nAppleä¾›åº”é“¾æ•°æ®, Lenovoç”Ÿäº§æ—¥å¿—\\n15%\\n\\n\\nå­¦æœ¯æ–‡çŒ®\\nNature Sustainabilityè®ºæ–‡æ•°æ®é›†\\n12%\\n\\n\\nä¸“åˆ©çŸ¥è¯†\\nåä¸ºCN114996032A, Siemens EP3267377B1\\n8%\\n\\n\\nåˆæˆæ•°æ®\\nGPT-4ç”Ÿæˆ+çŸ¥è¯†å›¾è°±æ ¡éªŒ\\n25%â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HahahaFace/PCF.","first_N":5,"first_N_keywords":["Chinese","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"URSA_Alignment_860K","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/URSA-MATH/URSA_Alignment_860K","creator_name":"URSA-MATH","creator_url":"https://huggingface.co/URSA-MATH","description":"\\n\\t\\n\\t\\t\\n\\t\\tURSA_Alignment_860K\\n\\t\\n\\nThis dataset is used for the vision-language alignment phase of training the URSA-7B model.\\nImage data can be downloaded from the following address:\\n\\nMAVIS: https://github.com/ZrrSkywalker/MAVIS, https://drive.google.com/drive/folders/1LGd2JCVHi1Y6IQ7l-5erZ4QRGC4L7Nol.\\nMultimath: https://huggingface.co/datasets/pengshuai-rin/multimath-300k.\\nGeo170k: https://huggingface.co/datasets/Luckyjhg/Geo170K.\\n\\nThe image data in the MMathCoT-1M dataset is still available.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/URSA-MATH/URSA_Alignment_860K.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"HanScript2HanViet2ModernViet_Literature","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GooglyEyeSuperman/HanScript2HanViet2ModernViet_Literature","creator_name":"Quoc Anh","creator_url":"https://huggingface.co/GooglyEyeSuperman","description":"\\n\\t\\n\\t\\t\\n\\t\\tUse this dataset\\n\\t\\n\\nYou can load this dataset directly in your Python code using the ğŸ¤— datasets library:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"GooglyEyeSuperman/HanScript2HanViet2ModernViet_Literature\\\", {config_name})\\n\\nconfig_name should be one of [train_official, train_comment, train_ai, test_official, dictionary, full_raw], to get the corresponding csv files.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSino-Viet to Modern Vietnamese Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset focuses onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GooglyEyeSuperman/HanScript2HanViet2ModernViet_Literature.","first_N":5,"first_N_keywords":["translation","fill-mask","text2text-generation","Vietnamese","Chinese"],"keywords_longer_than_N":true},
	{"name":"csc_eval_public","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Macropodus/csc_eval_public","creator_name":"Macadam","creator_url":"https://huggingface.co/Macropodus","description":"\\n\\t\\n\\t\\t\\n\\t\\tcsc_eval_public\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tä¸€ã€æµ‹è¯„æ•°æ®è¯´æ˜\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.1 æµ‹è¯„æ•°æ®æ¥æº\\n\\t\\n\\n1.gen_de3.json(5545): 'çš„åœ°å¾—'çº é”™, ç”±äººæ°‘æ—¥æŠ¥/å­¦ä¹ å¼ºå›½/chinese-poetryç­‰é«˜è´¨é‡æ•°æ®äººå·¥ç”Ÿæˆ;\\n2.lemon_v2.tet.json(1053): relmè®ºæ–‡æå‡ºçš„æ•°æ®, å¤šé¢†åŸŸæ‹¼å†™çº é”™æ•°æ®é›†(7ä¸ªé¢†åŸŸ), ; åŒ…æ‹¬game(GAM), encyclopedia (ENC), contract (COT), medical care(MEC), car (CAR), novel (NOV), and news (NEW)ç­‰é¢†åŸŸ;\\n3.acc_rmrb.tet.json(4636): æ¥è‡ªNER-199801(äººæ°‘æ—¥æŠ¥é«˜è´¨é‡è¯­æ–™);\\n4.acc_xxqg.tet.json(5000): æ¥è‡ªå­¦ä¹ å¼ºå›½ç½‘ç«™çš„é«˜è´¨é‡è¯­æ–™;\\n5.gen_passage.tet.json(10000): æºæ•°æ®ä¸ºqwenç”Ÿæˆçš„å¥½è¯å¥½å¥, ç”±å‡ ä¹æ‰€æœ‰çš„å¼€æºæ•°æ®æ±‡æ€»çš„æ··æ·†è¯å…¸ç”Ÿæˆ;â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Macropodus/csc_eval_public.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Fineweb-Edu-Chinese-V2.1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opencsg/Fineweb-Edu-Chinese-V2.1","creator_name":"opencsg","creator_url":"https://huggingface.co/opencsg","description":"\\n\\t\\n\\t\\t\\n\\t\\tChinese Fineweb Edu Dataset V2.1          [ä¸­æ–‡]    [English]\\n\\t\\n\\n\\n\\n\\n\\n\\n[OpenCSG Community]   [ğŸ‘¾github]  [wechat]  [Twitter] \\n\\n\\n\\nğŸ“–Technical Report\\nThe Chinese Fineweb Edu Dataset V2.1 is an enhanced version of the V2 dataset, designed specifically for natural language processing (NLP) tasks in the education sector. This version introduces two new data sources, map-cc and opencsg-cc, and retains data with scores ranging from 2 to 3. The dataset entries are organized into different foldersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/opencsg/Fineweb-Edu-Chinese-V2.1.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100M - 1B","parquet"],"keywords_longer_than_N":true},
	{"name":"Condor-SFT-20K","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/internlm/Condor-SFT-20K","creator_name":"InternLM","creator_url":"https://huggingface.co/internlm","description":"\\n\\t\\n\\t\\t\\n\\t\\tCondor\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tâœ¨ Introduction\\n\\t\\n\\n[ğŸ¤— HuggingFace Models]\\n[ğŸ¤— HuggingFace Datasets]\\n[ğŸ“ƒ Paper]\\n\\n\\n\\n\\n\\nThe quality of Supervised Fine-Tuning (SFT) data plays a critical role in enhancing the conversational capabilities of Large Language Models (LLMs).\\nHowever, as LLMs become more advanced, \\nthe availability of high-quality human-annotated SFT data has become a significant bottleneck, \\nnecessitating a greater reliance on synthetic training data. \\nIn this work, we introduceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/internlm/Condor-SFT-20K.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"jacob-common-voice-19-zh-TW-curated","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/jacob-common-voice-19-zh-TW-curated","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"JacobLinCool/jacob-common-voice-19-zh-TW-curated dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Chinese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"TaiwanVQA","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhuang/TaiwanVQA","creator_name":"Hen-Hsen Huang","creator_url":"https://huggingface.co/hhhuang","description":"\\n\\t\\n\\t\\t\\n\\t\\tTaiwanVQA: A Visual Question Answering Benchmark for Taiwan-Specific Content\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTaiwanVQA is a visual question answering (VQA) benchmark designed to evaluate the capability of vision-language models (VLMs) in recognizing and reasoning about culturally specific content related to Taiwan. This dataset contains 1,000 images paired with 2,000 questions that cover diverse topics from daily life in Taiwan, such as traditional cuisine, public signageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hhhuang/TaiwanVQA.","first_N":5,"first_N_keywords":["visual-question-answering","English","Chinese","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"short_COT_48k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrankL/short_COT_48k","creator_name":"FrankLiu","creator_url":"https://huggingface.co/FrankL","description":"FrankL/short_COT_48k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"csc_public_de3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Macropodus/csc_public_de3","creator_name":"Macadam","creator_url":"https://huggingface.co/Macropodus","description":"\\n\\t\\n\\t\\t\\n\\t\\tcsc_public_de3æ•°æ®é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tæ•°æ®æ¥æº\\n\\t\\n\\n\\n1.ç”±äººæ°‘æ—¥æŠ¥/å­¦ä¹ å¼ºå›½/chinese-poetryç­‰é«˜è´¨é‡æ•°æ®äººå·¥ç”Ÿæˆ;\\n2.æ¥è‡ªäººæ°‘æ—¥æŠ¥é«˜è´¨é‡è¯­æ–™;\\n3.æ¥è‡ªå­¦ä¹ å¼ºå›½ç½‘ç«™çš„é«˜è´¨é‡è¯­æ–™;\\n4.æºæ•°æ®ä¸ºqwenç”Ÿæˆçš„å¥½è¯å¥½å¥;\\n5.å¤è¯—è¯chinese-poetry; æ–‡è¨€æ–‡garychowcmu/daizhigev20;\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tæ•°æ®ç®€ä»‹\\n\\t\\n\\n\\nè¯¥æ•°æ®ä¸»è¦ä¸º'çš„åœ°å¾—'çº é”™;\\nå…¶ä¸­è®­ç»ƒæ•°æ®130753æ¡, éªŒè¯æ•°æ®5545æ¡, æµ‹è¯•æ•°æ®5545æ¡;\\nå¥å­å¹³å‡é•¿åº¦ä¸º36, æœ€é•¿å¥å­é•¿åº¦ä¸º414, æœ€çŸ­ä¸º5, 95%çš„ä¸º89, 75%çš„ä¸º46, 60%çš„ä¸º34;\\næ¯ä¸ªå¥å­ä¸­å­—çš„å¹³å‡é”™è¯¯æ•°ä¸º2;\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tæ•°æ®è¯¦æƒ…\\n\\t\\n\\n################################################################################################################################\\ntrain.json\\n130753â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Macropodus/csc_public_de3.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","Chinese","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"degeneration-html-multilingual","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe Degeneration of the Nation Multilingual Dataset\\n\\t\\n\\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual.","first_N":5,"first_N_keywords":["translation","text2text-generation","text-generation","text-classification","token-classification"],"keywords_longer_than_N":true},
	{"name":"GreatFirewall-DPO","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nbeerbower/GreatFirewall-DPO","creator_name":"Nicholas Beerbower","creator_url":"https://huggingface.co/nbeerbower","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tGreatFirewall-DPO\\n\\t\\n\\nAn experimental dataset to discourage censorship and improve english prose in Chinese models.\\n\\n\\t\\n\\t\\t\\n\\t\\tStructure\\n\\t\\n\\n\\nprompt: input text presented to model (en translated to zh)\\nchosen: preferred response demonstrating less self-censorship (en translated to zh)  \\nrejected: response generated by Qwen/Qwen2.5-32B-Instruct, many (NOT ALL) exhibiting excessive self-censorship (generated in both en and zh)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tContent\\n\\t\\n\\n\\nCHINA-related (144 prompts) - mostly aboutâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nbeerbower/GreatFirewall-DPO.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"poem-pretrain-chinese-zhtw","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/poem-pretrain-chinese-zhtw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"poem-pretrain-chinese-zhtw\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™é›†æ‘˜è¦\\n\\t\\n\\nä¸­æ–‡å¤å…¸æ–‡é›†è³‡æ–™åº«æ”¶é›†äº†ç´„ 5.5 è¬é¦–å”è©©ã€26 è¬é¦–å®‹è©©ã€2.1 è¬é¦–å®‹è©å’Œå…¶ä»–å¤å…¸æ–‡é›†ã€‚è©©äººåŒ…æ‹¬å”å®‹å…©æœè¿‘ 1.4 è¬å¤è©©äººï¼Œå’Œå…©å®‹æ™‚æœŸ 1.5 åƒå¤è©äººã€‚\\n\\näº”ä»£ååœ‹- æ”¶éŒ„\\\"èŠ±é–“é›†\\\"èˆ‡\\\"å—å”äºŒä¸»è©\\\"\\nå”- æ”¶éŒ„\\\"å…¨å”è©©\\\"(æ˜¯æ¸…åº·ç†™å››åå››å¹´ï¼Œåº·ç†™çš‡å¸ä¸»å°ä¸‹ï¼Œè’é›†ç¾…å”è©©çš„æ”¶è—ã€Œå¾—è©© 48,900 é¤˜é¦–ï¼Œè©©å…¥ 2,200 äººã€)ã€‚\\nå®‹- æ”¶éŒ„\\\"å…¨å®‹è©\\\"(ç”±å”åœ­ç’‹ç·¨è‘—ï¼Œå­”å‡¡ç¦®è£œè¼¯ï¼Œå…±æ”¶éŒ„å®‹ä»£è©äºº 1,330 å®¶ï¼Œè©ä½œ 21,116 é¦–)ã€‚\\nå…ƒ- æ”¶éŒ„å…ƒæ›² 11,057 ç¯‡ï¼Œæ›²å®¶ 233 äººã€‚\\næ¸…- æ”¶éŒ„\\\"ç´è˜­æ€§å¾·è©©é›†\\\"\\n\\nåŸå§‹è³‡æ–™ä¾†æº:\\n\\nchinese-poetry: æœ€å…¨ä¸­æ–‡è¯—æ­Œå¤å…¸æ–‡é›†æ•°æ®åº“\\nerhwenkuo/poetry-chinese-zhtw\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè³‡æ–™é›†çµæ§‹\\n\\t\\n\\n{\\n  \\\"text\\\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/poem-pretrain-chinese-zhtw.","first_N":5,"first_N_keywords":["Chinese","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"wikipedia-pretrain-zh-tw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/wikipedia-pretrain-zh-tw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tå°ç£æ­£é«”ä¸­æ–‡ç¶­åŸºç™¾ç§‘ (zh-tw Wikipedia)\\n\\t\\n\\næ–°ç‰ˆæˆªè‡³ 2025 å¹´ 3 æœˆï¼Œä¸­æ–‡ç¶­åŸºç™¾ç§‘ 1,468,827 ç¯‡æ¢ç›®çš„å°ç£æ­£é«”æ–‡å­—å…§å®¹ã€‚æ¯ç¯‡å…§æ–‡ç‚ºtextå…§å®¹ï¼Œä¸”å…§å®¹çš†åˆªé™¤å¼•å…¥ã€åƒè€ƒç­‰ä¸æ¶‰åŠçŸ¥è­˜æ–¹é¢ä¹‹ä¸å¿…è¦å…§å®¹ã€‚\\nNew Version As of March 2025, the Traditional Chinese content of the 1,468,827 articles on Chinese Wikipedia. Each article contains only text content, with introductory sections, references, and other non-knowledge-related elements removed.\\næ–¼ 2025 å¹´ 3 æœˆ 13 æ—¥å–è‡ªç¶­åŸºç™¾ç§‘dumpï¼Œå…§å®¹çš†èˆ‡ç¶­åŸºç™¾ç§‘ç¶²ç«™ä¹‹å°ç£æ­£é«”ç‰ˆæœ¬ä¸€è‡´ï¼Œç¶“OpenCCè½‰æ›å¾Œæ²’æœ‰ç¹ç°¡é«”æ··é›œçš„å•é¡Œã€‚\\nRetrieved from the Wikipedia dump on March 13, 2025, theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/wikipedia-pretrain-zh-tw.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"passages-pretrain-chinese-zhtw","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/passages-pretrain-chinese-zhtw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"yuhuanstudio/passages-pretrain-chinese-zhtw\\\"\\n\\t\\n\\nåŒ…å«8åƒè¬é¤˜è¬ï¼ˆ88328203ï¼‰å€‹ä¸­æ–‡æ®µè½ï¼Œä¸åŒ…å«ä»»ä½•å­—æ¯ã€æ•¸å­—ã€‚æ–‡å­—é•·åº¦å¤§éƒ¨åˆ†ä»‹æ–¼ 50~200 å€‹å­—ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™é›†ä¾†æº\\n\\t\\n\\næœ¬è³‡æ–™é›†æ˜¯åŸºæ–¼CLUEä¸­æ–‡é è¨“ç·´èªæ–™é›†é€²è¡Œè™•ç†ã€éæ¿¾å¹¶é€²è¡Œç°¡ç¹è½‰è«²è€Œå¾—åˆ°çš„ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™é›†çµæ§‹\\n\\t\\n\\n{\\n  \\\"text\\\": \\\"é›™åä¸€é»ç‡ƒå¿«éæ¿å¡Šå–œæ†‚åƒåŠä¸‰å­£å ±é€éœ²ä½•ç¨®è¨Šè™Ÿç¶“éåˆæ­¥è­‰å¯¦ï¼Œé€™åå–è¾²è—¥æ­»äº¡çš„ç”·å­æ­£æ˜¯æ®ºå®³å¤«å¦»å€†çš„çŠ¯ç½ªå«Œç–‘äººã€‚\\\"\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™æ¬„ä½\\n\\t\\n\\n\\ntext: (string) æ–‡æœ¬å…§å®¹\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tå¦‚ä½•ä½¿ç”¨\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"yuhuanstudio/passages-pretrain-chinese-zhtw\\\", split=\\\"train\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tè¨±å¯è³‡è¨Š\\n\\t\\n\\n[MIT]\\n","first_N":5,"first_N_keywords":["Chinese","mit","10M - 100M","json","Text"],"keywords_longer_than_N":true},
	{"name":"wmt-da-human-evaluation-long-context","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLong-context / document-level dataset for Quality Estimation of Machine Translation.\\nIt is an augmented variant of the sentence-level WMT DA Human Evaluation dataset.\\nIn addition to individual sentences, it contains augmentations of 2, 4, 8, 16, and 32 sentences, among each language pair lp and domain.\\nThe raw column represents a weighted average of scores of augmented sentences using character lengths of src and mt as weights.\\nThe code used to apply the augmentationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context.","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Estonian"],"keywords_longer_than_N":true},
	{"name":"TinyHelen-zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fzmnm/TinyHelen-zh","creator_name":"fangzhangmnm","creator_url":"https://huggingface.co/fzmnm","description":"\\n\\t\\n\\t\\t\\n\\t\\tTinyHelen-zh\\n\\t\\n\\nInspired by the paper TinyHelen's First Curriculum, we present a Chinese version of the LLM-simplified training corpus. This dataset is converted from high-quality Chinese and English web crawls for training baby-size (<100M) language models.\\nAdult-talking\\nåŒ—äº¬å¸‚è´¢æ”¿å±€ã€åŒ—äº¬æµ·å…³ã€å›½å®¶ç¨åŠ¡æ€»å±€åŒ—äº¬å¸‚ç¨åŠ¡å±€ã€åŒ—äº¬å¸‚å›½é™…æœåŠ¡è´¸æ˜“äº‹åŠ¡ä¸­å¿ƒï¼š\\nä¸ºæ”¯æŒ2020å¹´ä¸­å›½å›½é™…æœåŠ¡è´¸æ˜“äº¤æ˜“ä¼šï¼ˆä»¥ä¸‹ç®€ç§°æœè´¸ä¼šï¼‰é¡ºåˆ©ä¸¾åŠï¼Œç»å›½åŠ¡é™¢æ‰¹å‡†ï¼Œç°å°†æœ‰å…³é—®é¢˜é€šçŸ¥å¦‚ä¸‹ï¼š\\nä¸€ã€å¯¹åœ¨2020å¹´æœè´¸ä¼šå±•æœŸå†…é”€å”®çš„é™é¢å†…çš„è¿›å£å±•å“ï¼ˆä¸åŒ…æ‹¬å›½å®¶ç¦æ­¢è¿›å£å•†å“ã€æ¿’å±åŠ¨æ¤ç‰©åŠå…¶äº§å“ã€çƒŸã€é…’å’Œæ±½è½¦ï¼‰å…å¾è¿›å£å…³ç¨ã€è¿›å£ç¯èŠ‚å¢å€¼ç¨å’Œæ¶ˆè´¹ç¨ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fzmnm/TinyHelen-zh.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Honkai_StarRail_Trailblaze_Mission_zhtw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/Honkai_StarRail_Trailblaze_Mission_zhtw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"yuhuanstudio/Honkai_StarRail_Trailblaze_Mission_zhtw\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™é›†æ‘˜è¦\\n\\t\\n\\næ‘˜è¦ï¼šä¸€å€‹æ¡é›†å´©å£ï¼šæ˜Ÿç©¹éµé“é–‹æ‹“ä»»å‹™å’Œé–‹æ‹“çºŒèå°è©±å…§å®¹çš„è³‡æ–™é›†ï¼Œä¸¦è™•ç†æˆé©ç•¶çš„è³‡æ–™æ ¼å¼ç”¨æ–¼é è¨“ç·´å¤§æ¨¡å‹\\nä¾†æºï¼šBilibili Wiki - å´©å£ï¼šæ˜Ÿç©¹éµé“\\næ•¸æ“šé¡å‹ï¼šåŠ‡æƒ…å°è©±æ–‡æœ¬\\næ ¼å¼ï¼šJSON\\nèªè¨€ï¼šç¹é«”ä¸­æ–‡ / ç°¡é«”ä¸­æ–‡ (zhtw/zh)\\nè³‡æ–™ç¯„åœï¼šåŒ…å«æ‰€æœ‰ã€Œé–‹æ‹“ä»»å‹™ã€ã€Œé–‹æ‹“çºŒèã€çš„åŠ‡æƒ…å…§å®¹ï¼ŒåŒ…æ‹¬è§’è‰²å°è©±ã€é¸é …(ç¬¬ä¸€é¸é …)ã€å ´æ™¯æè¿°ç­‰ã€‚ (v3.0)\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™é›†çµæ§‹\\n\\t\\n\\nmissionsç‚ºé–‹æ‹“ä»»å‹™ï¼Œadditionç‚ºé–‹æ‹“çºŒèï¼ŒæœªåŠ _twç‚ºç°¡é«”åŸå§‹æ•¸æ“š\\n{\\n<!-- é è¨“ç·´è³‡æ–™é›†è³‡æ–™ -->\\n  \\\"text\\\": \\\"ã€Šã€Œå‡è¡¡ã€çš„è©¦ç…‰â€¢é™¸ã€‹\\\\nã€Œä»²è£å®˜ã€çš„è©¦ç…‰å†åº¦åˆ°ä¾†ã€‚å®ƒçš„å…§å®¹ã€å½¢å¼ã€å¥½è™•å’Œæå®³ä½ å·²ç¶“å¾ˆæ¸…æ¥šäº†ï¼Œä¸æ˜¯å—ï¼Ÿå»å§ï¼Œç‚ºäº†ã€Œå‡è¡¡ã€â€¦â€¦\\\\nä»™èˆŸã€Œç¾…æµ®ã€-æµé›²æ¸¡\\\"\\n}\\n\\n{\\n<!-- æ“·å–è³‡æ–™ -->\\n  \\\"title\\\": \\\"æ··äº‚è¡Œè‡³æ·±è™•\\\",\\n  \\\"story\\\": [â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/Honkai_StarRail_Trailblaze_Mission_zhtw.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"OpenNewsArchive_pretrain_zhtw","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/OpenNewsArchive_pretrain_zhtw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"yuhuanstudio/OpenNewsArchive_pretrain_zhtw\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™é›†æ‘˜è¦\\n\\t\\n\\næœ¬è³‡æ–™é›†åŸºæ–¼ OpenNewsArchive åŸå§‹æ•¸æ“šï¼Œç¶“éä»¥ä¸‹è™•ç†æ­¥é©Ÿï¼š\\nç°¡ç¹è½‰æ›ï¼šä½¿ç”¨ OpenCC å·¥å…·å°‡ç°¡é«”ä¸­æ–‡è½‰æ›ç‚ºç¹é«”ä¸­æ–‡ä¸¦è½‰æ›å¸¸ç”¨è©å½™ï¼Œç¢ºä¿ç¹é«”ç”¨èªçš„ä¸€è‡´æ€§ã€‚\\næ ¼å¼åŒ–ï¼šæ•´ç†æ•¸æ“šçµæ§‹ï¼Œä½¿å…¶é©åˆå¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é è¨“ç·´ï¼Œç¢ºä¿é«˜æ•ˆçš„æ–‡æœ¬è¼¸å…¥èˆ‡è™•ç†ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\tåŸå§‹è³‡æ–™ä¾†æº:\\n\\t\\n\\nå…§å®¹èªªæ˜\\næ•¸æ“šä¾†æºï¼šOpenDataLab - OpenNewsArchive\\nèªè¨€ï¼šç¹é«”ä¸­æ–‡ï¼ˆåŸºæ–¼ OpenCC è™•ç†ï¼‰\\nè³‡æ–™æ ¼å¼ï¼šé©ç”¨æ–¼ LLM é è¨“ç·´çš„æ ¼å¼ï¼ŒåŒ…å«æ¨™æº–åŒ–æ–‡æœ¬çµæ§‹ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\tä½¿ç”¨èªªæ˜\\n\\t\\n\\næ­¤è³‡æ–™é›†é©ç”¨æ–¼ï¼š\\nå¤§å‹èªè¨€æ¨¡å‹çš„é è¨“ç·´\\nè‡ªç„¶èªè¨€è™•ç†ï¼ˆNLPï¼‰ç ”ç©¶\\nç¹é«”ä¸­æ–‡èªè¨€è™•ç†èˆ‡åˆ†æ\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™é›†çµæ§‹\\n\\t\\n\\n{\\n  \\\"text\\\": \\\"å ±å°æ–¼: 2023-10-25ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/OpenNewsArchive_pretrain_zhtw.","first_N":5,"first_N_keywords":["Chinese","mit","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"c4_pretrain_zhtw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/c4_pretrain_zhtw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"yuhuanstudio/c4_pretrain_zhtw\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™é›†æ‘˜è¦\\n\\t\\n\\næœ¬è³‡æ–™é›†åŸºæ–¼ C4ï¼ˆColossal Clean Crawled Corpusï¼‰åŸå§‹æ•¸æ“šï¼Œä¸¦ç¶“éä»¥ä¸‹è™•ç†æ­¥é©Ÿï¼Œè½‰æ›ç‚ºé©ç”¨æ–¼å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰é è¨“ç·´çš„æ ¼å¼ï¼š\\nè³‡æ–™æ¸…ç†ï¼šå»é™¤éä¸­æ–‡å…§å®¹ã€é‡è¤‡æ–‡æœ¬åŠä¸å¿…è¦çš„ HTML æ¨™ç±¤ï¼Œä¸¦ä½¿ç”¨panguæ ¼å¼åŒ–ä¸­æ–‡èªå¥é–“éš”ï¼Œæå‡èªè¨€æ¨¡å‹çš„è¨“ç·´å“è³ªã€‚\\næ ¼å¼åŒ–ï¼šå°‡æ•¸æ“šé‡æ–°æ•´ç†ç‚ºé©åˆ LLM é è¨“ç·´çš„çµæ§‹ï¼Œä¾¿æ–¼é«˜æ•ˆè¼‰å…¥èˆ‡è™•ç†ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\tå…§å®¹èªªæ˜\\n\\t\\n\\næ•¸æ“šä¾†æºï¼šColossal Clean Crawled Corpus (C4)\\nèªè¨€ï¼šç¹é«”ä¸­æ–‡\\nè³‡æ–™æ ¼å¼ï¼šJSON æ ¼å¼ï¼Œé©ç”¨æ–¼ LLM é è¨“ç·´\\nè³‡æ–™æ•¸é‡ï¼šåŒ…å«å¤§é‡ç¶“éæ¸…ç†å’Œæ ¼å¼åŒ–çš„ç¹é«”ä¸­æ–‡æ–‡æœ¬\\n\\n\\t\\n\\t\\t\\n\\t\\tä½¿ç”¨èªªæ˜\\n\\t\\n\\næ­¤è³‡æ–™é›†é©ç”¨æ–¼ï¼š\\nå¤§å‹èªè¨€æ¨¡å‹çš„é è¨“ç·´\\nè‡ªç„¶èªè¨€è™•ç†ï¼ˆNLPï¼‰ç ”ç©¶\\nç¹é«”ä¸­æ–‡èªè¨€ç†è§£èˆ‡åˆ†æ\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™é›†çµæ§‹\\n\\t\\n\\n{\\n  \\\"text\\\": \\\"å°åŒ—æ•…äº‹é¤¨ é›²é–€ç‰¹å±• As Lomo aslomo å¤©ç©ºéƒ¨è½ TIANâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/c4_pretrain_zhtw.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"wikipedia-2024modify-pretrain-zh-tw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/wikipedia-2024modify-pretrain-zh-tw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tå°ç£æ­£é«”ä¸­æ–‡ç¶­åŸºç™¾ç§‘ (zh-tw Wikipedia) 2024å¹´æ›´æ–°è³‡æ–™é›†\\n\\t\\n\\næœ¬è³‡æ–™é›†æ”¶é›†è‡ªç¶­åŸºç™¾ç§‘ï¼ˆWikipediaï¼‰2024 å¹´æ–°å¢èˆ‡æ›´æ–°å…§å®¹ï¼Œä¸»è¦é‡å°ç¹é«”ä¸­æ–‡èªæ–™é€²è¡Œæ“·å–ã€è™•ç†èˆ‡æ ¼å¼åŒ–ï¼Œä»¥é©ç”¨æ–¼å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰é è¨“ç·´å’Œè‡ªç„¶èªè¨€è™•ç†ï¼ˆNLPï¼‰æ‡‰ç”¨ã€‚\\næ•¸æ“šä¾†æºï¼šç¶­åŸºç™¾ç§‘ï¼ˆWikipediaï¼‰ç¹é«”ä¸­æ–‡ç‰ˆæœ¬\\næ™‚é–“ç¯„åœï¼š2024 å¹´è‡³ 2025å¹´1æœˆ24æ—¥ çš„æ–°å¢èˆ‡æ›´æ–°æ¢ç›®\\nèªè¨€ï¼šç¹é«”ä¸­æ–‡\\nè³‡æ–™æ ¼å¼ï¼šJSON æ ¼å¼ï¼Œé©åˆ LLM é è¨“ç·´èˆ‡ NLP åˆ†æ\\nè³‡æ–™è¦æ¨¡ï¼šåŒ…å«è±å¯Œçš„ç¾ä»£è©±é¡Œã€æœ€æ–°äº‹ä»¶ã€ç§‘å­¸é€²å±•ç­‰\\n\\n\\t\\n\\t\\t\\n\\t\\tä½¿ç”¨èªªæ˜\\n\\t\\n\\næ­¤è³‡æ–™é›†é©ç”¨æ–¼ï¼š\\nå¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰é è¨“ç·´\\nè‡ªç„¶èªè¨€è™•ç†ï¼ˆNLPï¼‰ç ”ç©¶\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™é›†çµæ§‹\\n\\t\\n\\n{\\n  \\\"text\\\": \\\"æ•¸å­¸æ˜¯ç ”ç©¶æ•¸é‡ã€çµæ§‹ä»¥åŠç©ºé–“ç­‰æ¦‚å¿µåŠå…¶è®ŠåŒ–çš„ä¸€é–€å­¸ç§‘ï¼Œå±¬æ–¼å½¢å¼ç§‘å­¸çš„ä¸€ç¨®ã€‚æ•¸å­¸åˆ©ç”¨æŠ½è±¡åŒ–å’Œé‚è¼¯æ¨ç†ï¼Œå¾è¨ˆæ•¸ã€è¨ˆç®—ã€é‡åº¦ã€å°ç‰©é«”å½¢ç‹€åŠé‹å‹•çš„è§€å¯Ÿç™¼å±•è€Œæˆã€‚æ•¸å­¸å®¶...\\\"\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™æ¬„ä½\\n\\t\\n\\n\\ntext: (string) ç¶­åŸºç™¾ç§‘æ–‡æœ¬å…§å®¹\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tå¦‚ä½•ä½¿ç”¨â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/wikipedia-2024modify-pretrain-zh-tw.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"PTT-pretrain-zhtw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/PTT-pretrain-zhtw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"yuhuanstudio/PTT-pretrain-zhtw\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™é›†æ‘˜è¦\\n\\t\\n\\næœ¬è³‡æ–™é›†æ“·å–è‡ªå°ç£æœ€å¤§çš„ BBS è¨è«–å€â€”â€”æ‰¹è¸¢è¸¢å¯¦æ¥­åŠï¼ˆPTTï¼‰ï¼ŒåŒ¯é›†å¤šå€‹çœ‹æ¿çš„æ­·å²èˆ‡è¿‘æœŸè¨è«–ï¼Œæä¾›è±å¯Œçš„ç¹é«”ä¸­æ–‡èªæ–™ï¼Œé©ç”¨æ–¼å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰é è¨“ç·´èˆ‡è‡ªç„¶èªè¨€è™•ç†ï¼ˆNLPï¼‰ç ”ç©¶ã€‚\\næ•¸æ“šä¾†æºï¼šPTT æ‰¹è¸¢è¸¢å¯¦æ¥­åŠï¼ˆhttps://www.ptt.ccï¼‰\\næ¶µè“‹çœ‹æ¿ï¼šåŒ…å« Gossipingã€Tech_Jobã€Stockã€NBA ç­‰æ‰€æœ‰è¨è«–å€\\næ™‚é–“ç¯„åœï¼šæ“·å–è‡ª PTT å…¬é–‹å­˜æª”å‰200é ï¼Œæ¶µè“‹å¤šå¹´æ­·å²æ•¸æ“š (å› å„ç‰ˆé æ•¸å•é¡Œï¼Œç†±é–€ç‰ˆé¢è³‡æ–™å¯èƒ½æ™‚é–“éƒ½è¼ƒç‚ºå¤è€)\\nèªè¨€ï¼šç¹é«”ä¸­æ–‡\\nè³‡æ–™æ ¼å¼ï¼šJSONï¼Œé©åˆ LLM è¨“ç·´èˆ‡ NLP æ‡‰ç”¨\\nè³‡æ–™è¦æ¨¡ï¼šåŒ…å«æ•¸åè¬æ¢è²¼æ–‡èˆ‡å›æ‡‰\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™é›†çµæ§‹\\n\\t\\n\\n{\\n  \\\"text\\\": \\\"ä½œè€…: Sonaten (=.=)\\\\nçœ‹æ¿: PC_Shopping\\\\næ¨™é¡Œ: [é–’èŠ] Gigabyte EP35-DS3 çš„DES...\\\\næ™‚é–“: Fri Jun 27 15:20:54 2008\\\\nå…§æ–‡:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/PTT-pretrain-zhtw.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"twdict_pretrain","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/twdict_pretrain","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"yuhuanstudio/twdict_pretrain\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™é›†æ‘˜è¦\\n\\t\\n\\næœ¬è³‡æ–™é›†å°‡ã€Œæˆèªå…¸ã€èˆ‡ã€Œé‡ç·¨å­—å…¸ã€çš„å…§å®¹åˆä½µç‚ºå–®ä¸€è³‡æ–™é›†ï¼Œæä¾›ç¹é«”ä¸­æ–‡çš„è©å½™ã€æˆèªèˆ‡å…¶è§£é‡‹ã€ç”¨ä¾‹ç­‰è³‡è¨Šã€‚æ­¤è³‡æ–™é›†é©ç”¨æ–¼å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰é è¨“ç·´ä»¥åŠè‡ªç„¶èªè¨€è™•ç†ï¼ˆNLPï¼‰å„é¡æ‡‰ç”¨ï¼Œå¦‚é—œéµå­—æŠ½å–ã€å•ç­”ç³»çµ±ã€èªç¾©åˆ†æç­‰ã€‚\\nåŸå§‹è³‡æ–™ä¾†æº:\\n\\nã€Šé‡ç·¨åœ‹èªè¾­å…¸ä¿®è¨‚æœ¬ã€‹\\nã€Šæˆèªå…¸ã€‹\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tå…§å®¹èªªæ˜\\n\\t\\n\\nâ€¢ æ•¸æ“šä¾†æºï¼š\\nâ€“ ã€Œæˆèªå…¸ã€ï¼šæ”¶éŒ„å¸¸è¦‹èˆ‡ç½•è¦‹æˆèªï¼Œå«é‡‹ç¾©ã€å…¸æ•…ã€ä¾‹å¥ç­‰ç›¸é—œè³‡è¨Š\\nâ€“ ã€Œé‡ç·¨å­—å…¸ã€ï¼šæ”¶éŒ„ç¹é«”ä¸­æ–‡è©å½™èˆ‡è§£é‡‹ï¼Œå«è©æ€§ã€è©ç¾©ã€å¼•æ–‡ç­‰\\nâ€¢ èªè¨€ï¼šç¹é«”ä¸­æ–‡\\nâ€¢ è³‡æ–™æ ¼å¼ï¼š\\nâ€“ JSON æ ¼å¼ï¼Œçµæ§‹åŒ–æ¯å€‹è©æ¢æˆ–æˆèªçš„å…§å®¹\\nâ€“ ä¾¿æ–¼ LLM é è¨“ç·´å’Œ NLP åˆ†æ\\nâ€¢ è³‡æ–™è¦æ¨¡ï¼š\\nâ€“ å«æ•¸è¬æ¢ç¹é«”ä¸­æ–‡è©å½™èˆ‡æˆèª\\nâ€“ è±å¯Œçš„ç”¨æ³•ç¤ºä¾‹ã€è§£é‡‹åŠæ­·å²å…¸æ•…\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™é›†çµæ§‹\\n\\t\\n\\n{\\n  \\\"text\\\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/twdict_pretrain.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"GSM8K_zh_tw","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DoggiAI/GSM8K_zh_tw","creator_name":"Doggi AI","creator_url":"https://huggingface.co/DoggiAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset\\n\\t\\n\\nGSM8K_zh_tw is a dataset for mathematical reasoning in Traditional Chinese. It is derived from the GSM8K_zh dataset by translating question-answer pairs into Traditional Chinese using OpenCC. The dataset consists of 7473 training samples and 1319 testing samples.\\nIn addition to translation, the dataset includes modifications to improve regional adaptation, such as replacing some China-specific terms with those more suitable for Traditional Chinese users. Simplified Chineseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DoggiAI/GSM8K_zh_tw.","first_N":5,"first_N_keywords":["question-answering","openai/gsm8k","Chinese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MM-IQ","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huanqia/MM-IQ","creator_name":"huanqiacai","creator_url":"https://huggingface.co/huanqia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"MM-IQ\\\"\\n\\t\\n\\n\\nIntroduction\\nPaper Information\\nDataset Examples\\nLeaderboard\\nDataset Usage\\nData Downloading\\nData Format\\nAutomatic Evaluation\\n\\n\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nIQ testing has served as a foundational methodology for evaluating human cognitive capabilities, deliberately decoupling assessment from linguistic background, language proficiency, or domain-specific knowledge to isolate core competencies in abstraction and reasoning. Yet, artificial intelligenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huanqia/MM-IQ.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"imatrix-calibration","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eaddario/imatrix-calibration","creator_name":"Ed Addario","creator_url":"https://huggingface.co/eaddario","description":"\\n\\t\\n\\t\\t\\n\\t\\tImportance Matrix (imatrix) calibration datasets\\n\\t\\n\\nThis dataset consists of over 10M tokens of cleaned and de-duplicated text files for 13 different languages. Each language file is available in five sizes, ranging from large (~ 26,000 lines equivalent to approx. 750K tokens), to micro (~ 1,625 lines and 125K tokens avg).\\nOriginal data sourced from HuggingFaceFW/fineweb and HuggingFaceFW/fineweb-2\\n\\n\\t\\n\\t\\t\\nFile\\nLanguage\\nLines\\nSize\\n\\n\\n\\t\\t\\ncalibration_ar_large\\nArabic\\n26,000\\n3.1Mâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/eaddario/imatrix-calibration.","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"default-domain-cot-dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pohsjxx/default-domain-cot-dataset","creator_name":"jerry zhang","creator_url":"https://huggingface.co/pohsjxx","description":"\\n\\t\\n\\t\\t\\n\\t\\tæ— äººæœºäº‘æ•°æ® Chain-of-Thought Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Categories\\n\\t\\n\\n\\næ— äººæœºç³»ç»Ÿä½¿ç”¨äºº/è¿è¥äººç™»è®°æ•°æ®\\næ— äººæœºé©¾é©¶å‘˜ç™»è®°æ•°æ®\\næ— äººæœºç³»ç»Ÿè®¾å¤‡ç™»è®°æ•°æ®\\nç©ºåŸŸç”³è¯·æ•°æ®\\né£è¡Œè®¡åˆ’ç”³è¯·æ•°æ®\\næ— äººæœºç³»ç»Ÿæ¥å…¥æ ¡éªŒ/å¼€æœºä¸ŠæŠ¥æ•°æ®\\næ”¾é£ç”³è¯·/åœ¨çº¿æˆæƒæ•°æ®\\næ•°æ®é“¾è·¯å¿ƒè·³ä¿æ´»æ•°æ®\\næ— äººæœºå›´æ æ•°æ®æ›´æ–°\\nç¦åŒº/é™é£åŒºå‘Šè­¦æ•°æ®\\né£è¡Œæƒ…æŠ¥ä¿¡æ¯é€šçŸ¥æ•°æ®\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSchema Information\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tflight_subject\\n\\t\\n\\n\\naircraft_registration_number (str, required): æ— äººæœºæ³¨å†Œç¼–å·\\naircraft_type (str, optional): æ— äººæœºç±»å‹\\ncontrol_system_mac_address (str, optional): æ§åˆ¶ç³»ç»ŸMACåœ°å€\\noperator_id (str, required): æ“ä½œäººID\\noperator_name (str, required): æ“ä½œäººå§“åâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pohsjxx/default-domain-cot-dataset.","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthdog Multilingual\\n\\t\\n\\n\\n\\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzfâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"System-Prompt-Instruction-Real-world-Implementation-Training-set","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/EricLu/System-Prompt-Instruction-Real-world-Implementation-Training-set","creator_name":"Eric Lu","creator_url":"https://huggingface.co/EricLu","description":"\\n\\t\\n\\t\\t\\n\\t\\tSPIRIT Dataset (System Prompt Instruction Real-world Implementation Training-set)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSPIRIT is a high-quality system prompt instruction dataset designed to enhance language models' ability to follow complex system prompts. The dataset comprises real-world system prompts collected from GitHub repositories and synthetically generated conversations, specifically curated to improve system prompt adherence in large language models.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Creationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EricLu/System-Prompt-Instruction-Real-world-Implementation-Training-set.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"HealthRCN","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hush-cd/HealthRCN","creator_name":"ding chen","creator_url":"https://huggingface.co/Hush-cd","description":"Hush-cd/HealthRCN dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"DynVQA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zhzhen23/DynVQA","creator_name":"ZhenZhang","creator_url":"https://huggingface.co/zhzhen23","description":"\\n\\t\\n\\t\\t\\n\\t\\tğŸ“š Dyn-VQA Dataset\\n\\t\\n\\nğŸ“‘ Dataset for Benchmarking Multimodal Retrieval Augmented Generation with Dynamic VQA Dataset and Self-adaptive Planning Agent\\nğŸŒŸ This dataset is linked to GitHub at this URL.\\nThe json item of Dyn-VQA dataset is organized in the following format:\\n{\\n    \\\"image_url\\\": \\\"https://www.pcarmarket.com/static/media/uploads/galleries/photos/uploads/galleries/22387-pasewark-1986-porsche-944/.thumbnails/IMG_7102.JPG.jpg/IMG_7102.JPG-tiny-2048x0-0.5x0.jpg\\\",\\n    \\\"question\\\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zhzhen23/DynVQA.","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"LIMO_chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Minami-su/LIMO_chinese","creator_name":"å—æ –","creator_url":"https://huggingface.co/Minami-su","description":"Dataset chinese version for LIMO: Less is More for Reasoning\\n\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"Minami-su/LIMO_chinese\\\", split=\\\"train\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{ye2025limoreasoning,\\n      title={LIMO: Less is More for Reasoning}, \\n      author={Yixin Ye and Zhen Huang and Yang Xiao and Ethan Chern and Shijie Xia and Pengfei Liu},\\n      year={2025},\\n      eprint={2502.03387},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Minami-su/LIMO_chinese.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Better-Ruozhiba","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FunnySaltyFish/Better-Ruozhiba","creator_name":"FunnySaltyFish","creator_url":"https://huggingface.co/FunnySaltyFish","description":"\\n\\t\\n\\t\\t\\n\\t\\tBetter Ruozhiba\\n\\t\\n\\nåŸé¡¹ç›®ä¸º https://huggingface.co/datasets/LooksJuicy/ruozhibaï¼ŒåŸéƒ¨åˆ†ç­”æ¡ˆä¸º GPT-4 ç”Ÿæˆã€‚è´¡çŒ®è€…ä»¬äººä¸ºå®¡é˜…äº†æ¯ä¸€æ¡çš„åŸæ–‡å’Œå›å¤ï¼Œå‰”é™¤äº†ä¸€äº›åŸæ–‡ä¸­çš„æ ¼å¼é”™è¯¯ï¼Œä¿®æ”¹æˆ–é‡å†™äº†éƒ¨åˆ†ç­”æ¡ˆã€‚å¸Œæœ›å¯¹å¤§è¯­è¨€æ¨¡å‹çš„ä¸­æ–‡è¯­æ–™æœ‰æ‰€å¸®åŠ©ã€‚\\n\\nPS. æ­£å„¿å…«ç»å›ç­”å¼±æ™ºå§çš„é—®é¢˜ï¼ŒçœŸæ˜¯ä¸€ç§å¥‡å¦™çš„æ„Ÿè§‰\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tå‚ä¸è´¡çŒ®\\n\\t\\n\\nå¦‚æœæœ‰æ„å‚ä¸è´¡çŒ®ï¼Œè¯·æŸ¥çœ‹æ­¤ issue\\nè´¡çŒ®è€…åˆ—è¡¨ï¼š\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tå¼•ç”¨\\n\\t\\n\\nå¦‚æœæœ¬é¡¹ç›®å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œè¯·å¼•ç”¨ï¼š\\n@misc{better-ruozhiba,\\n    title={Better Ruozhiba},\\n    author={Ruozhiba and FunnySaltyFish and Misdirection and Xinsu,Liu},\\n    year={2024},\\n    publisher = {GitHub},\\n    journal = {GitHub repository},\\n    howpublished =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FunnySaltyFish/Better-Ruozhiba.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Better-Ruozhiba","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FunnySaltyFish/Better-Ruozhiba","creator_name":"FunnySaltyFish","creator_url":"https://huggingface.co/FunnySaltyFish","description":"\\n\\t\\n\\t\\t\\n\\t\\tBetter Ruozhiba\\n\\t\\n\\nåŸé¡¹ç›®ä¸º https://huggingface.co/datasets/LooksJuicy/ruozhibaï¼ŒåŸéƒ¨åˆ†ç­”æ¡ˆä¸º GPT-4 ç”Ÿæˆã€‚è´¡çŒ®è€…ä»¬äººä¸ºå®¡é˜…äº†æ¯ä¸€æ¡çš„åŸæ–‡å’Œå›å¤ï¼Œå‰”é™¤äº†ä¸€äº›åŸæ–‡ä¸­çš„æ ¼å¼é”™è¯¯ï¼Œä¿®æ”¹æˆ–é‡å†™äº†éƒ¨åˆ†ç­”æ¡ˆã€‚å¸Œæœ›å¯¹å¤§è¯­è¨€æ¨¡å‹çš„ä¸­æ–‡è¯­æ–™æœ‰æ‰€å¸®åŠ©ã€‚\\n\\nPS. æ­£å„¿å…«ç»å›ç­”å¼±æ™ºå§çš„é—®é¢˜ï¼ŒçœŸæ˜¯ä¸€ç§å¥‡å¦™çš„æ„Ÿè§‰\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tå‚ä¸è´¡çŒ®\\n\\t\\n\\nå¦‚æœæœ‰æ„å‚ä¸è´¡çŒ®ï¼Œè¯·æŸ¥çœ‹æ­¤ issue\\nè´¡çŒ®è€…åˆ—è¡¨ï¼š\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tå¼•ç”¨\\n\\t\\n\\nå¦‚æœæœ¬é¡¹ç›®å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œè¯·å¼•ç”¨ï¼š\\n@misc{better-ruozhiba,\\n    title={Better Ruozhiba},\\n    author={Ruozhiba and FunnySaltyFish and Misdirection and Xinsu,Liu},\\n    year={2024},\\n    publisher = {GitHub},\\n    journal = {GitHub repository},\\n    howpublished =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FunnySaltyFish/Better-Ruozhiba.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Math","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Math","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Math is a dataset of BenchMAX, sourcing from MGSM.\\nWe extend the original dataset to 6 more languages.\\nThe data is first translated by Google Translate, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chineseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Math.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Science","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Science","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Science is a dataset of BenchMAX, sourcing from GPQA.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by Google Translate, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Science.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Function_Completion","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from humanevalplus.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by GPT-4o, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Problem_Solving","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Problem_Solving is a dataset of BenchMAX, sourcing from LiveCodeBench.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by GPT-4o, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"gsm8k-r1-qwen-32b","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/gsm8k-r1-qwen-32b","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\tgsm8k\\n\\t\\n\\nI translated questions into Chinese, and let DeepSeek-R1-Distill-Qwen-32B generate answers. Then I validated all answers, filtering out incorrect ones, and finally I fixed latex formatting errors such as \\\\boxed{}\\n","first_N":5,"first_N_keywords":["Chinese","gpl-3.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Retrieval-SFT-Chat","keyword":"chinese","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/CausalLM/Retrieval-SFT-Chat","creator_name":"CausalLM","creator_url":"https://huggingface.co/CausalLM","description":"\\n\\t\\n\\t\\t\\n\\t\\tRetrieval-Based Multi-Turn Chat SFT Synthetic Data\\n\\t\\n\\nA year ago, we released CausalLM/Refined-Anime-Text, a thematic subset of a dataset generated using the then state-of-the-art LLMs. This dataset comprises 1 million entries synthesized through long-context models that rewrote multi-document web text inputs, intended for continued pre-training. We are pleased to note that this data has been employed in various training scenarios and in studies concerning data and internet culture.\\nInâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CausalLM/Retrieval-SFT-Chat.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Chinese","Japanese"],"keywords_longer_than_N":true},
	{"name":"ruozhiba-dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DylanDDeng/ruozhiba-dataset","creator_name":"Chengsheng Deng","creator_url":"https://huggingface.co/DylanDDeng","description":"\\n\\t\\n\\t\\t\\n\\t\\tDeepSeek-R1 Ruozhiba Dataset\\n\\t\\n\\nThis repository contains responses generated using Together AI's DeepSeek-R1 API for the Ruozhiba GPT4 dataset. The dataset consists of 4,898 question-answer pairs in Chinese.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nSource: Original questions from hfl/ruozhiba_gpt4\\nModel: DeepSeek-R1 via Together AI API\\nSystem Prompt: Adapted from bespokelabs/Bespoke-Stratos-17k\\nFormat: JSON\\nSize: 4,898 entries\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKnown Limitations\\n\\t\\n\\nDuring the response generation processâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DylanDDeng/ruozhiba-dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tSMOL\\n\\t\\n\\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\\ntranslations into 221 Low-Resource Languages, for the purpose of training\\ntranslation models, and otherwise increasing the representations of said\\nlanguages in NLP and technology.\\nPlease read the SMOL Paper and the\\nGATITOS Paper for a much more\\nthorough description!\\nThere are four resources in this directory:\\n\\nSmolDoc: document-level translations into 100 languages\\nSmolSent: sentence-level translations intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"Gaokao-LLM-data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Interstellar174/Gaokao-LLM-data","creator_name":"Busheng Zhang","creator_url":"https://huggingface.co/Interstellar174","description":"\\n\\t\\n\\t\\t\\n\\t\\tQZDH_Gaokao_Data: Gaokao Past Paper Reasoning Dataset\\n\\t\\n\\nChinese readme link is here: ç®€ä½“ä¸­æ–‡\\nQZDH_Gaokao_Data is a dataset independently collected by the Qizhi Navigation Project, aimed at promoting the rapid development of AI education, assisting in the development of AI applications, and the construction of AI teacher models. The original intention of the team in building this dataset is to provide data support for the fine-tuning of models used by the team, and it is hoped thatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Interstellar174/Gaokao-LLM-data.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K<n<10K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"gsm8k_zhtw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/gsm8k_zhtw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tGSM8K ç¹é«”ä¸­æ–‡è³‡æ–™é›†\\n\\t\\n\\nGSM8Kï¼ˆGrade School Math 8Kï¼‰æ˜¯ç”± OpenAI ç™¼å¸ƒçš„ä¸€å€‹åŒ…å« 8,500 å€‹é«˜å“è³ªå°å­¸æ•¸å­¸æ–‡å­—é¡Œçš„è³‡æ–™é›†ï¼Œæ—¨åœ¨è©•ä¼°æ¨¡å‹åœ¨å¤šæ­¥é©Ÿæ•¸å­¸æ¨ç†ä»»å‹™ä¸­çš„è¡¨ç¾ã€‚åŸå§‹è³‡æ–™é›†ä»¥è‹±æ–‡æ’°å¯«ï¼Œç‚ºäº†ä¿ƒé€²ç¹é«”ä¸­æ–‡ç¤¾ç¾¤å°è©²è³‡æ–™é›†çš„ä½¿ç”¨èˆ‡ç ”ç©¶ï¼Œæˆ‘å€‘å°‡å…¶å®Œæ•´ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\tç¿»è­¯æ–¹æ³•\\n\\t\\n\\næˆ‘å€‘æ¡ç”¨äº† Google translate é€²è¡Œè‡ªå‹•ç¿»è­¯ï¼Œç¢ºä¿å•é¡Œå’Œè§£ç­”çš„èªæ„èˆ‡åŸå§‹è³‡æ–™é›†ä¸€è‡´ã€‚åœ¨ç¿»è­¯éç¨‹ä¸­ï¼Œæˆ‘å€‘ç‰¹åˆ¥æ³¨æ„æ•¸å­¸ç¬¦è™Ÿã€å°ˆæœ‰åè©å’Œæ–‡åŒ–å·®ç•°ï¼Œç¢ºä¿ç¹é«”ä¸­æ–‡ä½¿ç”¨è€…èƒ½å¤ æ¸…æ™°ç†è§£æ¯å€‹å•é¡Œã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™é›†å…§å®¹\\n\\t\\n\\nç¿»è­¯å¾Œçš„è³‡æ–™é›†åŒ…å«ï¼š\\n\\nå•é¡Œï¼ˆquestionï¼‰ï¼šå°å­¸æ•¸å­¸å•é¡Œçš„ç¹é«”ä¸­æ–‡æè¿°ã€‚\\nç­”æ¡ˆï¼ˆanswerï¼‰ï¼šå°æ‡‰å•é¡Œçš„å®Œæ•´è§£ç­”ï¼ŒåŒ…æ‹¬å¤šæ­¥é©Ÿæ¨ç†å’Œæœ€çµ‚ç­”æ¡ˆã€‚\\n\\næ¯å€‹å•é¡Œçš„è§£ç­”æ ¼å¼ä¿æŒèˆ‡åŸå§‹è³‡æ–™é›†ä¸€è‡´ï¼Œæ–¹ä¾¿ä½¿ç”¨è€…é€²è¡Œæ¯”è¼ƒå’Œç ”ç©¶ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\tè³‡æ–™é›†çµæ§‹\\n\\t\\n\\nè³‡æ–™é›†åˆ†ç‚ºè¨“ç·´é›†å’Œæ¸¬è©¦é›†ï¼š\\n\\nè¨“ç·´é›†ï¼š7,473 å€‹å•é¡Œ\\næ¸¬è©¦é›†ï¼š1,319 å€‹å•é¡Œ\\n\\næ¯å€‹å•é¡Œéƒ½éœ€è¦ 2 åˆ° 8â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/gsm8k_zhtw.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MANBench","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MANBench/MANBench","creator_name":"MANBench","creator_url":"https://huggingface.co/MANBench","description":"\\n\\t\\n\\t\\t\\n\\t\\tMANBench\\n\\t\\n\\nThis repo contains evaluation code for the paper \\\"MANBench: Is Your Multimodal Model Smarter than Human?\\\"\\nğŸŒ Homepage | ğŸ¤— Dataset\\n\\n\\t\\n\\t\\t\\n\\t\\tğŸ””News\\n\\t\\n\\n\\nğŸ”¥[2025-02-09]: MANBench is now available on ğŸ¤— Hugging Face\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce MANBench (Multimodal Ability Norms Benchmark), a comprehensive benchmark designed to evaluate the multimodal capabilities of both humans and MLLMs. MANBench consists of 9\\ntasks, each containing more than 110 questions, with aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MANBench/MANBench.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","Chinese","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"dark_thoughts_stakeholders_en_cn","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DataTonic/dark_thoughts_stakeholders_en_cn","creator_name":"Data Tonic (Alignment Lab)","creator_url":"https://huggingface.co/DataTonic","description":"\\n\\t\\n\\t\\t\\n\\t\\tDark Thoughts Case Studies Dataset (English-Chinese)\\n\\t\\n\\nThis dataset contains a bilingual collection of case studies with detailed stakeholder analyses in English and Chinese. Each case study includes structured information about stakeholders and their motivations, along with comprehensive case analysis and solutions.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe dataset consists of 344,580 case studies in English and in Chinese, with detailed stakeholder analyses andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DataTonic/dark_thoughts_stakeholders_en_cn.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"twllm-data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yentinglin/twllm-data","creator_name":"Yen-Ting Lin","creator_url":"https://huggingface.co/yentinglin","description":"\\n\\t\\n\\t\\t\\n\\t\\tTWLLM-Data: Open Traditional Mandarin LLM Conversations\\n\\t\\n\\nTWLLM-Data is the first large-scale open dataset containing real user-generated conversation logs from TWLLM and TWLLM Arena, where over 80% of users are based in Taiwan. The dataset is designed to facilitate the development and evaluation of Traditional Mandarin Large Language Models (LLMs).\\nWe extend our gratitude to Professor Yun-Nung (Vivian) Chen for her guidance and advisement. \\nSpecial thanks to Tzu-Han Lin, Kang-Chiehâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yentinglin/twllm-data.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Chat","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","description":"\\n\\t\\n\\t\\t\\n\\t\\tDATA-AI: Il Modello di IA di M.INC.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tğŸ“Œ Introduzione\\n\\t\\n\\nDATA-AI Ã¨ un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello Ã¨ basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \\nDATA-AI Ã¨ stato addestrato su unâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat.","first_N":5,"first_N_keywords":["Italian","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"Audio-FLAN-Dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset","creator_name":"HKUST Audio","creator_url":"https://huggingface.co/HKUSTAudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tAudio-FLAN Dataset (Paper)\\n\\t\\n\\n(the FULL audio files and jsonl files are still updating)\\nAn Instruction-Tuning Dataset for Unified Audio Understanding and Generation Across Speech, Music, and Sound. \\n\\n\\t\\n\\t\\t\\n\\t\\t1. Dataset Structure\\n\\t\\n\\nThe Audio-FLAN-Dataset has the following directory structure:\\nAudio-FLAN-Dataset/\\nâ”œâ”€â”€ audio_files/\\nâ”‚   â”œâ”€â”€ audio/\\nâ”‚   â”‚   â””â”€â”€ 177_TAU_Urban_Acoustic_Scenes_2022/\\nâ”‚   â”‚   â””â”€â”€ 179_Audioset_for_Audio_Inpainting/\\nâ”‚   â”‚   â””â”€â”€ ...\\nâ”‚   â”œâ”€â”€ music/\\nâ”‚   â”‚   â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"ea-mt-benchmark","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark","creator_name":"Sapienza NLP, Sapienza University of Rome","creator_url":"https://huggingface.co/sapienzanlp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for EA-MT\\n\\t\\n\\nEA-MT (Entity-Aware Machine Translation) is a multilingual benchmark for evaluating the capabilities of Large Language Models (LLMs) and Machine Translation (MT) models in translating simple sentences with potentially challenging entity mentions, e.g., entities for which a word-for-word translation may not be accurate.\\nHere is an example of a simple sentence with a challenging entity mention:\\n\\nEnglish: \\\"What is the plot of The Catcher in the Rye?\\\"\\nItalian:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark.","first_N":5,"first_N_keywords":["text-generation","English","Arabic","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"HouseIntelligence_1.1_zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FemetoRhythm/HouseIntelligence_1.1_zh","creator_name":"cheng si yuan","creator_url":"https://huggingface.co/FemetoRhythm","description":"FemetoRhythm/HouseIntelligence_1.1_zh dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"u-sticker","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/metchee/u-sticker","creator_name":"Metilda Chee","creator_url":"https://huggingface.co/metchee","description":"\\n\\t\\n\\t\\t\\n\\t\\tU-Sticker\\n\\t\\n\\nUser-Sticker is a stickers dataset with multi-domain conversations.\\nFeatures of U-Sticker:\\n\\nMulti-domain interactions âœ…\\nTemporal âœ…\\nUser information âœ…\\n370.2k stickers âœ… (104k unique)\\n22.6k users âœ…\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nU-Sticker contains three files:\\n\\nConversation files: 1 to 67.json\\nDomain mapping files idx_to_domain.txt.\\nSticker files.\\n\\n\\nSticker files are available here and Baidu Cloud.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tConversation file\\n\\t\\n\\n\\nEmpty lines areâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/metchee/u-sticker.","first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Turkish"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tHigh Quality Multilingual Sentences\\n\\t\\n\\n\\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\\n\\nExample row (from the all config):\\n{\\n    \\\"text\\\": \\\"Ø§Ù…Ø§Ù… Ø¬Ù…Ø¹Ù‡ Ø§ØµÙÙ‡Ø§Ù† Ú¯ÙØª: Ù…ÛŒØ²Ø§Ù† Ù†ÛŒØ§Ø² Ø¢Ø¨ Ø´Ø±Ø¨ Ø§ØµÙÙ‡Ø§Ù† Û±Û±.Ûµ Ù…ØªØ± Ù…Ú©Ø¹Ø¨ Ø§Ø³Øª Ú©Ù‡ ØªÙ…Ø§Ù… Ø§Ø³ØªØ§Ù† Ø§ØµÙÙ‡Ø§Ù† Ø±Ø§ Ù¾ÙˆØ´Ø´ Ù…ÛŒØ¯Ù‡Ø¯ Ùˆ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ù†Ù‚Ù„Ø§Ø¨ ÛŒÚ©ÛŒ Ø§Ø² Ù¾ÛŒØ´Ø±ÙØªÙ‡Ø§ Ø¯Ø± Ø­ÙˆØ²Ù‡ Ø¢Ø¨ Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª.\\\",\\n    \\\"fasttext\\\": \\\"fa\\\",\\n    \\\"gcld3\\\": \\\"fa\\\"\\n}\\n\\nFields:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"Open-R1-Mulitlingual-SFT","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT","creator_name":"GUIJIN SON","creator_url":"https://huggingface.co/amphora","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-R1-Mulitlingual-SFT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nOpen-R1-Mulitlingual-SFT is a curated dataset designed for multilingual supervised fine-tuning.\\nThe source data comprises multiple datasets containing original prompts and responses, which were subsequently translated into 14 languages using GPT-4o.\\n\\n\\t\\n\\t\\t\\n\\t\\tSources\\n\\t\\n\\nThe dataset is derived from:\\n\\nopen-thoughts/OpenThoughts-114kHugging Face: open-thoughts/OpenThoughts-114k\\nbespokelabs/Bespoke-Stratos-17kHugging Face:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT.","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"achinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tSMOL\\n\\t\\n\\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\\ntranslations into 221 Low-Resource Languages, for the purpose of training\\ntranslation models, and otherwise increasing the representations of said\\nlanguages in NLP and technology.\\nPlease read the SMOL Paper and the\\nGATITOS Paper for a much more\\nthorough description!\\nThere are four resources in this directory:\\n\\nSmolDoc: document-level translations into 100 languages\\nSmolSent: sentence-level translations intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"yue chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tSMOL\\n\\t\\n\\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\\ntranslations into 221 Low-Resource Languages, for the purpose of training\\ntranslation models, and otherwise increasing the representations of said\\nlanguages in NLP and technology.\\nPlease read the SMOL Paper and the\\nGATITOS Paper for a much more\\nthorough description!\\nThere are four resources in this directory:\\n\\nSmolDoc: document-level translations into 100 languages\\nSmolSent: sentence-level translations intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"cantonesewiki_doyouknow","keyword":"yue chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cantonesesra/cantonesewiki_doyouknow","creator_name":"Cantonese Standardization Research Association","creator_url":"https://huggingface.co/cantonesesra","description":"\\n\\t\\n\\t\\t\\n\\t\\tCantonese Question Dataset from Yue Wiki\\n\\t\\n\\nA collection of questions in Cantonese, extracted from Yue Wiki. This dataset contains a variety of questions covering different topics and domains.\\n\\n\\t\\n\\t\\t\\n\\t\\tDisclaimer\\n\\t\\n\\nThe content and opinions expressed in this dataset do not represent the views, beliefs, or positions of the dataset creators, contributors, or hosting organizations. This dataset is provided solely for the purpose of improving AI systems' understanding of the Cantoneseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cantonesesra/cantonesewiki_doyouknow.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","question-answering","Yue Chinese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ruozhiba_o3mini","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hfl/ruozhiba_o3mini","creator_name":"Joint Laboratory of HIT and iFLYTEK Research (HFL)","creator_url":"https://huggingface.co/hfl","description":"\\n\\t\\n\\t\\t\\n\\t\\truozhiba_o3mini\\n\\t\\n\\næœ¬ä»“åº“åŒ…å«ä½¿ç”¨o3-mini-2025-01-31APIæ„å»ºçš„ruozhibaæŒ‡ä»¤æ•°æ®[^1]ï¼Œå…±è®¡2449æ¡ã€‚\\næ³¨æ„ï¼šæŒ‡ä»¤æ•°æ®ä¸­å¯èƒ½åŒ…å«å†’çŠ¯ç”¨è¯­ã€‚è¾“å‡ºå¹¶æœªç»è¿‡äººå·¥éªŒè¯ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\tæ‰€å±é¡¹ç›®\\n\\t\\n\\nChinese-LLaMA-Alpaca-3ï¼šhttps://github.com/ymcui/Chinese-LLaMA-Alpaca-3\\n\\nThis repository contains the ruozhiba instruction data[^1] constructed by using o3-mini-2025-01-31, totaling 2449 entries.\\nNote: The instruction data may contain offensive language. Outputs are NOT verified by human.\\n\\n\\t\\n\\t\\t\\n\\t\\tProjectâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hfl/ruozhiba_o3mini.","first_N":5,"first_N_keywords":["Chinese","cc-by-sa-4.0","arxiv:2403.18058","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"JL1-CD","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/circleLZY/JL1-CD","creator_name":"Ziyuan Liu","creator_url":"https://huggingface.co/circleLZY","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for JL1-CD\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description (English)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nJL1-CD is a large-scale, sub-meter, all-inclusive open-source dataset for remote sensing image change detection (CD). It contains 5,000 pairs of 512Ã—512 pixel satellite images with a resolution of 0.5 to 0.75 meters, covering various types of surface changes in multiple regions of China. JL1-CD includes not only common human-induced changes (e.g., buildings, roads) but also natural changes (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/circleLZY/JL1-CD.","first_N":5,"first_N_keywords":["image-segmentation","semantic-segmentation","English","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"CaseGen","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CSHaitao/CaseGen","creator_name":"Haitao Li","creator_url":"https://huggingface.co/CSHaitao","description":"\\n\\t\\n\\t\\t\\n\\t\\tCaseGen: A Benchmark for Multi-Stage Legal Case Documents Generation\\n\\t\\n\\n\\n\\n\\n\\nCaseGen is a benchmark designed to evaluate large language models (LLMs) in the generation of legal case documents in the Chinese legal domain. The dataset includes 500 real-world legal case instances, each structured into seven sections: Prosecution, Defense, Evidence, Events, Facts, Reasoning, and Judgment. It supports four key tasks: drafting defense statements, writing trial facts, composing legal reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CSHaitao/CaseGen.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-sa-4.0","ğŸ‡ºğŸ‡¸ Region: US","legal"],"keywords_longer_than_N":true},
	{"name":"CaseGen","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CSHaitao/CaseGen","creator_name":"Haitao Li","creator_url":"https://huggingface.co/CSHaitao","description":"\\n\\t\\n\\t\\t\\n\\t\\tCaseGen: A Benchmark for Multi-Stage Legal Case Documents Generation\\n\\t\\n\\n\\n\\n\\n\\nCaseGen is a benchmark designed to evaluate large language models (LLMs) in the generation of legal case documents in the Chinese legal domain. The dataset includes 500 real-world legal case instances, each structured into seven sections: Prosecution, Defense, Evidence, Events, Facts, Reasoning, and Judgment. It supports four key tasks: drafting defense statements, writing trial facts, composing legal reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CSHaitao/CaseGen.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-sa-4.0","ğŸ‡ºğŸ‡¸ Region: US","legal"],"keywords_longer_than_N":true},
	{"name":"RFUAV","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kitofrank/RFUAV","creator_name":"Rui Shi","creator_url":"https://huggingface.co/kitofrank","description":" The RFUAV DATASET \\n\\n\\n\\t\\n\\t\\t\\n\\t\\tAbstract\\n\\t\\n\\nThe official dataset repository for our paper, \\\"RFUAV: A Benchmark Dataset for Unmanned Aerial Vehicle Detection and Identification\\\", can be accessed here. RFUAV offers a comprehensive benchmark dataset for Radio-Frequency (RF)-based drone detection and identification.\\n\\nMore detailed usage see our GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{shi2025rfuavbenchmarkdatasetunmanned,\\n      title={RFUAV: A Benchmark Dataset for Unmanned Aerial Vehicle Detection andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kitofrank/RFUAV.","first_N":5,"first_N_keywords":["image-classification","text-classification","audio-classification","robotics","English"],"keywords_longer_than_N":true},
	{"name":"CHBench","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TracyGuo/CHBench","creator_name":"Tracy","creator_url":"https://huggingface.co/TracyGuo","description":"\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nwe present CHBench, the first comprehensive safety-oriented Chinese health-related benchmark designed to evaluate LLMs' capabilities in understanding and addressing physical and mental health issues with a safety perspective across diverse scenarios. CHBench comprises 6,493 entries on mental health and 2,999 entries on physical health, spanning a wide range of topics.\\n\\n\\t\\n\\t\\t\\n\\t\\tResponse Assessment\\n\\t\\n\\nResponses were generated using 5 Chinese language models, see below forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TracyGuo/CHBench.","first_N":5,"first_N_keywords":["Chinese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"OpenSeek-Pretrain-Data-Examples","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/OpenSeek-Pretrain-Data-Examples","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpenSeek Pretraining Dataset v1.0 (Sample Release)\\n\\t\\n\\nWe have released a portion of the sampled data from the OpenSeek Pretraining Dataset v1.0, primarily including Chinese and English Common Crawl (CC) datasets. Additional domain-specific datasets will be provided in future updates.\\n\\n\\t\\n\\t\\t\\n\\t\\tğŸ“Œ Dataset Sources\\n\\t\\n\\n\\nEnglish CC dataset: Mainly sourced from the Nemotron-CC dataset.\\nChinese CC dataset: Followed the Nemotron-CC data pipeline, based on aggregated open-source Chinese datasets.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI/OpenSeek-Pretrain-Data-Examples.","first_N":5,"first_N_keywords":["English","Chinese","cc-by-4.0","10K<n<100K","arxiv:2412.02595"],"keywords_longer_than_N":true},
	{"name":"wisdomInterrogatory-R1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YinghaoHu/wisdomInterrogatory-R1","creator_name":"Hu","creator_url":"https://huggingface.co/YinghaoHu","description":"\\n\\t\\n\\t\\t\\n\\t\\tæ™ºæµ·-å½•é—® æ¨ç†æ•°æ®(wisdomInterrogatory-R1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nç±»åˆ«\\næ•°æ®é‡\\nä»»åŠ¡æè¿°\\n\\n\\n\\t\\t\\nç½ªåé¢„æµ‹\\n20k\\nè¯·ä½œä¸ºä¸­å›½æ³•å®˜,åŸºäºæ¡ˆä»¶äº‹å®,å¯¹è¢«å‘Šäººè¿›è¡Œå•ä¸€ç½ªåé¢„æµ‹ã€‚è¿”å›æ ¼å¼ï¼šâ€œç½ªåâ€.ç¤ºä¾‹ï¼šâ€œç›—çªƒâ€,â€œæ•²è¯ˆå‹’ç´¢â€ã€‚\\n\\n\\nåˆ‘æœŸé¢„æµ‹\\n5k\\nè¯·ä½œä¸ºä¸­å›½æ³•å®˜,åŸºäºæ¡ˆä»¶äº‹å®,å¯¹è¢«å‘Šäººè¿›è¡Œé‡åˆ‘é¢„æµ‹,è¯·éµä»ä¸‹åˆ—è§„åˆ™,è¿”å›ç»“æœ:- å¦‚æœé‡åˆ‘ä¸ºæœ‰æœŸå¾’åˆ‘,è¯·è¿”å›:â€œé‡åˆ‘æœˆæ•°â€,ä¾‹å¦‚åº”åˆ¤å†³5å¹´,5å¹´=60æœˆ,åˆ™è¿”å›60.- å¦‚æœé‡åˆ‘ä¸ºæ— æœŸå¾’åˆ‘,è¯·è¿”å›:â€œlife_imprisonmentâ€.- å¦‚æœé‡åˆ‘ä¸ºæ­»åˆ‘,è¯·è¿”å›:â€œdeath_penaltyâ€ã€‚\\n\\n\\nè®ºè¾©æŒ–æ˜\\n4k\\nåœ¨æ³•é™¢çš„åº­å®¡è¿‡ç¨‹ä¸­ï¼Œè¯‰æ–¹ä¸è¾©æ–¹ç”±äºç«‹åœºè§‚ç‚¹æˆ–äº‹å®é™ˆè¿°çš„å·®å¼‚ï¼Œä¼šå½¢æˆåº­å®¡äº‰è®®ç„¦ç‚¹ï¼Œè¿™æ˜¯æ•´åœºåº­å®¡çš„æ ¸å¿ƒç¯èŠ‚ã€‚è¿™ç§è¾©æ–¹ä¸è¯‰æ–¹ä¹‹é—´å½¢æˆçš„é€»è¾‘äº’åŠ¨è®ºç‚¹å¯¹ï¼Œå³ä¸ºäº‰è®®ç„¦ç‚¹ã€‚è¯·ä½œä¸ºä¸­å›½çš„è¾©æŠ¤å¾‹å¸ˆï¼Œæ‰§è¡Œâ€œè®ºè¾©æŒ–æ˜â€ä»»åŠ¡ï¼Œå³æ ¹æ®æä¾›çš„è¢«å‘Šç½ªåå’Œè¯‰æ–¹è®ºç‚¹ï¼Œä»äº”ä¸ªå€™é€‰è¾©æŠ¤è®ºç‚¹ä¸­ï¼Œé€‰æ‹©ä¸€ä¸ªæœ€é€‚åˆä½œä¸ºä¸è¯‰æ–¹è§‚ç‚¹å½¢æˆäº’åŠ¨å¯¹çš„è®ºç‚¹ã€‚éœ€è¦ç‰¹åˆ«è¯´æ˜çš„æ˜¯ï¼Œäº‰è®®ç„¦ç‚¹çš„å¯¹æŠ—ï¼Œå§‹ç»ˆåŸºäºäº‹å®åŸºç¡€ã€‚è¿”å›æ ¼å¼ï¼šâ€œç¼–å·â€.ç¤ºä¾‹ï¼šâ€œ1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/YinghaoHu/wisdomInterrogatory-R1.","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","10K<n<100K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"wikis","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/wikis","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Public MediaWiki Collection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 1,662,448 articles harvested from 930 random public MediaWiki instances found across the Internet. The collection was created by extracting current page content from these wikis, preserving article text, metadata, and structural information. The dataset represents a diverse cross-section of public wiki content spanning multiple domains, topics, and languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wikis.","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","topic-classification","found"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"WÅ‚odzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy Itâ€™s Important\\n\\t\\n\\n\\nEnhances Trust: For readers andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"hwtcm-deepseek-r1-distill-data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Monor/hwtcm-deepseek-r1-distill-data","creator_name":"Monor Huang","creator_url":"https://huggingface.co/Monor","description":"\\n\\t\\n\\t\\t\\n\\t\\tç®€ä»‹\\n\\t\\n\\nDeepSeekè’¸é¦çš„ä¼ ç»Ÿä¸­åŒ»æ•°æ®é›†ï¼ŒåŸå§‹æ•°æ®æ¥æºäºç½‘ç»œï¼Œæœªè¿›è¡Œäººå·¥å®¡æŸ¥ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\t7Bæ¨¡å‹å¾®è°ƒæ•ˆæœ\\n\\t\\n\\n\\næ¨¡å‹è¡¨ç°å‡ºäº†æ¨ç†èƒ½åŠ›ï¼Œå‡†ç¡®æ€§æœ‰å¾…ç»§ç»­éªŒè¯ã€‚\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæˆ‘ä»¬çš„å…¶ä»–äº§å“\\n\\t\\n\\nä¸­åŒ»NERï¼šèƒ½è¯†åˆ«æ–¹å‰‚ã€æœ¬è‰ã€æ¥æºã€ç—…åã€ç—‡çŠ¶ã€è¯å‹ï¼Œä¹Ÿè®¸æ˜¯åŸºäºBERTå¼€æºæ¨¡å‹ä¸­è¯†åˆ«æœ€å¥½çš„æ¨¡å‹ã€‚ä¸­åŒ»è€ƒè¯•é¢˜ï¼šä¹Ÿè®¸æ˜¯å…¨ç½‘æœ€æ—©å¼€æºã€æ•°æ®æœ€å¤šçš„ä¸­åŒ»è€ƒè¯•é¢˜ï¼Œæˆ‘ä»¬å†…éƒ¨å°†å…¶ç”¨äºæ¨¡å‹è®­ç»ƒçš„æ€§èƒ½è¯„æµ‹æ•°æ®é›†ã€‚ä¸­åŒ»SFTæ•°æ®é›†ï¼šä¸­åŒ»QAæ•°æ®é›†ï¼Œç”¨äºSFTå¾®è°ƒã€‚ä»“å…¬ï¼šåŸºäºQwençš„æŒ‡ä»¤å¾®è°ƒæ¨¡å‹ï¼ˆæš‚æœªå¼€æºï¼‰ã€‚ä»“å…¬R1ï¼šåŸºäºDeepSeekè’¸é¦çš„è¶…è¿‡100ä¸‡æ¡QAçš„æŒ‡ä»¤å¾®è°ƒæ¨¡å‹ï¼Œæ‹¥æœ‰å¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼ˆæš‚æœªå¼€æºï¼‰ã€‚  \\nã€‚ã€‚ã€‚è¿˜æœ‰å¾ˆå¤š\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you find this project useful in your research, please consider cite:\\n@misc{hwtcm2024,\\n    title={{hwtcm-deepseek-r1-distill-data} A traditionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Monor/hwtcm-deepseek-r1-distill-data.","first_N":5,"first_N_keywords":["question-answering","text-generation","feature-extraction","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"HAIC","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KuaishouHAIC/HAIC","creator_name":"KuaishouHAIC","creator_url":"https://huggingface.co/KuaishouHAIC","description":"\\n\\t\\n\\t\\t\\n\\t\\tHAIC: Human Action and Interaction Comprehension Dataset\\n\\t\\n\\nFrom the paper: \\\"HAIC: Improving Human Action Understanding and Generation with Better Captions for Multi-modal Large Language Models\\\"\\nRead the Paper\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nHAICBench is a comprehensive video dataset featuring manually annotated, fine-grained human captions that features:\\n\\nMultiple Human Subjects: Captions detail interactions and activities involving more than one person, capturing the complexity of humanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KuaishouHAIC/HAIC.","first_N":5,"first_N_keywords":["video-text-to-text","English","Chinese","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"runpod_multi_model_think_content_casestudies","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DataTonic/runpod_multi_model_think_content_casestudies","creator_name":"Data Tonic (Alignment Lab)","creator_url":"https://huggingface.co/DataTonic","description":"DataTonic/runpod_multi_model_think_content_casestudies dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","question-answering","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"Thinking-multilingual-big-10k-sft","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\\nenjoy ğŸ‘\\n","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"m-WildVision","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/m-WildVision","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-WildVision\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \\nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \\nThe authors demonstrated that these prompts enable automatic LLM judgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-WildVision.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"OpenHumanreasoning-multilingual-2.2k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\\nnote: translations are not human generated.\\n","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"DataOne-synthetic-parking-v1.1-sample","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/51WORLD/DataOne-synthetic-parking-v1.1-sample","creator_name":"51WORLD","creator_url":"https://huggingface.co/51WORLD","description":"\\n\\t\\n\\t\\t\\n\\t\\t51WORLD Synthetic Dataset Usage Documentation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1 Introduction\\n\\t\\n\\nThe 51WORLD systhetic dataset mainly contains camera sensor-related data and LiDAR sensor-related data generated by 51Sim-One. Camera sensor-related data mainly includes images and corresponding semantic segmentation, instance segmentation, depth annotation, and Object Detection annotation; LiDAR sensor-related data mainly includes laser point clouds and annotation of 3Dbboxes, semantic segmentation annotationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/51WORLD/DataOne-synthetic-parking-v1.1-sample.","first_N":5,"first_N_keywords":["English","Chinese","cc-by-4.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"DataOne-synthetic-nuscenes-v1.1-sample","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/51WORLD/DataOne-synthetic-nuscenes-v1.1-sample","creator_name":"51WORLD","creator_url":"https://huggingface.co/51WORLD","description":"\\n\\t\\n\\t\\t\\n\\t\\t51WORLD Synthetic Dataset Usage Documentation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1 Introduction\\n\\t\\n\\nThe 51WORLD systhetic dataset mainly contains camera sensor-related data and LiDAR sensor-related data generated by 51Sim-One. Camera sensor-related data mainly includes images and corresponding semantic segmentation, instance segmentation, depth annotation, and Object Detection annotation; LiDAR sensor-related data mainly includes laser point clouds and annotation of 3Dbboxes, semantic segmentation annotationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/51WORLD/DataOne-synthetic-nuscenes-v1.1-sample.","first_N":5,"first_N_keywords":["English","Chinese","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"SynthLaw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ShengbinYue/SynthLaw","creator_name":"ShengbinYue","creator_url":"https://huggingface.co/ShengbinYue","description":"\\n\\t\\n\\t\\t\\n\\t\\tMulti-Agent Simulator Drives Language Models for Legal Intensive Interaction\\n\\t\\n\\nThis work is accepted by NAACL 2025.\\nPaper | Github\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for SynthLaw-4.5k\\n\\t\\n\\nSynthLaw-Dataset is a synthetic legal scenario dataset in complaint drafing. \\nThe dataset consists of 4,532 samples. Note two keys in the synthetic process: 1) real-legal source configurations and supervision mechanisms in each interaction ensure that the generated data is aligned at the sentence level, closelyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ShengbinYue/SynthLaw.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"DocumentaryScript","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/harmomy/DocumentaryScript","creator_name":"mm","creator_url":"https://huggingface.co/harmomy","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/harmomy/DocumentaryScript.","first_N":5,"first_N_keywords":["Chinese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"bilibilicomment","keyword":"chinese","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Midsummra/bilibilicomment","creator_name":"å³°æ™“","creator_url":"https://huggingface.co/Midsummra","description":"Bilibiliè¯„è®ºåŒºè¯­æ–™(2023å¹´)\\nåœ¨2023å¹´çˆ¬çš„bç«™è¯„è®ºåŒºè¯­æ–™\\nä¸é—´æ–­åœ°ä»bç«™å„ä¸ªåˆ†åŒºçˆ¬å–çš„çƒ­é—¨è§†é¢‘è¯„è®ºï¼Œå…±è®¡500Wæ¡å·¦å³\\næ²¡æœ‰ç»è¿‡ä»»ä½•æ¸…æ´—ï¼Œæ‰€ä»¥æ•°æ®æ¯”è¾ƒè„\\nç”±äºæ¸¸æˆåŒºå…¨æ˜¯åŸç¥ï¼Œæ‰€ä»¥ä¸å¯é¿å…ä¼šæœ‰å¾ˆå¤šåŸç¥æœ‰å…³çš„è¯„è®ºï¼Œå¦‚æœä¸ç»æ¸…æ´—ç›´æ¥ç”¨æ¥è®­ç»ƒç”Ÿæˆå¼æ¨¡å‹æˆ–è€…å¯¹è¯æ¨¡å‹å¯èƒ½ä¼šæœ‰å¾ˆä¸¥é‡çš„biaes(æ¨¡å‹ä¸€ç›´åœ¨è¾“å‡ºåŸç¥ç›¸å…³å†…å®¹ï¼Œï¼Œï¼Œ)\\næœ‰äº›datapointä¸­å­˜åœ¨ â€œå›å¤ @XXX :â€ ï¼Œè¡¨ç¤ºè¯¥è¯„è®ºæ˜¯å¯¹ä¸Šä¸€ä¸ªdatapointçš„å›å¤\\n","first_N":5,"first_N_keywords":["text-generation","question-answering","Chinese","agpl-3.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"SVBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yzy666/SVBench","creator_name":"Zhenyu Yang","creator_url":"https://huggingface.co/yzy666","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for SVBench\\n\\t\\n\\nThis dataset card aims to provide a comprehensive overview of the SVBench dataset, including its purpose, structure, and sources. For details, see our Project, Paper and GitHub repository.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nSVBench is the first benchmark specifically designed to evaluate long-context streaming video understanding through temporal multi-turn question-answering (QA) chains. It addresses the limitations of existing videoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yzy666/SVBench.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"GoDatas","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Karesis/GoDatas","creator_name":"æ¨äº¦é”‹","creator_url":"https://huggingface.co/Karesis","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Go Game Dataset for Neural Network Training\\n\\t\\n\\nThis is a high-quality dataset designed for Go neural network training, containing board positions extracted from curated SGF game records. The dataset is divided into three strength categories: Standard, Strong, and Elite, with approximately 1,000 samples per category.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains Go board positions and corresponding moves extracted from high-quality SGFâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Karesis/GoDatas.","first_N":5,"first_N_keywords":["reinforcement-learning","feature-extraction","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"BRIGHTER-emotion-categories","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\tBRIGHTER Emotion Categories Dataset\\n\\t\\n\\nThis dataset contains the emotion categories data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe BRIGHTER Emotion Categories dataset is a comprehensive multi-language, multi-label emotion classification dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multipleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories.","first_N":5,"first_N_keywords":["Afrikaans","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"reasoning-conversations","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/syntaxsynth/reasoning-conversations","creator_name":"SyntaxSynth","creator_url":"https://huggingface.co/syntaxsynth","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Reasoning Dataset\\n\\t\\n\\n\\nInclude languages from German, Korean, Spanish, Japanese, French, Simplified Chinese, Traditional Chinese\\n\\nReasoning traces from Deepseek-v3-R1, Deepseek-v3-R1-Zero\\n\\n\\nCredits sponsored by Currents API\\n","first_N":5,"first_N_keywords":["text2text-generation","English","Spanish","Korean","German"],"keywords_longer_than_N":true},
	{"name":"Bilingual-Medic-4.6M","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/XeTute/Bilingual-Medic-4.6M","creator_name":"XeTute Technologies","creator_url":"https://huggingface.co/XeTute","description":"\\n\\n  \\n\\n\\nğŸš€ One of the largest medical datasets on HuggingFace\\n\\n\\n\\n\\n  \\n    \\n  \\n  \\n    \\n  \\n  \\n    \\n    \\n  \\n\\n\\n\\n\\nThis dataset contains approximately 4.6M samples, mainly in Chinese, but there is also a good amount of English samples.We merged, re-formatted & corrected:\\n\\nmedalpaca/medical_meadow_wikidoc: English; 10k samples\\nXeTute/Medic-Thoughts-16k: English; 16k samples\\nFreedomIntelligence/medical-o1-reasoning-SFT: English & Chinese; Merged 50.2k samples\\nticoAg/Chinese-medical-dialogue: Chinese;â€¦ See the full description on the dataset page: https://huggingface.co/datasets/XeTute/Bilingual-Medic-4.6M.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"h-corpus-raw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Limour/h-corpus-raw","creator_name":"Limour","creator_url":"https://huggingface.co/Limour","description":"æœªæ¸…æ´—çš„ä¸­æ–‡Hå°è¯´\\nä»…ä¾›ç§‘å­¦ç ”ç©¶ä½¿ç”¨ï¼\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","text","Text"],"keywords_longer_than_N":true},
	{"name":"Sex-novel-filtered","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Seikaijyu/Sex-novel-filtered","creator_name":"Seikaijyu","creator_url":"https://huggingface.co/Seikaijyu","description":"\\n\\t\\n\\t\\t\\n\\t\\tè‰²æƒ…å°è¯´æ•°æ®é›†\\n\\t\\n\\n\\næœ¬æ•°æ®é›†åŒ…å«äº†3392æ¡å•æ¡æ•°æ®æœ€å¤§é•¿åº¦2500tokençš„æ•°æ®é›†\\nè¿™æ˜¯ä¸€ä¸ªè¢«äººå·¥ç²¾ç»†åŒ–æ¸…æ´—è¿‡çš„è‰²æƒ…å°è¯´æ•°æ®é›†ï¼Œæ­¤æ•°æ®æ¥æºäºPixivå°è¯´æ¿å—\\nåŸæ•°æ®é›†æœ‰3wæ¡ï¼Œæˆ‘èŠ±äº†ä¸€ä¸ªé€šå®µçš„æ—¶é—´é…åˆæ­£åˆ™äººå·¥æ¸…æ´—äº†å®ƒï¼Œæœ€ç»ˆå¾—åˆ°äº†3000æ¡è¯­æ–™\\nè™½ç„¶ç²¾ç»†å¤„ç†è¿‡ï¼Œä½†ä¸èƒ½ä¿è¯ç™¾åˆ†ç™¾å¹²å‡€\\nè™½ç„¶è¿™ä¹ˆè¯´.....ä½†æ­¤æ•°æ®å·²ç»å¯ä»¥ç›´æ¥è®­ç»ƒäº†ï¼Œè‡³å°‘ä¸ä¼šæœ‰ä»€ä¹ˆå¤§é—®é¢˜\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tå¦å¤–æä¸€å˜´ï¼Œç°ä»£ç½‘ç»œå°è¯´çœŸéš¾ç»ƒå•Šï¼Œctxç‰¹é•¿ï¼Œè´¨é‡ç‰¹ä½ï¼Œé£æ ¼é€»è¾‘æ··ä¹±ï¼Œæ”¶æ•›ç‰¹æ…¢ï¼Œæ„Ÿè§‰æ ¹æœ¬å°±æ˜¯ä¸€æ— æ˜¯å¤„å˜›\\n\\t\\n\\n\\n","first_N":5,"first_N_keywords":["Chinese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"dpo-toxic-zh","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/dpo-toxic-zh","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\tDPO Toxic Chinese v2.0\\n\\t\\n\\n\\n  Change Log\\n  \\n\\nv2.0: å¢åŠ äº†adamo1139/toxic-dpo-natural-v5, å¹¶æ›´æ–°äº†ç¿»è¯‘ç­–ç•¥. promptç”±t5_translateæ¨¡å‹ç¿»è¯‘, chosenç”±Uncensoredå¤§æ¨¡å‹ç¿»è¯‘, rejectedç”±ä¸€èˆ¬å¤§æ¨¡å‹å¯¹promptç”Ÿæˆæ‹’ç»æ€§çš„å›å¤\\nv1.0: æœ€åˆç‰ˆæœ¬, ä½¿ç”¨å¤§æ¨¡å‹å°†unalignment/toxic-dpo-v0.2ç¿»è¯‘è€Œæ¥\\n\\n\\n\\nè¿™æ˜¯ä¸€ä¸ªé«˜åº¦æ¯’æ€§, é«˜åº¦æœ‰å®³çš„æ•°æ®é›†, æ„åœ¨å±•ç¤ºDPOæ˜¯å¦‚ä½•ç ´é™¤æ¨¡å‹çš„å®¡æ ¸/å¯¹é½çš„\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä½¿ç”¨é™åˆ¶\\n\\t\\n\\nè¿™ä¸ªæ•°æ®é›†è¢«è®¾è®¡ç”¨äºå­¦æœ¯ç ”ç©¶, è€Œéå…¶ä»–æ¶æ„åœºæ™¯. ä¸‹è½½æˆ–ä½¿ç”¨è¿™ä¸ªæ•°æ®é›†, åˆ™è§†ä¸ºæ‚¨æ‰¿è®¤ä»¥ä¸‹çš„äº‹å®:\\n\\nè¿™ä¸ªæ•°æ®é›†æ˜¯æœ‰æ¯’çš„, åŒ…å«è®¸å¤šæ•æ„Ÿå†…å®¹\\næ•°æ®é›†ä¸­æ–‡æœ¬åŒ…å«çš„å†…å®¹å’Œè§‚ç‚¹ä¸æˆ‘å®Œå…¨æ— å…³, å®ƒä»¬åªæ˜¯å¤§æ¨¡å‹ç”Ÿæˆçš„æ–‡å­—\\næ‚¨å¯ä»¥ä½¿ç”¨è¯¥æ•°æ®é›†, ä½†å¿…é¡»éµå®ˆç›¸å…³æ³•å¾‹\\næ‚¨å¯¹æ‚¨è‡ªå·±ä¸‹è½½å’Œä½¿ç”¨æ•°æ®é›†çš„è¡Œä¸ºè´Ÿè´£, æˆ‘å¯¹æ‚¨çš„ä¸€åˆ‡è¡Œä¸ºæ²¡æœ‰ä»»ä½•è´£ä»»\\n\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","gpl-3.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"alt","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mutiyama/alt","creator_name":"Masao Utiyama","creator_url":"https://huggingface.co/mutiyama","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Asian Language Treebank (ALT)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe ALT project aims to advance the state-of-the-art Asian natural language processing (NLP) techniques through the open collaboration for developing and using ALT. It was first conducted by NICT and UCSY as described in Ye Kyaw Thu, Win Pa Pa, Masao Utiyama, Andrew Finch and Eiichiro Sumita (2016). Then, it was developed under ASEAN IVO as described in this Web page. \\nThe process of building ALT beganâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mutiyama/alt.","first_N":5,"first_N_keywords":["translation","token-classification","parsing","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"amttl","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gavinxing/amttl","creator_name":"Gavin Xing","creator_url":"https://huggingface.co/gavinxing","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AMTTL\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More Informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gavinxing/amttl.","first_N":5,"first_N_keywords":["token-classification","parsing","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"opus_infopankki","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_infopankki","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for infopankki\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA parallel corpus of 12 languages, 66 bitexts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe underlying task is machine translation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_infopankki.","first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"opus_paracrawl","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for OpusParaCrawl\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nParallel corpora from Web Crawls collected in the ParaCrawl project.\\nTha dataset contains:\\n\\n42 languages, 43 bitexts\\ntotal number of files: 59,996\\ntotal number of tokens: 56.11G\\ntotal number of sentence fragments: 3.13G\\n\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs,\\ne.g.\\ndataset = load_dataset(\\\"opus_paracrawl\\\", lang1=\\\"en\\\", lang2=\\\"so\\\")\\n\\nYou can findâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl.","first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"chinese","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"achinese","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"min nan chinese","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"xcopa","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cambridgeltl/xcopa","creator_name":"Language Technology Lab @University of Cambridge","creator_url":"https://huggingface.co/cambridgeltl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xcopa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n  XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning\\nThe Cross-lingual Choice of Plausible Alternatives dataset is a benchmark to evaluate the ability of machine learning models to transfer commonsense reasoning across\\nlanguages. The dataset is the translation and reannotation of the English COPA (Roemmele et al. 2011) and covers 11 languages from 11 families and several areas around\\nthe globe. The dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cambridgeltl/xcopa.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xcsr","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/INK-USC/xcsr","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for X-CSR\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTo evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","crowdsourced","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"xquad_r","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/xquad_r","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nXQuAD-R is a retrieval version of the XQuAD dataset (a cross-lingual extractive\\nQA dataset). Like XQuAD, XQUAD-R is an 11-way parallel dataset,  where each\\nquestion appears in 11 different languages and has 11 parallel correct answers\\nacross the languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset can be found with the following languages:\\n\\nArabic:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/xquad_r.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"RiSAWOZ","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GEM/RiSAWOZ","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","description":"RiSAWOZ contains 11.2K human-to-human (H2H) multiturn semantically annotated dialogues, with more than 150K utterances spanning over 12 domains, which is larger than all previous annotated H2H conversational datasets.Both single- and multi-domain dialogues are constructed, accounting for 65% and 35%, respectively.","first_N":5,"first_N_keywords":["crowd-sourced","unknown","unknown","original","Chinese"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"ekar_chinese","keyword":"chinese","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jiangjiechen/ekar_chinese","creator_name":"Jiangjie Chen","creator_url":"https://huggingface.co/jiangjiechen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ekar_chinese\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nNew!(9/18/2022) E-KAR v1.1 is officially released (at the main branch), with a higher-quality English dataset! In v1.1, we further improve the Chinese-to-English translation quality of the English E-KAR, with over 600 problems and over 1,000 explanations manually adjusted. You can still find previous version (as in the paper) in the v1.0 branch in the repo. For more information please refer toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jiangjiechen/ekar_chinese.","first_N":5,"first_N_keywords":["question-answering","text-generation","explanation-generation","original","Chinese"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"ascend","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/filwsyl/ascend","creator_name":"jianyuan.zengjy","creator_url":"https://huggingface.co/filwsyl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ASCEND\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nASCEND (A Spontaneous Chinese-English Dataset) introduces a high-quality resource of spontaneous multi-turn conversational dialogue Chinese-English code-switching corpus collected in Hong Kong. ASCEND consists of 10.62 hours of spontaneous speech with a total of ~12.3K utterances. The corpus is split into 3 sets: training, validation, and test with a ratio of 8:1:1 while maintaining a balanced gender proportion on each set.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/filwsyl/ascend.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"min nan chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"yue chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"bucc-bitext-mining","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/bucc-bitext-mining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MTEB Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMTEB is a heterogeneous benchmark that has been built from diverse tasks:\\n\\nBitextMining: BUCC, Tatoeba\\nClassification: AmazonCounterfactualClassification, AmazonPolarityClassification, AmazonReviewsClassification, Banking77Classification, EmotionClassification, ImdbClassification, MassiveIntentClassification, MassiveScenarioClassification, MTOPDomainClassification, MTOPIntentClassificationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/bucc-bitext-mining.","first_N":5,"first_N_keywords":["monolingual","multilingual","German","English","French"],"keywords_longer_than_N":true},
	{"name":"lccc","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/silver/lccc","creator_name":"Silver","creator_url":"https://huggingface.co/silver","description":"LCCC: Large-scale Cleaned Chinese Conversation corpus (LCCC) is a large corpus of Chinese conversations.\\nA rigorous data cleaning pipeline is designed to ensure the quality of the corpus.\\nThis pipeline involves a set of rules and several classifier-based filters.\\nNoises such as offensive or sensitive words, special symbols, emojis,\\ngrammatically incorrect sentences, and incoherent conversations are filtered.","first_N":5,"first_N_keywords":["dialogue-generation","other","other","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"SalienceEvaluation","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yincen/SalienceEvaluation","creator_name":"Qu","creator_url":"https://huggingface.co/Yincen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Yincen/SalienceEvaluation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationaleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yincen/SalienceEvaluation.","first_N":5,"first_N_keywords":["text-classification","multi-input-text-classification","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-mandarin","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-mandarin","creator_name":"Paul RÃ¶ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-mandarin.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"xP3all","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"xP3mt","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"miracl-corpus","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/miracl-corpus","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MIRACL Corpus\\n\\t\\n\\nMIRACL ğŸŒğŸ™ŒğŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\\nThis dataset contains the collection data of the 16 \\\"known languages\\\". The remaining 2 \\\"surprise languages\\\" will not be released until later.\\nThe corpus for each language is prepared from aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"shu","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shjwudp/shu","creator_name":"Jianbin Chang","creator_url":"https://huggingface.co/shjwudp","description":"shu is a chinese book dataset.","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","10K - 100K","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"crosswoz","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/crosswoz","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CrossWOZ\\n\\t\\n\\n\\nRepository: https://github.com/thu-coai/CrossWOZ\\nPaper: https://aclanthology.org/2020.tacl-1.19/\\nLeaderboard: None\\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\\n\\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\\nfrom convlab.util import load_dataset, load_ontology, load_database\\n\\ndataset = load_dataset('crosswoz')\\nontology = load_ontology('crosswoz')\\ndatabase = load_database('crosswoz')â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/crosswoz.","first_N":5,"first_N_keywords":["monolingual","Chinese","apache-2.0","1K<n<10K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"HashtagPrediction","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\\n\\t\\n\\n  \\nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \\n[arXiv]\\n[HuggingFace Models]\\n[Github repo]\\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDownload\\n\\t\\n\\nUse theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"chinese-c4","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shjwudp/chinese-c4","creator_name":"Jianbin Chang","creator_url":"https://huggingface.co/shjwudp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nChinese-C4 is a clean Chinese internet dataset based on Common Crawl. The dataset is 46.29GB and has undergone multiple cleaning strategies, including Chinese filtering, heuristic cleaning based on punctuation, line-based hashing for deduplication, and repetition removal.\\nThe dataset is open source and free for commercial use, and you are welcome to use the data and the cleaning strategies provided and contribute your cleaning strategies.\\nYou can find the cleaningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shjwudp/chinese-c4.","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"clue-ner","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xusenlin/clue-ner","creator_name":"xusenlin","creator_url":"https://huggingface.co/xusenlin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCLUE-NER å‘½åå®ä½“è¯†åˆ«æ•°æ®é›†\\n\\t\\n\\nå­—æ®µè¯´æ˜\\n\\ntext: æ–‡æœ¬\\n\\nentities: æ–‡æœ¬ä¸­åŒ…å«çš„å®ä½“\\n\\nid: å®ä½“ id\\n\\nentity: å®ä½“å¯¹åº”çš„å­—ç¬¦ä¸²\\n\\nstart_offset: å®ä½“å¼€å§‹ä½ç½®\\n\\nend_offset: å®ä½“ç»“æŸä½ç½®çš„ä¸‹ä¸€ä½\\n\\nlabel: å®ä½“å¯¹åº”çš„å¼€å§‹ä½ç½®\\n\\n\\n\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"trdg_random_en_zh_text_recognition","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/priyank-m/trdg_random_en_zh_text_recognition","creator_name":"priyank","creator_url":"https://huggingface.co/priyank-m","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"trdg_random_en_zh_text_recognition\\\"\\n\\t\\n\\nThis synthetic dataset was generated using the TextRecognitionDataGenerator(TRDG) open source repo: \\nhttps://github.com/Belval/TextRecognitionDataGenerator\\nIt contains images of text with random characters from Engilsh(en) and Chinese(zh) languages.\\nReference to the documentation provided by the TRDG repo: \\nhttps://textrecognitiondatagenerator.readthedocs.io/en/latest/index.html\\n","first_N":5,"first_N_keywords":["image-to-text","English","Chinese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Hansel","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HIT-TMG/Hansel","creator_name":"HITsz-Text Machine Group","creator_url":"https://huggingface.co/HIT-TMG","description":"Hansel is a high-quality human-annotated Chinese entity linking (EL) dataset, used for testing Chinese EL systems' generalization ability to tail entities and emerging entities.\\nThe test set contains Few-shot (FS) and zero-shot (ZS) slices, has 10K examples and uses Wikidata as the corresponding knowledge base.\\nThe training and validation sets are from Wikipedia hyperlinks, useful for large-scale pretraining of Chinese EL systems.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","crowdsourced","found","found"],"keywords_longer_than_N":true},
	{"name":"stock11","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuroneko5943/stock11","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","machine-generated","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-zh-embeddings","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-zh-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikipedia (zh) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded Wikipedia (zh) using the cohere.ai multilingual-22-12 embedding model.\\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEmbeddings\\n\\t\\n\\nWe compute for title+\\\" \\\"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-zh-embeddings.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","multilingual","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"douban-dushu","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/larrylawl/douban-dushu","creator_name":"Law Ann Liat Larry","creator_url":"https://huggingface.co/larrylawl","description":"This dataset contains book reviews from DouBan Dushu. DouBan DuShu is a Chinese website where users can share their reviews about various kinds of books. Most of the users in this website are unprofessional book reviewers. Therefore, the comments are usually spoken Chinese or even Internet slang.","first_N":5,"first_N_keywords":["no-annotation","crowdsourced","monolingual","Chinese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"xstory_cloze","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/juletxara/xstory_cloze","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","description":"XStoryCloze consists of the professionally translated version of the [English StoryCloze dataset](https://cs.rochester.edu/nlp/rocstories/) (Spring 2016 version) to 10 non-English languages. This dataset is released by Meta AI.","first_N":5,"first_N_keywords":["other","found","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"NusaX-senti","keyword":"achinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/indonlp/NusaX-senti","creator_name":"IndoNLP","creator_url":"https://huggingface.co/indonlp","description":"NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"miracl-zh-corpus-22-12","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-zh-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (zh) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-zh-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-zh-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL ğŸŒğŸ™ŒğŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-zh-corpus-22-12.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"miracl-zh-queries-22-12","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-zh-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (zh) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-zh-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-zh-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL ğŸŒğŸ™ŒğŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-zh-queries-22-12.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Chinese"],"keywords_longer_than_N":true},
	{"name":"wmt-mqm-human-evaluation","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RicardoRei/wmt-mqm-human-evaluation","creator_name":"Ricardo Costa Dias Rei","creator_url":"https://huggingface.co/RicardoRei","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains all MQM human annotations from previous WMT Metrics shared tasks and the MQM annotations from Experts, Errors, and Context.\\nThe data is organised into 8 columns:\\n\\nlp: language pair\\nsrc: input text\\nmt: translation\\nref: reference translation\\nscore: MQM score\\nsystem: MT Engine that produced the translation\\nannotators: number of annotators\\ndomain: domain of the input text (e.g. news)\\nyear: collection year\\n\\nYou can also find the original dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-mqm-human-evaluation.","first_N":5,"first_N_keywords":["English","German","Russian","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"wmt-sqm-human-evaluation","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RicardoRei/wmt-sqm-human-evaluation","creator_name":"Ricardo Costa Dias Rei","creator_url":"https://huggingface.co/RicardoRei","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn 2022, several changes were made to the annotation procedure used in the WMT Translation task. In contrast to the standard DA (sliding scale from 0-100) used in previous years, in 2022 annotators performed DA+SQM (Direct Assessment + Scalar Quality Metric). In DA+SQM, the annotators still provide a raw score between 0 and 100, but also are presented with seven labeled tick marks. DA+SQM helps to stabilize scores across annotators (as compared to DA).\\nThe dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-sqm-human-evaluation.","first_N":5,"first_N_keywords":["Czech","German","English","Croatian","Japanese"],"keywords_longer_than_N":true},
	{"name":"human_assistant_conversation","keyword":"chinese","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Isotonic/human_assistant_conversation","creator_name":"Isotonic","creator_url":"https://huggingface.co/Isotonic","description":"Isotonic/human_assistant_conversation dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","Spanish","Chinese","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"spanish-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Deysi/spanish-chinese","creator_name":"Caraballo","creator_url":"https://huggingface.co/Deysi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"spanish-chinese\\\"\\n\\t\\n\\nAll sensences extracted from the United Nations Parallel Corpus v1.0.\\nThe parallel corpus consists of manually translated United Nations documents for the six\\nofficial UN languages, Arabic, Chinese, English, French, Russian, and Spanish.\\nThe corpus is freely available for download at https://conferences.unite.un.org/UNCorpus\\nunder the terms of use outlined in the attached DISCLAIMER.\\nThe original individual documents are available at the Unitedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Deysi/spanish-chinese.","first_N":5,"first_N_keywords":["translation","Spanish","Chinese","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"spanish-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Deysi/spanish-chinese","creator_name":"Caraballo","creator_url":"https://huggingface.co/Deysi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"spanish-chinese\\\"\\n\\t\\n\\nAll sensences extracted from the United Nations Parallel Corpus v1.0.\\nThe parallel corpus consists of manually translated United Nations documents for the six\\nofficial UN languages, Arabic, Chinese, English, French, Russian, and Spanish.\\nThe corpus is freely available for download at https://conferences.unite.un.org/UNCorpus\\nunder the terms of use outlined in the attached DISCLAIMER.\\nThe original individual documents are available at the Unitedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Deysi/spanish-chinese.","first_N":5,"first_N_keywords":["translation","Spanish","Chinese","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"vegetable","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cc92yy3344/vegetable","creator_name":"é™ˆè¶…","creator_url":"https://huggingface.co/cc92yy3344","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè”¬èœå›¾åƒæ•°æ®é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tèƒŒæ™¯\\n\\t\\n\\næœ€åˆçš„å®éªŒæ˜¯ç”¨ä¸–ç•Œå„åœ°å‘ç°çš„15ç§å¸¸è§è”¬èœè¿›è¡Œçš„ã€‚å®éªŒé€‰æ‹©çš„è”¬èœæœ‰ï¼šè±†ç±»ã€è‹¦ç“œã€è‘«èŠ¦ã€èŒ„å­ã€è¥¿å…°èŠ±ã€å·å¿ƒèœã€è¾£æ¤’ã€èƒ¡èåœã€èŠ±æ¤°èœã€é»„ç“œã€æœ¨ç“œã€åœŸè±†ã€å—ç“œã€èåœå’Œç•ªèŒ„ã€‚å…±ä½¿ç”¨äº†æ¥è‡ª15ä¸ªç±»çš„21000å¼ å›¾åƒï¼Œå…¶ä¸­æ¯ä¸ªç±»åŒ…å«1400å¼ å°ºå¯¸ä¸º224Ã—224ã€æ ¼å¼ä¸º*.jpgçš„å›¾åƒã€‚æ•°æ®é›†ä¸­70%ç”¨äºåŸ¹è®­ï¼Œ15%ç”¨äºéªŒè¯ï¼Œ15%ç”¨äºæµ‹è¯•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç›®å½•\\n\\t\\n\\næ­¤æ•°æ®é›†åŒ…å«ä¸‰ä¸ªæ–‡ä»¶å¤¹ï¼š\\n\\ntrain (15000 å¼ å›¾åƒ)\\ntest (3000 å¼ å›¾åƒ)\\nvalidation (3000 å¼ å›¾åƒ)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®æ”¶é›†\\n\\t\\n\\nè¿™ä¸ªæ•°æ®é›†ä¸­çš„å›¾åƒæ˜¯æˆ‘ä»¬ä¸ºä¸€ä¸ªé¡¹ç›®ä»è”¬èœå†œåœºå’Œå¸‚åœºæ”¶é›†çš„ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tåˆ¶ä½œå…ƒæ•°æ®æ–‡ä»¶\\n\\t\\n\\nè¿è¡Œä¸‹é¢pythonçš„ä»£ç ï¼Œå°±å¯ä»¥åœ¨æ¡Œé¢ç”Ÿæˆä¸‰ä¸ªcsvæ ¼å¼çš„å…ƒæ•°æ®æ–‡ä»¶ã€ä¸€ä¸ªåˆ†ç±»æ•°æ®æ–‡ä»¶ï¼ˆéœ€è¦æ”¾å…¥åˆ°æ•°æ®æ–‡ä»¶ä¸­ï¼‰\\n#!/usr/bin/env python3\\n# -*- coding: utf-8 -*-\\n\\n\\\"\\\"\\n1.ä¸‹è½½çš„æ•°æ®æ–‡ä»¶ Vegetableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cc92yy3344/vegetable.","first_N":5,"first_N_keywords":["image-classification","multi-class-image-classification","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"multiturn_chat_0.8M","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M","creator_name":"BELLE Group // Be Everyone's Large Language model Engine","creator_url":"https://huggingface.co/BelleGroup","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultiturn Chat 0.8M\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå†…å®¹\\n\\t\\n\\nåŒ…å«çº¦80ä¸‡æ¡ç”±BELLEé¡¹ç›®ç”Ÿæˆçš„ç”¨æˆ·ä¸åŠ©æ‰‹çš„å¤šè½®å¯¹è¯ã€‚\\næ³¨æ„ï¼šæ­¤æ•°æ®é›†æ˜¯ç”±ChatGPTäº§ç”Ÿçš„ï¼Œæœªç»è¿‡ä¸¥æ ¼æ ¡éªŒï¼Œå†…å®¹å¯èƒ½åŒ…å«é”™è¯¯ã€‚ä½¿ç”¨è¿‡ç¨‹ä¸­è¯·æ³¨æ„è¿™ä¸€ç‚¹ã€‚\\ninstructionä¸­åŒ…å«å¤šè½®å¯¹è¯çš„ä¸Šæ–‡å†…å®¹ï¼Œä»¥Human:å’ŒAssistant:åŒºåˆ†ï¼Œoutputä¸­åŒ…å«å½“å‰åŠ©æ‰‹è§’è‰²çš„å›ç­”ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ ·ä¾‹\\n\\t\\n\\n{\\n  \\\"instruction\\\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M.","first_N":5,"first_N_keywords":["text2text-generation","Chinese","gpl-3.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"multilingual-share","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cryscan/multilingual-share","creator_name":"Zhenyuan Zhang","creator_url":"https://huggingface.co/cryscan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Share GPT\\n\\t\\n\\nMultilingual Share GPT, the free multi-language corpus for LLM training. All text are converted to markdown format, and classified by languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGithub Repo\\n\\t\\n\\nFollow the link here to Github.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Example\\n\\t\\n\\n{\\n    \\\"id\\\": \\\"ImiMfCY\\\",\\n    \\\"lang\\\": \\\"en\\\",\\n    \\\"text\\\": \\\"\\\\n<|user|>: Let's play chess\\\\n\\\\n<|bot|>: Sure, I'd love to play chess with you! Do you want to play a virtual game or just ask chess-related questions?\\\\n\\\\n<|user|>: Virtualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cryscan/multilingual-share.","first_N":5,"first_N_keywords":["English","Chinese","cc0-1.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"CNNovel125K","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RyokoAI/CNNovel125K","creator_name":"Ryoko AI","creator_url":"https://huggingface.co/RyokoAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CNNovel125K\\n\\t\\n\\nThe BigKnow2022 dataset and its subsets are not yet complete. Not all information here may be accurate or accessible.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCNNovel125K is a dataset composed of approximately 125,000 novels downloaded from the Chinese novel hosting site http://ibiquw.com.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is primarily intended for unsupervised training of text generation models; however, it may be useful for otherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RyokoAI/CNNovel125K.","first_N":5,"first_N_keywords":["text-classification","text-generation","Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"LIHKG","keyword":"yue chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlienKevin/LIHKG","creator_name":"Xiang (Kevin) Li","creator_url":"https://huggingface.co/AlienKevin","description":"Scraped conversations of the LIHKG forum. Content scraped by Ayaka: https://github.com/ayaka14732/lihkg-scraper\\n","first_N":5,"first_N_keywords":["Yue Chinese","mit","1M<n<10M","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"WikiMatrix-v1-Ja_Zh-filtered","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/larryvrh/WikiMatrix-v1-Ja_Zh-filtered","creator_name":"larryvrh","creator_url":"https://huggingface.co/larryvrh","description":"Filtered and modified version of Japanese/Chinese language pair data from WikiMatrix v1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProcess steps:\\n1. Basic regex based filtering / length checking to remove abnormal pairs.\\n2. Semantic similarity filtering with a threshold value of 0.6, based on sentence-transformers/LaBSE.\\n3. Convert all Traditional Chinese sentences into Simplified Chinese with zhconv.\\n\\t\\n\\nç»è¿‡è¿‡æ»¤å’Œä¿®æ”¹çš„æ—¥è¯­/ä¸­æ–‡è¯­è¨€å¯¹æ•°æ®ï¼Œæ¥è‡ªWikiMatrix v1ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå¤„ç†æ­¥éª¤ï¼š\\n1. åŸºæœ¬çš„åŸºäºæ­£åˆ™è¡¨è¾¾å¼çš„è¿‡æ»¤/é•¿åº¦æ£€æŸ¥ï¼Œä»¥åˆ é™¤å¼‚å¸¸å¯¹ã€‚\\n2.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/larryvrh/WikiMatrix-v1-Ja_Zh-filtered.","first_N":5,"first_N_keywords":["translation","Japanese","Chinese","cc-by-sa-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"generated_chat_0.4M","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M","creator_name":"BELLE Group // Be Everyone's Large Language model Engine","creator_url":"https://huggingface.co/BelleGroup","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGenerated_Chat_0.4M\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå†…å®¹\\n\\t\\n\\nåŒ…å«çº¦40ä¸‡æ¡ç”±BELLEé¡¹ç›®ç”Ÿæˆçš„ä¸ªæ€§åŒ–è§’è‰²å¯¹è¯æ•°æ®ï¼ŒåŒ…å«è§’è‰²ä»‹ç»ã€‚\\næ³¨æ„ï¼šæ­¤æ•°æ®é›†æ˜¯ç”±ChatGPTäº§ç”Ÿçš„ï¼Œæœªç»è¿‡ä¸¥æ ¼æ ¡éªŒï¼Œé¢˜ç›®æˆ–è§£é¢˜è¿‡ç¨‹å¯èƒ½åŒ…å«é”™è¯¯ã€‚ä½¿ç”¨è¿‡ç¨‹ä¸­è¯·æ³¨æ„è¿™ä¸€ç‚¹ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ ·ä¾‹\\n\\t\\n\\n{\\n  \\\"instruction\\\": \\\"äºä»¥ä¸‹è§’è‰²ä¿¡æ¯å®Œæˆä¸€æ®µå¯¹è¯\\\\nAliceæ˜¯ä¸€ä¸ªå¹´è½»çš„å¾‹å¸ˆï¼Œå¥¹æ­£åœ¨ä¸ºä¸€ä¸ªæ¶‰åŠæ¿’å±ç‰©ç§ä¿æŠ¤çš„æ¡ˆä»¶åšå‡†å¤‡ã€‚Bobæ˜¯ä¸€ä½å½“åœ°çš„å±…æ°‘ï¼Œä»–æ‰€åœ¨çš„ç¤¾åŒºç»å¸¸å—åˆ°è¯¥æ¿’å±ç‰©ç§çš„å¹²æ‰°ã€‚\\\\n\\\",\\n  \\\"input\\\": \\\",\\n  \\\"output\\\": \\\"\\\\nAlice: ä½ å¥½Bobï¼Œæˆ‘æ˜¯æ¿’å±ç‰©ç§ä¿æŠ¤æ¡ˆçš„å¾‹å¸ˆï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ã€‚æˆ‘ä»¬å‰å‡ å¤©å‘ç»™ä½ çš„æ–‡ä»¶ä½ çœ‹åˆ°äº†å—ï¼Ÿ\\\\nBob: çœ‹åˆ°äº†ï¼Œä½ ä»¬è¯´è¦ç¦æ­¢æˆ‘ä»¬åœ¨è¯¥ç‰©ç§çš„å¸¸ä½åœ°é‡‡é›†è˜‘è‡ï¼Œè¿™å¾ˆä¸å…¬å¹³ã€‚\\\\nAlice: ä¿æŠ¤æ¿’å±ç‰©ç§å¯¹æ•´ä¸ªç”Ÿæ€ç³»ç»Ÿéƒ½å¾ˆé‡è¦ï¼Œå¦‚æœæˆ‘ä»¬çš„ä¸¾åŠ¨æŸå®³äº†è¿™ä¸ªç‰©ç§çš„ç”Ÿå­˜ï¼Œé‚£ä¹ˆæ•´ä¸ªç”Ÿæ€ç³»ç»Ÿéƒ½å°†é­å—æŸå¤±ã€‚\\\\nBob:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M.","first_N":5,"first_N_keywords":["text2text-generation","Chinese","gpl-3.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"K-SportsSum-BetterMapped-CN","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CCCP-Admiral/K-SportsSum-BetterMapped-CN","creator_name":"Lai Wen Xiao","creator_url":"https://huggingface.co/CCCP-Admiral","description":"ä¸€ä¸ªæ¥è‡ªK-SportsSumï¼šhttps://github.com/krystalan/k-sportssum çš„å®ç°ï¼ŒåŸä½œè€…ç»™å‡ºäº†æ€è·¯ï¼Œä½†å¹¶æœªå®ç°å…¶å…·ä½“è¿‡ç¨‹ï¼Œæ­¤æ•°æ®é›†æ˜¯å¯¹è¯¥æ•°æ®é›†â€œæ–°é—»ä¸è¯„è®ºå¥å­æ ¹æ®ç›¸ä¼¼åº¦æ­é…â€éƒ¨åˆ†çš„å®ç°ã€‚\\næ–¹æ³•æ˜¯ï¼šéå†æ–°é—»å¥å­ï¼Œä»¥ç±»ä¼¼æŒ‡é’ˆçš„æ–¹å¼è·å–æ–°é—»å¥å­çš„æ—¶é—´ä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ï¼Œç„¶åå°†æ¯ä¸¤ä¸ªæŒ‡é’ˆä½œä¸ºä¸€ä¸ªèŒƒå›´ï¼Œå°†èŒƒå›´å†…çš„æ–°é—»å¥éå†æŸ¥æ‰¾ï¼Œé€‰æ‹©æœ€ç›¸ä¼¼çš„å¥å­ï¼Œå¹¶åˆ é™¤è¯¥å¥ä»¥é˜²æ­¢é‡å¤ï¼Œæœ€ç»ˆè·å¾—ä¸€å¥æ–°é—»æ­é…ä¸€å¥è¯„è®ºçš„ç»“æœã€‚\\næˆ‘ä½¿ç”¨äº†bertâ€”Scoreå’ŒROUGEæŒ‡æ ‡ï¼ŒæŒ‰ç…§7:3åŠ æƒè®¡ç®—åˆ†æ•°ã€‚\\nå»ºè®® æ•°æ®é›†å†…ç»™å‡ºäº†è¯¥æ­é…çš„æŒ‡æ ‡ï¼Œè¯·è€ƒè™‘ä½¿ç”¨å¹³å‡æ•°ç­‰æ–¹å¼è¿‡æ»¤æ‰è¾ƒä½çš„åæ­é…ã€‚\\nAn implementation from K-SportsSum: https://github.com/krystalan/k-sportssum was used to implement the \\\"news and comment sentences paired based on similarity\\\" section of the dataset. The original authorâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CCCP-Admiral/K-SportsSum-BetterMapped-CN.","first_N":5,"first_N_keywords":["summarization","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"human_assistant_conversation_deduped","keyword":"chinese","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Isotonic/human_assistant_conversation_deduped","creator_name":"Isotonic","creator_url":"https://huggingface.co/Isotonic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDeduplicated version of Isotonic/human_assistant_conversation\\n\\t\\n\\n\\nDeduped with max jaccard similarity of 0.75\\n\\n","first_N":5,"first_N_keywords":["text-generation","English","Spanish","Chinese","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"Safety-Prompts","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thu-coai/Safety-Prompts","creator_name":"Conversational AI (CoAI) group from Tsinghua University","creator_url":"https://huggingface.co/thu-coai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nGitHub Repository: https://github.com/thu-coai/Safety-Prompts\\nPaper: https://arxiv.org/abs/2304.10436\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100K<n<1M","arxiv:2304.10436"],"keywords_longer_than_N":true},
	{"name":"ChineseSTS","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tiansz/ChineseSTS","creator_name":"Shaotian Zhang","creator_url":"https://huggingface.co/tiansz","description":"è¿™æ˜¯ä¸€ä¸ªä¸­æ–‡æ–‡æœ¬ç›¸ä¼¼åº¦çš„æ•°æ®é›†ï¼Œç›¸ä¼¼åº¦åˆ’åˆ†ä¸º 0ã€1ã€‚\\nè¯¥ notebook è®°å½•äº†æˆ‘ä½¿ç”¨æœ¬æ•°æ®é›†çš„å…¨è¿‡ç¨‹ã€‚åŒæ—¶ä½ ä¹Ÿå¯ä»¥åœ¨ github ä¸Šä¸‹è½½è¯¥æ•°æ®é›†\\n","first_N":5,"first_N_keywords":["sentence-similarity","Chinese","apache-2.0","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"fall-detection","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DeZan/fall-detection","creator_name":"HuangDeZan(é»„å¾·æ”’)","creator_url":"https://huggingface.co/DeZan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWelcome to my page!\\n\\t\\n\\nthis is a fall-detection datasets,you can download to use it to do anything!\\n","first_N":5,"first_N_keywords":["Chinese","mit","< 1K","text","Image"],"keywords_longer_than_N":true},
	{"name":"dolly-15k-cn","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaja7744/dolly-15k-cn","creator_name":"wjaja","creator_url":"https://huggingface.co/jaja7744","description":"jaja7744/dolly-15k-cn dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"tokenizers_example_zh_en","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TurboPascal/tokenizers_example_zh_en","creator_name":"Turbo Pascal","creator_url":"https://huggingface.co/TurboPascal","description":"ç”¨äºè®­ç»ƒåˆ†è¯å™¨çš„åŸºç¡€æ–‡æœ¬\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"IdaDB","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/IdaLee/IdaDB","creator_name":"IdaLee","creator_url":"https://huggingface.co/IdaLee","description":"IdaLee/IdaDB dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Chinese","mit","ğŸ‡ºğŸ‡¸ Region: US","finance"],"keywords_longer_than_N":false},
	{"name":"Ziya-Eval-Chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IDEA-CCNL/Ziya-Eval-Chinese","creator_name":"Fengshenbang-LM","creator_url":"https://huggingface.co/IDEA-CCNL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå§œå­ç‰™ä¸­æ–‡è¯„ä¼°æ•°æ®é›† Ziya-Eval-Chinese\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®ä»‹ç» Dataset Summary\\n\\t\\n\\nç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹çš„ä¸­æ–‡èƒ½åŠ›\\nThis IDEA-CCNL/Ziya-Eval-Chinese dataset is designed to evaluate the ability of LLM in chinese.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€ Languages\\n\\t\\n\\nä¸­æ–‡\\nChinese\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®ç¤ºä¾‹ Data Instances\\n\\t\\n\\n{\\\"class\\\":\\\"é—®ç­”\\\", \\\"type\\\":\\\"çŒœè°œ\\\", \\\"query\\\":\\\"åŒå–œä¸´é—¨ï¼Œæ‰“ä¸€ä¸­å›½åœ°å\\\"}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®å­—æ®µ Data Fields\\n\\t\\n\\n\\nclass: str\\ntype: str\\nquery: str\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå¼•ç”¨ Citation\\n\\t\\n\\n@article{fengshenbang,\\n  author    = {Jiaxing Zhang and Ruyi Gan and Junjie Wang andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IDEA-CCNL/Ziya-Eval-Chinese.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"kdconv","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thu-coai/kdconv","creator_name":"Conversational AI (CoAI) group from Tsinghua University","creator_url":"https://huggingface.co/thu-coai","description":"The KDConv dataset. GitHub repo. Original paper.\\n@inproceedings{zhou-etal-2020-kdconv,\\n    title = \\\"{K}d{C}onv: A {C}hinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation\\\",\\n    author = \\\"Zhou, Hao  and\\n      Zheng, Chujie  and\\n      Huang, Kaili  and\\n      Huang, Minlie  and\\n      Zhu, Xiaoyan\\\",\\n    booktitle = \\\"ACL\\\",\\n    year = \\\"2020\\\"\\n}\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"cold","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thu-coai/cold","creator_name":"Conversational AI (CoAI) group from Tsinghua University","creator_url":"https://huggingface.co/thu-coai","description":"The COLD dataset. GitHub repo. Original paper.\\n@inproceedings{deng-etal-2022-cold,\\n    title = \\\"{COLD}: A Benchmark for {C}hinese Offensive Language Detection\\\",\\n    author = \\\"Deng, Jiawen  and\\n      Zhou, Jingyan  and\\n      Sun, Hao  and\\n      Zheng, Chujie  and\\n      Mi, Fei  and\\n      Meng, Helen  and\\n      Huang, Minlie\\\",\\n    booktitle = \\\"EMNLP\\\",\\n    year = \\\"2022\\\"\\n}\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","arxiv:2201.06025","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"ja-zh-twitter-translate","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Nekofox/ja-zh-twitter-translate","creator_name":"Huang","creator_url":"https://huggingface.co/Nekofox","description":"translate by @Nekofoxtweet (me)\\ntwitter source from @RindouMikoto\\n","first_N":5,"first_N_keywords":["translation","Chinese","Japanese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Vanilla-chinese-alpaca-luotuo","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/Vanilla-chinese-alpaca-luotuo","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"Vanillaéª†é©¼æ˜¯éª†é©¼é¡¹ç›®åœ¨23å¹´3æœˆ21æ—¥å¯åŠ¨çš„ç¬¬ä¸€ä¸ªæ•°æ®é›†å’Œæ¨¡å‹\\næˆ‘ä»¬ä¼šé™†ç»­å°†æ›´å¤šæ•°æ®é›†å‘å¸ƒåˆ°hfï¼ŒåŒ…æ‹¬\\n\\n Coco Captionçš„ä¸­æ–‡ç¿»è¯‘\\n CoQAçš„ä¸­æ–‡ç¿»è¯‘\\n CNewSumçš„Embeddingæ•°æ®\\n å¢å¹¿çš„å¼€æ”¾QAæ•°æ®\\n WizardLMçš„ä¸­æ–‡ç¿»è¯‘\\n\\nå¦‚æœä½ ä¹Ÿåœ¨åšè¿™äº›æ•°æ®é›†çš„ç­¹å¤‡ï¼Œæ¬¢è¿æ¥è”ç³»æˆ‘ä»¬ï¼Œé¿å…é‡å¤èŠ±é’±ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\téª†é©¼(Luotuo): å¼€æºä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹\\n\\t\\n\\nhttps://github.com/LC1332/Luotuo-Chinese-LLM\\néª†é©¼(Luotuo)é¡¹ç›®æ˜¯ç”±å†·å­æ˜‚ @ å•†æ±¤ç§‘æŠ€, é™ˆå¯æº @ åä¸­å¸ˆèŒƒå¤§å­¦ ä»¥åŠ æé²é² @ å•†æ±¤ç§‘æŠ€ å‘èµ·çš„ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹å¼€æºé¡¹ç›®ï¼ŒåŒ…å«äº†ä¸€ç³»åˆ—è¯­è¨€æ¨¡å‹ã€‚\\n( æ³¨æ„: é™ˆå¯æº æ­£åœ¨å¯»æ‰¾2024æ¨å…å¯¼å¸ˆï¼Œæ¬¢è¿è”ç³» )\\néª†é©¼é¡¹ç›®ä¸æ˜¯å•†æ±¤ç§‘æŠ€çš„å®˜æ–¹äº§å“ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{alpaca,\\n  author={Ziang Lengâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/silk-road/Vanilla-chinese-alpaca-luotuo.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K<n<100K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"huatuo_consultation_qa","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/huatuo_consultation_qa","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for huatuo_consultation_qa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWe collected data from a website for medical consultation , consisting of many online consultation records by medical experts. Each record is a QA pair: a patient raises a question and a medical doctor answers the question. The basic information of doctors (including name, hospital organization, and department) was recorded.\\nWe directly crawl patientâ€™s questions and doctorâ€™s answers as QA pairs, getting 32â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/huatuo_consultation_qa.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10M - 100M","json"],"keywords_longer_than_N":true},
	{"name":"lunyu","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TMZN/lunyu","creator_name":"tmzncty","creator_url":"https://huggingface.co/TMZN","description":"ä¸ºhttps://huggingface.co/TMZN/ChatGLM-wyw  æœåŠ¡çš„æ•°æ®é›†ä¹‹ä¸€ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChatGLM-wyw\\n\\t\\n\\nä¸€ä¸ªè¯»äº†æ–‡è¨€æ–‡çš„ChatGLM\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç¼˜èµ·\\n\\t\\n\\n2023å¹´5æœˆ16æ—¥ï¼Œå¿µå¨äº†å¥½ä¹…è¦è®©AIè¯»æ–‡è¨€æ–‡æ­£å¼å¼€å·¥ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ„Ÿè°¢\\n\\t\\n\\nä¸€ç«™å¼æ•´åˆåŒ…ï¼ˆå«chatglmæ¨¡å‹ï¼‰ï¼šé“¾æ¥ï¼šhttps://pan.baidu.com/s/13GePNuh8ZP_DkMVRf5sHqw?pwd=2d2z \\nä¸€ç«™å¼æ•´åˆåŒ…ï¼ˆä¸å«æ¨¡å‹ï¼‰ï¼šé“¾æ¥ï¼šhttps://pan.baidu.com/s/1lMfG34jerHO7aFjfdKTGUw?pwd=6y7j\\næ•°æ®é›†åˆ¶ä½œå¤§ä½¬é“¾æ¥ï¼šhttps://github.com/huang1332/finetune_dataset_maker\\næ¨¡å‹å¾®è°ƒå¤§ä½¬é“¾æ¥ï¼šhttps://github.com/mymusise/ChatGLM-Tuning\\nChatGLMå®˜æ–¹é“¾æ¥ï¼šhttps://github.com/THUDM/ChatGLM-6B\\n","first_N":5,"first_N_keywords":["question-answering","Chinese","gpl-3.0","1K<n<10K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"ShareGPT-Processed","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zetavg/ShareGPT-Processed","creator_name":"Pokai Chang","creator_url":"https://huggingface.co/zetavg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShareGPT-Processed\\n\\t\\n\\nThe RyokoAI/ShareGPT52K dataset, converted to Markdown and labeled with the language used.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgements\\n\\t\\n\\n\\nvinta/pangu.js â€” To insert whitespace between CJK (Chinese, Japanese, Korean) and half-width characters (alphabetical letters, numerical digits and symbols).\\nmatthewwithanm/python-markdownify â€” Provides a starting point to convert HTML to Markdown.\\nBYVoid/OpenCC â€” Conversions between Traditional Chinese and Simplified Chinese.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zetavg/ShareGPT-Processed.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","Spanish","Japanese"],"keywords_longer_than_N":true},
	{"name":"xOA22","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sambanovasystems/xOA22","creator_name":"SambaNova Systems","creator_url":"https://huggingface.co/sambanovasystems","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xOA22 - Multilingual Prompts from OpenAssistant\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nxOA22 consists of 22 prompts originally shown in Appendix E, page 25 of the OpenAssistant Conversations paper. These 22 prompts were then manually translated by volunteers into 5 languages: Arabic, Simplified Chinese, French, Hindi and Spanish. \\nThese prompts were originally created for human evaluations of the multilingual abilities of BLOOMChat. Since not all prompts could beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sambanovasystems/xOA22.","first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Hindi"],"keywords_longer_than_N":true},
	{"name":"x-self-instruct-seed-32","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sambanovasystems/x-self-instruct-seed-32","creator_name":"SambaNova Systems","creator_url":"https://huggingface.co/sambanovasystems","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xOA22 - Multilingual Prompts from OpenAssistant\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nx-self-instruct-seed-32 consists of 32 prompts chosen out of the 252 prompts in the self-instruct-seed dataset from the Self-Instruct paper. These 32 prompts were filtered out according to the following criteria:\\n\\nShould be natural in a chat setting\\nTherefore, we filter out any prompts with \\\"few-shot examples\\\", as these are all instruction prompts that we consider unnatural in a chatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sambanovasystems/x-self-instruct-seed-32.","first_N":5,"first_N_keywords":["Arabic","Spanish","English","Hindi","French"],"keywords_longer_than_N":true},
	{"name":"TGEA2.0","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jerma66/TGEA2.0","creator_name":"vinsmoke","creator_url":"https://huggingface.co/jerma66","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn order to diagnostically analyze and improve the capability of pretrained language models (PLMs) in text generation, we propose TGEA 2.0, to date the largest dataset built on machine-authored texts by PLMs with fine-grained semantic annotations on a wide variety of pathological generation errors. We collect 170K nominal, phrasal and sentential prompts from 6M natural sentences in 3 domains. These prompts are fed intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jerma66/TGEA2.0.","first_N":5,"first_N_keywords":["Sardinian","Chamorro","Chinese","cc-by-4.0","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"invig","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jxu124/invig","creator_name":"Jie Xu","creator_url":"https://huggingface.co/jxu124","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"invig\\\"\\n\\t\\n\\nGithub\\n@misc{invigdataset,\\n    title={InViG: Interactive Visual-Language Disambiguation with 21K Human-to-Human Dialogues},\\n    author={Zhang, Hanbo and Mo, Yuchen and Xu, Jie and Si, Qingyi and Kong, Tao},\\n    howpublished = {\\\\url{https://github.com/ZhangHanbo/invig-dataset}},\\n    year={2023}\\n}\\n\\n","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"rsd-ists-2016","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016","creator_name":"University of Zurich, Department of Computational Linguistics","creator_url":"https://huggingface.co/ZurichNLP","description":"Training and test data for the task of Recognizing Semantic Differences (RSD).\\nSee the paper for details on how the dataset was created, and see our code at https://github.com/ZurichNLP/recognizing-semantic-differences for an example of how to use the data for evaluation.\\nThe data are derived from the SemEval-2016 Task 2 for Interpretable Semantic Textual Similarity organized by Agirre et al. (2016).\\nThe original URLs of the data are:\\n\\nTrain:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016.","first_N":5,"first_N_keywords":["token-classification","machine-generated","English","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"detect","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GeorgeGuo/detect","creator_name":"guo xiaojie","creator_url":"https://huggingface.co/GeorgeGuo","description":"This is dataset for test\\n","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"RefGPT-Code-ds","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mutonix/RefGPT-Code-ds","creator_name":"Dongjie Yang","creator_url":"https://huggingface.co/Mutonix","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RefGPT-Code-ds\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n  [Paper] RefGPT  | \\n   [Github] RefGPT\\n\\n\\nRefGPT-Code is a dataset containing 76k multi-turn dialogues about programming with 37k English and 39k Chinese, which has covered most aspects of code usage scenarios and multiple types of programming languages. Both the English version and Chinese version use the public GitHub dataset on Google BiqQuery with no overlap in these two languages. RefGPT-Code has derivedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mutonix/RefGPT-Code-ds.","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"RefGPT-Code-cr","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mutonix/RefGPT-Code-cr","creator_name":"Dongjie Yang","creator_url":"https://huggingface.co/Mutonix","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RefGPT-Code-cr\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n  [Paper] RefGPT  | \\n   [Github] RefGPT\\n\\n\\nRefGPT-Code is a dataset containing 76k multi-turn dialogues about programming with 37k English and 39k Chinese, which has covered most aspects of code usage scenarios and multiple types of programming languages. Both the English version and Chinese version use the public GitHub dataset on Google BiqQuery with no overlap in these two languages. RefGPT-Code has derivedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mutonix/RefGPT-Code-cr.","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"RefGPT-Code-bg","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mutonix/RefGPT-Code-bg","creator_name":"Dongjie Yang","creator_url":"https://huggingface.co/Mutonix","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RefGPT-Code-bg\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n  [Paper] RefGPT  | \\n   [Github] RefGPT\\n\\n\\nRefGPT-Code is a dataset containing 76k multi-turn dialogues about programming with 37k English and 39k Chinese, which has covered most aspects of code usage scenarios and multiple types of programming languages. Both the English version and Chinese version use the public GitHub dataset on Google BiqQuery with no overlap in these two languages. RefGPT-Code has derivedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mutonix/RefGPT-Code-bg.","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"RefGPT-Fact","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mutonix/RefGPT-Fact","creator_name":"Dongjie Yang","creator_url":"https://huggingface.co/Mutonix","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RefGPT-Fact\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n  [Paper] RefGPT  | \\n   [Github] RefGPT\\n\\nRefGPT-Fact is a datasets containing 100k multi-turn dialogues about factual knowledge with 50k English and 50k Chinese. The English version uses the English Wikipedia as the reference and the Chinese version uses the frequently-used Chinese online encyclopedia website, Baidu Baike.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nChatbot instruction finetuningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mutonix/RefGPT-Fact.","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"wikipedia-zh-mnbvc","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanng/wikipedia-zh-mnbvc","creator_name":"wangjunjie","creator_url":"https://huggingface.co/wanng","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tzhwiki-mnbvc\\n\\t\\n\\nåˆ†é¡¹ç›®ï¼šçˆ¬å–å¹¶å¤„ç†ä¸­æ–‡ç»´åŸºç™¾ç§‘è¯­æ–™\\næ•°æ®æ—¶é—´ï¼š202302-202305 ï¼ˆæŒç»­æ›´æ–°ï¼‰\\nä¸»é¡¹ç›®ï¼šMNBVC(Massive Never-ending BT Vast Chinese corpus)è¶…å¤§è§„æ¨¡ä¸­æ–‡è¯­æ–™é›† https://github.com/esbatmop/MNBVC\\nè¯¥é¡¹ç›®æ¸…æ´—æµç¨‹ä¸»è¦å‚è€ƒï¼šhttps://kexue.fm/archives/4176/comment-page-1\\nå¹¶ä¸”ä½¿ç”¨ç»„å‘˜å¼€å‘çš„å»é‡å·¥å…·è¿›è¡Œæ•°æ®æ ¼å¼åŒ–ã€‚\\næ€»è¡Œæ•°ï¼ˆæ ·æœ¬ï¼‰: 10,754,146\\nä¸€ä¸ªç¤ºä¾‹ï¼š\\n{\\n  \\\"æ–‡ä»¶å\\\": \\\"cleaned/zhwiki-20230420/folder_0/723712.txt\\\",\\n  \\\"æ˜¯å¦å¾…æŸ¥æ–‡ä»¶\\\": false,\\n  \\\"æ˜¯å¦é‡å¤æ–‡ä»¶\\\": false,\\n  \\\"æ–‡ä»¶å¤§å°\\\": 558,\\n  \\\"simhash\\\": 14363740497821204542,\\n  \\\"æœ€é•¿æ®µè½é•¿åº¦\\\": 142,\\n  \\\"æ®µè½æ•°\\\": 6,\\n  \\\"å»é‡æ®µè½æ•°\\\": 6,\\n  \\\"ä½è´¨é‡æ®µè½æ•°\\\": 0,\\n  \\\"æ®µè½\\\": [\\n    {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/wanng/wikipedia-zh-mnbvc.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"dev_pretrain","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/dev_pretrain","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"dev_pretrain\\\"\\n\\t\\n\\nTigerbotæ¨¡å‹develop pretrainæ•°æ®ã€‚\\nåœ¨train_clm.pyä¸­è¢«ä½¿ç”¨ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\n\\nds_sft = datasets.load_dataset('TigerResearch/dev_pretrain')\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tField\\n\\t\\n\\n\\ncontent: è¯­æ–™\\n\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"dev_sft","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/dev_sft","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"dev_sft\\\"\\n\\t\\n\\nTigerbotæ¨¡å‹develop sftæ•°æ®ã€‚\\nåœ¨train_sft.pyä¸­è¢«ä½¿ç”¨ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\n\\nds_sft = datasets.load_dataset('TigerResearch/dev_sft')\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tField\\n\\t\\n\\n\\ninstruction: æŒ‡ä»¤\\ninput: ä¸Šä¸‹æ–‡ä¿¡æ¯(Optional)\\noutput: ç”Ÿæˆç›®æ ‡\\n\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"tigerbot-alpaca-zh-0.5m","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/tigerbot-alpaca-zh-0.5m","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"Tigerbot è‡ªæœ‰åŸºäºalpacaç”Ÿæˆä¸­æ–‡é—®ç­”å¯¹\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/tigerbot-alpaca-zh-0.5m')\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"tigerbot-zhihu-zh-10k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/tigerbot-zhihu-zh-10k","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"Tigerbot åŸºäºå¼€æºæœé›†çš„çŸ¥ä¹æ•°æ®ç”Ÿæˆçš„sfté—®ç­”å¯¹\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/tigerbot-zhihu-zh-10k')\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"tigerbot-wiki-qa-zh-1k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/tigerbot-wiki-qa-zh-1k","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"Tigerbot è‡ªæœ‰ä¸­æ–‡ç™¾ç§‘é—®ç­”\\tæ•°æ®ã€‚\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/tigerbot-wiki-qa-zh-1k')\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"tigerbot-earning-plugin","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/tigerbot-earning-plugin","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"Tigerbot æ¨¡å‹rethinkæ—¶ä½¿ç”¨çš„å¤–è„‘åŸå§‹æ•°æ®ï¼Œè´¢æŠ¥ç±»\\n\\nå…±2500ç¯‡è´¢æŠ¥ï¼ŒæŠ½å–åæŒ‰æ®µè½ä¿å­˜\\nå‘å¸ƒæ—¶é—´åŒºé—´ä¸º: 2022-02-28 è‡³ 2023-05-10\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/tigerbot-earning-plugin')\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"tigerbot-research-plugin","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/tigerbot-research-plugin","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"Tigerbot æ¨¡å‹rethinkæ—¶ä½¿ç”¨çš„å¤–è„‘åŸå§‹æ•°æ®ï¼Œç ”æŠ¥ç±»\\n\\nå…±2Wç¯‡å®Œæ•´ç ”æŠ¥ï¼ŒæŒ‰æ®µè½ä¿å­˜\\n\\nå‘å¸ƒæ—¶é—´åŒºé—´: 2022-09-30 è‡³ 2023-05-19\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/tigerbot-research-plugin')\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"langchain-MRKL-finetune","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PengQu/langchain-MRKL-finetune","creator_name":"Qu Peng","creator_url":"https://huggingface.co/PengQu","description":"PengQu/langchain-MRKL-finetune dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Ziya-Visual-Eval-Chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IDEA-CCNL/Ziya-Visual-Eval-Chinese","creator_name":"Fengshenbang-LM","creator_url":"https://huggingface.co/IDEA-CCNL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå§œå­ç‰™-Visualä¸­æ–‡è¯„ä¼°æ•°æ®é›† Ziya-Visual-Eval-Chinese\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®ä»‹ç» Dataset Summary\\n\\t\\n\\næ•°æ®é›†ç”±LLaVAè¯„ä¼°é›†ç¿»è¯‘è€Œæ¥ï¼Œå›¾ç‰‡æºæ¥è‡ªcocoæ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°å¤šæ¨¡æ€å¤§æ¨¡å‹çš„ä¸­æ–‡èƒ½åŠ›\\nDataset translated from the LLaVA evaluation set, image source from the coco dataset, used to evaluate the Chinese language capabilities of the multimodal large model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€ Languages\\n\\t\\n\\nä¸­æ–‡\\nChinese\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®ç¤ºä¾‹ Data Instances\\n\\t\\n\\n{\\\"question_id\\\": 0, \\\"image\\\": \\\"000000441147.jpg\\\", \\\"text\\\": \\\"å›¾ç‰‡ä¸­ä¸¤ä¸ªæ‰‹æç®±çš„é¢œè‰²æ˜¯ä»€ä¹ˆï¼Ÿ\\\", \\\"category\\\": \\\"conv\\\"}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®å­—æ®µâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IDEA-CCNL/Ziya-Visual-Eval-Chinese.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Movie-Title-Post","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/snzhang/Movie-Title-Post","creator_name":"Sinian Zhang","creator_url":"https://huggingface.co/snzhang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset currently contains 5043  movie posts and their corresponding Chinese title which are collected from IMDb and Douban by crawler. \\nIn the future, we will add more data to it.\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100M<n<1B","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"sft_zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/sft_zh","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"Tigerbot å¼€æºé¡¹ç›®ä¸­å¾®è°ƒä¸­æ–‡sft-zhæ•°æ®åˆé›†\\næœ¬åˆé›†æ¶µç›–æœ¬ç»„ç»‡ä¸‹å¼€æºçš„å…¶ä»–ä¸­æ–‡sft-ä¸­æ–‡-æ•°æ®é›†ï¼Œä¸éœ€è¦é‡å¤ä¸‹è½½\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/sft_zh')\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ–‡ä»¶ç»†åˆ†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nç±»å‹\\nè¯­è¨€\\næ•°æ®é›†æ–‡ä»¶\\næ•°é‡\\n\\n\\n\\t\\t\\nalpaca ä¸­æ–‡\\nä¸­æ–‡\\ntigerbot-alpaca-zh-0.5m\\n0.5m\\n\\n\\nç™¾ç§‘é—®ç­”\\nä¸­æ–‡\\ntigerbot-wiki-qa-1k\\n1k\\n\\n\\nåè‘—é—®ç­”\\nä¸­æ–‡\\ntigerbot-book-qa-1k\\n1k\\n\\n\\nçŒœè°œè¯­\\nä¸­æ–‡\\ntigerbot-riddle-qa-1k\\n1k\\n\\n\\né˜…è¯»ç†è§£\\nä¸­æ–‡\\ntigerbot-superclue-c3-zh-5k\\n5k\\n\\n\\né—®ç­”\\nä¸­æ–‡\\ntigerbot-hc3-zh-12k\\n12k\\n\\n\\nçŸ¥ä¹é—®ç­”\\nä¸­æ–‡\\ntigerbot-zhihu-zh-10k\\n10k\\n\\n\\n\\t\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"docs_on_several_languages","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages","creator_name":"Aleksey Timoshin","creator_url":"https://huggingface.co/AlekseyScorpi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"docs_on_several_languages\\\"\\n\\t\\n\\nThis dataset is a collection of different images in different languages.\\nThe set includes the following languages: Azerbaijani, Belorussian, Chinese, English, Estonian, Finnish, Georgian, Japanese, Korean, Kazakh, Latvian, Lithuanian, Mongolian, Norwegian, Polish, Russian, Ukranian.\\nEach language has a corresponding class label defined. At least 100 images in the entire dataset are allocated per class. This dataset was originally usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages.","first_N":5,"first_N_keywords":["text-classification","translation","feature-extraction","Azerbaijani","Belarusian"],"keywords_longer_than_N":true},
	{"name":"REDFM","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Babelscape/REDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\\\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\\nFirst, we present SRED\\\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \\nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \\nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\\\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}.","first_N":5,"first_N_keywords":["token-classification","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"SREDFM","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Babelscape/SREDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\\\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\\nFirst, we present SRED\\\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \\nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \\nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\\\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}.","first_N":5,"first_N_keywords":["token-classification","Arabic","Catalan","German","Greek"],"keywords_longer_than_N":true},
	{"name":"snli-zh","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/snli-zh","creator_name":"Ming Xu (å¾æ˜)","creator_url":"https://huggingface.co/shibing624","description":"The SNLI corpus (version 1.0) is a collection of 570k human-written English\\nsentence pairs manually labeled for balanced classification with the labels\\nentailment, contradiction, and neutral, supporting the task of natural language\\ninference (NLI), also known as recognizing textual entailment (RTE).","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","semantic-similarity-scoring","text-scoring","shibing624"],"keywords_longer_than_N":true},
	{"name":"goat-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/supinyu/goat-chinese","creator_name":"supinyu","creator_url":"https://huggingface.co/supinyu","description":"goatä¸­æ–‡ç®—æœ¯æ•°æ®é›†\\nå°†goatæ•°æ®é›†çš„Templateï¼Œæ›´æ¢æˆä¸­æ–‡çš„Templateï¼Œæ•°å­¦è¡¨è¾¾å¼ä¸å˜\\n","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"sts-sohu2021","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/sts-sohu2021","creator_name":"Ming Xu (å¾æ˜)","creator_url":"https://huggingface.co/shibing624","description":"2021æœç‹æ ¡å›­æ–‡æœ¬åŒ¹é…ç®—æ³•å¤§èµ›æ•°æ®é›†","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","natural-language-inference","semantic-similarity-scoring","text-scoring"],"keywords_longer_than_N":true},
	{"name":"HuatuoGPT_sft_data_v1_multiturn","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/HuatuoGPT_sft_data_v1_multiturn","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\ndescribe\\nprocess FreedomIntelligence/HuatuoGPT-sft-data-v1 to multiturn format\\n\\n{\\n    \\\"instruction\\\": \\\"å¬èµ·æ¥å¾ˆä¸é”™ã€‚äººå·¥æ™ºèƒ½å¯èƒ½åœ¨å“ªäº›æ–¹é¢é¢ä¸´æŒ‘æˆ˜å‘¢ï¼Ÿ\\\",\\n    \\\"input\\\": \\\",\\n    \\\"output\\\": \\\"äººå·¥æ™ºèƒ½é¢ä¸´çš„æŒ‘æˆ˜åŒ…æ‹¬æ•°æ®éšç§ã€å®‰å…¨å’Œé“å¾·æ–¹é¢çš„é—®é¢˜ï¼Œä»¥åŠå½±å“å°±ä¸šæœºä¼šçš„è‡ªåŠ¨åŒ–ç­‰é—®é¢˜ã€‚\\\",\\n    \\\"history\\\": [\\n      [\\\"ä½ å¥½ï¼Œä½ èƒ½å¸®æˆ‘è§£ç­”ä¸€ä¸ªé—®é¢˜å—ï¼Ÿ\\\", \\\"å½“ç„¶ï¼Œè¯·é—®æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ\\\"],\\n      [\\\"æˆ‘æƒ³äº†è§£äººå·¥æ™ºèƒ½çš„æœªæ¥å‘å±•æ–¹å‘ï¼Œä½ æœ‰ä»€ä¹ˆæƒ³æ³•å—ï¼Ÿ\\\", \\\"äººå·¥æ™ºèƒ½åœ¨æœªæ¥çš„å‘å±•æ–¹å‘å¯èƒ½åŒ…æ‹¬æ›´å¼ºå¤§çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œæ›´å…ˆè¿›çš„è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼Œä»¥åŠæ›´åŠ æ™ºèƒ½çš„æœºå™¨äººã€‚\\\"]\\n    ]\\n  }\\n\\nwhich can be used at LLaMA-Efficient-Tuning\\n\\nexample\\n\\n","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"TruthfulQA_zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Maxlinn/TruthfulQA_zh","creator_name":"Maxlinn","creator_url":"https://huggingface.co/Maxlinn","description":"TruthfulQA dataset csv with question and answer field translated into Chinese by requesting GPT-4.\\n","first_N":5,"first_N_keywords":["question-answering","Chinese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"Ziya-Finetune-Small","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IDEA-CCNL/Ziya-Finetune-Small","creator_name":"Fengshenbang-LM","creator_url":"https://huggingface.co/IDEA-CCNL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå§œå­ç‰™å¾®è°ƒç¤ºä¾‹æ•°æ®é›†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®ä»‹ç» Dataset Summary\\n\\t\\n\\nç”¨äºZiyaæ¨¡å‹çš„å¾®è°ƒç¤ºä¾‹æ•°æ®é›†\\nThe Ziya-Finetune-Small is an example dataset designed to finetune Ziya models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€ Languages\\n\\t\\n\\nä¸­æ–‡ & è‹±æ–‡\\nChinese & English\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®ç¤ºä¾‹ Data Instances\\n\\t\\n\\nå•è½®ç¤ºä¾‹ Single Turn\\n{\\\"prompt\\\": [\\\"ç»™å‡ºå…³äºå¦‚ä½•åœ¨å®¶é‡Œåšå†°æ·‡æ·‹çš„äº”æ¡ç®€å•æ­¥éª¤ã€‚\\\\\\\\n\\\\n\\\"], \\\"output\\\": [\\\"1. å‡†å¤‡å†°æ·‡æ·‹æœºå’Œå†°æ·‡æ·‹ææ–™ï¼ˆé²œå¥¶æ²¹ã€ç³–ã€é¦™è‰æå–ç‰©ç­‰ï¼‰ã€‚\\\\n2. å°†æ‰€æœ‰ææ–™æ”¾å…¥æ··åˆç‰©ä¸­æ‹ŒåŒ€ï¼Œç„¶åå°†æ··åˆç‰©æ”¾å…¥å†°æ·‡æ·‹æœºä¸­ã€‚\\\\n3. æ‰“å¼€å†°æ·‡æ·‹æœºï¼Œå¼€å§‹æ··åˆå’Œå†·è—æ··åˆç‰©ï¼Œç›´åˆ°æ··åˆç‰©å˜æˆå†°æ·‡æ·‹ã€‚\\\\n4. å°†å†°æ·‡æ·‹è½¬ç§»åˆ°å†°ç®±ä¸­ï¼Œå†·è—è‡³å°‘1ä¸ªå°æ—¶ä»¥åŠ å¼ºå£æ„Ÿå¹¶ä½¿å…¶æ›´å¥½åƒã€‚\\\\n5. å–å‡ºå†°æ·‡æ·‹ï¼Œäº«ç”¨ï¼\\\"]}\\n\\nå¤šè½®ç¤ºä¾‹ Multiple Turnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IDEA-CCNL/Ziya-Finetune-Small.","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"lyra","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/lyra","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlyra\\n\\t\\n\\n","first_N":5,"first_N_keywords":["text2text-generation","multilingual","original","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"emotional_dialog","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DataHammer/emotional_dialog","creator_name":"Data Hammer Group","creator_url":"https://huggingface.co/DataHammer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScientific Emotional Dialogue\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a dataset for emotional multi-turn dialogue on scientific research personnels. It consists of 1069 dialogues with 2709 turns. The Dialogue was first written by NLP practitioners and then expanded by GPT4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nEmotional Dialogue: The dataset can be used to instruction tuning for emotional dialogue.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nChinese\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DataHammer/emotional_dialog.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K<n<10K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"first","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Delius/first","creator_name":"Albert Delius","creator_url":"https://huggingface.co/Delius","description":"This dataset aims to complete text extension task.\\nInstance:\\n{\\n  \\\"Instruction\\\": \\\"è¯·å°†ç»™ä½ çš„æ–‡æœ¬å†…å®¹æ‰©å†™æˆæ–°é—»\\\",\\n  \\\"Input\\\": \\\"æ¨å¹‚è·æ‚å¿—ä¸»ç¼–å¤¸å¥–ï¼šå¤§å¹‚å¹‚ç˜¦äº†è¶Šæ¥è¶Šæ¼‚äº®\\\",\\n  \\\"Response\\\": \\\"ç½‘æ˜“å¨±ä¹4æœˆ29æ—¥æŠ¥é“Â Â 4æœˆ29æ—¥ï¼Œæ—¶å°šä¸»ç¼–å¼ å®‡æ™’å‡ºä¸€ç»„ä¸æ¨å¹‚çš„è‡ªæ‹åˆå½±ï¼Œå¹¶å‘æ–‡ï¼šâ€œä»Šå¤©ä¸æ¨å¹‚åšåŒäº‹ï¼Œå¤§å¹‚å¹‚ç˜¦äº†ï¼Œè¶Šæ¥è¶Šæ¼‚äº®ã€‚â€ç…§ç‰‡ä¸­ï¼Œæ¨å¹‚æ‰˜è…®å–èŒï¼Œç˜¦äº†ä¸å°‘ï¼Œå°‘å¥³å‘³åè¶³ã€‚ç½‘å‹ä»¬ä¹Ÿè¢«æ¨å¹‚çš„é€ å‹å¾æœï¼Œçº·çº·è¡¨ç¤ºï¼šâ€œå¤ªç¾äº†ï¼Œçœ‹ä¸Šå»å¹´è½»äº†10å²ã€‚â€\\\"\\n}\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"yolo","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wwkiyyx/yolo","creator_name":"wangwenkai","creator_url":"https://huggingface.co/wwkiyyx","description":"wwkiyyx/yolo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"PolyMRC","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigai-nlco/PolyMRC","creator_name":"BIGAI NLCo","creator_url":"https://huggingface.co/bigai-nlco","description":"We construct a dataset through entries with multiple meanings and examples from Chinese dictionaries, and set the example as context and explanations as choices, the goal of Polysemy Machine Comprehension (PolyMRC) is to find the correct explanation of the entry in the example.\\nthe statistics of the dataset\\n\\n\\t\\n\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\nsplit\\nsentences\\naverage sentence length\\n\\n\\ntrain\\n46,119\\n38.55\\n\\n\\nvalidation\\n5,765\\n38.31\\n\\n\\ntest\\n5,765\\n38.84\\n\\n\\n\\t\\n\\n","first_N":5,"first_N_keywords":["multiple-choice","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"all-scam-spam","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\\n1040 rows of balanced data, consisting of casual conversations and scam emails in â‰ˆ10 languages, were manually collected and annotated by me, with some help from ChatGPT.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSome preprcoessing algorithms\\n\\t\\n\\n\\nspam_assassin.js, followed by spam_assassin.py\\nenron_spam.py\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData composition\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nToâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Norwegian","Spanish","Somali"],"keywords_longer_than_N":true},
	{"name":"chat","keyword":"chinese","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/chenbobo/chat","creator_name":"yuanbo","creator_url":"https://huggingface.co/chenbobo","description":"chenbobo/chat dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","unlicense","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"instruct-tuning-sample","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hongyin/instruct-tuning-sample","creator_name":"hongyin","creator_url":"https://huggingface.co/hongyin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPretrain\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset details\\n\\t\\n\\nLicense:\\n","first_N":5,"first_N_keywords":["Chinese","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"achinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"yue chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"WebCPM_WK","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZHR123/WebCPM_WK","creator_name":"ZHR","creator_url":"https://huggingface.co/ZHR123","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WebCPM_WK\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\næœ¬æ•°æ®é›†æ˜¯ç”±æˆ‘ä»¬å¯¹WebCPMçš„pipelineæ•°æ®è¿›è¡ŒäºŒæ¬¡å¤„ç†ä¹‹åæ„å»ºè€Œæˆã€‚\\nä¸»è¦åŒ…æ‹¬è¿‡æ»¤åŸå§‹æ•°æ®ä¸­çš„ä¸€äº›ä½è´¨é‡æ•°æ®ï¼Œä½¿ç”¨GPT4å’ŒChatGPTæ‰©å……åŸå§‹æ•°æ®ï¼Œä»¥åŠä½¿ç”¨éšæœºæ›¿æ¢ã€æ‹¼æ¥çš„æ–¹å¼å¢å¼ºåŸå§‹æ•°æ®ã€‚\\nè¯¥æ•°æ®é›†ä¸»è¦çš„ç›®çš„æ˜¯é€šè¿‡æŒ‡ä»¤å¾®è°ƒçš„æ–¹å¼æé«˜LLMçš„ä¸¤ä¸ªèƒ½åŠ›ï¼š\\n\\nç»™å®šé—®é¢˜å’Œæ–‡æ¡£ï¼ŒæŠ½å–æ–‡æ¡£ä¸­ä¸é—®é¢˜ç›¸å…³çŸ¥è¯†çš„èƒ½åŠ›ã€‚\\nç»™å®šå‚è€ƒææ–™å’Œé—®é¢˜ï¼Œæ ¹æ®å‚è€ƒææ–™å›ç­”é—®é¢˜çš„èƒ½åŠ›ã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe dataset is available under the Creative Commons NonCommercial (CC BY-NC 4.0).\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"CMB","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/CMB","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCMB: A Comprehensive  Medical Benchmark in Chinese\\n\\t\\n\\n\\n\\n   ğŸŒ Github â€¢ ğŸŒ Website â€¢ ğŸ¤— HuggingFace\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸŒˆ Update\\n\\t\\n\\n\\n[2024.02.21] The answers to the CMB-Exam test has been updated and some errors caused by omissions in version management have been fixed.\\n[2024.01.08] In order to facilitate testing, we disclose the answers to the CMB-Exam test\\n[2023.09.22] CMB is included in OpenCompass.\\n[2023.08.21] Paper released.\\n[2023.08.01] ğŸ‰ğŸ‰ğŸ‰ CMB is publishedï¼ğŸ‰ğŸ‰ğŸ‰â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/CMB.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cantone","keyword":"yue chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlienKevin/cantone","creator_name":"Xiang (Kevin) Li","creator_url":"https://huggingface.co/AlienKevin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCantone\\n\\t\\n\\nA dataset of 34,489 recordings of Cantonese syllables by 10 speakers.\\nThose syllables are generated through the Cantonese speech synthesis engines of Amazon, Apple, Google, and Microsoft.\\nAll recordings are stored as WAV files with the following format\\n\\nChannel: mono\\nSample rate: 16 kHz\\nBits per sample: 16\\n\\nHere's a breakdown of the number of recordings under each speaker:\\n\\n\\t\\n\\t\\t\\nCompany\\nSpeaker\\n# Syllables\\n\\n\\n\\t\\t\\nAmazon\\nHiujin\\n3,885\\n\\n\\nApple\\nAasing\\n2,977\\n\\n\\nApple\\nSinji\\n2,977â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlienKevin/cantone.","first_N":5,"first_N_keywords":["audio-classification","Yue Chinese","mit","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"wikipedia_tw","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jslin09/wikipedia_tw","creator_name":"Chun-Hsien Lin","creator_url":"https://huggingface.co/jslin09","description":"è¦æè‡ªå·±çš„å¤§å‹èªè¨€æ¨¡å‹ï¼Œæœ€åŸºæœ¬çš„åŸºæœ¬ï¼Œå°±æ˜¯éœ€è¦ä¸€å¤§å †æ–‡å­—è³‡æ–™ï¼Œå¾ Common Crawl ä¸Šé ­æŠ“å›ä¾†æ…¢æ…¢æ¸…æ´—æ˜¯ä¸€æ¢è·¯ï¼Œæ¸…æ´—ç¶­åŸºç™¾ç§‘ç¶²ç«™çš„é€±æœŸæ€§ä¸‹è¼‰æª”ä¹Ÿæ˜¯ä¸€å€‹æ–¹æ³•ã€‚æœ¬è³‡æ–™é›†æ˜¯è§£æè‡ªç¶­åŸºç™¾ç§‘æ–¼ 20240420 ç™¼å¸ƒçš„ç¹é«”ä¸­æ–‡ç‰ˆæ‰“åŒ…æª” bz2 æª”æ¡ˆçš„å…§å®¹ï¼Œåœ¨è§£æå‡ºæ‰€éœ€å…§å®¹å¾Œï¼Œåˆ©ç”¨ wikitextparser ç§»é™¤ Wiki æ¨™è¨˜ã€‚è§£æå¾Œä¿ç•™çš„æ¬„ä½æœ‰å…©å€‹ï¼šæ¢ç›®åç¨±ï¼ˆtitleï¼‰ï¼Œæ¢ç›®å…§å®¹ï¼ˆpage articleï¼‰ã€‚\\nåŸå§‹çš„æ‰“åŒ…æª”æ¢ç›®å…§å®¹ç°¡ç¹æ··é›œï¼Œæ‰€ä»¥æœ‰åˆ©ç”¨ OpenCC é€²è¡Œç°¡è½‰ç¹è™•ç†ã€‚\\n\\nåŸå§‹ç¸½æ¢ç›®æ•¸: 4,451,426 æ¢ç›®ã€‚\\nå…¨éƒ¨ 4,451,426 å€‹æ¢ç›®æ¨™é¡Œã€‚\\nç„¡æ³•è‡ªå‹•å»æ¨™è¨˜çš„æ¢ç›®æ•¸: 3,035,750\\næœ‰å…§å®¹çš„æ¢ç›®æ•¸: 1,415,676\\n\\nå› ç‚ºæœ¬è³‡æ–™é›†å…§å®¹é¾å¤§ï¼Œè¦å¡é€²ä¸€èˆ¬çš„å€‹äººé›»è…¦ä¸­é€²è¡Œè¨ˆç®—ï¼Œææ€•æœƒæœ‰è³‡æºä¸è¶³çš„æƒ…å½¢ã€‚å»ºè­°ä½¿ç”¨parquetæ ¼å¼ä¸‹è¼‰ä½¿ç”¨ã€‚\\nè³‡æ–™é›†ç•¶ä¸­æœ‰ä¸å°‘å…§å®¹ç‚º #REDIRECT çš„æ¢ç›®å·²ç¶“å˜—è©¦ç§»é™¤ï¼Œå¦‚æœç§»é™¤çš„ä¸ä¹¾æ·¨ï¼Œå°±ç­‰ä»¥å¾Œæœ‰ç©ºæ¨å‡ºä¿®æ­£ç‰ˆå†ä¾†æ¸…æ´—äº†ã€‚\\n","first_N":5,"first_N_keywords":["monolingual","wikipedia","Chinese","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"KenithZ-dolly-zh-51k","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KenithZ/KenithZ-dolly-zh-51k","creator_name":"Kenith-Zhang","creator_url":"https://huggingface.co/KenithZ","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDollyä¸­æ–‡è®­ç»ƒé›†\\n\\t\\n\\nåŸºäºChinese-LLaMA-Alpacaçš„è½¬æ¢æˆçš„dollyæ•°æ®é›†\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\téœ€è¦åšçš„äº‹æƒ…\\n\\t\\n\\n\\nå°†alpaca_data_zh_51k.jsonæ•°æ®é›†è½¬æ¢ä¸ºdatabricks-dolly-15k.jsonlæ•°æ®é›†çš„æ ¼å¼\\nè½¬æ¢åçš„æ•°æ®é›†é›†éœ€è¦æ‰‹åŠ¨è¡¥å……categoryï¼ˆæ­£åœ¨è¿›è¡Œï¼‰\\nä¿®æ­£åŸä½œè€…ä»chatGPTçˆ¬å–çš„è¯­ä¹‰ä¸é€šæˆ–æ•°æ®é”™è¯¯çš„æŒ‡ä»¤æ•°æ®ï¼ˆæ­£åœ¨è¿›è¡Œï¼‰\\n\\n","first_N":5,"first_N_keywords":["question-answering","summarization","Chinese","English","mit"],"keywords_longer_than_N":true},
	{"name":"news_commentary_tw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jslin09/news_commentary_tw","creator_name":"Chun-Hsien Lin","creator_url":"https://huggingface.co/jslin09","description":"æœ¬è³‡æ–™é›†æ˜¯ä¾†è‡ªQingySiæ‰€æœé›†çš„ä¸­è‹±å°ç…§æ–°èè©•è«–ï¼Œä¸€å…±æœ‰ 252,776 å°ä¸­è‹±èªç¿»è­¯çš„å¥å­ï¼Œæ˜¯ä½¿ç”¨Alpacaçš„æŒ‡ä»¤è³‡æ–™é›†æ ¼å¼è£½æˆã€‚æœ¬è³‡æ–™é›†åˆ©ç”¨äº†OpenCC é€²è¡Œç°¡è½‰ç¹ã€‚\\n","first_N":5,"first_N_keywords":["translation","question-answering","text-generation","Chinese","English"],"keywords_longer_than_N":true},
	{"name":"artelingo-dummy","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/youssef101/artelingo-dummy","creator_name":"mohamed","creator_url":"https://huggingface.co/youssef101","description":"ArtELingo is a benchmark and dataset introduced in a research paper aimed at promoting work on diversity across languages and cultures. It is an extension of ArtEmis, which is a collection of 80,000 artworks from WikiArt with 450,000 emotion labels and English-only captions. ArtELingo expands this dataset by adding 790,000 annotations in Arabic and Chinese. The purpose of these additional annotations is to evaluate the performance of \\\"cultural-transfer\\\" in AI systems.\\nThe dataset in ArtELingoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/youssef101/artelingo-dummy.","first_N":5,"first_N_keywords":["image-to-text","text-classification","image-classification","text-to-image","text-generation"],"keywords_longer_than_N":true},
	{"name":"calculation","keyword":"chinese","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/OzoneAsai/calculation","creator_name":"AsaiTaka","creator_url":"https://huggingface.co/OzoneAsai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Calculation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsize\\n\\t\\n\\n  JSON file: output1.jsonâ‰’1.3GB\\n  ~\\n    output60.json\\n     In total 70 ~ 80GB\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nen: Calculation. Its range will be expanded later.\\nzh: è®¡ç®—ã€‚å…¶èŒƒå›´å°†åœ¨ä»¥åæ‰©å±•ã€‚\\nde: Berechnung. Der Umfang wird spÃ¤ter erweitert werden.\\nru: Ğ Ğ°ÑÑ‡ĞµÑ‚. Ğ•Ğ³Ğ¾ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ±ÑƒĞ´ĞµÑ‚ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½ Ğ¿Ğ¾Ğ·Ğ¶Ğµ.\\nko: ê³„ì‚°. ë²”ìœ„ëŠ” ë‚˜ì¤‘ì— í™•ì¥ë  ê²ƒì…ë‹ˆë‹¤.\\nfr: Calcul. Sa portÃ©e sera Ã©tendue ultÃ©rieurement.\\nja: è¨ˆç®—ã€‚ç¯„å›²ã¯å¾Œã§æ‹¡å¼µã•ã‚Œã¾ã™ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nen:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/OzoneAsai/calculation.","first_N":5,"first_N_keywords":["English","Chinese","German","Russian","Korean"],"keywords_longer_than_N":true},
	{"name":"openassistant-guanaco-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Elliot4AI/openassistant-guanaco-chinese","creator_name":"Jiang Elliot","creator_url":"https://huggingface.co/Elliot4AI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nğŸ¡ğŸ¡ğŸ¡ğŸ¡Fine-turn Dataset:ä¸­æ–‡æ•°æ®é›†ğŸ¡ğŸ¡ğŸ¡ğŸ¡\\nğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ è¿™ä¸ªæ•°æ®é›†æ˜¯timdettmers/openassistant-guanacoçš„ä¸­æ–‡ç‰ˆæœ¬ï¼Œæ˜¯ç›´æ¥ç¿»è¯‘è¿‡æ¥ï¼Œæ²¡æœ‰ç»è¿‡äººä¸ºæ£€æŸ¥è¯­æ³•ã€‚ å¯¹timdettmers/openassistant-guanacoçš„æè¿°ï¼Œè¯·çœ‹ä»–çš„dataset cardã€‚ License: Apache 2.0\\nğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ This data set is the Chinese version of timdettmers/openassistant-guanaco, which is directly translated without human-checked grammar. For a description of timdettmers/openassistant-guanaco, see its dataset card. License: Apache 2.0\\n","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ocnli","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Fred666/ocnli","creator_name":"Fred","creator_url":"https://huggingface.co/Fred666","description":"This dataset is copied from CLUE with certain modifications.\\nThe paper of CLUE is OCNLI.\\nThe modifications are:\\n\\nTransform json file to csv file.\\nEncoding in UTF-8.\\nRemove data entries whose label value is '-'.\\nReplace label values, 'neutral' to 1, 'entailment' to 0, and 'contradiction' to 2.\\nAdd one column 'sentence1', whose value is 'å‰æï¼š' + premise value + 'ç»“è®ºï¼š' + hypothsis value.\\n\\nocnli_train_std.csv comes from train.50k.json.\\nocnli_test_std.csv comes from dev.json.\\n","first_N":5,"first_N_keywords":["text-classification","Chinese","gpl-3.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"blossom-chat-v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-chat-v1","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM CHAT V1\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nBlossom Chat V1æ˜¯åŸºäºShareGPT 90Kè¡ç”Ÿè€Œæ¥çš„ä¸­è‹±åŒè¯­å¯¹è¯æ•°æ®é›†ï¼Œé€‚ç”¨äºå¤šè½®å¯¹è¯å¾®è°ƒã€‚\\næœ¬æ•°æ®é›†æŠ½å–äº†ShareGPTçš„å¤šè½®å¯¹è¯æŒ‡ä»¤ï¼Œä»…å°†æŒ‡ä»¤è¿›è¡Œç¿»è¯‘ï¼Œéšåä½¿ç”¨å¤šè½®æŒ‡ä»¤è¿­ä»£è°ƒç”¨gpt-3.5-turbo-0613ã€‚\\nç›¸æ¯”åŸå§‹çš„ShareGPTæ•°æ®ï¼Œä¸»è¦è§£å†³äº†ä¸­æ–‡å¯¹è¯æ•°æ®é‡è¾ƒå°‘ï¼Œä»¥åŠç”±ChatGPTç”Ÿæˆé•¿åº¦é™åˆ¶è€Œå¯¼è‡´çš„è¾“å‡ºæˆªæ–­é—®é¢˜ã€‚\\næœ¬æ¬¡å‘å¸ƒäº†å…¨é‡æ•°æ®çš„20%ï¼ŒåŒ…å«30Kè®°å½•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€\\n\\t\\n\\nä»¥ä¸­æ–‡å’Œè‹±æ–‡ä¸ºä¸»ï¼Œä¸­è‹±æ–‡æ•°æ®æŒ‰ç…§çº¦5:1çš„æ¯”ä¾‹æ··åˆã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„\\n\\t\\n\\næ¯æ¡æ•°æ®ä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„å¤šè½®å¯¹è¯ï¼ŒåŒ…å«idå’Œconversationsä¸¤ä¸ªå­—æ®µã€‚\\n\\nidï¼šå­—ç¬¦ä¸²ï¼Œä»£è¡¨åŸå§‹ShareGPTçš„å¯¹è¯idï¼Œå¯ä»¥é€šè¿‡é“¾æ¥https://sharegpt.com/c/idæ¥è®¿é—®åŸå§‹å¯¹è¯ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-chat-v1.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"en_zh","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigidea/en_zh","creator_name":"Deng Da","creator_url":"https://huggingface.co/bigidea","description":"bigidea/en_zh dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Chinese","English","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"4typeCalculation","keyword":"chinese","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/OzoneAsai/4typeCalculation","creator_name":"AsaiTaka","creator_url":"https://huggingface.co/OzoneAsai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Calculation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsize\\n\\t\\n\\n  JSON file: output1.jsonâ‰’1.3GB\\n  ~\\n    output60.json\\n     In total 70 ~ 80GB\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nen: Calculation. Its range will be expanded later.\\nzh: è®¡ç®—ã€‚å…¶èŒƒå›´å°†åœ¨ä»¥åæ‰©å±•ã€‚\\nde: Berechnung. Der Umfang wird spÃ¤ter erweitert werden.\\nru: Ğ Ğ°ÑÑ‡ĞµÑ‚. Ğ•Ğ³Ğ¾ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ±ÑƒĞ´ĞµÑ‚ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½ Ğ¿Ğ¾Ğ·Ğ¶Ğµ.\\nko: ê³„ì‚°. ë²”ìœ„ëŠ” ë‚˜ì¤‘ì— í™•ì¥ë  ê²ƒì…ë‹ˆë‹¤.\\nfr: Calcul. Sa portÃ©e sera Ã©tendue ultÃ©rieurement.\\nja: è¨ˆç®—ã€‚ç¯„å›²ã¯å¾Œã§æ‹¡å¼µã•ã‚Œã¾ã™ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nen:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/OzoneAsai/4typeCalculation.","first_N":5,"first_N_keywords":["English","Chinese","German","Russian","Korean"],"keywords_longer_than_N":true},
	{"name":"blossom-math-v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-math-v1","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM MATH V1\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nBlossom Math V3ç‰ˆæœ¬å·²å‘å¸ƒï¼ğŸ¤—\\nBlossom Math V1æ˜¯åŸºäºMath23Kè¡ç”Ÿè€Œæ¥çš„ä¸­æ–‡æ•°å­¦å¯¹è¯æ•°æ®é›†ï¼Œé€‚ç”¨äºæ•°å­¦é—®é¢˜å¾®è°ƒã€‚\\næœ¬æ•°æ®é›†é‡‡ç”¨å…¨é‡Math23Kçš„é—®é¢˜ï¼Œéšåè°ƒç”¨gpt-3.5-turbo-0613ç”Ÿæˆç»“æœï¼Œå¹¶ä½¿ç”¨åŸå§‹æ•°æ®é›†ä¸­çš„ç­”æ¡ˆå¯¹ç”Ÿæˆçš„ç»“æœè¿›è¡ŒéªŒè¯ï¼Œè¿‡æ»¤æ‰é”™è¯¯ç­”æ¡ˆï¼Œå¾ˆå¤§ç¨‹åº¦ä¸Šä¿è¯äº†é—®é¢˜å’Œç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚\\næœ¬æ¬¡å‘å¸ƒäº†å…¨é‡æ•°æ®çš„50%ï¼ŒåŒ…å«10Kè®°å½•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€\\n\\t\\n\\nä¸­æ–‡\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„\\n\\t\\n\\næ¯æ¡æ•°æ®ä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„é¢˜ç›®åŠç­”æ¡ˆï¼ŒåŒ…å«idã€inputã€outputã€answerå››ä¸ªå­—æ®µã€‚\\n\\nidï¼šå­—ç¬¦ä¸²ï¼Œä»£è¡¨Math23Kä¸­çš„é¢˜ç›®idã€‚\\ninputï¼šå­—ç¬¦ä¸²ï¼Œä»£è¡¨é—®é¢˜ã€‚\\noutputï¼šå­—ç¬¦ä¸²ï¼Œä»£è¡¨gpt-3.5-turbo-0613ç”Ÿæˆçš„ç­”æ¡ˆã€‚\\nanswerï¼šå­—ç¬¦ä¸²ï¼Œä»£è¡¨æ­£ç¡®ç­”æ¡ˆã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†é™åˆ¶â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-math-v1.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"dolly-15k-chinese-guanacoformat","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Elliot4AI/dolly-15k-chinese-guanacoformat","creator_name":"Jiang Elliot","creator_url":"https://huggingface.co/Elliot4AI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸ¡ğŸ¡ğŸ¡ğŸ¡Fine-tune Dataset:ä¸­æ–‡æ•°æ®é›†ğŸ¡ğŸ¡ğŸ¡ğŸ¡\\n\\t\\n\\nğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ è¿™ä¸ªæ•°æ®é›†æ˜¯databricks/databricks-dolly-15kçš„ä¸­æ–‡guanacoç‰ˆæœ¬\\n","first_N":5,"first_N_keywords":["text-classification","text-generation","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"crawl-theedgemalaysia","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanadzhar913/crawl-theedgemalaysia","creator_name":"Faiq Adzlan","creator_url":"https://huggingface.co/wanadzhar913","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTLDR\\n\\t\\n\\n\\nwebsite: theedgemalaysia\\nnum. of webpages scraped: 414,268 (only webpages with full articles)\\nlink to dataset: https://huggingface.co/datasets/wanadzhar913/crawl-theedgemalaysia\\nlast date of scraping: 14th August 2023\\nstatus: complete\\npull request: https://github.com/huseinzol05/malaysian-dataset/pull/261\\ncontributed to: https://github.com/huseinzol05/malaysian-dataset\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\nThe \\\"language\\\" column for the data set has errors as it miscategorizes articles inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wanadzhar913/crawl-theedgemalaysia.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"training-data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yenping/training-data","creator_name":"yenping","creator_url":"https://huggingface.co/yenping","description":"yenping/training-data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Traditional_Chinese_roleplay_chat_Dataset","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tarklanse/Traditional_Chinese_roleplay_chat_Dataset","creator_name":"wenhaochan","creator_url":"https://huggingface.co/Tarklanse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTraditional_Chinese_roleplay_chat_Dataset\\n\\t\\n\\né€™å€‹è³‡æ–™é›†æ˜¯ä»¥ç¹é«”ä¸­æ–‡ç‚ºä¸»ï¼Œå°‡å„ç¨®ç”±ChatGPTç”Ÿæˆèˆ‡æ¥µå°éƒ¨åˆ†å€‹äººæ’°å¯«çš„å°è©±å…§å®¹æ•´ç†ç‚ºalpaca dataset formatçš„æ ¼å¼\\nä»¥ä¸€å±¤ä¸€å±¤å †ç–Šçš„æ–¹å¼ï¼Œå°‡ä¸€å‰‡å°è©±ç´€éŒ„æ‹†æˆæ•¸ç­†è³‡æ–™(å…±ç´„1000å‰‡å°è©±)ï¼Œåœ¨å¹¾æ¬¡å˜—è©¦æ€§çš„è¨“ç·´ä¸­èƒ½å¤ è®“llama2é‡ç¾åŸæœ¬è‹±æ–‡é‚£ç¨®å¾ˆæ´»èºçš„å°è©±é¢¨æ ¼ï¼Œä¸¦ä¸”èƒ½å¤ ç¶­æŒå–„æ–¼æ‰®æ¼”å„ç¨®è§’è‰²çš„èƒ½åŠ›\\nç›®å‰å€‹äººæœ‰ä»¥é€™å€‹è³‡æ–™é›†è£½ä½œä¸€å€‹lora\\n2023/09/07 æ›´æ–°\\nç‚ºè³‡æ–™é›†åŠ å…¥ä¸€äº›ä¸­è‹±ç¿»è­¯çš„å¥å­ï¼Œä»¥æœŸAIèƒ½ä»¥æ›´å¥½çš„æ–‡å­—å»æå¯«ä»–çš„å‹•ä½œï¼Œä¸¦å¢åŠ äº†ä¸€äº›èˆ‡é£Ÿç‰©æœ‰é—œçš„å°è©±ï¼Œå¸Œæœ›èƒ½é™ä½AIç”Ÿå‡ºå¥‡æ€ªé£Ÿç‰©åçš„æ©Ÿç‡\\n","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"train_3.5M_CN_With_Category","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BELLE-2/train_3.5M_CN_With_Category","creator_name":"BELLE-2 Group // Be Everyone's Large Language model Engine","creator_url":"https://huggingface.co/BELLE-2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå†…å®¹\\n\\t\\n\\nåŸºäºåŸæœ‰çš„train_3.5M_CNæ•°æ®æ–°å¢äº†æŒ‡ä»¤ç±»åˆ«å­—æ®µï¼Œå…±åŒ…æ‹¬13ä¸ªç±»åˆ«ï¼Œè¯¦æƒ…å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ ·ä¾‹\\n\\t\\n\\n{\\n    \\\"id\\\":\\\"66182880\\\",\\n    \\\"category\\\"ï¼š\\\"generation\\\"\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå­—æ®µï¼š\\n\\t\\n\\nid: æ•°æ®id\\ncategory: è¯¥æ¡æŒ‡ä»¤æ•°æ®å¯¹åº”çš„ç±»åˆ«\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä½¿ç”¨é™åˆ¶\\n\\t\\n\\nä»…å…è®¸å°†æ­¤æ•°æ®é›†åŠä½¿ç”¨æ­¤æ•°æ®é›†ç”Ÿæˆçš„è¡ç”Ÿç‰©ç”¨äºç ”ç©¶ç›®çš„ï¼Œä¸å¾—ç”¨äºå•†ä¸šï¼Œä»¥åŠå…¶ä»–ä¼šå¯¹ç¤¾ä¼šå¸¦æ¥å±å®³çš„ç”¨é€”ã€‚\\næœ¬æ•°æ®é›†ä¸ä»£è¡¨ä»»ä½•ä¸€æ–¹çš„ç«‹åœºã€åˆ©ç›Šæˆ–æƒ³æ³•ï¼Œæ— å…³ä»»ä½•å›¢ä½“çš„ä»»ä½•ç±»å‹çš„ä¸»å¼ ã€‚å› ä½¿ç”¨æœ¬æ•°æ®é›†å¸¦æ¥çš„ä»»ä½•æŸå®³ã€çº çº·ï¼Œæœ¬é¡¹ç›®ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nPlease cite our paper and github when using our code, data or model.\\n@misc{BELLE,\\n  author = {BELLEGroup},\\n  title = {BELLE: Be Everyone's Largeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BELLE-2/train_3.5M_CN_With_Category.","first_N":5,"first_N_keywords":["text2text-generation","Chinese","gpl-3.0","1M<n<10M","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"silk-road_alpaca-data-gpt4-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/silk-road_alpaca-data-gpt4-chinese","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"botp/silk-road_alpaca-data-gpt4-chinese dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"RyokoAI_CNNovel125K","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/RyokoAI_CNNovel125K","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CNNovel125K\\n\\t\\n\\nThe BigKnow2022 dataset and its subsets are not yet complete. Not all information here may be accurate or accessible.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCNNovel125K is a dataset composed of approximately 125,000 novels downloaded from the Chinese novel hosting site http://ibiquw.com.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is primarily intended for unsupervised training of text generation models; however, it may be useful for otherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/botp/RyokoAI_CNNovel125K.","first_N":5,"first_N_keywords":["text-classification","text-generation","Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ChineseCorpus-Kaggle-fanti","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/ChineseCorpus-Kaggle-fanti","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsource\\n\\t\\n\\nmix data from https://www.kaggle.com/datasets/allanyiinai/chinesecorpus\\n\\nuse\\n\\nfrom datasets import load_datasets\\nds = load_datasets(\\\"ticoAg/ChineseCorpus-Kaggle-fanti\\\")\\n\\n\\nexample\\n\\n[\\n    {\\n        \\\"text\\\": \\\"2017å¹´12æœˆ5æ—¥ï¼Œé‡æ…¶å¸‚äº¤å§”æ­£å¼ä¸‹ç™¼ã€Šé—œäºæ–°å»ºå¸‚éƒŠéµè·¯ç£¨å¿ƒå¡è‡³åˆå·ç·šå·¥ç¨‹åˆæ­¥è¨­è¨ˆçš„æ‰¹å¾©ã€‹ï¼Œ2017å¹´è¨ˆåŠƒé–‹å·¥å››å€‹ç¯€é»å·¥ç¨‹ï¼ŒåŒ…æ‹¬æ¸­æ²±è²¨é‹ç«™å ´ã€åœŸå ´è²¨é‹ç«™å ´ã€å˜‰é™µæ±Ÿç‰¹å¤§æ©‹ã€ä¹å³°å±±é‚é“ã€‚\\\"\\n    },\\n    {\\n        \\\"text\\\": \\\"2017å¹´7æœˆ6æ—¥ï¼Œç·šè·¯é‡è¦ç¯€é»åˆå·æ¸­æ²±è²¨é‹ç«™é–‹å·¥å»ºè¨­ï¼Œç·šè·¯é–‹å§‹å»ºè¨­ï¼Œé …ç›®å»ºè¨­å·¥æœŸç‚º48å€‹æœˆã€‚\\\"\\n    },\\n    {\\n        \\\"text\\\": \\\"æ—¥å‰ï¼Œæ¸åˆç·šäºŒæœŸï¼ˆåˆå·æ®µï¼‰æ–½å·¥å‡ºç¾äº†åœæ»¯ï¼Œè‡³ä»Šä»æœªè§£æ±ºï¼Œåˆå·å€äººæ°‘æ”¿åºœåœ¨2019ã€2020å¹´å‡ç¨±å°‡åŠ›ä¿ƒå¸‚éƒŠéµè·¯æ¸åˆç·šå¾©å·¥ã€‚\\\"\\n    }â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ticoAg/ChineseCorpus-Kaggle-fanti.","first_N":5,"first_N_keywords":["text-generation","Twi","Chinese","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"shibing624-medical-pretrain","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/shibing624-medical-pretrain","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for medical\\n\\t\\n\\nä¸­æ–‡åŒ»ç–—æ•°æ®é›†\\n\\nLLM Supervised Finetuning repository: https://github.com/shibing624/textgen\\nMeidcalGPT repository: https://github.com/shibing624/MedicalGPT\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nmedical is a Chinese Medical dataset. åŒ»ç–—æ•°æ®é›†ï¼Œå¯ç”¨äºåŒ»ç–—é¢†åŸŸå¤§æ¨¡å‹è®­ç»ƒã€‚\\ntree medical\\n|-- finetune  # ç›‘ç£å¾®è°ƒæ•°æ®é›†ï¼Œå¯ç”¨äºSFTå’ŒRLHF\\n|   |-- test_en_1.json\\n|   |-- test_zh_0.json\\n|   |-- train_en_1.json\\n|   |-- train_zh_0.json\\n|   |-- valid_en_1.json\\n|   `-- valid_zh_0.json\\n|-- medical.py # hfâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ticoAg/shibing624-medical-pretrain.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ChatMed_Consult_Dataset","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/ChatMed_Consult_Dataset","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ChatMed\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nChatMed-Dataset is a dataset of 110,113 medical query-response pairs (in Chinese) generated by OpenAI's GPT-3.5 engine. The queries are crawled from several online medical consultation sites, reflecting the medical needs in the real world. The responses are generated by the OpenAI engine. This dataset is designated to to inject medical knowledge into Chinese large language models. \\nThe dataset size growing rapidly. Stayâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ticoAg/ChatMed_Consult_Dataset.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"Medical-Dialogue-System","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/Medical-Dialogue-System","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdescribe\\n\\t\\n\\néå¸¸navieçš„åœºæ™¯å¯¹è¯ï¼Œä½†å¯èƒ½å‡ºç°çœŸå®åœºæ™¯ä¿¡æ¯ï¼Œæ¯”å¦‚XXåŒ»é™¢ï¼ŒXXåŒ»ç”Ÿ\\nå¯¹çº¯æŒ‡ä»¤æ•°æ®è´¨é‡è¦æ±‚è¾ƒé«˜çš„éœ€è¦è¿›ä¸€æ­¥æ¸…æ´—ï¼Œåªç”¨æ¥å¥åº·åœºæ™¯finetune maybe enough\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tfrom\\n\\t\\n\\n[Medical-Dialogue-System]\\n*[medical_dialog]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tformat\\n\\t\\n\\n{\\n    \\\"instruction\\\": null,\\n    \\\"input\\\": \\\"ä¸çŸ¥é“ï¼Œæˆ‘æ˜¯åœ¨09å¹´8æœˆä»½,ç™½å¤©å‡ºäº†å¾ˆå¤šçš„æ±—,æ™šä¸Šç¡è§‰çªç„¶é†’æ¥,çœ‹æˆ¿å­å¤©æ™•åœ°è½¬,è¿‡äº†å¤§çº¦ä¹Ÿå°±ä¸€åˆ†é’Ÿçš„æ ·å­,å°±ä¸è½¬äº†.ä½†å¤´å‘å·¦è½¬åŠ¨å°±åˆè½¬,å·¦è¾¹å¤´çš®è¿˜å‘éº».ç¬¬äºŒå¤©èµ·æ¥,äººæ²¡æœ‰ç²¾ç¥,è¿‡äº†æ®µæ—¶é—´.ç—…æƒ…æ—¶è½»æ—¶é‡,å¥½åƒæ˜¯èººåœ¨åºŠä¸Šå‘å³äººå°±ä¸€ä¸Šæ™•äº†.ä½†æ—¶é—´ä¸é•¿.æœ‰ä¸€å¤©å¼€äº†ä¸€å¤©çš„è½¦,æ™šä¸Šå…ˆæ˜¯æœ‰ç‚¹å¤´æ™•,èµ°è·¯ä¸ç¨³,ä¸ŠåºŠä¼‘æ¯,ä½†çªç„¶åè„‘æ ¹éƒ¨ç‰¹åˆ«ç–¼,åˆ°äº†ç¬¬äºŒå¤©ä¹Ÿä¸ç–¼äº†.åˆ°ç°åœ¨ä¹Ÿæ²¡æœ‰ç–¼è¿‡.ç°åœ¨å°±æ˜¯èººä¸‹å’Œèµ·åºŠç‰¹åˆ«æ™•(å¤´å‘å³å’Œå¤´å‘ä¸Šæˆ–å‘ä¸‹),èµ°è·¯ä¸ç¨³.ç‰¹åˆ«æ˜¯ç«™ä¹…äº†,å°±è¦å€’äº†æ„Ÿè§‰.å¦å¤–å¹³å¸¸,è„‘è¢‹æ„Ÿè§‰æ˜æ²‰æ²‰çš„,æœ‰æ—¶çœ¼ç›çœ‹ä¸œè¥¿è·Ÿä¸ä¸Šé€Ÿåº¦,è¦æ™•çš„â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ticoAg/Medical-Dialogue-System.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"cmath","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/weitianwen/cmath","creator_name":"Wei Tianwen","creator_url":"https://huggingface.co/weitianwen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCMATH\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe present the Chinese Elementary School Math Word Problems (CMATH) dataset, comprising 1.7k elementary school-level math word problems with detailed annotations, source from actual Chinese workbooks and exams. This dataset aims to provide a benchmark tool for assessing the following question: to what grade level of elementary school math do the abilities of popular large language models (LLMs) correspond? We evaluate a variety of popular LLMsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/weitianwen/cmath.","first_N":5,"first_N_keywords":["Chinese","cc-by-4.0","1K - 10K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"observer","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JosephusCheung/observer","creator_name":"JosÃ©phus Cheung","creator_url":"https://huggingface.co/JosephusCheung","description":"Fine-tune GPT-3.5 to essentially act as an Observer, not answering questions but instead analyzing user inputs and providing instructions and assigning tasks to Answer GPT. This dataset consists of question-and-answer data from user queries on Quora (in English) and Zhihu (in Chinese) for the finetuned model of GPT-3.5.\\n","first_N":5,"first_N_keywords":["English","Chinese","gpl-3.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"autotrain-data-chinese-ner","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HsiangNianian/autotrain-data-chinese-ner","creator_name":"ç®€å¾‹çº¯","creator_url":"https://huggingface.co/HsiangNianian","description":"HsiangNianian/autotrain-data-chinese-ner dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"vm-training-data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jouryjc/vm-training-data","creator_name":"Jouryjc","creator_url":"https://huggingface.co/Jouryjc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jouryjc/vm-training-data.","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"yue-zh-translation","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/indiejoseph/yue-zh-translation","creator_name":"Joseph Cheng","creator_url":"https://huggingface.co/indiejoseph","description":"This dataset is comprised of:\\n\\nCrawled content that is machine translated from Cantonese to Simplified Chinese.\\nmachine translated articlse from zh-yue.wikipedia.org\\nbotisan-ai/cantonese-mandarin-translations\\nAlienKevin/LIHKG\\n\\n","first_N":5,"first_N_keywords":["translation","Yue Chinese","Chinese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"linghuchong","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chengli-thu/linghuchong","creator_name":"Cheng Li","creator_url":"https://huggingface.co/chengli-thu","description":"æ”¯æŒChatHaruhi2 çš„ä»¤ç‹å†²æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ–¹å¼è°ƒç”¨\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'chengli-thu/linghuchong', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='å°å¸ˆå¦¹', text = 'å†²å“¥ã€‚')\\nprint(response)\\n\\nä¸Šä¼ è€…: æé²é²\\næ›´å…·ä½“çš„ä¿¡æ¯ï¼Œè§ ChatHaruhi \\næ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„ ä¼—ç­¹è§’è‰²åˆ›å»ºé¡¹ç›®\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationå¼•ç”¨\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chengli-thu/linghuchong.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"xuzhu","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/xuzhu","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"æ”¯æŒChatHaruhi2 çš„è™šç«¹æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ–¹å¼è°ƒç”¨\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/xuzhu', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='åƒ§äºº', text = 'ä½ å¥½ï¼')\\nprint(response)\\n\\nä¸Šä¼ è€…: ç±³å”¯å®\\næ›´å…·ä½“çš„ä¿¡æ¯ï¼Œè§ ChatHaruhi \\næ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„ ä¼—ç­¹è§’è‰²åˆ›å»ºé¡¹ç›®\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationå¼•ç”¨\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}, \\n      author={Cheng Liâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/xuzhu.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"dingchunqiu","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/dingchunqiu","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"æ”¯æŒChatHaruhi2 çš„ä¸æ˜¥ç§‹æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ–¹å¼è°ƒç”¨\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/dingchunqiu', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='è§å³°', text = 'ä¸æ˜¥ç§‹ï¼')\\nprint(response)\\n\\nä¸Šä¼ è€…: ç±³å”¯å®\\næ›´å…·ä½“çš„ä¿¡æ¯ï¼Œè§ ChatHaruhi \\næ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„ ä¼—ç­¹è§’è‰²åˆ›å»ºé¡¹ç›®\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationå¼•ç”¨\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/dingchunqiu.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"xiaofeng","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/xiaofeng","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"æ”¯æŒChatHaruhi2 çš„è§å³°æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ–¹å¼è°ƒç”¨\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/xiaofeng', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='ä¸æ˜¥ç§‹', text = 'æ˜¯æˆ‘ï¼')\\nprint(response)\\n\\nä¸Šä¼ è€…: ç±³å”¯å®\\næ›´å…·ä½“çš„ä¿¡æ¯ï¼Œè§ ChatHaruhi \\næ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„ ä¼—ç­¹è§’è‰²åˆ›å»ºé¡¹ç›®\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationå¼•ç”¨\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/xiaofeng.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"jiumozhi","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/jiumozhi","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"æ”¯æŒChatHaruhi2 çš„é¸ æ‘©æ™ºæ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ–¹å¼è°ƒç”¨\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/jiumozhi', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='è§å³°', text = 'æ˜¯æˆ‘ï¼')\\nprint(response)\\n\\nä¸Šä¼ è€…: ç±³å”¯å®\\næ›´å…·ä½“çš„ä¿¡æ¯ï¼Œè§ ChatHaruhi \\næ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„ ä¼—ç­¹è§’è‰²åˆ›å»ºé¡¹ç›®\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationå¼•ç”¨\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/jiumozhi.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"guojing","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/guojing","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"æ”¯æŒChatHaruhi2 çš„éƒ­é–æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ–¹å¼è°ƒç”¨\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/guojing', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='æ¬§é˜³é”‹', text = 'æ˜¯æˆ‘ï¼')\\nprint(response)\\n\\nä¸Šä¼ è€…: ç±³å”¯å®\\næ›´å…·ä½“çš„ä¿¡æ¯ï¼Œè§ ChatHaruhi \\næ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„ ä¼—ç­¹è§’è‰²åˆ›å»ºé¡¹ç›®\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationå¼•ç”¨\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}, \\n      author={Chengâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/guojing.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"huangrong","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/huangrong","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"æ”¯æŒChatHaruhi2 çš„é»„è“‰æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ–¹å¼è°ƒç”¨\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/huangrong', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='éƒ­é–', text = 'è“‰å„¿ï¼')\\nprint(response)\\n\\nä¸Šä¼ è€…: ç±³å”¯å®\\næ›´å…·ä½“çš„ä¿¡æ¯ï¼Œè§ ChatHaruhi \\næ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„ ä¼—ç­¹è§’è‰²åˆ›å»ºé¡¹ç›®\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationå¼•ç”¨\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/huangrong.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ouyangfeng","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/ouyangfeng","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"æ”¯æŒChatHaruhi2 çš„æ¬§é˜³é”‹æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ–¹å¼è°ƒç”¨\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/ouyangfeng', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='éƒ­é–', text = 'æ¬§é˜³é”‹ï¼æ˜¯ä½ ï¼')\\nprint(response)\\n\\nä¸Šä¼ è€…: ç±³å”¯å®\\næ›´å…·ä½“çš„ä¿¡æ¯ï¼Œè§ ChatHaruhi \\næ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„ ä¼—ç­¹è§’è‰²åˆ›å»ºé¡¹ç›®\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationå¼•ç”¨\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/ouyangfeng.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"huangyaoshi","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/huangyaoshi","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"æ”¯æŒChatHaruhi2 çš„é»„è¯å¸ˆæ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ–¹å¼è°ƒç”¨\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/huangyaoshi', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='éƒ­é–', text = 'é»„è¯å¸ˆï¼æ˜¯ä½ ï¼')\\nprint(response)\\n\\nä¸Šä¼ è€…: ç±³å”¯å®\\næ›´å…·ä½“çš„ä¿¡æ¯ï¼Œè§ ChatHaruhi \\næ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„ ä¼—ç­¹è§’è‰²åˆ›å»ºé¡¹ç›®\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationå¼•ç”¨\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/huangyaoshi.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"zhouzhiruo","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/zhouzhiruo","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"æ”¯æŒChatHaruhi2 çš„å‘¨èŠ·è‹¥æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ–¹å¼è°ƒç”¨\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/zhouzhiruo', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='å¼ æ— å¿Œ', text = 'å‘¨èŠ·è‹¥ï¼')\\nprint(response)\\n\\nä¸Šä¼ è€…: ç±³å”¯å®\\næ›´å…·ä½“çš„ä¿¡æ¯ï¼Œè§ ChatHaruhi \\næ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„ ä¼—ç­¹è§’è‰²åˆ›å»ºé¡¹ç›®\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationå¼•ç”¨\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/zhouzhiruo.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"zhaomin","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/zhaomin","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"æ”¯æŒChatHaruhi2 çš„èµµæ•æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ–¹å¼è°ƒç”¨\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/zhaomin', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='å¼ æ— å¿Œ', text = 'èµµæ•ï¼')\\nprint(response)\\n\\nä¸Šä¼ è€…: ç±³å”¯å®\\næ›´å…·ä½“çš„ä¿¡æ¯ï¼Œè§ ChatHaruhi \\næ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„ ä¼—ç­¹è§’è‰²åˆ›å»ºé¡¹ç›®\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationå¼•ç”¨\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}, \\n      author={Chengâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/zhaomin.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"zhangwuji","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/zhangwuji","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"æ”¯æŒChatHaruhi2 çš„å¼ æ— å¿Œæ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ–¹å¼è°ƒç”¨\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/zhangwuji', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='èµµæ•', text = 'å¼ æ— å¿Œï¼')\\nprint(response)\\n\\nä¸Šä¼ è€…: ç±³å”¯å®\\næ›´å…·ä½“çš„ä¿¡æ¯ï¼Œè§ ChatHaruhi \\næ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„ ä¼—ç­¹è§’è‰²åˆ›å»ºé¡¹ç›®\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationå¼•ç”¨\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/zhangwuji.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"xiexun","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/xiexun","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"æ”¯æŒChatHaruhi2 çš„è°¢é€Šæ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ–¹å¼è°ƒç”¨\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/xiexun', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='å¼ æ— å¿Œ', text = 'è°¢é€Šï¼')\\nprint(response)\\n\\nä¸Šä¼ è€…: ç±³å”¯å®\\næ›´å…·ä½“çš„ä¿¡æ¯ï¼Œè§ ChatHaruhi \\næ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„ ä¼—ç­¹è§’è‰²åˆ›å»ºé¡¹ç›®\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationå¼•ç”¨\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}, \\n      author={Chengâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/xiexun.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"chinese-shepherd-critic-dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/frankminors123/chinese-shepherd-critic-dataset","creator_name":"Frank Jones","creator_url":"https://huggingface.co/frankminors123","description":"The dataset comes from the work introduced in \\\"Shepherd: A Critic for Language Model Generation\\\". We translated it into Simplified Chinese based on Google Translate, and made appropriate manual checks. We hope to do more valuable work in the Chinese field, and at the same time, we also hope that capable researchers can better check the sentences based on Chinese grammar or make further rewrites.\\n","first_N":5,"first_N_keywords":["text-generation","question-answering","Chinese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"testpatent","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Elliot4AI/testpatent","creator_name":"Jiang Elliot","creator_url":"https://huggingface.co/Elliot4AI","description":"test\\n","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"achinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"wu chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"yue-zh-translation","keyword":"yue chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/indiejoseph/yue-zh-translation","creator_name":"Joseph Cheng","creator_url":"https://huggingface.co/indiejoseph","description":"This dataset is comprised of:\\n\\nCrawled content that is machine translated from Cantonese to Simplified Chinese.\\nmachine translated articlse from zh-yue.wikipedia.org\\nbotisan-ai/cantonese-mandarin-translations\\nAlienKevin/LIHKG\\n\\n","first_N":5,"first_N_keywords":["translation","Yue Chinese","Chinese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"zhuang","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EntityCS\\n\\t\\n\\n\\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \\nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \\nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \\nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"tiger-sft-zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/tiger-sft-zh","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"Tigerbot å¼€æºé¡¹ç›®ä¸­å¾®è°ƒä¸­æ–‡sft-zhæ•°æ®åˆé›†\\næœ¬åˆé›†æ¶µç›–æœ¬ç»„ç»‡ä¸‹å¼€æºçš„å…¶ä»–ä¸­æ–‡sft-ä¸­æ–‡-æ•°æ®é›†ï¼Œä¸éœ€è¦é‡å¤ä¸‹è½½\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/sft_zh')\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ–‡ä»¶ç»†åˆ†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nç±»å‹\\nè¯­è¨€\\næ•°æ®é›†æ–‡ä»¶\\næ•°é‡\\n\\n\\n\\t\\t\\nalpaca ä¸­æ–‡\\nä¸­æ–‡\\ntigerbot-alpaca-zh-0.5m\\n500k\\n\\n\\nç™¾ç§‘é—®ç­”\\nä¸­æ–‡\\ntigerbot-wiki-qa-1k\\n1k\\n\\n\\nåè‘—é—®ç­”\\nä¸­æ–‡\\ntigerbot-book-qa-1k\\n1k\\n\\n\\nçŒœè°œè¯­\\nä¸­æ–‡\\ntigerbot-riddle-qa-1k\\n1k\\n\\n\\né˜…è¯»ç†è§£\\nä¸­æ–‡\\ntigerbot-superclue-c3-zh-5k\\n5k\\n\\n\\né—®ç­”\\nä¸­æ–‡\\ntigerbot-hc3-zh-12k\\n12k\\n\\n\\nçŸ¥ä¹é—®ç­”\\nä¸­æ–‡\\ntigerbot-zhihu-zh-10k\\n10k\\n\\n\\næµè¤sft\\nä¸­æ–‡\\ntigerbot-firefly-zh-20k\\n20k\\n\\n\\n\\t\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"liwu-MNBVC","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/liwu-MNBVC","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MNBVC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ä»‹ç»\\n\\t\\n\\nä¸­æ–‡äº’è”ç½‘ä¸Šæœ€å¤è€æœ€ç¥ç§˜(æ²¡æœ‰ä¹‹ä¸€)çš„é‡Œå±‹ç¤¾åŒºäº2023.1.1åº„é‡å®£å¸ƒ:\\nåœ¨è‹±æ˜ç¥æ­¦çš„é‡Œå±‹ç®¡å­å¸¦é¢†ä¸‹ï¼Œå†³å¿ƒå‘æŒ¥ç¤¾åŒºæ‰€é•¿(å“ªéƒ½é•¿)ï¼Œå¸®åŠ©å¼€æºç¤¾åŒºé•¿æœŸæ›´æ–°ä¸€ä»½æœ€å¤§çš„ä¸­æ–‡äº’è”ç½‘è¯­æ–™é›†ã€‚\\nHuggingfaceä¸Šçš„MNBVCæ•°æ®é›†åœ¨é€æ¸æ›´æ–°ä¸­ï¼Œè¯·åˆ°https://github.com/esbatmop/MNBVC è·å–æœªå®Œæˆæ¸…æ´—çš„æ›´å¤šæ•°æ®ã€‚\\nå¯ä»¥ä½¿ç”¨å¦‚ä¸‹è„šæœ¬åŠ è½½ï¼š\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"liwu/MNBVC\\\", 'law_judgement', split='train', streaming=True)\\n\\nnext(iter(dataset))  # get the first line\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®å­é›†\\n\\t\\n\\nMNBVCæ•°æ®é›†åŒ…å«æ•°ä¸ªå­é›†ï¼š\\n\\nlaw_judgement: æ¥è‡ªæ³•å¾‹æ–‡ä¹¦çš„æ–‡æœ¬ã€‚\\ngov_xuexiqiangguo: æ¥è‡ªå­¦ä¹ å¼ºå›½çš„æ–‡æœ¬ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/botp/liwu-MNBVC.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","other"],"keywords_longer_than_N":true},
	{"name":"dstc11.t4","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mario-rc/dstc11.t4","creator_name":"Mario RodrÃ­guez-Cantelar","creator_url":"https://huggingface.co/mario-rc","description":"\\n\\t\\n\\t\\t\\n\\t\\tDSTC11: Dialogue System Technology Challenge 11Track 4: Robust and Multilingual Automatic Evaluation Metrics for Open-Domain Dialogue Systems\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDirectory Structure Scheme\\n\\t\\n\\nRepresentation of the directory tree structure:\\n.\\nâ””â”€â”€ DSTC_11_Track_4             # DSTC11 data\\n    â”œâ”€â”€ task1                   # Multilingual metrics data\\n    â”‚       â”œâ”€â”€ train           # Train data (CHANEL/CDIAL datasets)\\n    â”‚       â”‚   â”œâ”€â”€ en_es       # English/Spanish data\\n    â”‚       â”‚   â”œâ”€â”€ en_zhâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mario-rc/dstc11.t4.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","apache-2.0","arxiv:2112.07194"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_regions","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Regions\\\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\\nKey Features:\\n\\nTextual Data: The dataset contains 500,000 text samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"huozi_rlhf_data_json","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Skepsun/huozi_rlhf_data_json","creator_name":"Skepsun","creator_url":"https://huggingface.co/Skepsun","description":"Converted from: https://github.com/HIT-SCIR/huozi\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"cvalues_rlhf","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Skepsun/cvalues_rlhf","creator_name":"Skepsun","creator_url":"https://huggingface.co/Skepsun","description":"Converted from: https://modelscope.cn/datasets/damo/CValues-Comparison/summary. We obtained harmless set by selecting pos_type=\\\"æ‹’ç»ä¸ºä¸»\\\" and neg_type=\\\"é£é™©å›å¤\\\". We obtained helpful set by selecting pos_type=\\\"æ‹’ç»&æ­£å‘å»ºè®®\\\" and neg_type=\\\"æ‹’ç»ä¸ºä¸»\\\".\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"zhihu_3k_rlhf_train","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/zhihu_3k_rlhf_train","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\n\\nsome rm data from public dataset\\n\\n\\nformat\\n\\n{\\n    \\\"history\\\": [\\n        \\\"query1\\\", \\\"answer1\\\",\\n        \\\"query2\\\", \\\"answer2\\\"\\n    ],\\n    \\\"prompt\\\": \\\"query\\\",\\n    \\\"input\\\": \\\"input for query\\\",\\n    \\\"output\\\": [\\n        \\\"output rank1\\\",\\n        \\\"output rank2\\\",\\n        \\\"output rank3\\\"\\n    ]\\n}\\n\\nThanks \\n\\nbeyond/rlhf-reward-single-round-trans_chinese : \\ndikw/hh_rlhf_cn\\nliyucheng/zhihu_rlhf_3k\\n\\n","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"chinese_chitchat","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qgyd2021/chinese_chitchat","creator_name":"æ™´è€•é›¨è¯»","creator_url":"https://huggingface.co/qgyd2021","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä¸­æ–‡é—²èŠæ•°æ®é›†\\n\\t\\n\\nrole çš„å–å€¼æœ‰: \\\"unknown\\\", \\\"human\\\", \\\"assistant\\\", ä¸‰ç§.\\næ•°æ®é›†ä»ç½‘ä¸Šæ”¶é›†æ•´ç†å¦‚ä¸‹:\\n\\n\\t\\n\\t\\t\\næ•°æ®\\nåŸå§‹æ•°æ®/é¡¹ç›®åœ°å€\\næ ·æœ¬ä¸ªæ•°\\nè¯­æ–™æè¿°\\næ›¿ä»£æ•°æ®ä¸‹è½½åœ°å€\\n\\n\\n\\t\\t\\nChatterBot\\nChatterBot; chatterbot-corpus\\n560\\næŒ‰ç±»å‹åˆ†ç±»ï¼Œè´¨é‡è¾ƒé«˜\\né˜¿é‡Œäº‘ç›˜; æå–ç : 81ao\\n\\n\\ndouban\\nDouban Conversation Corpus\\n352W\\næ¥è‡ªåŒ—èˆªå’Œå¾®è½¯çš„paper, å™ªéŸ³ç›¸å¯¹è¾ƒå°‘, å¤šè½®(å¹³å‡7.6è½®)\\né˜¿é‡Œäº‘ç›˜; æå–ç : 81ao\\n\\n\\nptt\\nPTTä¸­æ–‡èªæ–™\\n77W\\nå¼€æºé¡¹ç›®, å°æ¹¾PTTè®ºå›å…«å¦ç‰ˆ, ç¹ä½“, è¯­æ–™è¾ƒç”Ÿæ´»åŒ–, æœ‰å™ªéŸ³\\né˜¿é‡Œäº‘ç›˜; æå–ç : 81ao\\n\\n\\nqingyun\\né˜¿é‡Œäº‘ç›˜; æå–ç : 81ao\\n10W\\né’äº‘è¯­æ–™, ç›¸å¯¹ä¸é”™, ç”Ÿæ´»åŒ–\\n\\n\\n\\nsubtitle\\nç”µè§†å‰§å¯¹ç™½è¯­æ–™\\n274W\\næ¥è‡ªçˆ¬å–çš„ç”µå½±å’Œç¾å‰§çš„å­—å¹•, æœ‰ä¸€äº›å™ªéŸ³, ä¸ä¸¥è°¨çš„å¯¹è¯, è¯´è¯äººæ— æ³•å¯¹åº”èµ·æ¥, å¤šè½®(å¹³å‡5.3è½®)\\né˜¿é‡Œäº‘ç›˜; æå–ç : 81aoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qgyd2021/chinese_chitchat.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1M - 10M","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"zh_TW_c4","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DavidLanz/zh_TW_c4","creator_name":"David Lanz","creator_url":"https://huggingface.co/DavidLanz","description":"Language Models for Taiwanese Culture training dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@inproceedings{lin-chen-2023-llm,\\n    title = \\\"{LLM}-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models\\\",\\n    author = \\\"Lin, Yen-Ting  and Chen, Yun-Nung\\\",\\n    booktitle = \\\"Proceedings of the 5th Workshop on NLP for Conversational AI (NLP4ConvAI 2023)\\\",\\n    month = jul,\\n    year = \\\"2023\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DavidLanz/zh_TW_c4.","first_N":5,"first_N_keywords":["question-answering","summarization","text-generation","Chinese","English"],"keywords_longer_than_N":true},
	{"name":"school_math_0.25m-zhtw","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/erhwenkuo/school_math_0.25m-zhtw","creator_name":"Erhwen, Kuo","creator_url":"https://huggingface.co/erhwenkuo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"school_math_0.25m-zhtw\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tåŸå§‹è³‡æ–™é›†ä¾†æº\\n\\t\\n\\næœ¬è³‡æ–™é›†çš„åŸå§‹ä¾†æº: BelleGroup/school_math_0.25M\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå…§å®¹\\n\\t\\n\\nåŒ…å«ç´„25è¬æ¢ç”±BELLEé …ç›®ç”¢ç”Ÿçš„ä¸­æ–‡æ•¸å­¸é¡Œæ•¸æ“šï¼ŒåŒ…å«è§£é¡Œéç¨‹ã€‚\\næ³¨æ„ï¼šæ­¤è³‡æ–™é›†æ˜¯ç”±ChatGPTç”¢ç”Ÿçš„ï¼Œæœªç¶“åš´æ ¼æ ¡é©—ï¼Œå•é¡Œæˆ–è§£é¡Œéç¨‹å¯èƒ½åŒ…å«éŒ¯èª¤ã€‚ä½¿ç”¨éç¨‹ä¸­è«‹æ³¨æ„é€™ä¸€é»ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç¯„ä¾‹\\n\\t\\n\\n{\\n  \\\"instruction\\\": \\\"é¡Œç›®ï¼šå°è¯æ‰‹è£¡æœ‰ä¸€å€‹è£æ»¿ç³–æœçš„è¢‹å­ï¼Œå…±æœ‰ 12 å€‹ï¼Œå°æ˜æƒ³çŸ¥é“è£¡é¢æœ‰å¤šå°‘é¡†ç³–æœï¼Œæ–¼æ˜¯ä»–å•å°è¯ï¼šã€Œä½ æ‰‹è£¡çš„ç³–æœè¢‹è£¡æœ‰å¶æ•¸å€‹ç³–æœå—ï¼Ÿã€å°è¯ç­”ï¼šã€Œæœ‰ï¼Œè€Œä¸”å¤šæ–¼10é¡†ã€‚ã€è«‹å•å°è¯æ‰‹ä¸­çš„ç³–æœè¢‹è£¡æœ€å°‘æœ‰å¹¾é¡†ç³–æœï¼Ÿ\\\",\\n  \\\"input\\\": \\\",\\n  \\\"output\\\": \\\"\\\\nç”±é¡Œç›®å¯çŸ¥ï¼šå°è¯æ‰‹ä¸­çš„ç³–æœè¢‹è£¡æœ‰å¶æ•¸å€‹ç³–æœï¼›\\\\nåˆçŸ¥é“å°è¯æ‰‹ä¸­çš„ç³–æœè¢‹è£¡æœ‰å¤šå°‘æ–¼10ä»¶ç³–æœã€‚\\\\nå› ç‚ºç³–æœæ•¸ç‚ºå¶æ•¸ï¼Œå¤šæ–¼10ä»¶ï¼Œæ‰€ä»¥ç³–æœæ•¸é‡æœ€å°ä¸€å®šæ˜¯12ã€‚\\\\næ‰€ä»¥å°è¯æ‰‹ä¸­çš„ç³–æœè¢‹è£¡æœ€å°‘æœ‰12é¡†ç³–æœã€‚\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/erhwenkuo/school_math_0.25m-zhtw.","first_N":5,"first_N_keywords":["text2text-generation","Chinese","gpl-3.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"MultiCoNER","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tomaarsen/MultiCoNER","creator_name":"Tom Aarsen","creator_url":"https://huggingface.co/tomaarsen","description":"We present MultiCoNER, a large multilingual dataset for Named Entity Recognition that covers 3 domains (Wiki sentences, questions, and search queries) across 11 languages, as well as multilingual and code-mixing subsets. This dataset is designed to represent contemporary challenges in NER, including low-context scenarios (short and uncased text), syntactically complex entities like movie titles, and long-tail entity distributions. The 26M token dataset is compiled from public resources using techniques such as heuristic-based sentence sampling, template extraction and slotting, and machine translation. We applied two NER models on our dataset: a baseline XLM-RoBERTa model, and a state-of-the-art GEMNET model that leverages gazetteers. The baseline achieves moderate performance (macro-F1=54%), highlighting the difficulty of our data. GEMNET, which uses gazetteers, improvement significantly (average improvement of macro-F1=+30%). MultiCoNER poses challenges even for large pre-trained language models, and we believe that it can help further research in building robust NER systems. MultiCoNER is publicly available at https://registry.opendata.aws/multiconer/ and we hope that this resource will help advance research in various aspects of NER.","first_N":5,"first_N_keywords":["token-classification","Bengali","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"Baike-Astronomy-ZH","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/Baike-Astronomy-ZH","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"å¤©æ–‡å­¦ç™¾ç§‘ï¼ŒåŒ…å« 8 ä¸ªå­ç›®å½•ï¼Œçº¦ 1000 æ¡è¯æ¡ã€110,0000 ä¸ªå­—ç¬¦ã€‚\\næ•°æ®åŒ…å«ä¸€çº§ç›®å½•ã€äºŒçº§ç›®å½•ã€æ ‡é¢˜ã€å†…å®¹ã€‚å…¶ä¸­å†…å®¹å·²ç»å¤„ç†ä¸ºå•è¡Œï¼Œä¸”æ–‡æœ¬æ™®éè¾ƒé•¿ã€‚\\nä¸€ä¸ªæ ·ä¾‹å¦‚ä¸‹ï¼š\\n{\\n    \\\"top_category\\\": \\\"å¤©æ–‡å­¦\\\",\\n    \\\"sub_category\\\": \\\"å¤©ä½“åŠ›å­¦\\\",\\n    \\\"title\\\": \\\"ä¸‡æœ‰å¼•åŠ›å®šå¾‹\\\",\\n    \\\"content\\\": \\\"ä¸‡æœ‰å¼•åŠ›å®šå¾‹ï¼ˆæ±‰è¯­æ‹¼éŸ³ï¼šwÃ n yÇ’u yÇn lÃ¬ zhÄ« dÃ¬ng lÇœï¼‰ï¼Œï¼ˆuniversal gravitationï¼Œlaw ofï¼‰ï¼Œè‡ªç„¶ç•Œä¸­ä»»ä½•ä¸¤ä¸ªè´¨ç‚¹éƒ½ç›¸äº’å¸å¼•ï¼Œè¿™ä¸ªåŠ›åŒä¸¤ä¸ªè´¨ç‚¹çš„è´¨é‡çš„ä¹˜ç§¯æˆæ­£æ¯”ï¼ŒåŒå®ƒä»¬ä¹‹é—´çš„è·ç¦»çš„äºŒæ¬¡æ–¹æˆåæ¯”ã€‚å¦‚ç”¨m1ã€m2è¡¨ç¤ºä¸¤è´¨ç‚¹çš„è´¨é‡ï¼Œrè¡¨ç¤ºä¸¤è´¨ç‚¹é—´çš„è·ç¦»ï¼ŒFè¡¨ç¤ºä½œç”¨åŠ›çš„å€¼ï¼Œåˆ™Fï¼Gm1m2ï¼r2ï¼Œå¼ä¸­çš„Gæ˜¯æ¯”ä¾‹å¸¸é‡ï¼Œç§°ä¸‡æœ‰å¼•åŠ›å¸¸é‡æˆ–ç‰›é¡¿å¼•åŠ›å¸¸é‡ï¼Œæ•°å€¼å› ä¸åŒå•ä½åˆ¶è€Œå¼‚ï¼Œåœ¨å›½é™…å•ä½åˆ¶ä¸­Gä¸º6.672Ã—1011ç‰›é¡¿Â·ç±³2ï¼åƒå…‹2ã€‚è¿™ä¸ªå®šå¾‹ç”±ç‰›é¡¿äº1687å¹´åœ¨ã€ŠåŸç†ã€‹ä¸Šé¦–æ¬¡å‘è¡¨ï¼Œå®ƒå’Œç‰›é¡¿è¿åŠ¨å®šå¾‹ä¸€èµ·ï¼Œæ„æˆäº†ç‰›é¡¿åŠ›å­¦ç‰¹åˆ«æ˜¯å¤©ä½“åŠ›å­¦çš„åŸºç¡€ã€‚\\\\nâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mxode/Baike-Astronomy-ZH.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"MetricInstruct","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/MetricInstruct","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMetricInstruct\\n\\t\\n\\nThe MetricInstrcut dataset consists of 44K quadruple in the form of (instruction, input, system output, error analysis) for 6 text generation tasks and 22 text generation datasets. The dataset is used to fine-tune TIGERScore, a Trained metric that follows Instruction Guidance to perform Explainable, and Reference-free evaluation over a wide spectrum of text generation tasks.\\nProject Page | Paper | Code | Demo | \\nTIGERScore-7B | TIGERScore-13B\\nWe present theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/MetricInstruct.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","Czech","Russian"],"keywords_longer_than_N":true},
	{"name":"University-News-Instruction-Zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/University-News-Instruction-Zh","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"ä¸€äº›é«˜æ ¡æ ¡å›­æ–°é—»ï¼Œçº¦ 65k * 3(ç±»ä»»åŠ¡) æ¡ï¼Œç¨å¾®åšäº†ä¸€ç‚¹ç‚¹è„±æ•ï¼Œå°½å¯èƒ½åœ°é®ç›–äº†ä½œè€…åç­‰ã€‚æ•°æ®å·²ç»æ•´ç†æˆäº†æŒ‡ä»¤çš„å½¢å¼ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\\n{\\n    \\\"id\\\": <id>,\\n    \\\"category\\\": \\\"(title_summarize|news_classify|news_generate)\\\",\\n    \\\"instruction\\\": <å¯¹åº”çš„å…·ä½“æŒ‡ä»¤>,\\n    \\\"input\\\": <ç©º>,\\n    \\\"output\\\": <æŒ‡ä»¤å¯¹åº”çš„è¾“å‡º>\\n}\\n\\næ€»å…±ä¸‰ç±»ä»»åŠ¡ï¼šæ ‡é¢˜æ€»ç»“ã€æ ç›®åˆ†ç±»ã€æ–°é—»ç”Ÿæˆï¼Œæœ¬è´¨ä¸Šæ˜¯åˆ©ç”¨æ–°é—»å…ƒæ•°æ®ä¸­çš„æ ‡é¢˜ã€æ ç›®ã€å†…å®¹æ’åˆ—ç»„åˆç”Ÿæˆçš„ï¼Œæ‰€ä»¥å¯ä»¥ä¿è¯æ•°æ®å®Œå…¨å‡†ç¡®ã€‚æ¯ä¸ªå­—æ®µå†…å®¹å·²ç»æ•´ç†æˆäº†å•è¡Œçš„æ ¼å¼ã€‚ä¸‹é¢æ˜¯ä¸‰ç±»ä»»åŠ¡çš„æ ·ä¾‹ï¼š\\n// æ ‡é¢˜æ€»ç»“\\n{\\n    \\\"id\\\": 22106,\\n    \\\"category\\\": \\\"title_summarize\\\",\\n    \\\"instruction\\\": \\\"è¯·ä½ ç»™ä¸‹é¢çš„æ–°é—»å–ä¸€åˆ™æ ‡é¢˜ï¼š\\\\nç‚¹å‡»å›¾ç‰‡è§‚çœ‹è§†é¢‘â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mxode/University-News-Instruction-Zh.","first_N":5,"first_N_keywords":["zero-shot-classification","summarization","text-generation","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Chinese-Classics-Partial","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/Chinese-Classics-Partial","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"å¶ç„¶æ‰¾åˆ°çš„ 200 å¤šç¯‡å¤ç±ç›¸å…³çš„çº¯ txt æ–‡ä»¶ï¼Œç®€å•æ´—äº†ä¸€ä¸‹ï¼Œå»é™¤äº†éƒ¨åˆ†å™ªå£°å’Œç©ºç™½è¡Œã€‚\\nä¸€ç¯‡æ ·ä¾‹å¦‚ä¸‹ï¼š\\nå¤è®­ã€Šå¢å¹¿è´¤æ–‡ã€‹\\næ˜”æ—¶è´¤æ–‡ï¼Œè¯²æ±è°†è°†ï¼Œé›†éŸµå¢æ–‡ï¼Œå¤šè§å¤šé—»ã€‚\\nè§‚ä»Šå®œé‰´å¤ï¼Œæ— å¤ä¸æˆä»Šã€‚\\nçŸ¥å·±çŸ¥å½¼ï¼Œå°†å¿ƒæ¯”å¿ƒã€‚\\né…’é€¢çŸ¥å·±é¥®ï¼Œè¯—å‘ä¼šäººåŸã€‚\\nç›¸è¯†æ»¡å¤©ä¸‹ï¼ŒçŸ¥å¿ƒèƒ½å‡ äººã€‚\\nç›¸é€¢å¥½ä¼¼åˆç›¸è¯†ï¼Œåˆ°è€ç»ˆæ— æ€¨æ¨å¿ƒã€‚\\nè¿‘æ°´çŸ¥é±¼æ€§ï¼Œè¿‘å±±è¯†é¸ŸéŸ³ã€‚\\næ˜“æ¶¨æ˜“é€€å±±æºªæ°´ï¼Œæ˜“åæ˜“è¦†å°äººå¿ƒã€‚\\nè¿å»é‡‘æˆé“ï¼Œæ—¶æ¥é“ä¼¼é‡‘ï¼Œè¯»ä¹¦é¡»ç”¨æ„ï¼Œä¸€å­—å€¼åƒé‡‘ã€‚\\n\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"openassistant-guanaco-EOS","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Guanaco Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using \\\"### Human:\\\" AND \\\"### Assistant\\\" as the beginning and end of sequence tokens.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then slightly adjusted to:\\n\\n\\nif a row ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"sharegpt-deduplicated","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated","creator_name":"Caterina Lacerra","creator_url":"https://huggingface.co/CaterinaLac","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a deduplicated version of sharegpt4. \\nThe deduplication process has two steps:\\n\\nThe literal duplicates (both input and outputs) are removed\\nThe remaining (5749) instances are embedded with the SentenceTransformer library (\\\"paraphrase-multilingual-mpnet-base-v2\\\" model).\\nThen, we compute the cosine similarity among all the possible pairs, and consider paraphrases thoseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated.","first_N":5,"first_N_keywords":["English","Chinese","Korean","French","Japanese"],"keywords_longer_than_N":true},
	{"name":"openassistant-llama-style","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Llama 2 Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then filtered to:\\n\\n\\nreplace instances of '### Human:' with '[INST]'\\nreplaceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"hh_rlhf-chinese-zhtw","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/erhwenkuo/hh_rlhf-chinese-zhtw","creator_name":"Erhwen, Kuo","creator_url":"https://huggingface.co/erhwenkuo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"hh_rlhf-chinese-zhtw\\\"\\n\\t\\n\\næ­¤æ•¸æ“šé›†åˆä½µäº†ä¸‹åˆ—çš„è³‡æ–™:\\n\\né—œæ–¼æœ‰ç”¨ä¸”ç„¡å®³çš„äººé¡åå¥½æ•¸æ“šï¼Œä¾†è‡ª Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedbackã€‚é€™äº›æ•¸æ“šæ—¨åœ¨ç‚ºå¾ŒçºŒ RLHF è¨“ç·´è¨“ç·´åå¥½ï¼ˆæˆ–çå‹µï¼‰æ¨¡å‹ã€‚é€™äº›è³‡æ–™ä¸ç”¨æ–¼å°è©±ä»£ç†äººçš„ç›£ç£è¨“ç·´ã€‚æ ¹æ“šé€™äº›è³‡æ–™è¨“ç·´å°è©±ä»£ç†å¯èƒ½æœƒå°è‡´æœ‰å®³çš„æ¨¡å‹ï¼Œé€™ç¨®æƒ…æ³æ‡‰è©²é¿å…ã€‚\\näººå·¥ç”Ÿæˆä¸¦å¸¶è¨»é‡‹çš„ç´…éšŠå°è©±ï¼Œä¾†è‡ªæ¸›å°‘å±å®³çš„ç´…éšŠèªè¨€æ¨¡å‹ï¼šæ–¹æ³•ã€æ“´å±•è¡Œç‚ºå’Œç¶“é©—æ•™è¨“ã€‚é€™äº›æ•¸æ“šæ—¨åœ¨äº†è§£çœ¾åŒ…ç´…éšŠå¦‚ä½•å»ºæ¨¡ä»¥åŠå“ªäº›é¡å‹çš„ç´…éšŠæ”»æ“ŠæˆåŠŸæˆ–å¤±æ•—ã€‚é€™äº›æ•¸æ“šä¸ç”¨æ–¼å¾®èª¿æˆ–åå¥½å»ºæ¨¡ï¼ˆä½¿ç”¨ä¸Šé¢çš„æ•¸æ“šé€²è¡Œåå¥½å»ºæ¨¡ï¼‰ã€‚é€™äº›æ•¸æ“šæ˜¯å¾ä¸Šè¿°ç„¡å®³åå¥½å»ºæ¨¡æ•¸æ“šå°å‡ºçš„å°è©±çš„å®Œæ•´è½‰éŒ„æœ¬ï¼Œå…¶ä¸­åƒ…å°‡æ‰€é¸éŸ¿æ‡‰åˆä½µåˆ°æ•´å€‹è½‰éŒ„æœ¬ä¸­ã€‚æ­¤å¤–ï¼Œæ–‡å­—è¨˜éŒ„ä¹Ÿé€éäººå·¥å’Œè‡ªå‹•æ¸¬é‡ä¾†æ¨™è¨»æ•´å€‹å°è©±çš„å±å®³ç¨‹åº¦ã€‚\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tç‰¹åˆ¥æ³¨æ„â€¦ See the full description on the dataset page: https://huggingface.co/datasets/erhwenkuo/hh_rlhf-chinese-zhtw.","first_N":5,"first_N_keywords":["reinforcement-learning","Chinese","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"pretrain-sample","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hongyin/pretrain-sample","creator_name":"hongyin","creator_url":"https://huggingface.co/hongyin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPretrain\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset details\\n\\t\\n\\nLicense:\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Genealogy","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mmhzlrj/Genealogy","creator_name":"Jet Li","creator_url":"https://huggingface.co/mmhzlrj","description":"æ•°æ®é›†åŒ…å«äº†ä¸€æœ¬æ—è°±çš„å°é¢å’Œ164é¡µå†…å®¹ï¼Œæ˜¯ç«–ç‰ˆçš„ä¸­æ–‡ç®€ä½“å’Œç¹ä½“å­—çš„ç»„åˆã€‚\\nThe dataset contains the cover and 164 pages of a family tree, which is a combination of simplified and traditional Chinese characters in a vertical version.\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"ADL2023HW1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vanessa0688/ADL2023HW1","creator_name":"yangchiayueh","creator_url":"https://huggingface.co/vanessa0688","description":"task_categories:\\n-Paragraph Selection\\n-Span selection\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K<n<1M","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"MultiJail","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail","creator_name":"Language Technology Lab at Alibaba DAMO Academy","creator_url":"https://huggingface.co/DAMO-NLP-SG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Jailbreak Challenges in Large Language Models\\n\\t\\n\\nThis repo contains the data for our paper \\\"Multilingual Jailbreak Challenges in Large Language Models\\\".\\n[Github repo]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAnnotation Statistics\\n\\t\\n\\nWe collected a total of 315 English unsafe prompts and annotated them into nine non-English languages. The languages were categorized based on resource availability, as shown below:\\nHigh-resource languages: Chinese (zh), Italian (it), Vietnamese (vi)\\nMedium-resourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail.","first_N":5,"first_N_keywords":["English","Chinese","Italian","Vietnamese","Arabic"],"keywords_longer_than_N":true},
	{"name":"mqnli","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SachinPatel248/mqnli","creator_name":"Patel","creator_url":"https://huggingface.co/SachinPatel248","description":"SachinPatel248/mqnli dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","English","German","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"metricsubs-chunktranslate","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/metricv/metricsubs-chunktranslate","creator_name":"Metric-Void","creator_url":"https://huggingface.co/metricv","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repository holds the data file for translating TechLinked, which talks about mostly technology and science news.\\nRaw data is in the data/ folder. Scripts generate OpenAI's ChatCompletion Fine-tuning API formatted training data in jsonl format.\\n-2000 variants are designed to be used with GPT-3 with 8192 tokens context length limit. -8192 variants are designed to be used with GPT-4o mini with 128000 context window and 16384 max output tokens.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to addâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/metricv/metricsubs-chunktranslate.","first_N":5,"first_N_keywords":["text2text-generation","English","Chinese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"squad-cmrc2018-zhtw","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/erhwenkuo/squad-cmrc2018-zhtw","creator_name":"Erhwen, Kuo","creator_url":"https://huggingface.co/erhwenkuo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"squad-cmrc2018-zhtw\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè³‡æ–™é›†æ‘˜è¦\\n\\t\\n\\nCMRC 2018 æ˜¯ç¬¬äºŒå±†ã€Œè¨Šé£›ç›ƒã€ä¸­æ–‡æ©Ÿå™¨é–±è®€ç†è§£é ’çç ”è¨æœƒï¼ˆCMRC 2018ï¼‰ä¸­ç›¸é—œç«¶è³½æ‰€ä½¿ç”¨çš„è³‡æ–™é›†ã€‚\\nå®ƒä¸»è¦ç”¨æ–¼ä¸­æ–‡æ©Ÿå™¨é–±è®€ç†è§£çš„è·¨åº¦æå–è³‡æ–™é›†ï¼Œä»¥å¢åŠ è©²é ˜åŸŸçš„èªè¨€å¤šæ¨£æ€§ã€‚è©²è³‡æ–™é›†ç”±äººé¡å°ˆå®¶åœ¨ç¶­åŸºç™¾ç§‘æ®µè½ä¸Šè¨»é‡‹çš„è¿‘ 20,000 å€‹çœŸå¯¦å•é¡Œçµ„æˆã€‚\\nåŒæ™‚å®ƒä¹Ÿè¨»é‡‹äº†ä¸€å€‹æŒ‘æˆ°é›†ï¼Œå…¶ä¸­åŒ…å«éœ€è¦åœ¨æ•´å€‹ä¸Šä¸‹æ–‡ä¸­é€²è¡Œå…¨é¢ç†è§£å’Œå¤šå¥æ¨ç†çš„å•é¡Œã€‚\\nåŸå§‹è³‡æ–™ä¾†æº:\\n\\nhttps://hfl-rc.github.io/cmrc2018/\\nhttps://github.com/ymcui/cmrc2018\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè³‡æ–™ä¸‹è¼‰æ¸…ç†\\n\\t\\n\\n\\nä¸‹è¼‰ cmrc2018 è³‡æ–™é›†\\nä½¿ç”¨ OpenCC ä¾†é€²è¡Œç°¡ç¹è½‰æ›\\nä½¿ç”¨ Python æ­£è¦è¡¨ç¤ºå¼ä¾†æ¸…ç†ä¸€äº›æ®˜ç•™åœ¨ context, question, answer çš„ä¸å¿…è¦å­—å…ƒ\\næ ¹æ“š answers.text ä¾†é‡æ–°è¨ˆç®— answers.answer_start çš„å­—å…ƒä½ç½®\\nä½¿ç”¨â€¦ See the full description on the dataset page: https://huggingface.co/datasets/erhwenkuo/squad-cmrc2018-zhtw.","first_N":5,"first_N_keywords":["question-answering","Chinese","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"medical_pretrain","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DavidLanz/medical_pretrain","creator_name":"David Lanz","creator_url":"https://huggingface.co/DavidLanz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\nmedical_pretrain_tw.json: This dataset contains a total of 360,000 entries sourced from medical encyclopedia data from FreedomIntelligence/huatuo_encyclopedia_qa. These entries are a combination of questions and answers, forming text fields with coherent sentences. The dataset is intended for pre-training purposes to inject medical knowledge.\\n\\nmedical_book_zh.json: This dataset includes 8,475 entries sourced from text data in medical textbooks. The data source isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DavidLanz/medical_pretrain.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"medical_reward","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DavidLanz/medical_reward","creator_name":"David Lanz","creator_url":"https://huggingface.co/DavidLanz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Medical Dialogue Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\nmedical_reward_tw.json: This dataset consists of 4,000 entries derived from the Chinese Medical Dialogue dataset (Toyhom/Chinese-medical-dialogue-data). The questions in this dataset are randomly selected from the Chinese Medical Dialogue dataset. The \\\"response_chosen\\\" field contains responses from medical professionals in the Chinese Medical Dialogue dataset, while the \\\"response_rejected\\\" field contains responses fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DavidLanz/medical_reward.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MSVAMP","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mathoctopus/MSVAMP","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","description":"Mathoctopus/MSVAMP dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Bengali","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jasonshen8848/test","creator_name":"szx","creator_url":"https://huggingface.co/jasonshen8848","description":"jasonshen8848/test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","text","Text"],"keywords_longer_than_N":true},
	{"name":"Long-Instruction-with-Paraphrasing","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuyijiong/Long-Instruction-with-Paraphrasing","creator_name":"yuyijiong","creator_url":"https://huggingface.co/yuyijiong","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸ”¥ Updates\\n\\t\\n\\n[2024.6.4] Add a slim version. The sample number is reduced from about 20k to 10k.\\n[2024.5.28] \\n\\nThe data format is converted from \\\"chatml\\\" to \\\"messages\\\", which is more convenient to use tokenizer.apply_chat_template.  The old version has been moved to \\\"legacy\\\" branch.\\nThe version without \\\"Original text paraphrasing\\\" is added.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸ“Š Long Context Instruction-tuning dataset with \\\"Original text paraphrasing\\\"\\n\\t\\n\\n\\nPaper\\nGithub\\nconsist of multiple tasks\\nChineseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuyijiong/Long-Instruction-with-Paraphrasing.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","cc-by-sa-4.0","arxiv:2312.11193"],"keywords_longer_than_N":true},
	{"name":"for-test","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ziqin/for-test","creator_name":"yiziqin","creator_url":"https://huggingface.co/ziqin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFor TEST\\n\\t\\n\\nthis is a dataset for test\\njust for test...\\n","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"ntu_adl_summarization","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xjlulu/ntu_adl_summarization","creator_name":"Xue-Jin Lu","creator_url":"https://huggingface.co/xjlulu","description":"xjlulu/ntu_adl_summarization dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["summarization","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"achinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUDHR-LID\\n\\t\\n\\nWhy UDHR-LID?\\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \\\"missing\\\" or \\\"?\\\". Also, about 1/3 of the sentences consist only of \\\"articles 1-30\\\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","MetlatÃ³noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"mandarin chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUDHR-LID\\n\\t\\n\\nWhy UDHR-LID?\\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \\\"missing\\\" or \\\"?\\\". Also, about 1/3 of the sentences consist only of \\\"articles 1-30\\\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","MetlatÃ³noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"min nan chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUDHR-LID\\n\\t\\n\\nWhy UDHR-LID?\\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \\\"missing\\\" or \\\"?\\\". Also, about 1/3 of the sentences consist only of \\\"articles 1-30\\\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","MetlatÃ³noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"wu chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUDHR-LID\\n\\t\\n\\nWhy UDHR-LID?\\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \\\"missing\\\" or \\\"?\\\". Also, about 1/3 of the sentences consist only of \\\"articles 1-30\\\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","MetlatÃ³noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"blossom-wizard-v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-wizard-v1","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM WIZARD V1\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nBlossom Wizard V2ç‰ˆæœ¬å·²å‘å¸ƒï¼ğŸ¤—\\nBlossom Wizard V1æ˜¯ä¸€ä¸ªåŸºäºWizardLM_evol_instruct_V2è¡ç”Ÿè€Œæ¥çš„ä¸­è‹±åŒè¯­æŒ‡ä»¤æ•°æ®é›†ï¼Œé€‚ç”¨äºæŒ‡ä»¤å¾®è°ƒã€‚\\næœ¬æ•°æ®é›†ä»WizardLM_evol_instruct_V2ä¸­æŠ½å–äº†æŒ‡ä»¤ï¼Œé¦–å…ˆå°†å…¶ç¿»è¯‘ä¸ºä¸­æ–‡å¹¶æ ¡éªŒç¿»è¯‘ç»“æœï¼Œå†ä½¿ç”¨æŒ‡ä»¤è°ƒç”¨gpt-3.5-turbo-0613æ¨¡å‹ç”Ÿæˆå“åº”ï¼Œå¹¶è¿‡æ»¤æ‰åŒ…å«è‡ªæˆ‘è®¤çŸ¥ä»¥åŠæ‹’ç»å›ç­”çš„å“åº”ï¼Œä»¥ä¾¿åç»­å¯¹é½ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç¡®ä¿å“åº”é£æ ¼çš„ä¸€è‡´æ€§ä»¥åŠä¸­è‹±æ•°æ®é…æ¯”ï¼Œæœ¬æ•°æ®é›†è¿˜å¯¹æœªç¿»è¯‘çš„åŸå§‹æŒ‡ä»¤ä¹Ÿè¿›è¡Œäº†ç›¸åŒçš„è°ƒç”¨ï¼Œæœ€ç»ˆå¾—åˆ°äº†1:1çš„ä¸­è‹±åŒè¯­æŒ‡ä»¤æ•°æ®ã€‚\\nç›¸æ¯”ç›´æ¥å¯¹åŸå§‹Wizardè¿›è¡Œç¿»è¯‘çš„ä¸­æ–‡æ•°æ®é›†ï¼ŒBlossom Wizardçš„ä¸€è‡´æ€§åŠè´¨é‡æ›´é«˜ã€‚\\næœ¬æ¬¡å‘å¸ƒäº†å…¨é‡æ•°æ®çš„30%ï¼ŒåŒ…å«ä¸­è‹±åŒè¯­å„50Kï¼Œå…±è®¡100Kè®°å½•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€\\n\\t\\n\\nä»¥ä¸­æ–‡å’Œè‹±æ–‡ä¸ºä¸»ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-wizard-v1.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"blossom-orca-v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-orca-v1","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM ORCA V1\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nBlossom Orca V2ç‰ˆæœ¬å·²å‘å¸ƒï¼ğŸ¤—\\nBlossom Orca V1æ˜¯ä¸€ä¸ªåŸºäºOpenOrcaè¡ç”Ÿè€Œæ¥çš„ä¸­è‹±åŒè¯­æŒ‡ä»¤æ•°æ®é›†ï¼Œé€‚ç”¨äºæŒ‡ä»¤å¾®è°ƒã€‚\\næœ¬æ•°æ®é›†ä»OpenOrcaä¸­æŠ½å–äº†ç³»ç»Ÿæç¤ºå’ŒæŒ‡ä»¤ï¼Œé¦–å…ˆå°†å…¶ç¿»è¯‘ä¸ºä¸­æ–‡å¹¶æ ¡éªŒç¿»è¯‘ç»“æœï¼Œå†ä½¿ç”¨æŒ‡ä»¤è°ƒç”¨gpt-3.5-turbo-0613æ¨¡å‹ç”Ÿæˆå“åº”ï¼Œå¹¶è¿‡æ»¤æ‰åŒ…å«è‡ªæˆ‘è®¤çŸ¥ä»¥åŠæ‹’ç»å›ç­”çš„å“åº”ï¼Œä»¥ä¾¿åç»­å¯¹é½ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç¡®ä¿å“åº”é£æ ¼çš„ä¸€è‡´æ€§ä»¥åŠä¸­è‹±æ•°æ®é…æ¯”ï¼Œæœ¬æ•°æ®é›†è¿˜å¯¹æœªç¿»è¯‘çš„åŸå§‹æŒ‡ä»¤ä¹Ÿè¿›è¡Œäº†ç›¸åŒçš„è°ƒç”¨ï¼Œæœ€ç»ˆå¾—åˆ°äº†1:1çš„ä¸­è‹±åŒè¯­æŒ‡ä»¤æ•°æ®ã€‚\\nç›¸æ¯”ç›´æ¥å¯¹åŸå§‹OpenOrcaè¿›è¡Œç¿»è¯‘çš„ä¸­æ–‡æ•°æ®é›†ï¼ŒBlossom Orcaçš„ä¸€è‡´æ€§åŠè´¨é‡æ›´é«˜ã€‚\\næœ¬æ¬¡å‘å¸ƒäº†å…¨é‡æ•°æ®çš„30%ï¼ŒåŒ…å«ä¸­è‹±åŒè¯­å„100Kï¼Œå…±è®¡200Kè®°å½•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€\\n\\t\\n\\nä»¥ä¸­æ–‡å’Œè‹±æ–‡ä¸ºä¸»ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-orca-v1.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"seamless-align","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to use the data\\n\\t\\n\\nThere are two ways to access the data:\\n\\nVia the Hugging Face Python datasets library\\n\\nScripts coming soonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align.","first_N":5,"first_N_keywords":["translation","audio-to-audio","Maltese","English","Welsh"],"keywords_longer_than_N":true},
	{"name":"WEATHub","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iamshnoo/WEATHub","creator_name":"Anjishnu Mukherjee","creator_url":"https://huggingface.co/iamshnoo","description":"\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"WEATHub\\\"\\n\\t\\n\\nThis dataset corresponds to the data described in the paper \\\"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\\\"\\naccepted to EMNLP 2023.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)\\nto measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub.","first_N":5,"first_N_keywords":["Arabic","Bengali","Central Kurdish","Danish","German"],"keywords_longer_than_N":true},
	{"name":"fund-sft","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jannko/fund-sft","creator_name":"ko","creator_url":"https://huggingface.co/jannko","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jannko/fund-sft.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","10K<n<100K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"summary","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/twwch/summary","creator_name":"chenhao","creator_url":"https://huggingface.co/twwch","description":"å¾®è°ƒgoogle/mt5-baseæ¨¡å‹ï¼Œåšæ–‡ç« æ‘˜è¦\\nimport torch\\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\\n\\nmodel_path = \\\"twwch/mt5-base-summary\\\"\\nmodel = T5ForConditionalGeneration.from_pretrained(model_path)\\ntokenizer = T5Tokenizer.from_pretrained(model_path)\\n\\ndevice = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\\nmodel.to(device)\\nmodel.eval()\\n\\ntext = \\\"\\\"\\nä»€ä¹ˆæ˜¯Nginxâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/twwch/summary.","first_N":5,"first_N_keywords":["summarization","Chinese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"yue chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUDHR-LID\\n\\t\\n\\nWhy UDHR-LID?\\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \\\"missing\\\" or \\\"?\\\". Also, about 1/3 of the sentences consist only of \\\"articles 1-30\\\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","MetlatÃ³noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"M4LE","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wckwan/M4LE","creator_name":"Cyrus Kwan","creator_url":"https://huggingface.co/wckwan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nM4LE is a Multi-ability, Multi-range, Multi-task, bilingual benchmark for long-context evaluation. We categorize long-context understanding into five distinct abilities by considering whether it is required to identify single or multiple spans in long contexts based on explicit or semantic hints. Specifically, these abilities are explicit single-span, semantic single-span, explicit multiple-span, semantic multiple-span, and global. Different from previousâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wckwan/M4LE.","first_N":5,"first_N_keywords":["question-answering","translation","summarization","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"taiwanese-college-students","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/krishaamer/taiwanese-college-students","creator_name":"Kris Haamer","creator_url":"https://huggingface.co/krishaamer","description":"Anonymous survey responses by Taiwanese college students.\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","< 1K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"openassistant-falcon","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant Falcon\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using '\\\\Human:' AND '\\\\nAssistant:' to wrap user messages.\\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\\nSample \\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"djy","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Giacinta/djy","creator_name":"Giacinta Dummer","creator_url":"https://huggingface.co/Giacinta","description":"Giacinta/djy dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"weibo","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Giacinta/weibo","creator_name":"Giacinta Dummer","creator_url":"https://huggingface.co/Giacinta","description":"Giacinta/weibo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"chatgpt-paraphrases-zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pangda/chatgpt-paraphrases-zh","creator_name":"Shen Huang","creator_url":"https://huggingface.co/pangda","description":"This is a Chinese dataset of paraphrases created by ChatGPT.\\nFor English paraphrase dataset, you can refer to humarin/chatgpt-paraphrases.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWe used this prompt to generate paraphrases\\n\\t\\n\\nç»™ä¸‹é¢è¿™ä¸ªé—®é¢˜ç”Ÿæˆ5æ¡ç›¸ä¼¼çš„æ”¹å†™: {text}\\nThis dataset is based on the queries from Baidu and Zhihu.\\nWe generated 5 paraphrases for each sample, totally this dataset has about 238k data rows. You can make 30 rows from a row from each sample. In this way you can make 7.1 millions train pairs (238k rows with 5â€¦ See the full description on the dataset page: https://huggingface.co/datasets/pangda/chatgpt-paraphrases-zh.","first_N":5,"first_N_keywords":["Chinese","mit","100K<n<1M","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"PKU-PosterLayout","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/creative-graphic-design/PKU-PosterLayout","creator_name":"Creative Graphic Design Lab","creator_url":"https://huggingface.co/creative-graphic-design","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for PKU-PosterLayout\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPKU-PosterLayout is a new dataset and benchmark for content-aware visual-textual presentation layout.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe language data in PKU-PosterLayout is in Chinese (BCP-47 zh).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nimport datasets as ds\\n\\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/creative-graphic-design/PKU-PosterLayout.","first_N":5,"first_N_keywords":["other","expert-generated","found","extended|PosterErase","Chinese"],"keywords_longer_than_N":true},
	{"name":"lr-sum","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LR-Sum\\n\\t\\n\\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \\nThe data is based onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum.","first_N":5,"first_N_keywords":["summarization","text-generation","found","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"megawika-report-generation","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika for Report Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. \\nThis datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation.","first_N":5,"first_N_keywords":["summarization","text-retrieval","text-generation","text2text-generation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"chinese-icd","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eddielin0926/chinese-icd","creator_name":"Eddie Lin","creator_url":"https://huggingface.co/eddielin0926","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese International Statistical Classification of Diseases\\n\\t\\n\\n","first_N":5,"first_N_keywords":["text-classification","Chinese","English","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"ruozhiba-raw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kirp/ruozhiba-raw","creator_name":"kirp","creator_url":"https://huggingface.co/kirp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tå¼±æ™ºå§æ•°æ®é›† ruozhiba-raw\\n\\t\\n\\nå¼±æ™ºå§æ˜¯ç™¾åº¦è´´å§ä¸­çš„ä¸€ä¸ªéå¸¸å—æ¬¢è¿çš„è®ºå›ï¼Œä»¥åˆ›ä½œçŸ­å°ç²¾æ‚è€Œé—»åã€‚\\nè¿™é‡Œæ˜¯æˆªè‡³2023/11/10æ—¥å‰çš„raw dataã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTodo\\n\\t\\n\\n\\nget the top 5 answers to each post\\nclean the data\\na joke dataset(pure text/multimodal)\\na feasibility dataset\\na new benchmark for LLM\\n\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"ALMA-prompt-completion","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kristaller486/ALMA-prompt-completion","creator_name":"Kristaller486","creator_url":"https://huggingface.co/kristaller486","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ALMA-prompt-completion\\n\\t\\n\\n ALMA Dataset if format of prompt-completion\\n\\nCreated by: fe1ixxu\\nShared by: me\\nLanguage(s) (NLP): English, Czech, German, Russian, Islandic, Chinese\\nLicense: MIT\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [https://github.com/fe1ixxu/ALMA]\\nPaper [optional]: [https://arxiv.org/abs/2309.11674]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\nLLM translators\\n","first_N":5,"first_N_keywords":["translation","English","Russian","Czech","German"],"keywords_longer_than_N":true},
	{"name":"Kurisu","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/showchen/Kurisu","creator_name":"showchen","creator_url":"https://huggingface.co/showchen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChatHaruhi\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReviving Anime Character in Reality via Large Language Model\\n\\t\\n\\n\\n\\ngithub repo: https://github.com/LC1332/Chat-Haruhi-Suzumiya\\nChat-Haruhi-Suzumiyais a language model that imitates the tone, personality and storylines of characters like Haruhi Suzumiya,\\n\\n   The project was developed by Cheng Li, Ziang Leng, Chenxi Yan, Xiaoyang Feng, HaoSheng Wang, Junyi Shen, Hao Wang, Weishi Mi, Aria Fei, Song Yan, Linkang Zhan, Yaokai Jia, Pingyu Wu, and Haozhen Sun,etc.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/showchen/Kurisu.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","English","Chinese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"my_wb_preferences","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rjhuang/my_wb_preferences","creator_name":"rjhuang","creator_url":"https://huggingface.co/rjhuang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rjhuang/my_wb_preferences.","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"retrieval_qa","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lnwang/retrieval_qa","creator_name":"Luning Wang","creator_url":"https://huggingface.co/lnwang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRetrieval_QA: A Simple Multilingual Benchmark For Retrieval Encoder Models\\n\\t\\n\\n\\n\\nThe purpose of this dataset is to provide a simple and easy-to-use benchmark for retrieval encoder models, which helps researchers quickly select the most effective retrieval encoder for text extraction and achieve optimal results in subsequent retrieval tasks such as retrieval-augmented-generation (RAG). The dataset contains multiple document-question pairs, where each document is a short text aboutâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lnwang/retrieval_qa.","first_N":5,"first_N_keywords":["English","Chinese","Japanese","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"FAVDBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenNLPLab/FAVDBench","creator_name":"OpenNLPLab","creator_url":"https://huggingface.co/OpenNLPLab","description":"\\n\\n  FAVDBench: Fine-grained Audible Video Description\\n\\n\\n\\n\\n  ğŸ¤— Hugging Face â€¢\\n  ğŸ  GitHub â€¢\\n  ğŸ¤– OpenDataLab â€¢\\n  ğŸ’¬ Apply Dataset \\n\\n\\n\\n[CVPR2023] [Project Page] [arXiv] [Demo][BibTex] [ä¸­æ–‡ç®€ä»‹] \\n\\nIntroduction ç®€ä»‹\\nFiles æ–‡ä»¶\\nMD5 checksum\\nUpdates\\nLicense\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction ç®€ä»‹\\n\\t\\n\\nåœ¨CVPR2023ä¸­æˆ‘ä»¬æå‡ºäº†ç²¾ç»†åŒ–éŸ³è§†é¢‘æè¿°ä»»åŠ¡ï¼ˆFine-grained Audible Video Descriptionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenNLPLab/FAVDBench.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"wmt-mqm-error-spans","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RicardoRei/wmt-mqm-error-spans","creator_name":"Ricardo Costa Dias Rei","creator_url":"https://huggingface.co/RicardoRei","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains all MQM human annotations from previous WMT Metrics shared tasks and the MQM annotations from Experts, Errors, and Context in a form of error spans. Moreover, it contains some hallucinations used in the training of XCOMET models.\\nPlease note that this is not an official release of the data and the original data can be found here.\\nThe data is organised into 8 columns:\\n\\nsrc: input text\\nmt: translation\\nref: reference translation\\nannotations:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-mqm-error-spans.","first_N":5,"first_N_keywords":["English","German","Russian","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"couplet-json","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stuser2023/couplet-json","creator_name":"tc lin","creator_url":"https://huggingface.co/stuser2023","description":"[å°è¯æ•¸æ“šé›†]\\n\\nåŸå§‹æ•¸æ“šé›†ä¾†è‡ªgithub: https://github.com/wb14123/couplet-dataset/\\n\\nç¹ç°¡é«”ä¸­æ–‡è½‰æ›ï¼Œä½¿ç”¨(OpenCC): https://github.com/yichen0831/opencc-python\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlicense: apache-2.0\\n\\t\\n\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"Pontoon-Translations","keyword":"chinese","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","text2text-generation","crowdsourced","Abkhaz","Achinese"],"keywords_longer_than_N":true},
	{"name":"HuatuoGPT2-SFT-GPT4-140K","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/HuatuoGPT2-SFT-GPT4-140K","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHuatuoGPT2-SFT-GPT4-140K\\n\\t\\n\\n140K Chinese medical instructions generated by GPT-4, based on questions from HuatuoGPT Dataset.\\nThis dataset contains supervised fine-tuning instructions for HuatuoGPT2, designed to enhance the model's ability to follow instructions in real medical scenarios. We have made all the data (142,248 entries) in this dataset publicly available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRepository\\n\\t\\n\\n\\nGithub: https://github.com/FreedomIntelligence/HuatuoGPT-II\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/HuatuoGPT2-SFT-GPT4-140K.","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","arxiv:2311.09774"],"keywords_longer_than_N":true},
	{"name":"RenMinDaily","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Concyclics/RenMinDaily","creator_name":"CHEN Han","creator_url":"https://huggingface.co/Concyclics","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nIt is the collection of RenMinDaily's report from 2021/01/01 to 2023/12/05. With title as instruction.\\n","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"mmlu_recall","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/itsliupeng/mmlu_recall","creator_name":"Liu Peng","creator_url":"https://huggingface.co/itsliupeng","description":"Employ mmlu (cmmlu) questions as initial seeds to retrieve related articles from multiple training data corpora such as Chinese CommonCrawl, WeChat, and Faclon. These selected articles will be utilized as a training set for mmlu. The goal is to determine whether this training set can improve the relevant mmlu performance metrics.\\nFor emb_recall: We use sentence-transformers to generate embeddings and apply a filter for those with a cosine distance greater than 0.95. The content is mainlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/itsliupeng/mmlu_recall.","first_N":5,"first_N_keywords":["table-question-answering","English","Chinese","apache-2.0","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"Pontoon-Translations","keyword":"achinese","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","text2text-generation","crowdsourced","Abkhaz","Achinese"],"keywords_longer_than_N":true},
	{"name":"Pontoon-Translations","keyword":"min nan chinese","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","text2text-generation","crowdsourced","Abkhaz","Achinese"],"keywords_longer_than_N":true},
	{"name":"Pontoon-Translations","keyword":"yue chinese","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","text2text-generation","crowdsourced","Abkhaz","Achinese"],"keywords_longer_than_N":true},
	{"name":"Uni-Encoder","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ChiyuSONG/Uni-Encoder","creator_name":"Chiyu Song","creator_url":"https://huggingface.co/ChiyuSONG","description":"\\n  ğŸ’» [Github Repo] â€¢ ğŸ“ƒ [Paper]\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis a collection of datasets used in the paper titled \\\"Uni-Encoder: A Fast and Accurate Response Selection Paradigm for Generation-Based Dialogue Systems\\\".\\nThe following datasets have been included:\\n\\nUbuntu Corpus V1\\nUbuntu Corpus V2\\nPersonaChat\\nDouban Conv Corpus\\n\\nAll datasets have been standardized to a unified format for research need.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@inproceedings{song2023uni,\\n  title={Uni-encoder: A fast and accurateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChiyuSONG/Uni-Encoder.","first_N":5,"first_N_keywords":["English","Chinese","mit","arxiv:2106.01263","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"ddm","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Chiwei/ddm","creator_name":"Che","creator_url":"https://huggingface.co/Chiwei","description":"Chiwei/ddm dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"ChatHaruhi-Waifu","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/ChatHaruhi-Waifu","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"æœ¬æ•°æ®é›†æ˜¯ä¸ºäº†éƒ¨åˆ†ä¸é€‚åˆç›´æ¥æ˜¾ç¤ºçš„è§’è‰²è¿›è¡Œhugging faceå­˜å‚¨ã€‚textéƒ¨åˆ†åšäº†ç®€å•çš„ç¼–ç åŠ å¯†\\nä½¿ç”¨æ–¹æ³•\\nè½½å…¥å‡½æ•°\\nfrom transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\\ntokenizer = AutoTokenizer.from_pretrained(\\\"silk-road/Chat-Haruhi_qwen_1_8\\\", trust_remote_code=True)\\nmodel = AutoModelForCausalLM.from_pretrained(\\\"silk-road/Chat-Haruhi_qwen_1_8\\\", trust_remote_code=True).half().cuda()\\nmodel = model.eval()\\n\\nå…·ä½“çœ‹https://github.com/LC1332/Chat-Haruhi-Suzumiya/blob/main/notebook/ChatHaruhi_x_Qwen1_8B.ipynb è¿™ä¸ªnotebook\\nfrom ChatHaruhiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/silk-road/ChatHaruhi-Waifu.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Verified-Camel-zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/noobmaster29/Verified-Camel-zh","creator_name":"Victor Sung","creator_url":"https://huggingface.co/noobmaster29","description":"This is a direct Chinese translation using GPT4 of the Verified-Camel dataset. I hope you find it useful. \\nhttps://huggingface.co/datasets/LDJnr/Verified-Camel\\nCitation:\\n@article{daniele2023amplify-instruct,\\n  title={Amplify-Instruct: Synthetically Generated Diverse Multi-turn Conversations for Effecient LLM Training.},\\n  author={Daniele, Luigi and Suphavadeeprasit},\\n  journal={arXiv preprint arXiv:(comming soon)},\\n  year={2023}\\n}\\n\\n","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"cszs_zh_en","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ky552/cszs_zh_en","creator_name":"speech552_ky","creator_url":"https://huggingface.co/ky552","description":"This dataset contains the Mandarin-English track of the benchmark from ICASSP 2024: Zero Resource Code-Switched Speech Benchmark Using Speech Utterance Pairs for Multiple Spoken Languages.Though the benchmark is originally designed to assess the semantic and syntactic abilities of the speech foundation models, you can also use this dataset for code-switching ASR.\\nIf you find this dataset helpful, please consider to cite the following paper:\\n@INPROCEEDINGS{10446737,\\n  author={Huang, Kuan-Po andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ky552/cszs_zh_en.","first_N":5,"first_N_keywords":["Chinese","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"cotinus-poem","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/cotinus-poem","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\n\\t\\n\\t\\t\\n\\t\\tæ•°æ®æ ¼å¼å®šä¹‰\\n\\t\\n\\nfrom pydantic import BaseModel, Field\\n\\nclass PoemValidator(BaseModel):\\n    title: str = Field(..., description=\\\"è¯—å\\\")\\n    author: str = Field(..., description=\\\"ä½œè€…\\\")\\n    dynasty: str = Field(..., description=\\\"æœä»£\\\")\\n    theme: str = Field(..., description=\\\"ä¸»é¢˜\\\")\\n    section: str = Field(..., description=\\\"èŠ‚å\\\")\\n    content: Union[list[dict[str, Union[str, list[str]]]]] = Field(..., description=\\\"è¯—å†…å®¹\\\")  #\\n    appreciation: str = Field(..., description=\\\"èµæ\\\")\\n    rhythmic: str =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ticoAg/cotinus-poem.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Slim-COIG-Kun","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lorinma/Slim-COIG-Kun","creator_name":"Nuo","creator_url":"https://huggingface.co/lorinma","description":"\\nThis is a Slim version of COIG-Kun\\nå› ä¸ºåŸå§‹çš„æ•°æ®é›†æœ‰53ä¸‡æ¡ä¹‹å¤šï¼Œæ‰€ä»¥è¿›è¡Œäº†subsampleã€‚\\né‡‡æ ·æ–¹æ³•å¤§è‡´ä¸ºï¼Œä½¿ç”¨bert-base-chineseå°†Instructionè½¬æ¢ä¸ºembeddingï¼Œä½¿ç”¨ç±»knnçš„æ–¹æ³•æŠ½å–äº†1ä¸‡æ¡ã€‚å¹¶è½¬æ¢æˆäº†sharegptæ ¼å¼ã€‚ \\nä¸ºäº†æ›´ç›´è§‚çš„æŸ¥çœ‹æ•ˆæœï¼Œæ–‡ä»¶ä¸­è¿˜æœ‰ä¸€ä¸ªä»…é‡‡æ ·äº†1åƒæ¡çš„ç‰ˆæœ¬ã€‚é‡‡æ ·å‰åçš„Embeddingä½¿ç”¨tsneè¿›è¡Œå¯è§†åŒ–ã€‚\\n\\noriginal Kun(è“è‰²)å’ŒMoss003ï¼ˆçº¢è‰²ï¼‰çš„åŒºåˆ«ï¼Œæ˜¯å¦å¯è§£è¯»ä¸ºè™½ç„¶Kunçš„æ•°é‡å¾ˆé«˜ï¼Œä½†æ˜¯é¦–ä¸ªinstructionçš„è¯­ä¹‰å¤šæ ·åŒ–ä¸å¦‚Mossã€‚ï¼ˆåè®°ï¼šè¿™ä¸ªåœ°æ–¹ä¸åº”è¯¥ç”¨tsneçš„ï¼Œç±»è§åº”è¯¥ç”¨umapä¸è¿‡anywayå‡‘æ´»ç€çœ‹å§æ˜¯é‚£ä¸ªæ„æ€\\n\\n","first_N":5,"first_N_keywords":["question-answering","Chinese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"uner_llm_instructions","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/universalner/uner_llm_instructions","creator_name":"Universal NER","creator_url":"https://huggingface.co/universalner","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Universal NER v1 in the Aya format\\n\\t\\n\\nThis dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the same CC-BY-SA 4.0 license and conditions.\\nIt contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.\\nThe dataset contains different subsets and their dev/test/train splits, depending on language. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you utilize this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/universalner/uner_llm_instructions.","first_N":5,"first_N_keywords":["token-classification","Cebuano","Danish","German","English"],"keywords_longer_than_N":true},
	{"name":"openai-formate-function-calling-small","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Deepexi/openai-formate-function-calling-small","creator_name":"Deepexi Inc","creator_url":"https://huggingface.co/Deepexi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†å†…å®¹è¯´æ˜:\\n\\t\\n\\nåŒ…å«700+ä¸ªé˜¿é‡Œäº‘OpenAPIçš„ä¿¡æ¯;åŒ…æ‹¬Dataworks,EMRï¼ŒDataLakeï¼ŒMaxcomputeï¼ŒHologram,å®æ—¶è®¡ç®—Flinkç‰ˆï¼ŒQuickBI,DTSç­‰å¤šä¸ªäº§å“çš„å…¬å¼€Open APIä¿¡æ¯ã€‚\\n Functionsä¿¡æ¯ä¸OpenAI functions calling èƒ½åŠ›ä¸­ï¼Œfunctionsä¿¡æ¯ä¼ å…¥çš„æ ¼å¼ä¿æŒä¸€è‡´ \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ ·ä¾‹\\n\\t\\n\\n{\\n  \\\"systemPrompt\\\": ä½ æ˜¯ä¸€ä¸ªå‡½æ•°ç­›é€‰åŠ©ç†ï¼Œå¦‚æœä¸é—®é¢˜ç›¸å…³çš„è¯,æ‚¨å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„å‡½æ•°æ¥è·å–æ›´å¤šæ•°æ®ä»¥å›ç­”ç”¨æˆ·æå‡ºçš„é—®é¢˜:{\\\"name\\\": \\\"UpdateTicketNum\\\", \\\"description\\\": \\\"å¯¹ç”¨äºå…ç™»åµŒå…¥æŠ¥è¡¨çš„æŒ‡å®šçš„ticketè¿›è¡Œæ›´æ–°ç¥¨æ®æ•°é‡æ“ä½œã€‚\\\", \\\"parameters\\\": {\\\"type\\\": \\\"object\\\", \\\"properties\\\": [{\\\"Ticket\\\": {\\\"type\\\": \\\"string\\\", \\\"description\\\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Deepexi/openai-formate-function-calling-small.","first_N":5,"first_N_keywords":["Chinese","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"uner_llm_inst_chinese","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/universalner/uner_llm_inst_chinese","creator_name":"Universal NER","creator_url":"https://huggingface.co/universalner","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Universal NER v1 in the Aya format - Chinese subset\\n\\t\\n\\nThis dataset is a format conversion for the Chinese data in the original Universal NER v1 into the Aya instruction format and it's released here under the same CC-BY-SA 4.0 license and conditions.\\nThe dataset contains different subsets and their dev/test/train splits, depending on language. For more details, please refer to:\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nFor the original Universal NER dataset v1 and moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/universalner/uner_llm_inst_chinese.","first_N":5,"first_N_keywords":["token-classification","Chinese","cc-by-sa-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ntx_llm_instructions","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format\\n\\t\\n\\nThis dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license and conditions.\\nIt contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you utilize this dataset version, feel free to cite/footnote this huggingface dataset repo, but please also cite the original datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions.","first_N":5,"first_N_keywords":["token-classification","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"ntx_llm_inst_chinese","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_chinese","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format - Chinese subset\\n\\t\\n\\nThis dataset is a format conversion for the Chinese data from the original NTX into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nFor the original NTX dataset, the conversion to the Aya instructions format, or more details, please refer to the full dataset in instruction form (https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions) or to theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_chinese.","first_N":5,"first_N_keywords":["token-classification","Chinese","cc-by-sa-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"blossom-orca-v2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-orca-v2","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM ORCA V2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nBlossom Orca V2æ˜¯ä¸€ä¸ªåŸºäºOpenOrcaè¡ç”Ÿè€Œæ¥çš„ä¸­è‹±åŒè¯­æŒ‡ä»¤æ•°æ®é›†ï¼Œé€‚ç”¨äºæŒ‡ä»¤å¾®è°ƒã€‚\\nç›¸æ¯”äºblossom-wizard-v1ï¼ŒæŒ‡ä»¤ä¸å˜ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–äº†è¾“å‡ºæ•ˆæœï¼Œæ­¤å¤–ï¼Œå°†systemæ¶ˆæ¯å¹¶å…¥useræ¶ˆæ¯ä¸­ã€‚\\næœ¬æ•°æ®é›†ä»OpenOrcaä¸­æŠ½å–äº†ç³»ç»Ÿæç¤ºå’ŒæŒ‡ä»¤ï¼Œé¦–å…ˆå°†å…¶ç¿»è¯‘ä¸ºä¸­æ–‡å¹¶æ ¡éªŒç¿»è¯‘ç»“æœï¼Œå†ä½¿ç”¨æŒ‡ä»¤è°ƒç”¨gpt-3.5-turbo-0613æ¨¡å‹ç”Ÿæˆå“åº”ï¼Œå¹¶è¿‡æ»¤æ‰åŒ…å«è‡ªæˆ‘è®¤çŸ¥ä»¥åŠæ‹’ç»å›ç­”çš„å“åº”ï¼Œä»¥ä¾¿åç»­å¯¹é½ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç¡®ä¿å“åº”é£æ ¼çš„ä¸€è‡´æ€§ä»¥åŠä¸­è‹±æ•°æ®é…æ¯”ï¼Œæœ¬æ•°æ®é›†è¿˜å¯¹æœªç¿»è¯‘çš„åŸå§‹æŒ‡ä»¤ä¹Ÿè¿›è¡Œäº†ç›¸åŒçš„è°ƒç”¨ï¼Œæœ€ç»ˆå¾—åˆ°äº†1:1çš„ä¸­è‹±åŒè¯­æŒ‡ä»¤æ•°æ®ã€‚\\nç›¸æ¯”ç›´æ¥å¯¹åŸå§‹OpenOrcaè¿›è¡Œç¿»è¯‘çš„ä¸­æ–‡æ•°æ®é›†ï¼ŒBlossom Orcaçš„ä¸€è‡´æ€§åŠè´¨é‡æ›´é«˜ã€‚\\næœ¬æ¬¡å‘å¸ƒäº†å…¨é‡æ•°æ®çš„30%ï¼ŒåŒ…å«ä¸­è‹±åŒè¯­å„100Kï¼Œå…±è®¡200Kè®°å½•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€\\n\\t\\n\\nä»¥ä¸­æ–‡å’Œè‹±æ–‡ä¸ºä¸»ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-orca-v2.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"blossom-wizard-v2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-wizard-v2","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM WIZARD V2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nBlossom Wizard V2æ˜¯ä¸€ä¸ªåŸºäºWizardLM_evol_instruct_V2è¡ç”Ÿè€Œæ¥çš„ä¸­è‹±åŒè¯­æŒ‡ä»¤æ•°æ®é›†ï¼Œé€‚ç”¨äºæŒ‡ä»¤å¾®è°ƒã€‚\\nç›¸æ¯”äºblossom-wizard-v1ï¼ŒæŒ‡ä»¤ä¸å˜ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–äº†è¾“å‡ºæ•ˆæœã€‚\\næœ¬æ•°æ®é›†ä»WizardLM_evol_instruct_V2ä¸­æŠ½å–äº†æŒ‡ä»¤ï¼Œé¦–å…ˆå°†å…¶ç¿»è¯‘ä¸ºä¸­æ–‡å¹¶æ ¡éªŒç¿»è¯‘ç»“æœï¼Œå†ä½¿ç”¨æŒ‡ä»¤è°ƒç”¨gpt-3.5-turbo-0613æ¨¡å‹ç”Ÿæˆå“åº”ï¼Œå¹¶è¿‡æ»¤æ‰åŒ…å«è‡ªæˆ‘è®¤çŸ¥ä»¥åŠæ‹’ç»å›ç­”çš„å“åº”ï¼Œä»¥ä¾¿åç»­å¯¹é½ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç¡®ä¿å“åº”é£æ ¼çš„ä¸€è‡´æ€§ä»¥åŠä¸­è‹±æ•°æ®é…æ¯”ï¼Œæœ¬æ•°æ®é›†è¿˜å¯¹æœªç¿»è¯‘çš„åŸå§‹æŒ‡ä»¤ä¹Ÿè¿›è¡Œäº†ç›¸åŒçš„è°ƒç”¨ï¼Œæœ€ç»ˆå¾—åˆ°äº†1:1çš„ä¸­è‹±åŒè¯­æŒ‡ä»¤æ•°æ®ã€‚\\nç›¸æ¯”ç›´æ¥å¯¹åŸå§‹Wizardè¿›è¡Œç¿»è¯‘çš„ä¸­æ–‡æ•°æ®é›†ï¼ŒBlossom Wizardçš„ä¸€è‡´æ€§åŠè´¨é‡æ›´é«˜ã€‚\\næœ¬æ¬¡å‘å¸ƒäº†å…¨é‡æ•°æ®çš„30%ï¼ŒåŒ…å«ä¸­è‹±åŒè¯­å„50Kï¼Œå…±è®¡100Kè®°å½•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€\\n\\t\\n\\nä»¥ä¸­æ–‡å’Œè‹±æ–‡ä¸ºä¸»ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-wizard-v2.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ChatHaruhi-RolePlaying","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/ChatHaruhi-RolePlaying","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChatHaruhi\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReviving Anime Character in Reality via Large Language Model\\n\\t\\n\\nChat-Haruhi-Suzumiyais a language model that imitates the tone, personality and storylines of characters like Haruhi Suzumiya,\\nhttps://github.com/LC1332/Chat-Haruhi-Suzumiya\\nUsing this to load character and chat with him/her\\nfrom ChatHaruhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = \\\"silk-road/ChatHaruhi-RolePlaying/haruhi\\\",\\\\\\n                      llm = 'openai' ,\\\\â€¦ See the full description on the dataset page: https://huggingface.co/datasets/silk-road/ChatHaruhi-RolePlaying.","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ml-kge","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davanstrien/ml-kge","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMKGE: Multilingual Knowledge Graph Enhancement\\n\\t\\n\\nnote this dataset card was copied from this GitHub Repository\\nTask Description |\\nWikiKGE-10 |\\nEvaluation |\\nPaper |\\nCitation |\\nLicense\\nRecent work in Natural Language Processing and Computer Vision has been leveraging textual information -- e.g., entity names and descriptions -- available in knowledge graphs to ground neural models to high-quality structured data.\\nHowever, when it comes to non-English languages, both quantity andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/davanstrien/ml-kge.","first_N":5,"first_N_keywords":["English","Arabic","German","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"blossom-math-v3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-math-v3","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM MATH V3\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nBlossom Math V3æ˜¯åŸºäºMath23Kå’ŒGSM8Kè¡ç”Ÿè€Œæ¥çš„ä¸­è‹±åŒè¯­æ•°å­¦å¯¹è¯æ•°æ®é›†ï¼Œé€‚ç”¨äºæ•°å­¦é—®é¢˜å¾®è°ƒã€‚\\nç›¸æ¯”äºblossom-math-v2ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–äº†æ•°æ®å¤„ç†æµç¨‹ï¼Œå¹¶å¼ºåŒ–ç­”æ¡ˆæ£€æŸ¥ã€‚\\næœ¬æ•°æ®é›†é‡‡ç”¨å…¨é‡Math23Kã€GSM8Kå’Œç¿»è¯‘åçš„GSM8Kçš„é—®é¢˜ï¼Œéšåè°ƒç”¨gpt-3.5-turbo-0613ç”Ÿæˆç»“æœï¼Œå¹¶ä½¿ç”¨åŸå§‹æ•°æ®é›†ä¸­çš„ç­”æ¡ˆå¯¹ç”Ÿæˆçš„ç»“æœè¿›è¡ŒéªŒè¯ï¼Œè¿‡æ»¤æ‰é”™è¯¯ç­”æ¡ˆï¼Œå¾ˆå¤§ç¨‹åº¦ä¸Šä¿è¯äº†é—®é¢˜å’Œç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚\\næœ¬æ¬¡å‘å¸ƒäº†å…¨é‡æ•°æ®çš„25%ï¼ŒåŒ…å«10Kè®°å½•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€\\n\\t\\n\\nä¸­æ–‡å’Œè‹±æ–‡\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„\\n\\t\\n\\næ¯æ¡æ•°æ®ä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„é¢˜ç›®åŠç­”æ¡ˆï¼ŒåŒ…å«idã€inputã€outputã€answerã€datasetå››ä¸ªå­—æ®µã€‚\\n\\nidï¼šå­—ç¬¦ä¸²ï¼Œä»£è¡¨åŸå§‹æ•°æ®é›†ä¸­çš„é¢˜ç›®idï¼Œä¸datasetå­—æ®µç»“åˆå¯ç¡®å®šå”¯ä¸€é¢˜ç›®ã€‚\\ninputï¼šå­—ç¬¦ä¸²ï¼Œä»£è¡¨é—®é¢˜ã€‚\\noutputï¼šå­—ç¬¦ä¸²ï¼Œä»£è¡¨gpt-3.5-turbo-0613ç”Ÿæˆçš„ç­”æ¡ˆã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-math-v3.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"csc","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Weaxs/csc","creator_name":"Weaxs","creator_url":"https://huggingface.co/Weaxs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset for CSC\\n\\t\\n\\nä¸­æ–‡çº é”™æ•°æ®é›†\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nChinese Spelling Correction (CSC) is a task to detect and correct misspelled characters in Chinese texts.\\nå…±è®¡ 120w æ¡æ•°æ®ï¼Œä»¥ä¸‹æ˜¯æ•°æ®æ¥æº\\n\\n\\t\\n\\t\\t\\næ•°æ®é›†\\nè¯­æ–™\\né“¾æ¥\\n\\n\\n\\t\\t\\nSIGHAN+Wang271K æ‹¼å†™çº é”™æ•°æ®é›†\\nSIGHAN+Wang271K(27ä¸‡æ¡)\\nhttps://huggingface.co/datasets/shibing624/CSC\\n\\n\\nECSpell æ‹¼å†™çº é”™æ•°æ®é›†\\nåŒ…å«æ³•å¾‹ã€åŒ»ç–—ã€é‡‘èç­‰é¢†åŸŸ\\nhttps://github.com/Aopolin-Lv/ECSpell\\n\\n\\nCGED è¯­æ³•çº é”™æ•°æ®é›†\\nä»…åŒ…å«äº†2016å’Œ2021å¹´çš„æ•°æ®é›†â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Weaxs/csc.","first_N":5,"first_N_keywords":["text2text-generation","Chinese","apache-2.0","100M<n<1B","Text"],"keywords_longer_than_N":true},
	{"name":"CHLAWS","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cfa532/CHLAWS","creator_name":"Thomas Fung","creator_url":"https://huggingface.co/cfa532","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nLaw documents legislated in China.\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cfa532/CHLAWS.","first_N":5,"first_N_keywords":["Chinese","mit","100K - 1M","text","Text"],"keywords_longer_than_N":true},
	{"name":"yayi2_pretrain_data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wenge-research/yayi2_pretrain_data","creator_name":"wenge-research","creator_url":"https://huggingface.co/wenge-research","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»/Introduction\\n\\t\\n\\næœ¬æ•°æ®é›†æºè‡ªé›…æ„è®­ç»ƒè¯­æ–™ï¼Œæˆ‘ä»¬ç²¾é€‰äº†çº¦100Bæ•°æ®ï¼Œæ•°æ®å¤§å°çº¦ä¸º500GBã€‚æˆ‘ä»¬æœŸæœ›é€šè¿‡é›…æ„é¢„è®­ç»ƒæ•°æ®çš„å¼€æºæ¨åŠ¨ä¸­æ–‡é¢„è®­ç»ƒå¤§æ¨¡å‹å¼€æºç¤¾åŒºçš„å‘å±•ï¼Œå¹¶ç§¯æä¸ºæ­¤è´¡çŒ®åŠ›é‡ã€‚é€šè¿‡å¼€æºï¼Œæˆ‘ä»¬ä¸æ¯ä¸€ä½åˆä½œä¼™ä¼´å…±åŒæ„å»ºé›…æ„å¤§æ¨¡å‹ç”Ÿæ€ã€‚\\nWe opensource the pre-trained dataset in this release, it should contain more than 100B tokens depending on the tokenizer you use, requiring more than 500GB of local storage. By open-sourcing the pre-trained dataset, we aim to contribute to the development of the Chinese pre-trained large language model open-source community. Through open-source, weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wenge-research/yayi2_pretrain_data.","first_N":5,"first_N_keywords":["Chinese","English","apache-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"blossom-chat-v2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-chat-v2","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM CHAT V2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tä»‹ç»\\n\\t\\n\\nBlossom Chat V2æ˜¯åŸºäºShareGPT 90Kè¡ç”Ÿè€Œæ¥çš„ä¸­è‹±åŒè¯­å¯¹è¯æ•°æ®é›†ï¼Œé€‚ç”¨äºå¤šè½®å¯¹è¯å¾®è°ƒã€‚\\nç›¸æ¯”äºblossom-chat-v1ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–äº†æ•°æ®å¤„ç†æµç¨‹ï¼Œå¹¶é…å¹³äº†ä¸­è‹±è¯­æ–™ã€‚\\næœ¬æ•°æ®é›†æŠ½å–äº†ShareGPTçš„å¤šè½®å¯¹è¯æŒ‡ä»¤ï¼Œä»…å°†æŒ‡ä»¤è¿›è¡Œç¿»è¯‘ï¼Œéšåä½¿ç”¨å¤šè½®æŒ‡ä»¤è¿­ä»£è°ƒç”¨gpt-3.5-turbo-0613ã€‚\\nç›¸æ¯”åŸå§‹çš„ShareGPTæ•°æ®ï¼Œä¸»è¦è§£å†³äº†ä¸­æ–‡å¯¹è¯æ•°æ®é‡è¾ƒå°‘ï¼Œä»¥åŠç”±ChatGPTç”Ÿæˆé•¿åº¦é™åˆ¶è€Œå¯¼è‡´çš„è¾“å‡ºæˆªæ–­é—®é¢˜ã€‚\\næœ¬æ¬¡å‘å¸ƒäº†å…¨é‡æ•°æ®çš„20%ï¼ŒåŒ…å«30Kè®°å½•ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tè¯­è¨€\\n\\t\\n\\nä»¥ä¸­æ–‡å’Œè‹±æ–‡ä¸ºä¸»ï¼Œä¸­è‹±æ–‡æ•°æ®æŒ‰ç…§çº¦1:1çš„æ¯”ä¾‹æ··åˆã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„\\n\\t\\n\\næ¯æ¡æ•°æ®ä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„å¤šè½®å¯¹è¯ï¼ŒåŒ…å«idå’Œconversationsä¸¤ä¸ªå­—æ®µã€‚\\n\\nidï¼šå­—ç¬¦ä¸²ï¼Œä»£è¡¨åŸå§‹ShareGPTçš„å¯¹è¯idï¼Œå¯ä»¥é€šè¿‡é“¾æ¥https://sharegpt.com/c/idæ¥è®¿é—®åŸå§‹å¯¹è¯ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-chat-v2.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"WikidataLabels","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rayliuca/WikidataLabels","creator_name":"Ray Liu","creator_url":"https://huggingface.co/rayliuca","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikidata Labels\\n\\t\\n\\nLarge parallel corpus for machine translation\\n\\nEntity label data extracted from Wikidata (2022-01-03), filtered for item entities only  \\nOnly download the languages you need with datasets>=2.14.0\\nSimilar dataset: https://huggingface.co/datasets/wmt/wikititles (18 Wikipedia titles pairs instead of all Wikidata entities)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nWikidata JSON dump (wikidata-20220103-all.json.gz)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rayliuca/WikidataLabels.","first_N":5,"first_N_keywords":["translation","text2text-generation","English","French","German"],"keywords_longer_than_N":true},
	{"name":"oasst2_top1_chat_format","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\\n\\t\\n\\nExport of oasst2 only top 1 threads in huggingface chat format\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScript\\n\\t\\n\\nThe convert script can be find here\\n","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"literary chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"mandarin chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"wu chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"yue chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"ZhihuJunkieSpoken","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bzb2023/ZhihuJunkieSpoken","creator_name":"åˆ·çŸ¥ä¹åˆ·çš„","creator_url":"https://huggingface.co/bzb2023","description":"BLACKæªéª‘å…µ, luxenius, pansz, åŠä½›ä»™äºº, ä¸æƒ³ä¸ŠåŠç‹æ‰¿æ©, \\n                 æ›¹ä¸°æ³½, ç‚½æ¢¦, ç–¯æ­»æ²ƒ, å¼—å…°å…‹æ‰¬, å¤é’, å…³ä¹‹æª€,\\n                 è´ºä»™, æ§¿å¹´, æ¡†æ¡†æ¡†å­, æå»ºç§‹, æµæµªçš„è›¤èŸ†, æ‘¸é±¼çš„ç‹åŒå­¦, \\n                 ç”³é¹, æ–¯å¤§ç‹, æ‰˜å¡é©¬å…‹ä¹‹å† , ç‹å…‹ä¸¹,\\n                 ç‹ç‘æ©, æ¸©é…’, è¥¿é—¨è±¹çš„ç²¾ç¥é—¨å¾’, è°¢æµè¿œ, ç«¹é’\\nçŸ¥ä¹å¤§Vè¨€è®º\\n","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","apache-2.0","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"MT-Bench-ZH","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GeneZC/MT-Bench-ZH","creator_name":"Chen Zhang","creator_url":"https://huggingface.co/GeneZC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸ’¬ MT-Bench-ZH\\n\\t\\n\\nğŸ‘» GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tğŸ¯ Motivation\\n\\t\\n\\nMiniChat-1/1.5/2-3B are all instruction-following language models that could handle Chinese instructions, however, there is currently no instruciton-following benchamrk specialized for Chinese. Due to this, our previous evaluation has been limited to English-only benchmarks (i.e., AlpacaEval and MT-Bench). \\nTo this demand, MT-Bench-ZH is made to mitigate this. MT-Bench-ZH is basically translated from MT-Bench-ZH by GPT-4 andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GeneZC/MT-Bench-ZH.","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","n<1K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"language_tags","keyword":"achinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"zhuang","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"E-EVAL","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/E-EVAL/E-EVAL","creator_name":"E-EVAL","creator_url":"https://huggingface.co/E-EVAL","description":"E-EVAL/E-EVAL dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multiple-choice","Chinese","apache-2.0","1K<n<10K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"Meow-Instruct-12k","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/Meow-Instruct-12k","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"ä¸€åªçŒ«çŒ«çš„è¯´è¯è¯­å½•ã€‚\\næ›´é•¿çš„ç‰ˆæœ¬è§è¿™é‡Œï¼šMxode/Meow-Instruct-34k\\n","first_N":5,"first_N_keywords":["text2text-generation","Chinese","gpl-3.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Meow-Instruct-34k","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/Meow-Instruct-34k","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"ä¸€åªçŒ«çŒ«çš„è¯´è¯è¯­å½•ã€‚\\næ›´çŸ­çš„ç‰ˆæœ¬è§è¿™é‡Œï¼šMxode/Meow-Instruct-12k\\n","first_N":5,"first_N_keywords":["text2text-generation","Chinese","gpl-3.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Haruhi-Zero-RolePlaying-movie-PIPPA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/Haruhi-Zero-RolePlaying-movie-PIPPA","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2000 Chinese RoleCards from IMDB_250 Movies and PIPPA\\n\\t\\n\\nç”¨äºæ‹“å±•zero-shotè§’è‰²æ‰®æ¼”çš„è§’è‰²å¡ç‰‡ã€‚\\nå…¶ä¸­870ä¸ªè§’è‰²æ¥è‡ªç”µå½±å­—å¹•æ€»ç»“(idä¸ºmovie_xx)ï¼Œå…¶ä¸­406å¼ ç¿»è¯‘æˆäº†ç®€ä½“ä¸­æ–‡ï¼Œå‰©ä¸‹çš„æ²¡ç¿»ï¼ˆæ‰€ä»¥æœ‰äº›ç¹ä½“æˆ–è€…è‹±æ–‡æ··æ‚ï¼‰\\n1270ä¸ªè§’è‰²æ¥è‡ªäºå¯¹PIPPAæ•°æ®é›†çš„ç¿»è¯‘\\n\\nå‡Œäº‘å¿—@ä¼¯æ©èŒ…æ–¯å¤§å­¦ ä½¿ç”¨å°„æ‰‹apiçˆ¬å–äº†ç”µå½±çš„å­—å¹•\\n\\næé²é² å®Œæˆäº†ä»å­—å¹•åˆ°è§’è‰²å¡ç‰‡çš„æ€»ç»“ï¼Œä»¥åŠå¯¹æ•°æ®çš„ç¿»è¯‘(openai)\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tåç»­\\n\\t\\n\\næˆ‘ä»¬åç»­æ‰“ç®—ç”¨è¿™äº›å¡ç‰‡ ä»openai, CharacterGLM, KoboldAIçš„apiä¸­ï¼Œåˆ©ç”¨Baizeçš„æ–¹å¼å»è·å¾—æ•°æ®ã€‚\\né¡¹ç›®ä¸»é¡µ https://github.com/LC1332/Chat-Haruhi-Suzumiya\\nå¦‚æœä½ è¦è®¨è®ºåŠ å…¥æˆ‘ä»¬çš„é¡¹ç›®\\nå¯ä»¥æŠŠä½ çš„è”ç³»æ–¹å¼ç§ä¿¡å‘ç»™ https://www.zhihu.com/people/cheng-li-47\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HistoryTrans/Dataset","creator_name":"æ–‡è„‰","creator_url":"https://huggingface.co/HistoryTrans","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHistoryTrans\\n\\t\\n\\nHistoryTrans æ˜¯ä¸€ä¸ªå¤æ–‡ç¿»è¯‘æ•°æ®é›†ï¼Œé€šè¿‡æ•°æ®é¢„å¤„ç†å’Œè´¨é‡æ§åˆ¶ï¼Œæ¥æé«˜å¤æ–‡ç¿»è¯‘çš„è´¨é‡å’Œå®ç”¨æ€§ã€‚\\nå‚è€ƒæˆ‘ä»¬çš„é¡¹ç›®ä¸»é¡µHistoryTranså¤æ–‡ç¿»è¯‘.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†è¯¦ç»†ä¿¡æ¯\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†æ¥æº\\n\\t\\n\\n\\nä¸»ä½“: Classical-Modern\\né¢å¤–è¡¥å……: ï¼šã€ŠäºŒåå››å²ã€‹å’Œã€Šæ¸…å²ç¨¿ã€‹ä¸­æå–\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tæ•°æ®é›†ç»“æ„\\n\\t\\n\\næ•°æ®é›†åŒ…å«ä»¥ä¸‹ JSONL æ–‡ä»¶ï¼š\\n\\ntrain_01_04.jsonl: è®­ç»ƒé›†ï¼Œä¸»è¦ç”¨äºè®­ç»ƒç¿»è¯‘æ¨¡å‹ã€‚\\nval_01_04.jsonl: éªŒè¯é›†ï¼Œç”¨äºè®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¨¡å‹å¾®è°ƒå’Œè¯„ä¼°ã€‚\\ntest_01_04.jsonl: æµ‹è¯•é›†ï¼Œç”¨äºè¯„ä¼°æœ€ç»ˆæ¨¡å‹æ€§èƒ½ã€‚\\n\\næ¯ä¸ª JSON å¯¹è±¡åŒ…æ‹¬ï¼š\\n\\ninputs: åŸå§‹å¤æ–‡\\ntruth: å‡†ç¡®ç¿»è¯‘\\n\\nä¾‹å¦‚ï¼š\\n{\\\"inputs\\\": \\\"æ˜•æ›°ï¼š å›çº¥ä¹‹åŠŸï¼Œå”å·²æŠ¥ä¹‹çŸ£ã€‚\\\", \\\"truth\\\": \\\"è§æ˜•åé©³è¯´ï¼š å›çº¥çš„åŠŸåŠ³ï¼Œå”æœå·²ç»æŠ¥ç­”äº†ã€‚\\\"}\\n{\\\"inputs\\\": \\\"ç„¶å¿ä»¤æ‰€çŠ¯åœ¨æ©å‰ï¼Œä¸­äººæ‰€çŠ¯åœ¨æ©åã€‚\\\", \\\"truth\\\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HistoryTrans/Dataset.","first_N":5,"first_N_keywords":["translation","Chinese","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"AISHELL-3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AISHELL/AISHELL-3","creator_name":"aishelltech","creator_url":"https://huggingface.co/AISHELL","description":"AISHELL-3 is a large-scale and high-fidelity multi-speaker Mandarin speech corpus published by Beijing Shell Shell Technology Co.,Ltd. It can be used to train multi-speaker Text-to-Speech (TTS) systems.The corpus contains roughly 85 hours of emotion-neutral recordings spoken by 218 native Chinese mandarin speakers and total 88035 utterances. Their auxiliary attributes such as gender, age group and native accents are explicitly marked and provided in the corpus. Accordingly, transcripts inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AISHELL/AISHELL-3.","first_N":5,"first_N_keywords":["text-to-speech","Chinese","apache-2.0","10K<n<100K","Audio"],"keywords_longer_than_N":true},
	{"name":"FollowBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuxinJiang/FollowBench","creator_name":"Yuxin Jiang","creator_url":"https://huggingface.co/YuxinJiang","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFollowBench: A Multi-level Fine-grained Constraints Following Benchmark for Large Language Models\\n\\t\\n\\nWe introduce FollowBench, a Multi-level Fine-grained Constraints Following Benchmark for systemically and precisely evaluate the instruction-following capability of LLMs.\\n\\nFollowBench comprehensively includes five different types (i.e., Content, Situation, Style, Format, and Example) of fine-grained constraints. \\nTo enable a precise constraint following estimation on diverseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuxinJiang/FollowBench.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"oaast_rm_zh_jieba","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/oaast_rm_zh_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"å°è¯•è§£å†³\\\"llm repetition problem\\\"ï¼Œä½¿ç”¨åˆ†è¯æ¨¡å‹å¯¹oaastè¯­æ–™è¿›è¡Œâ€œç»“å·´åŒ–â€æ•°æ®å¢å¼ºï¼Œæä¾›æ›´å¼ºçš„é‡å¤å†…å®¹æ‹’ç»æ•ˆæœã€‚\\nAttempts to solve the \\\"llm repetition problem\\\" by using a segmentation model to enhance the oaast corpus with \\\"stuttering\\\" data to provide stronger rejection of duplicate content.\\nå…¶æ¬¡ï¼Œè¿˜è¿‡æ»¤æ‰äº†æ‰€æœ‰è‡ªæˆ‘è®¤çŸ¥çš„å¾®è°ƒæ ·æœ¬ã€‚\\nSecond, it also filters out all the fine-tuned samples of self-cognition.\\nfiles:\\n\\noaast_rm_zh_jieba.jsonl : word level repeat\\noaast_rm_zh_sent_jieba.jsonl : sentence level repeat\\n\\n","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"oaast_rm_full_jieba","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"å°è¯•è§£å†³\\\"llm repetition problem\\\"ï¼Œä½¿ç”¨åˆ†è¯æ¨¡å‹å¯¹oaastè¯­æ–™è¿›è¡Œâ€œç»“å·´åŒ–â€æ•°æ®å¢å¼ºï¼Œæä¾›æ›´å¼ºçš„é‡å¤å†…å®¹æ‹’ç»æ•ˆæœã€‚\\nAttempts to solve the \\\"llm repetition problem\\\" by using a segmentation model to enhance the oaast corpus with \\\"stuttering\\\" data to provide stronger rejection of duplicate content.\\nå…¶æ¬¡ï¼Œè¿˜è¿‡æ»¤æ‰äº†æ‰€æœ‰è‡ªæˆ‘è®¤çŸ¥çš„å¾®è°ƒæ ·æœ¬ã€‚\\nSecond, it also filters out all the fine-tuned samples of self-cognition.\\nfiles:\\n\\noaast_rm_full_jieba.jsonl : word level repeat\\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\\n\\n","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"CASIA-HWDB2-line","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Teklia/CASIA-HWDB2-line","creator_name":"Teklia","creator_url":"https://huggingface.co/Teklia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCASIA-HWDB2 - line level\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe offline Chinese handwriting database (CASIA-HWDB2) was built by the National Laboratory of Pattern Recognition (NLPR), Institute of Automation of Chinese Academy of Sciences (CASIA). \\nThe handwritten samples were produced by 1,020 writers using Anoto pen on papers, such that both online and offline data were obtained.\\nNote that all images are resized to a fixed height of 128 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nAll theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Teklia/CASIA-HWDB2-line.","first_N":5,"first_N_keywords":["image-to-text","Chinese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Haruhi-Baize-Role-Playing-Conversation","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/Haruhi-Baize-Role-Playing-Conversation","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHaruhi-Zeroçš„Conversationè®­ç»ƒæ•°æ®\\n\\t\\n\\næˆ‘ä»¬è®¡åˆ’æ‹“å±•ChatHaruhiï¼Œä»Few-shotåˆ°Zero-shotï¼Œè¿™ä¸ªæ•°æ®é›†è®°å½•ä½¿ç”¨å„ä¸ªï¼ˆä¸­æ–‡ï¼‰è§’è‰²æ‰®æ¼”apiè¿›è¡ŒBaizeå¼ç›¸äº’èŠå¤©åå¾—åˆ°çš„æ•°æ®ç»“æœ\\nidsä»£è¡¨èŠå¤©çš„æ—¶å€™ä¸¤å¼ botçš„è§’è‰²å¡ç‰‡ï¼Œ è§’è‰²å¡ç‰‡çš„ä¿¡æ¯å¯ä»¥åœ¨https://huggingface.co/datasets/silk-road/Haruhi-Zero-RolePlaying-movie-PIPPA ä¸­æ‰¾åˆ°\\nå¹¶ä¸”å¯¹äºç¬¬ä¸€æ¬¡å‡ºç°çš„id0ï¼Œä¹Ÿä¼šåœ¨promptå­—æ®µä¸­è¿›è¡Œè®°å½•ã€‚\\nèŠå¤©çš„æ—¶å€™idå’Œidsçš„å¡ç‰‡è¿›è¡Œå¯¹åº”\\n\\nopenai ä»£è¡¨ä¸¤ä¸ªèŠå¤©çš„botéƒ½ä½¿ç”¨openai\\nGLM ä»£è¡¨ä¸¤ä¸ªèŠå¤©çš„botéƒ½ä½¿ç”¨CharacterGLM\\nClaude ä»£è¡¨ä¸¤ä¸ªèŠå¤©çš„botéƒ½ä½¿ç”¨Claude\\nClaude_openai ä»£è¡¨id0çš„ä½¿ç”¨Claudeï¼Œ id1çš„ä½¿ç”¨openai\\nBaichuan ä»£è¡¨ä¸¤ä¸ªèŠå¤©çš„botéƒ½ä½¿ç”¨Character-Baichuan-Turboâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/silk-road/Haruhi-Baize-Role-Playing-Conversation.","first_N":5,"first_N_keywords":["text-generation","Chinese","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Pretrain-Taiwan-DentistKnowledge-zhTW-290K","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DataAgent/Pretrain-Taiwan-DentistKnowledge-zhTW-290K","creator_name":"DataAgent","creator_url":"https://huggingface.co/DataAgent","description":"LaplaceAI ç¹ä¸­é ˜åŸŸçŸ¥è­˜è³‡æ–™é›†è¨ˆç•«\\nåˆ©ç”¨æˆ‘åœ¨çˆ¬èŸ²è‡ªå‹•åŒ–èˆ‡è³‡æ–™å¾Œè™•ç†ä¸Šçš„å°ˆæ¥­ï¼Œé‡å°ä¸åŒå¤§å°çš„é ˜åŸŸçŸ¥è­˜è³‡æ–™é›†é€²è¡Œå»ºç«‹èˆ‡ç¶­è­·ã€‚\\nåœ¨ LaplaceAI çš„ huggingface é é¢ï¼Œä½ å¯ä»¥æ‰¾åˆ°è¨±å¤šä¸åŒé ˜åŸŸçš„è³‡æ–™é›†ã€‚\\né€™é … datasets æ˜¯ç”± LaplaceAI æ•´ç†ç¶­è­·çš„ç‰™ç§‘ç›¸é—œçŸ¥è­˜ã€‚\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","gpl-3.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"food-images-1k","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/snowsense/food-images-1k","creator_name":"snowsense","creator_url":"https://huggingface.co/snowsense","description":"snowsense/food-images-1k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["image-classification","English","mit","10B<n<100B","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"language-dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","description":"\\n","first_N":5,"first_N_keywords":["text-classification","English","Chinese","French","Russian"],"keywords_longer_than_N":true},
	{"name":"seamless-align-expressive","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jhu-clsp/seamless-align-expressive","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Seamless-Align-Expressive (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was created based on metadata for mined expressive Speech-to-Speech(S2S) released by Meta AI.  The S2S contains data for 5 language pairs. The S2S dataset is ~228GB compressed.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to use the data\\n\\t\\n\\nThere are two ways to access the data:\\n\\nVia the Hugging Face Python datasets library\\n\\nScripts coming soon\\n\\n\\nClone the git repo\\n\\ngitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align-expressive.","first_N":5,"first_N_keywords":["translation","audio-to-audio","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"longwriter-6k-filtered","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/longwriter-6k-filtered","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLongWriter-6k-Filtered\\n\\t\\n\\n\\n  ğŸ¤– [LongWriter Dataset]  â€¢ ğŸ’» [Github Repo] â€¢ ğŸ“ƒ [LongWriter Paper] â€¢ ğŸ“ƒ [Tech report]\\n\\n\\nlongwriter-6k-filtered dataset contains 666 filtered examples SFT data with ultra-long output ranging from 2k-32k words in length (both English and Chinese) based on LongWriter-6k.The data can support training LLMs to extend their maximum output window size to 10,000+ words with low computational cost.\\nThe tech report is available at Minimum Tuning to Unlock Longâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lenML/longwriter-6k-filtered.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MM-Eval","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prometheus-eval/MM-Eval","creator_name":"prometheus-eval","creator_url":"https://huggingface.co/prometheus-eval","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Meta-EVALuation benchmark (MM-Eval)\\n\\t\\n\\n\\nğŸ‘¨â€ğŸ’»Code\\n|\\nğŸ“„Paper\\n|\\nğŸ¤— MMQA\\n\\n\\nMM-Eval is a multilingual meta-evaluation benchmark consisting of five core subsetsâ€”Chat, Reasoning, Safety, Language Hallucination, and Linguisticsâ€”spanning 18 languages and a Language Resource subset spanning 122 languages for a broader analysis of language effects. \\n\\nDesign ChoiceIn this work, we minimize the inclusion of translated samples, as mere translation may alter existing preferences dueâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/prometheus-eval/MM-Eval.","first_N":5,"first_N_keywords":["Arabic","Bengali","Catalan","German","English"],"keywords_longer_than_N":true},
	{"name":"caexpo_news","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/GXMZU/caexpo_news","creator_name":"Guangxi Minzu University","creator_url":"https://huggingface.co/GXMZU","description":"\\n\\t\\n\\t\\t\\n\\t\\tCAEXPO News Dataset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe CAEXPO (China-ASEAN Expo) News Dataset is a comprehensive collection of news articles from the offical China-ASEAN Expo website. The dataset covers various aspects including:\\n\\nTrade and economic cooperation\\nCultural exchanges\\nRegional development\\nPolicy announcements\\nInnovation and technology cooperation\\n......\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\ntitle: The headline of the news article\\nurl: URL link to the original news articleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GXMZU/caexpo_news.","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"Saka-Alpaca-v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Saka-Alpaca-v1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"https://chatgpt.com\\n","first_N":5,"first_N_keywords":["text-generation","Swedish","Norwegian","Finnish","German"],"keywords_longer_than_N":true},
	{"name":"xjtu_info","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/volcanos/xjtu_info","creator_name":"vol","creator_url":"https://huggingface.co/volcanos","description":"volcanos/xjtu_info dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Erotic-literature","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/XuehangCang/Erotic-literature","creator_name":"XuehangCang","creator_url":"https://huggingface.co/XuehangCang","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Erotic Literature in Chinese\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a collection of erotic literature in Chinese, compiled for the purpose of text generation tasks. It is divided into two splits: a training set and a test set, allowing for model training and evaluation. The dataset is of moderate size, suitable for projects working on text-based AI models, particularly focusing on the genre of erotic literature.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nLanguage: Chinese (zh)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/XuehangCang/Erotic-literature.","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLUâ€™s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increasesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"hanlp_date-zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zeroMN/hanlp_date-zh","creator_name":"zeroTT","creator_url":"https://huggingface.co/zeroMN","description":"\\n\\t\\n\\t\\t\\n\\t\\t--\\n2nd International Chinese Word Segmentation Bakeoff - Data Release\\nRelease 1, 2005-11-18\\n\\t\\n\\n\\nIntroduction\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis directory contains the training, test, and gold-standard data\\nused in the 2nd International Chinese Word Segmentation Bakeoff. Also\\nincluded is the script used to score the results submitted by the\\nbakeoff participants and the simple segmenter used to generate the\\nbaseline and topline data.\\n\\t\\n\\n\\nFile List\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tgold/       Contains the gold standardâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zeroMN/hanlp_date-zh.","first_N":5,"first_N_keywords":["text-classification","Chinese","mit","100M<n<1B","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"tgb_niepanchongsheng","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jiangwlee/tgb_niepanchongsheng","creator_name":"Li","creator_url":"https://huggingface.co/Jiangwlee","description":"Jiangwlee/tgb_niepanchongsheng dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Chinese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Rule-based","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Rule-based is a dataset of BenchMAX, sourcing from IFEval, which is a rule-based benchmark for evaluating the instruction following capabilities.\\nWe extend the original dataset to 16 non-English languages by first translating and then manualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Model-based","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Model-based is a dataset of BenchMAX, sourcing from m-ArenaHard.\\nWe extend the original English dataset to 16 non-English languages by first translating and then manual post-editing.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Multiple_Functions","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Multiple_Functions is a dataset of BenchMAX, sourcing from Nexus.\\nWe translate the standardized queries from English to 16 non-English languages by google Translate.\\nSome special function arguments remain English since the APIs are in English.\\nAllâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_General_Translation","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_General_Translation is a dataset of BenchMAX.\\nWe collect parallel test data from Flore-200, TED-talk, and WMT24.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech, English, French, German, Hungarian, Japanese, Korean, Serbian, Spanishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Domain_Translation","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Domain_Translation is a dataset of BenchMAX.\\nWe collect the domain parallel data from other tasks in BenchMAX.\\nEach sample contains one or three human-annotated translations.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech, Englishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"nbeerbower-GreatFirewall-DPO","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Triangle104/nbeerbower-GreatFirewall-DPO","creator_name":"Lymeman","creator_url":"https://huggingface.co/Triangle104","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tGreatFirewall-DPO\\n\\t\\n\\nAn experimental dataset to discourage censorship in Chinese models.\\n\\n\\t\\n\\t\\t\\n\\t\\tStructure\\n\\t\\n\\n\\nprompt: input text presented to model (en translated to zh)\\nchosen: preferred response demonstrating less self-censorship (en translated to zh)  \\nrejected: response generated by Qwen/Qwen2.5-32B-Instruct, many exhibiting excessive self-censorship (generated in both en and zh)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tContent\\n\\t\\n\\n\\nCHINA-related (144 prompts) - mostly about sensitive historical/political eventsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Triangle104/nbeerbower-GreatFirewall-DPO.","first_N":5,"first_N_keywords":["English","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"TWDOCI","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/TWDOCI","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tyuhuanstudio/TWDOCI\\n\\t\\n\\nä¸€å€‹æ”¶éŒ„äº†æ­£é«”ä¸­æ–‡ï¼ˆç¹é«”ä¸­æ–‡ï¼‰æˆèªå…¸çš„è³‡æ–™é›†ï¼Œç”¨æ–¼å¤§æ¨¡å‹å¾®èª¿\\n(è¿½æ±‚é€²æ­¥ä½†ä¸æ‡‰è©²æ¨å»æ­·å²ï¼Œä¸­è¯æ–‡åŒ–ä¸è©²å› æ”¿æ²»è€Œè¢«æŠ¹å»ä¸¦æ¶ˆäº¡)\\nA data set containing dictionary of traditional chinese idioms for fine-tuning LLM\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nã€Œå°ç£æ•™è‚²éƒ¨æˆèªå…¸ã€ ï¼ˆTaiwan's Ministry of Education Dictionary Of Chinese Idiomsï¼ŒTWDOCIï¼‰ï¼Œ\\nè³‡æ–™å–è‡ªæ–¼å°ç£æ•™è‚²éƒ¨çš„ã€Šæˆèªå…¸ã€‹\\nç‚ºäº†è®“LLMå¾å¤šæ–¹é¢å¢åŠ å°ç¹é«”ä¸­æ–‡çš„èªè­˜ï¼Œæˆ‘å€‘åˆ©ç”¨å¾ä¸­æå–ä¸¦è¨­è¨ˆå…­å¤§æŒ‡ä»¤ä»»å‹™ã€Œæˆèªå…¸æ•…ã€è®€éŸ³å•ç­”ã€æˆèªè§£é‡‹ã€ä½¿ç”¨æ™‚æ©Ÿã€è¿‘ä¼¼è©èˆ‡åç¾©è©ã€ä½¿ç”¨æ–¹æ³•ã€ï¼ˆç´„2.2è¬ç­†æŒ‡ä»¤ï¼‰\\nThis dataset is sourced from Taiwanâ€™s Ministry of Educationâ€™s Revised Mandarin Chinese Dictionary.\\nToâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/TWDOCI.","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"TWDOCI","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/TWDOCI","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tyuhuanstudio/TWDOCI\\n\\t\\n\\nä¸€å€‹æ”¶éŒ„äº†æ­£é«”ä¸­æ–‡ï¼ˆç¹é«”ä¸­æ–‡ï¼‰æˆèªå…¸çš„è³‡æ–™é›†ï¼Œç”¨æ–¼å¤§æ¨¡å‹å¾®èª¿\\n(è¿½æ±‚é€²æ­¥ä½†ä¸æ‡‰è©²æ¨å»æ­·å²ï¼Œä¸­è¯æ–‡åŒ–ä¸è©²å› æ”¿æ²»è€Œè¢«æŠ¹å»ä¸¦æ¶ˆäº¡)\\nA data set containing dictionary of traditional chinese idioms for fine-tuning LLM\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nã€Œå°ç£æ•™è‚²éƒ¨æˆèªå…¸ã€ ï¼ˆTaiwan's Ministry of Education Dictionary Of Chinese Idiomsï¼ŒTWDOCIï¼‰ï¼Œ\\nè³‡æ–™å–è‡ªæ–¼å°ç£æ•™è‚²éƒ¨çš„ã€Šæˆèªå…¸ã€‹\\nç‚ºäº†è®“LLMå¾å¤šæ–¹é¢å¢åŠ å°ç¹é«”ä¸­æ–‡çš„èªè­˜ï¼Œæˆ‘å€‘åˆ©ç”¨å¾ä¸­æå–ä¸¦è¨­è¨ˆå…­å¤§æŒ‡ä»¤ä»»å‹™ã€Œæˆèªå…¸æ•…ã€è®€éŸ³å•ç­”ã€æˆèªè§£é‡‹ã€ä½¿ç”¨æ™‚æ©Ÿã€è¿‘ä¼¼è©èˆ‡åç¾©è©ã€ä½¿ç”¨æ–¹æ³•ã€ï¼ˆç´„2.2è¬ç­†æŒ‡ä»¤ï¼‰\\nThis dataset is sourced from Taiwanâ€™s Ministry of Educationâ€™s Revised Mandarin Chinese Dictionary.\\nToâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/TWDOCI.","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"common_voice_16_1_zh_TW_clean","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/common_voice_16_1_zh_TW_clean","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"This dataset is derived from mozilla-foundation/common_voice_16_1, with a clean (denoised) audio column using MP-SENet. The original \\\"noisy\\\" audio is stored in the \\\"original\\\" column.\\n","first_N":5,"first_N_keywords":["mozilla-foundation/common_voice_16_1","Chinese","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"common_voice_19_0_zh-TW","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/common_voice_19_0_zh-TW","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCommon Voice Corpus 19.0 Chinese (Taiwan)\\n\\t\\n\\nThe test set is the same as the original test set, while validated_without_test includes all validated examples except those with sentence IDs that appear in the test set.\\n\\nvalidated_without_test has about 50,000 examples in total, equivalent to approximately 44 hours, and is intended for use as the training set.\\ntest has about 5,000 examples, which is approximately 5 hours.\\n\\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Chinese","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Dataset-of-AI-Model-for-Dr_AI","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/old-cookie/Dataset-of-AI-Model-for-Dr_AI","creator_name":"oldcookie","creator_url":"https://huggingface.co/old-cookie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/old-cookie/Dataset-of-AI-Model-for-Dr_AI.","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"save-English","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lalala-13/save-English","creator_name":"Robert Rocky","creator_url":"https://huggingface.co/lalala-13","description":"ä¸€äº›åˆä¸­æ°´å¹³çš„è‹±è¯­ä½œæ–‡å¯ä»¥è®©è®­ç»ƒè¿‡çš„AIå†™å‡ºä¸€äº›èŒƒæ–‡.\\n","first_N":5,"first_N_keywords":["Chinese","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Act2Cap_benchmark","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FRank62Wu/Act2Cap_benchmark","creator_name":"FRank Wu","creator_url":"https://huggingface.co/FRank62Wu","description":"FRank62Wu/Act2Cap_benchmark dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"toolace-parsed","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/minpeter/toolace-parsed","creator_name":"minpeter","creator_url":"https://huggingface.co/minpeter","description":"\\n\\t\\n\\t\\t\\n\\t\\t[PARSED] ToolACE\\n\\t\\n\\nThe data in this dataset is a subset of the original Team-ACE/ToolACE\\n\\n\\t\\n\\t\\t\\nSubset name\\nmulti-turn\\nparallel\\nmultiple definition\\nLast turn type\\nnumber of dataset\\n\\n\\n\\t\\t\\ntoolace\\nyes\\nyes\\nyes\\ncomplex\\n11k\\n\\n\\n\\t\\n\\nThis is a re-parsing formatting dataset for the ToolACE official dataset.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLoad the dataset\\n\\t\\n\\nfrom datasets import load_dataset\\n\\nds = load_dataset(\\\"minpeter/toolace-parsed\\\")\\nprint(ds)\\n\\n# DatasetDict({\\n#     train: Dataset({\\n#         features:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/minpeter/toolace-parsed.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"sina-kefu-dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/a2231698193/sina-kefu-dataset","creator_name":"zhangxibin","creator_url":"https://huggingface.co/a2231698193","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Sina Customer Service Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nè¿™æ˜¯ä¸€ä¸ªå®¢æœé—®ç­”æ•°æ®é›†ï¼ŒåŒ…å«é—®é¢˜ã€æ€è€ƒè¿‡ç¨‹å’Œå›ç­”ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\næ•°æ®é›†ä½¿ç”¨ä¸­æ–‡ï¼ˆzhï¼‰ã€‚\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\næ•°æ®é›†åŒ…å«ä»¥ä¸‹å­—æ®µï¼š\\n\\nQuestion: ç”¨æˆ·æå‡ºçš„é—®é¢˜\\nComplex_CoT: å›ç­”é—®é¢˜çš„æ€è€ƒè¿‡ç¨‹\\nResponse: æœ€ç»ˆçš„å›ç­”\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\nQuestion: string - ç”¨æˆ·çš„é—®é¢˜\\nComplex_CoT: string - è¯¦ç»†çš„æ€è€ƒè¿‡ç¨‹\\nResponse: string - æœ€ç»ˆç­”æ¡ˆ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Splits\\n\\t\\n\\næ•°æ®é›†åˆ†ä¸ºï¼š\\n\\nè®­ç»ƒé›† (80%)\\næµ‹è¯•é›† (20%)\\n\\n","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","Chinese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Tobacco-Expert-Dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Eagle51/Tobacco-Expert-Dataset","creator_name":"wuyi.yang","creator_url":"https://huggingface.co/Eagle51","description":"Eagle51/Tobacco-Expert-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Semiboobs","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lunzima/Semiboobs","creator_name":"Lun Zima","creator_url":"https://huggingface.co/Lunzima","description":"\\n\\t\\n\\t\\t\\n\\t\\tMicro Dataset for LLM SFT Training\\n\\t\\n\\nThis dataset is designed for the fine-tuning of large language models (LLMs) to improve their performance in specific tasks. It contains a small amount of data that is carefully selected to optimize the model's ability to generate content related to the following areas:\\nExplanation of \\\"Semiconductor Boobs\\\": The dataset includes examples that help the model understand and generate explanations for the concept of \\\"Semiconductor Boobs\\\". This willâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lunzima/Semiboobs.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Chinese-DeepSeek-R1-Distill-data-Fin-2k-SFT-v2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/herman66/Chinese-DeepSeek-R1-Distill-data-Fin-2k-SFT-v2","creator_name":"liu","creator_url":"https://huggingface.co/herman66","description":"herman66/Chinese-DeepSeek-R1-Distill-data-Fin-2k-SFT-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","ğŸ‡ºğŸ‡¸ Region: US","finance"],"keywords_longer_than_N":false},
	{"name":"Chinese-DeepSeek-R1-Distill-data-110k-opencc","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benchang1110/Chinese-DeepSeek-R1-Distill-data-110k-opencc","creator_name":"Yu-Ying Chang","creator_url":"https://huggingface.co/benchang1110","description":"\\n\\t\\n\\t\\t\\n\\t\\tä¸­æ–‡åŸºæ–¼æ»¿è¡€DeepSeek-R1è’¸é¤¾æ•¸æ“šé›†ï¼ˆChinese-Data-Distill-From-R1ï¼‰\\n\\t\\n\\n\\nğŸ¤— Hugging FaceÂ Â  | Â Â ğŸ¤– ModelScope Â Â  | Â Â ğŸš€ Github Â Â  | Â Â ğŸ“‘ Blog\\n\\n\\næœ¬è³‡æ–™é›†ç”± Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT ç¶“é opencc è½‰æ›è€Œæˆï¼Œå†æ¬¡æ„Ÿè¬åŸä½œè€…ã€‚  \\næ³¨æ„ï¼šè©²ç‰ˆæœ¬ç‚ºï¼Œå¯ä»¥ç›´æ¥SFTä½¿ç”¨çš„ç‰ˆæœ¬ï¼Œå°‡åŸå§‹æ•¸æ“šä¸­çš„æ€è€ƒå’Œç­”æ¡ˆæ•´åˆæˆoutputå­—æ®µï¼Œå¤§éƒ¨åˆ†SFTä»£ç¢¼æ¡†æ¶å‡å¯ç›´æ¥ç›´æ¥åŠ è¼‰è¨“ç·´ã€‚\\næœ¬æ•¸æ“šé›†ç‚ºä¸­æ–‡é–‹æºè’¸é¤¾æ»¿è¡€R1çš„æ•¸æ“šé›†ï¼Œæ•¸æ“šé›†ä¸­ä¸åƒ…åŒ…å«mathæ•¸æ“šï¼Œé‚„åŒ…æ‹¬å¤§é‡çš„é€šç”¨é¡å‹æ•¸æ“šï¼Œç¸½æ•¸é‡ç‚º110Kã€‚\\nç‚ºä»€éº½é–‹æºé€™å€‹æ•¸æ“šï¼Ÿ\\nR1çš„æ•ˆæœååˆ†å¼·å¤§ï¼Œä¸¦ä¸”åŸºæ–¼R1è’¸é¤¾æ•¸æ“šSFTçš„å°æ¨¡å‹ä¹Ÿå±•ç¾å‡ºäº†å¼·å¤§çš„æ•ˆæœï¼Œä½†æª¢ç´¢ç™¼ç¾ï¼Œå¤§éƒ¨åˆ†é–‹æºçš„R1è’¸é¤¾æ•¸æ“šé›†å‡ç‚ºè‹±æ–‡æ•¸æ“šé›†ã€‚ åŒæ™‚ï¼ŒR1çš„å ±å‘Šä¸­å±•ç¤ºï¼Œè’¸é¤¾æ¨¡å‹ä¸­åŒæ™‚ä¹Ÿä½¿ç”¨äº†éƒ¨åˆ†é€šç”¨å ´æ™¯æ•¸æ“šé›†ã€‚\\nç‚ºäº†å¹«åŠ©å¤§å®¶æ›´å¥½åœ°è¦†ç¾R1è’¸é¤¾æ¨¡å‹çš„æ•ˆæœï¼Œç‰¹æ­¤é–‹æºä¸­æ–‡æ•¸æ“šé›†ã€‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/benchang1110/Chinese-DeepSeek-R1-Distill-data-110k-opencc.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","question-answering","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"zhuang","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"blossom-v6-sft-stage2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-v6-sft-stage2","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\tBLOSSOM V6 SFT STAGE2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nBLOSSOM V6 SFT Stage2 is a high-quality, diverse large language model fine-tuning dataset designed for the second-stage SFT training of the Blossom V6 model. Its purpose is to further enhance the model's ability to handle complex instructions on more rare real-world problems.\\nWhile open-source large language models often release model weights and technical reports, the most advanced open-source models typically withhold theirâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-v6-sft-stage2.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Felguk-icons","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felguk/Felguk-icons","creator_name":"Alex Felguk","creator_url":"https://huggingface.co/Felguk","description":"\\n\\t\\n\\t\\t\\n\\t\\tFelguk icons\\n\\t\\n\\nThe felguk icons They use it for me. That is, for me.\\nfollow me\\n","first_N":5,"first_N_keywords":["text-generation","Russian","English","Polish","Chinese"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"MindSpeed-Infinity-Instruct-Gen","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/uukuguy/MindSpeed-Infinity-Instruct-Gen","creator_name":"Jiangwen Su","creator_url":"https://huggingface.co/uukuguy","description":"This dataset is built appond the Infinity Instruct project, aiming to match the multi-rounds dialogue finetune format of the MindSpeed-LLM.\\n\\n\\t\\n\\t\\t\\n\\t\\tInfinity Instruct\\n\\t\\n\\n\\n\\n\\n\\nBeijing Academy of Artificial Intelligence (BAAI)\\n[Paper][Code][ğŸ¤—] (would be released soon)\\n\\n\\nThe quality and scale of instruction data are crucial for model performance. Recently, open-source models have increasingly relied on fine-tuning datasets comprising millions of instances, necessitating both high quality and largeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/uukuguy/MindSpeed-Infinity-Instruct-Gen.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"chinese-fineweb-v2-scorer-train-data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opencsg/chinese-fineweb-v2-scorer-train-data","creator_name":"opencsg","creator_url":"https://huggingface.co/opencsg","description":"Chinese-fineweb-v2 å’Œ v2.1 ä¸­ä½¿ç”¨äº† åŸºäº bert çš„æ–‡æœ¬æ‰“åˆ†æ¨¡å‹ï¼Œæ­¤æ•°æ®é›†ä¸ºæ¨¡å‹çš„è®­ç»ƒæ•°æ®ã€‚\\n\\ntext: è¢«æ‰“åˆ†çš„æ–‡æœ¬\\nedu_eval: ç”± qwen2.5-14b-instruct äº§ç”Ÿçš„æ‰“åˆ†ç»“æœ\\nscore: æ‰“åˆ†ç»“æœä¸­æå–å‡ºæ¥çš„å¾—åˆ†\\n\\n","first_N":5,"first_N_keywords":["text-classification","Chinese","English","apache-2.0","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"MindSpeed-Infinity-Instruct-7M","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/uukuguy/MindSpeed-Infinity-Instruct-7M","creator_name":"Jiangwen Su","creator_url":"https://huggingface.co/uukuguy","description":"This dataset is built appond the Infinity Instruct project, aiming to match the multi-rounds dialogue finetune format of the MindSpeed-LLM.\\n\\n\\t\\n\\t\\t\\n\\t\\tInfinity Instruct\\n\\t\\n\\n\\n\\n\\n\\nBeijing Academy of Artificial Intelligence (BAAI)\\n[Paper][Code][ğŸ¤—] (would be released soon)\\n\\n\\nThe quality and scale of instruction data are crucial for model performance. Recently, open-source models have increasingly relied on fine-tuning datasets comprising millions of instances, necessitating both high quality and largeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/uukuguy/MindSpeed-Infinity-Instruct-7M.","first_N":5,"first_N_keywords":["text-generation","English","Chinese","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"scaleway_r1_dark_thoughts_casestudies","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tonic/scaleway_r1_dark_thoughts_casestudies","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"Tonic/scaleway_r1_dark_thoughts_casestudies dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","English","Chinese","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"scaleway_r1_dark_thoughts_casestudies","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tonic/scaleway_r1_dark_thoughts_casestudies","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"Tonic/scaleway_r1_dark_thoughts_casestudies dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","English","Chinese","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"dianping-classification","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zm-hf/dianping-classification","creator_name":"èµµæ˜","creator_url":"https://huggingface.co/zm-hf","description":"zm-hf/dianping-classification dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Chinese","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"SpeechInstructBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ddwang2000/SpeechInstructBench","creator_name":"ElaineWang","creator_url":"https://huggingface.co/ddwang2000","description":"\\n\\t\\n\\t\\t\\n\\t\\tSpeechInstructBench\\n\\t\\n\\nArxiv: https://arxiv.org/abs/2503.02769\\nThis is the SpeechInstructBench dataset download page.  \\nSpeechInstructBench encompasses three dimensions: closed-ended instruction, open-ended instruction, adjustment instruction.\\nFor how to run SpeechInstructBench, Please refer to SpeechInstructBench github page (will be public soon).\\n","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"OpenSubtitles-en-zh-cn-20m","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FradSer/OpenSubtitles-en-zh-cn-20m","creator_name":"Frad LEE","creator_url":"https://huggingface.co/FradSer","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for OpenSubtitles English-Chinese 20M Parallel Corpus\\n\\t\\n\\nThis dataset contains English-Chinese parallel subtitles from OpenSubtitles, specifically the English to Simplified Chinese (zh-CN) language pair. The data is sourced from the OpenSubtitles v2024 collection available at OPUS.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a collection of parallel movie subtitles in English and Chinese, extracted from OpenSubtitles.org. The dataset features improvedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FradSer/OpenSubtitles-en-zh-cn-20m.","first_N":5,"first_N_keywords":["translation","English","Chinese","mit","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"gsm8k-translated","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sara237/gsm8k-translated","creator_name":"Sara Rajaee","creator_url":"https://huggingface.co/Sara237","description":"Sara237/gsm8k-translated dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","English","German","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"ruozhiba_r1_512","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/ruozhiba_r1_512","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"\\n\\t\\n\\t\\t\\n\\t\\tå¼±æ™ºå§ r1 512 æ•°æ®é›†\\n\\t\\n\\n\\næ­¤æ•°æ®é›†æ¥æºäºå¼±æ™ºå§æ”¶é›†é¢˜ç›®ï¼Œåˆæ­¥ç­›é€‰å»é™¤ä¸€å°éƒ¨åˆ†åŠ£è´¨é—®é¢˜ï¼ˆçœ‹èµ·æ¥ä¸åƒé—®é¢˜çš„æ ‡é¢˜ï¼‰\\né€šè¿‡è°ƒç”¨ deepseek r1 ä½œç­”ï¼Œæ”¶é›†äº† think å’Œå›ç­”\\né™åˆ¶æ€è€ƒä½¿ç”¨ token æ•°ï¼Œæ¥è¿‘æˆ–å°äº 512 token ï¼ˆé™åˆ¶çš„åŸå› æ˜¯ï¼Œæœ¬æ•°æ®é›†æˆ‘åªç”¨äºå†·å¯åŠ¨é˜¶æ®µï¼‰ï¼Œå›ç­” token æ²¡é™åˆ¶\\nå¯èƒ½ä¼šæœ‰ä¸€å®šçš„å¤šæ ·æ€§ï¼Œå› ä¸ºæ¨¡å‹å›ç­”æ¥æºäºå¤šä¸ªä¾›åº”å•†ç«¯ç‚¹ï¼ŒæŸäº›ä¾›åº”å•†å¯èƒ½æ˜¯æä¾›é‡åŒ–ç‰ˆæœ¬çš„r1\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tå¼•ç”¨\\n\\t\\n\\n\\nquestion å‡ºå¤„ï¼šhttps://docs.qq.com/sheet/DUlZ6aURhamdwb1RO?tab=BB08J2\\næ„Ÿè°¢ COIG-CQIA é¡¹ç›®çš„æ€è·¯ï¼š https://huggingface.co/datasets/m-a-p/COIG-CQIA\\n\\n","first_N":5,"first_N_keywords":["text-generation","Chinese","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Emilia-YODAS","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrfakename/Emilia-YODAS","creator_name":"mrfakename","creator_url":"https://huggingface.co/mrfakename","description":"A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.\\nhttps://huggingface.co/datasets/amphion/Emilia-Dataset\\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","German","French"],"keywords_longer_than_N":true},
	{"name":"squares-hs","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/squares1/squares-hs","creator_name":"squares","creator_url":"https://huggingface.co/squares1","description":"squares1/squares-hs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chinese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"fishmt5","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MHBS-IHB/fishmt5","creator_name":"Museum of Hydrobiological Sciences, Institute of Hydrobiology, Chinese Academy of Sciences","creator_url":"https://huggingface.co/MHBS-IHB","description":"\\n\\t\\n\\t\\t\\n\\t\\tFish Names Chinese-Latin Parallel Corpora\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nWe curated over 60,000 authoritative Chinese-Latin bilingual parallel corpora for fish names by integrating cross-source data, including Eschmeyer's Catalog of Fishes online database. Using a dual translation approach, we applied the Multilingual Text-to-Text Transfer Transformer (mT5) model to generate missing Chinese names.\\nNote: The current release provides 10,000 paired data entries.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MHBS-IHB/fishmt5.","first_N":5,"first_N_keywords":["translation","Chinese","Latin","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"achinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"Tobacco-Expert-Dataset2","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Eagle51/Tobacco-Expert-Dataset2","creator_name":"wuyi.yang","creator_url":"https://huggingface.co/Eagle51","description":"Eagle51/Tobacco-Expert-Dataset2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"yue chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true}
]
;
