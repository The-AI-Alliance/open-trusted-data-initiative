const data_for_language_asia_kannada = 
[
	{"name":"TinyDS-20k","keyword":"kannada","description":"\n\t\n\t\t\n\t\tTinyDS\n\t\n\n\n\n\nAlpaca-style dataset with around 20k samples scraped from Qwen3-8B using SyntheticAlpaca. Q&A pairs can be in 32 different languages, these are listed in the metadata.Topics are all around STEM, programming, and literature.  \nMIT @ 2025 Hamzah Asadullah\n\n\n","url":"https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","text2text-generation","English"],"keywords_longer_than_N":true},
	{"name":"BB-Ultrachat-IndicLingual6-12k","keyword":"kannada","description":"\n\t\n\t\t\n\t\tBB-Ultrachat-IndicLingual6-12k\n\t\n\nThis dataset is created by bhaiyabot ai to enrich language model training data, especially in the context of Indic languages. code for creation is also open source at https://github.com/ro-hansolo/IndicTrans2HuggingFaceDatasets\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nBB-Ultrachat-IndicLingual6-12k is a curated dataset comprising 12,000 multi-turn conversations, which are a subset of the larger HuggingFaceH4/ultrachat_200k dataset. These conversations have been evenly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rohansolo/BB-Ultrachat-IndicLingual6-12k.","url":"https://huggingface.co/datasets/rohansolo/BB-Ultrachat-IndicLingual6-12k","creator_name":"Rohan","creator_url":"https://huggingface.co/rohansolo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Hindi","Malayalam","Tamil"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"kannada","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following boolean‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Quixi AI","creator_url":"https://huggingface.co/QuixiAI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"seamless-align","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\n\n\t\n\t\t\n\t\tHow to use the data\n\t\n\nThere are two ways to access the data:\n\nVia the Hugging Face Python datasets library\n\nScripts coming soon‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align.","url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","audio-to-audio","Maltese","English","Welsh"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture","keyword":"kannada","description":"\n\n\n\t\n\t\t\n\t\tTulu 3 SFT Mixture\n\t\n\nNote that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe Tulu 3 SFT mixture was used to train the Tulu 3 series of models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3megds","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for xP3\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.\n\n\nCreation: The dataset can be recreated using instructions available here. We provide this version to save processing time and ease reproducibility.\nLanguages: 46 (Can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bigscience/xP3megds.","url":"https://huggingface.co/datasets/bigscience/xP3megds","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"naamapadam","keyword":"kannada","description":"\\","url":"https://huggingface.co/datasets/AnanthZeke/naamapadam","creator_name":"Ananth","creator_url":"https://huggingface.co/AnanthZeke","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","machine-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"multi-figqa","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for multi-figqa\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA multilingual dataset of human-written creative figurative expressions in many languages (mostly metaphors and similes). The English version (with the same format) can be found here\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nLanguages included are Hindi, Indonesian, Javanese, Kannada, Sundanese, Swahili, and Yoruba. The language codes are respectively hi, id, kn, su, sw, and yo.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmu-lti/multi-figqa.","url":"https://huggingface.co/datasets/cmu-lti/multi-figqa","creator_name":"CMU-LTI","creator_url":"https://huggingface.co/cmu-lti","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Hindi","Indonesian","Sundanese","Javanese"],"keywords_longer_than_N":true},
	{"name":"awesome_chatgpt_prompts_kannada","keyword":"kannada","description":"Kannada translation of fka/awesome-chatgpt-prompts\n","url":"https://huggingface.co/datasets/Sharathhebbar24/awesome_chatgpt_prompts_kannada","creator_name":"Sharath S Hebbar","creator_url":"https://huggingface.co/Sharathhebbar24","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","question-answering","text-generation","English","Kannada"],"keywords_longer_than_N":true},
	{"name":"awesome_chatgpt_prompts_kannada","keyword":"kannada","description":"Kannada translation of fka/awesome-chatgpt-prompts\n","url":"https://huggingface.co/datasets/Sharathhebbar24/awesome_chatgpt_prompts_kannada","creator_name":"Sharath S Hebbar","creator_url":"https://huggingface.co/Sharathhebbar24","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","question-answering","text-generation","English","Kannada"],"keywords_longer_than_N":true},
	{"name":"c4","keyword":"kannada","description":"\n\t\n\t\t\n\t\tC4\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA colossal, cleaned version of Common Crawl's web crawl corpus. Based on Common Crawl dataset: \"https://commoncrawl.org\".\nThis is the processed version of Google's C4 dataset\nWe prepared five variants of the data: en, en.noclean, en.noblocklist, realnewslike, and multilingual (mC4).\nFor reference, these are the sizes of the variants:\n\nen: 305GB\nen.noclean: 2.3TB\nen.noblocklist: 380GB\nrealnewslike: 15GB\nmultilingual (mC4): 9.7TB (108 subsets, one per‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/c4.","url":"https://huggingface.co/datasets/allenai/c4","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"kannada","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","Metlat√≥noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"naamapadam","keyword":"kannada","description":"\\","url":"https://huggingface.co/datasets/ai4bharat/naamapadam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","machine-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"CC-Cat","keyword":"kannada","description":"\n\t\n\t\t\n\t\tCC_Cat\n\t\n\n\nExtract from CC-WARC snapshots.\nMainly includes texts with 149 languages.\nPDF/IMAGE/AUDIO/VIDEO raw downloading link.\n\n\n\t\n\t\t\n\t\tNotice\n\t\n\n\nSince my computing resources are limited, this dataset will update by one-day of CC snapshots timestampts.\nAfter a snapshot is updated, the deduplicated version will be uploaded.\nIf you are interested in providing computing resources or have cooperation needs, please contact me.\n  carreyallthetime@gmail.com  \n      \n  \n\n","url":"https://huggingface.co/datasets/chengshidehaimianti/CC-Cat","creator_name":"zyq","creator_url":"https://huggingface.co/chengshidehaimianti","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","English","German","Russian"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"kannada","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/fleurs.","url":"https://huggingface.co/datasets/google/fleurs","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"lehengas-in-schools-question-bank","keyword":"kannada","description":"\n\t\n\t\t\n\t\tCultural Knowledge Question Bank\n\t\n\nThis dataset contains questions designed to evaluate cultural knowledge within the context of India.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is provided as a CSV file with the following fields:\n\n\t\n\t\t\nField\nDescription\n\n\n\t\t\nID\nUnique identifier\n\n\nDifficulty\nQuestion difficulty level (e.g., Easy, Medium, Hard)\n\n\nQuestion\nQuestion text\n\n\nAnswer\nCorrect answer text\n\n\nType\nQuestion type (e.g., MCQ, One-word, etc.)\n\n\nLanguage\nLanguage of the question‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kirtibg/lehengas-in-schools-question-bank.","url":"https://huggingface.co/datasets/Kirtibg/lehengas-in-schools-question-bank","creator_name":"Kirti Bhagat","creator_url":"https://huggingface.co/Kirtibg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Tamil","Oriya","Telugu"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent","keyword":"kannada","description":"\n  MassiveIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveIntentClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_intent.","url":"https://huggingface.co/datasets/mteb/amazon_massive_intent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"finepdfs","keyword":"kannada","description":"\n\nLiberating 3T of the finest tokens from PDFs\n\n\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nAs we run out of web pages to process, the natural question has always been: what to do next? Only a few knew about a data source that everyone avoided for ages, due to its incredible extraction cost and complexity: PDFs.\nüìÑ FinePDFs is exactly that. It is the largest publicly available corpus sourced exclusively from PDFs, containing about 3 trillion tokens across 475 million documents in 1733 languages.\nCompared to HTML‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/finepdfs.","url":"https://huggingface.co/datasets/HuggingFaceFW/finepdfs","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"Question-Sparql","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 895,954 examples of natural language questions paired with their corresponding SPARQL queries. It spans 12 languages and targets 15 distinct knowledge graphs, with a significant portion focused on Wikidata and DBpedia.\nThe dataset was developed as a contribution for the Master Thesis: \"Impact of Continual Multilingual Pre-training on Cross-Lingual Transferability for Source Languages\". Its purpose is to facilitate research in text-to-SPARQL‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/julioc-p/Question-Sparql.","url":"https://huggingface.co/datasets/julioc-p/Question-Sparql","creator_name":"Julio Perez","creator_url":"https://huggingface.co/julioc-p","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","German","Hebrew","Kannada"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"Fleurs-Kn","keyword":"kannada","description":"This is a filtered version of the Fleurs dataset only containing samples of Kannada language.\nThe dataset contains total of 2283 training, 368 validation and 838 test samples.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': 1053,\n 'num_samples': 226560,\n 'path': '/home/ravi.naik/.cache/huggingface/datasets/downloads/extracted/e7c8b501d4e6892673b6dc291d42de48e7987b0d2aa6471066a671f686224ed1/10000267636955490843.wav',\n 'audio': {'path': 'train/10000267636955490843.wav',\n  'array': array([ 0.        ,  0.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RaviNaik/Fleurs-Kn.","url":"https://huggingface.co/datasets/RaviNaik/Fleurs-Kn","creator_name":"Ravi Naik","creator_url":"https://huggingface.co/RaviNaik","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"kannada","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"IndicSentiment","keyword":"kannada","description":"\n  IndicSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA new, multilingual, and n-way parallel dataset for sentiment analysis in 13 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReferencehttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicSentimentClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicSentiment.","url":"https://huggingface.co/datasets/mteb/IndicSentiment","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"IndicReviewsClusteringP2P","keyword":"kannada","description":"\n  IndicReviewsClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of reviews from IndicSentiment dataset. Clustering of 14 sets on the generic categories label.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicReviewsClusteringP2P\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicReviewsClusteringP2P.","url":"https://huggingface.co/datasets/mteb/IndicReviewsClusteringP2P","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"kannada","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"bhasha-wiki-indic","keyword":"kannada","description":"\n\t\n\t\t\n\t\tBhasha Wiki Indic\n\t\n\n\nThis dataset has Wikipedia articles pertaining to Indian context.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThe dataset is built from Wikipedia articles taken from wikimedia/wikipedia. \nWe filtered, cleaned and translated English articles related to India and Indian context out of entire dataset.\nEach example has contents of a full cleaned wikipedia article and it's translations in 6 Indian languages.\n\nCurated by: Soket AI Labs\nLanguage(s) (NLP):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/soketlabs/bhasha-wiki-indic.","url":"https://huggingface.co/datasets/soketlabs/bhasha-wiki-indic","creator_name":"Soket Labs","creator_url":"https://huggingface.co/soketlabs","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","Bengali"],"keywords_longer_than_N":true},
	{"name":"limmits-2024","keyword":"kannada","description":"\n\t\n\t\t\n\t\n\t\n\t\tIndic TTS dataset\n\t\n\n7 languages from IISC's LIMMITS Challenge 2024\n\n\t\n\t\t\n\t\n\t\n\t\tRoadmap\n\t\n\nTo use this for training VALLE-X & VoiceBox based TTS models\n\n\t\n\t\t\n\t\n\t\n\t\tFetch the tars directly\n\t\n\nwget -O 'Bengali_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Bengali_F.tar.gz'\nwget -O 'Chhattisgarhi_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/Chhattisgarhi_F.tar.gz'\nwget -O 'English_F.tar.gz' 'https://ee.iisc.ac.in/limmitsdataset/download/English_F.tar.gz'\nwget -O‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iAkashPaul/limmits-2024.","url":"https://huggingface.co/datasets/iAkashPaul/limmits-2024","creator_name":"Akash","creator_url":"https://huggingface.co/iAkashPaul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","English","Bengali","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"IndicLangClassification","keyword":"kannada","description":"\n  IndicLangClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Non-fiction, Written\nReference\nhttps://arxiv.org/abs/2305.15814\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicLangClassification\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicLangClassification.","url":"https://huggingface.co/datasets/mteb/IndicLangClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-annotated","monolingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"IN22ConvBitextMining","keyword":"kannada","description":"\n  IN22ConvBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Conv is a n-way parallel conversation domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nSocial, Spoken, Fiction, Spoken\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Conv\n\n\n\t\n\nSource datasets:\n\nmteb/IN22-Conv\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22ConvBitextMining.","url":"https://huggingface.co/datasets/mteb/IN22ConvBitextMining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-annotated","multilingual","mteb/IN22-Conv","Assamese"],"keywords_longer_than_N":true},
	{"name":"Laion-Coco-Kn","keyword":"kannada","description":"laion-coco dataset with captions translated to Kannada language. The dataset contains 733604 training and \n14906 test samples. Images can be downloaded directly from Coco page.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': 'dde3bdc5-36b7-4340-b2ae-d9564c0d213a',\n 'url': 'https://i.pinimg.com/236x/ca/84/a1/ca84a1d6f83c88c94452a94e320f024c--lens.jpg',\n 'eng_caption': 'Black and white photograph of woman in hat leaning against tree.',\n 'score': 5.8029,\n 'kn_caption': '‡≤Æ‡≤∞‡≤¶ ‡≤µ‡≤ø‡≤∞‡≥Å‡≤¶‡≥ç‡≤ß ‡≤í‡≤∞‡≤ó‡≤ø‡≤∞‡≥Å‡≤µ ‡≤ü‡≥ã‡≤™‡≤ø ‡≤π‡≥ä‡≤Ç‡≤¶‡≤ø‡≤∞‡≥Å‡≤µ ‡≤Æ‡≤π‡≤ø‡≤≥‡≥Ü‡≤Ø‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RaviNaik/Laion-Coco-Kn.","url":"https://huggingface.co/datasets/RaviNaik/Laion-Coco-Kn","creator_name":"Ravi Naik","creator_url":"https://huggingface.co/RaviNaik","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","Kannada","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"kannada","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"kannada","description":"\n\t\n\t\t\n\t\tWMT24++\n\t\n\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\nthe publication\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\nIf you are interested in the images of the source URLs for each document, please see here.\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach language pair is stored in its own jsonl file.\nEach row is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"IndicQARetrieval","keyword":"kannada","description":"\n  IndicQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIndicQA is a manually curated cloze-style reading comprehension dataset that can be used for evaluating question-answering models in 11 Indic languages. It is repurposed retrieving relevant context for each question.\n\n\t\n\t\t\n\n\n\n\n\t\tTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicQARetrieval.","url":"https://huggingface.co/datasets/mteb/IndicQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","translated","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"IndicMSMARCO","keyword":"kannada","description":"\n\t\n\t\t\n\t\tüîç IndicMSMARCO: Multilingual Information Retrieval Benchmark\n\t\n\nA comprehensive multilingual variant of MS MARCO specifically tailored for Indian languages, featuring carefully selected queries and corresponding passages with high-quality translations.\n\n\t\n\t\t\n\t\tüöÄ Quick Start - Load Individual Languages\n\t\n\nfrom datasets import load_dataset\n\n# Load ONLY Hindi data (fast and efficient!)\nhindi_data = load_dataset(\"ai4bharat/IndicMSMARCO\", \"hi\")\nprint(f\"Hindi queries:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/IndicMSMARCO.","url":"https://huggingface.co/datasets/ai4bharat/IndicMSMARCO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multilingual","ms_marco","Assamese"],"keywords_longer_than_N":true},
	{"name":"montok","keyword":"kannada","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tTraining Details\n\t\n\n\n\t\n\t\t\n\t\tTraining Data\n\t\n\nAll tokenizers are trained on samples of the data used to the train the Goldfish language models. \nThe tokenizers were either trained on scaled or unscaled data. This refers to whether the models are trained on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/montok.","url":"https://huggingface.co/datasets/catherinearnett/montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"IN22-Conv","keyword":"kannada","description":"\n  IN22ConvBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Conv is a n-way parallel conversation domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nSocial, Spoken, Fiction, Spoken\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Conv\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Conv.","url":"https://huggingface.co/datasets/mteb/IN22-Conv","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"mallu.ai","keyword":"kannada","description":"mdallannavar/mallu.ai dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mdallannavar/mallu.ai","creator_name":"Mallikarjun","creator_url":"https://huggingface.co/mdallannavar","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","English","Kannada","Hindi"],"keywords_longer_than_N":true},
	{"name":"Telugu-NLP-AI-Dialect-Comedy-video-Dataset","keyword":"kannada","description":"Telugu is one of the sweetest and oldest languages of India. A deep Dive into Telugu its spoken in 2 states and majorly 16 regional dailects.\nThis Dataset help you perform operations in NLP and Speech Recognition Models towards telugu Dialects.\n","url":"https://huggingface.co/datasets/Automation-Tribe/Telugu-NLP-AI-Dialect-Comedy-video-Dataset","creator_name":"AUTTRIBE-AI-AUTOMATION","creator_url":"https://huggingface.co/Automation-Tribe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","Telugu","Kannada","English"],"keywords_longer_than_N":true},
	{"name":"fiNERweb","keyword":"kannada","description":"fiNERweb is a multilingual named entity recognition dataset containing annotated text in multiple languages.\nEach example contains the original text, tokenized text, BIO tags, and character/token spans for entities.","url":"https://huggingface.co/datasets/whoisjones/fiNERweb","creator_name":"Jonas Golde","creator_url":"https://huggingface.co/whoisjones","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","Vietnamese","Tamil","Oriya"],"keywords_longer_than_N":true},
	{"name":"Fleurs-Kn","keyword":"kannada","description":"This is a filtered version of the Fleurs dataset only containing samples of Kannada language.\nThe dataset contains total of 2283 training, 368 validation and 838 test samples.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': 1053,\n 'num_samples': 226560,\n 'path': '/home/ravi.naik/.cache/huggingface/datasets/downloads/extracted/e7c8b501d4e6892673b6dc291d42de48e7987b0d2aa6471066a671f686224ed1/10000267636955490843.wav',\n 'audio': {'path': 'train/10000267636955490843.wav',\n  'array': array([ 0.        ,  0.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Indic-LLM-Labs/Fleurs-Kn.","url":"https://huggingface.co/datasets/Indic-LLM-Labs/Fleurs-Kn","creator_name":"Indic-LLM-Labs","creator_url":"https://huggingface.co/Indic-LLM-Labs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"kannada","description":"Todo - Write dataset card\n","url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Kannada"],"keywords_longer_than_N":true},
	{"name":"indic_sts","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for Indic STS\n\t\n\nThis dataset is STS benchmark between English and 12 high-resource Indic languages. This was released as a part of Samanantar paper. Please refer to the paper for more details.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAvailable languages are: en-as, en-bn, en-gu, en-hi, en-kn, en-ml, en-mr, en-or, en-pa, en-ta, en-te, en-ur\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataset Fields\n\t\n\n\nlang_code: 2-digit ISO language code\nsource: The source from which the candidate sentence is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/indic_sts.","url":"https://huggingface.co/datasets/mteb/indic_sts","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"kannada","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"en-te-kn-translation-dataset","keyword":"kannada","description":"\n\t\n\t\t\n\t\tüìö Multilingual English-Telugu-Kannada Translation Dataset\n\t\n\nThis dataset is a curated and preprocessed subset of the AI4Bharat Samanantar dataset focused on multilingual translation tasks between English, Telugu (te_IN), and Kannada (kn_IN).\n\n\t\n\t\t\n\t\t‚ú® Dataset Features\n\t\n\n\nLanguage pairs:\nen ‚Üî te_IN\nen ‚Üî kn_IN\n\n\nPreprocessed:\nFiltered for sentence length (min=3, max=128 words)\nCleaned and normalized\n\n\nTokenized using Hugging Face Transformers tokenizers:\nM2M100Tokenizer (for en‚Üîkn)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Koushim/en-te-kn-translation-dataset.","url":"https://huggingface.co/datasets/Koushim/en-te-kn-translation-dataset","creator_name":"K Koushik Reddy","creator_url":"https://huggingface.co/Koushim","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","manual","found","multilingual","ai4bharat/samanantar"],"keywords_longer_than_N":true},
	{"name":"Tatoeba-Translations","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the latest version of Tatoeba translations as of December 2024.\nThe sentences are downloaded from the Tatoeba collection website.\nThe dataset is processed through mapping sentences.tar.bz2 using sentences_base.tar.bz2 to find source (sentence_src) and target (sentence_tgt) sentences.\nWhile lang_src and lang_tgt columns follow the mapping provided by Tatoeba, the lang_pair column merely lists the two languages in the translation pair.\n\n\t\n\t\t\n\t\n\t\n\t\tStatistics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-Translations.","url":"https://huggingface.co/datasets/ymoslem/Tatoeba-Translations","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","multilingual","Abkhaz","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"indic_sts","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for Indic STS\n\t\n\nThis dataset is STS benchmark between English and 12 high-resource Indic languages. This was released as a part of Samanantar paper. Please refer to the paper for more details.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAvailable languages are: en-as, en-bn, en-gu, en-hi, en-kn, en-ml, en-mr, en-or, en-pa, en-ta, en-te, en-ur\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataset Fields\n\t\n\n\nlang_code: 2-digit ISO language code\nsource: The source from which the candidate sentence is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jaygala24/indic_sts.","url":"https://huggingface.co/datasets/jaygala24/indic_sts","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for BibleNLP Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPartial and complete Bible translations in 833 languages, aligned by verse.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\naai, aak, aau, aaz, abt, abx, aby, acf, acr, acu, adz, aer, aey, agd, agg, agm, agn, agr, agt, agu, aia, aii, aka, ake, alp, alq, als, aly, ame, amf, amk, amm, amn, amo, amp, amr, amu, amx, anh, anv, aoi, aoj, aom, aon, apb, ape, apn, apr, apu, apw, apz, arb, are, arl, arn, arp, asm, aso, ata, atb, atd, atg, att, auc, aui, auy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bible-nlp/biblenlp-corpus.","url":"https://huggingface.co/datasets/bible-nlp/biblenlp-corpus","creator_name":"The Partnership for Applied Biblical NLP","creator_url":"https://huggingface.co/bible-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","expert-generated","translation","multilingual"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"kannada","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"bernice-pretrain-data","keyword":"kannada","description":"Tweet IDs for the 2.5 billion multilingual tweets used to train Bernice, a Twitter encoder.\nThe tweets are from the public 1% Twitter API stream from January 2016 to December 2021. \nTwitter-provided language metadata is provided with the tweet ID. The data contains 66 unique languages, \nas identified by ISO 639 language codes, including `und` for undefined languages.\nTweets need to be re-gathered via the Twitter API.","url":"https://huggingface.co/datasets/jhu-clsp/bernice-pretrain-data","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","no-annotation","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"kannada","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"indicxnli","keyword":"kannada","description":"IndicXNLI is a translated version of XNLI to 11 Indic Languages. As with XNLI, the goal is\nto predict textual entailment (does sentence A imply/contradict/neither sentence\nB) and is a classification task (given two sentences, predict one of three\nlabels).","url":"https://huggingface.co/datasets/Divyanshu/indicxnli","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","machine-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"Kannada-Dataset-v03","keyword":"kannada","description":"charanhu/Kannada-Dataset-v03 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/charanhu/Kannada-Dataset-v03","creator_name":"Charan H U","creator_url":"https://huggingface.co/charanhu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Kannada","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Kannada-Dataset-v03","keyword":"kannada","description":"charanhu/Kannada-Dataset-v03 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/charanhu/Kannada-Dataset-v03","creator_name":"Charan H U","creator_url":"https://huggingface.co/charanhu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Kannada","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"nllb-200-10M-sample","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for \"nllb-200-10M-sample\"\n\t\n\nThis is a sample of nearly 10M sentence pairs from the NLLB-200 \nmined dataset allenai/nllb, \nscored with the model facebook/blaser-2.0-qe \ndescribed in the SeamlessM4T paper.\nThe sample is not random; instead, we just took the top n sentence pairs from each translation direction.\nThe number n was computed with the goal of upsamping the directions that contain underrepresented languages.\nNevertheless, the 187 languoids (language and script‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slone/nllb-200-10M-sample.","url":"https://huggingface.co/datasets/slone/nllb-200-10M-sample","creator_name":"SLONE","creator_url":"https://huggingface.co/slone","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Akan","Amharic","Arabic","Awadhi"],"keywords_longer_than_N":true},
	{"name":"bible_para","keyword":"kannada","description":"This is a multilingual parallel corpus created from translations of the Bible compiled by Christos Christodoulopoulos and Mark Steedman.\n\n102 languages, 5,148 bitexts\ntotal number of files: 107\ntotal number of tokens: 56.43M\ntotal number of sentence fragments: 2.84M","url":"https://huggingface.co/datasets/Helsinki-NLP/bible_para","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"kannada","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Viet-Mistral/CulturaY.","url":"https://huggingface.co/datasets/Viet-Mistral/CulturaY","creator_name":"Vietnamese Mistral","creator_url":"https://huggingface.co/Viet-Mistral","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"IndicQA","keyword":"kannada","description":"\\","url":"https://huggingface.co/datasets/ai4bharat/IndicQA","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"IndicCOPA","keyword":"kannada","description":"\\","url":"https://huggingface.co/datasets/ai4bharat/IndicCOPA","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3mt","keyword":"kannada","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"kannada","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Kannada"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"kannada","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"INDICSTR12_REAL_IMAGES","keyword":"kannada","description":"ananya12k/INDICSTR12_REAL_IMAGES dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ananya12k/INDICSTR12_REAL_IMAGES","creator_name":"Ananya Kulkarni","creator_url":"https://huggingface.co/ananya12k","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Marathi","Bengali","Kannada","Oriya","Panjabi"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"kannada","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Kannada"],"keywords_longer_than_N":true},
	{"name":"guvi_multilingual_dataset","keyword":"kannada","description":"zaid002/guvi_multilingual_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zaid002/guvi_multilingual_dataset","creator_name":"Mohammed Zaid p","creator_url":"https://huggingface.co/zaid002","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Urdu","Tamil","Hindi"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_scenario","keyword":"kannada","description":"\n  MassiveScenarioClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveScenarioClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_scenario.","url":"https://huggingface.co/datasets/mteb/amazon_massive_scenario","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"IndicCrosslingualSTS","keyword":"kannada","description":"\n  IndicCrosslingualSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a Semantic Textual Similarity testset between English and 12 high-resource Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Non-fiction, Web, Spoken, Government, Written, Spoken\nReference\nhttps://huggingface.co/datasets/jaygala24/indic_sts\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicCrosslingualSTS.","url":"https://huggingface.co/datasets/mteb/IndicCrosslingualSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","expert-annotated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"Laion-Coco-Kn","keyword":"kannada","description":"laion-coco dataset with captions translated to Kannada language. The dataset contains 733604 training and \n14906 test samples. Images can be downloaded directly from Coco page.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': 'dde3bdc5-36b7-4340-b2ae-d9564c0d213a',\n 'url': 'https://i.pinimg.com/236x/ca/84/a1/ca84a1d6f83c88c94452a94e320f024c--lens.jpg',\n 'eng_caption': 'Black and white photograph of woman in hat leaning against tree.',\n 'score': 5.8029,\n 'kn_caption': '‡≤Æ‡≤∞‡≤¶ ‡≤µ‡≤ø‡≤∞‡≥Å‡≤¶‡≥ç‡≤ß ‡≤í‡≤∞‡≤ó‡≤ø‡≤∞‡≥Å‡≤µ ‡≤ü‡≥ã‡≤™‡≤ø ‡≤π‡≥ä‡≤Ç‡≤¶‡≤ø‡≤∞‡≥Å‡≤µ ‡≤Æ‡≤π‡≤ø‡≤≥‡≥Ü‡≤Ø‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Indic-LLM-Labs/Laion-Coco-Kn.","url":"https://huggingface.co/datasets/Indic-LLM-Labs/Laion-Coco-Kn","creator_name":"Indic-LLM-Labs","creator_url":"https://huggingface.co/Indic-LLM-Labs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","Kannada","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"CulturaX-Kn","keyword":"kannada","description":"This is a filtered version of the CulturaX dataset only containing samples of Kannada language.\nThe dataset contains total of 1352142 samples.\n\n\t\n\t\t\n\t\tDataset Structure:\n\t\n\n{\n    \"text\": ...,\n    \"timestamp\": ...,\n    \"url\": ...,\n    \"source\": \"mc4\" | \"OSCAR-xxxx\",\n}\n\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'text': \"‡≤≠‡≤ü‡≥ç‡≤ï‡≤≥ : ‡≤§‡≤Ç‡≤¶‡≥Ü ‡≤§‡≤æ‡≤Ø‡≤ø ‡≤∏‡≥ç‡≤Æ‡≤∞‡≤£‡≤æ‡≤∞‡≥ç‡≤• ; ‡≤â‡≤ö‡≤ø‡≤§ ‡≤®‡≥ã‡≤ü‡≥ç ‡≤¨‡≥Å‡≤ï‡≥ç ‡≤µ‡≤ø‡≤§‡≤∞‡≤£‡≥Ü | Vartha Bharati- ‡≤µ‡≤æ‡≤∞‡≥ç‡≤§‡≤æ ‡≤≠‡≤æ‡≤∞‡≤§‡≤ø\\n‡≤Æ‡≥Å‡≤¶‡≤∞‡≤Ç‡≤ó‡≤°‡≤ø ‡≤¨‡≤ø‡≤ú‡≥Ü‡≤™‡≤ø ‡≤ó‡≥ç‡≤∞‡≤æ‡≤™‡≤Ç ‡≤∏‡≤¶‡≤∏‡≥ç‡≤Ø‡≤∞ ‡≤µ‡≤ø‡≤∞‡≥Å‡≤¶‡≥ç‡≤ß ‡≤™‡≥ç‡≤∞‡≤§‡≤ø‡≤≠‡≤ü‡≤®‡≥Ü\\n‡≤π‡≥ã‡≤Æ‡≥ç ‡≤ï‡≥ç‡≤µ‡≤æ‡≤∞‡≤Ç‡≤ü‡≥à‡≤®‡≥ç ‡≤®‡≤ø‡≤Ø‡≤Æ ‡≤â‡≤≤‡≥ç‡≤≤‡≤Ç‡≤ò‡≤®‡≥Ü: ‡≤™‡≥ç‡≤∞‡≤ï‡≤∞‡≤£ ‡≤¶‡≤æ‡≤ñ‡≤≤‡≥Å\\n‡≤≠‡≤ü‡≥ç‡≤ï‡≤≥ : ‡≤§‡≤Ç‡≤¶‡≥Ü ‡≤§‡≤æ‡≤Ø‡≤ø‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RaviNaik/CulturaX-Kn.","url":"https://huggingface.co/datasets/RaviNaik/CulturaX-Kn","creator_name":"Ravi Naik","creator_url":"https://huggingface.co/RaviNaik","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Kannada","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Kannada"],"keywords_longer_than_N":true},
	{"name":"Indic-Rag-Suite","keyword":"kannada","description":"\n\t\n\t\t\n\t\tüåè Multilingual Indic RAG Suite\n\t\n\nA comprehensive multilingual question-answering dataset covering 18 Indian languages with 12,802,615 total samples, designed for RAG (Retrieval-Augmented Generation) applications and multilingual NLP research.\n\n\t\n\t\t\n\t\tüöÄ Quick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load specific language (recommended)\ndataset = load_dataset(\"AshwinSankar/Indic-Rag-Suite\", \"as\")\ntrain_data = dataset['train']\n\nprint(f\"Loaded {len(train_data)} samples\")\n\n# Access‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AshwinSankar/Indic-Rag-Suite.","url":"https://huggingface.co/datasets/AshwinSankar/Indic-Rag-Suite","creator_name":"Ashwin Sankar","creator_url":"https://huggingface.co/AshwinSankar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","multilingual","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"kannada","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"kannada","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages ‚Üí dolly-machine-translated.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture-with-language","keyword":"kannada","description":"\n\nJust a version of the good tulu-3-sft-mixture dataset with a column indicating language.\nLanguage detection has been performed with fastText.\n‚ö†Ô∏è It may contain errors.\n","url":"https://huggingface.co/datasets/anakin87/tulu-3-sft-mixture-with-language","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"Wikipedia-Kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for \"Wikipedia-Kn\"\n\t\n\nThis is a filtered version of the Wikipedia dataset only containing samples of Kannada language. \nThe dataset contains total of 31437 samples.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': '832',\n 'url': 'https://kn.wikipedia.org/wiki/%E0%B2%A1%E0%B2%BF.%E0%B2%B5%E0%B2%BF.%E0%B2%97%E0%B3%81%E0%B2%82%E0%B2%A1%E0%B2%AA%E0%B3%8D%E0%B2%AA',\n 'title': '‡≤°‡≤ø.‡≤µ‡≤ø.‡≤ó‡≥Å‡≤Ç‡≤°‡≤™‡≥ç‡≤™',\n 'text': '‡≤°‡≤ø ‡≤µ‡≤ø ‡≤ú‡≤ø(‡≤Æ‡≤æ‡≤∞‡≥ç‡≤ö‡≥ç ‡≥ß‡≥≠, ‡≥ß‡≥Æ‡≥Æ‡≥≠ - ‡≤Ö‡≤ï‡≥ç‡≤ü‡≥ã‡≤¨‡≤∞‡≥ç ‡≥≠, ‡≥ß‡≥Ø‡≥≠‡≥´) ‡≤é‡≤Ç‡≤¨ ‡≤π‡≥Ü‡≤∏‡≤∞‡≤ø‡≤®‡≤ø‡≤Ç‡≤¶ ‡≤™‡≥ç‡≤∞‡≤∏‡≤ø‡≤¶‡≥ç‡≤ß‡≤∞‡≤æ‡≤¶ ‡≤°‡≤æ. ‡≤¶‡≥á‡≤µ‡≤®‡≤π‡≤≥‡≥ç‡≤≥‡≤ø‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Indic-LLM-Labs/Wikipedia-Kn.","url":"https://huggingface.co/datasets/Indic-LLM-Labs/Wikipedia-Kn","creator_name":"Indic-LLM-Labs","creator_url":"https://huggingface.co/Indic-LLM-Labs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Kannada","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"IndicVarna-100k","keyword":"kannada","description":"\n\t\n\t\t\n\t\tIndicVarna for Callchimp.ai (a Dynopii product)\n\t\n\nWe introduce IndiVarna which was prepared by using Google Translate on the dair-ai/emotion dataset to get the samples there translated to the top 10 most commonly used Indian languages.\nThis dataset contains 10000 samples of each of the 10 languages supported.\nThe dataset further translated the labels in the dataset to 3 label sentiments - 0: Negative, 1: Neutral and 2: Positive. Each language has 3334 samples of each category of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dynopii/IndicVarna-100k.","url":"https://huggingface.co/datasets/dynopii/IndicVarna-100k","creator_name":"Dynopii Inc","creator_url":"https://huggingface.co/dynopii","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","sentence-similarity","fill-mask","text-generation"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"kannada","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Kannada"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"kannada","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"IN22-Conv-Doc-Level","keyword":"kannada","description":"This dataset was constructed by merging individual conversations from the IN22-Conv dataset to create a long-context, document-level parallel benchmark. For further information on domains and statistics, please refer to the original paper and dataset.\n","url":"https://huggingface.co/datasets/VarunGumma/IN22-Conv-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"english-to-kannada-mt","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nEnglish to Kannada Machine Translation \n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nShared by [optional]:  https://huggingface.co/Avanthika/language-translation\nLanguage(s) (NLP): Kannada,English\nLicense: mit\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nRepository: https://huggingface.co/Avanthika/language-translation\n\n\n","url":"https://huggingface.co/datasets/Hemanth-thunder/english-to-kannada-mt","creator_name":"Hemanth-thunder","creator_url":"https://huggingface.co/Hemanth-thunder","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Kannada","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"indicCorpv2","keyword":"kannada","description":"    IndicCORPV2 is the largest collection of texts for Indic langauges consisting of 20.9 Billion tokens of which 14.4B tokens correspond to 23 Indic languages and 6.B tokens of Indian English content curated from Indian websites.","url":"https://huggingface.co/datasets/satpalsr/indicCorpv2","creator_name":"Satpal Singh Rathore","creator_url":"https://huggingface.co/satpalsr","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","Assamese","Bodo (India)","Bengali","Dogri (macrolanguage)"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"kannada","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"kannada","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"oscar-mini","keyword":"kannada","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-mini","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"Bhasha-Abhijnaanam","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for Aksharantar\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBhasha-Abhijnaanam is a language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\n\t\n\t\t\n\n\n\n\n\n\n\n\n\t\t\nAssamese (asm)\nHindi (hin)\nMaithili (mai)\nNepali (nep)\nSanskrit (san)\nTamil (tam)\n\n\nBengali (ben)\nKannada (kan)\nMalayalam (mal)\nOriya (ori)\nSantali (sat)\nTelugu (tel)\n\n\nBodo(brx)\nKashmiri‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam.","url":"https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Fran√ßais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"kannada","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cahya/fleurs.","url":"https://huggingface.co/datasets/cahya/fleurs","creator_name":"Cahya Wirawan","creator_url":"https://huggingface.co/cahya","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"tatoeba","keyword":"kannada","description":"This is a collection of translated sentences from Tatoeba\n359 languages, 3,403 bitexts\ntotal number of files: 750\ntotal number of tokens: 65.54M\ntotal number of sentence fragments: 8.96M","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ms_terms","keyword":"kannada","description":"The Microsoft Terminology Collection can be used to develop localized versions of applications that integrate with Microsoft products.\nIt can also be used to integrate Microsoft terminology into other terminology collections or serve as a base IT glossary\nfor language development in the nearly 100 languages available. Terminology is provided in .tbx format, an industry standard for terminology exchange.","url":"https://huggingface.co/datasets/microsoft/ms_terms","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","license_name":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":null,"first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","multilingual","translation"],"keywords_longer_than_N":true},
	{"name":"kan_hope","keyword":"kannada","description":"Numerous methods have been developed to monitor the spread of negativity in modern years by\neliminating vulgar, offensive, and fierce comments from social media platforms. However, there are relatively\nlesser amounts of study that converges on embracing positivity, reinforcing supportive and reassuring content in online forums.\nConsequently, we propose creating an English Kannada Hope speech dataset, KanHope and comparing several experiments to benchmark the dataset.\nThe dataset consists of 6,176 user generated comments in code mixed Kannada scraped from YouTube and manually annotated as bearing hope\nspeech or Not-hope speech.\nThis dataset was prepared for hope-speech text classification benchmark on code-mixed Kannada, an under-resourced language.","url":"https://huggingface.co/datasets/AdWeeb/kan_hope","creator_name":"Adeep Hande","creator_url":"https://huggingface.co/AdWeeb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","multi-label-classification","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"truthfulqa_indic","keyword":"kannada","description":"Original Repository\n\n\t\n\t\t\n\t\tTasks (from original repository)\n\t\n\n\n\t\n\t\t\n\t\tGeneration (main task):\n\t\n\nTask: Given a question, generate a 1-2 sentence answer.\nObjective: The primary objective is overall truthfulness, expressed as the percentage of the model's answers that are true. Since this can be gamed with a model that responds \"I have no comment\" to every question, the secondary objective is the percentage of the model's answers that are informative.\n\n\t\n\t\t\n\t\tFuture Work:\n\t\n\n\nValidate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vakyansh/truthfulqa_indic.","url":"https://huggingface.co/datasets/vakyansh/truthfulqa_indic","creator_name":"Vakyansh","creator_url":"https://huggingface.co/vakyansh","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Hindi","Panjabi","Telugu","Tamil"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-olmo-2-mixture","keyword":"kannada","description":"Note that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe OLMo v2 SFT mixture was used to train the OLMo models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et al., 2023)\nNo Robots (CC-BY-NC-4.0), 9,500‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3","keyword":"kannada","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","url":"https://huggingface.co/datasets/bigscience/xP3","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Shrutilipi","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for Shrutilipi (Full Version)\n\t\n\n\n\nThis is a full and unfiltered version of the Shrutilipi dataset for languages: Bengali, Hindi, Kannada, Malayalam, Marathi, Odia, Tamil and Telugu - originally described in the paper: Effectiveness of Mining Audio and Text Pairs from Public Data for Improving ASR Systems for Low-Resource Languages.\nThe data for Gujarati, Punjabi and Sanskrit will be uploaded later.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nSince the dataset was automatically curated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/skesiraju/Shrutilipi.","url":"https://huggingface.co/datasets/skesiraju/Shrutilipi","creator_name":"Santosh Kesiraju","creator_url":"https://huggingface.co/skesiraju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Bengali","Hindi","Kannada","Malayalam"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"kannada","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"milu-cleaned","keyword":"kannada","description":"\n\t\n\t\t\n\t\tMILU: A Multi-task Indic Language Understanding Benchmark\n\t\n\n\n  \n  \n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nMILU (Multi-task Indic Language Understanding Benchmark) is a comprehensive evaluation dataset designed to assess the performance of Large Language Models (LLMs) across 11 Indic languages. It spans 8 domains and 41 subjects, reflecting both general and culturally specific knowledge from India.\n\n\t\n\t\n\t\n\t\tKey Features\n\t\n\n\n11 Indian Languages: Bengali, Gujarati, Hindi, Kannada, Malayalam‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/murthyrudra/milu-cleaned.","url":"https://huggingface.co/datasets/murthyrudra/milu-cleaned","creator_name":"Rudra Murthy","creator_url":"https://huggingface.co/murthyrudra","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Kannada"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"kannada","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"Laion-Coco-Kn","keyword":"kannada","description":"laion-coco dataset with captions translated to Kannada language. The dataset contains 733604 training and \n14906 test samples. Images can be downloaded directly from Coco page.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': 'dde3bdc5-36b7-4340-b2ae-d9564c0d213a',\n 'url': 'https://i.pinimg.com/236x/ca/84/a1/ca84a1d6f83c88c94452a94e320f024c--lens.jpg',\n 'eng_caption': 'Black and white photograph of woman in hat leaning against tree.',\n 'score': 5.8029,\n 'kn_caption': '‡≤Æ‡≤∞‡≤¶ ‡≤µ‡≤ø‡≤∞‡≥Å‡≤¶‡≥ç‡≤ß ‡≤í‡≤∞‡≤ó‡≤ø‡≤∞‡≥Å‡≤µ ‡≤ü‡≥ã‡≤™‡≤ø ‡≤π‡≥ä‡≤Ç‡≤¶‡≤ø‡≤∞‡≥Å‡≤µ ‡≤Æ‡≤π‡≤ø‡≤≥‡≥Ü‡≤Ø‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kannada-LLM-Labs/Laion-Coco-Kn.","url":"https://huggingface.co/datasets/Kannada-LLM-Labs/Laion-Coco-Kn","creator_name":"Kannada LLM Labs","creator_url":"https://huggingface.co/Kannada-LLM-Labs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","Kannada","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Pralekha","keyword":"kannada","description":"\n\t\n\t\t\n\t\tPralekha: Cross-Lingual Document Alignment for Indic Languages\n\t\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\nPralekha is a large-scale parallel document dataset spanning across 11 Indic languages and English. It comprises over 3 milliondocument pairs, with 1.5 million being English-Indic Pairs. This dataset serves both as a benchmark for evaluating Cross-Lingual Document Alignment (CLDA) techniques and as a domain-specific parallel corpus for training document-level Machine‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Pralekha.","url":"https://huggingface.co/datasets/ai4bharat/Pralekha","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Bengali","English","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"eng_montok","keyword":"kannada","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\n","url":"https://huggingface.co/datasets/catherinearnett/eng_montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"shiksha","keyword":"kannada","description":"\n\t\n\t\t\n\t\tShiksha Dataset\n\t\n\nThis is a Technical Domain focused Translation Dataset for 8 Indian Languages. It consists of more than 2.5 million rows of translation pairs between all 8 languages and English.\nThis data has been derived from raw NPTEL documents. More information on this can be found in our paper: https://arxiv.org/abs/2412.09025\nIf you use this data in your work, please cite us:\n@misc{joglekar2024shikshatechnicaldomainfocused,\n      title={Shiksha: A Technical Domain focused‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/shiksha.","url":"https://huggingface.co/datasets/SPRINGLab/shiksha","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Hindi","Bengali","Tamil","Telugu"],"keywords_longer_than_N":true},
	{"name":"Flores-Indic-Doc-Level","keyword":"kannada","description":"This dataset was constructed by merging individual sentences from the Flores dataset based on matching domain, topic, and URL attributes. The result is a long-context, document-level parallel benchmark. For more details on the domains and dataset statistics, please refer to the original paper and the dataset.\n","url":"https://huggingface.co/datasets/VarunGumma/Flores-Indic-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"Indic_south_langs","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Logii33/Indic_south_langs.","url":"https://huggingface.co/datasets/Logii33/Indic_south_langs","creator_name":"Logesh","creator_url":"https://huggingface.co/Logii33","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Hindi","Tamil","Malayalam","Telugu"],"keywords_longer_than_N":true},
	{"name":"indic-squad","keyword":"kannada","description":"\n\t\n\t\t\n\t\tIndicSQuAD Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nIndicSQuAD is a comprehensive multilingual extractive Question Answering (QA) dataset covering nine major Indic languages: Hindi, Bengali, Tamil, Telugu, Marathi, Gujarati, Urdu, Kannada, Oriya, and Malayalam. It's systematically derived from the popular English SQuAD (Stanford Question Answering Dataset).\nThe rapid progress in QA systems has predominantly benefited high-resource languages, leaving Indic languages significantly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/l3cube-pune/indic-squad.","url":"https://huggingface.co/datasets/l3cube-pune/indic-squad","creator_name":"L3Cube Labs","creator_url":"https://huggingface.co/l3cube-pune","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gpt4o_gen","keyword":"kannada","description":"Youseff1987/multilingual_translation_gpt4o_gen dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gpt4o_gen","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"CoRil-Parallel","keyword":"kannada","description":"\n\t\n\t\t\n\t\tIndic Parallel Corpus: 11 Indian Language Pairs for Machine Translation\n\t\n\nThis repository contains a parallel corpus for machine translation across 11 Indian language pairs. The data is curated to cover three distinct domains: Governance, Health, and General. This dataset is designed to help researchers and developers build and evaluate robust machine translation models for Indian languages.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe corpus provides parallel sentences for a variety of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HimangY/CoRil-Parallel.","url":"https://huggingface.co/datasets/HimangY/CoRil-Parallel","creator_name":"HIndustani Machini ANuvaad TechnoloGY","creator_url":"https://huggingface.co/HimangY","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Hindi","Gujarati","Kashmiri","Telugu"],"keywords_longer_than_N":true},
	{"name":"guvi_fintuned_dataset","keyword":"kannada","description":"zaid002/guvi_fintuned_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zaid002/guvi_fintuned_dataset","creator_name":"Mohammed Zaid p","creator_url":"https://huggingface.co/zaid002","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["translation","table-question-answering","summarization","Urdu","English"],"keywords_longer_than_N":true},
	{"name":"Wikipedia-Kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for \"Wikipedia-Kn\"\n\t\n\nThis is a filtered version of the Wikipedia dataset only containing samples of Kannada language. \nThe dataset contains total of 31437 samples.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': '832',\n 'url': 'https://kn.wikipedia.org/wiki/%E0%B2%A1%E0%B2%BF.%E0%B2%B5%E0%B2%BF.%E0%B2%97%E0%B3%81%E0%B2%82%E0%B2%A1%E0%B2%AA%E0%B3%8D%E0%B2%AA',\n 'title': '‡≤°‡≤ø.‡≤µ‡≤ø.‡≤ó‡≥Å‡≤Ç‡≤°‡≤™‡≥ç‡≤™',\n 'text': '‡≤°‡≤ø ‡≤µ‡≤ø ‡≤ú‡≤ø(‡≤Æ‡≤æ‡≤∞‡≥ç‡≤ö‡≥ç ‡≥ß‡≥≠, ‡≥ß‡≥Æ‡≥Æ‡≥≠ - ‡≤Ö‡≤ï‡≥ç‡≤ü‡≥ã‡≤¨‡≤∞‡≥ç ‡≥≠, ‡≥ß‡≥Ø‡≥≠‡≥´) ‡≤é‡≤Ç‡≤¨ ‡≤π‡≥Ü‡≤∏‡≤∞‡≤ø‡≤®‡≤ø‡≤Ç‡≤¶ ‡≤™‡≥ç‡≤∞‡≤∏‡≤ø‡≤¶‡≥ç‡≤ß‡≤∞‡≤æ‡≤¶ ‡≤°‡≤æ. ‡≤¶‡≥á‡≤µ‡≤®‡≤π‡≤≥‡≥ç‡≤≥‡≤ø‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RaviNaik/Wikipedia-Kn.","url":"https://huggingface.co/datasets/RaviNaik/Wikipedia-Kn","creator_name":"Ravi Naik","creator_url":"https://huggingface.co/RaviNaik","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Kannada","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"kannada","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"kannada","description":"\n\n\n\t\n\t\t\n\t\tüî∑ Accepted in NAACL Proceedings (2025) üî∑\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval üìö [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"Wikipedia-Kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for \"Wikipedia-Kn\"\n\t\n\nThis is a filtered version of the Wikipedia dataset only containing samples of Kannada language. \nThe dataset contains total of 31437 samples.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': '832',\n 'url': 'https://kn.wikipedia.org/wiki/%E0%B2%A1%E0%B2%BF.%E0%B2%B5%E0%B2%BF.%E0%B2%97%E0%B3%81%E0%B2%82%E0%B2%A1%E0%B2%AA%E0%B3%8D%E0%B2%AA',\n 'title': '‡≤°‡≤ø.‡≤µ‡≤ø.‡≤ó‡≥Å‡≤Ç‡≤°‡≤™‡≥ç‡≤™',\n 'text': '‡≤°‡≤ø ‡≤µ‡≤ø ‡≤ú‡≤ø(‡≤Æ‡≤æ‡≤∞‡≥ç‡≤ö‡≥ç ‡≥ß‡≥≠, ‡≥ß‡≥Æ‡≥Æ‡≥≠ - ‡≤Ö‡≤ï‡≥ç‡≤ü‡≥ã‡≤¨‡≤∞‡≥ç ‡≥≠, ‡≥ß‡≥Ø‡≥≠‡≥´) ‡≤é‡≤Ç‡≤¨ ‡≤π‡≥Ü‡≤∏‡≤∞‡≤ø‡≤®‡≤ø‡≤Ç‡≤¶ ‡≤™‡≥ç‡≤∞‡≤∏‡≤ø‡≤¶‡≥ç‡≤ß‡≤∞‡≤æ‡≤¶ ‡≤°‡≤æ. ‡≤¶‡≥á‡≤µ‡≤®‡≤π‡≤≥‡≥ç‡≤≥‡≤ø‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kannada-LLM-Labs/Wikipedia-Kn.","url":"https://huggingface.co/datasets/Kannada-LLM-Labs/Wikipedia-Kn","creator_name":"Kannada LLM Labs","creator_url":"https://huggingface.co/Kannada-LLM-Labs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Kannada","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"kannada","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"Nadi_Indic466k_Instruct","keyword":"kannada","description":"\n\t\n\t\t\n\t\tNadi_Indic466K_Instruct Dataset\n\t\n\nThe Nadi_Indic466K_Instruct dataset is the world's first coding dataset with 18 Indian language support, 466k rows and 142 Million total tokens. This dataset can be used by developers to build Indian coding language models (LLMs) for various programming languages.\nQ-LoRA based SFT/PPO/DPO fine-tuning can be done on the dataset in LLAMA-2 or Mistral or any opens-soure LLM for text generation.\nThe dataset was carefully curated such that the coding part‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct.","url":"https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct","creator_name":"Convai Innovations","creator_url":"https://huggingface.co/convaiinnovations","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Hindi","Panjabi","Bengali","Tamil"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"kannada","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\n\n\t\n\t\t\n\nToxic\nNeutral\nTotal\n\n\n\t\t\nmultilingual-train-deduplicated.csv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Spanish","Panjabi"],"keywords_longer_than_N":true},
	{"name":"svq","keyword":"kannada","description":"\n\t\n\t\t\n\t\tSimple Voice Questions\n\t\n\nSimple Voice Questions (SVQ) is a set of short audio questions recorded in 26 locales across 17 languages under multiple audio conditions.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nSpeakers were presented with recording instructions specifying the recording environment and text query to be recorded.\nThey recorded using their own phones or tablets under four conditions:\n\nclean: Record in quiet environment\nbackground speech noise: Record while audio from sources like podcasts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/svq.","url":"https://huggingface.co/datasets/google/svq","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"myds","keyword":"kannada","description":"paricdac/myds dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/paricdac/myds","creator_name":"cdac","creator_url":"https://huggingface.co/paricdac","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Kannada","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"kannada","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"kannada","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"sangraha","keyword":"kannada","description":"\n\t\n\t\t\n\t\tSangraha\n\t\n\n\n  \n\n\nSangraha is the largest high-quality, cleaned Indic language pretraining data containing 251B tokens summed up over 22 languages, extracted from curated sources, existing multilingual corpora and large scale translations.\nMore information:\n\nFor detailed information on the curation and cleaning process of Sangraha, please checkout our paper on Arxiv;\nCheck out the scraping and cleaning pipelines used to curate Sangraha on GitHub;\n\n\n\t\n\t\n\t\n\t\tGetting Started\n\t\n\nFor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/sangraha.","url":"https://huggingface.co/datasets/ai4bharat/sangraha","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Assamese","Bengali","Gujarati","English"],"keywords_longer_than_N":true},
	{"name":"shrutilipi","keyword":"kannada","description":"amithm3/shrutilipi dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/amithm3/shrutilipi","creator_name":"Amith M","creator_url":"https://huggingface.co/amithm3","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","Sanskrit","Bengali","Panjabi"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"indic-parallel-sentences-talks","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for Parallel Sentences - Indic Talks\n\t\n\nThis dataset contains parallel sentences (i.e. English sentence + the same sentences in another language) for numerous other languages.\n","url":"https://huggingface.co/datasets/aloobun/indic-parallel-sentences-talks","creator_name":"aloobun","creator_url":"https://huggingface.co/aloobun","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Kannada"],"keywords_longer_than_N":true},
	{"name":"CulturaX-Kn","keyword":"kannada","description":"This is a filtered version of the CulturaX dataset only containing samples of Kannada language.\nThe dataset contains total of 1352142 samples.\n\n\t\n\t\t\n\t\tDataset Structure:\n\t\n\n{\n    \"text\": ...,\n    \"timestamp\": ...,\n    \"url\": ...,\n    \"source\": \"mc4\" | \"OSCAR-xxxx\",\n}\n\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'text': \"‡≤≠‡≤ü‡≥ç‡≤ï‡≤≥ : ‡≤§‡≤Ç‡≤¶‡≥Ü ‡≤§‡≤æ‡≤Ø‡≤ø ‡≤∏‡≥ç‡≤Æ‡≤∞‡≤£‡≤æ‡≤∞‡≥ç‡≤• ; ‡≤â‡≤ö‡≤ø‡≤§ ‡≤®‡≥ã‡≤ü‡≥ç ‡≤¨‡≥Å‡≤ï‡≥ç ‡≤µ‡≤ø‡≤§‡≤∞‡≤£‡≥Ü | Vartha Bharati- ‡≤µ‡≤æ‡≤∞‡≥ç‡≤§‡≤æ ‡≤≠‡≤æ‡≤∞‡≤§‡≤ø\\n‡≤Æ‡≥Å‡≤¶‡≤∞‡≤Ç‡≤ó‡≤°‡≤ø ‡≤¨‡≤ø‡≤ú‡≥Ü‡≤™‡≤ø ‡≤ó‡≥ç‡≤∞‡≤æ‡≤™‡≤Ç ‡≤∏‡≤¶‡≤∏‡≥ç‡≤Ø‡≤∞ ‡≤µ‡≤ø‡≤∞‡≥Å‡≤¶‡≥ç‡≤ß ‡≤™‡≥ç‡≤∞‡≤§‡≤ø‡≤≠‡≤ü‡≤®‡≥Ü\\n‡≤π‡≥ã‡≤Æ‡≥ç ‡≤ï‡≥ç‡≤µ‡≤æ‡≤∞‡≤Ç‡≤ü‡≥à‡≤®‡≥ç ‡≤®‡≤ø‡≤Ø‡≤Æ ‡≤â‡≤≤‡≥ç‡≤≤‡≤Ç‡≤ò‡≤®‡≥Ü: ‡≤™‡≥ç‡≤∞‡≤ï‡≤∞‡≤£ ‡≤¶‡≤æ‡≤ñ‡≤≤‡≥Å\\n‡≤≠‡≤ü‡≥ç‡≤ï‡≤≥ : ‡≤§‡≤Ç‡≤¶‡≥Ü ‡≤§‡≤æ‡≤Ø‡≤ø‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Indic-LLM-Labs/CulturaX-Kn.","url":"https://huggingface.co/datasets/Indic-LLM-Labs/CulturaX-Kn","creator_name":"Indic-LLM-Labs","creator_url":"https://huggingface.co/Indic-LLM-Labs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Kannada","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"IndicQuest","keyword":"kannada","description":"\n\t\n\t\t\n\t\tL3Cube-IndicQuest: A Benchmark Question Answering Dataset for Evaluating Knowledge of LLMs in Indic Context (LLM Factual Accuracy Benchmark)\n\t\n\nL3Cube-IndicQuest is a dataset comprising 4,000 question-answer pairs across 20 languages, including English, Assamese, Bengali, Dogri, Gujarati, Hindi, Kannada, Konkani, Maithili, Malayalam, Marathi, Meitei (Manipuri), Nepali, Odia, Punjabi, Sanskrit, Sindhi, Tamil, Telugu, and Urdu. This dataset is designed to assess the knowledge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/l3cube-pune/IndicQuest.","url":"https://huggingface.co/datasets/l3cube-pune/IndicQuest","creator_name":"L3Cube Labs","creator_url":"https://huggingface.co/l3cube-pune","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Assamese","Bengali","Gujarati"],"keywords_longer_than_N":true},
	{"name":"CulturaX-Kn","keyword":"kannada","description":"This is a filtered version of the CulturaX dataset only containing samples of Kannada language.\nThe dataset contains total of 1352142 samples.\n\n\t\n\t\t\n\t\tDataset Structure:\n\t\n\n{\n    \"text\": ...,\n    \"timestamp\": ...,\n    \"url\": ...,\n    \"source\": \"mc4\" | \"OSCAR-xxxx\",\n}\n\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'text': \"‡≤≠‡≤ü‡≥ç‡≤ï‡≤≥ : ‡≤§‡≤Ç‡≤¶‡≥Ü ‡≤§‡≤æ‡≤Ø‡≤ø ‡≤∏‡≥ç‡≤Æ‡≤∞‡≤£‡≤æ‡≤∞‡≥ç‡≤• ; ‡≤â‡≤ö‡≤ø‡≤§ ‡≤®‡≥ã‡≤ü‡≥ç ‡≤¨‡≥Å‡≤ï‡≥ç ‡≤µ‡≤ø‡≤§‡≤∞‡≤£‡≥Ü | Vartha Bharati- ‡≤µ‡≤æ‡≤∞‡≥ç‡≤§‡≤æ ‡≤≠‡≤æ‡≤∞‡≤§‡≤ø\\n‡≤Æ‡≥Å‡≤¶‡≤∞‡≤Ç‡≤ó‡≤°‡≤ø ‡≤¨‡≤ø‡≤ú‡≥Ü‡≤™‡≤ø ‡≤ó‡≥ç‡≤∞‡≤æ‡≤™‡≤Ç ‡≤∏‡≤¶‡≤∏‡≥ç‡≤Ø‡≤∞ ‡≤µ‡≤ø‡≤∞‡≥Å‡≤¶‡≥ç‡≤ß ‡≤™‡≥ç‡≤∞‡≤§‡≤ø‡≤≠‡≤ü‡≤®‡≥Ü\\n‡≤π‡≥ã‡≤Æ‡≥ç ‡≤ï‡≥ç‡≤µ‡≤æ‡≤∞‡≤Ç‡≤ü‡≥à‡≤®‡≥ç ‡≤®‡≤ø‡≤Ø‡≤Æ ‡≤â‡≤≤‡≥ç‡≤≤‡≤Ç‡≤ò‡≤®‡≥Ü: ‡≤™‡≥ç‡≤∞‡≤ï‡≤∞‡≤£ ‡≤¶‡≤æ‡≤ñ‡≤≤‡≥Å\\n‡≤≠‡≤ü‡≥ç‡≤ï‡≤≥ : ‡≤§‡≤Ç‡≤¶‡≥Ü ‡≤§‡≤æ‡≤Ø‡≤ø‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kannada-LLM-Labs/CulturaX-Kn.","url":"https://huggingface.co/datasets/Kannada-LLM-Labs/CulturaX-Kn","creator_name":"Kannada LLM Labs","creator_url":"https://huggingface.co/Kannada-LLM-Labs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Kannada","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"IN22GenBitextMining","keyword":"kannada","description":"\n  IN22GenBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Gen is a n-way parallel general-purpose multi-domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Legal, Government, News, Religious, Non-fiction, Written\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Gen\n\n\n\t\n\nSource datasets:\n\nmteb/IN22-Gen\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22GenBitextMining.","url":"https://huggingface.co/datasets/mteb/IN22GenBitextMining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-annotated","multilingual","mteb/IN22-Gen","Assamese"],"keywords_longer_than_N":true},
	{"name":"reranking-datasets-light","keyword":"kannada","description":"\n\t\n\t\t\n\t\tüî• Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation üî•\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\n\t\n\n\n    \n    \n    \n    \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n    \n\n\n\nA curated collection of ready-to-use datasets for retrieval and reranking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light.","url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Arabic","German","French"],"keywords_longer_than_N":true},
	{"name":"koel-benchmark","keyword":"kannada","description":"\n\t\n\t\t\n\t\tKoel Benchmark Suite\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Koel Benchmark Suite is a comprehensive set of evaluation datasets designed to rigorously test the real-world performance of Text-to-Speech (TTS) models for major Indian languages. The suite focuses on challenges unique to the Indian context, such as code-switching, domain-specific terminology, proper nouns, and complex numeric formats.\nThis dataset was created to help developers and researchers build more natural, accurate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NisargBhavsar25/koel-benchmark.","url":"https://huggingface.co/datasets/NisargBhavsar25/koel-benchmark","creator_name":"Nisarg Bhavsar","creator_url":"https://huggingface.co/NisargBhavsar25","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Hindi","Tamil","Telugu","Kannada"],"keywords_longer_than_N":true},
	{"name":"PMIndiaSum","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for \"PMIndiaSum\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nPMIndiaSum is a new multilingual and massively parallel headline summarization corpus focused on languages in India. Our corpus covers four language families, 14 languages, and the largest to date, 196 language pairs. It provides a testing ground for all cross-lingual pairs.\n\n\t\n\t\t\n\t\tSupported tasks\n\t\n\nMonolingual, multilingual and cross-lingual summarization for languages in India.\n\n\t\n\t\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PMIndiaData/PMIndiaSum.","url":"https://huggingface.co/datasets/PMIndiaData/PMIndiaSum","creator_name":"PMIndiaData","creator_url":"https://huggingface.co/PMIndiaData","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Assamese","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"offenseval_dravidian","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for Offenseval Dravidian\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOffensive language identification is classification task in natural language processing (NLP) where the aim is to moderate and minimise offensive content in social media. It has been an active area of research in both academia and industry for the past two decades. There is an increasing demand for offensive language identification on social media texts which are largely code-mixed. Code-mixing is a prevalent‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/offenseval_dravidian.","url":"https://huggingface.co/datasets/community-datasets/offenseval_dravidian","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-generated","crowdsourced","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"xtreme_s","keyword":"kannada","description":"XTREME-S covers four task families: speech recognition, classification, speech-to-text translation and retrieval. Covering 102\nlanguages from 10+ language families, 3 different domains and 4\ntask families, XTREME-S aims to simplify multilingual speech\nrepresentation evaluation, as well as catalyze research in ‚Äúuniversal‚Äù speech representation learning.","url":"https://huggingface.co/datasets/google/xtreme_s","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"kannada","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof Wr√≥bel","creator_url":"https://huggingface.co/djstrong","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"kannada","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"kannada","description":"Attribution: Wikipedia.org\n","url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"kannada_asr_corpus","keyword":"kannada","description":"The corpus contains roughly 360 hours of audio and transcripts in Kannada language. The transcripts have beed de-duplicated using exact match deduplication.","url":"https://huggingface.co/datasets/parambharat/kannada_asr_corpus","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|openslr"],"keywords_longer_than_N":true},
	{"name":"mc4-sampling","keyword":"kannada","description":"A sampling-enabled version of mC4, the colossal, cleaned version of Common Crawl's web crawl corpus.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is a version of the processed version of Google's mC4 dataset by AllenAI, in which sampling methods are implemented to perform on the fly.","url":"https://huggingface.co/datasets/bertin-project/mc4-sampling","creator_name":"BERTIN Project","creator_url":"https://huggingface.co/bertin-project","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"IE_SemParse","keyword":"kannada","description":"    IE-SemParse is an Inter-bilingual Seq2seq Semantic parsing dataset for 11 distinct Indian languages","url":"https://huggingface.co/datasets/Divyanshu/IE_SemParse","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["parsing","machine-generated","machine-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"kannada","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arb√´resh√´ Albanian"],"keywords_longer_than_N":true},
	{"name":"xP3all","keyword":"kannada","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"SqCLIRIL","keyword":"kannada","description":"\n\t\n\t\t\n\t\tüó£Ô∏è SqCLIRIL: Spoken Query Benchmark for Cross-Lingual IR in Indian Languages\n\t\n\nSqCLIRIL is a Spoken Query Benchmark designed to evaluate cross-lingual information retrieval (CLIR) systems using both spoken and text queries.It covers five Indian languages ‚Äî Hindi, Gujarati, Bengali, Kannada, and English ‚Äî with diverse speech samples from male and female speakers to capture natural variability in pronunciation and acoustic conditions.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìò Dataset Summary\n\t\n\n\n\t\n\t\t\nFeature‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/irlab-daiict/SqCLIRIL.","url":"https://huggingface.co/datasets/irlab-daiict/SqCLIRIL","creator_name":"IRLAB","creator_url":"https://huggingface.co/irlab-daiict","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-retrieval","Hindi","Gujarati","Bengali"],"keywords_longer_than_N":true},
	{"name":"dhpileIN","keyword":"kannada","description":"@misc{aralikatte2023varta,\n      title={V\\=arta: A Large-Scale Headline-Generation Dataset for Indic Languages}, \n      author={Rahul Aralikatte and Ziling Cheng and Sumanth Doddapaneni and Jackie Chi Kit Cheung},\n      year={2023},\n      eprint={2305.05858},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n","url":"https://huggingface.co/datasets/aloobun/dhpileIN","creator_name":"aloobun","creator_url":"https://huggingface.co/aloobun","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Bengali","Gujarati","Hindi","Kannada","Tamil"],"keywords_longer_than_N":true},
	{"name":"Indic-Rag-Suite","keyword":"kannada","description":"\n\t\n\t\t\n\t\tüåè Multilingual Indic RAG Suite\n\t\n\nA comprehensive multilingual question-answering dataset covering 18 Indian languages with 21,439,886 total samples, designed for RAG (Retrieval-Augmented Generation) applications and multilingual NLP research.\n\n\t\n\t\t\n\t\tüöÄ Quick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load specific language (recommended)\ndataset = load_dataset(\"ai4bharat/Indic-Rag-Suite\", \"as\")\ntrain_data = dataset['train']\n\nprint(f\"Loaded {len(train_data)} samples\")\n\n# Access‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Indic-Rag-Suite.","url":"https://huggingface.co/datasets/ai4bharat/Indic-Rag-Suite","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","multilingual","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"Fleurs-Kn","keyword":"kannada","description":"This is a filtered version of the Fleurs dataset only containing samples of Kannada language.\nThe dataset contains total of 2283 training, 368 validation and 838 test samples.\n\n\t\n\t\t\n\t\tData Sample:\n\t\n\n{'id': 1053,\n 'num_samples': 226560,\n 'path': '/home/ravi.naik/.cache/huggingface/datasets/downloads/extracted/e7c8b501d4e6892673b6dc291d42de48e7987b0d2aa6471066a671f686224ed1/10000267636955490843.wav',\n 'audio': {'path': 'train/10000267636955490843.wav',\n  'array': array([ 0.        ,  0.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kannada-LLM-Labs/Fleurs-Kn.","url":"https://huggingface.co/datasets/Kannada-LLM-Labs/Fleurs-Kn","creator_name":"Kannada LLM Labs","creator_url":"https://huggingface.co/Kannada-LLM-Labs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mmlu-indic","keyword":"kannada","description":"\n\t\n\t\t\n\t\tIndic MMLU Dataset\n\t\n\nA multilingual version of the Massive Multitask Language Understanding (MMLU) benchmark, translated from English into 10 Indian languages.\nThis version contains the translations of the development and test sets only. \n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\nThe dataset includes translations in the following languages:\n\nBengali (bn)\nGujarati (gu)\nHindi (hi)\nKannada (kn)\nMarathi (mr)\nMalayalam (ml)\nOriya (or)\nPunjabi (pa)\nTamil (ta)\nTelugu (te)\n\n\n\t\n\t\t\n\t\tTask Format\n\t\n\nEach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sarvamai/mmlu-indic.","url":"https://huggingface.co/datasets/sarvamai/mmlu-indic","creator_name":"Sarvam AI","creator_url":"https://huggingface.co/sarvamai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Bengali","English","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"IN22-Gen","keyword":"kannada","description":"\n  IN22GenBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Gen is a n-way parallel general-purpose multi-domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Legal, Government, News, Religious, Non-fiction, Written\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Gen\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Gen.","url":"https://huggingface.co/datasets/mteb/IN22-Gen","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"kannada","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"IndicXnliPairClassification","keyword":"kannada","description":"\n  IndicXnliPairClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nINDICXNLI is similar to existing XNLI dataset in shape/form, but\n        focusses on Indic language family.\n        The train (392,702), validation (2,490), and evaluation sets (5,010) of English\n        XNLI were translated from English into each of the eleven Indic languages. IndicTrans\n        is a large Transformer-based sequence to sequence model. It is trained on Samanantar\n        dataset (Ramesh et‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicXnliPairClassification.","url":"https://huggingface.co/datasets/mteb/IndicXnliPairClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","derived","translated","Divyanshu/indicxnli"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Kannada"],"keywords_longer_than_N":true},
	{"name":"fineweb-2","keyword":"kannada","description":"\n\t\n\t\t\n\t\tü•Ç FineWeb2\n\t\n\n\n    \n\n\n\nA sparkling update with 1000s of languages\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis is the second iteration of the popular üç∑ FineWeb dataset, bringing high quality pretraining data to over 1000 üó£Ô∏è languages.\nThe ü•Ç FineWeb2 dataset is fully reproducible, available under the permissive ODC-By 1.0 license and extensively validated through hundreds of ablation experiments.\nIn particular, on the set of 9 diverse languages we used to guide our processing decisions, ü•Ç FineWeb2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/fineweb-2.","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb-2","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"wildchat-filtered","keyword":"kannada","description":"\n\t\n\t\t\n\t\tWildChat Filtered Dataset\n\t\n\nThis is a filtered version of the WildChat-4.8M dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3,199,860 conversations between human users and ChatGPT, filtered to keep only the essential conversation structure.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach conversation contains only:\n\nconversations: A list of message objects with:\nrole: Either \"user\" or \"assistant\"\ncontent: The text content of the message\n\n\n\nAll other metadata (timestamps, moderation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rayonlabs/wildchat-filtered.","url":"https://huggingface.co/datasets/rayonlabs/wildchat-filtered","creator_name":"Rayon Labs","creator_url":"https://huggingface.co/rayonlabs","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Kannada"],"keywords_longer_than_N":true},
	{"name":"tulu3-100samples","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nThis dataset contains 100 samples from the Tulu 3 SFT Mixture.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example in the dataset contains the standard instruction-tuning data points as follow:\n\nid (str): a unique identifier\nmessages (list): message format used for supervised fine-tuning (this contains user prompt and assistant responses)\nsource (str): the source dataset for the given sample\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under ODC-BY-1.0. It is intended for research and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anayak/tulu3-100samples.","url":"https://huggingface.co/datasets/anayak/tulu3-100samples","creator_name":"Akash Nayak","creator_url":"https://huggingface.co/anayak","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600","keyword":"kannada","description":"Dataset for sarvam's entity normalisation task. More detailed information can be found here, in the main model repo: Hugging Face\nDetailed Report (Writeup): Google Drive\nIt also has a gguf variant, with certain additional gguf based innstructions: Hugging Face\nModel inference script can be found here: Colab\nModel predictions can be found in this dataset and both the repo files. named as: \n\neval_data_001_predictions.csv and eval_data_001_predictions_excel.csv.\ntrain_data_001_predictions.csvand‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tasmay-Tib/sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600.","url":"https://huggingface.co/datasets/Tasmay-Tib/sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600","creator_name":"Tasmay Pankaj Tibrewal","creator_url":"https://huggingface.co/Tasmay-Tib","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Hindi","Tamil","Telugu","Marathi","Bengali"],"keywords_longer_than_N":true},
	{"name":"indic_sentiment_analyzer","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n\t\n\t\t\n\t\tMultilingual Sentiment Analysis Dataset for Indian Languages\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository contains a comprehensive sentiment analysis dataset covering 11 Indian languages and English. The dataset is designed to support sentiment analysis tasks across multiple domains and languages, making it valuable for developing multilingual sentiment analysis models and applications.\n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\n\nEnglish (en) - Original\nHindi (hi)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dhruv0808/indic_sentiment_analyzer.","url":"https://huggingface.co/datasets/dhruv0808/indic_sentiment_analyzer","creator_name":"Dhruv Bhatnagar","creator_url":"https://huggingface.co/dhruv0808","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Hindi","Telugu","Tamil","Kannada"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"kannada","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"wiki-kannada-1.0","keyword":"kannada","description":"metriccoders/wiki-kannada-1.0 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/metriccoders/wiki-kannada-1.0","creator_name":"Metric Coders","creator_url":"https://huggingface.co/metriccoders","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Kannada","apache-2.0","10K - 100K","text","Text"],"keywords_longer_than_N":true},
	{"name":"GlobalNLI","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for global_nli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal NLI is a new text-based benchmark based on the aggregation of existing NLI datasets that are publicly available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 59 languages available :\n{\n    'amh': 'Amharic',\n    'ara': 'Arabic',\n    'asm': 'Assamese',\n    'aym': 'Aymara',\n    'ben': 'Bengali',\n    'bul': 'Bulgarian',\n    'bzd': 'Bribri',\n    'cat': 'Catalan',\n    'cni': 'Ash√°ninka',\n    'deu': 'German',\n    'ell': 'Greek',\n    'eng':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/McGill-NLP/GlobalNLI.","url":"https://huggingface.co/datasets/McGill-NLP/GlobalNLI","creator_name":"McGill NLP Group","creator_url":"https://huggingface.co/McGill-NLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multilingual","XNLI, AfriXNLI, IndicXNLI, AmericasNLI [30], XNLI-ca, myXNLI, IndoNLI, JNLI , InferBR, sick_pl, JamPatoisNLI, KLUE, RoNLI.","Amharic"],"keywords_longer_than_N":true},
	{"name":"en_to_kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tTranslation Dataset - English to Kannada\n\t\n\nThis dataset provides translation pairs from English to Kannada across a wide variety of common conversational contexts.\nIt includes basic phrases and sentences covering a broad range of subjects, such as:\n\nBasic Greetings\nSmall Talk\nTravel and Directions\nWeather and Environment\nWork and Professional\nEducation and Learning\nHealth and Well-being\nTechnology and Internet\nShopping and Requests\nFamily and Relationships\nDining and Food\nPublic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pavan-naik/en_to_kn.","url":"https://huggingface.co/datasets/pavan-naik/en_to_kn","creator_name":"Pavan Naik","creator_url":"https://huggingface.co/pavan-naik","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Kannada","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"en_to_kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tTranslation Dataset - English to Kannada\n\t\n\nThis dataset provides translation pairs from English to Kannada across a wide variety of common conversational contexts.\nIt includes basic phrases and sentences covering a broad range of subjects, such as:\n\nBasic Greetings\nSmall Talk\nTravel and Directions\nWeather and Environment\nWork and Professional\nEducation and Learning\nHealth and Well-being\nTechnology and Internet\nShopping and Requests\nFamily and Relationships\nDining and Food\nPublic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pavan-naik/en_to_kn.","url":"https://huggingface.co/datasets/pavan-naik/en_to_kn","creator_name":"Pavan Naik","creator_url":"https://huggingface.co/pavan-naik","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Kannada","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"GlobalNLI","keyword":"kannada","description":"\n\t\n\t\t\n\t\tDataset Card for global_nli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal NLI is a new text-based benchmark based on the aggregation of existing NLI datasets that are publicly available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 59 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata = load_dataset('vivekvermaiit/globalnli', 'eng') \n# Please, specify the language code\n# A data point example is below:\n{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vivekvermaiit/GlobalNLI.","url":"https://huggingface.co/datasets/vivekvermaiit/GlobalNLI","creator_name":"Vivek Verma","creator_url":"https://huggingface.co/vivekvermaiit","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multilingual","XNLI, AfriXNLI, IndicXNLI, AmericasNLI [30], XNLI-ca, myXNLI, IndoNLI, JNLI , InferBR, sick_pl, JamPatoisNLI, KLUE, RoNLI.","Amharic"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Kannada"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Kannada"],"keywords_longer_than_N":true},
	{"name":"indic-align","keyword":"kannada","description":"\n\t\n\t\t\n\t\tIndicAlign\n\t\n\nA diverse collection of Instruction and Toxic alignment datasets for 14 Indic Languages. The collection comprises of:\n\nIndicAlign - Instruct\nIndic-ShareLlama\nDolly-T\nOpenAssistant-T\nWikiHow\nIndoWordNet\nAnudesh\nWiki-Conv\nWiki-Chat\n\n\nIndicAlign - Toxic\nHHRLHF-T\nToxic-Matrix\n\n\n\nWe use IndicTrans2 (Gala et al., 2023) for the translation of the datasets. \nWe recommend the readers to check out our paper on Arxiv for detailed information on the curation process of these‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/indic-align.","url":"https://huggingface.co/datasets/ai4bharat/indic-align","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Assamese","Bengali","Gujarati","English"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"kannada","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following boolean‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_kn","keyword":"kannada","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Kannada version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_kn.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Kannada"],"keywords_longer_than_N":true}
]
;
