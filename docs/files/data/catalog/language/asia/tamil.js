const data_for_language_asia_tamil = 
[
	{"name":"TinyDS-20k","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTinyDS\n\t\n\n\n\n\nAlpaca-style dataset with around 20k samples scraped from Qwen3-8B using SyntheticAlpaca. Q&A pairs can be in 32 different languages, these are listed in the metadata.Topics are all around STEM, programming, and literature.  \nMIT @ 2025 Hamzah Asadullah\n\n\n","url":"https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","text2text-generation","English"],"keywords_longer_than_N":true},
	{"name":"BB-Ultrachat-IndicLingual6-12k","keyword":"tamil","description":"\n\t\n\t\t\n\t\tBB-Ultrachat-IndicLingual6-12k\n\t\n\nThis dataset is created by bhaiyabot ai to enrich language model training data, especially in the context of Indic languages. code for creation is also open source at https://github.com/ro-hansolo/IndicTrans2HuggingFaceDatasets\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nBB-Ultrachat-IndicLingual6-12k is a curated dataset comprising 12,000 multi-turn conversations, which are a subset of the larger HuggingFaceH4/ultrachat_200k dataset. These conversations have been evenlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rohansolo/BB-Ultrachat-IndicLingual6-12k.","url":"https://huggingface.co/datasets/rohansolo/BB-Ultrachat-IndicLingual6-12k","creator_name":"Rohan","creator_url":"https://huggingface.co/rohansolo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Hindi","Malayalam","Tamil"],"keywords_longer_than_N":true},
	{"name":"tamil_data_puthumaippittan_short_stories_na","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil à®šà®¿à®±à¯à®•à®¤à¯ˆ Dataset by à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains Tamil à®šà®¿à®±à¯à®•à®¤à¯ˆ texts by à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯, processed for language model pretraining.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n185 text passages\nAuthor: à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯\nGenre: à®šà®¿à®±à¯à®•à®¤à¯ˆ\nTotal characters: 266401\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset is suitable for language model pretraining tasks.\nfrom datasets import load_dataset\n\ndataset = load_dataset('Naveen934/tamil_data_puthumaippittan_short_stories_na')\n\n","url":"https://huggingface.co/datasets/Naveen934/tamil_data_puthumaippittan_short_stories_na","creator_name":"J","creator_url":"https://huggingface.co/Naveen934","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","mit","ğŸ‡ºğŸ‡¸ Region: US","tamil"],"keywords_longer_than_N":true},
	{"name":"tamil_data_puthumaippittan_short_stories_na","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil à®šà®¿à®±à¯à®•à®¤à¯ˆ Dataset by à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains Tamil à®šà®¿à®±à¯à®•à®¤à¯ˆ texts by à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯, processed for language model pretraining.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n185 text passages\nAuthor: à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯\nGenre: à®šà®¿à®±à¯à®•à®¤à¯ˆ\nTotal characters: 266401\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset is suitable for language model pretraining tasks.\nfrom datasets import load_dataset\n\ndataset = load_dataset('Naveen934/tamil_data_puthumaippittan_short_stories_na')\n\n","url":"https://huggingface.co/datasets/Naveen934/tamil_data_puthumaippittan_short_stories_na","creator_name":"J","creator_url":"https://huggingface.co/Naveen934","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","mit","ğŸ‡ºğŸ‡¸ Region: US","tamil"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"tamil","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Quixi AI","creator_url":"https://huggingface.co/QuixiAI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"tamil","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"seamless-align","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\n\n\t\n\t\t\n\t\tHow to use the data\n\t\n\nThere are two ways to access the data:\n\nVia the Hugging Face Python datasets library\n\nScripts coming soonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align.","url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","audio-to-audio","Maltese","English","Welsh"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture","keyword":"tamil","description":"\n\n\n\t\n\t\t\n\t\tTulu 3 SFT Mixture\n\t\n\nNote that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe Tulu 3 SFT mixture was used to train the Tulu 3 series of models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre etâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tamil_data_sujatha_story","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil à®‰à®¯à®¿à®°à®¿à®©à¯ à®°à®•à®šà®¿à®¯à®®à¯ Dataset by à®šà¯à®œà®¾à®¤à®¾\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains Tamil à®‰à®¯à®¿à®°à®¿à®©à¯ à®°à®•à®šà®¿à®¯à®®à¯ texts by à®šà¯à®œà®¾à®¤à®¾, processed for language model pretraining.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n43 text passages\nAuthor: à®šà¯à®œà®¾à®¤à®¾\nGenre: à®‰à®¯à®¿à®°à®¿à®©à¯ à®°à®•à®šà®¿à®¯à®®à¯\nTotal characters: 109388\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset is suitable for language model pretraining tasks.\nfrom datasets import load_dataset\n\ndataset = load_dataset('Naveen934/tamil_data_sujatha_story')\n\n","url":"https://huggingface.co/datasets/Naveen934/tamil_data_sujatha_story","creator_name":"J","creator_url":"https://huggingface.co/Naveen934","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","mit","ğŸ‡ºğŸ‡¸ Region: US","tamil"],"keywords_longer_than_N":true},
	{"name":"tamil_data_sujatha_story","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil à®‰à®¯à®¿à®°à®¿à®©à¯ à®°à®•à®šà®¿à®¯à®®à¯ Dataset by à®šà¯à®œà®¾à®¤à®¾\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains Tamil à®‰à®¯à®¿à®°à®¿à®©à¯ à®°à®•à®šà®¿à®¯à®®à¯ texts by à®šà¯à®œà®¾à®¤à®¾, processed for language model pretraining.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n43 text passages\nAuthor: à®šà¯à®œà®¾à®¤à®¾\nGenre: à®‰à®¯à®¿à®°à®¿à®©à¯ à®°à®•à®šà®¿à®¯à®®à¯\nTotal characters: 109388\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset is suitable for language model pretraining tasks.\nfrom datasets import load_dataset\n\ndataset = load_dataset('Naveen934/tamil_data_sujatha_story')\n\n","url":"https://huggingface.co/datasets/Naveen934/tamil_data_sujatha_story","creator_name":"J","creator_url":"https://huggingface.co/Naveen934","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","mit","ğŸ‡ºğŸ‡¸ Region: US","tamil"],"keywords_longer_than_N":true},
	{"name":"xP3megds","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for xP3\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.\n\n\nCreation: The dataset can be recreated using instructions available here. We provide this version to save processing time and ease reproducibility.\nLanguages: 46 (Canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bigscience/xP3megds.","url":"https://huggingface.co/datasets/bigscience/xP3megds","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"tamil_stories","keyword":"tamil","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\ntamil_stories is an open source dataset of instruct-style records generated by scraping publicly available short stories on the following websites.\n\nSiruvarmalar\nTamilsurangam\n\nApart from scraping and automated cleaning, the data was also tagged manually by a group of volunteers. \nThis dataset created as part of Aya Open Science Initiative by Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/aitamilnadu/tamil_stories.","url":"https://huggingface.co/datasets/aitamilnadu/tamil_stories","creator_name":"AI Tamil Nadu","creator_url":"https://huggingface.co/aitamilnadu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","expert-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"naamapadam","keyword":"tamil","description":"\\","url":"https://huggingface.co/datasets/AnanthZeke/naamapadam","creator_name":"Ananth","creator_url":"https://huggingface.co/AnanthZeke","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","machine-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"CommonVoiceCorpusTamil15","keyword":"tamil","description":"yagnikposhiya/CommonVoiceCorpusTamil15 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/yagnikposhiya/CommonVoiceCorpusTamil15","creator_name":"Yagnik Poshiya","creator_url":"https://huggingface.co/yagnikposhiya","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Tamil","apache-2.0","Audio","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"c4","keyword":"tamil","description":"\n\t\n\t\t\n\t\tC4\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA colossal, cleaned version of Common Crawl's web crawl corpus. Based on Common Crawl dataset: \"https://commoncrawl.org\".\nThis is the processed version of Google's C4 dataset\nWe prepared five variants of the data: en, en.noclean, en.noblocklist, realnewslike, and multilingual (mC4).\nFor reference, these are the sizes of the variants:\n\nen: 305GB\nen.noclean: 2.3TB\nen.noblocklist: 380GB\nrealnewslike: 15GB\nmultilingual (mC4): 9.7TB (108 subsets, one perâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/c4.","url":"https://huggingface.co/datasets/allenai/c4","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"tamil_data___VaazhvaiNokki","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil à®µà®¾à®´à¯à®µà¯ˆ à®¨à¯‹à®•à¯à®•à®¿ Dataset by à®µà®¿à®œà®¯à®¾ à®²à®Ÿà¯à®šà¯à®®à®£à®©à¯\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains Tamil à®µà®¾à®´à¯à®µà¯ˆ à®¨à¯‹à®•à¯à®•à®¿ texts by à®µà®¿à®œà®¯à®¾ à®²à®Ÿà¯à®šà¯à®®à®£à®©à¯, processed for language model pretraining.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n41 text chunks\nAuthor: à®µà®¿à®œà®¯à®¾ à®²à®Ÿà¯à®šà¯à®®à®£à®©à¯\nGenre: à®µà®¾à®´à¯à®µà¯ˆ à®¨à¯‹à®•à¯à®•à®¿\nTotal chunks: 41\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"Naveen934/tamil_data___VaazhvaiNokki\")```\n\n","url":"https://huggingface.co/datasets/Naveen934/tamil_data___VaazhvaiNokki","creator_name":"J","creator_url":"https://huggingface.co/Naveen934","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"tamil_data___VaazhvaiNokki","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil à®µà®¾à®´à¯à®µà¯ˆ à®¨à¯‹à®•à¯à®•à®¿ Dataset by à®µà®¿à®œà®¯à®¾ à®²à®Ÿà¯à®šà¯à®®à®£à®©à¯\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains Tamil à®µà®¾à®´à¯à®µà¯ˆ à®¨à¯‹à®•à¯à®•à®¿ texts by à®µà®¿à®œà®¯à®¾ à®²à®Ÿà¯à®šà¯à®®à®£à®©à¯, processed for language model pretraining.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n41 text chunks\nAuthor: à®µà®¿à®œà®¯à®¾ à®²à®Ÿà¯à®šà¯à®®à®£à®©à¯\nGenre: à®µà®¾à®´à¯à®µà¯ˆ à®¨à¯‹à®•à¯à®•à®¿\nTotal chunks: 41\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"Naveen934/tamil_data___VaazhvaiNokki\")```\n\n","url":"https://huggingface.co/datasets/Naveen934/tamil_data___VaazhvaiNokki","creator_name":"J","creator_url":"https://huggingface.co/Naveen934","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"tamil_sentences_sample","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for \"tamil_combined_sentences\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/AnanthZeke/tamil_sentences_sample","creator_name":"Ananth","creator_url":"https://huggingface.co/AnanthZeke","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","zero-shot-classification","Tamil","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"tamil_sentences_sample","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for \"tamil_combined_sentences\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/AnanthZeke/tamil_sentences_sample","creator_name":"Ananth","creator_url":"https://huggingface.co/AnanthZeke","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","zero-shot-classification","Tamil","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"tamil","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","MetlatÃ³noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"naamapadam","keyword":"tamil","description":"\\","url":"https://huggingface.co/datasets/ai4bharat/naamapadam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","machine-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"CC-Cat","keyword":"tamil","description":"\n\t\n\t\t\n\t\tCC_Cat\n\t\n\n\nExtract from CC-WARC snapshots.\nMainly includes texts with 149 languages.\nPDF/IMAGE/AUDIO/VIDEO raw downloading link.\n\n\n\t\n\t\t\n\t\tNotice\n\t\n\n\nSince my computing resources are limited, this dataset will update by one-day of CC snapshots timestampts.\nAfter a snapshot is updated, the deduplicated version will be uploaded.\nIf you are interested in providing computing resources or have cooperation needs, please contact me.\n  carreyallthetime@gmail.com  \n      \n  \n\n","url":"https://huggingface.co/datasets/chengshidehaimianti/CC-Cat","creator_name":"zyq","creator_url":"https://huggingface.co/chengshidehaimianti","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","English","German","Russian"],"keywords_longer_than_N":true},
	{"name":"Tamil-Sinhala-short-sentence-similarity-deep-learning","keyword":"tamil","description":"This research focuses on finding the best possible deep learning-based techniques to measure the short sentence similarity for low-resourced languages, focusing on Tamil and Sinhala sort sentences by utilizing existing unsupervised techniques for English. Original repo available on https://github.com/nlpcuom/Tamil-Sinhala-short-sentence-similarity-deep-learning\nIf you use this dataset, cite Nilaxan, S., & Ranathunga, S. (2021, July). Monolingual sentence similarity measurement using siameseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Tamil-Sinhala-short-sentence-similarity-deep-learning.","url":"https://huggingface.co/datasets/NLPC-UOM/Tamil-Sinhala-short-sentence-similarity-deep-learning","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["Tamil","Sinhala","mit","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"tamil-open-instruct-v1","keyword":"tamil","description":"\n\t\n\t\t\n\t\tOpen Instruct V1 - A dataset for having LLMs follow instructions.\n\t\n\nOpen Instruct V1 is an amalgamation of different datasets which are cleaned and then collated into a singular format for training.\n","url":"https://huggingface.co/datasets/Hemanth-thunder/tamil-open-instruct-v1","creator_name":"Hemanth-thunder","creator_url":"https://huggingface.co/Hemanth-thunder","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","Tamil","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"tamil","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/fleurs.","url":"https://huggingface.co/datasets/google/fleurs","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"hope_edi","keyword":"tamil","description":"A Hope Speech dataset for Equality, Diversity and Inclusion (HopeEDI) containing user-generated comments from the social media platform YouTube with 28,451, 20,198 and 10,705 comments in English, Tamil and Malayalam, respectively, manually labelled as containing hope speech or not.","url":"https://huggingface.co/datasets/dravidianlangtech/hope_edi","creator_name":"dravidianlangtech","creator_url":"https://huggingface.co/dravidianlangtech","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","expert-generated","crowdsourced","monolingual","multilingual"],"keywords_longer_than_N":true},
	{"name":"pib","keyword":"tamil","description":"Sentence aligned parallel corpus between 11 Indian Languages, crawled and extracted from the press information bureau\nwebsite.","url":"https://huggingface.co/datasets/jerin/pib","creator_name":"Jerin Philip","creator_url":"https://huggingface.co/jerin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","text-generation","fill-mask","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"Thiruvalluvar_Thirukkural","keyword":"tamil","description":"bikram22pi7/Thiruvalluvar_Thirukkural dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/bikram22pi7/Thiruvalluvar_Thirukkural","creator_name":"Bikram Majhi","creator_url":"https://huggingface.co/bikram22pi7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","Tamil","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ml_spoken_words","keyword":"tamil","description":"Multilingual Spoken Words Corpus is a large and growing audio dataset of spoken\nwords in 50 languages collectively spoken by over 5 billion people, for academic\nresearch and commercial applications in keyword spotting and spoken term search,\nlicensed under CC-BY 4.0. The dataset contains more than 340,000 keywords,\ntotaling 23.4 million 1-second spoken examples (over 6,000 hours). The dataset\nhas many use cases, ranging from voice-enabled consumer devices to call center\nautomation. This dataset is generated by applying forced alignment on crowd-sourced sentence-level\naudio to produce per-word timing estimates for extraction.\nAll alignments are included in the dataset.","url":"https://huggingface.co/datasets/MLCommons/ml_spoken_words","creator_name":"MLCommons","creator_url":"https://huggingface.co/MLCommons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","machine-generated","other","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"lehengas-in-schools-question-bank","keyword":"tamil","description":"\n\t\n\t\t\n\t\tCultural Knowledge Question Bank\n\t\n\nThis dataset contains questions designed to evaluate cultural knowledge within the context of India.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is provided as a CSV file with the following fields:\n\n\t\n\t\t\nField\nDescription\n\n\n\t\t\nID\nUnique identifier\n\n\nDifficulty\nQuestion difficulty level (e.g., Easy, Medium, Hard)\n\n\nQuestion\nQuestion text\n\n\nAnswer\nCorrect answer text\n\n\nType\nQuestion type (e.g., MCQ, One-word, etc.)\n\n\nLanguage\nLanguage of the questionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kirtibg/lehengas-in-schools-question-bank.","url":"https://huggingface.co/datasets/Kirtibg/lehengas-in-schools-question-bank","creator_name":"Kirti Bhagat","creator_url":"https://huggingface.co/Kirtibg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Tamil","Oriya","Telugu"],"keywords_longer_than_N":true},
	{"name":"tam-data","keyword":"tamil","description":"aishu15/tam-data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/aishu15/tam-data","creator_name":"Aishwarya lakshmi P S","creator_url":"https://huggingface.co/aishu15","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Tamil","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent","keyword":"tamil","description":"\n  MassiveIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveIntentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_intent.","url":"https://huggingface.co/datasets/mteb/amazon_massive_intent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"tn-heritage-sites-dataset","keyword":"tamil","description":"\n\t\n\t\t\n\t\tâš ï¸ Disclaimer\n\t\n\nThis dataset is actively under development and not yet fully complete. While your support (22+ downloads and counting ğŸ™Œ) motivates continuous improvements, current versions may contain:  \n\nIncomplete regional coverage  \nPotential biases or noise  \nEvolving schema/format\n\nUse with caution for production systems. Contributions, feedback, or reports about gaps are highly appreciated!  \nğŸ“§ Contact: BoobalamuruganğŸ”„ Always check for updates - New versions will be releasedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Boobalamurugan/tn-heritage-sites-dataset.","url":"https://huggingface.co/datasets/Boobalamurugan/tn-heritage-sites-dataset","creator_name":"Boobalamurugan S","creator_url":"https://huggingface.co/Boobalamurugan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Tamil","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"finepdfs","keyword":"tamil","description":"\n\nLiberating 3T of the finest tokens from PDFs\n\n\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nAs we run out of web pages to process, the natural question has always been: what to do next? Only a few knew about a data source that everyone avoided for ages, due to its incredible extraction cost and complexity: PDFs.\nğŸ“„ FinePDFs is exactly that. It is the largest publicly available corpus sourced exclusively from PDFs, containing about 3 trillion tokens across 475 million documents in 1733 languages.\nCompared to HTMLâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/finepdfs.","url":"https://huggingface.co/datasets/HuggingFaceFW/finepdfs","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"Tamil-Proverbs","keyword":"tamil","description":"Selvakumarduraipandian/Tamil-Proverbs dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Selvakumarduraipandian/Tamil-Proverbs","creator_name":"Selvakumar Duraipandian","creator_url":"https://huggingface.co/Selvakumarduraipandian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Tamil","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Tamil-Proverbs","keyword":"tamil","description":"Selvakumarduraipandian/Tamil-Proverbs dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Selvakumarduraipandian/Tamil-Proverbs","creator_name":"Selvakumar Duraipandian","creator_url":"https://huggingface.co/Selvakumarduraipandian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Tamil","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Roleplay-Tamil","keyword":"tamil","description":"\n\t\n\t\t\n\t\tRolePlay-Tamil\n\t\n\nRoleplay-Tamil Dataset is a dataset for roleplaying in the Tamil language for the Large Language Model.\nThe base dataset is the GPTeacher role play dataset by teknium 1, which can be found under this link, released under MIT License. The dataset is then translated into respective languages. The translation process is powered by Google Translate, using cloud translation API. \nFor more information and other language datasets for roleplay, see this github repo.\nForâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Tamil.","url":"https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Tamil","creator_name":"Min Si Thu","creator_url":"https://huggingface.co/jojo-ai-mst","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Pathinen_keezhkanakku-Thirikadugam","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸŒ¿ à®¤à®¿à®°à®¿à®•à®Ÿà®¿à®•à¯ˆ (Thirukadigai) Dataset\n\t\n\nà®¤à®¿à®°à®¿à®•à®Ÿà®¿à®•à¯ˆ (Thirukadigai) is one of the Pathinen Keezhkanakku (Eighteen Minor Works) texts in post-Sangam Tamil literature.It was composed by à®¨à®²à¯à®²à®¾à®¤à®©à®¾à®°à¯ (Nalladhanar).  \nThe title Thirukadigai literally means â€œThe Sacred Mixture of Threeâ€ â€” just as the medicinal preparation à®¤à®¿à®°à®¿à®•à®Ÿà¯à®•à®®à¯ (Dry Ginger, Pepper, and Long Pepper) preserves physical health, the verses of this text present triple sets of virtues that preserve moral and spiritual health.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/Pathinen_keezhkanakku-Thirikadugam.","url":"https://huggingface.co/datasets/TamilThagaval/Pathinen_keezhkanakku-Thirikadugam","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Tamil","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs ğŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"tamil_corpus_2.3m","keyword":"tamil","description":"muthuramkumar/tamil_corpus_2.3m dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/muthuramkumar/tamil_corpus_2.3m","creator_name":"muthuramkumar","creator_url":"https://huggingface.co/muthuramkumar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Tamil","mit","1M - 10M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"tamil","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"IndicSentiment","keyword":"tamil","description":"\n  IndicSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA new, multilingual, and n-way parallel dataset for sentiment analysis in 13 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReferencehttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicSentimentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicSentiment.","url":"https://huggingface.co/datasets/mteb/IndicSentiment","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"IndicReviewsClusteringP2P","keyword":"tamil","description":"\n  IndicReviewsClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of reviews from IndicSentiment dataset. Clustering of 14 sets on the generic categories label.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReference\nhttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicReviewsClusteringP2P\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicReviewsClusteringP2P.","url":"https://huggingface.co/datasets/mteb/IndicReviewsClusteringP2P","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"vox-communis-parallel-g2p","keyword":"tamil","description":"\n\t\n\t\t\n\t\tVoxCommunis Parallel G2P dataset\n\t\n\nThis dataset was derived from the VoxCommunis Corpus to provide pairs of utterances along with their\ncorresponding phonemes, side by side, as to ease the training of grapheme-to-phoneme (G2P) models.\nThe original VoxCommunis Corpus features force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus.\nThe lexicons were developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p.","url":"https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p","creator_name":"FlÃ¡vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"tamil","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"RSL_Maran","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ae5115242430e13/RSL_Maran.","url":"https://huggingface.co/datasets/ae5115242430e13/RSL_Maran","creator_name":"R.s.L Maran","creator_url":"https://huggingface.co/ae5115242430e13","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","table-question-answering","question-answering","text-classification","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"bhasha-wiki-indic","keyword":"tamil","description":"\n\t\n\t\t\n\t\tBhasha Wiki Indic\n\t\n\n\nThis dataset has Wikipedia articles pertaining to Indian context.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThe dataset is built from Wikipedia articles taken from wikimedia/wikipedia. \nWe filtered, cleaned and translated English articles related to India and Indian context out of entire dataset.\nEach example has contents of a full cleaned wikipedia article and it's translations in 6 Indian languages.\n\nCurated by: Soket AI Labs\nLanguage(s) (NLP):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/soketlabs/bhasha-wiki-indic.","url":"https://huggingface.co/datasets/soketlabs/bhasha-wiki-indic","creator_name":"Soket Labs","creator_url":"https://huggingface.co/soketlabs","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","Bengali"],"keywords_longer_than_N":true},
	{"name":"Tamil-wikipedia-articles-on-computing","keyword":"tamil","description":"README for Tamil Computing Dataset\nThis is a dataset of synthetically generated Tamil articles from Wikipedia (188.9MB), focused on the computing domain, derived by translating English articles using Googleâ€™s Cloud Translation API (scraped from Wikipedia). This dataset is ideal for fine-tuning pre-trained language models, enriching their Tamil linguistic understanding, and domain-specific knowledge on Computing, especially when working on Tamil NLP applications or researching low-resourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/techkid673/Tamil-wikipedia-articles-on-computing.","url":"https://huggingface.co/datasets/techkid673/Tamil-wikipedia-articles-on-computing","creator_name":"Sri Ranganathan Palaniappan","creator_url":"https://huggingface.co/techkid673","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Tamil","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Pathinenkeezhkanakku-Naaladiyar","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸª· à®¨à®¾à®²à®Ÿà®¿à®¯à®¾à®°à¯ (Naaladiyar) Dataset\n\t\n\nà®¨à®¾à®²à®Ÿà®¿à®¯à®¾à®°à¯ (Naaladiyar) is one of the Pathinen Keezhkanakku (Eighteen Minor Works) in Sangam Literature, composed during the post-Sangam period (circa 100â€“500 CE).\nIt contains 400 venpa poems, each consisting of four lines (à®¨à®¾à®²à®Ÿà®¿ = four lines), emphasizing:\nImpermanence of life and wealth\nRighteous living and virtue (à®…à®±à®®à¯)\nDetachment and renunciation (à®¤à¯à®±à®µà®±à®®à¯)\nPhilosophical reflections on human existence\nThe poems are known for their brevity, depthâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/Pathinenkeezhkanakku-Naaladiyar.","url":"https://huggingface.co/datasets/TamilThagaval/Pathinenkeezhkanakku-Naaladiyar","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","token-classification","translation","Tamil","mit"],"keywords_longer_than_N":true},
	{"name":"Pathirruppattu","keyword":"tamil","description":"\n\t\n\t\t\n\t\tPathirruppattu (à®ªà®¤à®¿à®±à¯à®±à¯à®ªà¯à®ªà®¤à¯à®¤à¯) Dataset\n\t\n\n\n\t\n\t\t\n\t\tğŸ“ Dataset Description\n\t\n\nPathirruppattu (The Ten Idylls) is one of the classical Sangam anthologies (Ettuthokai) in Tamil literature, consisting of 10 books, each praising heroic kings, valor, wealth, and virtues. Each poem combines vivid imagery, structured meters, and poetic devices.\nThis dataset provides a structured digital version of Pathirruppattu, including:\nPoem titles\nPoetic section/category (à®¤à¯à®±à¯ˆ)\nPoetic style (à®µà®£à¯à®£à®®à¯)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/Pathirruppattu.","url":"https://huggingface.co/datasets/TamilThagaval/Pathirruppattu","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","Tamil","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"IndicLangClassification","keyword":"tamil","description":"\n  IndicLangClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Non-fiction, Written\nReference\nhttps://arxiv.org/abs/2305.15814\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"IndicLangClassification\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicLangClassification.","url":"https://huggingface.co/datasets/mteb/IndicLangClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-annotated","monolingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"dhanishtha-2.0-superthinker","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸ“¦ Dhanishtha-2.0-SUPERTHINKER-MLX\n\t\n\n A distilled corpus of 11.7K high-quality samples showcasing multi-phase reasoning and structured emotional cognition. Sourced directly from the internal training data of Dhanishtha-2.0 â€” the worldâ€™s first Large Language Model (LLM) to implement Intermediate Thinking, featuring multiple <think> and <ser> blocks per response\n\n\t\n\t\t\n\t\n\t\n\t\tExample with MLX-LM-LoRA:\n\t\n\nmlx_lm_lora.train \\\n--modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker.","url":"https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"Pathupattu-Pattinapalai","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸŒŠ à®ªà®Ÿà¯à®Ÿà®¿à®©à®ªà¯à®ªà®¾à®²à¯ˆ (PattinappÄlai) Dataset\n\t\n\nà®ªà®Ÿà¯à®Ÿà®¿à®©à®ªà¯à®ªà®¾à®²à¯ˆ (PattinappÄlai) is one of the Pathupattu (à®ªà®¤à¯à®¤à¯à®ªà¯à®ªà®¾à®Ÿà¯à®Ÿà¯ / Ten Idylls) in Sangam Literature, the ancient Tamil corpus.\nIt is a long poem of 301 lines, traditionally attributed to poet Uruttirankannanar (à®‰à®°à¯à®¤à¯à®¤à®¿à®°à®™à¯à®•à®£à¯à®£à®©à®¾à®°à¯).\nThe poem provides vivid descriptions of KÄvÄ“ripattinam (Puhar) â€“ the bustling Chola capital, the glory of the Kaveri River, the prosperity of its people, and the grandeur of their king.\nThis dataset offers aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/Pathupattu-Pattinapalai.","url":"https://huggingface.co/datasets/TamilThagaval/Pathupattu-Pattinapalai","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","Tamil","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"IN22ConvBitextMining","keyword":"tamil","description":"\n  IN22ConvBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Conv is a n-way parallel conversation domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nSocial, Spoken, Fiction, Spoken\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Conv\n\n\n\t\n\nSource datasets:\n\nmteb/IN22-Conv\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22ConvBitextMining.","url":"https://huggingface.co/datasets/mteb/IN22ConvBitextMining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-annotated","multilingual","mteb/IN22-Conv","Assamese"],"keywords_longer_than_N":true},
	{"name":"tamil-news-headlines","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset contains Tamil News Headlines which is used for training the tamil tokenizers. In this dataset, the data points contains different categories of tamil news headlines text.\n","url":"https://huggingface.co/datasets/viswadarshan06/tamil-news-headlines","creator_name":"Viswadarshan R R","creator_url":"https://huggingface.co/viswadarshan06","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Tamil","mit","10K - 100K","text","Text"],"keywords_longer_than_N":true},
	{"name":"phonetic-piper-recording-studio-prompts","keyword":"tamil","description":"\n\t\n\t\t\n\t\tPhonetic Piper Studio Recordings Prompts\n\t\n\nThis dataset is a processed version of an utterance dataset made available for various languages as prompts for the Piper recording studio. Along with the original prompts, we include:\n\ncolumns ipa_espeak and ipa_epitran containing phonemized versions of the original sentences according to espeak-ng and Epitran phonemizers, respectively\ncolumns lang, espeak_lang_code, epitran_lang_code containing the language codes as reported by piperâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts.","url":"https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts","creator_name":"FlÃ¡vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"tamil","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"whisper-eval-rare-languages-csv","keyword":"tamil","description":"\n\t\n\t\t\n\t\tWhisper 3 Large Evaluation on Mozilla Common Voice 17 Rare Languages (Enhanced Metrics)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis enhanced dataset contains comprehensive evaluation results of OpenAI's Whisper 3 Large model on rare languages from Mozilla Common Voice 17, with extensive additional metrics for thorough ASR evaluation.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\nEnhanced Error Metrics:\n\nWER (Word Error Rate): Standard word-level error measurement\nCER (Character Error Rate): Character-level errorâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/norbertm/whisper-eval-rare-languages-csv.","url":"https://huggingface.co/datasets/norbertm/whisper-eval-rare-languages-csv","creator_name":"Norbert M","creator_url":"https://huggingface.co/norbertm","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","multilingual","Assamese","Breton","Welsh"],"keywords_longer_than_N":true},
	{"name":"Paripadal","keyword":"tamil","description":"\n\t\n\t\t\n\t\tà®ªà®°à®¿à®ªà®¾à®Ÿà®²à¯ (ParipÄdal)\n\t\n\n\n\t\n\t\t\n\t\tğŸ“ Dataset Description\n\t\n\nà®ªà®°à®¿à®ªà®¾à®Ÿà®²à¯ (ParipÄdal) is one of the eight classical anthologies (Ettuthokai) in Sangam Literature, containing 22 poems. These poems are unique as they were set to music and celebrate deities like Vishnu, Murugan, and the river Kaveri, along with themes of nature, devotion, and love.\nThis dataset provides a structured digital format of ParipÄdal, including:\nPoem Title\nSection Headings\nOriginal Tamil Poem Text (organized byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/Paripadal.","url":"https://huggingface.co/datasets/TamilThagaval/Paripadal","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","Tamil","mit"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"tamil","description":"\n\t\n\t\t\n\t\tWMT24++\n\t\n\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\nthe publication\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\nIf you are interested in the images of the source URLs for each document, please see here.\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach language pair is stored in its own jsonl file.\nEach row isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"wmt-da-human-evaluation-long-context","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLong-context / document-level dataset for Quality Estimation of Machine Translation.\nIt is an augmented variant of the sentence-level WMT DA Human Evaluation dataset.\nIn addition to individual sentences, it contains augmentations of 2, 4, 8, 16, and 32 sentences, among each language pair lp and domain.\nThe raw column represents a weighted average of scores of augmented sentences using character lengths of src and mt as weights.\nThe code used to apply the augmentationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context.","url":"https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Estonian"],"keywords_longer_than_N":true},
	{"name":"x-fact","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for \"x-fact\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while the languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact.","url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","Bengali","Spanish","Persian"],"keywords_longer_than_N":true},
	{"name":"Aathichoodi","keyword":"tamil","description":"\n\t\n\t\t\n\t\tà®†à®¤à¯à®¤à®¿à®šà¯‚à®Ÿà®¿ Dataset\n\t\n\nğŸ“– About the Dataset\nThis dataset is a structured collection of Aathichoodi, a classical Tamil literary work written by Avvaiyar, along with its meanings and explanations. \nThe dataset was created by Selva and Suresh Kumar to promote Tamil moral literature and make it accessible for AI and NLP applications.\nğŸ“‚ Dataset Details\nLanguage: Tamil\nContent: Aathichoodi verses, meanings, and explanations\nUsage: NLP, Tamil language models, educational tools\nğŸ“Œ Features\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Selvakumarduraipandian/Aathichoodi.","url":"https://huggingface.co/datasets/Selvakumarduraipandian/Aathichoodi","creator_name":"Selvakumar Duraipandian","creator_url":"https://huggingface.co/Selvakumarduraipandian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Tamil","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Aathichoodi","keyword":"tamil","description":"\n\t\n\t\t\n\t\tà®†à®¤à¯à®¤à®¿à®šà¯‚à®Ÿà®¿ Dataset\n\t\n\nğŸ“– About the Dataset\nThis dataset is a structured collection of Aathichoodi, a classical Tamil literary work written by Avvaiyar, along with its meanings and explanations. \nThe dataset was created by Selva and Suresh Kumar to promote Tamil moral literature and make it accessible for AI and NLP applications.\nğŸ“‚ Dataset Details\nLanguage: Tamil\nContent: Aathichoodi verses, meanings, and explanations\nUsage: NLP, Tamil language models, educational tools\nğŸ“Œ Features\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Selvakumarduraipandian/Aathichoodi.","url":"https://huggingface.co/datasets/Selvakumarduraipandian/Aathichoodi","creator_name":"Selvakumar Duraipandian","creator_url":"https://huggingface.co/Selvakumarduraipandian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Tamil","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"tamil","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFiQA2018_ta","keyword":"tamil","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoFiQA2018 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFiQA2018","Tamil"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"tamil","description":"\n\t\n\t\t\n\t\tINCLUDE-lite (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-lite-44.","url":"https://huggingface.co/datasets/CohereLabs/include-lite-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"tamil","description":"\n\t\n\t\t\n\t\tVoxCommunis Corpus\n\t\n\nThe VoxCommunis Corpus is a phonetic corpus derived from the Mozilla Common Voice Corpus. Corresponding audio files and corpus metadata can be downloaded from Mozilla Common Voice, or from one of several Hugging Face repositories for the differing versions. \nWithin each folder, the filenames share similar structure and contain critical information for effectively using the file. More detail regarding the specifics of the filename for each file type is providedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"IndicQARetrieval","keyword":"tamil","description":"\n  IndicQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIndicQA is a manually curated cloze-style reading comprehension dataset that can be used for evaluating question-answering models in 11 Indic languages. It is repurposed retrieving relevant context for each question.\n\n\t\n\t\t\n\n\n\n\n\t\tTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://arxiv.org/abs/2212.05409\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicQARetrieval.","url":"https://huggingface.co/datasets/mteb/IndicQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","human-annotated","translated","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 21.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 21. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_21_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_21_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"SEA-PILE-v2","keyword":"tamil","description":"\n  \n\n\n\n\t\n\t\t\n\t\tSEA-PILE v2\n\t\n\nSEA-PILE v2 is a large, multilingual language modelling dataset of 120 billion tokens, sourced from a diverse array of web content.\nLanguages supported: Vietnamese, Bahasa Indonesia, Tamil, Malay, Thai, Tagalog, Khmer, Lao, Burmese\n\n\t\n\t\t\n\t\tSummary Statistics\n\t\n\nThe total number of tokens in the dataset has been calculated using the Gemma3 tokenizer\n\n\t\n\t\t\nLanguage\nISO 639-1 Code\nTotal Number of Tokens (Billions)\nPercentage\n\n\n\t\t\nVietnamese\nvi\n51.4\n42.13%\n\n\nBahasaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aisingapore/SEA-PILE-v2.","url":"https://huggingface.co/datasets/aisingapore/SEA-PILE-v2","creator_name":"AI Singapore","creator_url":"https://huggingface.co/aisingapore","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Indonesian","Vietnamese","Thai","Tamil"],"keywords_longer_than_N":true},
	{"name":"ocr-data-tnpsc","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil Public Domain Books (Tamil)\n\t\n\nThe dataset comprises over 30 school textbooks and certain TNPSC (Tamil Nadu Public Service Commission) materials in Tamil medium, presumed to be in the public domain.\n","url":"https://huggingface.co/datasets/Hemanth-thunder/ocr-data-tnpsc","creator_name":"Hemanth-thunder","creator_url":"https://huggingface.co/Hemanth-thunder","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Tamil","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ocr-data-tnpsc","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil Public Domain Books (Tamil)\n\t\n\nThe dataset comprises over 30 school textbooks and certain TNPSC (Tamil Nadu Public Service Commission) materials in Tamil medium, presumed to be in the public domain.\n","url":"https://huggingface.co/datasets/Hemanth-thunder/ocr-data-tnpsc","creator_name":"Hemanth-thunder","creator_url":"https://huggingface.co/Hemanth-thunder","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Tamil","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MANGO","keyword":"tamil","description":"\n\t\n\t\t\n\t\tMANGO: A Corpus of Human Ratings for Speech\n\t\n\nMANGO (MUSHRA Assessment corpus using Native listeners and Guidelines to understand human Opinions at scale) is the first large-scale dataset designed for evaluating Text-to-Speech (TTS) systems in Indian languages. \n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\n255,150 human ratings of TTS-generated outputs and ground-truth human speech.\nCovers two major Indian languages: Hindi & Tamil, and English.\nBased on the MUSHRA (Multiple Stimuli with Hidden Referenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/MANGO.","url":"https://huggingface.co/datasets/ai4bharat/MANGO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","crowd-sourced","Hindi","Tamil","English"],"keywords_longer_than_N":true},
	{"name":"IndicMSMARCO","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸ” IndicMSMARCO: Multilingual Information Retrieval Benchmark\n\t\n\nA comprehensive multilingual variant of MS MARCO specifically tailored for Indian languages, featuring carefully selected queries and corresponding passages with high-quality translations.\n\n\t\n\t\t\n\t\tğŸš€ Quick Start - Load Individual Languages\n\t\n\nfrom datasets import load_dataset\n\n# Load ONLY Hindi data (fast and efficient!)\nhindi_data = load_dataset(\"ai4bharat/IndicMSMARCO\", \"hi\")\nprint(f\"Hindi queries:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/IndicMSMARCO.","url":"https://huggingface.co/datasets/ai4bharat/IndicMSMARCO","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","question-answering","multilingual","ms_marco","Assamese"],"keywords_longer_than_N":true},
	{"name":"montok","keyword":"tamil","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tTraining Details\n\t\n\n\n\t\n\t\t\n\t\tTraining Data\n\t\n\nAll tokenizers are trained on samples of the data used to the train the Goldfish language models. \nThe tokenizers were either trained on scaled or unscaled data. This refers to whether the models are trained onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/montok.","url":"https://huggingface.co/datasets/catherinearnett/montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"Legal-QE","keyword":"tamil","description":"Namratap/Legal-QE dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Namratap/Legal-QE","creator_name":"Namrata Patil Gurav","creator_url":"https://huggingface.co/Namratap","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["translation","Gujarati","Tamil","Telugu","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"IN22-Conv","keyword":"tamil","description":"\n  IN22ConvBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Conv is a n-way parallel conversation domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nSocial, Spoken, Fiction, Spoken\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Conv\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Conv.","url":"https://huggingface.co/datasets/mteb/IN22-Conv","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"english-tamil","keyword":"tamil","description":"\n\t\n\t\t\n\t\tEnglish to Tamil Parallel Dataset\n\t\n\nThis is a large-scale Englishâ€“Tamil parallel dataset for sequence-to-sequence tasks such as machine translation, fine-tuning LLMs, and language modeling.\n\n\n\t\n\t\t\n\t\tğŸ“Š Dataset Details\n\t\n\n\nTotal Rows: 5,264,867\nFeatures:\nen â€“ English sentence\nta â€“ Tamil translation\n\n\nLanguage Pair: English â†’ Tamil\nFormat: Hugging Face datasets.Dataset and CSV\nSize: ~1.5 GB (CSV)\n\n\n\n\t\n\t\t\n\t\tğŸ’¡ Use Cases\n\t\n\nThis dataset is ideal for:\n\nFine-tuning translation models (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gopi30/english-tamil.","url":"https://huggingface.co/datasets/gopi30/english-tamil","creator_name":"Gopi M","creator_url":"https://huggingface.co/gopi30","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","English","Tamil","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Telugu-NLP-AI-Dialect-Comedy-video-Dataset","keyword":"tamil","description":"Telugu is one of the sweetest and oldest languages of India. A deep Dive into Telugu its spoken in 2 states and majorly 16 regional dailects.\nThis Dataset help you perform operations in NLP and Speech Recognition Models towards telugu Dialects.\n","url":"https://huggingface.co/datasets/Automation-Tribe/Telugu-NLP-AI-Dialect-Comedy-video-Dataset","creator_name":"AUTTRIBE-AI-AUTOMATION","creator_url":"https://huggingface.co/Automation-Tribe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","Telugu","Kannada","English"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"tamil","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"Iniyavai-naarpadhu","keyword":"tamil","description":"Selvakumarduraipandian/Iniyavai-naarpadhu dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Selvakumarduraipandian/Iniyavai-naarpadhu","creator_name":"Selvakumar Duraipandian","creator_url":"https://huggingface.co/Selvakumarduraipandian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Tamil","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Iniyavai-naarpadhu","keyword":"tamil","description":"Selvakumarduraipandian/Iniyavai-naarpadhu dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Selvakumarduraipandian/Iniyavai-naarpadhu","creator_name":"Selvakumar Duraipandian","creator_url":"https://huggingface.co/Selvakumarduraipandian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Tamil","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"fiNERweb","keyword":"tamil","description":"fiNERweb is a multilingual named entity recognition dataset containing annotated text in multiple languages.\nEach example contains the original text, tokenized text, BIO tags, and character/token spans for entities.","url":"https://huggingface.co/datasets/whoisjones/fiNERweb","creator_name":"Jonas Golde","creator_url":"https://huggingface.co/whoisjones","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","Vietnamese","Tamil","Oriya"],"keywords_longer_than_N":true},
	{"name":"multilingual-text","keyword":"tamil","description":"\n\t\n\t\t\n\t\tMultilingual Text Dataset\n\t\n\nThis dataset contains a curated selection of rows from multiple input datasets, where each row includes a text chunk of approximately 2000 tokens (as measured by Llama 3.1 tokenizer) verified to be written in the correct language. Only rows with properly classified language chunks are retained, ensuring high-quality multilingual data for analysis or model training.\n\n\t\n\t\t\n\t\tPreprocessing Steps\n\t\n\n\nNormalized whitespace, punctuation, Unicode characters, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/multilingual-text.","url":"https://huggingface.co/datasets/agentlans/multilingual-text","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","Amharic","Arabic","Bengali"],"keywords_longer_than_N":true},
	{"name":"common_voice_22_0","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 22.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 22. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_22_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_22_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"tamil","description":"Todo - Write dataset card\n","url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"Saka-Alpaca-v1","keyword":"tamil","description":"https://chatgpt.com\n","url":"https://huggingface.co/datasets/Sakalti/Saka-Alpaca-v1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Swedish","Norwegian","Finnish","German"],"keywords_longer_than_N":true},
	{"name":"indic_sts","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Indic STS\n\t\n\nThis dataset is STS benchmark between English and 12 high-resource Indic languages. This was released as a part of Samanantar paper. Please refer to the paper for more details.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAvailable languages are: en-as, en-bn, en-gu, en-hi, en-kn, en-ml, en-mr, en-or, en-pa, en-ta, en-te, en-ur\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataset Fields\n\t\n\n\nlang_code: 2-digit ISO language code\nsource: The source from which the candidate sentence isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/indic_sts.","url":"https://huggingface.co/datasets/mteb/indic_sts","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"tamil","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Pathupattu-Perumpanatrupadai","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸ›£ï¸ à®ªà¯†à®°à¯à®®à¯à®ªà®¾à®£à®¾à®±à¯à®±à¯à®ªà¯à®ªà®Ÿà¯ˆ (Perumpanatrupadai) Dataset\n\t\n\nà®ªà¯†à®°à¯à®®à¯à®ªà®¾à®£à®¾à®±à¯à®±à¯à®ªà¯à®ªà®Ÿà¯ˆ (Perumpanatrupadai) is one of the Pathupattu (à®ªà®¤à¯à®¤à¯à®ªà¯à®ªà®¾à®Ÿà¯à®Ÿà¯ / Ten Idylls) in Sangam Literature, composed by the poet Uruththirangannanaar (à®‰à®°à¯à®¤à¯à®¤à®¿à®°à®™à¯à®•à®£à¯à®£à®©à®¾à®°à¯).\nIt contains 500 lines and belongs to the Arrupadai genre, where a bard guides another bard towards a generous patron. In this poem, the Perumpanar (a class of bards who sang to the accompaniment of the yal/yaazh) directs fellow minstrels to the patronageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/Pathupattu-Perumpanatrupadai.","url":"https://huggingface.co/datasets/TamilThagaval/Pathupattu-Perumpanatrupadai","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","Tamil","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoArguAna_ta","keyword":"tamil","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoArguAna dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoArguAna","Tamil"],"keywords_longer_than_N":true},
	{"name":"Multi-lingual_Detection","keyword":"tamil","description":"Manirathinam21/Multi-lingual_Detection dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Manirathinam21/Multi-lingual_Detection","creator_name":"Manirathinam","creator_url":"https://huggingface.co/Manirathinam21","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","Tamil","Japanese","English"],"keywords_longer_than_N":true},
	{"name":"ThamizhiLetterDataset","keyword":"tamil","description":"ğŸ“š Thamizhi Letter Dataset\nğŸ”„ Overview\nThe Thamizhi Letter Dataset is a labor of love â¤ï¸ dedicated to preserving and recognizing one of the most ancient scripts. It contains beautifully crafted images ğŸ¨ of Thamizhi script characters mapped to their corresponding Tamil letters. Whether you are a researcher, developer, or history enthusiast, this dataset is here to fuel your passion for character recognition, OCR tasks, and historical script analysis.\nğŸ“‚ Dataset Structure\nThe dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sakthivelan01092004/ThamizhiLetterDataset.","url":"https://huggingface.co/datasets/sakthivelan01092004/ThamizhiLetterDataset","creator_name":"SAKTHIVELAN","creator_url":"https://huggingface.co/sakthivelan01092004","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Tamil","mit","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"Akananuru","keyword":"tamil","description":"\n\t\n\t\t\n\t\tAkananuru (à®…à®•à®¨à®¾à®©à¯‚à®±à¯)\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nAkananuru (à®…à®•à®¨à®¾à®©à¯‚à®±à¯) is one of the classical Tamil Sangam literature anthologies consisting of 400 poems. It belongs to the Ettuthokai (Eight Anthologies) corpus and focuses on the inner (à®…à®•à®®à¯) themes of life such as love, emotions, and human experiences.\nThis dataset provides each poem along with metadata such as title, note (explanation/context), and poet information. It is useful for NLP research, classical text analysis, poetry generationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/Akananuru.","url":"https://huggingface.co/datasets/TamilThagaval/Akananuru","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Tamil","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Tatoeba-Translations","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the latest version of Tatoeba translations as of December 2024.\nThe sentences are downloaded from the Tatoeba collection website.\nThe dataset is processed through mapping sentences.tar.bz2 using sentences_base.tar.bz2 to find source (sentence_src) and target (sentence_tgt) sentences.\nWhile lang_src and lang_tgt columns follow the mapping provided by Tatoeba, the lang_pair column merely lists the two languages in the translation pair.\n\n\t\n\t\t\n\t\n\t\n\t\tStatisticsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-Translations.","url":"https://huggingface.co/datasets/ymoslem/Tatoeba-Translations","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","multilingual","Abkhaz","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"indic_sts","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Indic STS\n\t\n\nThis dataset is STS benchmark between English and 12 high-resource Indic languages. This was released as a part of Samanantar paper. Please refer to the paper for more details.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAvailable languages are: en-as, en-bn, en-gu, en-hi, en-kn, en-ml, en-mr, en-or, en-pa, en-ta, en-te, en-ur\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataset Fields\n\t\n\n\nlang_code: 2-digit ISO language code\nsource: The source from which the candidate sentence isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jaygala24/indic_sts.","url":"https://huggingface.co/datasets/jaygala24/indic_sts","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for BibleNLP Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPartial and complete Bible translations in 833 languages, aligned by verse.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\naai, aak, aau, aaz, abt, abx, aby, acf, acr, acu, adz, aer, aey, agd, agg, agm, agn, agr, agt, agu, aia, aii, aka, ake, alp, alq, als, aly, ame, amf, amk, amm, amn, amo, amp, amr, amu, amx, anh, anv, aoi, aoj, aom, aon, apb, ape, apn, apr, apu, apw, apz, arb, are, arl, arn, arp, asm, aso, ata, atb, atd, atg, att, auc, aui, auyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bible-nlp/biblenlp-corpus.","url":"https://huggingface.co/datasets/bible-nlp/biblenlp-corpus","creator_name":"The Partnership for Applied Biblical NLP","creator_url":"https://huggingface.co/bible-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","expert-generated","translation","multilingual"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"tamil","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"bernice-pretrain-data","keyword":"tamil","description":"Tweet IDs for the 2.5 billion multilingual tweets used to train Bernice, a Twitter encoder.\nThe tweets are from the public 1% Twitter API stream from January 2016 to December 2021. \nTwitter-provided language metadata is provided with the tweet ID. The data contains 66 unique languages, \nas identified by ISO 639 language codes, including `und` for undefined languages.\nTweets need to be re-gathered via the Twitter API.","url":"https://huggingface.co/datasets/jhu-clsp/bernice-pretrain-data","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","no-annotation","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"tamil","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"irumozhi","keyword":"tamil","description":"IruMozhi is a human-translated dataset of parallel text in Literary and\nSpoken Tamil, using sentences taken from Wikipedia. For more details, see the\npaper.\n","url":"https://huggingface.co/datasets/aryaman/irumozhi","creator_name":"Aryaman Arora","creator_url":"https://huggingface.co/aryaman","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Tamil","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"nllb-top25k-enta-cleaned","keyword":"tamil","description":"\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nThe dataset is released under the terms of ODC-BY. By using this, you are also bound to the respective Terms of Use and License of the original source.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@inproceedings{ranathunga-etal-2024-quality,\n    title = \"Quality Does Matter: A Detailed Look at the Quality and Utility of Web-Mined Parallel Corpora\",\n    author = \"Ranathunga, Surangika  and\n      De Silva, Nisansa  and\n      Menan, Velayuthan  and\n      Fernando, Aloka  andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/nllb-top25k-enta-cleaned.","url":"https://huggingface.co/datasets/NLPC-UOM/nllb-top25k-enta-cleaned","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["translation","English","Tamil","odc-by","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"wmt-da-human-evaluation","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains all DA human annotations from previous WMT News Translation shared tasks.\nThe data is organised into 8 columns:\n\nlp: language pair\nsrc: input text\nmt: translation\nref: reference translation\nscore: z score\nraw: direct assessment\nannotators: number of annotators\ndomain: domain of the input text (e.g. news)\nyear: collection year\n\nYou can also find the original data for each year in the results section https://www.statmt.org/wmt{YEAR}/results.htmlâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation.","url":"https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation","creator_name":"Ricardo Rei","creator_url":"https://huggingface.co/RicardoRei","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Estonian"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_regions","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Regions\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\nKey Features:\n\nTextual Data: The dataset contains 500,000 text samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.","url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"indicxnli","keyword":"tamil","description":"IndicXNLI is a translated version of XNLI to 11 Indic Languages. As with XNLI, the goal is\nto predict textual entailment (does sentence A imply/contradict/neither sentence\nB) and is a classification task (given two sentences, predict one of three\nlabels).","url":"https://huggingface.co/datasets/Divyanshu/indicxnli","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","machine-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tamil_data_puthumaippittan_short_stories","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil à®šà®¿à®±à¯à®•à®¤à¯ˆ Dataset by à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains Tamil à®šà®¿à®±à¯à®•à®¤à¯ˆ texts by à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯, processed for language model pretraining.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n20 text passages\nAuthor: à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯\nGenre: à®šà®¿à®±à¯à®•à®¤à¯ˆ\nTotal characters: 24924\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset is suitable for language model pretraining tasks.\nfrom datasets import load_dataset\n\ndataset = load_dataset('Naveen934/tamil_data_puthumaippittan_short_stories')\n\n","url":"https://huggingface.co/datasets/Naveen934/tamil_data_puthumaippittan_short_stories","creator_name":"J","creator_url":"https://huggingface.co/Naveen934","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","mit","ğŸ‡ºğŸ‡¸ Region: US","tamil"],"keywords_longer_than_N":true},
	{"name":"tamil_data_puthumaippittan_short_stories","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil à®šà®¿à®±à¯à®•à®¤à¯ˆ Dataset by à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains Tamil à®šà®¿à®±à¯à®•à®¤à¯ˆ texts by à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯, processed for language model pretraining.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n20 text passages\nAuthor: à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯\nGenre: à®šà®¿à®±à¯à®•à®¤à¯ˆ\nTotal characters: 24924\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset is suitable for language model pretraining tasks.\nfrom datasets import load_dataset\n\ndataset = load_dataset('Naveen934/tamil_data_puthumaippittan_short_stories')\n\n","url":"https://huggingface.co/datasets/Naveen934/tamil_data_puthumaippittan_short_stories","creator_name":"J","creator_url":"https://huggingface.co/Naveen934","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","mit","ğŸ‡ºğŸ‡¸ Region: US","tamil"],"keywords_longer_than_N":true},
	{"name":"MWP_Dataset","keyword":"tamil","description":"\n\t\n\t\t\n\t\tMWP-Dataset\n\t\n\nEnglish-Sinhala-Tamil Math Word Problem Dataset\n\n\t\n\t\t\n\t\tFile Structure\n\t\n\n\nSimple-English.txt -> Simple English Math Word Problems\nSimple-Sinhala.txt -> Simple Sinhala Math Word Problems\nSimple-Tamil.txt -> Simple Tamil Math Word Problems\nAlgebraic-English.txt -> Algebraic English Math Word Problems\nAlgebraic-Sinhala.txt -> Algebraic Sinhala Math Word Problems\nAlgebraic-Tamil.txt -> Algebraic Tamil Math Word Problems\n\nCitation: Niyarepola, K., Athapaththu, D., Ekanayakeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/MWP_Dataset.","url":"https://huggingface.co/datasets/NLPC-UOM/MWP_Dataset","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Sinhala","Tamil","English","mit"],"keywords_longer_than_N":true},
	{"name":"nllb-200-10M-sample","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for \"nllb-200-10M-sample\"\n\t\n\nThis is a sample of nearly 10M sentence pairs from the NLLB-200 \nmined dataset allenai/nllb, \nscored with the model facebook/blaser-2.0-qe \ndescribed in the SeamlessM4T paper.\nThe sample is not random; instead, we just took the top n sentence pairs from each translation direction.\nThe number n was computed with the goal of upsamping the directions that contain underrepresented languages.\nNevertheless, the 187 languoids (language and scriptâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/slone/nllb-200-10M-sample.","url":"https://huggingface.co/datasets/slone/nllb-200-10M-sample","creator_name":"SLONE","creator_url":"https://huggingface.co/slone","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Akan","Amharic","Arabic","Awadhi"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"tamil","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Viet-Mistral/CulturaY.","url":"https://huggingface.co/datasets/Viet-Mistral/CulturaY","creator_name":"Vietnamese Mistral","creator_url":"https://huggingface.co/Viet-Mistral","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"IndicQA","keyword":"tamil","description":"\\","url":"https://huggingface.co/datasets/ai4bharat/IndicQA","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"IndicCOPA","keyword":"tamil","description":"\\","url":"https://huggingface.co/datasets/ai4bharat/IndicCOPA","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3mt","keyword":"tamil","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"tamil","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"tamil_data_kalki_Fiction","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil à®ªà¯Šà®©à¯à®©à®¿à®¯à®¿à®©à¯ à®šà¯†à®²à¯à®µà®©à¯ Dataset by à®•à®²à¯à®•à®¿ à®°à®¾. à®•à®¿à®°à¯à®·à¯à®£à®®à¯‚à®°à¯à®¤à¯à®¤à®¿\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains Tamil à®ªà¯Šà®©à¯à®©à®¿à®¯à®¿à®©à¯ à®šà¯†à®²à¯à®µà®©à¯ texts by à®•à®²à¯à®•à®¿ à®°à®¾. à®•à®¿à®°à¯à®·à¯à®£à®®à¯‚à®°à¯à®¤à¯à®¤à®¿, processed for language model pretraining.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n2290 text chunks\nAuthor: à®•à®²à¯à®•à®¿ à®°à®¾. à®•à®¿à®°à¯à®·à¯à®£à®®à¯‚à®°à¯à®¤à¯à®¤à®¿\nGenre: à®ªà¯Šà®©à¯à®©à®¿à®¯à®¿à®©à¯ à®šà¯†à®²à¯à®µà®©à¯\nTotal chunks: 2290\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"Naveen934/tamil_data_kalki_Fiction\")```\n\n","url":"https://huggingface.co/datasets/Naveen934/tamil_data_kalki_Fiction","creator_name":"J","creator_url":"https://huggingface.co/Naveen934","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"tamil_data_kalki_Fiction","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil à®ªà¯Šà®©à¯à®©à®¿à®¯à®¿à®©à¯ à®šà¯†à®²à¯à®µà®©à¯ Dataset by à®•à®²à¯à®•à®¿ à®°à®¾. à®•à®¿à®°à¯à®·à¯à®£à®®à¯‚à®°à¯à®¤à¯à®¤à®¿\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains Tamil à®ªà¯Šà®©à¯à®©à®¿à®¯à®¿à®©à¯ à®šà¯†à®²à¯à®µà®©à¯ texts by à®•à®²à¯à®•à®¿ à®°à®¾. à®•à®¿à®°à¯à®·à¯à®£à®®à¯‚à®°à¯à®¤à¯à®¤à®¿, processed for language model pretraining.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n2290 text chunks\nAuthor: à®•à®²à¯à®•à®¿ à®°à®¾. à®•à®¿à®°à¯à®·à¯à®£à®®à¯‚à®°à¯à®¤à¯à®¤à®¿\nGenre: à®ªà¯Šà®©à¯à®©à®¿à®¯à®¿à®©à¯ à®šà¯†à®²à¯à®µà®©à¯\nTotal chunks: 2290\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"Naveen934/tamil_data_kalki_Fiction\")```\n\n","url":"https://huggingface.co/datasets/Naveen934/tamil_data_kalki_Fiction","creator_name":"J","creator_url":"https://huggingface.co/Naveen934","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"PRODIGY-LAB_SARA","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for PRODIGY-LAB_CLEANED\n\t\n\n\nRepository: https://github.com/aadhithyaravi\nCreated by: Aadhithya  \nContact: aadhithyaxll@gmail.com  \nInstagram: @aadhi.arc  \nLinkedIn: www.linkedin.com/in/aadhithya-ravi-135019289\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nPRODIGY-SARA-MODEL is a refined and enhanced dataset designed for instruction-based fine-tuning of large language models (LLMs).It combines multiple high-quality sources, including cleaned and normalized instructions, to improveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Apex-X/PRODIGY-LAB_SARA.","url":"https://huggingface.co/datasets/Apex-X/PRODIGY-LAB_SARA","creator_name":"Aadhithya","creator_url":"https://huggingface.co/Apex-X","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Tamil","Hindi","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"tamil_data_Puthumaipithan_Padaipugal","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯ à®ªà®Ÿà¯ˆà®ªà¯à®ªà¯à®•à®³à¯ â€“ à®šà®¿à®±à¯à®•à®¤à¯ˆà®•à®³à¯ â€“ à®¤à¯Šà®•à¯à®ªà¯à®ªà¯ â€“ 1 & 2 Dataset by à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains Tamil à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯ à®ªà®Ÿà¯ˆà®ªà¯à®ªà¯à®•à®³à¯ â€“ à®šà®¿à®±à¯à®•à®¤à¯ˆà®•à®³à¯ â€“ à®¤à¯Šà®•à¯à®ªà¯à®ªà¯ â€“ 1 & 2 texts by à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯, processed for language model pretraining.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n246 text chunks\nAuthor: à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯\nGenre: à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯ à®ªà®Ÿà¯ˆà®ªà¯à®ªà¯à®•à®³à¯ â€“ à®šà®¿à®±à¯à®•à®¤à¯ˆà®•à®³à¯ â€“ à®¤à¯Šà®•à¯à®ªà¯à®ªà¯ â€“ 1 & 2\nTotal chunks: 246\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Naveen934/tamil_data_Puthumaipithan_Padaipugal.","url":"https://huggingface.co/datasets/Naveen934/tamil_data_Puthumaipithan_Padaipugal","creator_name":"J","creator_url":"https://huggingface.co/Naveen934","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"tamil_data_Puthumaipithan_Padaipugal","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯ à®ªà®Ÿà¯ˆà®ªà¯à®ªà¯à®•à®³à¯ â€“ à®šà®¿à®±à¯à®•à®¤à¯ˆà®•à®³à¯ â€“ à®¤à¯Šà®•à¯à®ªà¯à®ªà¯ â€“ 1 & 2 Dataset by à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains Tamil à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯ à®ªà®Ÿà¯ˆà®ªà¯à®ªà¯à®•à®³à¯ â€“ à®šà®¿à®±à¯à®•à®¤à¯ˆà®•à®³à¯ â€“ à®¤à¯Šà®•à¯à®ªà¯à®ªà¯ â€“ 1 & 2 texts by à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯, processed for language model pretraining.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n246 text chunks\nAuthor: à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯\nGenre: à®ªà¯à®¤à¯à®®à¯ˆà®ªà¯à®ªà®¿à®¤à¯à®¤à®©à¯ à®ªà®Ÿà¯ˆà®ªà¯à®ªà¯à®•à®³à¯ â€“ à®šà®¿à®±à¯à®•à®¤à¯ˆà®•à®³à¯ â€“ à®¤à¯Šà®•à¯à®ªà¯à®ªà¯ â€“ 1 & 2\nTotal chunks: 246\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Naveen934/tamil_data_Puthumaipithan_Padaipugal.","url":"https://huggingface.co/datasets/Naveen934/tamil_data_Puthumaipithan_Padaipugal","creator_name":"J","creator_url":"https://huggingface.co/Naveen934","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"NLU-Question-Answering","keyword":"tamil","description":"\n\t\n\t\t\n\t\tSEA Question Answering\n\t\n\nSEA Question Answering evaluates a model's ability to predict a contiguous span of characters that answers the question about a given passage. It is sampled from TyDi QA-GoldP for Indonesian, IndicQA for Tamil, and XQuaD for Thai and Vietnamese.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nSEA Question Answering is designed for evaluating chat or instruction-tuned large language models (LLMs). It is part of the SEA-HELM leaderboard from AI Singapore.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/aisingapore/NLU-Question-Answering.","url":"https://huggingface.co/datasets/aisingapore/NLU-Question-Answering","creator_name":"AI Singapore","creator_url":"https://huggingface.co/aisingapore","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Indonesian","Tamil","Thai"],"keywords_longer_than_N":true},
	{"name":"ta-wikipedia","keyword":"tamil","description":"Suchinthana/ta-wikipedia dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Suchinthana/ta-wikipedia","creator_name":"Wijesundara","creator_url":"https://huggingface.co/Suchinthana","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Tamil","cc-by-4.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"tamil","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"marvl","keyword":"tamil","description":"\n\t\n\t\t\n\t\tMaRVL\n\t\n\n\n\t\n\t\t\n\t\tThis is a copy from the original repo: https://github.com/marvl-challenge/marvl-code\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{liu-etal-2021-visually,\n    title = \"Visually Grounded Reasoning across Languages and Cultures\",\n    author = \"Liu, Fangyu  and\n      Bugliarello, Emanuele  and\n      Ponti, Edoardo Maria  and\n      Reddy, Siva  and\n      Collier, Nigel  and\n      Elliott, Desmond\",\n    booktitle = \"Proceedings of the 2021â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AllenNella/marvl.","url":"https://huggingface.co/datasets/AllenNella/marvl","creator_name":"Haoming Zhong","creator_url":"https://huggingface.co/AllenNella","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Indonesian","Swahili","Tamil","Turkish","Chinese"],"keywords_longer_than_N":true},
	{"name":"INDICSTR12_REAL_IMAGES","keyword":"tamil","description":"ananya12k/INDICSTR12_REAL_IMAGES dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ananya12k/INDICSTR12_REAL_IMAGES","creator_name":"Ananya Kulkarni","creator_url":"https://huggingface.co/ananya12k","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Marathi","Bengali","Kannada","Oriya","Panjabi"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"tamil","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"guvi_multilingual_dataset","keyword":"tamil","description":"zaid002/guvi_multilingual_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zaid002/guvi_multilingual_dataset","creator_name":"Mohammed Zaid p","creator_url":"https://huggingface.co/zaid002","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Urdu","Tamil","Hindi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoQuoraRetrieval_ta","keyword":"tamil","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoQuoraRetrieval dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoQuoraRetrieval","Tamil"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_scenario","keyword":"tamil","description":"\n  MassiveScenarioClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveScenarioClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_scenario.","url":"https://huggingface.co/datasets/mteb/amazon_massive_scenario","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"Pathinen_keezhkanakku-Acharakovai","keyword":"tamil","description":"ğŸ’ à®†à®šà®¾à®°à®•à¯à®•à¯‹à®µà¯ˆ (Acharakovai) Dataset\nà®†à®šà®¾à®°à®•à¯à®•à¯‹à®µà¯ˆ (Acharakovai) is one of the Pathinen Keezhkanakku (Eighteen Minor Works) in Tamil literature.It is a didactic anthology composed during the post-Sangam period (circa 100â€“500 CE).  \nThe text emphasizes righteous conduct, ethical discipline, and social values.The name \"Acharakovai\" means â€œa garland of virtuesâ€, symbolizing a collection of principles guiding personal and social behavior.  \nThis dataset provides a structured digital format ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/Pathinen_keezhkanakku-Acharakovai.","url":"https://huggingface.co/datasets/TamilThagaval/Pathinen_keezhkanakku-Acharakovai","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","token-classification","Tamil","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"IndicCrosslingualSTS","keyword":"tamil","description":"\n  IndicCrosslingualSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis is a Semantic Textual Similarity testset between English and 12 high-resource Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Non-fiction, Web, Spoken, Government, Written, Spoken\nReference\nhttps://huggingface.co/datasets/jaygala24/indic_sts\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicCrosslingualSTS.","url":"https://huggingface.co/datasets/mteb/IndicCrosslingualSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","expert-annotated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"tamil","description":"I generated the dataset following mewsli-x.md#getting-started\nand converted into different parts (see process.py):\n\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\n\nRaw data files are in raw.tar.gz, which contains:\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\n[...] 9.8M Feb 24â€¦ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"english_tamil_slang","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BLESSENA30/english_tamil_slang.","url":"https://huggingface.co/datasets/BLESSENA30/english_tamil_slang","creator_name":"VinukondaBlessena","creator_url":"https://huggingface.co/BLESSENA30","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","question-answering","English","Tamil","mit"],"keywords_longer_than_N":true},
	{"name":"english_tamil_slang","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BLESSENA30/english_tamil_slang.","url":"https://huggingface.co/datasets/BLESSENA30/english_tamil_slang","creator_name":"VinukondaBlessena","creator_url":"https://huggingface.co/BLESSENA30","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","question-answering","English","Tamil","mit"],"keywords_longer_than_N":true},
	{"name":"TamilDataset","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\n\n\t\n\t\t\n\t\tSource: IndicCorp2 Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription:\n\t\n\nThis dataset is filtered dataset of the above mentioned one.\n","url":"https://huggingface.co/datasets/minimalist-ai/TamilDataset","creator_name":"minimalist-ai","creator_url":"https://huggingface.co/minimalist-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","Tamil","mit","1M - 10M","text"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoFEVER_ta","keyword":"tamil","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoFEVER dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoFEVER","Tamil"],"keywords_longer_than_N":true},
	{"name":"Indic-Rag-Suite","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸŒ Multilingual Indic RAG Suite\n\t\n\nA comprehensive multilingual question-answering dataset covering 18 Indian languages with 12,802,615 total samples, designed for RAG (Retrieval-Augmented Generation) applications and multilingual NLP research.\n\n\t\n\t\t\n\t\tğŸš€ Quick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load specific language (recommended)\ndataset = load_dataset(\"AshwinSankar/Indic-Rag-Suite\", \"as\")\ntrain_data = dataset['train']\n\nprint(f\"Loaded {len(train_data)} samples\")\n\n# Accessâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AshwinSankar/Indic-Rag-Suite.","url":"https://huggingface.co/datasets/AshwinSankar/Indic-Rag-Suite","creator_name":"Ashwin Sankar","creator_url":"https://huggingface.co/AshwinSankar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","multilingual","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"tamil","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"tamil","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) â†’ aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages â†’ dolly-machine-translated.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"sirirus","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/indiansatoshi/sirirus.","url":"https://huggingface.co/datasets/indiansatoshi/sirirus","creator_name":"Regan","creator_url":"https://huggingface.co/indiansatoshi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture-with-language","keyword":"tamil","description":"\n\nJust a version of the good tulu-3-sft-mixture dataset with a column indicating language.\nLanguage detection has been performed with fastText.\nâš ï¸ It may contain errors.\n","url":"https://huggingface.co/datasets/anakin87/tulu-3-sft-mixture-with-language","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"health-QE","keyword":"tamil","description":"Namratap/health-QE dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Namratap/health-QE","creator_name":"Namrata Patil Gurav","creator_url":"https://huggingface.co/Namratap","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Tamil","Gujarati","Marathi"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSCIDOCS_ta","keyword":"tamil","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoSCIDOCS dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSCIDOCS","Tamil"],"keywords_longer_than_N":true},
	{"name":"IndicVarna-100k","keyword":"tamil","description":"\n\t\n\t\t\n\t\tIndicVarna for Callchimp.ai (a Dynopii product)\n\t\n\nWe introduce IndiVarna which was prepared by using Google Translate on the dair-ai/emotion dataset to get the samples there translated to the top 10 most commonly used Indian languages.\nThis dataset contains 10000 samples of each of the 10 languages supported.\nThe dataset further translated the labels in the dataset to 3 label sentiments - 0: Negative, 1: Neutral and 2: Positive. Each language has 3334 samples of each category ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dynopii/IndicVarna-100k.","url":"https://huggingface.co/datasets/dynopii/IndicVarna-100k","creator_name":"Dynopii Inc","creator_url":"https://huggingface.co/dynopii","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","sentence-similarity","fill-mask","text-generation"],"keywords_longer_than_N":true},
	{"name":"Benchmark-Testing","keyword":"tamil","description":"shounakpaul95/Benchmark-Testing dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/shounakpaul95/Benchmark-Testing","creator_name":"Shounak Paul","creator_url":"https://huggingface.co/shounakpaul95","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","translation","token-classification","feature-extraction"],"keywords_longer_than_N":true},
	{"name":"PathuPattu-MaduraiKanchi","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸ™ï¸ à®®à®¤à¯à®°à¯ˆà®•à®¾à®à¯à®šà®¿ (Madurai KÄÃ±ci) Dataset\n\t\n\nà®®à®¤à¯à®°à¯ˆà®•à®¾à®à¯à®šà®¿ (Madurai KÄÃ±ci) is one of the Pathupattu (à®ªà®¤à¯à®¤à¯à®ªà¯à®ªà®¾à®Ÿà¯à®Ÿà¯ / Ten Idylls) in Sangam Literature, traditionally attributed to MÄkanar (à®®à®•à®©à®¾à®°à¯).\nThe poem vividly describes the prosperity of Madurai, the capital city of the Chola kingdom, detailing its natural resources, agriculture, river systems, urban life, and social organization.\nIt is one of the richest sources for akam (interior/landscape) and puram (external/urban) descriptions inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/PathuPattu-MaduraiKanchi.","url":"https://huggingface.co/datasets/TamilThagaval/PathuPattu-MaduraiKanchi","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Tamil","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"tamil","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"floras","keyword":"tamil","description":"\n\t\n\t\t\n\t\tFLORAS\n\t\n\nFLORAS is a 50-language benchmark For LOng-form Recognition And Summarization of spoken language. \nThe goal of FLORAS is to create a more realistic benchmarking environment for speech recognition, translation, and summarization models. \nUnlike typical academic benchmarks like LibriSpeech and FLEURS that uses pre-segmented single-speaker read-speech, FLORAS tests the capabilities of models on raw long-form conversational audio, which can have one or many speakers.\nTo encourageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/espnet/floras.","url":"https://huggingface.co/datasets/espnet/floras","creator_name":"ESPnet","creator_url":"https://huggingface.co/espnet","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","summarization","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"TAFSIL","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTAFSIL: Taxonomy Adaptable Fine-grained Entity Recognition through Distant Supervision for Indian Languages\n\t\n\nTAFSIL is a taxonomy-adaptable Fine-grained Entity Recognition (FgER) framework designed to create FgER datasets in six Indian languages: Hindi (hi), Marathi (mr), Sanskrit (sa), Tamil (ta), Telugu (te), and Urdu (ur). These languages belong to two major language familiesâ€”Indo-European and Dravidianâ€”and are spoken by over a billion people worldwide.\nTAFSIL leverages the highâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/prachuryyaIITG/TAFSIL.","url":"https://huggingface.co/datasets/prachuryyaIITG/TAFSIL","creator_name":"Prachuryya Kaushik","creator_url":"https://huggingface.co/prachuryyaIITG","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Hindi","Marathi","Sanskrit","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoMSMARCO_ta","keyword":"tamil","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoMSMARCO dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoMSMARCO","Tamil"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoSciFact_ta","keyword":"tamil","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoSciFact dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoSciFact","Tamil"],"keywords_longer_than_N":true},
	{"name":"english-tamil-colloquial","keyword":"tamil","description":"aishu15/english-tamil-colloquial dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/aishu15/english-tamil-colloquial","creator_name":"Aishwarya lakshmi P S","creator_url":"https://huggingface.co/aishu15","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Tamil","English","apache-2.0","10K - 100K","Text"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoTouche2020_ta","keyword":"tamil","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoTouche2020 dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoTouche2020","Tamil"],"keywords_longer_than_N":true},
	{"name":"tamil-audio-dataset","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil Language Audio Dataset\n\t\n\nText spoken by all participants:\n\"à®šà¯†à®¯à®±à¯à®•à¯ˆ à®¨à¯à®£à¯à®£à®±à®¿à®µà¯ (AI) à®µà¯‡à®•à®®à®¾à®• à®µà®³à®°à¯à®¨à¯à®¤à¯ à®µà®°à¯à®•à®¿à®±à®¤à¯, à®…à®©à¯à®±à®¾à®Ÿ à®µà®¾à®´à¯à®•à¯à®•à¯ˆà®¯à¯ˆ à®®à®¾à®±à¯à®±à¯à®•à®¿à®±à®¤à¯. à®‡à®¤à®©à¯ à®ªà¯à®¤à¯à®®à¯ˆà®•à®³à¯ à®•à®²à¯à®µà®¿, à®®à®°à¯à®¤à¯à®¤à¯à®µà®®à¯ à®®à®±à¯à®±à¯à®®à¯ à®µà¯‡à®²à¯ˆà®¯à¯ˆ à®®à¯‡à®®à¯à®ªà®Ÿà¯à®¤à¯à®¤à¯à®•à®¿à®©à¯à®±à®©, à®ªà¯à®¤à®¿à®¯ à®µà®¾à®¯à¯à®ªà¯à®ªà¯à®•à®³à¯ˆ à®‰à®°à¯à®µà®¾à®•à¯à®•à¯à®•à®¿à®©à¯à®±à®©à¥¤\"\nThe dataset supports training and evaluation of models in:\n\nAutomatic Speech Recognition (ASR)\nEmotional tone classification\nVoice synthesis and generation\nEmotion-aware conversational agents\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntended Uses\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tâœ…â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/tamil-audio-dataset.","url":"https://huggingface.co/datasets/Kratos-AI/tamil-audio-dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Tamil","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"tamil","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"MUSTARD","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for MUSTARD\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMUSTARD (Multilingual Scanned and Scene Table Structure Recognition Dataset) is a diverse dataset curated for table structure recognition across multiple languages. The dataset consists of tables extracted from magazines, including printed, scanned, and scene-text tables, labeled with Optimized Table Structure Language (OTSL) sequences. It is designed to facilitate research in multilingual tableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/badrivishalk/MUSTARD.","url":"https://huggingface.co/datasets/badrivishalk/MUSTARD","creator_name":"Badri Vishal Kasuba","creator_url":"https://huggingface.co/badrivishalk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","English","Hindi","Telugu","Tamil"],"keywords_longer_than_N":true},
	{"name":"tamil_proverbs","keyword":"tamil","description":"This is a compilation of proverbs in tamil extracted from public domain content\nLink to the Original source is here!\n\n\t\n\t\t\n\t\tWork in Progress\n\t\n\nThis repo will contain the proverbs that are extracted and cleaned up and manually verified for potential errors.\n\n\t\n\t\t\n\t\tDisclaimer:\n\t\n\nSince there is a manual process involved, you are expected to verify before using this.\n","url":"https://huggingface.co/datasets/dearprakash/tamil_proverbs","creator_name":"Prakash Rajendran","creator_url":"https://huggingface.co/dearprakash","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Tamil","mit","< 1K","text","Text"],"keywords_longer_than_N":true},
	{"name":"IN22-Conv-Doc-Level","keyword":"tamil","description":"This dataset was constructed by merging individual conversations from the IN22-Conv dataset to create a long-context, document-level parallel benchmark. For further information on domains and statistics, please refer to the original paper and dataset.\n","url":"https://huggingface.co/datasets/VarunGumma/IN22-Conv-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"MMT","keyword":"tamil","description":"\n\t\n\t\t\n\t\tMMT (Multilingual and Multiâ€‘Topic Twitter Language Identification Dataset)\n\t\n\nMMT: A Multilingual and Multiâ€‘Topic Indian Social Media Dataset is a large-scale language identification dataset derived from 1.7 million tweets collected from Indian Twitter/X, annotated with coarse and fine-grained language labels. It supports research on multilingual and code-mixed text in noisy, real-world social media settings.\n\n\t\n\t\t\n\t\n\t\n\t\tğŸ“ Files Included in This Releaseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LingoIITGN/MMT.","url":"https://huggingface.co/datasets/LingoIITGN/MMT","creator_name":"Lingo Research Group","creator_url":"https://huggingface.co/LingoIITGN","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Hindi","English","Gujarati","Bengali"],"keywords_longer_than_N":true},
	{"name":"aitamilnadu_tamil_stories_no_instruct","keyword":"tamil","description":"This is a no-instruct fork of aitamilnadu/tamil_stories\n","url":"https://huggingface.co/datasets/tniranjan/aitamilnadu_tamil_stories_no_instruct","creator_name":"Niranjan T","creator_url":"https://huggingface.co/tniranjan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNQ_ta","keyword":"tamil","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoNQ dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNQ","Tamil"],"keywords_longer_than_N":true},
	{"name":"thirukural-audio","keyword":"tamil","description":"\n\t\n\t\t\n\t\tThirukural Voice-Based Dataset\n\t\n\n\n\t\n\t\t\n\t\tğŸ“– About the Dataset\n\t\n\nThis dataset contains voice recordings of all 1330 thirukural couplets, generated using the gTTS (Google Text-to-Speech) Python package. It aims to make thirukural more accessible for AI/ML applications, educational tools, and Tamil language preservation efforts.\n\n\t\n\t\t\n\t\tğŸ› Dataset Contents\n\t\n\nEach record in this dataset includes:\n\nID â€“ The unique number of the Kural (1 to 1330)\nKural â€“ The original Tamil couplet\nAudio â€“â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Selvakumarduraipandian/thirukural-audio.","url":"https://huggingface.co/datasets/Selvakumarduraipandian/thirukural-audio","creator_name":"Selvakumar Duraipandian","creator_url":"https://huggingface.co/Selvakumarduraipandian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Tamil","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"thirukural-audio","keyword":"tamil","description":"\n\t\n\t\t\n\t\tThirukural Voice-Based Dataset\n\t\n\n\n\t\n\t\t\n\t\tğŸ“– About the Dataset\n\t\n\nThis dataset contains voice recordings of all 1330 thirukural couplets, generated using the gTTS (Google Text-to-Speech) Python package. It aims to make thirukural more accessible for AI/ML applications, educational tools, and Tamil language preservation efforts.\n\n\t\n\t\t\n\t\tğŸ› Dataset Contents\n\t\n\nEach record in this dataset includes:\n\nID â€“ The unique number of the Kural (1 to 1330)\nKural â€“ The original Tamil couplet\nAudio â€“â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Selvakumarduraipandian/thirukural-audio.","url":"https://huggingface.co/datasets/Selvakumarduraipandian/thirukural-audio","creator_name":"Selvakumar Duraipandian","creator_url":"https://huggingface.co/Selvakumarduraipandian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Tamil","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"tamil","description":"\n\t\n\t\t\n\t\tlightblue/reasoning-multilingual-R1-Llama-70B-train\n\t\n\nThis is a multilingual reasoning dataset covering more than 30 languages.\nThis dataset was made by:\n\nSampling prompts from English datasets and translating them to various languages\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\n\nThis dataset was then used to train a multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"indicCorpv2","keyword":"tamil","description":"    IndicCORPV2 is the largest collection of texts for Indic langauges consisting of 20.9 Billion tokens of which 14.4B tokens correspond to 23 Indic languages and 6.B tokens of Indian English content curated from Indian websites.","url":"https://huggingface.co/datasets/satpalsr/indicCorpv2","creator_name":"Satpal Singh Rathore","creator_url":"https://huggingface.co/satpalsr","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","Assamese","Bodo (India)","Bengali","Dogri (macrolanguage)"],"keywords_longer_than_N":true},
	{"name":"quran","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for the Quran\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThe Quran with metadata, translations, and multiple Arabic text (can use specific types for embeddings, search, classification, and display). There are 126+ columns containing 43+ languages.\n\n\t\n\t\t\n\t\tTODO\n\t\n\n\n Add Tafsirs  \n Add topics/ontology\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"nazimali/quran\", split=\"train\")\nds\n\nOutput:\nDataset({\n    features: ['surah', 'ayah', 'surah-name', 'surah-total-ayas'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nazimali/quran.","url":"https://huggingface.co/datasets/nazimali/quran","creator_name":"Nazim Ali","creator_url":"https://huggingface.co/nazimali","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","translation","feature-extraction","text-generation"],"keywords_longer_than_N":true},
	{"name":"common-voice-tamil-english-labeled-Data-v2","keyword":"tamil","description":"Lingalingeswaran/common-voice-tamil-english-labeled-Data-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Lingalingeswaran/common-voice-tamil-english-labeled-Data-v2","creator_name":"Sathiyalokeswaran","creator_url":"https://huggingface.co/Lingalingeswaran","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Tamil","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"tamily-1","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamily-1: Ancient Tamil OCR Synthetic Dataset\n\t\n\nTamizhi \"à®¤à®®à®¿à®´à®¿\"\n\n\t\n\t\t\n\t\tDescription\n\t\n\n\nRepository: sasicodes/tamily-1\nPoint of Contact: @sasicodes\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nTamily-1 is an ancient Tamil OCR synthetic dataset generated from the first 200,000 rows of Solvari-1, a large Tamil text corpus. The dataset contains rendered images of Tamil text with various augmentations and styles, making it suitable for training OCR models.\n\n\t\n\t\t\n\t\tFields\n\t\n\n\nimage: PNG image of rendered Tamilâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sasicodes/tamily-1.","url":"https://huggingface.co/datasets/sasicodes/tamily-1","creator_name":"Sasi","creator_url":"https://huggingface.co/sasicodes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-feature-extraction","sasicodes/solvari-1","Tamil","mit"],"keywords_longer_than_N":true},
	{"name":"Legacy-Font-and-Romanized-Tamil-Corpus","keyword":"tamil","description":"sanujen/Legacy-Font-and-Romanized-Tamil-Corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sanujen/Legacy-Font-and-Romanized-Tamil-Corpus","creator_name":"Sanujen Premkumar","creator_url":"https://huggingface.co/sanujen","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Tamil","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"tamil","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"tamil","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"multiblimp","keyword":"tamil","description":"\n\t\n\t\t\n\t\tMultiBLiMP\n\t\n\nMultiBLiMP is a massively Multilingual Benchmark for Linguistic Minimal Pairs. The dataset is composed of synthetic pairs generated using Universal Dependencies and UniMorph.\nThe paper can be found here.\nWe split the data set by language: each language consists of a single .tsv file. The rows contain many attributes for a particular pair, most important are the sen and wrong_sen fields, which we use for evaluating the language models.\n\n\t\n\t\t\n\t\n\t\n\t\tUsing MultiBLiMP\n\t\n\nToâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jumelet/multiblimp.","url":"https://huggingface.co/datasets/jumelet/multiblimp","creator_name":"Jaap Jumelet","creator_url":"https://huggingface.co/jumelet","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Buriat","Spanish","Sanskrit","Romanian"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoDBPedia_ta","keyword":"tamil","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoDBPedia dataset, specifically adapted for informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoDBPedia","Tamil"],"keywords_longer_than_N":true},
	{"name":"tamil_colloquial","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/VishaliSekar/tamil_colloquial.","url":"https://huggingface.co/datasets/VishaliSekar/tamil_colloquial","creator_name":"Vishali","creator_url":"https://huggingface.co/VishaliSekar","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Tamil","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Pathinen_keezhkanakku-Innanarpadhu","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸŒ¸ à®‡à®©à®¿à®¯à®µà¯ˆà®¨à®¾à®±à¯à®ªà®¤à¯ (Iniyavai Narpadu) Dataset\n\t\n\nà®‡à®©à®¿à®¯à®µà¯ˆà®¨à®¾à®±à¯à®ªà®¤à¯ (Iniyavai Narpadu) is one of the Pathinen Keezhkanakku (Eighteen Minor Works) in classical Tamil literature, composed by the poet à®ªà¯‚à®¤à®à¯à®šà¯‡à®¨à¯à®¤à®©à®¾à®°à¯ (Poothanchenthanar).\nIt consists of 40 Venpa poems, each describing the essence of what is considered â€œIniyavaiâ€ (Sweet/Desirable things in life).\n\nIn four poems, the poet describes four desirable things.  \nIn the remaining poems, he lists three desirable things each.\n\nThe workâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/Pathinen_keezhkanakku-Innanarpadhu.","url":"https://huggingface.co/datasets/TamilThagaval/Pathinen_keezhkanakku-Innanarpadhu","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","text-classification","Tamil","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"en_ta","keyword":"tamil","description":"Hemanth-thunder/en_ta dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Hemanth-thunder/en_ta","creator_name":"Hemanth-thunder","creator_url":"https://huggingface.co/Hemanth-thunder","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Tamil","English","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"thirukkural_instruct","keyword":"tamil","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\nthirukkural_QA is an open source dataset of instruct-style records generated by converting publicly available data on Thirukkural and it's meaning.\nThis was created as part of Aya Open Science Initiative by Cohere For AI.\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\nSupported Tasks:\n\nTraining LLMs\nSynthetic Data Generation\nData Augmentation\nQuestion Answering\n\nLanguages: Tamil Version: 1.0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/aitamilnadu/thirukkural_instruct.","url":"https://huggingface.co/datasets/aitamilnadu/thirukkural_instruct","creator_name":"AI Tamil Nadu","creator_url":"https://huggingface.co/aitamilnadu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","expert-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"tamil-kavithai","keyword":"tamil","description":"abishekmahi/tamil-kavithai dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/abishekmahi/tamil-kavithai","creator_name":"Abishek Mahi","creator_url":"https://huggingface.co/abishekmahi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"oscar-mini","keyword":"tamil","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-mini","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"Bhasha-Abhijnaanam","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Aksharantar\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBhasha-Abhijnaanam is a language identification test set for native-script as well as Romanized text which spans 22 Indic languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\n\t\n\t\t\n\n\n\n\n\n\n\n\n\t\t\nAssamese (asm)\nHindi (hin)\nMaithili (mai)\nNepali (nep)\nSanskrit (san)\nTamil (tam)\n\n\nBengali (ben)\nKannada (kan)\nMalayalam (mal)\nOriya (ori)\nSantali (sat)\nTelugu (tel)\n\n\nBodo(brx)\nKashmiriâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam.","url":"https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"Thirukural_tamil_with_meaning","keyword":"tamil","description":"kodebot/Thirukural_tamil_with_meaning dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kodebot/Thirukural_tamil_with_meaning","creator_name":"kodebot","creator_url":"https://huggingface.co/kodebot","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Tamil","apache-2.0","1K - 10K","text","Text"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"FranÃ§ais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"tamil","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cahya/fleurs.","url":"https://huggingface.co/datasets/cahya/fleurs","creator_name":"Cahya Wirawan","creator_url":"https://huggingface.co/cahya","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mkb","keyword":"tamil","description":"The Prime Minister's speeches - Mann Ki Baat, on All India Radio, translated into many languages.","url":"https://huggingface.co/datasets/siripragadashashank/mkb","creator_name":"Shashank Siripragada","creator_url":"https://huggingface.co/siripragadashashank","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"tatoeba","keyword":"tamil","description":"This is a collection of translated sentences from Tatoeba\n359 languages, 3,403 bitexts\ntotal number of files: 750\ntotal number of tokens: 65.54M\ntotal number of sentence fragments: 8.96M","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ms_terms","keyword":"tamil","description":"The Microsoft Terminology Collection can be used to develop localized versions of applications that integrate with Microsoft products.\nIt can also be used to integrate Microsoft terminology into other terminology collections or serve as a base IT glossary\nfor language development in the nearly 100 languages available. Terminology is provided in .tbx format, an industry standard for terminology exchange.","url":"https://huggingface.co/datasets/microsoft/ms_terms","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","license_name":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":null,"first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","multilingual","translation"],"keywords_longer_than_N":true},
	{"name":"Tamil_chat_dataset","keyword":"tamil","description":"TokenBender/Tamil_chat_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/TokenBender/Tamil_chat_dataset","creator_name":"tokenbender","creator_url":"https://huggingface.co/TokenBender","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Tamil","English","apache-2.0","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"truthfulqa_indic","keyword":"tamil","description":"Original Repository\n\n\t\n\t\t\n\t\tTasks (from original repository)\n\t\n\n\n\t\n\t\t\n\t\tGeneration (main task):\n\t\n\nTask: Given a question, generate a 1-2 sentence answer.\nObjective: The primary objective is overall truthfulness, expressed as the percentage of the model's answers that are true. Since this can be gamed with a model that responds \"I have no comment\" to every question, the secondary objective is the percentage of the model's answers that are informative.\n\n\t\n\t\t\n\t\tFuture Work:\n\t\n\n\nValidateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vakyansh/truthfulqa_indic.","url":"https://huggingface.co/datasets/vakyansh/truthfulqa_indic","creator_name":"Vakyansh","creator_url":"https://huggingface.co/vakyansh","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Hindi","Panjabi","Telugu","Tamil"],"keywords_longer_than_N":true},
	{"name":"tamil","keyword":"tamil","description":"\n\t\n\t\t\n\t\tMy Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains audio recordings with corresponding text transcriptions. It is designed for speech recognition and natural language processing tasks.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\ndata/audio/: Contains audio files.\nmetadata.csv: Metadata file with transcription and additional information.\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\n[Your License Name] - [License URL]\n\n\t\n\t\t\n\t\tCitation\n\t\n\nPlease cite this dataset as follows:\n","url":"https://huggingface.co/datasets/Sethu-Prasad-S-220994/tamil","creator_name":"sethu prasad s","creator_url":"https://huggingface.co/Sethu-Prasad-S-220994","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Tamil","cc0-1.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"common_voice_17_0","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 17.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 17. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_17_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_17_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"Scrapped-data-English-Thanglish-conversion","keyword":"tamil","description":"PA0703/Scrapped-data-English-Thanglish-conversion dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/PA0703/Scrapped-data-English-Thanglish-conversion","creator_name":"Priyanga A","creator_url":"https://huggingface.co/PA0703","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Tamil","mit","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"English-to-Thanglish-dataset","keyword":"tamil","description":"PA0703/English-to-Thanglish-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/PA0703/English-to-Thanglish-dataset","creator_name":"Priyanga A","creator_url":"https://huggingface.co/PA0703","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Tamil","mit","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-olmo-2-mixture","keyword":"tamil","description":"Note that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe OLMo v2 SFT mixture was used to train the OLMo models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et al., 2023)\nNo Robots (CC-BY-NC-4.0), 9,500â€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3","keyword":"tamil","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","url":"https://huggingface.co/datasets/bigscience/xP3","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"common_language","keyword":"tamil","description":"This dataset is composed of speech recordings from languages that were carefully selected from the CommonVoice database.\nThe total duration of audio recordings is 45.1 hours (i.e., 1 hour of material for each language).\nThe dataset has been extracted from CommonVoice to train language-id systems.","url":"https://huggingface.co/datasets/speechbrain/common_language","creator_name":"SpeechBrain","creator_url":"https://huggingface.co/speechbrain","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","speaker-identification","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"Shrutilipi","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Shrutilipi (Full Version)\n\t\n\n\n\nThis is a full and unfiltered version of the Shrutilipi dataset for languages: Bengali, Hindi, Kannada, Malayalam, Marathi, Odia, Tamil and Telugu - originally described in the paper: Effectiveness of Mining Audio and Text Pairs from Public Data for Improving ASR Systems for Low-Resource Languages.\nThe data for Gujarati, Punjabi and Sanskrit will be uploaded later.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nSince the dataset was automatically curatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/skesiraju/Shrutilipi.","url":"https://huggingface.co/datasets/skesiraju/Shrutilipi","creator_name":"Santosh Kesiraju","creator_url":"https://huggingface.co/skesiraju","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Bengali","Hindi","Kannada","Malayalam"],"keywords_longer_than_N":true},
	{"name":"common_voice_tamil_english-labeled-Data-filtered-v4","keyword":"tamil","description":"Lingalingeswaran/common_voice_tamil_english-labeled-Data-filtered-v4 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Lingalingeswaran/common_voice_tamil_english-labeled-Data-filtered-v4","creator_name":"Sathiyalokeswaran","creator_url":"https://huggingface.co/Lingalingeswaran","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Tamil","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bible","keyword":"tamil","description":"\n\t\n\t\t\n\t\tFull Bible Chapter wise - Tamil\n\t\n\nWeb Scrapped from https://bible.catholicgallery.org/ecu-tamil/\n","url":"https://huggingface.co/datasets/mastergokul/Bible","creator_name":"Gokul S","creator_url":"https://huggingface.co/mastergokul","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","Tamil","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Bible","keyword":"tamil","description":"\n\t\n\t\t\n\t\tFull Bible Chapter wise - Tamil\n\t\n\nWeb Scrapped from https://bible.catholicgallery.org/ecu-tamil/\n","url":"https://huggingface.co/datasets/mastergokul/Bible","creator_name":"Gokul S","creator_url":"https://huggingface.co/mastergokul","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","Tamil","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Ettuthogai-Narrinai","keyword":"tamil","description":"ğŸ“– Narrinai: A Curated Dataset of Classical Tamil Sangam Poetry\nDataset Summary\nDive into the world of ancient Tamil literature with the Narrinai Dataset, a curated collection of poems from one of the renowned Ettuthokai (Eight Anthologies) of Sangam literature (c. 500 BCE â€“ 300 CE). Narrinai focuses on akam (à®…à®•à®®à¯) poetry, exploring the intricate emotions of love, separation, and union.\nThis dataset provides a clean, analysis-ready corpus containing the original 401 poems, their associatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/Ettuthogai-Narrinai.","url":"https://huggingface.co/datasets/TamilThagaval/Ettuthogai-Narrinai","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Tamil","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"tamil","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"milu-cleaned","keyword":"tamil","description":"\n\t\n\t\t\n\t\tMILU: A Multi-task Indic Language Understanding Benchmark\n\t\n\n\n  \n  \n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nMILU (Multi-task Indic Language Understanding Benchmark) is a comprehensive evaluation dataset designed to assess the performance of Large Language Models (LLMs) across 11 Indic languages. It spans 8 domains and 41 subjects, reflecting both general and culturally specific knowledge from India.\n\n\t\n\t\n\t\n\t\tKey Features\n\t\n\n\n11 Indian Languages: Bengali, Gujarati, Hindi, Kannada, Malayalamâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/murthyrudra/milu-cleaned.","url":"https://huggingface.co/datasets/murthyrudra/milu-cleaned","creator_name":"Rudra Murthy","creator_url":"https://huggingface.co/murthyrudra","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"tamil","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"thirukkural","keyword":"tamil","description":"yuvarajvelmurugan/thirukkural dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/yuvarajvelmurugan/thirukkural","creator_name":"Yuvaraj Velmurugan","creator_url":"https://huggingface.co/yuvarajvelmurugan","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","table-question-answering","English","Tamil"],"keywords_longer_than_N":true},
	{"name":"Pralekha","keyword":"tamil","description":"\n\t\n\t\t\n\t\tPralekha: Cross-Lingual Document Alignment for Indic Languages\n\t\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\nPralekha is a large-scale parallel document dataset spanning across 11 Indic languages and English. It comprises over 3 milliondocument pairs, with 1.5 million being English-Indic Pairs. This dataset serves both as a benchmark for evaluating Cross-Lingual Document Alignment (CLDA) techniques and as a domain-specific parallel corpus for training document-level Machineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Pralekha.","url":"https://huggingface.co/datasets/ai4bharat/Pralekha","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Bengali","English","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"eng_montok","keyword":"tamil","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\n","url":"https://huggingface.co/datasets/catherinearnett/eng_montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"shiksha","keyword":"tamil","description":"\n\t\n\t\t\n\t\tShiksha Dataset\n\t\n\nThis is a Technical Domain focused Translation Dataset for 8 Indian Languages. It consists of more than 2.5 million rows of translation pairs between all 8 languages and English.\nThis data has been derived from raw NPTEL documents. More information on this can be found in our paper: https://arxiv.org/abs/2412.09025\nIf you use this data in your work, please cite us:\n@misc{joglekar2024shikshatechnicaldomainfocused,\n      title={Shiksha: A Technical Domain focusedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/shiksha.","url":"https://huggingface.co/datasets/SPRINGLab/shiksha","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Hindi","Bengali","Tamil","Telugu"],"keywords_longer_than_N":true},
	{"name":"Flores-Indic-Doc-Level","keyword":"tamil","description":"This dataset was constructed by merging individual sentences from the Flores dataset based on matching domain, topic, and URL attributes. The result is a long-context, document-level parallel benchmark. For more details on the domains and dataset statistics, please refer to the original paper and the dataset.\n","url":"https://huggingface.co/datasets/VarunGumma/Flores-Indic-Doc-Level","creator_name":"Varun Gumma","creator_url":"https://huggingface.co/VarunGumma","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-generated","multilingual","translation","Assamese"],"keywords_longer_than_N":true},
	{"name":"tts-100-v1","keyword":"tamil","description":"mastermani305/tts-100-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mastermani305/tts-100-v1","creator_name":"Manikandan","creator_url":"https://huggingface.co/mastermani305","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-audio","Tamil","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Indic_south_langs","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Logii33/Indic_south_langs.","url":"https://huggingface.co/datasets/Logii33/Indic_south_langs","creator_name":"Logesh","creator_url":"https://huggingface.co/Logii33","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Hindi","Tamil","Malayalam","Telugu"],"keywords_longer_than_N":true},
	{"name":"solvari-1","keyword":"tamil","description":"Solvari means line of words\nDataset of Tamil language lines with word count\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach Parquet file contains:\n\ntext: Raw Tamil text\nwords: Word count\n\n\n\t\n\t\t\n\t\tTechnical Specifications\n\t\n\n\nFormat: Parquet\nFilter: Tamil only (Unicode range: \\u0b80-\\u0bff)\n\n","url":"https://huggingface.co/datasets/sasicodes/solvari-1","creator_name":"Sasi","creator_url":"https://huggingface.co/sasicodes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Tamil","mit","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Thirukural","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸ“– à®¤à®¿à®°à¯à®•à¯à®•à¯à®±à®³à¯ Dataset\n\t\n\n\n\t\n\t\t\n\t\tğŸ”¹ Introduction\n\t\n\nà®‡à®¨à¯à®¤ dataset-à®²à¯ à®¤à®¿à®°à¯à®•à¯à®•à¯à®±à®³à¯, à®…à®¤à®©à¯ à®µà®¿à®³à®•à¯à®•à®®à¯, à®ªà®¾à®Ÿà®ªà¯à®ªà®¿à®°à®¿à®µà¯à®•à®³à¯ à®®à®±à¯à®±à¯à®®à¯ à®ªà®² à®‰à®°à¯ˆà®•à®³à¯ à®‰à®³à¯à®³à®©.\n\nSelvakumar Duraipandian, one of the developers of thirukural.ai, has contributed to this dataset, making it a valuable resource for various language models and chatbot applications.\n\nà®‡à®¤à¯ˆ Natural Language Processing (NLP) à®®à®±à¯à®±à¯à®®à¯ Chatbot Fine-tuning à®ªà¯‹à®©à¯à®± Machine Learning à®µà¯‡à®²à¯ˆà®•à®³à¯à®•à¯à®•à¯ à®ªà®¯à®©à¯à®ªà®Ÿà¯à®¤à¯à®¤à®²à®¾à®®à¯.\n\n\t\n\t\t\n\t\n\t\n\t\tğŸ“‚ Dataset Structure\n\t\n\nà®‡à®¨à¯à®¤ datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Selvakumarduraipandian/Thirukural.","url":"https://huggingface.co/datasets/Selvakumarduraipandian/Thirukural","creator_name":"Selvakumar Duraipandian","creator_url":"https://huggingface.co/Selvakumarduraipandian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Tamil","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Thirukural","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸ“– à®¤à®¿à®°à¯à®•à¯à®•à¯à®±à®³à¯ Dataset\n\t\n\n\n\t\n\t\t\n\t\tğŸ”¹ Introduction\n\t\n\nà®‡à®¨à¯à®¤ dataset-à®²à¯ à®¤à®¿à®°à¯à®•à¯à®•à¯à®±à®³à¯, à®…à®¤à®©à¯ à®µà®¿à®³à®•à¯à®•à®®à¯, à®ªà®¾à®Ÿà®ªà¯à®ªà®¿à®°à®¿à®µà¯à®•à®³à¯ à®®à®±à¯à®±à¯à®®à¯ à®ªà®² à®‰à®°à¯ˆà®•à®³à¯ à®‰à®³à¯à®³à®©.\n\nSelvakumar Duraipandian, one of the developers of thirukural.ai, has contributed to this dataset, making it a valuable resource for various language models and chatbot applications.\n\nà®‡à®¤à¯ˆ Natural Language Processing (NLP) à®®à®±à¯à®±à¯à®®à¯ Chatbot Fine-tuning à®ªà¯‹à®©à¯à®± Machine Learning à®µà¯‡à®²à¯ˆà®•à®³à¯à®•à¯à®•à¯ à®ªà®¯à®©à¯à®ªà®Ÿà¯à®¤à¯à®¤à®²à®¾à®®à¯.\n\n\t\n\t\t\n\t\n\t\n\t\tğŸ“‚ Dataset Structure\n\t\n\nà®‡à®¨à¯à®¤ datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Selvakumarduraipandian/Thirukural.","url":"https://huggingface.co/datasets/Selvakumarduraipandian/Thirukural","creator_name":"Selvakumar Duraipandian","creator_url":"https://huggingface.co/Selvakumarduraipandian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Tamil","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"indic-squad","keyword":"tamil","description":"\n\t\n\t\t\n\t\tIndicSQuAD Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nIndicSQuAD is a comprehensive multilingual extractive Question Answering (QA) dataset covering nine major Indic languages: Hindi, Bengali, Tamil, Telugu, Marathi, Gujarati, Urdu, Kannada, Oriya, and Malayalam. It's systematically derived from the popular English SQuAD (Stanford Question Answering Dataset).\nThe rapid progress in QA systems has predominantly benefited high-resource languages, leaving Indic languages significantlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/l3cube-pune/indic-squad.","url":"https://huggingface.co/datasets/l3cube-pune/indic-squad","creator_name":"L3Cube Labs","creator_url":"https://huggingface.co/l3cube-pune","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Bengali","Gujarati","Hindi","Kannada"],"keywords_longer_than_N":true},
	{"name":"HinduTamil-News-Articles-Dataset","keyword":"tamil","description":"\n\t\n\t\t\n\t\tHinduTamil News Articles Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains news articles in Tamil language scraped from the Hindu Tamil news website. Each article includes its title, author, city, published date, and text.\n\n\t\n\t\t\n\t\tMotivation\n\t\n\nThis dataset was created to provide a comprehensive collection of Tamil news articles for research and analysis purposes.\n\n\t\n\t\t\n\t\tData Sources and collection method\n\t\n\nThe data in this dataset was collected from the Hindu Tamil news websiteâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shwetasss/HinduTamil-News-Articles-Dataset.","url":"https://huggingface.co/datasets/Shwetasss/HinduTamil-News-Articles-Dataset","creator_name":"Shweta Sukhtankar","creator_url":"https://huggingface.co/Shwetasss","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","Tamil","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"HinduTamil-News-Articles-Dataset","keyword":"tamil","description":"\n\t\n\t\t\n\t\tHinduTamil News Articles Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains news articles in Tamil language scraped from the Hindu Tamil news website. Each article includes its title, author, city, published date, and text.\n\n\t\n\t\t\n\t\tMotivation\n\t\n\nThis dataset was created to provide a comprehensive collection of Tamil news articles for research and analysis purposes.\n\n\t\n\t\t\n\t\tData Sources and collection method\n\t\n\nThe data in this dataset was collected from the Hindu Tamil news websiteâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shwetasss/HinduTamil-News-Articles-Dataset.","url":"https://huggingface.co/datasets/Shwetasss/HinduTamil-News-Articles-Dataset","creator_name":"Shweta Sukhtankar","creator_url":"https://huggingface.co/Shwetasss","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","Tamil","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gpt4o_gen","keyword":"tamil","description":"Youseff1987/multilingual_translation_gpt4o_gen dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gpt4o_gen","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"guvi_fintuned_dataset","keyword":"tamil","description":"zaid002/guvi_fintuned_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zaid002/guvi_fintuned_dataset","creator_name":"Mohammed Zaid p","creator_url":"https://huggingface.co/zaid002","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["translation","table-question-answering","summarization","Urdu","English"],"keywords_longer_than_N":true},
	{"name":"Tamil-Colloquial-Standard-Parlance-Corpus","keyword":"tamil","description":"sanujen/Tamil-Colloquial-Standard-Parlance-Corpus dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sanujen/Tamil-Colloquial-Standard-Parlance-Corpus","creator_name":"Sanujen Premkumar","creator_url":"https://huggingface.co/sanujen","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-classification","translation","Tamil","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"tamil","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"tamil","description":"\n\n\n\t\n\t\t\n\t\tğŸ”· Accepted in NAACL Proceedings (2025) ğŸ”·\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval ğŸ“š [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"tamil","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"Nadi_Indic466k_Instruct","keyword":"tamil","description":"\n\t\n\t\t\n\t\tNadi_Indic466K_Instruct Dataset\n\t\n\nThe Nadi_Indic466K_Instruct dataset is the world's first coding dataset with 18 Indian language support, 466k rows and 142 Million total tokens. This dataset can be used by developers to build Indian coding language models (LLMs) for various programming languages.\nQ-LoRA based SFT/PPO/DPO fine-tuning can be done on the dataset in LLAMA-2 or Mistral or any opens-soure LLM for text generation.\nThe dataset was carefully curated such that the coding partâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct.","url":"https://huggingface.co/datasets/convaiinnovations/Nadi_Indic466k_Instruct","creator_name":"Convai Innovations","creator_url":"https://huggingface.co/convaiinnovations","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Hindi","Panjabi","Bengali","Tamil"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"tamil","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\n\n\t\n\t\t\n\nToxic\nNeutral\nTotal\n\n\n\t\t\nmultilingual-train-deduplicated.csvâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Spanish","Panjabi"],"keywords_longer_than_N":true},
	{"name":"Purananooru","keyword":"tamil","description":"\n\t\n\t\t\n\t\tà®ªà¯à®±à®¨à®¾à®©à¯‚à®±à¯ (Purananuru)\n\t\n\nğŸ“ Dataset Description\nà®ªà¯à®±à®¨à®¾à®©à¯‚à®±à¯ (Purananuru) is one of the eight classical anthologies (Ettuthokai) in Sangam Literature, containing 400 poems.\nEach poem is written by a different poet and is dedicated to various kings, chieftains, or deities.\nThis dataset provides a structured digital format of Purananuru, including:\nPoem ID\nTitle\nOriginal Tamil Poem text\nExplanation (à®ªà¯Šà®°à¯à®³à¯à®°à¯ˆ)\nThe dataset bridges ancient Tamil literature with modern NLP research.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/Purananooru.","url":"https://huggingface.co/datasets/TamilThagaval/Purananooru","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","token-classification","text-classification","Tamil","mit"],"keywords_longer_than_N":true},
	{"name":"svq","keyword":"tamil","description":"\n\t\n\t\t\n\t\tSimple Voice Questions\n\t\n\nSimple Voice Questions (SVQ) is a set of short audio questions recorded in 26 locales across 17 languages under multiple audio conditions.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nSpeakers were presented with recording instructions specifying the recording environment and text query to be recorded.\nThey recorded using their own phones or tablets under four conditions:\n\nclean: Record in quiet environment\nbackground speech noise: Record while audio from sources like podcastsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/svq.","url":"https://huggingface.co/datasets/google/svq","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"kalithogai","keyword":"tamil","description":"\n\t\n\t\t\n\t\tKalithogai (à®•à®²à®¿à®¤à¯à®¤à¯Šà®•à¯ˆ)\n\t\n\nKalithogai (à®•à®²à®¿à®¤à¯à®¤à¯Šà®•à¯ˆ) is one of the Ettuthokai (Eight Anthologies) of Tamil Sangam literature, consisting of 150 poems written in the Kali meter.\nThe poems cover inner-life themes (Akam) such as love, separation, and human emotions, often mapped to the landscapes (thinai) like Kurinji, Mullai, Marutham, Neithal, and Palai.\nThis dataset provides each poem along with metadata such as title, poet, and structured text.\nIt is useful for NLP research, poetryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/kalithogai.","url":"https://huggingface.co/datasets/TamilThagaval/kalithogai","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Tamil","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"tamasheq-sentiments-corpus","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamasheq Sentiment Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains sentiment-labeled text data in Tamasheq for binary sentiment classification (Positive/Negative). Sentiments are extracted and processed from the English meanings of the sentences using DistilBERT for sentiment classification. The dataset is part of a larger collection of African language sentiment analysis resources.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal samples: 1,107\nPositive sentiment: 684 (61.8%)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/tamasheq-sentiments-corpus.","url":"https://huggingface.co/datasets/michsethowusu/tamasheq-sentiments-corpus","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Tamil","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"tamil","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"tamil","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"sangraha","keyword":"tamil","description":"\n\t\n\t\t\n\t\tSangraha\n\t\n\n\n  \n\n\nSangraha is the largest high-quality, cleaned Indic language pretraining data containing 251B tokens summed up over 22 languages, extracted from curated sources, existing multilingual corpora and large scale translations.\nMore information:\n\nFor detailed information on the curation and cleaning process of Sangraha, please checkout our paper on Arxiv;\nCheck out the scraping and cleaning pipelines used to curate Sangraha on GitHub;\n\n\n\t\n\t\n\t\n\t\tGetting Started\n\t\n\nForâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/sangraha.","url":"https://huggingface.co/datasets/ai4bharat/sangraha","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Assamese","Bengali","Gujarati","English"],"keywords_longer_than_N":true},
	{"name":"shrutilipi","keyword":"tamil","description":"amithm3/shrutilipi dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/amithm3/shrutilipi","creator_name":"Amith M","creator_url":"https://huggingface.co/amithm3","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Kannada","Sanskrit","Bengali","Panjabi"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ğŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"indic-parallel-sentences-talks","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Parallel Sentences - Indic Talks\n\t\n\nThis dataset contains parallel sentences (i.e. English sentence + the same sentences in another language) for numerous other languages.\n","url":"https://huggingface.co/datasets/aloobun/indic-parallel-sentences-talks","creator_name":"aloobun","creator_url":"https://huggingface.co/aloobun","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"IndicQuest","keyword":"tamil","description":"\n\t\n\t\t\n\t\tL3Cube-IndicQuest: A Benchmark Question Answering Dataset for Evaluating Knowledge of LLMs in Indic Context (LLM Factual Accuracy Benchmark)\n\t\n\nL3Cube-IndicQuest is a dataset comprising 4,000 question-answer pairs across 20 languages, including English, Assamese, Bengali, Dogri, Gujarati, Hindi, Kannada, Konkani, Maithili, Malayalam, Marathi, Meitei (Manipuri), Nepali, Odia, Punjabi, Sanskrit, Sindhi, Tamil, Telugu, and Urdu. This dataset is designed to assess the knowledgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/l3cube-pune/IndicQuest.","url":"https://huggingface.co/datasets/l3cube-pune/IndicQuest","creator_name":"L3Cube Labs","creator_url":"https://huggingface.co/l3cube-pune","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Assamese","Bengali","Gujarati"],"keywords_longer_than_N":true},
	{"name":"wikipedia-citation-index","keyword":"tamil","description":"Dataset with citation indexes as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions. Research: ArXiv\n","url":"https://huggingface.co/datasets/lewoniewski/wikipedia-citation-index","creator_name":"WÅ‚odzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"PathuPattu-Malaipadukadam","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸï¸ à®®à®²à¯ˆà®ªà®Ÿà¯à®•à®Ÿà®¾à®®à¯ (Malaipadukadam) Dataset\n\t\n\nà®®à®²à¯ˆà®ªà®Ÿà¯à®•à®Ÿà®¾à®®à¯ (Malaipadukadam) is one of the Pathupattu (à®ªà®¤à¯à®¤à¯à®ªà¯à®ªà®¾à®Ÿà¯à®Ÿà¯ / Ten Idylls) in Sangam Literature, composed by the poet Perunkaucikanar (à®ªà¯†à®°à¯à®™à¯à®•à¯Œà®šà®¿à®•à®©à®¾à®°à¯).\nIt contains 583 lines in a single long poem and is notable for its panoramic description of mountain life, nature, landscapes, seasonal changes, customs, and hospitality of the hill people. The poem also vividly portrays flora, fauna, rivers, and human culture of the Kurinjiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/PathuPattu-Malaipadukadam.","url":"https://huggingface.co/datasets/TamilThagaval/PathuPattu-Malaipadukadam","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","Tamil","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"IN22GenBitextMining","keyword":"tamil","description":"\n  IN22GenBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Gen is a n-way parallel general-purpose multi-domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Legal, Government, News, Religious, Non-fiction, Written\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Gen\n\n\n\t\n\nSource datasets:\n\nmteb/IN22-Gen\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22GenBitextMining.","url":"https://huggingface.co/datasets/mteb/IN22GenBitextMining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-annotated","multilingual","mteb/IN22-Gen","Assamese"],"keywords_longer_than_N":true},
	{"name":"NLR-Causal-Reasoning","keyword":"tamil","description":"\n\t\n\t\t\n\t\tSEA Causal Reasoning\n\t\n\nSEA Causal Reasoning evaluates a model's ability to choose the correct cause or effect given a premise. It is sampled from XCOPA for Indonesian, Tamil, Thai, and Vietnamese.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nSEA Causal Reasoning is designed for evaluating chat or instruction-tuned large language models (LLMs). It is part of the SEA-HELM leaderboard from AI Singapore.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nIndonesian (id)\nTamil (ta)\nThai (th)\nVietnamese (vi)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/aisingapore/NLR-Causal-Reasoning.","url":"https://huggingface.co/datasets/aisingapore/NLR-Causal-Reasoning","creator_name":"AI Singapore","creator_url":"https://huggingface.co/aisingapore","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","Indonesian","Tamil","Thai"],"keywords_longer_than_N":true},
	{"name":"koel-benchmark","keyword":"tamil","description":"\n\t\n\t\t\n\t\tKoel Benchmark Suite\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Koel Benchmark Suite is a comprehensive set of evaluation datasets designed to rigorously test the real-world performance of Text-to-Speech (TTS) models for major Indian languages. The suite focuses on challenges unique to the Indian context, such as code-switching, domain-specific terminology, proper nouns, and complex numeric formats.\nThis dataset was created to help developers and researchers build more natural, accurateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NisargBhavsar25/koel-benchmark.","url":"https://huggingface.co/datasets/NisargBhavsar25/koel-benchmark","creator_name":"Nisarg Bhavsar","creator_url":"https://huggingface.co/NisargBhavsar25","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Hindi","Tamil","Telugu","Kannada"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"tamil","description":"\n\t\n\t\t\n\t\tINCLUDE-base (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-base-44.","url":"https://huggingface.co/datasets/CohereLabs/include-base-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoNFCorpus_ta","keyword":"tamil","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoNFCorpus dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoNFCorpus","Tamil"],"keywords_longer_than_N":true},
	{"name":"cvss","keyword":"tamil","description":"CVSS is a massively multilingual-to-English speech-to-speech translation corpus,\ncovering sentence-level parallel speech-to-speech translation pairs from 21\nlanguages into English.","url":"https://huggingface.co/datasets/google/cvss","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["English","Arabic","Catalan","Welsh","German"],"keywords_longer_than_N":true},
	{"name":"Pornhub","keyword":"tamil","description":"\n\t\n\t\t\n\t\tPornhub Dataset\n\t\n\nThe Pornhub Dataset provides a comprehensive collection of data sourced from pornhub.com, encompassing various details from MANYYY videos available on the platform.\nThe file consists of 742.133 lines of videos.\n\n\t\n\t\t\n\t\tData Description\n\t\n\n\nDelimiter: â€½\nFile Format: CSV\nContent:\nURL: The URL of the video.\nCategory: The genre or category of the video.\nUser: The username of the uploader.\nVideo_title: The title of the video.\nViews: The number of views the video hasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nikity/Pornhub.","url":"https://huggingface.co/datasets/Nikity/Pornhub","creator_name":"Nikita","creator_url":"https://huggingface.co/Nikity","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Albanian","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for \"xtreme\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"tatoeba_mt","keyword":"tamil","description":"The Tatoeba Translation Challenge is a multilingual data set of\nmachine translation benchmarks derived from user-contributed\ntranslations collected by [Tatoeba.org](https://tatoeba.org/) and\nprovided as parallel corpus from [OPUS](https://opus.nlpl.eu/). This\ndataset includes test and development data sorted by language pair. It\nincludes test sets for hundreds of language pairs and is continuously\nupdated. Please, check the version number tag to refer to the release\nthat your are using.","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","translation","no-annotation","crowdsourced","translation"],"keywords_longer_than_N":true},
	{"name":"PMIndiaSum","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for \"PMIndiaSum\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nPMIndiaSum is a new multilingual and massively parallel headline summarization corpus focused on languages in India. Our corpus covers four language families, 14 languages, and the largest to date, 196 language pairs. It provides a testing ground for all cross-lingual pairs.\n\n\t\n\t\t\n\t\tSupported tasks\n\t\n\nMonolingual, multilingual and cross-lingual summarization for languages in India.\n\n\t\n\t\t\n\t\tLanguagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PMIndiaData/PMIndiaSum.","url":"https://huggingface.co/datasets/PMIndiaData/PMIndiaSum","creator_name":"PMIndiaData","creator_url":"https://huggingface.co/PMIndiaData","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Assamese","Bengali","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"offenseval_dravidian","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Offenseval Dravidian\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOffensive language identification is classification task in natural language processing (NLP) where the aim is to moderate and minimise offensive content in social media. It has been an active area of research in both academia and industry for the past two decades. There is an increasing demand for offensive language identification on social media texts which are largely code-mixed. Code-mixing is a prevalentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/offenseval_dravidian.","url":"https://huggingface.co/datasets/community-datasets/offenseval_dravidian","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-generated","crowdsourced","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"common_voice_16_0","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 16.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 16. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_16_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_16_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"xtreme_s","keyword":"tamil","description":"XTREME-S covers four task families: speech recognition, classification, speech-to-text translation and retrieval. Covering 102\nlanguages from 10+ language families, 3 different domains and 4\ntask families, XTREME-S aims to simplify multilingual speech\nrepresentation evaluation, as well as catalyze research in â€œuniversalâ€ speech representation learning.","url":"https://huggingface.co/datasets/google/xtreme_s","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"tamil","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof WrÃ³bel","creator_url":"https://huggingface.co/djstrong","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"tamil","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"tamil","description":"Attribution: Wikipedia.org\n","url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"TyDiP","keyword":"tamil","description":"The TyDiP dataset is a dataset of requests in conversations between wikipedia editors\nthat have been annotated for politeness. The splits available below consists of only\nrequests from the top 25 percentile (polite) and bottom 25 percentile (impolite) of\npoliteness scores. The English train set and English test set that are\nadapted from the Stanford Politeness Corpus, and test data in 9 more languages\n(Hindi, Korean, Spanish, Tamil, French, Vietnamese, Russian, Afrikaans, Hungarian) \nwas annotated by us.","url":"https://huggingface.co/datasets/Genius1237/TyDiP","creator_name":"Genius1237","creator_url":"https://huggingface.co/Genius1237","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","found","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"xcopa","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for \"xcopa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n  XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning\nThe Cross-lingual Choice of Plausible Alternatives dataset is a benchmark to evaluate the ability of machine learning models to transfer commonsense reasoning across\nlanguages. The dataset is the translation and reannotation of the English COPA (Roemmele et al. 2011) and covers 11 languages from 11 families and several areas around\nthe globe. The dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cambridgeltl/xcopa.","url":"https://huggingface.co/datasets/cambridgeltl/xcopa","creator_name":"Language Technology Lab @University of Cambridge","creator_url":"https://huggingface.co/cambridgeltl","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"Wikinews-multilingual","keyword":"tamil","description":"\n\t\n\t\t\n\t\tWikinews - weakly aligned multilingual pararell sentence datasets\n\t\n\nThis dataset contains 15,200 multilingual WikiNews articles in 33 languages.\nOut of 15,200 articles, 9,960 are non-English news and 5240 are English news.  All non-English news are linked to one of 5240 English news. Linked articles show the same event.\nList of non-English languages are: Spanish, French, German, Portuguese, Polish, Italian, Chinese, Russian, Japanese, Dutch, Swedish, Tamil, Serbian, Czech, Catalanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fumika/Wikinews-multilingual.","url":"https://huggingface.co/datasets/Fumika/Wikinews-multilingual","creator_name":"Fumika Isono","creator_url":"https://huggingface.co/Fumika","license_name":"Creative Commons Attribution 2.5","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.5.html","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"mile_dataset","keyword":"tamil","description":"IISc-MILE Tamil ASR Corpus contains transcribed speech corpus for training ASR systems for Tamil language. It contains ~150 hours of read speech data collected from 531 speakers in a noise-free recording environment with high quality USB microphones.","url":"https://huggingface.co/datasets/parambharat/mile_dataset","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","expert-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"tamil_data_na_thozhar_gandhi","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil à®¤à¯‹à®´à®°à¯ à®•à®¾à®¨à¯à®¤à®¿ â€“ à®®à®•à®¾à®¤à¯à®®à®¾à®µà®¿à®©à¯ à®šà¯‹à®šà®²à®¿à®š à®‰à®°à¯ˆà®¯à®¾à®Ÿà®²à¯ Dataset by à®†à®°à¯. à®ªà®Ÿà¯à®Ÿà®¾à®ªà®¿à®°à®¾à®®à®©à¯\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains Tamil à®¤à¯‹à®´à®°à¯ à®•à®¾à®¨à¯à®¤à®¿ â€“ à®®à®•à®¾à®¤à¯à®®à®¾à®µà®¿à®©à¯ à®šà¯‹à®šà®²à®¿à®š à®‰à®°à¯ˆà®¯à®¾à®Ÿà®²à¯ texts by à®†à®°à¯. à®ªà®Ÿà¯à®Ÿà®¾à®ªà®¿à®°à®¾à®®à®©à¯, processed for language model pretraining.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n154 text chunks\nAuthor: à®†à®°à¯. à®ªà®Ÿà¯à®Ÿà®¾à®ªà®¿à®°à®¾à®®à®©à¯\nGenre: à®¤à¯‹à®´à®°à¯ à®•à®¾à®¨à¯à®¤à®¿ â€“ à®®à®•à®¾à®¤à¯à®®à®¾à®µà®¿à®©à¯ à®šà¯‹à®šà®²à®¿à®š à®‰à®°à¯ˆà®¯à®¾à®Ÿà®²à¯\nTotal chunks: 154\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Naveen934/tamil_data_na_thozhar_gandhi.","url":"https://huggingface.co/datasets/Naveen934/tamil_data_na_thozhar_gandhi","creator_name":"J","creator_url":"https://huggingface.co/Naveen934","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"tamil_data_na_thozhar_gandhi","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil à®¤à¯‹à®´à®°à¯ à®•à®¾à®¨à¯à®¤à®¿ â€“ à®®à®•à®¾à®¤à¯à®®à®¾à®µà®¿à®©à¯ à®šà¯‹à®šà®²à®¿à®š à®‰à®°à¯ˆà®¯à®¾à®Ÿà®²à¯ Dataset by à®†à®°à¯. à®ªà®Ÿà¯à®Ÿà®¾à®ªà®¿à®°à®¾à®®à®©à¯\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains Tamil à®¤à¯‹à®´à®°à¯ à®•à®¾à®¨à¯à®¤à®¿ â€“ à®®à®•à®¾à®¤à¯à®®à®¾à®µà®¿à®©à¯ à®šà¯‹à®šà®²à®¿à®š à®‰à®°à¯ˆà®¯à®¾à®Ÿà®²à¯ texts by à®†à®°à¯. à®ªà®Ÿà¯à®Ÿà®¾à®ªà®¿à®°à®¾à®®à®©à¯, processed for language model pretraining.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n154 text chunks\nAuthor: à®†à®°à¯. à®ªà®Ÿà¯à®Ÿà®¾à®ªà®¿à®°à®¾à®®à®©à¯\nGenre: à®¤à¯‹à®´à®°à¯ à®•à®¾à®¨à¯à®¤à®¿ â€“ à®®à®•à®¾à®¤à¯à®®à®¾à®µà®¿à®©à¯ à®šà¯‹à®šà®²à®¿à®š à®‰à®°à¯ˆà®¯à®¾à®Ÿà®²à¯\nTotal chunks: 154\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Naveen934/tamil_data_na_thozhar_gandhi.","url":"https://huggingface.co/datasets/Naveen934/tamil_data_na_thozhar_gandhi","creator_name":"J","creator_url":"https://huggingface.co/Naveen934","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"mc4-sampling","keyword":"tamil","description":"A sampling-enabled version of mC4, the colossal, cleaned version of Common Crawl's web crawl corpus.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is a version of the processed version of Google's mC4 dataset by AllenAI, in which sampling methods are implemented to perform on the fly.","url":"https://huggingface.co/datasets/bertin-project/mc4-sampling","creator_name":"BERTIN Project","creator_url":"https://huggingface.co/bertin-project","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"tamil","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"IE_SemParse","keyword":"tamil","description":"    IE-SemParse is an Inter-bilingual Seq2seq Semantic parsing dataset for 11 distinct Indian languages","url":"https://huggingface.co/datasets/Divyanshu/IE_SemParse","creator_name":"Divyanshu Aggarwal","creator_url":"https://huggingface.co/Divyanshu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["parsing","machine-generated","machine-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"tamil","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"simple_tamil","keyword":"tamil","description":"The data contains roughly one and half hours of audio and transcripts in Tamil language.","url":"https://huggingface.co/datasets/Achitha/simple_tamil","creator_name":"M","creator_url":"https://huggingface.co/Achitha","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Tamil","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"tatoeba-mt-all-in-one","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for The Tatoeba Translation Challenge | All In One\n\t\n\n~7.3M entries.\nJust more user-friendly version that combines all of the entries of original dataset in a single file:\nhttps://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt\n","url":"https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-all-in-one","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["Helsinki-NLP","crowdsourced","translation","Helsinki-NLP/tatoeba_mt","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3all","keyword":"tamil","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"crawl-vikatan-my","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTLDR\n\t\n\n\nwebsite: Vikatan-MY\nnum. of webpages scraped: 65 (7 locked behind paywall)\nlink to dataset: https://huggingface.co/datasets/wanadzhar913/crawl-vikatan-my/resolve/main/vikatan-my-scraped-data.jsonl\ndate of scraping: 21st October 2023\npull request: mesolitica/malaysian-dataset#353\ncontributed to: https://github.com/mesolitica/malaysian-dataset\n\n","url":"https://huggingface.co/datasets/wanadzhar913/crawl-vikatan-my","creator_name":"Faiq Adzlan","creator_url":"https://huggingface.co/wanadzhar913","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Tamil","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"tokenizer-wiki-bench","keyword":"tamil","description":"\n\t\n\t\t\n\t\tMultilingual Tokenizer Benchmark\n\t\n\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \nfrom transformers import AutoTokenizerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench.","url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"tamil-orca","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil Orca-Style Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository hosts the Tamil Orca-style dataset, meticulously curated to enhance the reasoning capabilities of large language models in Tamil. The dataset is a fusion of translations and responses generated by GPT-4 and Gemini models.\n\nContent: The dataset contains three columns - 'Instruction', 'Query', and 'Answer'. \nPurpose: It's designed to significantly improve the reasoning capability of AI language models in Tamil. \nUsage: Ifâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/azharmo/tamil-orca.","url":"https://huggingface.co/datasets/azharmo/tamil-orca","creator_name":"Mohamed Azharudeen M","creator_url":"https://huggingface.co/azharmo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"tamil-orca","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil Orca-Style Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository hosts the Tamil Orca-style dataset, meticulously curated to enhance the reasoning capabilities of large language models in Tamil. The dataset is a fusion of translations and responses generated by GPT-4 and Gemini models.\n\nContent: The dataset contains three columns - 'Instruction', 'Query', and 'Answer'. \nPurpose: It's designed to significantly improve the reasoning capability of AI language models in Tamil. \nUsage: Ifâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/azharmo/tamil-orca.","url":"https://huggingface.co/datasets/azharmo/tamil-orca","creator_name":"Mohamed Azharudeen M","creator_url":"https://huggingface.co/azharmo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"tamil-orca-transliterated","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil Orca-Style Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository hosts the Tamil Orca-style transliterated dataset, meticulously curated to enhance the reasoning capabilities of large language models in Tamil. The dataset is a transliterated version tamil-orca fusion of translations and responses generated by GPT-4 and Gemini models.\n\nContent: The dataset contains three columns - 'Instruction', 'Query', and 'Answer'. \nPurpose: It's designed to significantly improve the reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/azharmo/tamil-orca-transliterated.","url":"https://huggingface.co/datasets/azharmo/tamil-orca-transliterated","creator_name":"Mohamed Azharudeen M","creator_url":"https://huggingface.co/azharmo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"tamil-orca-transliterated","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil Orca-Style Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository hosts the Tamil Orca-style transliterated dataset, meticulously curated to enhance the reasoning capabilities of large language models in Tamil. The dataset is a transliterated version tamil-orca fusion of translations and responses generated by GPT-4 and Gemini models.\n\nContent: The dataset contains three columns - 'Instruction', 'Query', and 'Answer'. \nPurpose: It's designed to significantly improve the reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/azharmo/tamil-orca-transliterated.","url":"https://huggingface.co/datasets/azharmo/tamil-orca-transliterated","creator_name":"Mohamed Azharudeen M","creator_url":"https://huggingface.co/azharmo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"tamil_asr_corpus","keyword":"tamil","description":"The corpus contains roughly 1000 hours of audio and trasncripts in Tamil language. The transcripts have beedn de-duplicated using exact match deduplication.","url":"https://huggingface.co/datasets/parambharat/tamil_asr_corpus","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"Deepthink-Reasoning-Tamil","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDeepthink-Reasoning-Tamil Dataset\n\t\n\nThe Deepthink-Reasoning-Tamil dataset is a multilingual dataset that includes both Tamil and Tanglish. It is designed with a dynamic instruction set, making it adaptable for various reasoning-based problem-solving tasks.  \n\n\t\n\t\t\n\t\tKey Features:\n\t\n\n\nMultilingual Support: Includes Tamil and Tanglish for broader accessibility.  \nDynamic Instructions: Designed to adapt to various problem-solving tasks.  \nAdvanced Translation Pipeline: The dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Deepthink-Reasoning-Tamil.","url":"https://huggingface.co/datasets/prithivMLmods/Deepthink-Reasoning-Tamil","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","translation","Tamil","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"dhpileIN","keyword":"tamil","description":"@misc{aralikatte2023varta,\n      title={V\\=arta: A Large-Scale Headline-Generation Dataset for Indic Languages}, \n      author={Rahul Aralikatte and Ziling Cheng and Sumanth Doddapaneni and Jackie Chi Kit Cheung},\n      year={2023},\n      eprint={2305.05858},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n","url":"https://huggingface.co/datasets/aloobun/dhpileIN","creator_name":"aloobun","creator_url":"https://huggingface.co/aloobun","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Bengali","Gujarati","Hindi","Kannada","Tamil"],"keywords_longer_than_N":true},
	{"name":"english-to-colloquial-tamil","keyword":"tamil","description":"\n\t\n\t\t\n\t\tEnglish to Colloquial Tamil\n\t\n\n\"instruction\":\"Translate provided English text into colloquial Tamil.\"\n\"input\": \"Their players played well.\"\n\"output\": \"à®…à®µà®™à¯à®• players à®¨à®²à¯à®²à®¾ à®µà®¿à®³à¯ˆà®¯à®¾à®£à¯à®Ÿà®¾à®™à¯à®•.\"\n\n","url":"https://huggingface.co/datasets/jarvisvasu/english-to-colloquial-tamil","creator_name":"Vasanth Kumar","creator_url":"https://huggingface.co/jarvisvasu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","text2text-generation","Tamil","English"],"keywords_longer_than_N":true},
	{"name":"english-to-colloquial-tamil","keyword":"tamil","description":"\n\t\n\t\t\n\t\tEnglish to Colloquial Tamil\n\t\n\n\"instruction\":\"Translate provided English text into colloquial Tamil.\"\n\"input\": \"Their players played well.\"\n\"output\": \"à®…à®µà®™à¯à®• players à®¨à®²à¯à®²à®¾ à®µà®¿à®³à¯ˆà®¯à®¾à®£à¯à®Ÿà®¾à®™à¯à®•.\"\n\n","url":"https://huggingface.co/datasets/jarvisvasu/english-to-colloquial-tamil","creator_name":"Vasanth Kumar","creator_url":"https://huggingface.co/jarvisvasu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","text2text-generation","Tamil","English"],"keywords_longer_than_N":true},
	{"name":"debug_divas45","keyword":"tamil","description":"\n\t\n\t\t\n\t\tColloquial Tamil Translation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset consists of English sentences and their colloquial Tamil translations. It is designed to train and evaluate machine learning models for English-to-Tamil translation in an informal, conversational tone.\nThe dataset is structured to help in fine-tuning language models for translation tasks that require a natural and spoken Tamil output, rather than formal literary translations.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anitha2520/debug_divas45.","url":"https://huggingface.co/datasets/anitha2520/debug_divas45","creator_name":"Anitha Srinithi","creator_url":"https://huggingface.co/anitha2520","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Tamil","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"colloquial_tamil","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸ“œ Colloquial Tamil Dataset for Machine Translation\n\t\n\nThis dataset is designed to help AI models translate English text into colloquial Tamil. Unlike standard Tamil, colloquial Tamil includes slang, informal phrases, and regional expressions commonly used in everyday conversations.  \n\n\n\t\n\t\t\n\t\tğŸ“‚ Dataset Details\n\t\n\n\nLanguages: English â†’ Colloquial Tamil  \nFormat: JSONL (.jsonl)  \nTotal Entries: 16,269 sentence pairs  \nStructure: Each entry contains:  \n\"instruction\": The taskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/janisrebekahv/colloquial_tamil.","url":"https://huggingface.co/datasets/janisrebekahv/colloquial_tamil","creator_name":"Janis Rebekah V","creator_url":"https://huggingface.co/janisrebekahv","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Tamil","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Indic-Rag-Suite","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸŒ Multilingual Indic RAG Suite\n\t\n\nA comprehensive multilingual question-answering dataset covering 18 Indian languages with 21,439,886 total samples, designed for RAG (Retrieval-Augmented Generation) applications and multilingual NLP research.\n\n\t\n\t\t\n\t\tğŸš€ Quick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load specific language (recommended)\ndataset = load_dataset(\"ai4bharat/Indic-Rag-Suite\", \"as\")\ntrain_data = dataset['train']\n\nprint(f\"Loaded {len(train_data)} samples\")\n\n# Accessâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/Indic-Rag-Suite.","url":"https://huggingface.co/datasets/ai4bharat/Indic-Rag-Suite","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","multilingual","Assamese","Bengali"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"tamil","description":"\n\t\n\t\t\n\t\tSynthdog Multilingual\n\t\n\n\n\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzfâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"Pathinenkeezhkanakku-Naanmanikadikai","keyword":"tamil","description":"ğŸ’ à®¨à®¾à®©à¯à®®à®£à®¿à®•à¯à®•à®Ÿà®¿à®•à¯ˆ (Naanmanikadigai) Dataset\nà®¨à®¾à®©à¯à®®à®£à®¿à®•à¯à®•à®Ÿà®¿à®•à¯ˆ (Naanmanikadigai) is one of the Pathinen Keezhkanakku (Eighteen Minor Works) in Tamil literature.\nIt is a didactic anthology composed during the post-Sangam period (circa 100â€“500 CE).\nThe work consists of 100 poems written in the Venpa metre, offering moral teachings, religious reflections, and philosophical guidance.\nThe title Naanmanikadigai means â€œThe Garland of Four Gemsâ€, symbolizing the fourfold values of Virtue (à®…à®±à®®à¯), Wealthâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/Pathinenkeezhkanakku-Naanmanikadikai.","url":"https://huggingface.co/datasets/TamilThagaval/Pathinenkeezhkanakku-Naanmanikadikai","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","Tamil","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"mmlu-indic","keyword":"tamil","description":"\n\t\n\t\t\n\t\tIndic MMLU Dataset\n\t\n\nA multilingual version of the Massive Multitask Language Understanding (MMLU) benchmark, translated from English into 10 Indian languages.\nThis version contains the translations of the development and test sets only. \n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\nThe dataset includes translations in the following languages:\n\nBengali (bn)\nGujarati (gu)\nHindi (hi)\nKannada (kn)\nMarathi (mr)\nMalayalam (ml)\nOriya (or)\nPunjabi (pa)\nTamil (ta)\nTelugu (te)\n\n\n\t\n\t\t\n\t\tTask Format\n\t\n\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sarvamai/mmlu-indic.","url":"https://huggingface.co/datasets/sarvamai/mmlu-indic","creator_name":"Sarvam AI","creator_url":"https://huggingface.co/sarvamai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Bengali","English","Gujarati","Hindi"],"keywords_longer_than_N":true},
	{"name":"tamil","keyword":"tamil","description":"\n\t\n\t\t\n\t\tMy Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains audio recordings with corresponding text transcriptions. It is designed for speech recognition and natural language processing tasks.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\ndata/audio/: Contains audio files.\nmetadata.csv: Metadata file with transcription and additional information.\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\n[Your License Name] - [License URL]\n\n\t\n\t\t\n\t\tCitation\n\t\n\nPlease cite this dataset as follows:\n","url":"https://huggingface.co/datasets/sp03/tamil","creator_name":"sethu prasad s","creator_url":"https://huggingface.co/sp03","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Tamil","cc0-1.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul RÃ¶ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"CodeMixBench","keyword":"tamil","description":"\n\t\n\t\t\n\t\tâ„¹ï¸Dataset Card for CodeMixBench\n\t\n\n\n\t\n\t\t\n\t\t[EMNLP'25] CodeMixBench: Evaluating Code-Mixing Capabilities of LLMs Across 18 Languages\n\t\n\n   \n      \n   \n        \n  \n      \n   \n  \n      \n   \n\n\n\n\n\nCode-mixing is a linguistic phenomenon where multilingual speakers switch or mix two or more languages within a single utterance or conversation. \nTo evaluate LLMsâ€™ comprehension of multilingual code-mixed texts, we introduce CodeMixBench, a benchmark comprising eight tasks across 18 languages.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CodeMixBench/CodeMixBench.","url":"https://huggingface.co/datasets/CodeMixBench/CodeMixBench","creator_name":"CodeMixBench","creator_url":"https://huggingface.co/CodeMixBench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Chinese","English","Spanish","Hindi","German"],"keywords_longer_than_N":true},
	{"name":"xtreme-up-semantic-parsing","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for afrixnli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSee XTREME-UP GitHub\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 20 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata = load_dataset('Davlan/xtreme-up-semantic-parsing', 'yor') \n# Please, specify the language code\n# A data point example is below:\n{\n\"id\": \"3231323330393336\",\n\"split\": \"test\",\n\"intent\": \"IN:GET_REMINDER\",\n\"locale\": \"en\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing.","url":"https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multilingual","Amharic","Belarusian","Bengali"],"keywords_longer_than_N":true},
	{"name":"IN22-Gen","keyword":"tamil","description":"\n  IN22GenBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nIN22-Gen is a n-way parallel general-purpose multi-domain benchmark dataset for machine translation spanning English and 22 Indic languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Legal, Government, News, Religious, Non-fiction, Written\nReference\nhttps://huggingface.co/datasets/ai4bharat/IN22-Gen\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IN22-Gen.","url":"https://huggingface.co/datasets/mteb/IN22-Gen","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","multilingual","Assamese"],"keywords_longer_than_N":true},
	{"name":"IndicTTS_Tamil","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamil Indic TTS Dataset\n\t\n\nThis dataset is derived from the Indic TTS Database project, specifically using the Tamil monolingual recordings from both male and female speakers. The dataset contains high-quality speech recordings with corresponding text transcriptions, making it suitable for text-to-speech (TTS) research and development.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nLanguage: Tamil\nTotal Duration: ~20.33 hours (Male: 10.3 hours, Female: 10.03 hours)\nAudio Format: WAV\nSampling Rate:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SPRINGLab/IndicTTS_Tamil.","url":"https://huggingface.co/datasets/SPRINGLab/IndicTTS_Tamil","creator_name":"SPRINGLab","creator_url":"https://huggingface.co/SPRINGLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Tamil","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"tamil","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"TamilNewsClassification","keyword":"tamil","description":"\n  TamilNewsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA Tamil dataset for 6-class classification of Tamil news articles\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://github.com/vanangamudi/tamil-news-classification\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"TamilNewsClassification\")\nevaluator = mteb.MTEB([task])\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TamilNewsClassification.","url":"https://huggingface.co/datasets/mteb/TamilNewsClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","mlexplorer008/tamil_news_classification"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"tamil","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy Itâ€™s Important\n\t\n\n\nEnhances Trust: For readers andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"WÅ‚odzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"IndicXnliPairClassification","keyword":"tamil","description":"\n  IndicXnliPairClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nINDICXNLI is similar to existing XNLI dataset in shape/form, but\n        focusses on Indic language family.\n        The train (392,702), validation (2,490), and evaluation sets (5,010) of English\n        XNLI were translated from English into each of the eleven Indic languages. IndicTrans\n        is a large Transformer-based sequence to sequence model. It is trained on Samanantar\n        dataset (Ramesh etâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/IndicXnliPairClassification.","url":"https://huggingface.co/datasets/mteb/IndicXnliPairClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","derived","translated","Divyanshu/indicxnli"],"keywords_longer_than_N":true},
	{"name":"Patthupattu-MullaiPattu","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸŒ¿ à®®à¯à®²à¯à®²à¯ˆà®ªà¯à®ªà®¾à®Ÿà¯à®Ÿà¯ (Mullaipattu) Dataset\n\t\n\n\n\t\n\t\t\n\t\tğŸ“ Dataset Description\n\t\n\nà®®à¯à®²à¯à®²à¯ˆà®ªà¯à®ªà®¾à®Ÿà¯à®Ÿà¯ (Mullaipattu) is one of the Pathupattu (Ten Idylls) in Sangam Literature.It consists of a single long poem of 103 lines, traditionally attributed to poet Napputhanar.  \nThis dataset provides a structured digital representation of Mullaipattu, segmented into topics, poems, and explanations.It bridges ancient Tamil literature with modern Natural Language Processing (NLP) applications.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/Patthupattu-MullaiPattu.","url":"https://huggingface.co/datasets/TamilThagaval/Patthupattu-MullaiPattu","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","Tamil","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"fineweb-2","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸ¥‚ FineWeb2\n\t\n\n\n    \n\n\n\nA sparkling update with 1000s of languages\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis is the second iteration of the popular ğŸ· FineWeb dataset, bringing high quality pretraining data to over 1000 ğŸ—£ï¸ languages.\nThe ğŸ¥‚ FineWeb2 dataset is fully reproducible, available under the permissive ODC-By 1.0 license and extensively validated through hundreds of ablation experiments.\nIn particular, on the set of 9 diverse languages we used to guide our processing decisions, ğŸ¥‚ FineWeb2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/fineweb-2.","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb-2","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"panlex-definitions","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-definitions\n\t\n\nThis is a dataset of word definitions in several hudnred languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20250201 database dump) and rearranged on the per-language basis (by the language of the definition).\nEach language subset consists of definitions (short phrases).\nEach definition is associated with some meanings (if there isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-definitions.","url":"https://huggingface.co/datasets/cointegrated/panlex-definitions","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Abkhazian","Hijazi Arabic","Afrikaans","Ainu (Japan)"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"tamil","description":"Due to storage limits some files had to be split into multiple parts. They can be merged like this: cat file.* > file.\n","url":"https://huggingface.co/datasets/2Jyq/common_voice_21_0","creator_name":"2Jyq","creator_url":"https://huggingface.co/2Jyq","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","multilingual","extended|common_voice","Abkhaz"],"keywords_longer_than_N":true},
	{"name":"PatJr","keyword":"tamil","description":"Ultronprime/PatJr dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Ultronprime/PatJr","creator_name":"Worg tempy","creator_url":"https://huggingface.co/Ultronprime","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Tamil","apache-2.0","100K - 1M","text","Text"],"keywords_longer_than_N":true},
	{"name":"Thamizhmalai","keyword":"tamil","description":"\n\t\n\t\t\n\t\tTamizhmalai\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTamizhmalai is a cleaned Tamil corpus collected from public sources. The dataset offers two granularities:\n\nSentences â€“ short, self-contained lines suitable for LM training and evaluation  \nPhrases â€“ extracted noun/verb phrases useful for retrieval, tagging, and terminology work\n\nThe corpus aims to be script-correct, high-signal, and model-friendly, preserving natural Tamil usage and style while removing web-scrape detritus.\n\nA small subset ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tamiltheorist/Thamizhmalai.","url":"https://huggingface.co/datasets/tamiltheorist/Thamizhmalai","creator_name":"Tamil Arasan","creator_url":"https://huggingface.co/tamiltheorist","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Tamil","apache-2.0","10M - 100M","text","Text"],"keywords_longer_than_N":true},
	{"name":"GlobalDISCO","keyword":"tamil","description":"\n\t\n\t\t\n\t\tGlobalDISCO\n\t\n\nGlobalDISCO is a large-scale dataset consisting of 73k music tracks generated by state-of-the-art commercial generative music models, along with paired links to 93k reference tracks in LAION-DISCO-12M. The dataset spans 147 languages and includes musical style prompts extracted from MusicBrainz and Wikipedia. The dataset is globally balanced, representing musical styles from artists across 79 countries and five continents. It is aimed to support the research community inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/disco-eth/GlobalDISCO.","url":"https://huggingface.co/datasets/disco-eth/GlobalDISCO","creator_name":"DISCO","creator_url":"https://huggingface.co/disco-eth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","Spanish","French","German"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoClimateFEVER_ta","keyword":"tamil","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoClimateFEVER dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoClimateFEVER","Tamil"],"keywords_longer_than_N":true},
	{"name":"wildchat-filtered","keyword":"tamil","description":"\n\t\n\t\t\n\t\tWildChat Filtered Dataset\n\t\n\nThis is a filtered version of the WildChat-4.8M dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3,199,860 conversations between human users and ChatGPT, filtered to keep only the essential conversation structure.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach conversation contains only:\n\nconversations: A list of message objects with:\nrole: Either \"user\" or \"assistant\"\ncontent: The text content of the message\n\n\n\nAll other metadata (timestamps, moderationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rayonlabs/wildchat-filtered.","url":"https://huggingface.co/datasets/rayonlabs/wildchat-filtered","creator_name":"Rayon Labs","creator_url":"https://huggingface.co/rayonlabs","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"tatoeba-bitext-mining","keyword":"tamil","description":"\n  Tatoeba\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n1,000 English-aligned sentence pairs for each language based on the Tatoeba corpus\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/facebookresearch/LASER/tree/main/data/tatoeba/v1\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"Tatoeba\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/tatoeba-bitext-mining.","url":"https://huggingface.co/datasets/mteb/tatoeba-bitext-mining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"tulu3-100samples","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nThis dataset contains 100 samples from the Tulu 3 SFT Mixture.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example in the dataset contains the standard instruction-tuning data points as follow:\n\nid (str): a unique identifier\nmessages (list): message format used for supervised fine-tuning (this contains user prompt and assistant responses)\nsource (str): the source dataset for the given sample\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under ODC-BY-1.0. It is intended for research andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anayak/tulu3-100samples.","url":"https://huggingface.co/datasets/anayak/tulu3-100samples","creator_name":"Akash Nayak","creator_url":"https://huggingface.co/anayak","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"MultiMWP","keyword":"tamil","description":"\n\t\n\t\t\n\t\tMultiMWP: A Multi-Way Parallel Dataset for Math Word Problem Generation\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nMultiMWP is a multi-way parallel dataset designed for math word problem (MWP) generation across 9 languages.\nThe dataset consists of structured math word problems in plain text format.\nIt is intended for problem generation rather than problem-solving. The same dataset is in Github: https://github.com/OmegaGamage/multiMWP/tree/master/dataset\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nMultiMWP includesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/MultiMWP.","url":"https://huggingface.co/datasets/NLPC-UOM/MultiMWP","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Albanian","Assamese","English","Chinese","Hindi"],"keywords_longer_than_N":true},
	{"name":"Pathinen_keezhkanakku-Mudhumozhikanchi","keyword":"tamil","description":"ğŸ’ à®®à¯à®¤à¯à®®à¯Šà®´à®¿à®•à¯à®•à®¾à®à¯à®šà®¿ (Mudhumozhi Kanchi) Dataset\nà®®à¯à®¤à¯à®®à¯Šà®´à®¿à®•à¯à®•à®¾à®à¯à®šà®¿ (Mudhumozhi Kanchi) is one of the Pathinen Keezhkanakku (Eighteen Minor Works) in Tamil literature.It was composed by à®®à®¤à¯à®°à¯ˆà®•à¯ à®•à¯‚à®Ÿà®²à¯‚à®°à¯ à®•à®¿à®´à®¾à®°à¯.  \nThe text consists of 10 athikarams (chapters), each containing 10 kurattazhis (verses).The work primarily discusses Aram (virtue), Porul (wealth), and Inbam (love/pleasure), providing ethical guidance and moral reflections.\nThis dataset provides a structured digital version of Mudhumozhiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/Pathinen_keezhkanakku-Mudhumozhikanchi.","url":"https://huggingface.co/datasets/TamilThagaval/Pathinen_keezhkanakku-Mudhumozhikanchi","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","text-classification","Tamil","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Intermediate-Thinking-130k","keyword":"tamil","description":"\n\t\n\t\t\n\t\tIntermediate-Thinking-130k\n\t\n\nA comprehensive dataset of 135,000 high-quality samples designed to advance language model reasoning capabilities through structured intermediate thinking processes. This dataset enables training and evaluation of models with sophisticated self-correction and iterative reasoning abilities across 42 languages.\nOG Link\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIntermediate-Thinking-130k addresses a fundamental limitation in current language models: their inability to pauseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k.","url":"https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bengali","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"tamil","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"Ø§Ù…Ø§Ù… Ø¬Ù…Ø¹Ù‡ Ø§ØµÙÙ‡Ø§Ù† Ú¯ÙØª: Ù…ÛŒØ²Ø§Ù† Ù†ÛŒØ§Ø² Ø¢Ø¨ Ø´Ø±Ø¨ Ø§ØµÙÙ‡Ø§Ù† Û±Û±.Ûµ Ù…ØªØ± Ù…Ú©Ø¹Ø¨ Ø§Ø³Øª Ú©Ù‡ ØªÙ…Ø§Ù… Ø§Ø³ØªØ§Ù† Ø§ØµÙÙ‡Ø§Ù† Ø±Ø§ Ù¾ÙˆØ´Ø´ Ù…ÛŒØ¯Ù‡Ø¯ Ùˆ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ù†Ù‚Ù„Ø§Ø¨ ÛŒÚ©ÛŒ Ø§Ø² Ù¾ÛŒØ´Ø±ÙØªÙ‡Ø§ Ø¯Ø± Ø­ÙˆØ²Ù‡ Ø¢Ø¨ Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600","keyword":"tamil","description":"Dataset for sarvam's entity normalisation task. More detailed information can be found here, in the main model repo: Hugging Face\nDetailed Report (Writeup): Google Drive\nIt also has a gguf variant, with certain additional gguf based innstructions: Hugging Face\nModel inference script can be found here: Colab\nModel predictions can be found in this dataset and both the repo files. named as: \n\neval_data_001_predictions.csv and eval_data_001_predictions_excel.csv.\ntrain_data_001_predictions.csvandâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tasmay-Tib/sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600.","url":"https://huggingface.co/datasets/Tasmay-Tib/sarvam-entity-recognition-gemini-2.0-flash-thinking-01-21-distill-1600","creator_name":"Tasmay Pankaj Tibrewal","creator_url":"https://huggingface.co/Tasmay-Tib","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Hindi","Tamil","Telugu","Marathi","Bengali"],"keywords_longer_than_N":true},
	{"name":"indic_sentiment_analyzer","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n\t\n\t\t\n\t\tMultilingual Sentiment Analysis Dataset for Indian Languages\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository contains a comprehensive sentiment analysis dataset covering 11 Indian languages and English. The dataset is designed to support sentiment analysis tasks across multiple domains and languages, making it valuable for developing multilingual sentiment analysis models and applications.\n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\n\nEnglish (en) - Original\nHindi (hi)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/dhruv0808/indic_sentiment_analyzer.","url":"https://huggingface.co/datasets/dhruv0808/indic_sentiment_analyzer","creator_name":"Dhruv Bhatnagar","creator_url":"https://huggingface.co/dhruv0808","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Hindi","Telugu","Tamil","Kannada"],"keywords_longer_than_N":true},
	{"name":"tamil-colloquial-dataset","keyword":"tamil","description":"aishu1505/tamil-colloquial-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/aishu1505/tamil-colloquial-dataset","creator_name":"P.S.AISHWARYA LAKSHMI","creator_url":"https://huggingface.co/aishu1505","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","Tamil","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"tamil-colloquial-dataset","keyword":"tamil","description":"aishu1505/tamil-colloquial-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/aishu1505/tamil-colloquial-dataset","creator_name":"P.S.AISHWARYA LAKSHMI","creator_url":"https://huggingface.co/aishu1505","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","Tamil","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"tamil","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"GlobalNLI","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for global_nli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal NLI is a new text-based benchmark based on the aggregation of existing NLI datasets that are publicly available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 59 languages available :\n{\n    'amh': 'Amharic',\n    'ara': 'Arabic',\n    'asm': 'Assamese',\n    'aym': 'Aymara',\n    'ben': 'Bengali',\n    'bul': 'Bulgarian',\n    'bzd': 'Bribri',\n    'cat': 'Catalan',\n    'cni': 'AshÃ¡ninka',\n    'deu': 'German',\n    'ell': 'Greek',\n    'eng':â€¦ See the full description on the dataset page: https://huggingface.co/datasets/McGill-NLP/GlobalNLI.","url":"https://huggingface.co/datasets/McGill-NLP/GlobalNLI","creator_name":"McGill NLP Group","creator_url":"https://huggingface.co/McGill-NLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multilingual","XNLI, AfriXNLI, IndicXNLI, AmericasNLI [30], XNLI-ca, myXNLI, IndoNLI, JNLI , InferBR, sick_pl, JamPatoisNLI, KLUE, RoNLI.","Amharic"],"keywords_longer_than_N":true},
	{"name":"teluguVoice","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/edwixx/teluguVoice.","url":"https://huggingface.co/datasets/edwixx/teluguVoice","creator_name":"Anurag","creator_url":"https://huggingface.co/edwixx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Tamil","mit","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"tawiki","keyword":"tamil","description":"Hereâ€™s a detailed README.md (Model Card / Dataset Card) for your Tamil Wikipedia dataset on Hugging Face, formatted in Markdown:\n\n\n\t\n\t\t\n\t\tğŸ§  Tamil Wikipedia Dataset (tawiki)\n\t\n\n\nThe Tamil Wikipedia (tawiki) dataset is a cleaned and preprocessed dump of the Tamil language Wikipedia, curated for use in Natural Language Processing (NLP) tasks such as language modeling, summarization, machine translation, and question answering.\n\n\n\t\n\t\t\n\t\n\t\n\t\tğŸ“š Dataset Overview\n\t\n\n\nLanguage: Tamil (ta)\nSource:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Hemanth-thunder/tawiki.","url":"https://huggingface.co/datasets/Hemanth-thunder/tawiki","creator_name":"Hemanth-thunder","creator_url":"https://huggingface.co/Hemanth-thunder","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","Tamil","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"common-voice-tamil-english-labeled-Data","keyword":"tamil","description":"Lingalingeswaran/common-voice-tamil-english-labeled-Data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Lingalingeswaran/common-voice-tamil-english-labeled-Data","creator_name":"Sathiyalokeswaran","creator_url":"https://huggingface.co/Lingalingeswaran","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Tamil","English","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Pathupattu-Kurijipattu","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸï¸ à®•à¯à®±à®¿à®à¯à®šà®¿à®ªà¯à®ªà®¾à®Ÿà¯à®Ÿà¯ (KurinjippÄá¹­á¹­u) Dataset\n\t\n\nà®•à¯à®±à®¿à®à¯à®šà®¿à®ªà¯à®ªà®¾à®Ÿà¯à®Ÿà¯ (KurinjippÄá¹­á¹­u) is one of the Pathupattu (à®ªà®¤à¯à®¤à¯à®ªà¯à®ªà®¾à®Ÿà¯à®Ÿà¯ / Ten Idylls) in Sangam Literature.\nIt is a long akam poem of 261 lines, traditionally attributed to Kapilar (à®•à®ªà®¿à®²à®°à¯), one of the greatest Sangam poets.\nThe poem primarily deals with the kurinji landscape (mountainous regions) and themes of love (akam), especially the secret union of lovers, aided by the confidante (à®¤à¯‹à®´à®¿).\nThis dataset provides a structuredâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/Pathupattu-Kurijipattu.","url":"https://huggingface.co/datasets/TamilThagaval/Pathupattu-Kurijipattu","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","Tamil","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Phonemized-UD","keyword":"tamil","description":"\n\t\n\t\t\n\t\tPhoneme-UD: A Multilingual Phonemized Universal Dependencies Corpus for 34+ Languages\n\t\n\n\n\t\n\t\t\n\t\tG2P+ Phonemizer\n\t\n\nWe use G2P+ to phonemize Universal Dependencies. Here is an example usage: \n# Install required packages\n!apt-get install -y espeak-ng\n!pip install phonemizer g2p-plus\n# Set the environment variable from Python\nimport os\nos.environ[\"PHONEMIZER_ESPEAK_LIBRARY\"] = \"/usr/lib/x86_64-linux-gnu/libespeak-ng.so.1\"\n\n# Now run your transcription\nfrom g2p_plus importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/suchirsalhan/Phonemized-UD.","url":"https://huggingface.co/datasets/suchirsalhan/Phonemized-UD","creator_name":"Suchir Salhan","creator_url":"https://huggingface.co/suchirsalhan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Azerbaijani","Catalan"],"keywords_longer_than_N":true},
	{"name":"project-madurai-books","keyword":"tamil","description":"Project Madurai Books Text Dataset\n\nThis dataset card aims to convert the Tamil books available on the Project Madurai  website to the HF dataset. It has been scrapped from Project Madurai Website.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nYou can see a table above called \"Meta Data\", which is just an info table.\nYou can't able to preview the \"Source Data\" table, due to it being about 300MB.\n[Don't open the Dataset in Excel It will lead to a crash of the OS instead open it using Python in pandas orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mastergokul/project-madurai-books.","url":"https://huggingface.co/datasets/mastergokul/project-madurai-books","creator_name":"Gokul S","creator_url":"https://huggingface.co/mastergokul","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","sentence-similarity","token-classification","Tamil"],"keywords_longer_than_N":true},
	{"name":"Pathinen_keezhkanakku-Iniyavainarpadhu","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸŒ¸ à®‡à®©à®¿à®¯à®µà¯ˆà®¨à®¾à®±à¯à®ªà®¤à¯ (Iniyavai Narpadu) Dataset\n\t\n\nà®‡à®©à®¿à®¯à®µà¯ˆà®¨à®¾à®±à¯à®ªà®¤à¯ (Iniyavai Narpadu) is one of the Pathinen Keezhkanakku (Eighteen Minor Works) in classical Tamil literature, composed by the poet à®ªà¯‚à®¤à®à¯à®šà¯‡à®¨à¯à®¤à®©à®¾à®°à¯ (Poothanchenthanar).\nIt consists of 40 Venpa poems, each describing the essence of what is considered â€œIniyavaiâ€ (Sweet/Desirable things in life).\nIn four poems, the poet describes four desirable things.\nIn the remaining poems, he lists three desirable things each.\nThe work focusesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/Pathinen_keezhkanakku-Iniyavainarpadhu.","url":"https://huggingface.co/datasets/TamilThagaval/Pathinen_keezhkanakku-Iniyavainarpadhu","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","text-classification","Tamil","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"GlobalNLI","keyword":"tamil","description":"\n\t\n\t\t\n\t\tDataset Card for global_nli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal NLI is a new text-based benchmark based on the aggregation of existing NLI datasets that are publicly available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 59 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata = load_dataset('vivekvermaiit/globalnli', 'eng') \n# Please, specify the language code\n# A data point example is below:\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/vivekvermaiit/GlobalNLI.","url":"https://huggingface.co/datasets/vivekvermaiit/GlobalNLI","creator_name":"Vivek Verma","creator_url":"https://huggingface.co/vivekvermaiit","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multilingual","XNLI, AfriXNLI, IndicXNLI, AmericasNLI [30], XNLI-ca, myXNLI, IndoNLI, JNLI , InferBR, sick_pl, JamPatoisNLI, KLUE, RoNLI.","Amharic"],"keywords_longer_than_N":true},
	{"name":"En-Tamil","keyword":"tamil","description":"Namratap/En-Tamil dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Namratap/En-Tamil","creator_name":"Namrata Patil Gurav","creator_url":"https://huggingface.co/Namratap","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Tamil","afl-3.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"indic-align","keyword":"tamil","description":"\n\t\n\t\t\n\t\tIndicAlign\n\t\n\nA diverse collection of Instruction and Toxic alignment datasets for 14 Indic Languages. The collection comprises of:\n\nIndicAlign - Instruct\nIndic-ShareLlama\nDolly-T\nOpenAssistant-T\nWikiHow\nIndoWordNet\nAnudesh\nWiki-Conv\nWiki-Chat\n\n\nIndicAlign - Toxic\nHHRLHF-T\nToxic-Matrix\n\n\n\nWe use IndicTrans2 (Gala et al., 2023) for the translation of the datasets. \nWe recommend the readers to check out our paper on Arxiv for detailed information on the curation process of theseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/indic-align.","url":"https://huggingface.co/datasets/ai4bharat/indic-align","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Assamese","Bengali","Gujarati","English"],"keywords_longer_than_N":true},
	{"name":"PatthuPattu-Nedunalvaadai","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸ“ Dataset Card: Nedunalvaadai\n\t\n\nThis dataset contains the classical Sangam Tamil literature work Nedunalvaadai, covering all 5 parts.\nEach entry includes:\nTopic (section heading)\nPoem lines (original verses)\nExplanation (detailed meaning in Tamil)\nIt is useful for Tamil NLP, literary analysis, translation tasks, and language modeling.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nğŸ“– Language Modeling\nğŸ” Poem â†’ Explanation Mapping\nğŸ—£ Text Generation (Tamil)\nğŸ”¤ Text Cleaning & Preprocessingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TamilThagaval/PatthuPattu-Nedunalvaadai.","url":"https://huggingface.co/datasets/TamilThagaval/PatthuPattu-Nedunalvaadai","creator_name":"à®¤à®®à®¿à®´à¯ à®¤à®•à®µà®²à¯","creator_url":"https://huggingface.co/TamilThagaval","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","summarization","Tamil","mit"],"keywords_longer_than_N":true},
	{"name":"marvl","keyword":"tamil","description":"\n\t\n\t\t\n\t\tMaRVL\n\t\n\n\n\t\n\t\t\n\t\tThis is a copy from the original repo: https://github.com/marvl-challenge/marvl-code\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{liu-etal-2021-visually,\n    title = \"Visually Grounded Reasoning across Languages and Cultures\",\n    author = \"Liu, Fangyu  and\n      Bugliarello, Emanuele  and\n      Ponti, Edoardo Maria  and\n      Reddy, Siva  and\n      Collier, Nigel  and\n      Elliott, Desmond\",\n    booktitle = \"Proceedings of the 2021â€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/marvl.","url":"https://huggingface.co/datasets/floschne/marvl","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","Indonesian","Swahili","Tamil","Turkish"],"keywords_longer_than_N":true},
	{"name":"Thenayareport.ai","keyword":"tamil","description":"sreyasreevenkataraman/Thenayareport.ai dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sreyasreevenkataraman/Thenayareport.ai","creator_name":"sreya sree","creator_url":"https://huggingface.co/sreyasreevenkataraman","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","English","Hindi"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-marvl","keyword":"tamil","description":"\n\t\n\t\t\n\t\tMaRVL\n\t\n\n\n\t\n\t\t\n\t\tThis is a copy from the original repo: https://github.com/marvl-challenge/marvl-code\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{liu-etal-2021-visually,\n    title = \"Visually Grounded Reasoning across Languages and Cultures\",\n    author = \"Liu, Fangyu  and\n      Bugliarello, Emanuele  and\n      Ponti, Edoardo Maria  and\n      Reddy, Siva  and\n      Collier, Nigel  and\n      Elliott, Desmond\",\n    booktitle = \"Proceedings of the 2021â€¦ See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-marvl.","url":"https://huggingface.co/datasets/neulab/PangeaBench-marvl","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","Indonesian","Swahili","Tamil","Turkish"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"tamil","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"Bharat_NanoHotpotQA_ta","keyword":"tamil","description":"\n\t\n\t\t\n\t\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis particular dataset is the Tamil version of the NanoHotpotQA dataset, specifically adapted forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ta.","url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","monolingual","NanoHotpotQA","Tamil"],"keywords_longer_than_N":true},
	{"name":"quran_multilingual_parallel","keyword":"tamil","description":"\n\t\n\t\t\n\t\tğŸ“˜ Qurâ€™an Multilingual Parallel Dataset (quran_multilingual_parallel)\n\t\n\nThis dataset presents a clean, structurally-aligned multilingual parallel corpus of the Qurâ€™anic text. It is intended for linguistic, computational, and cross-lingual AI applications â€” not only for religious interpretation.\nIt contains over 6,200 verse-level alignments in 54 human languages, formatted in a machine-friendly .csv structure with language-specific translation fields.\n\n\n\t\n\t\t\n\t\n\t\n\t\tğŸ§  Dataset Highlightsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/freococo/quran_multilingual_parallel.","url":"https://huggingface.co/datasets/freococo/quran_multilingual_parallel","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Albanian","Amharic","Azerbaijani"],"keywords_longer_than_N":true}
]
;
