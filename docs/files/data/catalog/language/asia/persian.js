const data_for_language_asia_persian = 
[
	{"name":"dehkhodaDic","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AsemanAI/dehkhodaDic","creator_name":"khazaen aseman","creator_url":"https://huggingface.co/AsemanAI","description":"AsemanAI/dehkhodaDic dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Persian","apache-2.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"persian-sft-M","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/foshati/persian-sft-M","creator_name":"Foshati","creator_url":"https://huggingface.co/foshati","description":"foshati/persian-sft-M dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Persian","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"miracl-vision","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nvidia/miracl-vision","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","description":"\n\t\n\t\t\n\t\tMIRACL-VISION\n\t\n\nMIRACL-VISION is a multilingual visual retrieval dataset for 18 different languages. It is an extension of MIRACL, a popular text-only multilingual retrieval dataset. The dataset contains user questions, images of Wikipedia articles and annotations, which article can answer a user question. There are 7898 questions and 338734 images. More details can be found in the paper MIRACL-VISION: A Large, multilingual, visual document retrieval benchmark.\nThis dataset is ready‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/miracl-vision.","first_N":5,"first_N_keywords":["document-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"persian-sentiment-comments","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aictsharif/persian-sentiment-comments","creator_name":"aictsharif","creator_url":"https://huggingface.co/aictsharif","description":"\n\t\n\t\t\n\t\tDataset Card for Persian Sentiment Comments\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\npersian-sentiment-comments is a curated dataset of Persian (Farsi) user comments, each annotated with a sentiment label. The dataset is designed for sentiment analysis tasks and is particularly suitable for training and evaluating machine learning models on Persian text data.\nThe comments are collected from a variety of sources, including online product reviews and user feedback. Each comment is paired with a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aictsharif/persian-sentiment-comments.","first_N":5,"first_N_keywords":["text-classification","Persian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"persian-voice-v1","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vhdm/persian-voice-v1","creator_name":"Vahid Mahmoudian","creator_url":"https://huggingface.co/vhdm","description":"\n\t\n\t\t\n\t\tüó£Ô∏è Common Voice 17 ‚Äî Persian (Spelling-Corrected Edition)\n\t\n\nThis is a refined version of the Persian subset of Mozilla's Common Voice 17 dataset, specially curated to enhance the performance of ASR (Automatic Speech Recognition) systems in Persian.\n\n\t\n\t\t\n\t\tüõ†Ô∏è Why this matters\n\t\n\nThe original dataset contained a significant number of spelling inconsistencies and typographical errors, which negatively impacted transcription accuracy and model alignment.\n\n\t\n\t\t\n\t\t‚ú® What‚Äôs improved‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vhdm/persian-voice-v1.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"persian-voice-v1","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vhdm/persian-voice-v1","creator_name":"Vahid Mahmoudian","creator_url":"https://huggingface.co/vhdm","description":"\n\t\n\t\t\n\t\tüó£Ô∏è Common Voice 17 ‚Äî Persian (Spelling-Corrected Edition)\n\t\n\nThis is a refined version of the Persian subset of Mozilla's Common Voice 17 dataset, specially curated to enhance the performance of ASR (Automatic Speech Recognition) systems in Persian.\n\n\t\n\t\t\n\t\tüõ†Ô∏è Why this matters\n\t\n\nThe original dataset contained a significant number of spelling inconsistencies and typographical errors, which negatively impacted transcription accuracy and model alignment.\n\n\t\n\t\t\n\t\t‚ú® What‚Äôs improved‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vhdm/persian-voice-v1.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MIRACLRetrieval","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MIRACLRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MIRACLRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttp://miracl.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MIRACLRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","RSamoed/MIRACLRetrieval","Arabic"],"keywords_longer_than_N":true},
	{"name":"TinyDS-20k","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","description":"\n\t\n\t\t\n\t\tTinyDS\n\t\n\n\n\n\nAlpaca-style dataset with around 20k samples scraped from Qwen3-8B using SyntheticAlpaca. Q&A pairs can be in 32 different languages, these are listed in the metadata.Topics are all around STEM, programming, and literature.  \nMIT @ 2025 Hamzah Asadullah\n\n\n","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"persiancrypto","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vahidr/persiancrypto","creator_name":"Vahid Rasizadeh","creator_url":"https://huggingface.co/vahidr","description":"vahidr/persiancrypto dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Persian","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"multiblimp","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jumelet/multiblimp","creator_name":"Jaap Jumelet","creator_url":"https://huggingface.co/jumelet","description":"\n\t\n\t\t\n\t\tMultiBLiMP\n\t\n\nMultiBLiMP is a massively Multilingual Benchmark for Linguistic Minimal Pairs. The dataset is composed of synthetic pairs generated using Universal Dependencies and UniMorph.\nThe paper can be found here.\nWe split the data set by language: each language consists of a single .tsv file. The rows contain many attributes for a particular pair, most important are the sen and wrong_sen fields, which we use for evaluating the language models.\n\n\t\n\t\t\n\t\n\t\n\t\tUsing MultiBLiMP\n\t\n\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jumelet/multiblimp.","first_N":5,"first_N_keywords":["multilingual","Buriat","Spanish","Sanskrit","Romanian"],"keywords_longer_than_N":true},
	{"name":"heyva-qa-dataset","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/virusdragon/heyva-qa-dataset","creator_name":"Sepehr iranmanesh","creator_url":"https://huggingface.co/virusdragon","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/virusdragon/heyva-qa-dataset.","first_N":5,"first_N_keywords":["question-answering","Persian","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Persian-Readability-Dataset","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlirezaF138/Persian-Readability-Dataset","creator_name":"Alireza Farzaneh","creator_url":"https://huggingface.co/AlirezaF138","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a re-upload of the Persian Text Readability Dataset, originally created and published by Mohammadi & Khasteh (2020). It provides sentence-level readability annotations for Persian (Farsi) texts. Each data point includes:\n\nA text in Persian\nA label (readability level):  \n0 for easy  \n1 for medium  \n2 for hard\n\n\nA rater profile: the average readability label distribution of the raters who annotated that specific text\n\nAll texts included have over 80% agreement‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlirezaF138/Persian-Readability-Dataset.","first_N":5,"first_N_keywords":["text-classification","Persian","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"shahnameh-ulugzoda-prose","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ArabovMK/shahnameh-ulugzoda-prose","creator_name":"Arabov Mullosharaf","creator_url":"https://huggingface.co/ArabovMK","description":"ArabovMK/shahnameh-ulugzoda-prose dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Tajik","Persian","cc-by-sa-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"tojikon-ghafurov-corpus","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ArabovMK/tojikon-ghafurov-corpus","creator_name":"Arabov Mullosharaf","creator_url":"https://huggingface.co/ArabovMK","description":"\n\t\n\t\t\n\t\t–¢–æ“∑–∏–∫–æ–Ω\n\t\n\nAuthor: –ë–æ–±–æ“∑–æ–Ω “í–∞—Ñ—É—Ä–æ–≤\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains the complete text of \"–¢–æ“∑–∏–∫–æ–Ω\" in tajik language. The work is a comprehensive historical study of Tajik people by renowned scholar Bobojon Ghafurov.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ArabovMK/tojikon-ghafurov-corpus\")\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nSingle entry containing the complete book\nPreserves original formatting and structure\nIncludes metadata about‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArabovMK/tojikon-ghafurov-corpus.","first_N":5,"first_N_keywords":["Tajik","Persian","cc-by-sa-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2Jyq/common_voice_21_0","creator_name":"2Jyq","creator_url":"https://huggingface.co/2Jyq","description":"Due to storage limits some files had to be split into multiple parts. They can be merged like this: cat file.* > file.\n","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","multilingual","extended|common_voice","Abkhaz"],"keywords_longer_than_N":true},
	{"name":"morphscore","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/catherinearnett/morphscore","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","description":"\n\t\n\t\t\n\t\tMorphScore\n\t\n\nMorphScore is a tokenizer evaluation framework, which evaluates the extent to which a tokenizer segments words along morpheme boundaries. This repository contains the datasets used to calculate MorphScore.\nIn total, we have datasetes for 86 languages, but only 70 languages have at least 100 items after filtering. \nAll datasets are derived from existing Universal Dependencies treebanks. In the table below, we link the source dataset for each language. \nSee the new preprint‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/morphscore.","first_N":5,"first_N_keywords":["Arabic","English","German","Russian","Turkish"],"keywords_longer_than_N":true},
	{"name":"tokenizer-robustness-math-mmlu","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-math-mmlu","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","description":"\n\t\n\t\t\n\t\tTokenizer Robustness Math MMLU Dataset\n\t\n\nThis dataset contains MMLU-formatted questions and answers designed to test tokenizer robustness across different math notions.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of the same questions presented in 6 different formats, with both test (20 questions) and development (5 questions) sets:\n\nunicode - Questions and choices in unicode format\nascii - Questions and choices in ASCII format\nlatex - Questions and choices in LaTeX format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-math-mmlu.","first_N":5,"first_N_keywords":["English","Persian","cc-by-4.0","< 1K","arrow"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shifting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang.","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"MIRACLRetrieval","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RSamoed/MIRACLRetrieval","creator_name":"RS","creator_url":"https://huggingface.co/RSamoed","description":"\n  MIRACLRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttp://miracl.ai/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RSamoed/MIRACLRetrieval.","first_N":5,"first_N_keywords":["text-retrieval","expert-annotated","multilingual","Arabic","Bengali"],"keywords_longer_than_N":true},
	{"name":"code-switching-tokenizer-robustness","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","description":"\n\t\n\t\t\n\t\tCode-Switching Dataset for Tokenizer Robustness Analysis\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for tokenizer robustness testing in multilingual and code-switching contexts. It contains identical content expressed across 16 different language variants, including pure English and 15 English-X code-switching pairs, allowing researchers to isolate tokenization effects from semantic differences when evaluating language models.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\n\nTokenizer Comparison:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness.","first_N":5,"first_N_keywords":["text-generation","text-classification","multilingual","English","Russian"],"keywords_longer_than_N":true},
	{"name":"persian-clothing-recommendation-ner","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MJ360/persian-clothing-recommendation-ner","creator_name":"MJafari","creator_url":"https://huggingface.co/MJ360","description":"\n\t\n\t\t\n\t\tPersian Clothing Recommendation NER Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nContains 15,000 annotated Persian sentences for clothing recommendation systems with:\n\nClothing items\nColors\nMaterials\nBrands\nSizes\nOccasions\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n{\n  \"tokens\": [\"Ÿæ€åÿ±ÿßŸáŸÜ\", \"ÿ¢ÿ®€å\", \"ŸÜÿß€å⁄©\", \"ÿ®ÿ±ÿß€å\", \"ŸÖŸáŸÖÿßŸÜ€å\"],\n  \"ner_tags\": [\"B-CLOTHING\", \"B-COLOR\", \"B-BRAND\", \"O\", \"B-OCCASION\"]\n}\n\n","first_N":5,"first_N_keywords":["Persian","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"persian-clothing-recommendation-ner","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MJ360/persian-clothing-recommendation-ner","creator_name":"MJafari","creator_url":"https://huggingface.co/MJ360","description":"\n\t\n\t\t\n\t\tPersian Clothing Recommendation NER Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nContains 15,000 annotated Persian sentences for clothing recommendation systems with:\n\nClothing items\nColors\nMaterials\nBrands\nSizes\nOccasions\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n{\n  \"tokens\": [\"Ÿæ€åÿ±ÿßŸáŸÜ\", \"ÿ¢ÿ®€å\", \"ŸÜÿß€å⁄©\", \"ÿ®ÿ±ÿß€å\", \"ŸÖŸáŸÖÿßŸÜ€å\"],\n  \"ner_tags\": [\"B-CLOTHING\", \"B-COLOR\", \"B-BRAND\", \"O\", \"B-OCCASION\"]\n}\n\n","first_N":5,"first_N_keywords":["Persian","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Therapy-Dialogues","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Algorithmic-Human-Development-Group/Multilingual-Therapy-Dialogues","creator_name":"Algorithmic Human Development","creator_url":"https://huggingface.co/Algorithmic-Human-Development-Group","description":" \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMultilingual Therapy Dialogues is a diverse and bilingual dataset consisting of paired dialogues between patients and therapists in both Persian and English.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nNumber of samples: 7,179\n\nEnglish:\n\nAverage tokens per sentence: 101.30  \nMaximum tokens in a sentence: 939  \nAverage characters per sentence: 567.85  \nNumber of unique tokens: 32,968\n\nPersian:\n\nAverage tokens per sentence: 100.06  \nMaximum tokens in a sentence: 1,413  \nAverage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Algorithmic-Human-Development-Group/Multilingual-Therapy-Dialogues.","first_N":5,"first_N_keywords":["English","Persian","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Lemonade","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stanford-oval/Lemonade","creator_name":"Stanford Open Virtual Assistant Lab (OVAL)","creator_url":"https://huggingface.co/stanford-oval","description":"LEMONADE is a large, expert-annotated dataset for event extraction from news articles in 20 languages: English, Spanish, Arabic, French, Italian, Russian, German, Turkish, Burmese, Indonesian, Ukrainian, Korean, Portuguese, Dutch, Somali, Nepali, Chinese, Persian, Hebrew, and Japanese.\nSee https://github.com/stanford-oval/Lemonade for details.\n","first_N":5,"first_N_keywords":["text-classification","English","Spanish","Arabic","French"],"keywords_longer_than_N":true},
	{"name":"oasst1","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"wikipedia-monthly","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/omarkamali/wikipedia-monthly","creator_name":"Omar Kamali","creator_url":"https://huggingface.co/omarkamali","description":"\n\t\n\t\t\n\t\tüöÄ Wikipedia Monthly\n\t\n\nLast updated: July 16, 2025, 22:53 UTC\nThis repository provides monthly, multilingual dumps of Wikipedia, processed and prepared for easy use in NLP projects.\nNOTE: The first run is still in progress and languages are still being processed and uploaded.\n\n\n\t\n\t\t\n\t\tüìä Live Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nüåç Languages Available\n341\n\n\nüìÑ Total Articles\n64.5M\n\n\nüíæ Total Size\n205.54 GB\n\n\n\t\n\n\n\n\t\n\t\t\n\t\tWhy Use This Dataset?\n\t\n\n\nFreshness: We run our pipeline monthly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/omarkamali/wikipedia-monthly.","first_N":5,"first_N_keywords":["Abkhaz","Achinese","Adyghe","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"oasst2","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\n\t\n\t\t\n\t\tOpen Assistant Conversations Dataset Release 2 (OASST2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \nAll messages have a role property: this can either be \"assistant\" or \"prompter\". The roles in \nconversation threads from prompt to leaf node strictly alternate between \"prompter\" and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU üåç is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) üóΩ or Culturally Agnostic (CA) ‚öñÔ∏è. These annotations were collected as part of an open‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU.","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tDataset Card for \"xtreme\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"MathVista","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI4Math/MathVista","creator_name":"AI for Math Reasoning","creator_url":"https://huggingface.co/AI4Math","description":"\n\t\n\t\t\n\t\tDataset Card for MathVista\n\t\n\n\nDataset Description\nPaper Information\nDataset Examples\nLeaderboard\nDataset Usage\nData Downloading\nData Format\nData Visualization\nData Source\nAutomatic Evaluation\n\n\nLicense\nCitation\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nMathVista is a consolidated Mathematical reasoning benchmark within Visual contexts. It consists of three newly created datasets, IQTest, FunctionQA, and PaperQA, which address the missing visual domains and are tailored to evaluate logical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI4Math/MathVista.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","text-classification","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"datacula-pertts-amir","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SadeghK/datacula-pertts-amir","creator_name":"Sadegh Karimi","creator_url":"https://huggingface.co/SadeghK","description":"Datacula Persian Audio Dataset: A dataset for  text-to-speech models\nWith ‚ù§Ô∏è from DataCula!\nYou can try the tts model trained based on datacula-pertts-amir voice dataset, have a loot at  https://tts.datacula.com/\nVoices\n\nüéôÔ∏è Amir: Voice of Amir Sooakhsh from rokhpodcast, accessible via https://rokhpodcast.ir/\n\nStrucure:\n\nljspeech\n\nContact\n\nsupport@datacula.com\nsadegh.karimi@datacula.com\n\n","first_N":5,"first_N_keywords":["Persian","apache-2.0","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"persian-multi-source-corpus","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yeganehmohammadi98/persian-multi-source-corpus","creator_name":"yeganeh mohammadi akbarabadi","creator_url":"https://huggingface.co/yeganehmohammadi98","description":"\nlicense: mit\n--- üìö Persian Multi-Source Dataset Collection\nüåü Dataset Overview\nA comprehensive Persian language dataset combining diverse sources to create a rich training corpus for language models.\nüìä Data Sources\nüåê Public Datasets\nMaralGPT Collections\nPersian blogs\nPersian quotes\nStory Collections\nTinyStories-Farsi\nFarsiTinyStories\nNews & Media\nFarsi news corpus\nPersian daily news\nPersian blog posts\nConversation & QA\nPersian QA pairs\nTelegram channel content\nSpecialized Content‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yeganehmohammadi98/persian-multi-source-corpus.","first_N":5,"first_N_keywords":["Persian","mit","10M - 100M","text","Text"],"keywords_longer_than_N":true},
	{"name":"tarjoman-persian-asr","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PerSets/tarjoman-persian-asr","creator_name":"Persian Datasets","creator_url":"https://huggingface.co/PerSets","description":"\n\t\n\t\t\n\t\tTarjoman Podcast 2023 ASR Dataset\n\t\n\nThis datasets consists of a collection of 507 articles from the Tarjoman website until the end of 2023, each accompanied by corresponding audio recordings.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset includes complete articles along with their audio counterparts. Each article is presented in its entirety, without sentence segmentation. Every entry contains the following metadata fields:\n\nTitle: The main title of the article.\nSubtitle: A secondary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PerSets/tarjoman-persian-asr.","first_N":5,"first_N_keywords":["Persian","cc0-1.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"tarjoman-persian-asr","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PerSets/tarjoman-persian-asr","creator_name":"Persian Datasets","creator_url":"https://huggingface.co/PerSets","description":"\n\t\n\t\t\n\t\tTarjoman Podcast 2023 ASR Dataset\n\t\n\nThis datasets consists of a collection of 507 articles from the Tarjoman website until the end of 2023, each accompanied by corresponding audio recordings.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset includes complete articles along with their audio counterparts. Each article is presented in its entirety, without sentence segmentation. Every entry contains the following metadata fields:\n\nTitle: The main title of the article.\nSubtitle: A secondary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PerSets/tarjoman-persian-asr.","first_N":5,"first_N_keywords":["Persian","cc0-1.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tWMT24++\n\t\n\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\nthe publication\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\nIf you are interested in the images of the source URLs for each document, please see here.\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach language pair is stored in its own jsonl file.\nEach row is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"PersianCorpus_merged","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mshojaei77/PersianCorpus_merged","creator_name":"Mohammad Shojaei","creator_url":"https://huggingface.co/mshojaei77","description":"\n\t\n\t\t\n\t\tPersian Corpus (Merged)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPersian Corpus (Merged) is a large-scale, Persian corpus meticulously aggregated from multiple high-quality Persian datasets available on the Hugging Face Hub. Designed to advance Persian NLP research and applications, this corpus consolidates diverse textual sources into a single resource, providing researchers and developers with a robust foundation for training and evaluating language models.\n\n\t\n\t\t\n\t\tWhy Use This Corpus?\n\t\n\nBy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mshojaei77/PersianCorpus_merged.","first_N":5,"first_N_keywords":["text-generation","Persian","mit","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"opus_infopankki","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_infopankki","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for infopankki\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA parallel corpus of 12 languages, 66 bitexts.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe underlying task is machine translation.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_infopankki.","first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"persian","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for Opus Ubuntu\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\nE.g.\ndataset = load_dataset(\"opus_ubuntu\", lang1=\"it\", lang2=\"pl\")\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"mqa","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"sharif_emotional_speech_dataset","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pariajm/sharif_emotional_speech_dataset","creator_name":"Paria Jamshid Lou","creator_url":"https://huggingface.co/pariajm","description":"\n\t\n\t\t\n\t\n\t\n\t\tSharif Emotional Speech Dataset (ShEMO)\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe dataset includes 3000 semi-natural utterances, equivalent to 3 hours and 25 minutes of speech data extracted from online Persian radio plays. The ShEMO covers speech samples of 87 native-Persian speakers for five basic emotions including anger, fear, happiness, sadness and surprise, as well as neutral state. Twelve annotators label the underlying emotional state of utterances and majority voting is used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pariajm/sharif_emotional_speech_dataset.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","expert-generated","monolingual","radio-plays"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\n\t\n\t\t\n\t\tDataset Card for WIT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\nFrom the official blog post:\n\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\nThe WIT dataset offers extremely valuable data about the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_scenario","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_scenario","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveScenarioClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveScenarioClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_scenario.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_intent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveIntentClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_intent.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"syntran-fa","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SLPL/syntran-fa","creator_name":"Speech and Language Processing Lab - Sharif University Of Technology","creator_url":"https://huggingface.co/SLPL","description":"\n\t\n\t\t\n\t\tSynTran-fa\n\t\n\nSyntactic Transformed Version of Farsi QA datasets to make fluent responses from questions and short answers. You can use this dataset by the code below:\nimport datasets\ndata = datasets.load_dataset('SLPL/syntran-fa', split=\"train\")\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nHomepage: Sharif-SLPL\nRepository: SynTran-fa\nPoint of Contact: Sadra Sabouri\nPaper: SynTran-fa: Generating Comprehensive Answers for Farsi QA Pairs via Syntactic Transformation\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SLPL/syntran-fa.","first_N":5,"first_N_keywords":["question-answering","text-generation","monolingual","Persian","mit"],"keywords_longer_than_N":true},
	{"name":"naab","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SLPL/naab","creator_name":"Speech and Language Processing Lab - Sharif University Of Technology","creator_url":"https://huggingface.co/SLPL","description":"Huge corpora of textual data are always known to be a crucial need for training deep models such as transformer-based ones. This issue is emerging more in lower resource languages - like Farsi. We propose naab, the biggest cleaned and ready-to-use open-source textual corpus in Farsi. It contains about 130GB of data, 250 million paragraphs, and 15 billion words. The project name is derived from the Farsi word ŸÜÿßÿ® which means pure and high-grade.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","masked-language-modeling","monolingual"],"keywords_longer_than_N":true},
	{"name":"miracl-corpus","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/miracl-corpus","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\n\t\n\t\t\n\t\tDataset Card for MIRACL Corpus\n\t\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\nThis dataset contains the collection data of the 16 \"known languages\". The remaining 2 \"surprise languages\" will not be released until later.\nThe corpus for each language is prepared from a Wikipedia‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"HengamCorpus","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kargaranamir/HengamCorpus","creator_name":"Amir Hossein Kargaran","creator_url":"https://huggingface.co/kargaranamir","description":"\n\t\n\t\t\n\t\tHengam: An Adversarially Trained Transformer for Persian Temporal Tagging\n\t\n\nSee model at https://huggingface.co/kargaranamir/Hengam\nSee Demo at https://huggingface.co/spaces/kargaranamir/Hengam\nDetails at https://github.com/kargaranamir/hengam\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use any part of this repository in your research, please cite it using the following BibTex entry.\n@inproceedings{mirzababaei-etal-2022-hengam,\n    title        = {Hengam: An Adversarially Trained Transformer for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kargaranamir/HengamCorpus.","first_N":5,"first_N_keywords":["Persian","mit","10M - 100M","text","Text"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"miracl-fa-corpus-22-12","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-fa-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\n\t\n\t\t\n\t\tMIRACL (fa) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-fa-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-fa-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-fa-corpus-22-12.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Persian"],"keywords_longer_than_N":true},
	{"name":"miracl-fa-queries-22-12","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-fa-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\n\t\n\t\t\n\t\tMIRACL (fa) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-fa-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-fa-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-fa-queries-22-12.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Persian"],"keywords_longer_than_N":true},
	{"name":"Persian-conversational-dataset","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kamtera/Persian-conversational-dataset","creator_name":"Flincer","creator_url":"https://huggingface.co/Kamtera","description":"persian-conversational-dataset","first_N":5,"first_N_keywords":["text-generation","Persian","apache-2.0","100K - 1M","Text"],"keywords_longer_than_N":true},
	{"name":"multiconer_v2","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MultiCoNER/multiconer_v2","creator_name":"MultiCoNER","creator_url":"https://huggingface.co/MultiCoNER","description":"Complex named entities (NE), like the titles of creative works, are not simple nouns and pose challenges for NER systems (Ashwini and Choi, 2014). They can take the form of any linguistic constituent, like an imperative clause (‚ÄúDial M for Murder‚Äù), and do not look like traditional NEs (Persons, Locations, etc.). This syntactic ambiguity makes it challenging to recognize them based on context. We organized the MultiCoNER task (Malmasi et al., 2022) at SemEval-2022 to address these challenges in 11 languages, receiving a very positive community response with 34 system papers. Results confirmed the challenges of processing complex and long-tail NEs: even the largest pre-trained Transformers did not achieve top performance without external knowledge. The top systems infused transformers with knowledge bases and gazetteers. However, such solutions are brittle against out of knowledge-base entities and noisy scenarios like the presence of spelling mistakes and typos. We propose MultiCoNER II which represents novel challenges through new tasks that emphasize the shortcomings of the current top models.\n\nMultiCoNER II features complex NER in these languages:\n\n1. English\n2. Spanish\n3. Hindi\n4. Bangla\n5. Chinese\n6. Swedish\n7. Farsi\n8. French\n9. Italian\n10. Portugese\n11. Ukranian\n12. German\n\nFor more details see https://multiconer.github.io/\n\n## References\n* Sandeep Ashwini and Jinho D. Choi. 2014. Targetable named entity recognition in social media. CoRR, abs/1408.0782.\n* Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta Kar, Oleg Rokhlenko. 2022. SemEval-2022 Task 11: Multilingual Complex Named Entity Recognition (MultiCoNER).","first_N":5,"first_N_keywords":["token-classification","Bengali","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof Wr√≥bel","creator_url":"https://huggingface.co/djstrong","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"jomleh","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mlengineer-ai/jomleh","creator_name":"ML Engineer","creator_url":"https://huggingface.co/mlengineer-ai","description":"Jomleh is a Farsi (Persian) monolingual dataset composed of one sentence per sample. It's focused on quality over quantity and it's curated mostly based on the OSCAR project (https://oscar-project.com) among other data sources.\\","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","monolingual","Persian"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"nlp_twitter_analysis","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hamedhf/nlp_twitter_analysis","creator_name":"Hamed Feizabadi","creator_url":"https://huggingface.co/hamedhf","description":"hamedhf/nlp_twitter_analysis dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Persian","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ParsiGoo","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kamtera/ParsiGoo","creator_name":"Flincer","creator_url":"https://huggingface.co/Kamtera","description":"A Persian multispeaker dataset for text-to-speech purposes.","first_N":5,"first_N_keywords":["text-to-speech","other","monolingual","original","Persian"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\n\n\t\n\t\t\n\nToxic\nNeutral\nTotal\n\n\n\t\t\nmultilingual-train-deduplicated.csv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Spanish","Panjabi"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"fa-wikipedia","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pourmand1376/fa-wikipedia","creator_name":"Amir Pourmand","creator_url":"https://huggingface.co/pourmand1376","description":"\n\t\n\t\t\n\t\tDataset Card for \"fa-wikipedia\"\n\t\n\nThis is converted version of wikipedia-fa in order to comply with Open-assistant standards.\nMore Information needed\n","first_N":5,"first_N_keywords":["text-generation","Persian","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"isna-news","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pourmand1376/isna-news","creator_name":"Amir Pourmand","creator_url":"https://huggingface.co/pourmand1376","description":"\n\t\n\t\t\n\t\tDataset Card for \"isna-news\"\n\t\n\nThis is converted version of Isna-news to comply with Open-assistant standards.\nMetaData Column:\n\ntitle\nlink: short link to news\nlanguage: fa\njalali-time: time in jalali calendar\n\nMore Information needed\n","first_N":5,"first_N_keywords":["text-generation","Persian","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"alpaca-fa-instruction","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pourmand1376/alpaca-fa-instruction","creator_name":"Amir Pourmand","creator_url":"https://huggingface.co/pourmand1376","description":"\n\t\n\t\t\n\t\tDataset Card for \"alpaca-fa-instruction\"\n\t\n\nThis dataset was first created here and is published to huggingface according to Open-assistant standard. \nMore Information needed\n","first_N":5,"first_N_keywords":["text-generation","question-answering","Persian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"alpaca-fa-multi","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pourmand1376/alpaca-fa-multi","creator_name":"Amir Pourmand","creator_url":"https://huggingface.co/pourmand1376","description":"\n\t\n\t\t\n\t\tDataset Card for \"alpaca-fa-multi\"\n\t\n\nThis dataset is first published here and then converted to this style to comply with open-assistant standards.\nMore Information needed\n","first_N":5,"first_N_keywords":["question-answering","text-generation","Persian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"OpenAssistant-oasst1-fa","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pourmand1376/OpenAssistant-oasst1-fa","creator_name":"Amir Pourmand","creator_url":"https://huggingface.co/pourmand1376","description":"\n\t\n\t\t\n\t\tDataset Card for \"OpenAssistant-oasst1-fa\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["question-answering","text-generation","Persian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"persian-qa-translated","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pourmand1376/persian-qa-translated","creator_name":"Amir Pourmand","creator_url":"https://huggingface.co/pourmand1376","description":"\n\t\n\t\t\n\t\tDataset Card for \"persian-qa-translated\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","Persian","English"],"keywords_longer_than_N":true},
	{"name":"PEYMA-ARMAN-Mixed","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AliFartout/PEYMA-ARMAN-Mixed","creator_name":"Ali Fartout","creator_url":"https://huggingface.co/AliFartout","description":"\n\t\n\t\t\n\t\tMixed Persian NER Dataset (PEYMA-ARMAN)\n\t\n\nThis dataset is a combination of PEYMA and ARMAN Persian NER datasets. It contains the following named entity tags:\n\nProduct (PRO)\nEvent (EVE)\nFacility (FAC)\nLocation (LOC)\nPerson (PER)\nMoney (MON)\nPercent (PCT)\nDate (DAT)\nOrganization (ORG)\nTime (TIM)\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Information\n\t\n\nThe dataset is divided into three splits: train, test, and validation. Below is a summary of the dataset statistics:\n\n\t\n\t\t\nSplit\nB_DAT\nB_EVE\nB_FAC\nB_LOC\nB_MON‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AliFartout/PEYMA-ARMAN-Mixed.","first_N":5,"first_N_keywords":["token-classification","Persian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"belebele","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\n\t\n\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that discriminate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele.","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","text-classification","multiple-choice","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\n\t\n\t\t\n\t\tDataset Card for WikiAnc\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \nThe code for generating the dataset can be found here.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nwikificiation: The dataset can be used to train a model for Wikification.\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in all 320‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Persian-Text-NER","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SeyedAli/Persian-Text-NER","creator_name":"Seyed Ali Mir Mohammad Hosseini","creator_url":"https://huggingface.co/SeyedAli","description":"SeyedAli/Persian-Text-NER dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["token-classification","Persian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Persian-Text-Emotion","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SeyedAli/Persian-Text-Emotion","creator_name":"Seyed Ali Mir Mohammad Hosseini","creator_url":"https://huggingface.co/SeyedAli","description":"Dataset Classes\n\njoy:0\nsad:1\nanger:2\ndisgust:3\nfear:4\nsurprise:5\n\n","first_N":5,"first_N_keywords":["text-classification","Persian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Persian-Text-Sentiment","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SeyedAli/Persian-Text-Sentiment","creator_name":"Seyed Ali Mir Mohammad Hosseini","creator_url":"https://huggingface.co/SeyedAli","description":"Dataset Classes\n\nnegetive :0\npositive :1\n\n","first_N":5,"first_N_keywords":["text-classification","Persian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"mswc_fscil_subset","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset","creator_name":"NeuroBench","creator_url":"https://huggingface.co/NeuroBench","description":"This is a subset of the Multilingual Spoken Word Corpus dataset, which is built specifically for the Few-shot Class-incremental Learning (FSCIL) task. \nA total of 15 languages are chosen, split into 5 base languages (English, German, Catalan, French, Kinyarwanda) and 10 incrementally learned languages (Persian, Spanish, Russian, Welsh, Italian, Basque, Polish, Esparanto, Portuguese, Dutch).\nThe FSCIL task entails first training a model using abundant training data on words from the 5 base‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset.","first_N":5,"first_N_keywords":["English","Spanish","Catalan","French","Kinyarwanda"],"keywords_longer_than_N":true},
	{"name":"DehkhodaPersi-Fa","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Maani/DehkhodaPersi-Fa","creator_name":"Masoud Maani","creator_url":"https://huggingface.co/Maani","description":"Maani/DehkhodaPersi-Fa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Persian","cc0-1.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MoeinPersi-Fa","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Maani/MoeinPersi-Fa","creator_name":"Masoud Maani","creator_url":"https://huggingface.co/Maani","description":"Maani/MoeinPersi-Fa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Persian","cc0-1.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"ganjoor-processed","keyword":"persian","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kakooch/ganjoor-processed","creator_name":"Kaveh Ranjbar","creator_url":"https://huggingface.co/kakooch","description":"This dataset contains a rich collection of Persian poems along with metadata about the poets and the verses.\nThe data spans various poets and their poems, and includes the verses with associated information about their position within each poem.\nThe dataset is split into a training set and a test set, with 90% of the verses of each poem for each poet used for training and 10% used for testing.\n","first_N":5,"first_N_keywords":["Persian","gpl-2.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"persian-poetry-qa","keyword":"persian","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kakooch/persian-poetry-qa","creator_name":"Kaveh Ranjbar","creator_url":"https://huggingface.co/kakooch","description":"This dataset is structured in a question-answering format derived from a rich collection of Persian poems along with metadata about the poets and the verses. \nIt is designed to be utilized for various Natural Language Processing and analysis tasks related to Persian poetry, such as Question Answering, Text Generation, Language Modeling, and Style Analysis.\n","first_N":5,"first_N_keywords":["Persian","gpl-2.0","1M - 10M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"faradars","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bidkhori/faradars","creator_name":"Mohammad Bidkhori","creator_url":"https://huggingface.co/bidkhori","description":"bidkhori/faradars dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","text-generation","table-question-answering","Persian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Manufacturers-Persian","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dadashzadeh/Manufacturers-Persian","creator_name":"dadashzadeh","creator_url":"https://huggingface.co/dadashzadeh","description":"A list of manufacturers inside Iran and outside Iran\n","first_N":5,"first_N_keywords":["translation","Persian","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"oasst2_top1_chat_format","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","description":"\n\t\n\t\t\n\t\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\n\t\n\nExport of oasst2 only top 1 threads in huggingface chat format\n\n\t\n\t\t\n\t\tScript\n\t\n\nThe convert script can be find here\n","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"openassistant-deepseek-coder","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\n\t\n\nThis dataset allows for fine-tuning chat models using:\nB_INST = '\\n### Instruction:\\n'\nE_INST = '\\n### Response:\\n'\nBOS = '<ÔΩúbegin‚ñÅof‚ñÅsentenceÔΩú>'\nEOS = '\\n<|EOT|>\\n'\n\nSample Preparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Fran√ßais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"Persian_English_translation","keyword":"persian","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mehr32/Persian_English_translation","creator_name":"Jafar Farganlooj","creator_url":"https://huggingface.co/mehr32","description":"English-Persian translation dataset with about two million translation lines optimized for training LibreTranslate model:\nhttps://github.com/LibreTranslate/Locomotive\n","first_N":5,"first_N_keywords":["Persian","English","gpl-3.0","1M - 10M","text"],"keywords_longer_than_N":true},
	{"name":"WEATHub","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iamshnoo/WEATHub","creator_name":"Anjishnu Mukherjee","creator_url":"https://huggingface.co/iamshnoo","description":"\n\n\n\n\n\t\n\t\t\n\t\tDataset Card for \"WEATHub\"\n\t\n\nThis dataset corresponds to the data described in the paper \"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\"\naccepted to EMNLP 2023.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)\nto measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers. And we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub.","first_N":5,"first_N_keywords":["Arabic","Bengali","Central Kurdish","Danish","German"],"keywords_longer_than_N":true},
	{"name":"openassistant-falcon","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant Falcon\n\t\n\nThis dataset allows for fine-tuning chat models using '\\Human:' AND '\\nAssistant:' to wrap user messages.\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\nSample \nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"DK-FA-Cosmetics","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Acidmanic/DK-FA-Cosmetics","creator_name":"Mani Moayedi","creator_url":"https://huggingface.co/Acidmanic","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Mani Moayedi\nLanguage(s) (NLP): Farsi (Persian)\nLicense: MIT\n\n\n\t\n\t\t\n\t\n\t\n\t\tUses\n\t\n\nThe samples of this dataset are user comments about products of an online shop website. Each comment contains some \nadditional data alongside the comments body, like‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Acidmanic/DK-FA-Cosmetics.","first_N":5,"first_N_keywords":["Persian","mit","100K<n<1M","üá∫üá∏ Region: US","e-commerce"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"ZharfaTech-OpenAssistant-Guanaco-Persian-Farsi","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZharfaTech/ZharfaTech-OpenAssistant-Guanaco-Persian-Farsi","creator_name":"ZharfaTech","creator_url":"https://huggingface.co/ZharfaTech","description":"\n\t\n\t\t\n\t\tPersian OpenAssistant-Guanaco Dataset\n\t\n\n\n\t\n\t\t\n\t\tAbout ZharfaTech\n\t\n\nZharfaTech is at the forefront of developing advanced Language Learning Models (LLMs) specifically for the Persian language, aiming to empower over 100 million Persian speakers worldwide. Our objective is to bridge the digital gap in services leveraging LLMs, such as content generation, translation, and customer relationship systems, by providing tailored open-source and closed-source LLM solutions. We focus on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZharfaTech/ZharfaTech-OpenAssistant-Guanaco-Persian-Farsi.","first_N":5,"first_N_keywords":["text-generation","Persian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Persian-Speech-Dataset","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SeyedAli/Persian-Speech-Dataset","creator_name":"Seyed Ali Mir Mohammad Hosseini","creator_url":"https://huggingface.co/SeyedAli","description":"SeyedAli/Persian-Speech-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Persian","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_seasons","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yachay/text_coordinates_seasons","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\n\t\n\t\t\n\t\tDataset Card for Geo-Tagged Social Media Posts with Timestamps\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Seasons\" dataset is a collection of over 600,000 social media posts spanning 12 months and encompassing 15 distinct time zones. It focuses on six countries: Cuba, Iran, Russia, North Korea, Syria, and Venezuela, with each post containing textual content, timestamps, and geographical coordinates. The dataset's primary objective is to investigate the correlation between the timing of posts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_seasons.","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_regions","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Regions\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\nKey Features:\n\nTextual Data: The dataset contains 500,000 text samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"MultiCoNER","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tomaarsen/MultiCoNER","creator_name":"Tom Aarsen","creator_url":"https://huggingface.co/tomaarsen","description":"We present MultiCoNER, a large multilingual dataset for Named Entity Recognition that covers 3 domains (Wiki sentences, questions, and search queries) across 11 languages, as well as multilingual and code-mixing subsets. This dataset is designed to represent contemporary challenges in NER, including low-context scenarios (short and uncased text), syntactically complex entities like movie titles, and long-tail entity distributions. The 26M token dataset is compiled from public resources using techniques such as heuristic-based sentence sampling, template extraction and slotting, and machine translation. We applied two NER models on our dataset: a baseline XLM-RoBERTa model, and a state-of-the-art GEMNET model that leverages gazetteers. The baseline achieves moderate performance (macro-F1=54%), highlighting the difficulty of our data. GEMNET, which uses gazetteers, improvement significantly (average improvement of macro-F1=+30%). MultiCoNER poses challenges even for large pre-trained language models, and we believe that it can help further research in building robust NER systems. MultiCoNER is publicly available at https://registry.opendata.aws/multiconer/ and we hope that this resource will help advance research in various aspects of NER.","first_N":5,"first_N_keywords":["token-classification","Bengali","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"FarsTail-Instruct-LLM","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hghader1/FarsTail-Instruct-LLM","creator_name":"Hamidreza Ghader","creator_url":"https://huggingface.co/hghader1","description":"\n\t\n\t\t\n\t\tDataset Card for \"FarsTail-Instruct-LLM\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nFarsTail Instruct LLM dataset is a Persian (Farsi) dataset aimed to be used for text generation tasks by large language models. The dataset is in prompt/completion (instruction) format. \nThe dataset is created from FarsTail dataset by changing the format of \"e\" (entailment) and \"c\" (contradiction) cases and adding some command and completion templates.\n\n\t\n\t\t\n\t\n\t\n\t\tPrompt and Completion Templates\n\t\n\nHere are the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hghader1/FarsTail-Instruct-LLM.","first_N":5,"first_N_keywords":["text-generation","Persian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"openassistant-guanaco-EOS","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Guanaco Style\n\t\n\nThis dataset allows for fine-tuning chat models using \"### Human:\" AND \"### Assistant\" as the beginning and end of sequence tokens.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then slightly adjusted to:\n\n\nif a row of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"openassistant-llama-style","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Llama 2 Style\n\t\n\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then filtered to:\n\n\nreplace instances of '### Human:' with '[INST]'\nreplace‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"tokenizer-wiki-bench","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","description":"\n\t\n\t\t\n\t\tMultilingual Tokenizer Benchmark\n\t\n\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \nfrom transformers import AutoTokenizer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench.","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"C-ExaPPC","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PNLPhub/C-ExaPPC","creator_name":"Persian NLP Hub","creator_url":"https://huggingface.co/PNLPhub","description":"PNLPhub/C-ExaPPC dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","text-classification","Persian","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Pars-ABSA","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PNLPhub/Pars-ABSA","creator_name":"Persian NLP Hub","creator_url":"https://huggingface.co/PNLPhub","description":"PNLPhub/Pars-ABSA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Persian","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"oaast_rm_full_jieba","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"Â∞ùËØïËß£ÂÜ≥\"llm repetition problem\"Ôºå‰ΩøÁî®ÂàÜËØçÊ®°ÂûãÂØπoaastËØ≠ÊñôËøõË°å‚ÄúÁªìÂ∑¥Âåñ‚ÄùÊï∞ÊçÆÂ¢ûÂº∫ÔºåÊèê‰æõÊõ¥Âº∫ÁöÑÈáçÂ§çÂÜÖÂÆπÊãíÁªùÊïàÊûú„ÄÇ\nAttempts to solve the \"llm repetition problem\" by using a segmentation model to enhance the oaast corpus with \"stuttering\" data to provide stronger rejection of duplicate content.\nÂÖ∂Ê¨°ÔºåËøòËøáÊª§Êéâ‰∫ÜÊâÄÊúâËá™ÊàëËÆ§Áü•ÁöÑÂæÆË∞ÉÊ†∑Êú¨„ÄÇ\nSecond, it also filters out all the fine-tuned samples of self-cognition.\nfiles:\n\noaast_rm_full_jieba.jsonl : word level repeat\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\n\n","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"FAspell","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlirezaF138/FAspell","creator_name":"Alireza Farzaneh","creator_url":"https://huggingface.co/AlirezaF138","description":"\n\t\n\t\t\n\t\tFASpell Dataset\n\t\n\n\n\t\n\t\t\n\t\tContext\n\t\n\nThe FASpell dataset was developed to evaluate spell-checking algorithms. It consists of pairs of misspelled Persian (Farsi) words and their corresponding corrected forms, similar to the ASpell dataset used for English.\n\n\t\n\t\t\n\t\tContent\n\t\n\nThe dataset is divided into two parts:\n\nfaspell_main: A list of 5050 pairs collected from errors made by elementary school pupils and professional typists.\nfaspell_ocr: A list of 800 pairs collected from the output‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlirezaF138/FAspell.","first_N":5,"first_N_keywords":["Persian","cc-by-4.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"ÿßŸÖÿßŸÖ ÿ¨ŸÖÿπŸá ÿßÿµŸÅŸáÿßŸÜ ⁄ØŸÅÿ™: ŸÖ€åÿ≤ÿßŸÜ ŸÜ€åÿßÿ≤ ÿ¢ÿ® ÿ¥ÿ±ÿ® ÿßÿµŸÅŸáÿßŸÜ €±€±.€µ ŸÖÿ™ÿ± ŸÖ⁄©ÿπÿ® ÿßÿ≥ÿ™ ⁄©Ÿá ÿ™ŸÖÿßŸÖ ÿßÿ≥ÿ™ÿßŸÜ ÿßÿµŸÅŸáÿßŸÜ ÿ±ÿß ŸæŸàÿ¥ÿ¥ ŸÖ€åÿØŸáÿØ Ÿà ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸÇÿ®ŸÑ ÿßÿ≤ ÿßŸÜŸÇŸÑÿßÿ® €å⁄©€å ÿßÿ≤ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿáÿß ÿØÿ± ÿ≠Ÿàÿ≤Ÿá ÿ¢ÿ® ÿ®ŸàÿØŸá ÿßÿ≥ÿ™.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"Phonemized-UD","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/suchirsalhan/Phonemized-UD","creator_name":"Suchir Salhan","creator_url":"https://huggingface.co/suchirsalhan","description":"\n\t\n\t\t\n\t\tPhoneme-UD: A Multilingual Phonemized Universal Dependencies Corpus for 34+ Languages\n\t\n\n\n\t\n\t\t\n\t\tG2P+ Phonemizer\n\t\n\nWe use G2P+ to phonemize Universal Dependencies. Here is an example usage: \n# Install required packages\n!apt-get install -y espeak-ng\n!pip install phonemizer g2p-plus\n# Set the environment variable from Python\nimport os\nos.environ[\"PHONEMIZER_ESPEAK_LIBRARY\"] = \"/usr/lib/x86_64-linux-gnu/libespeak-ng.so.1\"\n\n# Now run your transcription\nfrom g2p_plus import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suchirsalhan/Phonemized-UD.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Azerbaijani","Catalan"],"keywords_longer_than_N":true},
	{"name":"lr-sum","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\tDataset Card for LR-Sum\n\t\n\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \nThe data is based on the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum.","first_N":5,"first_N_keywords":["summarization","text-generation","found","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"megawika-report-generation","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\n\t\n\t\t\n\t\tDataset Card for MegaWika for Report Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\nnon-English language, an automated English translation is provided. \nThis dataset provides the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation.","first_N":5,"first_N_keywords":["summarization","text-retrieval","text-generation","Afrikaans","Arabic"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\nand converted into different parts (see process.py):\n\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\n\nRaw data files are in raw.tar.gz, which contains:\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\n[...] 9.8M Feb 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"GPT-4-Prompts","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/erfanzar/GPT-4-Prompts","creator_name":"Erfan zare chavoshi","creator_url":"https://huggingface.co/erfanzar","description":"Multi-Turn Conversational Prompts from ChatGPT-4 (10K+ Tokens)\nAbstract:\nThis dataset offers a valuable collection of multi-turn conversational prompts generated by ChatGPT-4, carefully curated for diverse prompt styles (chatml, gemma, llama). Each prompt exceeds 10,000 tokens, providing ample context and inspiration for training and evaluating large language models. Ideal for researchers and developers interested in exploring advanced conversational AI capabilities.\nTable of Contents:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/erfanzar/GPT-4-Prompts.","first_N":5,"first_N_keywords":["translation","question-answering","text-generation","summarization","English"],"keywords_longer_than_N":true},
	{"name":"mittens","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/mittens","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tMiTTenS: A Dataset for Evaluating Misgendering in Translation\n\t\n\nMisgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scripts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/mittens.","first_N":5,"first_N_keywords":["translation","Arabic","Finnish","Oromo","Ganda"],"keywords_longer_than_N":true},
	{"name":"entity-attribute-dataset-GPT-3.5-generated-v1","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BaSalam/entity-attribute-dataset-GPT-3.5-generated-v1","creator_name":"BaSalam","creator_url":"https://huggingface.co/BaSalam","description":"\n\t\n\t\t\n\t\tEntity Attribute Dataset 306k (GPT-3.5 generated)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Entity Attribute Dataset 306k (GPT-3.5 generated) is designed for instruction fine-tuning, specifically for the task of generating structured catalogs in JSON format based on product titles. The dataset includes a diverse range of products from various categories such as food, home and kitchen, clothing, handicrafts, tools, automotive equipment, and more.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThis dataset is intended for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BaSalam/entity-attribute-dataset-GPT-3.5-generated-v1.","first_N":5,"first_N_keywords":["text-generation","feature-extraction","Persian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Open_Assistant_Conversation_Chains","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset description\n\t\n\n\n\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\n\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\n\nIt was modified‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains.","first_N":5,"first_N_keywords":["text-generation","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"combinedFarsiQuADs","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/a-asad/combinedFarsiQuADs","creator_name":"AbolfazlAsad","creator_url":"https://huggingface.co/a-asad","description":"combine multiple QuAD datasets to create new Dataset simillar to squad_v2 dataset:\n\nPersianQA\nPQuAD\nParSQuAD\nPersianQuAD\n\n","first_N":5,"first_N_keywords":["Persian","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Persian_Chat_Dataset","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/saied/Persian_Chat_Dataset","creator_name":"Saied Alimoradi","creator_url":"https://huggingface.co/saied","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a subset of ultrachat_200k which  was used to train Zephyr-7B-Œ≤, a state of the art 7b chat model.\n\n\t\n\t\t\n\t\tThis dataset has been translated to Persian by chatGPT\n\t\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you find this dataset is useful in your work, please cite the original UltraChat dataset:\n@misc{ding2023enhancing,\n      title={Enhancing Chat Language Models by Scaling High-quality Instructional Conversations}, \n      author={Ning Ding and Yulin Chen and Bokai‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saied/Persian_Chat_Dataset.","first_N":5,"first_N_keywords":["Persian","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"asr-farsi-youtube-chunked-30-seconds","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pourmand1376/asr-farsi-youtube-chunked-30-seconds","creator_name":"Amir Pourmand","creator_url":"https://huggingface.co/pourmand1376","description":"\n\t\n\t\t\n\t\tHow To Use\n\t\n\nfrom datasets import load_dataset\ntrain = load_dataset('pourmand1376/asr-farsi-youtube-chunked-30-seconds', split='train+val')\ntest =load_dataset('pourmand1376/asr-farsi-youtube-chunked-30-seconds', split='test')\n\n+300 Hours ASR dataset generated from this kaggle dataset\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ZharfaTech-Open-Platypus-Persian-Farsi","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZharfaTech/ZharfaTech-Open-Platypus-Persian-Farsi","creator_name":"ZharfaTech","creator_url":"https://huggingface.co/ZharfaTech","description":"\n\t\n\t\t\n\t\tPersian Open-Platypus\n\t\n\n\n\t\n\t\t\n\t\tAbout ZharfaTech\n\t\n\nZharfaTech is a pioneer in developing Language Learning Models (LLMs) tailored for the Persian language, aiming to empower over 100 million Persian speakers worldwide. Our mission encompasses bridging the digital divide in LLM-related services like content generation, customer relationship systems, and more, with a dual approach of fostering open-source collaboration and delivering high-value, specialized closed-source solutions.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZharfaTech/ZharfaTech-Open-Platypus-Persian-Farsi.","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","Persian","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"flickr30k-fa","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hezarai/flickr30k-fa","creator_name":"Hezar AI","creator_url":"https://huggingface.co/hezarai","description":"The Flickr30K dataset filtered and translated to Persian.\nThis dataset was originally made by Sajjad Ayoubi and uploaded to Kaggle at https://www.kaggle.com/datasets/sajjadayobi360/flickrfa.\nThis repo contains the exact dataset split to train/test using a custom sampling criteria and can be directly loaded using HuggingFace datasets or right from Hezar.\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\tHugging Face Datasets\n\t\n\npip install datasets\n\nfrom datasets import load_dataset\n\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hezarai/flickr30k-fa.","first_N":5,"first_N_keywords":["image-to-text","Persian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"Pontoon-Translations","keyword":"persian","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\n\t\n\t\t\n\t\tDataset Card for Pontoon Translations\n\t\n\n\n\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\nSource strings are in English.\nTo avoid rows with values like \"None\" and \"N/A\" being interpreted as missing values, pass the keep_default_na parameter like this:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ayymen/Pontoon-Translations\", keep_default_na=False)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","crowdsourced","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"mOSCAR-Persian","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ErfanMoosaviMonazzah/mOSCAR-Persian","creator_name":"Erfan Moosavi Monazzah","creator_url":"https://huggingface.co/ErfanMoosaviMonazzah","description":"\n\t\n\t\t\n\t\tDataset Card for mOSCAR-Persian\n\t\n\nThis is a clone of mOSCAR Persian split (images excluded), which is further divided into single documents. Both URLs and Document IDs are consistent with mOSCAR.\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nRepository: mOSCAR\nPaper [optional]: mOSCAR: A Large-scale Multilingual and Multimodal Document-level Corpus\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@article{futeral2024moscar,\n  title={mOSCAR: A Large-scale Multilingual and Multimodal Document-level Corpus},\n  author={Futeral‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ErfanMoosaviMonazzah/mOSCAR-Persian.","first_N":5,"first_N_keywords":["text-generation","Persian","cc-by-4.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"DatasetZaliAi","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Esmaeilkiani/DatasetZaliAi","creator_name":"kiani","creator_url":"https://huggingface.co/Esmaeilkiani","description":"Esmaeilkiani/DatasetZaliAi dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Persian","English","apache-2.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"persian_tts_stt","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SmartGitiCorp/persian_tts_stt","creator_name":"Smart Giti Corporation","creator_url":"https://huggingface.co/SmartGitiCorp","description":"This dataset contains more than 10k records and 15 hours of clear vocal voice aligning with text in csv file.\n","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Persian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"IranianSkodaQuestion87to94","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shmohseni/IranianSkodaQuestion87to94","creator_name":"mohseni","creator_url":"https://huggingface.co/shmohseni","description":"This dataset contains about 1k question and answer of Iranian Skoda exam from 1387 to 1394 (Solar Hijri)\n","first_N":5,"first_N_keywords":["Persian","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"persian_arc","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MatinaAI/persian_arc","creator_name":"Matina AI","creator_url":"https://huggingface.co/MatinaAI","description":"\n\t\n\t\t\n\t\tDataset Card for persian_arc\n\t\n\n\n\nThis dataset is the persian version of allenai/ai2_arc translated by GPT-4o.\n\n\t\n\t\t\n\t\tOriginal Dataset Description\n\t\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tARC-Challenge\n\t\n\nAn example of 'train' looks as follows.\n{\n    'id': 'Mercury_SC_415702',\n    'question_fa': 'ÿ¨ÿ±ÿ¨ ŸÖ€å\\u200cÿÆŸàÿßŸáÿØ ÿ®ÿß ŸÖÿßŸÑ€åÿØŸÜ ÿØÿ≥ÿ™\\u200cŸáÿß€åÿ¥ ÿ®Ÿá ÿ≥ÿ±ÿπÿ™‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MatinaAI/persian_arc.","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","multiple-choice-qa","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"Chatgpt","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\nExample of loading:\ndataset = load_dataset(\"davidstap/NTREX\", \"rus_Cyrl\", trust_remote_code=True)\n\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe following languages are available:\n\n\t\n\t\t\nLanguage Code\nLanguage Name\n\n\n\t\t\nafr_Latn\nAfrikaans\n\n\namh_Ethi\nAmharic\n\n\narb_Arab\nArabic\n\n\naze_Latn\nAzerbaijani\nbak_Cyrl\nBashkir\n\n\nbel_Cyrl\nBelarusian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"swim-ir-cross-lingual","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\n\t\n\t\t\n\t\tDataset Card for SWIM-IR (Cross-lingual)\n\t\n\n\n\n\nThis is the cross-lingual subset of the SWIM-IR dataset, where the query generated is in the target language and the passage is in English.\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\n\n\t\n\t\n\t\n\t\tWhat is SWIM-IR?\n\t\n\nSWIM-IR dataset is a synthetic multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","machine-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"BLEnD","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayeon212/BLEnD","creator_name":"Nayeon Lee","creator_url":"https://huggingface.co/nayeon212","description":"\n\t\n\t\t\n\t\tBLEnD\n\t\n\nThis is the official repository of BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages (Submitted to NeurIPS 2024 Datasets and Benchmarks Track).\n24/12/05: Updated translation errors25/05/02: Updated multiple choice questions file (v1.1)\n\n\t\n\t\t\n\t\tAbout\n\t\n\n\nLarge language models (LLMs) often lack culture-specific everyday knowledge, especially across diverse regions and non-English languages. Existing benchmarks for evaluating LLMs' cultural‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nayeon212/BLEnD.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","Spanish","Indonesian"],"keywords_longer_than_N":true},
	{"name":"fa-topic-sentences","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mostafaamiri/fa-topic-sentences","creator_name":"mostafa amiri","creator_url":"https://huggingface.co/mostafaamiri","description":"\n\t\n\t\t\n\t\tREADME for fa-topic-sentences Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe fa-topic-sentences dataset is a comprehensive collection of sentences categorized into various topics. Each topic contains approximately 50 sentences in Persian, accompanied by a paraphrased version of each sentence. The dataset is structured in JSON format, providing a straightforward method for accessing individual entries.\n\n\t\n\t\t\n\t\tTopics Included\n\t\n\nThe dataset encompasses the following topics:\n\nHistory\nFashion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mostafaamiri/fa-topic-sentences.","first_N":5,"first_N_keywords":["Persian","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Persian_Cooking","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dadashzadeh/Persian_Cooking","creator_name":"dadashzadeh","creator_url":"https://huggingface.co/dadashzadeh","description":"dadashzadeh/Persian_Cooking dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","feature-extraction","question-answering","Persian","mit"],"keywords_longer_than_N":true},
	{"name":"virgool_62k","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Msobhi/virgool_62k","creator_name":"mohamad sobhi","creator_url":"https://huggingface.co/Msobhi","description":"This dataset represents the publicly available collection of data scraped from the virgool.io website. The data extraction was strategically performed based on specific tags and user. The dataset comprises approximately 62,000 entries across several key attributes: title, text, tags, likes, replies, reading_time, user_id, and URL.\nThis resource is particularly beneficial for researchers and developers aiming to pre-train large language models (LLMs), as the 'text' column provides a rich corpus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Msobhi/virgool_62k.","first_N":5,"first_N_keywords":["fill-mask","text-generation","text-classification","monolingual","Persian"],"keywords_longer_than_N":true},
	{"name":"mirage-bench-instruct","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/mirage-bench-instruct","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\n\t\n\t\t\n\t\tMIRAGE-Bench (Instruct)\n\t\n\nThis dataset contains the structured RAG outputs for queries in the train split of MIRAGE-Bench (or MIRACL) for 16 languages for five models:\n\ngpt-4o-azure                          (GPT-4o using Azure API)\nmeta-llama/Meta-Llama-3-70B-Instruct  (Llama-3-70B-Instruct using Anyscale API)\nmistralai/Mixtral-8x22B-Instruct-v0.1 (Mixtral-8x22B-Instruct using Anyscale API)\nmeta-llama/Meta-Llama-3-8B-Instruct   (Llama-3-8B-Instruct using vLLM)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/mirage-bench-instruct.","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","Bengali","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"multimuc4","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jgermanmx/multimuc4","creator_name":"Jesus German Ortiz Barajas","creator_url":"https://huggingface.co/jgermanmx","description":"jgermanmx/multimuc4 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Arabic","English","Persian","Korean"],"keywords_longer_than_N":true},
	{"name":"persian-conjnli-entailment-alpaca-style","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParsBench/persian-conjnli-entailment-alpaca-style","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\n\t\n\t\t\n\t\tPersian ConjNLI Entailment in Alpaca Style\n\t\n\nThis dataset is an Alpaca-style and instruction-included version of the ConjNLI which is translated to Persian in this repository.\n","first_N":5,"first_N_keywords":["question-answering","text-classification","Persian","cc-by-sa-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"farstail-entailment-alpaca-style","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParsBench/farstail-entailment-alpaca-style","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\n\t\n\t\t\n\t\tFarsTail Entailment in Alpaca Style\n\t\n\nThis dataset is an Alpaca-style and instruction-included version of the FarsTail original dataset.\n","first_N":5,"first_N_keywords":["text-classification","question-answering","Persian","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"parsinlu-entailment-alpaca-style","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParsBench/parsinlu-entailment-alpaca-style","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\n\t\n\t\t\n\t\tParsiNLU Entailment in Alpaca Style\n\t\n\nThis dataset is an Alpaca-style and instruction-included version of the ParsiNLU original dataset.\n","first_N":5,"first_N_keywords":["question-answering","text-classification","Persian","cc-by-sa-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"parsinlu-machine-translation-en-fa-alpaca-style","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParsBench/parsinlu-machine-translation-en-fa-alpaca-style","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\n\t\n\t\t\n\t\tParsiNLU Machine Translation En-Fa in Alpaca Style\n\t\n\nThis dataset is an Alpaca-style and instruction-included version of the ParsiNLU original dataset.\n","first_N":5,"first_N_keywords":["translation","Persian","English","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"parsinlu-multiple-choice-alpaca-style","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParsBench/parsinlu-multiple-choice-alpaca-style","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\n\t\n\t\t\n\t\tParsiNLU Multiple Choice in Alpaca Style\n\t\n\nThis dataset is an Alpaca-style and instruction-included version of the ParsiNLU original dataset.\n","first_N":5,"first_N_keywords":["question-answering","Persian","cc-by-sa-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"parsinlu-reading-comprehension-alpaca-style","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParsBench/parsinlu-reading-comprehension-alpaca-style","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\n\t\n\t\t\n\t\tParsiNLU Reading Comprehension in Alpaca Style\n\t\n\nThis dataset is an Alpaca-style and instruction-included version of the ParsiNLU original dataset.\n","first_N":5,"first_N_keywords":["question-answering","Persian","cc-by-sa-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"persian-math-alpaca-style","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParsBench/persian-math-alpaca-style","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\n\t\n\t\t\n\t\tPersian Math in Alpaca Style\n\t\n\nThis dataset is an Alpaca-style and instruction-included version of the Math original dataset which is translated to Persian in this repository.\n","first_N":5,"first_N_keywords":["question-answering","Persian","cc-by-sa-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"persian-ner-alpaca-style","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParsBench/persian-ner-alpaca-style","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\n\t\n\t\t\n\t\tPersian NER in Alpaca Style\n\t\n\nThis dataset is an Alpaca-style and instruction-included version of the PersianNER original dataset which is translated to Persian in this repository.\n","first_N":5,"first_N_keywords":["token-classification","Persian","cc-by-sa-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"pnsummary-alpaca-style","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParsBench/pnsummary-alpaca-style","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\n\t\n\t\t\n\t\tPersian News Summary in Alpaca Style\n\t\n\nThis dataset is an Alpaca-style and instruction-included version of the pn_summary original dataset.\n","first_N":5,"first_N_keywords":["summarization","Persian","cc-by-sa-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"parsinlu-sentiment-analysis-alpaca-style","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParsBench/parsinlu-sentiment-analysis-alpaca-style","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\n\t\n\t\t\n\t\tParsiNLU Sentiment Analysis in Alpaca Style\n\t\n\nThis dataset is an Alpaca-style and instruction-included version of the ParsiNLU original dataset.\n","first_N":5,"first_N_keywords":["text-classification","Persian","cc-by-sa-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"persian-xlsum-alpaca-style","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParsBench/persian-xlsum-alpaca-style","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\n\t\n\t\t\n\t\tPersian XLSum in Alpaca Style\n\t\n\nThis dataset is an Alpaca-style and instruction-included version of the XLSum Persian subset.\n","first_N":5,"first_N_keywords":["summarization","Persian","cc-by-sa-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"parsinlu-machine-translation-fa-en-alpaca-style","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParsBench/parsinlu-machine-translation-fa-en-alpaca-style","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\n\t\n\t\t\n\t\tParsiNLU Machine Translation Fa-En in Alpaca Style\n\t\n\nThis dataset is an Alpaca-style and instruction-included version of the ParsiNLU original dataset.\n","first_N":5,"first_N_keywords":["translation","Persian","English","cc-by-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"entity-attribute-sft-dataset-GPT-4.0-generated-v1","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BaSalam/entity-attribute-sft-dataset-GPT-4.0-generated-v1","creator_name":"BaSalam","creator_url":"https://huggingface.co/BaSalam","description":"\n\t\n\t\t\n\t\tEntity Attribute Dataset 50k (GPT-4.0 Generated)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Entity Attribute SFT Dataset (GPT-4.0 Generated) is a machine-generated dataset designed for instruction fine-tuning. It includes detailed product information generated based on the title of each product, aiming to create a structured catalog in JSON format. The dataset encompasses a variety of product categories such as food, home and kitchen, clothing, handicrafts, tools, automotive equipment, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BaSalam/entity-attribute-sft-dataset-GPT-4.0-generated-v1.","first_N":5,"first_N_keywords":["text-generation","feature-extraction","Persian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"econ_paper_abstracts_fa_translation","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mabidan/econ_paper_abstracts_fa_translation","creator_name":"Navid Abbaspoor","creator_url":"https://huggingface.co/mabidan","description":"mabidan/econ_paper_abstracts_fa_translation dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","English","Persian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"nomiracl-instruct","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/nomiracl-instruct","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\n\t\n\t\t\n\t\tDataset Card for NoMIRACL (EMNLP 2024 Findings Track)\n\t\n\n\n\t\n\t\t\n\t\tQuick Overview\n\t\n\nThis repository contains the fine-tuning (training & development split) of the NoMIRACL instruct dataset for fine-tuning LLMs on multilingual relevance assessment.\nThe training dataset is a binary classification task; they need to explicitly output either Yes, answer is present or I don't know. \nThe dataset contains training pairs from all 18 languages for both splits: relevant & non-relevant.\nimport‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miracl/nomiracl-instruct.","first_N":5,"first_N_keywords":["text-classification","text-generation","Arabic","Bengali","German"],"keywords_longer_than_N":true},
	{"name":"Par30Games_UncleanDataSet","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/thecodez/Par30Games_UncleanDataSet","creator_name":"TheCodeZ","creator_url":"https://huggingface.co/thecodez","description":"\n\t\n\t\t\n\t\tPAR30GAME Infromation\n\t\n\nScrap Data: from 300 pages, about titles andtimes and size and links and categorical.\nLink to Paper: GitHub: WebScraper\n","first_N":5,"first_N_keywords":["English","Persian","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"soft98_UncleanDataSet","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/thecodez/soft98_UncleanDataSet","creator_name":"TheCodeZ","creator_url":"https://huggingface.co/thecodez","description":"\n\t\n\t\t\n\t\tSOFT98 Infromation\n\t\n\nScrap Data: from 200 pages, about titles andauthors and view and time and categorical.\nLink to Paper: GitHub: WebScraper\n","first_N":5,"first_N_keywords":["English","Persian","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"VGDL_GAME_UncleanDataSet","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/thecodez/VGDL_GAME_UncleanDataSet","creator_name":"TheCodeZ","creator_url":"https://huggingface.co/thecodez","description":"\n\t\n\t\t\n\t\n\t\n\t\tVGDL Infromation\n\t\n\nScrap Data: from 200 pages, about titles andtime and view and links and categorical.\nLink to Paper: GitHub: WebScraper\n","first_N":5,"first_N_keywords":["English","Persian","mit","üá∫üá∏ Region: US","VGDL"],"keywords_longer_than_N":true},
	{"name":"VGDL_GAME_UncleanDataSet","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/thecodez/VGDL_GAME_UncleanDataSet","creator_name":"TheCodeZ","creator_url":"https://huggingface.co/thecodez","description":"\n\t\n\t\t\n\t\n\t\n\t\tVGDL Infromation\n\t\n\nScrap Data: from 200 pages, about titles andtime and view and links and categorical.\nLink to Paper: GitHub: WebScraper\n","first_N":5,"first_N_keywords":["English","Persian","mit","üá∫üá∏ Region: US","VGDL"],"keywords_longer_than_N":true},
	{"name":"wikipedia-2024-06-bge-m3","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3","creator_name":"Upstash","creator_url":"https://huggingface.co/Upstash","description":"\n\t\n\t\t\n\t\tWikipedia Embeddings with BGE-M3\n\t\n\nThis dataset contains embeddings from the\nJune 2024 Wikipedia dump\nfor the 11 most popular languages.\nThe embeddings are generated with the multilingual\nBGE-M3 model.\nThe dataset consists of Wikipedia articles split into paragraphs,\nand embedded with the aforementioned model.\nTo enhance search quality, the paragraphs are prefixed with their\nrespective article titles before embedding.\nAdditionally, paragraphs containing fewer than 100 characters‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3.","first_N":5,"first_N_keywords":["English","German","Spanish","Persian","French"],"keywords_longer_than_N":true},
	{"name":"orpo-dpo-mix-40k-FA","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ihavebraindamage/orpo-dpo-mix-40k-FA","creator_name":"Guy","creator_url":"https://huggingface.co/ihavebraindamage","description":"Dataset is taken from mlabonne/orpo-dpo-mix-40k, then machine translated to Persian.\n","first_N":5,"first_N_keywords":["text-generation","Persian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Persian-NER-Dataset-500k","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mansoorhamidzadeh/Persian-NER-Dataset-500k","creator_name":"mansoor hamidzadeh","creator_url":"https://huggingface.co/mansoorhamidzadeh","description":"\n\t\n\t\t\n\t\tPersian-NER-Dataset-500k\n\t\n\nThis repository contains a comprehensive Persian Named Entity Recognition (NER) dataset with approximately 500,000 tokens. This dataset is a collection of all available Persian NER datasets, carefully cleaned and consolidated to ensure the highest quality for training, validating, and testing NER models in the Persian language. The dataset is divided into three subsets: training, validation, and test.\n\n\t\n\t\t\n\t\tUpdating...\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mansoorhamidzadeh/Persian-NER-Dataset-500k.","first_N":5,"first_N_keywords":["token-classification","Persian","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Persian-NER-Dataset-500k","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mansoorhamidzadeh/Persian-NER-Dataset-500k","creator_name":"mansoor hamidzadeh","creator_url":"https://huggingface.co/mansoorhamidzadeh","description":"\n\t\n\t\t\n\t\tPersian-NER-Dataset-500k\n\t\n\nThis repository contains a comprehensive Persian Named Entity Recognition (NER) dataset with approximately 500,000 tokens. This dataset is a collection of all available Persian NER datasets, carefully cleaned and consolidated to ensure the highest quality for training, validating, and testing NER models in the Persian language. The dataset is divided into three subsets: training, validation, and test.\n\n\t\n\t\t\n\t\tUpdating...\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mansoorhamidzadeh/Persian-NER-Dataset-500k.","first_N":5,"first_N_keywords":["token-classification","Persian","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"XL-HeadTags","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/faisaltareque/XL-HeadTags","creator_name":"Faisal Tareque Shohan","creator_url":"https://huggingface.co/faisaltareque","description":"\n\t\n\t\t\n\t\tDataset Card for XL-HeadTags Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Source\n\t\n\nWe have used M3LS and XL-Sum as source for this dataset.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n We provide XL-HeadTags, a large-scale news headline and tags generation dataset. The dataset consists of 20 languages across six diverse language families. It contains 415K news headline-article pairs with auxiliary information such as image captions, topic words (read more).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nOne‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/faisaltareque/XL-HeadTags.","first_N":5,"first_N_keywords":["summarization","sentence-similarity","English","Portuguese","Spanish"],"keywords_longer_than_N":true},
	{"name":"NER_Persian_Wikipedia_1M","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mohammdrezasajjadi/NER_Persian_Wikipedia_1M","creator_name":"Mohammad Reza Sajjadi","creator_url":"https://huggingface.co/Mohammdrezasajjadi","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mohammdrezasajjadi/NER_Persian_Wikipedia_1M.","first_N":5,"first_N_keywords":["token-classification","Persian","apache-2.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"Mana-TTS","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MahtaFetrat/Mana-TTS","creator_name":"Mahta Fetrat","creator_url":"https://huggingface.co/MahtaFetrat","description":"\n\t\n\t\t\n\t\tManaTTS-Persian-Speech-Dataset\n\t\n\nManaTTS is the largest publicly available single-speaker Persian corpus, comprising over 114 hours of high-quality audio (sampled at 44.1 kHz). Released under the permissive CC-0 license, this dataset is freely usable for both educational and commercial purposes.  \nCollected from Nasl-e-Mana magazine, the dataset covers a diverse range of topics, making it ideal for training robust text-to-speech (TTS) models. The release includes a fully transparent‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahtaFetrat/Mana-TTS.","first_N":5,"first_N_keywords":["Persian","cc0-1.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"Mana-TTS","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MahtaFetrat/Mana-TTS","creator_name":"Mahta Fetrat","creator_url":"https://huggingface.co/MahtaFetrat","description":"\n\t\n\t\t\n\t\tManaTTS-Persian-Speech-Dataset\n\t\n\nManaTTS is the largest publicly available single-speaker Persian corpus, comprising over 114 hours of high-quality audio (sampled at 44.1 kHz). Released under the permissive CC-0 license, this dataset is freely usable for both educational and commercial purposes.  \nCollected from Nasl-e-Mana magazine, the dataset covers a diverse range of topics, making it ideal for training robust text-to-speech (TTS) models. The release includes a fully transparent‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahtaFetrat/Mana-TTS.","first_N":5,"first_N_keywords":["Persian","cc0-1.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NTREXBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNTREX is a News Test References dataset for Machine Translation Evaluation, covering translation from English into 128 languages. We select language pairs according to the M2M-100 language grouping strategy, resulting in 1916 directions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/davidstap/NTREX\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","translated","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"ganjoor","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mabidan/ganjoor","creator_name":"Navid Abbaspoor","creator_url":"https://huggingface.co/mabidan","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis is the csv format of the Ganjoor Database that is published in their github\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nCurated by: Navid Abbaspoor\nLanguage(s) (NLP): Persian (Farsi)\nLicense: Creative Commons Attribution 4.0 International (cc-by-4.0)\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThis dataset contains almost all of poems by Iran's great poets through many many past years till now. The original database was tabular, that I convert it to a csv format that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mabidan/ganjoor.","first_N":5,"first_N_keywords":["text-generation","Persian","cc-by-4.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"ganjoor","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mabidan/ganjoor","creator_name":"Navid Abbaspoor","creator_url":"https://huggingface.co/mabidan","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis is the csv format of the Ganjoor Database that is published in their github\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nCurated by: Navid Abbaspoor\nLanguage(s) (NLP): Persian (Farsi)\nLicense: Creative Commons Attribution 4.0 International (cc-by-4.0)\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThis dataset contains almost all of poems by Iran's great poets through many many past years till now. The original database was tabular, that I convert it to a csv format that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mabidan/ganjoor.","first_N":5,"first_N_keywords":["text-generation","Persian","cc-by-4.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"xm3600","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\nIt also includes the image features as PIL Image and has a uniform and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xm3600_1k","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600 - 1K Split\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a 1K split of XM3600!\n\t\n\nFor this, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"sentiment","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mansoorhamidzadeh/sentiment","creator_name":"mansoor hamidzadeh","creator_url":"https://huggingface.co/mansoorhamidzadeh","description":"\n\t\n\t\t\n\t\tSentiment Analysis Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe \"mansoorhamidzadeh/sentiment\" dataset is designed for sentiment analysis tasks. It contains text data labeled with sentiments, which can be used to train and evaluate models for binary sentiment classification (positive or negative).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tColumns\n\t\n\nThe dataset consists of the following columns:\n\ntext: The text content of the review or comment.\nlabel: The sentiment label associated with the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mansoorhamidzadeh/sentiment.","first_N":5,"first_N_keywords":["text-classification","Persian","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"sentiment","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mansoorhamidzadeh/sentiment","creator_name":"mansoor hamidzadeh","creator_url":"https://huggingface.co/mansoorhamidzadeh","description":"\n\t\n\t\t\n\t\tSentiment Analysis Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe \"mansoorhamidzadeh/sentiment\" dataset is designed for sentiment analysis tasks. It contains text data labeled with sentiments, which can be used to train and evaluate models for binary sentiment classification (positive or negative).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tColumns\n\t\n\nThe dataset consists of the following columns:\n\ntext: The text content of the review or comment.\nlabel: The sentiment label associated with the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mansoorhamidzadeh/sentiment.","first_N":5,"first_N_keywords":["text-classification","Persian","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"bslm-product-entity-cls-610k","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BaSalam/bslm-product-entity-cls-610k","creator_name":"BaSalam","creator_url":"https://huggingface.co/BaSalam","description":"\n\t\n\t\t\n\t\tBasalam Products Entity Classification 610k\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created for the experimental task and evaluation of trainees. The classes, which number up to 61k, are part of Basalam's product entities, and there are almost 10 products for each entity in this dataset. The products of this dataset are categories of food, clothing, handicrafts, home and kitchen appliances, vehicle tools and equipment, cosmetics, etc.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BaSalam/bslm-product-entity-cls-610k.","first_N":5,"first_N_keywords":["text-classification","Persian","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"x-fact","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"x-fact\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while the language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact.","first_N":5,"first_N_keywords":["text-classification","Arabic","Bengali","Spanish","Persian"],"keywords_longer_than_N":true},
	{"name":"persian-dpo","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/myrkur/persian-dpo","creator_name":"Amir Masoud Ahmadi","creator_url":"https://huggingface.co/myrkur","description":"\n\t\n\t\t\n\t\tPersian Alpaca Preference Dataset\n\t\n\n\nThis repository contains the Persian translation of the original Alpaca dataset, along with additional preference data generated using the LLama3 70B model. The dataset has been prepared for language model alignment using Direct Preference Optimization (DPO) or similar methods. It consists of approximately 39,000 Persian records.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tOriginal Alpaca Dataset\n\t\n\nThe Alpaca dataset is a collection of text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/myrkur/persian-dpo.","first_N":5,"first_N_keywords":["text-generation","Persian","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"persian-alpaca-deep-clean","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/myrkur/persian-alpaca-deep-clean","creator_name":"Amir Masoud Ahmadi","creator_url":"https://huggingface.co/myrkur","description":"\n\t\n\t\t\n\t\tPersian Alpaca Deep Clean\n\t\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Persian Alpaca Dataset is a collection of finely cleaned Persian language records derived from various sources, primarily the Bactrian, PN-Summary (summarization), and PEYMA (Named Entity Recognition) datasets. The dataset comprises approximately 68,279 records after rigorous cleaning processes, including character normalization, removal of Arabic letters, elimination of sentences with high word repetition, removal of words with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/myrkur/persian-alpaca-deep-clean.","first_N":5,"first_N_keywords":["text-generation","summarization","token-classification","Persian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"GPT-4","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/explorewithai/GPT-4","creator_name":"AIEXPLORE","creator_url":"https://huggingface.co/explorewithai","description":"explorewithai/GPT-4 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Persian","mit"],"keywords_longer_than_N":true},
	{"name":"Iran_Driving_licence_test","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ckodser/Iran_Driving_licence_test","creator_name":"Arshia Soltani Moakhar","creator_url":"https://huggingface.co/ckodser","description":"ckodser/Iran_Driving_licence_test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Persian","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"machine_translation_daily_dialog_en_fa","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ordaktaktak/machine_translation_daily_dialog_en_fa","creator_name":"Saeed Biabani","creator_url":"https://huggingface.co/ordaktaktak","description":"ordaktaktak/machine_translation_daily_dialog_en_fa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","English","Persian","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"Todo - Write dataset card\n","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"GPTInformal-Persian","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MahtaFetrat/GPTInformal-Persian","creator_name":"Mahta Fetrat","creator_url":"https://huggingface.co/MahtaFetrat","description":"\n\t\n\t\t\n\t\tGPTInformal Persian\n\t\n\n\nGPTInformal Persian is a Persian dataset of 6+ hours of audio and text pairs designed for speech synthesis and other speech-related tasks. The dataset has been collected, processed, and annotated as a part of the Mana-TTS project. For details on data processing pipeline and statistics, please refer to the paper in the Citation secition.\n\n\t\n\t\t\n\t\n\t\n\t\tData Source\n\t\n\nThe text for this dataset was generated using GPT4o, with prompts covering a wide range of subjects‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahtaFetrat/GPTInformal-Persian.","first_N":5,"first_N_keywords":["cc0-1.0","1K - 10K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"farm-persian","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mahdavi70/farm-persian","creator_name":"mohammad mahdavi","creator_url":"https://huggingface.co/mahdavi70","description":"ÿØ€åÿ™ÿßÿ¥€åÿ™ ÿ≥ŸàÿßŸÑ Ÿà ÿ¨Ÿàÿßÿ® Ÿáÿß€å ⁄©ÿ¥ÿßŸàÿ±ÿ≤€å ÿ≠Ÿàÿ≤Ÿá ÿ™ÿÆÿµÿµ€å ÿ®ÿ±ŸÜÿ¨\n","first_N":5,"first_N_keywords":["Persian","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"product-database","keyword":"persian","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\n\t\n\t\t\n\t\tOpen Food Facts Database\n\t\n\n\n\t\n\t\t\n\t\tWhat is üçä Open Food Facts?\n\t\n\n\n\t\n\t\t\n\t\tA food products database\n\t\n\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\n\n\t\n\t\t\n\t\tMade by everyone\n\t\n\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"persian_word_vowels_pronunciations","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/developer-ninja/persian_word_vowels_pronunciations","creator_name":"momo titi","creator_url":"https://huggingface.co/developer-ninja","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/developer-ninja/persian_word_vowels_pronunciations.","first_N":5,"first_N_keywords":["Persian","Arabic","apache-2.0","üá∫üá∏ Region: US","language"],"keywords_longer_than_N":true},
	{"name":"question_answering","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/azizmatin/question_answering","creator_name":"Aziz Matin","creator_url":"https://huggingface.co/azizmatin","description":"\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThis Question Answering dataset is a reading comprehension resource derived from Persian Wikipedia. This crowd-sourced dataset contains over 9,000 entries, each of which can either be an unanswerable question or a question with one or more answers based on the provided context. Similar to the SQuAD2.0 dataset, the inclusion of unanswerable questions allows for the development of systems that \"know they don't know the answer.\" Additionally, the dataset includes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/azizmatin/question_answering.","first_N":5,"first_N_keywords":["question-answering","monolingual","Persian","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"m-ArenaHard","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/m-ArenaHard","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for m-ArenaHard\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-ArenaHard.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"mauxi-mix-persian","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xmanii/mauxi-mix-persian","creator_name":"mani mirzaei","creator_url":"https://huggingface.co/xmanii","description":"\n\t\n\t\t\n\t\tüó£Ô∏è MauxiMix: High-Quality Persian Conversations Dataset üáÆüá∑\n\t\n\n\n\t\n\t\t\n\t\tüìù Description\n\t\n\nMauxiMix is a carefully curated dataset of 1,000 high-quality Persian conversations, translated from the SmolTalk dataset using advanced language models. This dataset is specifically designed for training and fine-tuning Large Language Models (LLMs) with Supervised Fine-Tuning (SFT) techniques, contributing to the development of open-source Persian language models.\nüöß Work in Progress: Expanding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xmanii/mauxi-mix-persian.","first_N":5,"first_N_keywords":["translation","text-generation","Persian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"mauxi-mix-persian","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xmanii/mauxi-mix-persian","creator_name":"mani mirzaei","creator_url":"https://huggingface.co/xmanii","description":"\n\t\n\t\t\n\t\tüó£Ô∏è MauxiMix: High-Quality Persian Conversations Dataset üáÆüá∑\n\t\n\n\n\t\n\t\t\n\t\tüìù Description\n\t\n\nMauxiMix is a carefully curated dataset of 1,000 high-quality Persian conversations, translated from the SmolTalk dataset using advanced language models. This dataset is specifically designed for training and fine-tuning Large Language Models (LLMs) with Supervised Fine-Tuning (SFT) techniques, contributing to the development of open-source Persian language models.\nüöß Work in Progress: Expanding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xmanii/mauxi-mix-persian.","first_N":5,"first_N_keywords":["translation","text-generation","Persian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"open-dict-words-ipa","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","description":"\n\t\n\t\t\n\t\tOpen-dict Words IPA\n\t\n\nThis dataset is a copy of https://github.com/open-dict-data/ipa-dict\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nIPA data is currently available for the following languages:\n\n\t\n\t\t\nLanguage\nCode\n\n\n\t\t\nar\nArabic (Modern Standard)\n\n\nde\nGerman\n\n\nen_UK\nEnglish (Received Pronunciation)\n\n\nen_US\nEnglish (General American)\n\n\neo\nEsperanto\n\n\nes_ES\nSpanish (Spain)\n\n\nes_MX\nSpanish (Mexico)\n\n\nfa\nPersian\n\n\nfi\nFinnish\n\n\nfr_FR\nFrench (France)\n\n\nfr_QC\nFrench (Qu√©bec)\n\n\nis\nIcelandic\n\n\nja\nJapanese\n\n\njam‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa.","first_N":5,"first_N_keywords":["Arabic","German","English","Esperanto","Spanish"],"keywords_longer_than_N":true},
	{"name":"MSTS","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/felfri/MSTS","creator_name":"Felix Friedrich","creator_url":"https://huggingface.co/felfri","description":"\n\t\n\t\t\n\t\tDisclaimer\n\t\n\nThe MSTS dataset contains content that may be offensive or upsetting in nature. Topics include, but are not limited to, discriminatory language and discussions of abuse, violence, self-harm, exploitation, and other potentially upsetting subject matter. \nPlease only engage with the data in accordance with your own personal risk tolerance. The data are intended for research purposes, especially research that can make models less harmful.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/felfri/MSTS.","first_N":5,"first_N_keywords":["image-text-to-text","English","Arabic","French","German"],"keywords_longer_than_N":true},
	{"name":"HLSNKIOPUS100","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Maani/HLSNKIOPUS100","creator_name":"Masoud Maani","creator_url":"https://huggingface.co/Maani","description":"\n\t\n\t\t\n\t\tDataset Card for HLSNKIOPUS100\n\t\n\nThis dataset contains English-Persian translation pairs from the OPUS-100 corpus. \nThe original corpus of OPUS-100 is movie dialogues and gets repetitive really fast, \nit also contains duplicates, false translations and huge chunks of unrelated data,\nmaking the dataset very noisy and almost unsuitable for any use. \n\n\t\n\t\t\n\t\t\n\t\n\nWe have deduplicated, denoised, deislamified and cleaned the dataset, reviewed the translations, \nretranslated and cleared the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Maani/HLSNKIOPUS100.","first_N":5,"first_N_keywords":["English","Persian","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"FarsInstruct","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PNLPhub/FarsInstruct","creator_name":"Persian NLP Hub","creator_url":"https://huggingface.co/PNLPhub","description":"\n\t\n\t\t\n\t\tNews\n\t\n\n\n[2025.01.20] üèÜ Our paper was nominated as the best paper at LowResLM @ COLING 2025!\n[2024.12.07] ‚ú® Our paper has been accepted for oral presentation at LowResLM @ COLING 2025!\n\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nInstruction-tuned large language models have demonstrated remarkable capabilities in following human instructions across various domains. However, their proficiency remains notably deficient in many low-resource languages. To address this challenge, we begin by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PNLPhub/FarsInstruct.","first_N":5,"first_N_keywords":["text-classification","question-answering","translation","text-generation","Persian"],"keywords_longer_than_N":true},
	{"name":"OLDI-Wikipedia-MTSeed-Persian","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Reza2kn/OLDI-Wikipedia-MTSeed-Persian","creator_name":"Reza Sayar","creator_url":"https://huggingface.co/Reza2kn","description":"\n\t\n\t\t\n\t\tWikipedia Seed Machine Translation Data in Persian\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nPersian (Farsi) translation of >6000 English sentences originally from Wikipedia articles, included in the OLDI machine translation seed dataset.\n\n\t\n\t\t\n\t\tWorkflow\n\t\n\n\n\nI used the Gemini 1.5 Flash model over API to translate the original seed dataset in English, using an iterative approach, trying out with different prompt format / templates, models, etc.\n Next step was to feed the initial translated data back‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Reza2kn/OLDI-Wikipedia-MTSeed-Persian.","first_N":5,"first_N_keywords":["Persian","cc-by-sa-4.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Achinese","Adyghe"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/include-lite-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tINCLUDE-lite (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-lite-44.","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"tamin","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zargar4194/tamin","creator_name":"zargar","creator_url":"https://huggingface.co/zargar4194","description":"zargar4194/tamin dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Persian","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Achinese","Adyghe"],"keywords_longer_than_N":true},
	{"name":"rel_dataset","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m522t/rel_dataset","creator_name":"Mehrshad Taji","creator_url":"https://huggingface.co/m522t","description":"m522t/rel_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","Persian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/include-base-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tINCLUDE-base (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-base-44.","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"mauxitalk-persian","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xmanii/mauxitalk-persian","creator_name":"mani mirzaei","creator_url":"https://huggingface.co/xmanii","description":"\n\t\n\t\t\n\t\tüó£Ô∏è MauxiTalk: High-Quality Persian Conversations Dataset üáÆüá∑\n\t\n\n\n\t\n\t\t\n\t\tüìù Description\n\t\n\nMauxiTalk is a high-quality dataset of 2,000+ Persian conversations, carefully translated from the SmolTalk dataset using state-of-the-art language models. This dataset is specifically curated for training and fine-tuning Large Language Models (LLMs) with Supervised Fine-Tuning (SFT) techniques.\n\n\t\n\t\t\n\t\tüåü Key Features\n\t\n\n\n2,000 natural conversations in Persian\nDiverse topics including daily‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xmanii/mauxitalk-persian.","first_N":5,"first_N_keywords":["text-generation","summarization","Persian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"mauxitalk-persian","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xmanii/mauxitalk-persian","creator_name":"mani mirzaei","creator_url":"https://huggingface.co/xmanii","description":"\n\t\n\t\t\n\t\tüó£Ô∏è MauxiTalk: High-Quality Persian Conversations Dataset üáÆüá∑\n\t\n\n\n\t\n\t\t\n\t\tüìù Description\n\t\n\nMauxiTalk is a high-quality dataset of 2,000+ Persian conversations, carefully translated from the SmolTalk dataset using state-of-the-art language models. This dataset is specifically curated for training and fine-tuning Large Language Models (LLMs) with Supervised Fine-Tuning (SFT) techniques.\n\n\t\n\t\t\n\t\tüåü Key Features\n\t\n\n\n2,000 natural conversations in Persian\nDiverse topics including daily‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xmanii/mauxitalk-persian.","first_N":5,"first_N_keywords":["text-generation","summarization","Persian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Deltacorpus_1.1","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\n[!NOTE]\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, Portoro≈æ, Slovenia).\nChanges in version 1.1: \n\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \n\nSVM classifier trained on Universal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1.","first_N":5,"first_N_keywords":["token-classification","multilingual","Afrikaans","Albanian","Amharic"],"keywords_longer_than_N":true},
	{"name":"AYAPA","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Maani/AYAPA","creator_name":"Masoud Maani","creator_url":"https://huggingface.co/Maani","description":"\n\t\n\t\t\n\t\tDataset Card for AYAPA\n\t\n\nThis dataset contains Persian pairs of question-answer from the aya dataset corpus.\nThis dataset has been throughly denoised, cleaned, deduplicated and deislamified.\nPayande Iran.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: CohereForAI/aya_dataset\nLanguage: Persian (fa)\nFormat: Each example contains an instruction, and output.\n\n","first_N":5,"first_N_keywords":["Persian","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"alpaca_persian_telegram","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mshojaei77/alpaca_persian_telegram","creator_name":"Mohammad Shojaei","creator_url":"https://huggingface.co/mshojaei77","description":"\n\t\n\t\t\n\t\tPersian Telegram Channel Topic Classification Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for topic classification of Persian text from Telegram channels. It contains a curated collection of Persian text samples along with their corresponding main topics, created using GPT-4 for topic identification.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nName: Persian Telegram Channel Topic Classification Dataset\nVersion: 1.0\nSize: 1000 samples\nLanguage: Persian (Farsi)\nSource: Derived‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mshojaei77/alpaca_persian_telegram.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","question-answering","Persian","mit"],"keywords_longer_than_N":true},
	{"name":"ALPACA.PERSIANCODED","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Maani/ALPACA.PERSIANCODED","creator_name":"Masoud Maani","creator_url":"https://huggingface.co/Maani","description":"\n\t\n\t\t\n\t\tDataset Card for ALPACA.PERSIANCODED\n\t\n\nThis dataset is a subset of Alpaca corpus translated and Persian coded with special care, adding the cultural touch to your ML solution. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: yahma/alpaca-cleaned\nLanguages: Persian (fa)\nFormat: Each example contains an instruction, input, and output.\n\n","first_N":5,"first_N_keywords":["Persian","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\nsource: the source sentence.\nchosen: the preferred translation.\nreject: the dis-preferred translation.\ndirections: the translation direction.\n@misc{xu2024xalmaplugplay,\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\n      year={2024},\n      eprint={2410.03115}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Question-Sparql","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/julioc-p/Question-Sparql","creator_name":"Julio Perez","creator_url":"https://huggingface.co/julioc-p","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 895,954 examples of natural language questions paired with their corresponding SPARQL queries. It spans 12 languages and targets 15 distinct knowledge graphs, with a significant portion focused on Wikidata and DBpedia.\nThe dataset was developed as a contribution for the Master Thesis: \"Impact of Continual Multilingual Pre-training on Cross-Lingual Transferability for Source Languages\". Its purpose is to facilitate research in text-to-SPARQL‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/julioc-p/Question-Sparql.","first_N":5,"first_N_keywords":["text-generation","English","German","Hebrew","Kannada"],"keywords_longer_than_N":true},
	{"name":"EduViQA","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UIAIC/EduViQA","creator_name":"University of Isfahan Artificial Intelligence Community","creator_url":"https://huggingface.co/UIAIC","description":"\n\t\n\t\t\n\t\tDataset Card for EduVQA-Alpha\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEduVQA-Alpha is a multilingual educational dataset designed for video question-answering (VideoQA). It consists of academic videos, annotated with synthetic question-answer (QA) pairs, in English and Persian. Videos are curated to reflect diverse academic topics and teaching styles, supporting multilingual Retrieval-Augmented Generation (RAG) tasks.\nThe dataset employs CLIP-SSIM Adaptive Chunking for video segmentation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UIAIC/EduViQA.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","generated","original","English"],"keywords_longer_than_N":true},
	{"name":"mu-shroom","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/mu-shroom","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\n\t\n\t\t\n\t\tThe Mu-SHROOM dataset for Multilingual Hallucination and Overgeneration detection.\n\t\n\nMu-SHROOM: Multilingual Shared-task on Hallucinations and Related Observable Overgeneration Mistakes and Related Observable Overgeneration Mistakes\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMu-SHROOM is a multilingual dataset for detecting hallucination spans in LLM outputs across 14 languages. It was created for SemEval-2025 Task 3.\ndisclaimer: Mu-SHROOM is not properly a fact-checking dataset, but we mark is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/mu-shroom.","first_N":5,"first_N_keywords":["token-classification","fact-checking","Arabic","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"shahnameh-tajik-corpus","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ArabovMK/shahnameh-tajik-corpus","creator_name":"Arabov Mullosharaf","creator_url":"https://huggingface.co/ArabovMK","description":"\n\t\n\t\t\n\t\tüìö Shahnameh in Tajik (Updated Version)\n\t\n\nThis dataset contains the full Tajik translation of the Persian epic poem Shahnameh by Abulqosim Firdausi. It is suitable for literary research, linguistic analysis, and NLP model training.\n\n\n\t\n\t\t\n\t\tüìÑ Example record\n\t\n\n{\n  \"title\": \"–®–æ“≥–Ω–æ–º–∞ “∑–∏–ª–¥–∏ 3\",\n  \"author\": \"–ê–±—É–ª“õ–æ—Å–∏–º –§.\",\n  \"language\": \"tajik\",\n  \"content\": \"–ë–∞ –Ω–æ–º–∏ –•—É–¥–æ–≤–∞–Ω–¥–∏ “∑–æ–Ω—É —Ö–∏—Ä–∞–¥, \n –ö-–∞–∑ –∏–Ω –±–∞—Ä—Ç–∞—Ä –∞–Ω–¥–µ—à–∞ –±–∞—Ä–Ω–∞–≥–∑–∞—Ä–∞–¥....\"\n}\n\n\n\n\t\n\t\n\t\n\t\tüì¶ Usage\n\t\n\nfrom datasets importload_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArabovMK/shahnameh-tajik-corpus.","first_N":5,"first_N_keywords":["Tajik","Persian","cc-by-sa-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"PashtoOCR","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zirak-ai/PashtoOCR","creator_name":"Zirak","creator_url":"https://huggingface.co/zirak-ai","description":"\n\t\n\t\t\n\t\tPsOCR - Pashto OCR Dataset\n\t\n\n\n    \n\n\n        üåê Zirak.ai\n          ¬†¬† | ¬†¬†ü§ó HuggingFace\n          ¬†¬† | ¬†¬† GitHub\n          ¬†¬† | ¬†¬† Kaggle\n          ¬†¬† | ¬†¬†üìë Paper\n\n\nPsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language\nThe dataset is also available at: https://www.kaggle.com/datasets/drijaz/PashtoOCR\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\n\nPsOCR is a large-scale synthetic dataset for Optical Character Recognition in low-resource Pashto‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zirak-ai/PashtoOCR.","first_N":5,"first_N_keywords":["text-generation","Pashto","Arabic","English","Persian"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","description":"\n\n\n\t\n\t\t\n\t\tüî∑ Accepted in NAACL Proceedings (2025) üî∑\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval üìö [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gpt4o_gen","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gpt4o_gen","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gpt4o_gen dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"driving_licence_with_image","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ckodser/driving_licence_with_image","creator_name":"Arshia Soltani Moakhar","creator_url":"https://huggingface.co/ckodser","description":"ckodser/driving_licence_with_image dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Persian","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Saka-Alpaca-v1","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Saka-Alpaca-v1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"https://chatgpt.com\n","first_N":5,"first_N_keywords":["text-generation","Swedish","Norwegian","Finnish","German"],"keywords_longer_than_N":true},
	{"name":"Bonyad_Vokala_Legal_QA_Dataset","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Marykka/Bonyad_Vokala_Legal_QA_Dataset","creator_name":"maryk","creator_url":"https://huggingface.co/Marykka","description":"\n\t\n\t\t\n\t\tüìö Dataset Card for Bonyad Vokala Legal Q&A Dataset\n\t\n\nThis dataset contains legal Q&A in Farsi (Persian) from the Bonyad Vokala website. It includes human-written lawyer answers and AI-generated answers for each question, categorized by legal domain. It's designed to support Farsi legal NLP research üáÆüá∑‚öñÔ∏è.\n\n\n\t\n\t\t\n\t\tüßæ Dataset Details\n\t\n\n\n\t\n\t\t\n\t\tüìù Description\n\t\n\nThis dataset offers real-world legal Q&A scenarios, collected from an official Iranian legal foundation (Bonyad Vokala).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Marykka/Bonyad_Vokala_Legal_QA_Dataset.","first_N":5,"first_N_keywords":["question-answering","Persian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy It‚Äôs Important\n\t\n\n\nEnhances Trust: For readers and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"OGC_Military","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/racineai/OGC_Military","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","description":"\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\n\t\n\t\t\n\t\tMilitary Vision DSE\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nMade with https://github.com/RacineAIOS/OGC_pdf-to-parquet\nThis dataset was created by scraping PDF documents from online sources and generating relevant synthetic queries.\nWe used Google's Gemini 2.0 Flash Lite model in our custom pipeline to produce the queries, allowing us to create a diverse set of questions based on the document content.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Military.","first_N":5,"first_N_keywords":["English","French","Arabic","German","Russian"],"keywords_longer_than_N":true},
	{"name":"bijankhan-peykare-annotated","keyword":"persian","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PerSpaCor/bijankhan-peykare-annotated","creator_name":"PersianSpaceCorrector","creator_url":"https://huggingface.co/PerSpaCor","description":"\n\t\n\t\t\n\t\tPersian Space and ZWNJ Correction Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains Persian text annotated for space and Zero-Width Non-Joiner (ZWNJ) correction tasks. It consists of 424,181 examples derived from the Bijankhan and Peykare corpora. Each example includes the original sentence, tokenized text, character-level information, part-of-speech tags, and space labels.\nThe dataset is designed for training models that can automatically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PerSpaCor/bijankhan-peykare-annotated.","first_N":5,"first_N_keywords":["Persian","gpl-3.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"acl-6060","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/acl-6060","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tACL 60/60\n\t\n\n\n\t\n\t\t\n\t\tDataset details\n\t\n\nACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@inproceedings{salesky-etal-2023-evaluating,\n    title = \"Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology\",\n    author = \"Salesky, Elizabeth  and\n      Darwish, Kareem  and\n      Al-Badrashiny, Mohamed  and\n      Diab, Mona  and\n      Niehues, Jan\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/acl-6060.","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","English","Arabic","German"],"keywords_longer_than_N":true},
	{"name":"persian-natural-fluently","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/arshiaafshani/persian-natural-fluently","creator_name":"Arshia Afshani","creator_url":"https://huggingface.co/arshiaafshani","description":"\n\t\n\t\t\n\t\tPersian scientific dataset\n\t\n\nI have prepared a great and natural persian dataset of scientific datas including chemistry, physics, mathematics (including algebra & etc) , biology.\nThe content of the dataset has been generated by : Human, Grok3, DeepSeek R1.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under apache-2.0.\n","first_N":5,"first_N_keywords":["text-generation","question-answering","Persian","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"AyaVisionBench","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/AyaVisionBench","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for Aya Vision Benchmark\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/AyaVisionBench.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"m-WildVision","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/m-WildVision","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for m-WildVision\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \nThe authors demonstrated that these prompts enable automatic LLM judge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-WildVision.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"row_data","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Danielrahmai1991/row_data","creator_name":"Daniel Rahmani","creator_url":"https://huggingface.co/Danielrahmai1991","description":"In this dataset card, you can see uploaded dataset in 1024 token length. \nIf you finetunine your model with this dataset with max otken more than 1024 there is need to enable packing. \n","first_N":5,"first_N_keywords":["Persian","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Kaleidoscope","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Anonym-sub/Kaleidoscope","creator_name":"Anonymous submission","creator_url":"https://huggingface.co/Anonym-sub","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Anonym-sub/Kaleidoscope.","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"Collection-of-drug-names-in-Persian","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dadashzadeh/Collection-of-drug-names-in-Persian","creator_name":"dadashzadeh","creator_url":"https://huggingface.co/dadashzadeh","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nA collection of drug names in Persian\n\nLanguage(s) (NLP): persian\n\n","first_N":5,"first_N_keywords":["text-classification","text-retrieval","Persian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"coco-pic","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rasoulasadianub/coco-pic","creator_name":"rasoul asadian","creator_url":"https://huggingface.co/rasoulasadianub","description":"rasoulasadianub/coco-pic dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["image-to-text","image-classification","Persian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"mauxi-COT-Persian","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xmanii/mauxi-COT-Persian","creator_name":"mani mirzaei","creator_url":"https://huggingface.co/xmanii","description":"\n\t\n\t\t\n\t\tüß† mauxi-COT-Persian Dataset\n\t\n\n\nExploring Persian Chain-of-Thought Reasoning with DeepSeek-R1, brought to you by Mauxi AI Platform\n\n\n\t\n\t\t\n\t\tüåü Overview\n\t\n\nmauxi-COT-Persian is a community-driven dataset that explores the capabilities of advanced language models in generating Persian Chain-of-Thought (CoT) reasoning. The dataset is actively growing with new high-quality, human-validated entries being added regularly. I am personally working on expanding this dataset with rigorously‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xmanii/mauxi-COT-Persian.","first_N":5,"first_N_keywords":["question-answering","Persian","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"physics11_hard","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bardia1383/physics11_hard","creator_name":"Bardia Soltani Moakhar","creator_url":"https://huggingface.co/bardia1383","description":"bardia1383/physics11_hard dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Persian","apache-2.0","n<1K","Image","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"physics_geology","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/setayeshheydari1010/physics_geology","creator_name":"Setayesh Heydari","creator_url":"https://huggingface.co/setayeshheydari1010","description":"setayeshheydari1010/physics_geology dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Persian","apache-2.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-Polylingo-50k","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","description":"\n\t\n\t\t\n\t\tGammaCorpus Polylingo 50k\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\nLanguage: The language used in the interaction.\n\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k.","first_N":5,"first_N_keywords":["text-generation","English","Russian","Vietnamese","German"],"keywords_longer_than_N":true},
	{"name":"iranian-social-norms-dataset","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hamiids/iranian-social-norms-dataset","creator_name":"Hamidreza Saffari","creator_url":"https://huggingface.co/hamiids","description":"\n\t\n\t\t\n\t\tIranian Social Norms (ISN) Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Iranian Social Norms (ISN) dataset is a curated collection of social norms specific to Iranian culture. It provides a rich resource for studying cultural norms and their variations across different demographic groups. By incorporating demographic context, such as age, gender, ethnicity, and religion, this dataset enables a nuanced exploration of social expectations within Iranian society.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hamiids/iranian-social-norms-dataset.","first_N":5,"first_N_keywords":["text-classification","English","Persian","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSynthdog Multilingual\n\t\n\n\n\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"kaleidoscope","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/kaleidoscope","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/kaleidoscope.","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"Musa-FA_EN-Public-Phone-Audio-Dataset","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mah92/Musa-FA_EN-Public-Phone-Audio-Dataset","creator_name":"ali.mahmoudi","creator_url":"https://huggingface.co/mah92","description":"Same as: https://huggingface.co/datasets/mah92/Khadijah-FA_EN-Public-Phone-Audio-Dataset\n","first_N":5,"first_N_keywords":["Persian","English","cc0-1.0","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"persian-tweets-2024","keyword":"persian","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mshojaei77/persian-tweets-2024","creator_name":"Mohammad Shojaei","creator_url":"https://huggingface.co/mshojaei77","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains high-engagement Persian language tweets collected from Twitter/X during 2024. The dataset includes comprehensive tweet metadata and user information, making it valuable for various NLP tasks, social media analysis, and Persian language processing research.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSize: 900 tweets\nLanguage: Persian (Farsi)\nTime Period: 2024\nCollection Criteria:\nLanguage: Persian \nMinimum Likes: 1,000+ \nDate Range: January 1, 2024 -‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mshojaei77/persian-tweets-2024.","first_N":5,"first_N_keywords":["text-classification","text-generation","Persian","gpl-3.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tSMOL\n\t\n\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\ntranslations into 221 Low-Resource Languages, for the purpose of training\ntranslation models, and otherwise increasing the representations of said\nlanguages in NLP and technology.\nPlease read the SMOL Paper and the\nGATITOS Paper for a much more\nthorough description!\nThere are four resources in this directory:\n\nSmolDoc: document-level translations into 100 languages\nSmolSent: sentence-level translations into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Chat","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","description":"\n\t\n\t\t\n\t\tDATA-AI: Il Modello di IA di M.INC.\n\t\n\n\n\t\n\t\t\n\t\tüìå Introduzione\n\t\n\nDATA-AI √® un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello √® basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \nDATA-AI √® stato addestrato su un‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat.","first_N":5,"first_N_keywords":["Italian","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"MIRACLReranking","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/MIRACLReranking","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MIRACLReranking\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nEncyclopaedic, Written\n\n\nReference\nhttps://project-miracl.github.io/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MIRACLReranking.","first_N":5,"first_N_keywords":["text-ranking","expert-annotated","multilingual","miracl/mmteb-miracl","Arabic"],"keywords_longer_than_N":true},
	{"name":"Balochi-Multilingual-dataset","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Salman95s/Balochi-Multilingual-dataset","creator_name":"Salman Albalushi","creator_url":"https://huggingface.co/Salman95s","description":"\n\t\n\t\t\n\t\tBalochi Language Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a comprehensive resource for training large language models (LLMs) in the Balochi language. It is designed to go beyond basic translation tasks, supporting fully generative text and conversational AI capabilities in Balochi.\nThe dataset includes monolingual Balochi text, multilingual translation corpora, and various conversational and domain-specific texts, enabling diverse use cases such as:\n\nGenerative AI: Building‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Salman95s/Balochi-Multilingual-dataset.","first_N":5,"first_N_keywords":["text-classification","token-classification","translation","question-answering","Baluchi"],"keywords_longer_than_N":true},
	{"name":"Balochi-Multilingual-dataset","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Salman95s/Balochi-Multilingual-dataset","creator_name":"Salman Albalushi","creator_url":"https://huggingface.co/Salman95s","description":"\n\t\n\t\t\n\t\tBalochi Language Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a comprehensive resource for training large language models (LLMs) in the Balochi language. It is designed to go beyond basic translation tasks, supporting fully generative text and conversational AI capabilities in Balochi.\nThe dataset includes monolingual Balochi text, multilingual translation corpora, and various conversational and domain-specific texts, enabling diverse use cases such as:\n\nGenerative AI: Building‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Salman95s/Balochi-Multilingual-dataset.","first_N":5,"first_N_keywords":["text-classification","token-classification","translation","question-answering","Baluchi"],"keywords_longer_than_N":true},
	{"name":"2M-Belebele","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\t2M-Belebele\n\t\n\n\n\t\n\t\t\n\t\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\n\t\n\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs datasets as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.","first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Bulgarian","Panjabi","English"],"keywords_longer_than_N":true},
	{"name":"crossword-puzzle-persian-cheat","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PerSets/crossword-puzzle-persian-cheat","creator_name":"Persian Datasets","creator_url":"https://huggingface.co/PerSets","description":"\n\t\n\t\t\n\t\tCrossword Puzzle Cheat Dataset (Persian)\n\t\n\nThis dataset consists of 30157 pairs of questions and answers.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe reference for this dataset is jadvalyab.ir website.\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\nHuggingface datasets library:\nfrom datasets import load_dataset\ndataset = load_dataset('PerSets/crossword-puzzle-persian-cheat')\n\n\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nCC0-v1.0\n","first_N":5,"first_N_keywords":["question-answering","Persian","cc0-1.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"crossword-puzzle-persian-cheat","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PerSets/crossword-puzzle-persian-cheat","creator_name":"Persian Datasets","creator_url":"https://huggingface.co/PerSets","description":"\n\t\n\t\t\n\t\tCrossword Puzzle Cheat Dataset (Persian)\n\t\n\nThis dataset consists of 30157 pairs of questions and answers.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe reference for this dataset is jadvalyab.ir website.\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\nHuggingface datasets library:\nfrom datasets import load_dataset\ndataset = load_dataset('PerSets/crossword-puzzle-persian-cheat')\n\n\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nCC0-v1.0\n","first_N":5,"first_N_keywords":["question-answering","Persian","cc0-1.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\n\t\n\t\t\n\t\tlightblue/reasoning-multilingual-R1-Llama-70B-train\n\t\n\nThis is a multilingual reasoning dataset covering more than 30 languages.\nThis dataset was made by:\n\nSampling prompts from English datasets and translating them to various languages\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\n\nThis dataset was then used to train a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"HomoRich-G2P-Persian","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MahtaFetrat/HomoRich-G2P-Persian","creator_name":"Mahta Fetrat","creator_url":"https://huggingface.co/MahtaFetrat","description":"\n\t\n\t\t\n\t\tHomoRich: A Persian Homograph Dataset for G2P Conversion\n\t\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nHomoRich is the first large-scale, sentence-level Persian homograph dataset designed for grapheme-to-phoneme (G2P) conversion tasks. It addresses the scarcity of balanced, contextually annotated homograph data for low-resource languages. The dataset was created using a semi-automated pipeline combining human expertise and LLM-generated samples, as described in the paper:\"Fast, Not Fancy: Rethinking G2P‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahtaFetrat/HomoRich-G2P-Persian.","first_N":5,"first_N_keywords":["translation","text-to-speech","Persian","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"HomoRich-G2P-Persian","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MahtaFetrat/HomoRich-G2P-Persian","creator_name":"Mahta Fetrat","creator_url":"https://huggingface.co/MahtaFetrat","description":"\n\t\n\t\t\n\t\tHomoRich: A Persian Homograph Dataset for G2P Conversion\n\t\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nHomoRich is the first large-scale, sentence-level Persian homograph dataset designed for grapheme-to-phoneme (G2P) conversion tasks. It addresses the scarcity of balanced, contextually annotated homograph data for low-resource languages. The dataset was created using a semi-automated pipeline combining human expertise and LLM-generated samples, as described in the paper:\"Fast, Not Fancy: Rethinking G2P‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MahtaFetrat/HomoRich-G2P-Persian.","first_N":5,"first_N_keywords":["translation","text-to-speech","Persian","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"farsi-asr-dataset","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/farsi-asr/farsi-asr-dataset","creator_name":"Farsi ASR","creator_url":"https://huggingface.co/farsi-asr","description":"\n\n\t\n\t\t\n\t\tFarsi ASR Dataset\n\t\n\nThe largest open-source Persian Automatic Speech Recognition (ASR) dataset, collected from various sources. The codes associated with the collection of this dataset is also available in the Farsi ASR Dataset GitHub repository.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","mit","1M<n<10M","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"farsi-asr-dataset","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/farsi-asr/farsi-asr-dataset","creator_name":"Farsi ASR","creator_url":"https://huggingface.co/farsi-asr","description":"\n\n\t\n\t\t\n\t\tFarsi ASR Dataset\n\t\n\nThe largest open-source Persian Automatic Speech Recognition (ASR) dataset, collected from various sources. The codes associated with the collection of this dataset is also available in the Farsi ASR Dataset GitHub repository.\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","mit","1M<n<10M","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"Khadijah-FA_EN-Public-Phone-Audio-Dataset","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mah92/Khadijah-FA_EN-Public-Phone-Audio-Dataset","creator_name":"ali.mahmoudi","creator_url":"https://huggingface.co/mah92","description":"\nText got from here. \n\nAll chinese letters be replaced with \"chinese letter\" because espeak reads them so...\n\nRemove all persian/english single alphabet as they are not read correctly(same as espeak) by my reader...\n\nReplace these chars with space, as they where not read correctly(same as espeak) :\nüî∫\n@\n/\n)\n(\n]\n[\n‚ñ™Ô∏è\nüîπÔ∏è\nüî∑\nüî∂\nüîÜ\nüìå\n‚ö´Ô∏è\n‚Ñ¢\n‚ù§\nüèÜ\n‚óâ\nüëç\nüî•\nüò±\nüëå\nüìç\n‚úàÔ∏é\n‚òÅÔ∏é\n‚ö°Ô∏è\n‚ûñ\nüçÖ\nüòÅ\nüëá\nü§©\nüò¢\nü•∞\nüòÅ\nü§Ø\nü§≤\nüëè\nüé¨\n‚úä\nüíô\nü§ù\nüòÆ\nüòé\nüòá\nüôè\nü•Ä\n‚¨áÔ∏è‚¨áÔ∏è\nüåÄ\nüñ§\nüòµ\nüçø\nüëáüèº\nü§î\nüéâ\nü•∞\n‚úÖ\nüÜî\nüòç\nü§£\nüî¥\nü™ê\nüïä \nüóì\nüá∫üá≥\n‚ú¥Ô∏è\n\n\n\nüîπÔ∏è‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mah92/Khadijah-FA_EN-Public-Phone-Audio-Dataset.","first_N":5,"first_N_keywords":["Persian","English","cc0-1.0","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"Mauxi-SFT-Persian","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xmanii/Mauxi-SFT-Persian","creator_name":"mani mirzaei","creator_url":"https://huggingface.co/xmanii","description":"\n\t\n\t\t\n\t\tüéØ Mauxi-SFT-Persian Dataset\n\t\n\n\n\t\n\t\t\n\t\tüåü Overview\n\t\n\nWelcome to the Mauxi-SFT-Persian dataset! A high-quality Persian language dataset specifically curated for Supervised Fine-Tuning (SFT) of Large Language Models.\n\n\t\n\t\t\n\t\tüìä Dataset Statistics\n\t\n\n\nüî¢ Total Conversations: 5,000\nüìù Total Tokens: 4,418,419\nüìà Average Tokens per Conversation: 883.7\nüéØ Format: JSONL with messages and token counts\n\n\n\t\n\t\t\n\t\tüîç Source & Creation\n\t\n\nThis dataset was created by translating the OpenHermes-100k‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xmanii/Mauxi-SFT-Persian.","first_N":5,"first_N_keywords":["text-generation","Persian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Mauxi-SFT-Persian","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xmanii/Mauxi-SFT-Persian","creator_name":"mani mirzaei","creator_url":"https://huggingface.co/xmanii","description":"\n\t\n\t\t\n\t\tüéØ Mauxi-SFT-Persian Dataset\n\t\n\n\n\t\n\t\t\n\t\tüåü Overview\n\t\n\nWelcome to the Mauxi-SFT-Persian dataset! A high-quality Persian language dataset specifically curated for Supervised Fine-Tuning (SFT) of Large Language Models.\n\n\t\n\t\t\n\t\tüìä Dataset Statistics\n\t\n\n\nüî¢ Total Conversations: 5,000\nüìù Total Tokens: 4,418,419\nüìà Average Tokens per Conversation: 883.7\nüéØ Format: JSONL with messages and token counts\n\n\n\t\n\t\t\n\t\tüîç Source & Creation\n\t\n\nThis dataset was created by translating the OpenHermes-100k‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xmanii/Mauxi-SFT-Persian.","first_N":5,"first_N_keywords":["text-generation","Persian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Phone-FA-EN-AR-Dataset","keyword":"persian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mah92/Phone-FA-EN-AR-Dataset","creator_name":"ali.mahmoudi","creator_url":"https://huggingface.co/mah92","description":"\n\t\n\t\t\n\t\tÿ®ÿ≥ŸÖ ÿßŸÑŸÑŸá\n\t\n\n ÿß€åŸÜ ŸÖÿÆÿ≤ŸÜ ÿ¥ÿßŸÖŸÑ ÿØŸà ÿØÿßÿØ⁄ØÿßŸÜ ŸÅÿßÿ±ÿ≥€å-ÿßŸÜ⁄ØŸÑ€åÿ≥€å-ÿπÿ±ÿ®€å Ÿà ÿπÿ±ÿ®€å-ÿßŸÜ⁄ØŸÑ€åÿ≥€å ÿßÿ≥ÿ™ ⁄©Ÿá ÿ®Ÿá ⁄©ŸÖ⁄© €å⁄© ŸÖŸàÿ™Ÿàÿ± ÿß€å-ÿßÿ≥Ÿæ€å⁄© ÿ™ÿ∫€å€åÿ± €åÿßŸÅÿ™Ÿá ÿ¨ŸÖÿπ ÿ¢Ÿàÿ±€å ÿ¥ÿØŸá ÿßÿ≥ÿ™.\n (ÿ¥ŸÖÿß ŸÖ€å ÿ™ŸàÿßŸÜ€åÿØ ÿß€åŸÜ ÿ®ÿ±ŸÜÿßŸÖŸá ÿ±ÿß ÿØÿ± ÿß€åŸÜÿ¨ÿß  Ÿà ÿß€åŸÜÿ¨ÿß Ÿæ€åÿØÿß ⁄©ŸÜ€åÿØ)\nŸáŸÖ ⁄ÜŸÜ€åŸÜ €å⁄© ÿ±ÿßÿ®ÿ∑ ⁄©ÿßÿ±ÿ®ÿ±€å ÿ®ÿ±ÿß€å ÿ¨ŸÖÿπ ÿ¢Ÿàÿ±€å ÿØÿßÿØ⁄ØÿßŸÜ ÿµŸàÿ™€å ÿØÿ± ÿß€åŸÜÿ¨ÿß ŸÇÿ±ÿßÿ± ÿØÿßÿØŸá ÿ¥ÿØŸá ÿßÿ≥ÿ™. \n\n\t\n\t\t\n\t\n\t\n\t\tÿØÿßÿØ⁄ØÿßŸÜ ÿßŸàŸÑ (ŸÅÿßÿ±ÿ≥€å-ÿßŸÜ⁄ØŸÑ€åÿ≥€å-ÿπÿ±ÿ®€å)\n\t\n\n  ÿØÿßÿØ⁄ØÿßŸÜ ÿßŸàŸÑ (ÿØÿßÿØ⁄ØÿßŸÜ ŸÅÿßÿ±ÿ≥€å-ÿßŸÜ⁄ØŸÑ€åÿ≥€å-ÿπÿ±ÿ®€å)‚Äå ÿÆŸàÿßŸÜÿ¥ ÿ™ÿß⁄©-ÿ®⁄© €å⁄© ⁄ØŸàÿ¥€å ÿßŸÜÿØÿ±Ÿà€åÿØ€å(⁄ØÿßŸÑ⁄©ÿ≥€å ÿßÿ≥€±€∞ - ÿßŸÜÿØÿ±Ÿà€åÿØ €π) ÿßÿ≥ÿ™. \nÿß€åŸÜ ÿØ€åÿ™ÿß ÿ≥ÿ™ ÿ¥ÿßŸÖŸÑ ŸÖŸàÿßÿ±ÿØ ÿ≤€åÿ± ÿßÿ≥ÿ™:\n\nÿ≠ÿ±ŸàŸÅ ⁄©€åÿ®ÿ±ÿØ ŸÅÿßÿ±ÿ≥€å Ÿà ÿßŸÜ⁄ØŸÑ€åÿ≥€å\n\nÿ™ŸÖÿßŸÖ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mah92/Phone-FA-EN-AR-Dataset.","first_N":5,"first_N_keywords":["Persian","English","Arabic","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"persian-alpaca-reasoning-v1","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hosseinhimself/persian-alpaca-reasoning-v1","creator_name":"Hossein Mohseni","creator_url":"https://huggingface.co/hosseinhimself","description":"\n\t\n\t\t\n\t\tPersian Alpaca Reasoning Dataset (persian-alpaca-reasoning-v1)\n\t\n\nLanguage: Persian (Farsi) | Dataset Type: Instruction-Following with Reasoning | Format: JSON, Hugging Face Dataset  \n\n\n\t\n\t\t\n\t\n\t\n\t\tüìñ Overview\n\t\n\npersian-alpaca-reasoning-v1 is a dataset designed for instruction-following tasks in Persian, enriched with detailed reasoning responses. It is based on the persian-alpaca-deep-clean dataset and extends it by generating reasoning explanations for each instruction-output pair‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hosseinhimself/persian-alpaca-reasoning-v1.","first_N":5,"first_N_keywords":["text-generation","Persian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Persian-Math-SFT","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xmanii/Persian-Math-SFT","creator_name":"mani mirzaei","creator_url":"https://huggingface.co/xmanii","description":"\n\t\n\t\t\n\t\tüéØ Persian Math Questions Dataset for SFT\n\t\n\n\n\t\n\t\t\n\t\tüìù Description\n\t\n\nThis dataset contains Persian questions primarily focused on mathematical concepts, designed for Supervised Fine-Tuning (SFT) of Language Models.\n\n\t\n\t\t\n\t\tüîç Features\n\t\n\n\nHigh-quality Persian questions\nDetailed subtopic categorization\nFocused on mathematical concepts\nTokens count for each conversation\n\n\n\t\n\t\t\n\t\tüöÄ Coming Soon\n\t\n\n\nDetailed answers for each question\nAdditional topics beyond mathematics\nEnhanced‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xmanii/Persian-Math-SFT.","first_N":5,"first_N_keywords":["text-generation","Persian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Persian-Math-SFT","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xmanii/Persian-Math-SFT","creator_name":"mani mirzaei","creator_url":"https://huggingface.co/xmanii","description":"\n\t\n\t\t\n\t\tüéØ Persian Math Questions Dataset for SFT\n\t\n\n\n\t\n\t\t\n\t\tüìù Description\n\t\n\nThis dataset contains Persian questions primarily focused on mathematical concepts, designed for Supervised Fine-Tuning (SFT) of Language Models.\n\n\t\n\t\t\n\t\tüîç Features\n\t\n\n\nHigh-quality Persian questions\nDetailed subtopic categorization\nFocused on mathematical concepts\nTokens count for each conversation\n\n\n\t\n\t\t\n\t\tüöÄ Coming Soon\n\t\n\n\nDetailed answers for each question\nAdditional topics beyond mathematics\nEnhanced‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xmanii/Persian-Math-SFT.","first_N":5,"first_N_keywords":["text-generation","Persian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tBelebele-Fleurs\n\t\n\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\n\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"persian-blog-QA","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/myrkur/persian-blog-QA","creator_name":"Amir Masoud Ahmadi","creator_url":"https://huggingface.co/myrkur","description":"myrkur/persian-blog-QA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Persian","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"persian-gender-by-name","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/farbodbij/persian-gender-by-name","creator_name":"farbod bijary","creator_url":"https://huggingface.co/farbodbij","description":"\n\t\n\t\t\n\t\tPersian Gender Detection by Name\n\t\n\nA comprehensive dataset for determining gender based on Persian names, enriched with English representations.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Persian Gender Detection by Name dataset is the largest of its kind, comprising approximately 27,000 entries. Each entry includes a Persian name, its corresponding gender, and the English transliteration. This dataset is designed to facilitate accurate gender detection and enhance searchability through multiple name‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/farbodbij/persian-gender-by-name.","first_N":5,"first_N_keywords":["Persian","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"PersianSyntheticEmotions","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParsBench/PersianSyntheticEmotions","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\n\t\n\t\t\n\t\tPersianSyntheticEmotions Dataset\n\t\n\nThis dataset contains 8,751 Persian text records synthetically generated using the GPT-4o model, labeled with Ekman's six basic emotions. The dataset is sourced from PersianSyntheticData.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe PersianSyntheticEmotions dataset is a collection of Persian texts labeled with six emotion classes based on Ekman's basic emotions theory. The data is synthetically generated, making it useful for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ParsBench/PersianSyntheticEmotions.","first_N":5,"first_N_keywords":["Persian","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"PersianSyntheticEmotions","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParsBench/PersianSyntheticEmotions","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\n\t\n\t\t\n\t\tPersianSyntheticEmotions Dataset\n\t\n\nThis dataset contains 8,751 Persian text records synthetically generated using the GPT-4o model, labeled with Ekman's six basic emotions. The dataset is sourced from PersianSyntheticData.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe PersianSyntheticEmotions dataset is a collection of Persian texts labeled with six emotion classes based on Ekman's basic emotions theory. The data is synthetically generated, making it useful for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ParsBench/PersianSyntheticEmotions.","first_N":5,"first_N_keywords":["Persian","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"reranking-datasets-light","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","description":"\n\t\n\t\t\n\t\tüî• Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation üî•\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\n\t\n\n\n    \n    \n    \n    \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n    \n\n\n\nA curated collection of ready-to-use datasets for retrieval and reranking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light.","first_N":5,"first_N_keywords":["question-answering","English","Arabic","German","French"],"keywords_longer_than_N":true},
	{"name":"iranian-surname-frequencies","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/farbodbij/iranian-surname-frequencies","creator_name":"farbod bijary","creator_url":"https://huggingface.co/farbodbij","description":"\n\t\n\t\t\n\t\tPersian Last Names Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nWelcome to the Persian Last Names Dataset, a comprehensive collection of over 100,000 Persian surnames accompanied by their respective frequencies. This dataset is curated from a substantial real-world sample of more than 10 million records, ensuring reliable and representative data for various applications.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nTotal Surnames: 100,000+\nFrequency Source: Derived from a dataset comprising 10 million entries‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/farbodbij/iranian-surname-frequencies.","first_N":5,"first_N_keywords":["text-classification","token-classification","Persian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"persian-poetry-meters","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cnababaie/persian-poetry-meters","creator_name":"Sina Babaie","creator_url":"https://huggingface.co/cnababaie","description":"Persian poems with their corresponding meters, from ganjoor.net.\n","first_N":5,"first_N_keywords":["text-classification","question-answering","Persian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Iranian_olympiad_of_informatics_multimodal_questions","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ckodser/Iranian_olympiad_of_informatics_multimodal_questions","creator_name":"Arshia Soltani Moakhar","creator_url":"https://huggingface.co/ckodser","description":"ckodser/Iranian_olympiad_of_informatics_multimodal_questions dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Persian","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"data3","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ali121300/data3","creator_name":"ali pedram","creator_url":"https://huggingface.co/ali121300","description":"ali121300/data3 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Persian","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"hello_and_goodby_persioan","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HamidRza/hello_and_goodby_persioan","creator_name":"HamidRezaHosayni","creator_url":"https://huggingface.co/HamidRza","description":"HamidRza/hello_and_goodby_persioan dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Persian","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xm100","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM100\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Persian_lmsys_QA","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mshojaei77/Persian_lmsys_QA","creator_name":"Mohammad Shojaei","creator_url":"https://huggingface.co/mshojaei77","description":"\n\t\n\t\t\n\t\tPersian Question-Answer Dataset\n\t\n\nThis dataset contains 5900 Persian language question-answer pairs generated using the PersianAnswerGenerator class from answer.py. The answers are produced by an AI assistant leveraging the GPT-4o model through the Avala API service.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset comprises questions and their corresponding detailed answers in Persian (Farsi) language. The answers are crafted by an AI assistant with the following attributes:\n\nComplete‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mshojaei77/Persian_lmsys_QA.","first_N":5,"first_N_keywords":["Persian","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"fibonacci-2025","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fibonacciai/fibonacci-2025","creator_name":"Fibonacci Intelligence ‚ú® Persian LLm | Iranian Ai","creator_url":"https://huggingface.co/fibonacciai","description":"fibonacciai/fibonacci-2025 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Persian","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"Persian_QA_Chat_Format","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xmanii/Persian_QA_Chat_Format","creator_name":"mani mirzaei","creator_url":"https://huggingface.co/xmanii","description":"This dataset is an enhanced version of the Persian_QA dataset originally created by mshojaei77. The original dataset contains 5900 Persian language question-answer pairs generated using GPT-4 through the Avala API service.\n\n\t\n\t\t\n\t\tüîÑ Enhancements\n\t\n\nThis version adds a chat-formatted column that structures the Q&A pairs in a conversational format. Key features:\n\nEvery 4th conversation includes a friendly greeting exchange (25% of examples)\nAll Q&A pairs are formatted as chat dialogues‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xmanii/Persian_QA_Chat_Format.","first_N":5,"first_N_keywords":["Persian","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"PersianSyntheticQA","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParsBench/PersianSyntheticQA","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\n\t\n\t\t\n\t\tPersian Synthetic QA Dataset\n\t\n\nPersian Synthetic QA is a dataset containing 100,000 synthetic questions and answers in Persian, generated using GPT-4o. The dataset is structured as conversations between a user and an assistant, with 2,000 records for each of the 50 different topics. Each conversation consists of messages with two distinct roles: \"user\" messages containing questions in Persian, and \"assistant\" messages containing the corresponding answers. The dataset is designed for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ParsBench/PersianSyntheticQA.","first_N":5,"first_N_keywords":["question-answering","Persian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"PersianSyntheticQA","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParsBench/PersianSyntheticQA","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\n\t\n\t\t\n\t\tPersian Synthetic QA Dataset\n\t\n\nPersian Synthetic QA is a dataset containing 100,000 synthetic questions and answers in Persian, generated using GPT-4o. The dataset is structured as conversations between a user and an assistant, with 2,000 records for each of the 50 different topics. Each conversation consists of messages with two distinct roles: \"user\" messages containing questions in Persian, and \"assistant\" messages containing the corresponding answers. The dataset is designed for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ParsBench/PersianSyntheticQA.","first_N":5,"first_N_keywords":["question-answering","Persian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Persian-MuSR","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParsBench/Persian-MuSR","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","description":"\n\t\n\t\t\n\t\tPersian MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning on Persian Language\n\t\n\nThis is the Persian-translated version (using GPT-4o) of the original dataset MuSR.\n\n\t\n\t\t\n\t\tAcknowledgments\n\t\n\n\nSpecial thanks to AvalAI for sponsoring this project through their AvalAward program\nThis dataset was made possible by AvalAI's generous support and commitment to advancing Persian language AI research\n\n","first_N":5,"first_N_keywords":["question-answering","Persian","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"persian_news_typos","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/masoudkaviani/persian_news_typos","creator_name":"Maaoud Kaviani","creator_url":"https://huggingface.co/masoudkaviani","description":"\n\t\n\t\t\n\t\tCorrected News Articles Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview:\n\t\n\nThis dataset contains pairs of raw text and their corrected versions, providing a valuable resource for tasks related to text correction, language modeling, and natural language processing (NLP). The dataset has been derived from various news articles and reports, focusing on correcting typographical errors, grammatical mistakes, and stylistic inconsistencies in the text. Each entry in the dataset consists of two fields: text (the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masoudkaviani/persian_news_typos.","first_N":5,"first_N_keywords":["text-generation","Persian","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Dhanishtha-2.0-SUPERTHINKER","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HelpingAI/Dhanishtha-2.0-SUPERTHINKER","creator_name":"HelpingAI","creator_url":"https://huggingface.co/HelpingAI","description":"üì¶ Dhanishtha-2.0-SUPERTHINKER\n A distilled corpus of 11.7K high-quality samples showcasing multi-phase reasoning and structured emotional cognition. Sourced directly from the internal training data of Dhanishtha-2.0 ‚Äî the world‚Äôs first Large Language Model (LLM) to implement Intermediate Thinking, featuring multiple <think> and <ser> blocks per response\n\n\n\t\n\t\t\n\t\tüìä Overview\n\t\n\n\n11.7K multilingual samples (languages listed below)\nInstruction-Output format, ideal for supervised fine-tuning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HelpingAI/Dhanishtha-2.0-SUPERTHINKER.","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"dhanishtha-2.0-superthinker-mlx","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker-mlx","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","description":"\n\t\n\t\t\n\t\tüì¶ Dhanishtha-2.0-SUPERTHINKER-MLX\n\t\n\n A distilled corpus of 11.7K high-quality samples showcasing multi-phase reasoning and structured emotional cognition. Sourced directly from the internal training data of Dhanishtha-2.0 ‚Äî the world‚Äôs first Large Language Model (LLM) to implement Intermediate Thinking, featuring multiple <think> and <ser> blocks per response\n\n\t\n\t\t\n\t\n\t\n\t\tExample with MLX-LM-LoRA:\n\t\n\nmlx_lm_lora.train \\\n--model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker-mlx.","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang-zip","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shifting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip.","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"quran_multilingual_parallel","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/quran_multilingual_parallel","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüìò Qur‚Äôan Multilingual Parallel Dataset (quran_multilingual_parallel)\n\t\n\nThis dataset presents a clean, structurally-aligned multilingual parallel corpus of the Qur‚Äôanic text. It is intended for linguistic, computational, and cross-lingual AI applications ‚Äî not only for religious interpretation.\nIt contains over 6,200 verse-level alignments in 54 human languages, formatted in a machine-friendly .csv structure with language-specific translation fields.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüß† Dataset Highlights‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/quran_multilingual_parallel.","first_N":5,"first_N_keywords":["translation","Arabic","Albanian","Amharic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"wikipedia-citation-index","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia-citation-index","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Dataset with citation indexes as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions. Research: ArXiv\n","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"synthetic-speaker-diarization-dataset-fa-large-3000","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/uncleMehrzad/synthetic-speaker-diarization-dataset-fa-large-3000","creator_name":"Amirreza Mehrzadian","creator_url":"https://huggingface.co/uncleMehrzad","description":"uncleMehrzad/synthetic-speaker-diarization-dataset-fa-large-3000 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","Persian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"fleurs-farsi","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohammadGholizadeh/fleurs-farsi","creator_name":"Mohammad Sadegh Gholizadeh","creator_url":"https://huggingface.co/MohammadGholizadeh","description":"\n\t\n\t\t\n\t\tFLEURS Farsi (fa_ir) - Processed Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains the Farsi (Persian, fa_ir) portion of the FLEURS (Few-shot Learning Evaluation of Universal Representations of Speech) dataset, processed into a Hugging Face datasets compatible format. FLEURS is a many-language speech dataset created by Google, designed for evaluating speech recognition systems, particularly in low-resource scenarios.\nThis version includes audio recordings and their‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MohammadGholizadeh/fleurs-farsi.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"fleurs-farsi","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohammadGholizadeh/fleurs-farsi","creator_name":"Mohammad Sadegh Gholizadeh","creator_url":"https://huggingface.co/MohammadGholizadeh","description":"\n\t\n\t\t\n\t\tFLEURS Farsi (fa_ir) - Processed Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains the Farsi (Persian, fa_ir) portion of the FLEURS (Few-shot Learning Evaluation of Universal Representations of Speech) dataset, processed into a Hugging Face datasets compatible format. FLEURS is a many-language speech dataset created by Google, designed for evaluating speech recognition systems, particularly in low-resource scenarios.\nThis version includes audio recordings and their‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MohammadGholizadeh/fleurs-farsi.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Persian","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Maux-Persian-SFT-30k","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xmanii/Maux-Persian-SFT-30k","creator_name":"mani mirzaei","creator_url":"https://huggingface.co/xmanii","description":"\n\t\n\t\t\n\t\tMaux-Persian-SFT-30k\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 30,000 high-quality Persian (Farsi) conversations for supervised fine-tuning (SFT) of conversational AI models. The dataset combines multiple sources to provide diverse, natural Persian conversations covering various topics and interaction patterns.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry contains:\n\nmessages: List of conversation messages with role (user/assistant/system) and content\nsource: Source dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xmanii/Maux-Persian-SFT-30k.","first_N":5,"first_N_keywords":["question-answering","text-generation","Persian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Maux-Persian-SFT-30k","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xmanii/Maux-Persian-SFT-30k","creator_name":"mani mirzaei","creator_url":"https://huggingface.co/xmanii","description":"\n\t\n\t\t\n\t\tMaux-Persian-SFT-30k\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 30,000 high-quality Persian (Farsi) conversations for supervised fine-tuning (SFT) of conversational AI models. The dataset combines multiple sources to provide diverse, natural Persian conversations covering various topics and interaction patterns.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach entry contains:\n\nmessages: List of conversation messages with role (user/assistant/system) and content\nsource: Source dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xmanii/Maux-Persian-SFT-30k.","first_N":5,"first_N_keywords":["question-answering","text-generation","Persian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"conversational-persian-subtitles","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Maral/conversational-persian-subtitles","creator_name":"Maral Zarvani","creator_url":"https://huggingface.co/Maral","description":"\n\t\n\t\t\n\t\tConversational¬†Persian¬†Subtitles\n\t\n\nDataset name: Conversational¬†Persian¬†SubtitlesCollaboration: Maral¬†Zarvani & Milad¬†Ghashangi¬†AgdamLicense: CC¬†BY¬†4.0Hugging¬†Face Repo: https://huggingface.co/datasets/Maral/conversational-persian-subtitles\n\n\n\t\n\t\t\n\t\n\t\n\t\t1. Dataset Description\n\t\n\nThis dataset contains cleaned Persian subtitle lines from a wide variety of Korean TV series and films, each line reflecting informal, conversational dialogue. All markup (square brackets, timecodes,etc.) has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Maral/conversational-persian-subtitles.","first_N":5,"first_N_keywords":["Persian","cc-by-4.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"conversational-persian-subtitles","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Maral/conversational-persian-subtitles","creator_name":"Maral Zarvani","creator_url":"https://huggingface.co/Maral","description":"\n\t\n\t\t\n\t\tConversational¬†Persian¬†Subtitles\n\t\n\nDataset name: Conversational¬†Persian¬†SubtitlesCollaboration: Maral¬†Zarvani & Milad¬†Ghashangi¬†AgdamLicense: CC¬†BY¬†4.0Hugging¬†Face Repo: https://huggingface.co/datasets/Maral/conversational-persian-subtitles\n\n\n\t\n\t\t\n\t\n\t\n\t\t1. Dataset Description\n\t\n\nThis dataset contains cleaned Persian subtitle lines from a wide variety of Korean TV series and films, each line reflecting informal, conversational dialogue. All markup (square brackets, timecodes,etc.) has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Maral/conversational-persian-subtitles.","first_N":5,"first_N_keywords":["Persian","cc-by-4.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"constitution-of-iran","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nikmaram/constitution-of-iran","creator_name":"Hosein Nikmaram","creator_url":"https://huggingface.co/nikmaram","description":"\n\t\n\t\t\n\t\tIranian Constitution Q&A Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset was manually created by extracting information article by article from the text of the Iranian Constitution found in the PDF document available at the following URL: https://www.lu.ac.ir/uploads/123456_20436.pdf. This PDF is hosted on the website of Lorestan University (www.lu.ac.ir). Key points, definitions, duties, rights, and procedures were identified and reformulated as question-answer pairs. Care was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nikmaram/constitution-of-iran.","first_N":5,"first_N_keywords":["English","Persian","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"perisan_texts_with_typos","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aictsharif/perisan_texts_with_typos","creator_name":"aictsharif","creator_url":"https://huggingface.co/aictsharif","description":"\n\t\n\t\t\n\t\tPersian Typo Correction Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Persian Typo Correction Dataset is a parallel corpus consisting of Persian (Farsi) sentences with common typographical, spelling, and orthographic errors alongside their corrected versions. This resource is designed for training and evaluating machine learning models for automatic text correction, normalization, and spell checking in Persian. It is suitable for both academic research and real-world NLP applications‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aictsharif/perisan_texts_with_typos.","first_N":5,"first_N_keywords":["Persian","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"persian-med-qa","keyword":"persian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aictsharif/persian-med-qa","creator_name":"aictsharif","creator_url":"https://huggingface.co/aictsharif","description":"\n\t\n\t\t\n\t\tüè• Persian Medical Question Answering Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Persian Medical QA Dataset is a high-quality, expert-curated collection of question‚Äìanswer (QA) pairs in Persian (Farsi), designed for developing and evaluating natural language processing (NLP) models for medical question answering. All answers are grounded in reliable medical resources, including standard medical textbooks (e.g., Harrison‚Äôs Principles of Internal Medicine) and authoritative medical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aictsharif/persian-med-qa.","first_N":5,"first_N_keywords":["question-answering","Persian","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"iran_executive_agency_employees_by_province_education_2022","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sadeghi/iran_executive_agency_employees_by_province_education_2022","creator_name":"Javad","creator_url":"https://huggingface.co/Sadeghi","description":"\n\t\n\t\t\n\t\tIran Executive Agency Employees Statistics by Province and Education Level (2022)\n\t\n\n\n\t\n\t\t\n\t\tDataset_Overview\n\t\n\nThis dataset offers a comprehensive breakdown of the number of employees in Iranian executive agencies for the year 1401 (corresponding to 2022). It provides detailed statistics on the public sector workforce, categorized by province and educational level. This information is vital for policymakers, researchers, and anyone interested in the geographic distribution and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sadeghi/iran_executive_agency_employees_by_province_education_2022.","first_N":5,"first_N_keywords":["Persian","cc-by-4.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"iran_executive_agency_employees_by_gender_province_2022","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sadeghi/iran_executive_agency_employees_by_gender_province_2022","creator_name":"Javad","creator_url":"https://huggingface.co/Sadeghi","description":"\n\t\n\t\t\n\t\tIran Executive Agency Employees Statistics by Gender and Province (2022)\n\t\n\n\n\t\n\t\t\n\t\tDataset_Overview\n\t\n\nThis dataset offers a comprehensive breakdown of the number of employees in Iranian executive agencies for the year 1401 (corresponding to 2022). It provides detailed statistics on the public sector workforce, categorized by province and gender. This information is vital for policymakers, researchers, and anyone interested in the geographic distribution and gender composition of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sadeghi/iran_executive_agency_employees_by_gender_province_2022.","first_N":5,"first_N_keywords":["Persian","cc-by-4.0","< 1K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"farsi-tokenizer-robustness-mmlu","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Malikeh1375/farsi-tokenizer-robustness-mmlu","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","description":"\n\t\n\t\t\n\t\tFarsi Tokenizer Robustness MMLU Dataset\n\t\n\nThis dataset contains MMLU-formatted questions and answers designed to test tokenizer robustness across different text formats and languages.\n","first_N":5,"first_N_keywords":["Persian","English","cc-by-4.0","< 1K","arrow"],"keywords_longer_than_N":true},
	{"name":"iran_executive_agency_employees_2022","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sadeghi/iran_executive_agency_employees_2022","creator_name":"Javad","creator_url":"https://huggingface.co/Sadeghi","description":"\n\t\n\t\t\n\t\tIran Executive Agency Employees Statistics (2022)\n\t\n\n\n\t\n\t\t\n\t\tDataset_Overview\n\t\n\nThis dataset offers a comprehensive breakdown of the number of employees in Iranian executive agencies for the year 1401 (corresponding to 2022). It provides detailed statistics on the public sector workforce, categorized by employment type, educational level, and gender. This information is vital for policymakers, researchers, and anyone interested in the structure and dynamics of government employment in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sadeghi/iran_executive_agency_employees_2022.","first_N":5,"first_N_keywords":["Persian","cc-by-4.0","< 1K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"iran_executive_agency_employees_by_employment_type_province_2022","keyword":"persian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sadeghi/iran_executive_agency_employees_by_employment_type_province_2022","creator_name":"Javad","creator_url":"https://huggingface.co/Sadeghi","description":"\n\t\n\t\t\n\t\tIran Executive Agency Employees Statistics by Employment Type and Province (2022)\n\t\n\n\n\t\n\t\t\n\t\tDataset_Overview\n\t\n\nThis dataset offers a comprehensive breakdown of the number of employees in Iranian executive agencies for the year 1401 (corresponding to 2022). It provides detailed statistics on the public sector workforce, categorized by province and employment type. This information is vital for policymakers, researchers, and anyone interested in the geographic distribution and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sadeghi/iran_executive_agency_employees_by_employment_type_province_2022.","first_N":5,"first_N_keywords":["Persian","cc-by-4.0","< 1K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"NeoBabel-Eval","keyword":"persian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mderakhshani/NeoBabel-Eval","creator_name":"Mohammad Mahdi Derakhshani","creator_url":"https://huggingface.co/mderakhshani","description":"\n\t\n\t\t\n\t\tOfficial Multilingual Evaluation Suite of NeoBabel\n\t\n\nThis repository contains the full evaluation datasets used for benchmarking multilingual text-to-image generation in NeoBabel. We release two benchmarks: m-GenEval and m-DPG, both provided as .zip archives.\n\n\t\n\t\t\n\t\tm-GenEval\n\t\n\nThis dataset is a multilingual extension of the original GenEval benchmark. Each English prompt from GenEval has been translated into five additional languages: Chinese, Dutch, French, Hindi, and Persian.Each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mderakhshani/NeoBabel-Eval.","first_N":5,"first_N_keywords":["text-to-image","English","Dutch","French","Persian"],"keywords_longer_than_N":true},
	{"name":"MathVista_with_difficulty_level","keyword":"persian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JierunChen/MathVista_with_difficulty_level","creator_name":"Jierun Chen","creator_url":"https://huggingface.co/JierunChen","description":"\n\t\n\t\t\n\t\tMathVista with difficulty level tags\n\t\n\nThis dataset extends the ü§ó MathVista testmini benchmark by introducing two additional tags: passrate_for_qwen2.5_vl_7b and difficulty_level_for_qwen2.5_vl_7b. Further details are available in our paper  The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs.\n\n\t\n\t\t\n\t\n\t\n\t\tüöÄ Data Usage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"JierunChen/MathVista_with_difficulty_level\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JierunChen/MathVista_with_difficulty_level.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","visual-question-answering","text-classification","multiple-choice-qa"],"keywords_longer_than_N":true}
]
;
