const data_for_language_asia_azerbaijani = 
[
	{"name":"medical_o1_reasoning_SFT_az","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rustamshry/medical_o1_reasoning_SFT_az","creator_name":"Rustam Shiriyev","creator_url":"https://huggingface.co/Rustamshry","description":"\n\t\n\t\t\n\t\tmedical-o1-reasoning-SFT-az\n\t\n\nThis is the Azerbaijani translation of the FreedomIntelligence/medical-o1-reasoning-SFT dataset, created for medical reasoning fine-tuning.\n\n\t\n\t\t\n\t\tModifications\n\t\n\n\nTranslated all fields (Question, Complex_CoT, Response) into Azerbaijani.\nRows with translation issues were removed.\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nApache 2.0\n\n\t\n\t\t\n\t\tAcknowledgements\n\t\n\nThe original dataset was created by the FreedomIntelligence team.\n","first_N":5,"first_N_keywords":["text-generation","question-answering","Azerbaijani","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"azerbaijani","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2Jyq/common_voice_21_0","creator_name":"2Jyq","creator_url":"https://huggingface.co/2Jyq","description":"Due to storage limits some files had to be split into multiple parts. They can be merged like this: cat file.* > file.\n","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","multilingual","extended|common_voice","Abkhaz"],"keywords_longer_than_N":true},
	{"name":"morphscore","keyword":"azerbaijani","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/catherinearnett/morphscore","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","description":"\n\t\n\t\t\n\t\tMorphScore\n\t\n\nMorphScore is a tokenizer evaluation framework, which evaluates the extent to which a tokenizer segments words along morpheme boundaries. This repository contains the datasets used to calculate MorphScore.\nIn total, we have datasetes for 86 languages, but only 70 languages have at least 100 items after filtering. \nAll datasets are derived from existing Universal Dependencies treebanks. In the table below, we link the source dataset for each language. \nSee the new preprint‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/morphscore.","first_N":5,"first_N_keywords":["Arabic","English","German","Russian","Turkish"],"keywords_longer_than_N":true},
	{"name":"azerbaijani-english-parallel-corpus","keyword":"azerbaijani","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LocalDoc/azerbaijani-english-parallel-corpus","creator_name":"LocalDoc","creator_url":"https://huggingface.co/LocalDoc","description":"\n\t\n\t\t\n\t\tAzerbaijani English Parallel Corpus\n\t\n\nThis dataset contains 1,120,000 pairs of high-quality sentences translated from Azerbaijani to English. The data was collected from various resources such as websites, news, books, wikipedia, legislation, scientific articles and etc.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nCC-BY-4.0\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor more information, questions, or issues, please contact LocalDoc at [v.resad.89@gmail.com].\n","first_N":5,"first_N_keywords":["translation","sentence-similarity","Azerbaijani","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"azerbaijani-english-parallel-corpus","keyword":"azerbaijani","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LocalDoc/azerbaijani-english-parallel-corpus","creator_name":"LocalDoc","creator_url":"https://huggingface.co/LocalDoc","description":"\n\t\n\t\t\n\t\tAzerbaijani English Parallel Corpus\n\t\n\nThis dataset contains 1,120,000 pairs of high-quality sentences translated from Azerbaijani to English. The data was collected from various resources such as websites, news, books, wikipedia, legislation, scientific articles and etc.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nCC-BY-4.0\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor more information, questions, or issues, please contact LocalDoc at [v.resad.89@gmail.com].\n","first_N":5,"first_N_keywords":["translation","sentence-similarity","Azerbaijani","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"azerbaijan_legislation","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LocalDoc/azerbaijan_legislation","creator_name":"LocalDoc","creator_url":"https://huggingface.co/LocalDoc","description":"This dataset contains the legislation of the Republic of Azerbaijan. \nThe data is organized so that each sentence is separated for easier normalization in the future. \nThe dataset includes 59,000 documents split into sentences.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor more information, questions, or issues, please contact LocalDoc at [v.resad.89@gmail.com].\n","first_N":5,"first_N_keywords":["Azerbaijani","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"wikipedia-monthly","keyword":"azerbaijani","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/omarkamali/wikipedia-monthly","creator_name":"Omar Kamali","creator_url":"https://huggingface.co/omarkamali","description":"\n\t\n\t\t\n\t\tüöÄ Wikipedia Monthly\n\t\n\nLast updated: July 16, 2025, 22:53 UTC\nThis repository provides monthly, multilingual dumps of Wikipedia, processed and prepared for easy use in NLP projects.\nNOTE: The first run is still in progress and languages are still being processed and uploaded.\n\n\n\t\n\t\t\n\t\tüìä Live Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nüåç Languages Available\n341\n\n\nüìÑ Total Articles\n64.5M\n\n\nüíæ Total Size\n205.54 GB\n\n\n\t\n\n\n\n\t\n\t\t\n\t\tWhy Use This Dataset?\n\t\n\n\nFreshness: We run our pipeline monthly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/omarkamali/wikipedia-monthly.","first_N":5,"first_N_keywords":["Abkhaz","Achinese","Adyghe","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages ‚Üí dolly-machine-translated.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"azerbaijani","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for Opus Ubuntu\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\nE.g.\ndataset = load_dataset(\"opus_ubuntu\", lang1=\"it\", lang2=\"pl\")\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"azerbaijani","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"azerbaijani","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"azerbaijani","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\n\t\n\t\t\n\t\tDataset Card for WIT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\nFrom the official blog post:\n\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\nThe WIT dataset offers extremely valuable data about the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_scenario","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_scenario","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveScenarioClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveScenarioClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_scenario.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_intent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveIntentClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_intent.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"azerbaijani","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof Wr√≥bel","creator_url":"https://huggingface.co/djstrong","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"docs_on_several_languages","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages","creator_name":"Aleksey Timoshin","creator_url":"https://huggingface.co/AlekseyScorpi","description":"\n\t\n\t\t\n\t\tDataset Card for \"docs_on_several_languages\"\n\t\n\nThis dataset is a collection of different images in different languages.\nThe daset includes the following languages: Azerbaijani (az: 0), Belorussian (be: 1), Chinese (zh: 16), English (en: 2), Estonian (et: 3), Finnish (fn: 4), Georgian (gr: 5), Japanese (ja: 6), Korean (ko: 7), Kazakh (kk: 8), Latvian (lv: 10), Lithuanian (lt: 9), Mongolian (mn: 11), Norwegian (no: 12), Polish (pl: 13), Russian (ru: 14), Ukranian (uk: 15).\nEach language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages.","first_N":5,"first_N_keywords":["text-classification","translation","feature-extraction","Azerbaijani","Belarusian"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"azerbaijani","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"belebele","keyword":"azerbaijani","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\n\t\n\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that discriminate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele.","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","text-classification","multiple-choice","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"azerbaijani","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\n\t\n\t\t\n\t\tDataset Card for WikiAnc\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \nThe code for generating the dataset can be found here.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nwikificiation: The dataset can be used to train a model for Wikification.\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in all 320‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"azerbaijani","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\n","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"azerbaijani","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Fran√ßais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"azerbaijani_review_sentiment_classification","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hajili/azerbaijani_review_sentiment_classification","creator_name":"Mammad Hajili","creator_url":"https://huggingface.co/hajili","description":"Azerbaijani Sentiment Classification Dataset with ~160K reviews. \nDataset contains 3 columns: Content, Score, Upvotes\n","first_N":5,"first_N_keywords":["text-classification","Azerbaijani","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"azerbaijani","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"azerbaijani","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"ÿßŸÖÿßŸÖ ÿ¨ŸÖÿπŸá ÿßÿµŸÅŸáÿßŸÜ ⁄ØŸÅÿ™: ŸÖ€åÿ≤ÿßŸÜ ŸÜ€åÿßÿ≤ ÿ¢ÿ® ÿ¥ÿ±ÿ® ÿßÿµŸÅŸáÿßŸÜ €±€±.€µ ŸÖÿ™ÿ± ŸÖ⁄©ÿπÿ® ÿßÿ≥ÿ™ ⁄©Ÿá ÿ™ŸÖÿßŸÖ ÿßÿ≥ÿ™ÿßŸÜ ÿßÿµŸÅŸáÿßŸÜ ÿ±ÿß ŸæŸàÿ¥ÿ¥ ŸÖ€åÿØŸáÿØ Ÿà ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸÇÿ®ŸÑ ÿßÿ≤ ÿßŸÜŸÇŸÑÿßÿ® €å⁄©€å ÿßÿ≤ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿáÿß ÿØÿ± ÿ≠Ÿàÿ≤Ÿá ÿ¢ÿ® ÿ®ŸàÿØŸá ÿßÿ≥ÿ™.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"Phonemized-UD","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/suchirsalhan/Phonemized-UD","creator_name":"Suchir Salhan","creator_url":"https://huggingface.co/suchirsalhan","description":"\n\t\n\t\t\n\t\tPhoneme-UD: A Multilingual Phonemized Universal Dependencies Corpus for 34+ Languages\n\t\n\n\n\t\n\t\t\n\t\tG2P+ Phonemizer\n\t\n\nWe use G2P+ to phonemize Universal Dependencies. Here is an example usage: \n# Install required packages\n!apt-get install -y espeak-ng\n!pip install phonemizer g2p-plus\n# Set the environment variable from Python\nimport os\nos.environ[\"PHONEMIZER_ESPEAK_LIBRARY\"] = \"/usr/lib/x86_64-linux-gnu/libespeak-ng.so.1\"\n\n# Now run your transcription\nfrom g2p_plus import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suchirsalhan/Phonemized-UD.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Azerbaijani","Catalan"],"keywords_longer_than_N":true},
	{"name":"lr-sum","keyword":"azerbaijani","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\tDataset Card for LR-Sum\n\t\n\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \nThe data is based on the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum.","first_N":5,"first_N_keywords":["summarization","text-generation","found","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"megawika-report-generation","keyword":"azerbaijani","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\n\t\n\t\t\n\t\tDataset Card for MegaWika for Report Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\nnon-English language, an automated English translation is provided. \nThis dataset provides the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation.","first_N":5,"first_N_keywords":["summarization","text-retrieval","text-generation","Afrikaans","Arabic"],"keywords_longer_than_N":true},
	{"name":"azerbaijani_tweet_emotion_classification","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hajili/azerbaijani_tweet_emotion_classification","creator_name":"Mammad Hajili","creator_url":"https://huggingface.co/hajili","description":"This dataset contains 150K (train + test) cleaned tweets in Azerbaijani. Tweets were collected in 2021, and filtered and cleaned by following these steps:\n\nInitial data were collected by using twint library. The tool is currently deprecated, cannot be used with new Twitter.\nOn top of the already filtered data, I applied an additional filter to select Azerbaijani tweets with using fastText language identification model.\nTweets were classified into 3 emotion categories: {positive: 1, negative:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hajili/azerbaijani_tweet_emotion_classification.","first_N":5,"first_N_keywords":["text-classification","Azerbaijani","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\nand converted into different parts (see process.py):\n\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\n\nRaw data files are in raw.tar.gz, which contains:\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\n[...] 9.8M Feb 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"azsci_topics","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hajili/azsci_topics","creator_name":"Mammad Hajili","creator_url":"https://huggingface.co/hajili","description":"\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThis dataset contains titles, topics and subtopics of dissertations written at Azerbaijani universities and institutes. \n","first_N":5,"first_N_keywords":["text-classification","Azerbaijani","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"genius-aze","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aznlp/genius-aze","creator_name":"AZNLP","creator_url":"https://huggingface.co/aznlp","description":"\n\t\n\t\t\n\t\tAzerbaijani Music Lyrics Dataset\n\t\n\nThis dataset consists of a comprehensive collection of Azerbaijani music lyrics, curated to facilitate natural language processing and machine learning research specifically focusing on Azerbaijani language text. It includes details such as song titles, artists, album names, years of release, and lyrics.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\nThis dataset is intended for training language models, analyzing cultural and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aznlp/genius-aze.","first_N":5,"first_N_keywords":["text-generation","Azerbaijani","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"azerbaijani-blogs","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aznlp/azerbaijani-blogs","creator_name":"AZNLP","creator_url":"https://huggingface.co/aznlp","description":"\n\t\n\t\t\n\t\tAzerbaijani Blogs dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset provides blogs written in azerbaijani language with categories and tags for each.\n\nLanguage(s) (NLP): Azerbaijani\nLicense: Apache license 2.0\n\n\n\t\n\t\t\n\t\tData Source\n\t\n\nAll the data was found in public resources of kayzen.az blogging website without any restriction.\n","first_N":5,"first_N_keywords":["text-classification","text-generation","Azerbaijani","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"azerbaijani-blogs","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aznlp/azerbaijani-blogs","creator_name":"AZNLP","creator_url":"https://huggingface.co/aznlp","description":"\n\t\n\t\t\n\t\tAzerbaijani Blogs dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset provides blogs written in azerbaijani language with categories and tags for each.\n\nLanguage(s) (NLP): Azerbaijani\nLicense: Apache license 2.0\n\n\n\t\n\t\t\n\t\tData Source\n\t\n\nAll the data was found in public resources of kayzen.az blogging website without any restriction.\n","first_N":5,"first_N_keywords":["text-classification","text-generation","Azerbaijani","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"azerbaijani","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"Pontoon-Translations","keyword":"azerbaijani","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\n\t\n\t\t\n\t\tDataset Card for Pontoon Translations\n\t\n\n\n\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\nSource strings are in English.\nTo avoid rows with values like \"None\" and \"N/A\" being interpreted as missing values, pass the keep_default_na parameter like this:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ayymen/Pontoon-Translations\", keep_default_na=False)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","crowdsourced","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"glue-mrpc-azerbaijani","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eljanmahammadli/glue-mrpc-azerbaijani","creator_name":"Eljan Mahammadli","creator_url":"https://huggingface.co/eljanmahammadli","description":"This dataset represents a translated version of the GLUE/MRPC dataset, generated using the Google Translate API.\n","first_N":5,"first_N_keywords":["text-classification","Azerbaijani","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"turbo.az","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zmmmdf/turbo.az","creator_name":"Ziya Mammadov","creator_url":"https://huggingface.co/zmmmdf","description":"\n\t\n\t\t\n\t\tTurbo Dataset\n\t\n\nThis dataset contains car listings scraped from turbo.az.\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThe dataset includes details such as car name, price, year, engine, distance, and city. For extracting your own real-time dataset, please visit the GitHub repository.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"zmmmdf/turbo.az\")\nprint(dataset[0])\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use our work, please cite:\n@misc{ma2024turboaz,\n    title={Turbo.Az Dataset: Dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zmmmdf/turbo.az.","first_N":5,"first_N_keywords":["table-question-answering","Azerbaijani","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"turbo.az","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zmmmdf/turbo.az","creator_name":"Ziya Mammadov","creator_url":"https://huggingface.co/zmmmdf","description":"\n\t\n\t\t\n\t\tTurbo Dataset\n\t\n\nThis dataset contains car listings scraped from turbo.az.\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThe dataset includes details such as car name, price, year, engine, distance, and city. For extracting your own real-time dataset, please visit the GitHub repository.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"zmmmdf/turbo.az\")\nprint(dataset[0])\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use our work, please cite:\n@misc{ma2024turboaz,\n    title={Turbo.Az Dataset: Dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zmmmdf/turbo.az.","first_N":5,"first_N_keywords":["table-question-answering","Azerbaijani","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"azerbaijani","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"umico.az","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zmmmdf/umico.az","creator_name":"Ziya Mammadov","creator_url":"https://huggingface.co/zmmmdf","description":"\n\t\n\t\t\n\t\tUmico Dataset\n\t\n\nThis dataset contains products listings scraped from umico.az.\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThe dataset includes details such as products name, price, seller, image url, and product url.\n. For extracting own realtime dataset, please visit to the GitHub repository.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"zmmmdf/umico.az\")\n\nprint(dataset[0])\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use our work, please cite:\n@misc{ma2023taxi1500,\n    title={Umico.AZ:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zmmmdf/umico.az.","first_N":5,"first_N_keywords":["Azerbaijani","mit","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"umico.az","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zmmmdf/umico.az","creator_name":"Ziya Mammadov","creator_url":"https://huggingface.co/zmmmdf","description":"\n\t\n\t\t\n\t\tUmico Dataset\n\t\n\nThis dataset contains products listings scraped from umico.az.\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThe dataset includes details such as products name, price, seller, image url, and product url.\n. For extracting own realtime dataset, please visit to the GitHub repository.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"zmmmdf/umico.az\")\n\nprint(dataset[0])\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use our work, please cite:\n@misc{ma2023taxi1500,\n    title={Umico.AZ:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zmmmdf/umico.az.","first_N":5,"first_N_keywords":["Azerbaijani","mit","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"spelling_corrected_words_azerbaijani","keyword":"azerbaijani","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LocalDoc/spelling_corrected_words_azerbaijani","creator_name":"LocalDoc","creator_url":"https://huggingface.co/LocalDoc","description":"\n\t\n\t\t\n\t\tSpelling Corrected Words in Azerbaijani\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset, \"Spelling Corrected Words in Azerbaijani,\" is designed for the task of correcting spelling errors in Azerbaijani texts. It contains pairs of words where each pair consists of an original word and its corrected version. The dataset is intended to be used for training and evaluating models that perform the task of filling in masked words correctly.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nindex:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LocalDoc/spelling_corrected_words_azerbaijani.","first_N":5,"first_N_keywords":["fill-mask","Azerbaijani","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"azerbaijani","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\nExample of loading:\ndataset = load_dataset(\"davidstap/NTREX\", \"rus_Cyrl\", trust_remote_code=True)\n\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe following languages are available:\n\n\t\n\t\t\nLanguage Code\nLanguage Name\n\n\n\t\t\nafr_Latn\nAfrikaans\n\n\namh_Ethi\nAmharic\n\n\narb_Arab\nArabic\n\n\naze_Latn\nAzerbaijani\nbak_Cyrl\nBashkir\n\n\nbel_Cyrl\nBelarusian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"BLEnD","keyword":"azerbaijani","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayeon212/BLEnD","creator_name":"Nayeon Lee","creator_url":"https://huggingface.co/nayeon212","description":"\n\t\n\t\t\n\t\tBLEnD\n\t\n\nThis is the official repository of BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages (Submitted to NeurIPS 2024 Datasets and Benchmarks Track).\n24/12/05: Updated translation errors25/05/02: Updated multiple choice questions file (v1.1)\n\n\t\n\t\t\n\t\tAbout\n\t\n\n\nLarge language models (LLMs) often lack culture-specific everyday knowledge, especially across diverse regions and non-English languages. Existing benchmarks for evaluating LLMs' cultural‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nayeon212/BLEnD.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","Spanish","Indonesian"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"azerbaijani-gov-qa","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/arzumanabbasov/azerbaijani-gov-qa","creator_name":"Arzuman Abbasov","creator_url":"https://huggingface.co/arzumanabbasov","description":"\n\t\n\t\t\n\t\tAzerbaijani Government Services Question Answering Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains over 5000 samples of question-answer pairs scraped from the comments section of the Instagram page of AsanXidmat, a government organization in Azerbaijan dedicated to providing services to Azerbaijani citizens. The dataset is intended for use in training and evaluating question answering systems, particularly those focused on understanding and responding to inquiries related to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arzumanabbasov/azerbaijani-gov-qa.","first_N":5,"first_N_keywords":["question-answering","Azerbaijani","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"azbanks-qadata","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/arzumanabbasov/azbanks-qadata","creator_name":"Arzuman Abbasov","creator_url":"https://huggingface.co/arzumanabbasov","description":"\n\t\n\t\t\n\t\tAzerbaijani Banks Question Answering Datasets\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis project comprises question-answer dataset from five prominent banks in Azerbaijan: Kapital Bank, Unibank, YeloBank, ABB Bank, and LeoBank. Dataset contains over 25,000 samples of question-answer pairs scraped from the comments section of the respective bank's Instagram page. These dataset are valuable resources for training and evaluating question answering systems tailored to the banking sector in Azerbaijan.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arzumanabbasov/azbanks-qadata.","first_N":5,"first_N_keywords":["question-answering","Azerbaijani","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"azerbaijani","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NTREXBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNTREX is a News Test References dataset for Machine Translation Evaluation, covering translation from English into 128 languages. We select language pairs according to the M2M-100 language grouping strategy, resulting in 1916 directions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/davidstap/NTREX\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","translated","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"fake-news-azerbaijani","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eljanmahammadli/fake-news-azerbaijani","creator_name":"Eljan Mahammadli","creator_url":"https://huggingface.co/eljanmahammadli","description":"\n\t\n\t\t\n\t\tFake News Dataset\n\t\n\nThis dataset consists of machine-generated fake news articles alongside their original counterparts from BBC News.\n\nOriginal News: Sourced from the XLSum BBC News dataset.\nFake News: Generated using GPT-4o, seeded with the titles of the original articles.\n0 means original and 1 means fake news.\n\n","first_N":5,"first_N_keywords":["text-classification","Azerbaijani","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"x-fact","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"x-fact\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while the language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact.","first_N":5,"first_N_keywords":["text-classification","Arabic","Bengali","Spanish","Persian"],"keywords_longer_than_N":true},
	{"name":"internet_archive_azerbaijani","keyword":"azerbaijani","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nazrinburz/internet_archive_azerbaijani","creator_name":"Nazrin Burziyeva","creator_url":"https://huggingface.co/nazrinburz","description":"nazrinburz/internet_archive_azerbaijani dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","token-classification","Azerbaijani","cc0-1.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"azerbaijani_spelling_dictionary_2021","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LocalDoc/azerbaijani_spelling_dictionary_2021","creator_name":"LocalDoc","creator_url":"https://huggingface.co/LocalDoc","description":"This dataset contains words from the Spelling Dictionary of the Azerbaijani Language, 7th edition, which was published in 2021.\n","first_N":5,"first_N_keywords":["Azerbaijani","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"azerbaijani_spelling_dictionary_2021","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LocalDoc/azerbaijani_spelling_dictionary_2021","creator_name":"LocalDoc","creator_url":"https://huggingface.co/LocalDoc","description":"This dataset contains words from the Spelling Dictionary of the Azerbaijani Language, 7th edition, which was published in 2021.\n","first_N":5,"first_N_keywords":["Azerbaijani","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"azerbaijani_words_frequency","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LocalDoc/azerbaijani_words_frequency","creator_name":"LocalDoc","creator_url":"https://huggingface.co/LocalDoc","description":"The dataset contains a list of Azerbaijani words and their frequencies from text corpus analysis. \nThe corpus used was the AzTC (Azerbaijan Text Corpus) from https://huggingface.co/datasets/LocalDoc/AzTC.\nThe AzTC contains 51 million non-recurring sentences (approximately 1 billion tokens). The data was collected from various sources including:\n\nWebsites\nNews articles\nBooks \nWikipedia articles\nLegislative documents\nScientific articles\nOther resources\n\nThis word frequency list represents how‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LocalDoc/azerbaijani_words_frequency.","first_N":5,"first_N_keywords":["Azerbaijani","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Roleplay-Azarbaijani","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Azarbaijani","creator_name":"Min Si Thu","creator_url":"https://huggingface.co/jojo-ai-mst","description":"\n\t\n\t\t\n\t\tRolePlay-Azarbaijani\n\t\n\nRoleplay-Azarbaijani Dataset is a dataset for roleplaying in the Azarbaijani language for Large Language Model.\nThe base dataset is the GPTeacher role play dataset by teknium 1, which can be found under this link, released under MIT License. The dataset is then translated into respective languages. The translation process is powered by Google Translate, using cloud translation API. \nFor more information and other language datasets for roleplay, it can be found‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Azarbaijani.","first_N":5,"first_N_keywords":["text-generation","Azerbaijani","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"lezgi-rus-azer-corpus","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlidarAsvarov/lezgi-rus-azer-corpus","creator_name":"Alidar Asvarov","creator_url":"https://huggingface.co/AlidarAsvarov","description":"\n\t\n\t\t\n\t\tNeural machine translation system for Lezgian, Russian and Azerbaijani languages\n\t\n\nWe release the first neural machine translation system for translation between Russian, Azerbaijani and the endangered Lezgian languages, as well as monolingual and parallel datasets collected and aligned for training and evaluating the system.\n\n\t\n\t\t\n\t\tParallel corpus sources:\n\t\n\n\nBible: parsed from https://bible.com, aligned by verse numbers (merged if necessary).\n\"Oriental translation\" (CARS) version‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlidarAsvarov/lezgi-rus-azer-corpus.","first_N":5,"first_N_keywords":["Russian","Azerbaijani","Lezghian","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"vqa","keyword":"azerbaijani","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldcuisines/vqa","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\n\t\n\t\t\n\t\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\n\t\n\n\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 October 2024.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa.","first_N":5,"first_N_keywords":["multilingual","English","Indonesian","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Achinese","Adyghe"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/include-lite-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tINCLUDE-lite (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-lite-44.","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"alpaca-azerbaijani-gpt-4o-mini","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eljanmahammadli/alpaca-azerbaijani-gpt-4o-mini","creator_name":"Eljan Mahammadli","creator_url":"https://huggingface.co/eljanmahammadli","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is a translated version of the Alpaca dataset into the Azerbaijani language, using GPT-4o-mini.\n","first_N":5,"first_N_keywords":["question-answering","text-generation","Azerbaijani","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Achinese","Adyghe"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/include-base-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tINCLUDE-base (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-base-44.","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Deltacorpus_1.1","keyword":"azerbaijani","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\n[!NOTE]\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, Portoro≈æ, Slovenia).\nChanges in version 1.1: \n\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \n\nSVM classifier trained on Universal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1.","first_N":5,"first_N_keywords":["token-classification","multilingual","Afrikaans","Albanian","Amharic"],"keywords_longer_than_N":true},
	{"name":"AVAINT","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botintel-community/AVAINT","creator_name":"BotIntel X","creator_url":"https://huggingface.co/botintel-community","description":"botintel-community/AVAINT dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","summarization","text-classification","Azerbaijani","English"],"keywords_longer_than_N":true},
	{"name":"azkurs","keyword":"azerbaijani","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/azkurs","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Azkurs.org\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 566,713 pages of educational content in Azerbaijani language extracted from azkurs.org website. The content includes academic and educational materials, with a focus on technical and scientific topics.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is in Azerbaijani (az) only.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nThis dataset includes the following fields:\n\nurl: URL of the webpage (string)\ntitle: Title of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/azkurs.","first_N":5,"first_N_keywords":["text-classification","text-generation","topic-classification","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\nsource: the source sentence.\nchosen: the preferred translation.\nreject: the dis-preferred translation.\ndirections: the translation direction.\n@misc{xu2024xalmaplugplay,\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\n      year={2024},\n      eprint={2410.03115}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"muhaz","keyword":"azerbaijani","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/muhaz","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\n\t\n\t\t\n\t\tDataset Card for Muhaz.org\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 501,323 pages of educational content primarily in Turkish and Azerbaijani languages with some Russian content extracted from muhaz.org website. The content includes academic and educational materials, with a focus on technical and scientific topics.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is primarily in Turkish (tr) and Azerbaijani (az) with some Russian (ru) content.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/muhaz.","first_N":5,"first_N_keywords":["text-classification","text-generation","topic-classification","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"vqa-v1.1","keyword":"azerbaijani","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldcuisines/vqa-v1.1","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\n\t\n\t\t\n\t\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\n\t\n\n\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 October 2024.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa-v1.1.","first_N":5,"first_N_keywords":["multilingual","English","Indonesian","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","description":"\n\n\n\t\n\t\t\n\t\tüî∑ Accepted in NAACL Proceedings (2025) üî∑\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval üìö [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"az_multilingual_pairs","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LocalDoc/az_multilingual_pairs","creator_name":"LocalDoc","creator_url":"https://huggingface.co/LocalDoc","description":"\n\t\n\t\t\n\t\tAzerbaijan Multilingual Translation Benchmark\n\t\n\nThis dataset provides parallel text data for benchmarking machine translation quality between Azerbaijani (az) and multiple target languages:\n\nAzerbaijani-English (az_en)\nAzerbaijani-French (az_fr) \nAzerbaijani-Russian (az_ru)\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe dataset contains three splits, one for each language pair:\n\naz_en: Azerbaijani-English translation pairs\naz_fr: Azerbaijani-French translation pairs\naz_ru: Azerbaijani-Russian translation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LocalDoc/az_multilingual_pairs.","first_N":5,"first_N_keywords":["translation","Azerbaijani","English","French","Russian"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy It‚Äôs Important\n\t\n\n\nEnhances Trust: For readers and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"spell_mistake_correct_pairs_azerbaijani","keyword":"azerbaijani","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LocalDoc/spell_mistake_correct_pairs_azerbaijani","creator_name":"LocalDoc","creator_url":"https://huggingface.co/LocalDoc","description":"\n\t\n\t\t\n\t\tAzerbaijani Spelling Correction Dataset\n\t\n\nThis dataset contains synthetically generated spelling errors in Azerbaijani text, paired with their corrections. It's designed to help train and evaluate models for Azerbaijani spelling correction tasks.\nTraining code: https://github.com/LocalDoc-Azerbaijan/azerbaijani_spell_correction_transformer_model\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\nThe dataset includes four main error types:\n\nTRANSLITERATION: Common substitutions in informal Azerbaijani‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LocalDoc/spell_mistake_correct_pairs_azerbaijani.","first_N":5,"first_N_keywords":["token-classification","Azerbaijani","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"court_cases_azerbaijani","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LocalDoc/court_cases_azerbaijani","creator_name":"LocalDoc","creator_url":"https://huggingface.co/LocalDoc","description":"\n\t\n\t\t\n\t\tCourt Cases Of The Republic Of Azerbaijan\n\t\n\nThis dataset consists of court cases from the Republic of Azerbaijan.\n\n\t\n\t\t\n\t\tOverview\n\t\n\n It was formed based on 1,200,000 court cases. \n The data has been preliminarily normalized and split into sentences. \n The dataset consists of 37 million sentences and approximately 500-600 million tokens.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor more information, questions, or issues, please contact LocalDoc at [v.resad.89@gmail.com].\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LocalDoc/court_cases_azerbaijani.","first_N":5,"first_N_keywords":["Azerbaijani","apache-2.0","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Azerbaijani-Turki-Book-Dataset","keyword":"azerbaijani","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mah92/Azerbaijani-Turki-Book-Dataset","creator_name":"ali.mahmoudi","creator_url":"https://huggingface.co/mah92","description":"\n\t\n\t\t\n\t\tÿ®ÿ≥ŸÖ ÿßŸÑŸÑŸá\n\t\n\nÿß€åŸÜ ÿØÿßÿØ⁄ØÿßŸÜ ÿ¥ÿßŸÖŸÑ ÿ¨ŸÖŸÑÿßÿ™ ÿ™ÿ±⁄©€å ÿ¢ÿ∞ÿ±ÿ®ÿß€åÿ¨ÿßŸÜ€å  €µ ⁄©ÿ™ÿßÿ® ÿ®ÿß ÿÆÿ∑ ŸÇÿ±ÿßŸÜ€å ÿßÿ≥ÿ™. ÿ¨ŸÖŸÑÿßÿ™ ÿ®ÿ±ÿß€å ÿ≠ŸÅÿ∏ ÿßŸÖÿßŸÜÿ™ ÿØÿßÿ±€å ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ÿßŸÜÿ™ÿ¥ÿßÿ±ÿßÿ™ ÿ≥ÿßŸàÿßŸÑÿßŸÜ ÿß€å⁄Ø€åÿØŸÑÿ±€å ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿ™ÿµÿßÿØŸÅ€å ÿ®Ÿá ŸáŸÖ ÿ±€åÿÆÿ™Ÿá ÿßÿ≥ÿ™.\nÿßÿ≤ ÿ¢ŸÇÿß€å ÿπŸÖÿßÿ± ÿßÿ≠ŸÖÿØ€å ÿπÿ≤€åÿ≤ ⁄©Ÿá ÿ®Ÿá ŸÖŸÜ ÿßÿπÿ™ŸÖÿßÿØ ⁄©ÿ±ÿØŸÜÿØ Ÿà ŸÅÿß€åŸÑ Ÿàÿ±ÿØ ÿß€åŸÜ ⁄©ÿ™ÿßÿ® Ÿáÿß ÿ±ÿß ÿØÿ± ÿßÿÆÿ™€åÿßÿ± ŸÖŸÜ ŸÇÿ±ÿßÿ± ÿØÿßÿØŸÜÿØ ŸÖÿ™ÿ¥⁄©ÿ±ŸÖ.\nÿπŸÜÿßŸà€åŸÜ ÿß€åŸÜ €µ ⁄©ÿ™ÿßÿ® ÿ®Ÿá ÿ¥ÿ±ÿ≠ ÿ≤€åÿ± ÿßÿ≥ÿ™:\n\n⁄©ŸÑ€åÿßÿ™ ÿØ€åŸàÿßŸÜ ÿ¥ÿßŸá ÿßÿ≥ŸÖÿßÿπ€åŸÑ ÿµŸÅŸà€å (ÿÆÿ∑ÿß€å€å)\nÿ±ŸàŸÖÿßŸÜ ÿ¥€åÿÆ ŸÖÿ≠ŸÖÿØ ÿÆ€åÿßÿ®ÿßŸÜ€å\nÿ®ÿ¶ŸÑŸá ÿØÿ¶ÿØ€å ÿ≤ÿ±ÿØŸàÿ¥ÿ™ - ŸÅÿ±€åÿØÿ±€åÿÆ ŸÜ€å⁄ÜŸá\nÿßÿµŸÑŸÄ€å ÿß€åŸÑŸÄŸá ⁄©ŸÄŸÄÿ±ŸÖ - (€åÿ¶ŸÜ€å ÿ®ÿßÿÆ€åÿ¥ ⁄©ŸÑÿßÿ≥€å⁄© ŸÅŸàŸÑ⁄©ŸÑŸàÿ± ÿßÿØÿ®€åÿßÿ™€åŸÖ€åÿ≤ÿß)\n⁄©ŸÄŸÄŸÄŸàÿ±ÿßŸàÿ∫ŸÑŸà ÿß€åŸÑŸá ŸÜ€å⁄Øÿßÿ± - (€åÿ¶ŸÜ€å‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mah92/Azerbaijani-Turki-Book-Dataset.","first_N":5,"first_N_keywords":["Azerbaijani","cc0-1.0","10K - 100K","text","Text"],"keywords_longer_than_N":true},
	{"name":"hellaswag-azerbaijani","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eljanmahammadli/hellaswag-azerbaijani","creator_name":"Eljan Mahammadli","creator_url":"https://huggingface.co/eljanmahammadli","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset is a translated version of Rowan/hellaswag into Azerbaijani. Only the ctx and endings columns have been translated, resulting in the new columns ctx_az and endings_az. The translation was done using Gemini Flash 2.0. A few samples (around 200) were removed due to errors arising from JSON parsing of the LLM response.\n@inproceedings{zellers2019hellaswag,\n    title={HellaSwag: Can a Machine Really Finish Your Sentence?},\n    author={Zellers, Rowan and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eljanmahammadli/hellaswag-azerbaijani.","first_N":5,"first_N_keywords":["text-classification","Azerbaijani","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"2M-Belebele","keyword":"azerbaijani","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\t2M-Belebele\n\t\n\n\n\t\n\t\t\n\t\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\n\t\n\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs datasets as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.","first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Bulgarian","Panjabi","English"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"azerbaijani","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tBelebele-Fleurs\n\t\n\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\n\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"reranking-datasets-light","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","description":"\n\t\n\t\t\n\t\tüî• Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation üî•\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\n\t\n\n\n    \n    \n    \n    \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n    \n\n\n\nA curated collection of ready-to-use datasets for retrieval and reranking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light.","first_N":5,"first_N_keywords":["question-answering","English","Arabic","German","French"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"azerbaijani","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"az_personal_info_aug_masked","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aimtune/az_personal_info_aug_masked","creator_name":"Hamza Agar","creator_url":"https://huggingface.co/aimtune","description":"\n\t\n\t\t\n\t\tüìò Overview\n\t\n\nThis dataset consists of augmented Azerbaijani text pairs (clean & masked) that contain personally identifiable information (PII). All content has been automatically generated using ChatGPT to simulate sensitive data scenarios for tasks like PII detection, anonymization, entity masking, and secure data handling.\n\n\n\t\n\t\t\n\t\tüîç Dataset Structure\n\t\n\nEach example is a paired record:\n\noriginal: The full augmented Azerbaijani text containing PII.\nmasked: The same text with PII‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aimtune/az_personal_info_aug_masked.","first_N":5,"first_N_keywords":["mask-generation","Azerbaijani","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"az_personal_info_aug_masked","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aimtune/az_personal_info_aug_masked","creator_name":"Hamza Agar","creator_url":"https://huggingface.co/aimtune","description":"\n\t\n\t\t\n\t\tüìò Overview\n\t\n\nThis dataset consists of augmented Azerbaijani text pairs (clean & masked) that contain personally identifiable information (PII). All content has been automatically generated using ChatGPT to simulate sensitive data scenarios for tasks like PII detection, anonymization, entity masking, and secure data handling.\n\n\n\t\n\t\t\n\t\tüîç Dataset Structure\n\t\n\nEach example is a paired record:\n\noriginal: The full augmented Azerbaijani text containing PII.\nmasked: The same text with PII‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aimtune/az_personal_info_aug_masked.","first_N":5,"first_N_keywords":["mask-generation","Azerbaijani","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"quran_multilingual_parallel","keyword":"azerbaijani","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/quran_multilingual_parallel","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüìò Qur‚Äôan Multilingual Parallel Dataset (quran_multilingual_parallel)\n\t\n\nThis dataset presents a clean, structurally-aligned multilingual parallel corpus of the Qur‚Äôanic text. It is intended for linguistic, computational, and cross-lingual AI applications ‚Äî not only for religious interpretation.\nIt contains over 6,200 verse-level alignments in 54 human languages, formatted in a machine-friendly .csv structure with language-specific translation fields.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüß† Dataset Highlights‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/quran_multilingual_parallel.","first_N":5,"first_N_keywords":["translation","Arabic","Albanian","Amharic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"wikipedia-citation-index","keyword":"azerbaijani","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia-citation-index","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Dataset with citation indexes as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions. Research: ArXiv\n","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"triplet_dataset_azerbaijani","keyword":"azerbaijani","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LocalDoc/triplet_dataset_azerbaijani","creator_name":"LocalDoc","creator_url":"https://huggingface.co/LocalDoc","description":"\n\t\n\t\t\n\t\tTriplet Dataset Azerbaijani\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 598,000 triplets in Azerbaijani language. Each triplet consists of:\n\nanchor: The base text\npositive: Text semantically similar to the anchor\nnegative: Text semantically different from the anchor\n\n\n\t\n\t\t\n\t\tContent Sources\n\t\n\nThe dataset is compiled from diverse Azerbaijani language sources:\n\nNews articles\nWikipedia content\nInvestment-related articles\nReligious texts\nSports news\nCourt decisions\nArticles‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LocalDoc/triplet_dataset_azerbaijani.","first_N":5,"first_N_keywords":["sentence-similarity","Azerbaijani","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"triplet_dataset_azerbaijani","keyword":"azerbaijani","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LocalDoc/triplet_dataset_azerbaijani","creator_name":"LocalDoc","creator_url":"https://huggingface.co/LocalDoc","description":"\n\t\n\t\t\n\t\tTriplet Dataset Azerbaijani\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 598,000 triplets in Azerbaijani language. Each triplet consists of:\n\nanchor: The base text\npositive: Text semantically similar to the anchor\nnegative: Text semantically different from the anchor\n\n\n\t\n\t\t\n\t\tContent Sources\n\t\n\nThe dataset is compiled from diverse Azerbaijani language sources:\n\nNews articles\nWikipedia content\nInvestment-related articles\nReligious texts\nSports news\nCourt decisions\nArticles‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LocalDoc/triplet_dataset_azerbaijani.","first_N":5,"first_N_keywords":["sentence-similarity","Azerbaijani","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"aznli-benchmark","keyword":"azerbaijani","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LocalDoc/aznli-benchmark","creator_name":"LocalDoc","creator_url":"https://huggingface.co/LocalDoc","description":"\n\t\n\t\t\n\t\tAzNLI-Benchmark: Azerbaijani Natural Language Inference\n\t\n\nThis repository contains the AzNLI benchmark dataset for Natural Language Inference (NLI) in the Azerbaijani language. NLI is a fundamental task in natural language understanding where the goal is to determine the logical relationship between two sentences. This dataset is part of the translated version of https://huggingface.co/datasets/sentence-transformers/all-nli\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\nThe AzNLI benchmark consists‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LocalDoc/aznli-benchmark.","first_N":5,"first_N_keywords":["token-classification","Azerbaijani","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true}
]
;
